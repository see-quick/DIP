[[1;34mINFO[m] Scanning for projects...
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] [1mReactor Build Order:[m
[[1;34mINFO[m] 
[[1;34mINFO[m] Strimzi - Apache Kafka on Kubernetes and OpenShift                 [pom]
[[1;34mINFO[m] test                                                               [jar]
[[1;34mINFO[m] crd-annotations                                                    [jar]
[[1;34mINFO[m] crd-generator                                                      [jar]
[[1;34mINFO[m] api                                                                [jar]
[[1;34mINFO[m] mockkube                                                           [jar]
[[1;34mINFO[m] config-model                                                       [jar]
[[1;34mINFO[m] certificate-manager                                                [jar]
[[1;34mINFO[m] operator-common                                                    [jar]
[[1;34mINFO[m] systemtest                                                         [jar]
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m-------------------------< [0;36mio.strimzi:strimzi[0;1m >-------------------------[m
[[1;34mINFO[m] [1mBuilding Strimzi - Apache Kafka on Kubernetes and OpenShift 0.29.0-SNAPSHOT [1/10][m
[[1;34mINFO[m] [1m--------------------------------[ pom ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mstrimzi[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mstrimzi[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] No tests to run.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Skipping pom project
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--------------------------< [0;36mio.strimzi:test[0;1m >---------------------------[m
[[1;34mINFO[m] [1mBuilding test 0.29.0-SNAPSHOT                                     [2/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/test/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/test/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/test/src/test/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] No sources to compile
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] No tests to run.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mtest[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/test/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mtest[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/test/target/test-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] No tests to run.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m---------------------< [0;36mio.strimzi:crd-annotations[0;1m >---------------------[m
[[1;34mINFO[m] [1mBuilding crd-annotations 0.29.0-SNAPSHOT                          [3/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/crd-annotations/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/crd-annotations/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/crd-annotations/src/test/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mcrd-annotations[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/crd-annotations/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mcrd-annotations[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/crd-annotations/target/crd-annotations-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mcrd-annotations[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m----------------------< [0;36mio.strimzi:crd-generator[0;1m >----------------------[m
[[1;34mINFO[m] [1mBuilding crd-generator 0.29.0-SNAPSHOT                            [4/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/crd-generator/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/crd-generator/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 7 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mcrd-generator[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/crd-generator/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mcrd-generator[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/crd-generator/target/crd-generator-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-shade-plugin:3.1.0:shade[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Including io.strimzi:crd-annotations:jar:0.29.0-SNAPSHOT in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.core:jackson-core:jar:2.12.6 in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.core:jackson-databind:jar:2.12.6.1 in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.dataformat:jackson-dataformat-yaml:jar:2.12.6 in the shaded jar.
[[1;34mINFO[m] Including org.yaml:snakeyaml:jar:1.27 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-client:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-rbac:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-admissionregistration:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-apps:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-autoscaling:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-apiextensions:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-batch:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-certificates:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-coordination:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-discovery:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-events:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-extensions:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-flowcontrol:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-networking:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-metrics:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-policy:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-scheduling:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-storageclass:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-node:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including com.squareup.okhttp3:okhttp:jar:3.12.12 in the shaded jar.
[[1;34mINFO[m] Including com.squareup.okio:okio:jar:1.15.0 in the shaded jar.
[[1;34mINFO[m] Including com.squareup.okhttp3:logging-interceptor:jar:3.12.12 in the shaded jar.
[[1;34mINFO[m] Including org.slf4j:slf4j-api:jar:1.7.36 in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.datatype:jackson-datatype-jsr310:jar:2.13.1 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:zjsonpatch:jar:0.3.0 in the shaded jar.
[[1;34mINFO[m] Including com.github.mifmif:generex:jar:1.0.2 in the shaded jar.
[[1;34mINFO[m] Including dk.brics.automaton:automaton:jar:1.11-8 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-core:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-common:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.core:jackson-annotations:jar:2.12.6 in the shaded jar.
[[1;33mWARNING[m] Discovered module-info.class. Shading will break its strong encapsulation.
[[1;33mWARNING[m] Discovered module-info.class. Shading will break its strong encapsulation.
[[1;33mWARNING[m] Discovered module-info.class. Shading will break its strong encapsulation.
[[1;33mWARNING[m] Discovered module-info.class. Shading will break its strong encapsulation.
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, generex-1.0.2.jar define 7 overlapping classes: 
[[1;33mWARNING[m]   - com.mifmif.common.regex.GenerexIterator
[[1;33mWARNING[m]   - com.mifmif.common.regex.Generex
[[1;33mWARNING[m]   - com.mifmif.common.regex.GenerexIterator$Step
[[1;33mWARNING[m]   - com.mifmif.common.regex.Node
[[1;33mWARNING[m]   - com.mifmif.common.regex.Main
[[1;33mWARNING[m]   - com.mifmif.common.regex.util.Iterable
[[1;33mWARNING[m]   - com.mifmif.common.regex.util.Iterator
[[1;33mWARNING[m] kubernetes-model-rbac-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 80 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.SubjectBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.ClusterRoleBindingFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.RoleListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.ClusterRoleBindingFluent$MetadataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.RoleBindingBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.ClusterRoleBindingBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.AggregationRuleFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.SubjectFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.ClusterRoleListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.PolicyRuleFluent
[[1;33mWARNING[m]   - 70 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, jackson-annotations-2.12.6.jar define 71 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonAutoDetect
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonInclude
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.ObjectIdGenerators
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonFormat$Features
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonFormat$Feature
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonIgnore
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonSetter
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonTypeInfo$None
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonFormat$Shape
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonSubTypes
[[1;33mWARNING[m]   - 61 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-extensions-5.12.0.jar define 264 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.DaemonSetConditionBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.NetworkPolicyListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.DeploymentStrategyFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.IngressListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.NetworkPolicySpecFluent$IngressNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.IngressStatus
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.DaemonSetFluentImpl$SpecNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.IngressSpecFluent$RulesNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.DaemonSetSpecFluent$UpdateStrategyNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.NetworkPolicyPeerBuilder
[[1;33mWARNING[m]   - 254 more...
[[1;33mWARNING[m] kubernetes-model-autoscaling-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 350 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.MetricSpecFluentImpl$ObjectNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta2.HorizontalPodAutoscalerSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.CrossVersionObjectReferenceBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.HorizontalPodAutoscalerStatusFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta2.HorizontalPodAutoscalerFluent$SpecNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta2.ContainerResourceMetricStatusFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.HorizontalPodAutoscalerStatus
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.MetricStatusFluent$ObjectNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta2.HorizontalPodAutoscalerSpecFluent$ScaleTargetRefNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.HorizontalPodAutoscalerFluent$SpecNested
[[1;33mWARNING[m]   - 340 more...
[[1;33mWARNING[m] kubernetes-model-storageclass-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 172 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.v1beta1.CSIStorageCapacityListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.CSINodeFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.CSINodeDriverFluentImpl$AllocatableNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.StorageClass
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.VolumeAttachmentSourceBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.VolumeAttachmentSourceFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.TokenRequestFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.v1beta1.CSINodeDriverFluent$AllocatableNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.v1beta1.CSIDriverSpecBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.VolumeAttachmentSpecFluent
[[1;33mWARNING[m]   - 162 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-batch-5.12.0.jar define 112 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.JobFluentImpl$StatusNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.CronJobStatusFluentImpl$ActiveNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.JobSpecFluent$TemplateNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1beta1.CronJobListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1beta1.CronJobSpecFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.JobSpecFluentImpl$TemplateNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.Job
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1beta1.CronJobFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1beta1.CronJobListFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.CronJobListFluent
[[1;33mWARNING[m]   - 102 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-apiextensions-5.12.0.jar define 350 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceDefinitionVersionBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.JSONSchemaPropsOrBoolBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceDefinitionSpecFluent$ValidationNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceDefinitionVersionFluentImpl$SchemaNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.JSONSchemaPropsOrStringArraySerDe$Deserializer$1
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceValidationFluentImpl$OpenAPIV3SchemaNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.JSONSchemaPropsFluentImpl$NotNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.WebhookClientConfigFluentImpl$ServiceNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.JSONSchemaPropsOrArrayFluent$SchemaNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1.JSONSchemaPropsOrBoolSerDe
[[1;33mWARNING[m]   - 340 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-discovery-5.12.0.jar define 88 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointSliceFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1.EndpointSliceBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointPort
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.ForZoneBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1.EndpointFluent$TargetRefNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointFluentImpl$ConditionsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1.EndpointSliceListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointConditionsFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointSliceListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - 78 more...
[[1;33mWARNING[m] okhttp-3.12.12.jar, crd-generator-0.29.0-SNAPSHOT.jar define 208 overlapping classes: 
[[1;33mWARNING[m]   - okhttp3.WebSocket
[[1;33mWARNING[m]   - okhttp3.Cookie$Builder
[[1;33mWARNING[m]   - okhttp3.internal.http.HttpHeaders
[[1;33mWARNING[m]   - okhttp3.internal.http2.Http2Connection$ReaderRunnable
[[1;33mWARNING[m]   - okhttp3.internal.http2.Http2Reader$ContinuationSource
[[1;33mWARNING[m]   - okhttp3.internal.tls.OkHostnameVerifier
[[1;33mWARNING[m]   - okhttp3.Cache$Entry
[[1;33mWARNING[m]   - okhttp3.internal.http2.Http2Connection$3
[[1;33mWARNING[m]   - okhttp3.internal.ws.RealWebSocket$Streams
[[1;33mWARNING[m]   - okhttp3.CacheControl$Builder
[[1;33mWARNING[m]   - 198 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-metrics-5.12.0.jar define 30 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.PodMetricsFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetricsListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.ContainerMetricsFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetrics
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetricsListFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetricsListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetricsFluent$MetadataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.PodMetricsFluentImpl$ContainersNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.PodMetricsListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.PodMetricsListBuilder
[[1;33mWARNING[m]   - 20 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-flowcontrol-5.12.0.jar define 132 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfigurationFluentImpl$SpecNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.FlowSchemaConditionFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.FlowDistinguisherMethodBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfigurationReferenceBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.QueuingConfiguration
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.QueuingConfigurationFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfiguration
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfigurationReference
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PolicyRulesWithSubjects
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfigurationListFluent$ItemsNested
[[1;33mWARNING[m]   - 122 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-events-5.12.0.jar define 44 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventFluent$MetadataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventFluent$SeriesNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1.EventList
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1.EventListBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventFluent$RegardingNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1.EventSeriesFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - 34 more...
[[1;33mWARNING[m] automaton-1.11-8.jar, crd-generator-0.29.0-SNAPSHOT.jar define 25 overlapping classes: 
[[1;33mWARNING[m]   - dk.brics.automaton.AutomatonMatcher
[[1;33mWARNING[m]   - dk.brics.automaton.ShuffleOperations$ShuffleConfiguration
[[1;33mWARNING[m]   - dk.brics.automaton.RegExp$Kind
[[1;33mWARNING[m]   - dk.brics.automaton.RunAutomaton
[[1;33mWARNING[m]   - dk.brics.automaton.Automaton
[[1;33mWARNING[m]   - dk.brics.automaton.RegExp
[[1;33mWARNING[m]   - dk.brics.automaton.AutomatonProvider
[[1;33mWARNING[m]   - dk.brics.automaton.RegExp$1
[[1;33mWARNING[m]   - dk.brics.automaton.MinimizationOperations$StateListNode
[[1;33mWARNING[m]   - dk.brics.automaton.State
[[1;33mWARNING[m]   - 15 more...
[[1;33mWARNING[m] jackson-core-2.12.6.jar, crd-generator-0.29.0-SNAPSHOT.jar define 124 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.JsonGenerator$Feature
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.json.JsonReadFeature
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.util.ThreadLocalBufferManager$ThreadLocalBufferManagerHolder
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.util.Separators
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.io.SegmentedStringWriter
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.TreeNode
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.sym.Name
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.util.RequestPayload
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.util.JsonGeneratorDelegate
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.async.NonBlockingInputFeeder
[[1;33mWARNING[m]   - 114 more...
[[1;33mWARNING[m] kubernetes-model-networking-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 234 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1beta1.IngressClassListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1beta1.IngressClassListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.IngressServiceBackend
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyPort
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1beta1.IngressFluentImpl$StatusNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1beta1.IngressClassSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.IngressStatus
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.IngressClassFluent$SpecNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.IngressRuleFluentImpl$HttpNestedImpl
[[1;33mWARNING[m]   - 224 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-coordination-5.12.0.jar define 18 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseFluentImpl$SpecNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseFluent$SpecNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseSpecBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseSpecFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseFluentImpl$MetadataNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseListFluent
[[1;33mWARNING[m]   - 8 more...
[[1;33mWARNING[m] zjsonpatch-0.3.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 24 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.sequence.InsertCommand
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.Operation
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.sequence.CommandVisitor
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.guava.Strings
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.sequence.EditCommand
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.JsonDiff$EncodePathFunction
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.sequence.SequencesComparator
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.Diff
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.ListUtils
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.JsonPatch
[[1;33mWARNING[m]   - 14 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-common-5.12.0.jar define 16 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.Plural
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.Group
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.jackson.JsonUnwrappedDeserializer$CancelUnwrapped
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.jackson.JsonUnwrappedDeserializer
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.PrinterColumn
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.jackson.UnwrappedTypeResolverBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.Singular
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.StatusReplicas
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.SpecReplicas
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.Version
[[1;33mWARNING[m]   - 6 more...
[[1;33mWARNING[m] kubernetes-model-admissionregistration-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 362 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1beta1.MutatingWebhookFluent$ObjectSelectorNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authorization.v1.SubjectAccessReviewSpecFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authorization.v1beta1.SubjectRulesReviewStatusBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1.ValidatingWebhookConfigurationBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authentication.TokenReviewFluentImpl$MetadataNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authorization.v1beta1.SelfSubjectRulesReviewSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1beta1.MutatingWebhookFluentImpl$NamespaceSelectorNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1beta1.MutatingWebhookConfigurationFluentImpl$WebhooksNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authorization.v1beta1.SelfSubjectAccessReviewFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1.MutatingWebhookFluent$ClientConfigNested
[[1;33mWARNING[m]   - 352 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, okio-1.15.0.jar define 44 overlapping classes: 
[[1;33mWARNING[m]   - okio.ByteString
[[1;33mWARNING[m]   - okio.Source
[[1;33mWARNING[m]   - okio.ForwardingSink
[[1;33mWARNING[m]   - okio.BufferedSource
[[1;33mWARNING[m]   - okio.Util
[[1;33mWARNING[m]   - okio.AsyncTimeout$1
[[1;33mWARNING[m]   - okio.HashingSource
[[1;33mWARNING[m]   - okio.GzipSink
[[1;33mWARNING[m]   - okio.Okio$1
[[1;33mWARNING[m]   - okio.Pipe$PipeSink
[[1;33mWARNING[m]   - 34 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-certificates-5.12.0.jar define 60 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestStatusFluent$ConditionsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestFluent$SpecNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestFluentImpl$StatusNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestStatusFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestFluent$MetadataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestConditionFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestStatusBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestStatusFluent$ConditionsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestFluentImpl
[[1;33mWARNING[m]   - 50 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, jackson-datatype-jsr310-2.13.1.jar define 59 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.deser.LocalDateDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.deser.key.Jsr310KeyDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.PackageVersion
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.deser.YearDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.ser.key.Jsr310NullKeySerializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.deser.key.LocalDateTimeKeyDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.util.DurationUnitConverter
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.ser.InstantSerializerBase
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.ser.LocalDateTimeSerializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.ser.OffsetDateTimeSerializer
[[1;33mWARNING[m]   - 49 more...
[[1;33mWARNING[m] crd-annotations-0.29.0-SNAPSHOT.jar, crd-generator-0.29.0-SNAPSHOT.jar define 8 overlapping classes: 
[[1;33mWARNING[m]   - io.strimzi.api.annotations.VersionRange
[[1;33mWARNING[m]   - io.strimzi.api.annotations.ApiVersion
[[1;33mWARNING[m]   - io.strimzi.api.annotations.ApiVersion$Stability
[[1;33mWARNING[m]   - io.strimzi.api.annotations.ApiVersion$1
[[1;33mWARNING[m]   - io.strimzi.api.annotations.DeprecatedType
[[1;33mWARNING[m]   - io.strimzi.api.annotations.DeprecatedProperty
[[1;33mWARNING[m]   - io.strimzi.api.annotations.VersionRange$VersionParser
[[1;33mWARNING[m]   - io.strimzi.api.annotations.KubeVersion
[[1;33mWARNING[m] kubernetes-model-apps-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 212 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ReplicaSetSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.StatefulSetConditionFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.DeploymentStrategyFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ControllerRevisionFluent$DeploymentDataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ReplicaSetSpecFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.DeploymentFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ReplicaSetStatusFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ControllerRevisionFluentImpl$PersistentVolumeClaimDataNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ReplicaSetCondition
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.StatefulSetSpecFluent$UpdateStrategyNested
[[1;33mWARNING[m]   - 202 more...
[[1;33mWARNING[m] logging-interceptor-3.12.12.jar, crd-generator-0.29.0-SNAPSHOT.jar define 8 overlapping classes: 
[[1;33mWARNING[m]   - okhttp3.logging.HttpLoggingInterceptor$Logger$1
[[1;33mWARNING[m]   - okhttp3.logging.LoggingEventListener$Factory
[[1;33mWARNING[m]   - okhttp3.logging.HttpLoggingInterceptor$Level
[[1;33mWARNING[m]   - okhttp3.logging.HttpLoggingInterceptor
[[1;33mWARNING[m]   - okhttp3.logging.package-info
[[1;33mWARNING[m]   - okhttp3.logging.LoggingEventListener
[[1;33mWARNING[m]   - okhttp3.logging.LoggingEventListener$1
[[1;33mWARNING[m]   - okhttp3.logging.HttpLoggingInterceptor$Logger
[[1;33mWARNING[m] jackson-dataformat-yaml-2.12.6.jar, crd-generator-0.29.0-SNAPSHOT.jar define 17 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLMapper$Builder
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.snakeyaml.error.Mark
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLGenerator
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.UTF8Reader
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLParser
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.util.StringQuotingChecker
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLGenerator$Feature
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.JacksonYAMLParseException
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLParser$Feature
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.util.StringQuotingChecker$Default
[[1;33mWARNING[m]   - 7 more...
[[1;33mWARNING[m] kubernetes-model-core-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 2394 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.BaseKubernetesListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.StatusBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.KubeSchemaFluentImpl$APIResourceNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.NodeListBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.ResourceQuotaListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.WatchEventFluentImpl$APIServiceStatusObjectNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.WatchEventFluent$VsphereVirtualDiskVolumeSourceObjectNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.ProbeFluentImpl$HttpGetNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.PatchOptionsFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.ServerAddressByClientCIDRFluentImpl
[[1;33mWARNING[m]   - 2384 more...
[[1;33mWARNING[m] slf4j-api-1.7.36.jar, crd-generator-0.29.0-SNAPSHOT.jar define 34 overlapping classes: 
[[1;33mWARNING[m]   - org.slf4j.helpers.SubstituteLogger
[[1;33mWARNING[m]   - org.slf4j.helpers.NamedLoggerBase
[[1;33mWARNING[m]   - org.slf4j.helpers.NOPMDCAdapter
[[1;33mWARNING[m]   - org.slf4j.MarkerFactory
[[1;33mWARNING[m]   - org.slf4j.helpers.BasicMarker
[[1;33mWARNING[m]   - org.slf4j.spi.LoggerFactoryBinder
[[1;33mWARNING[m]   - org.slf4j.MDC$MDCCloseable
[[1;33mWARNING[m]   - org.slf4j.spi.LocationAwareLogger
[[1;33mWARNING[m]   - org.slf4j.helpers.MessageFormatter
[[1;33mWARNING[m]   - org.slf4j.helpers.Util$ClassContextSecurityManager
[[1;33mWARNING[m]   - 24 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-node-5.12.0.jar define 78 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1beta1.OverheadBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1.RuntimeClassListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1alpha1.Scheduling
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1beta1.RuntimeClassFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1beta1.RuntimeClassListBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1.RuntimeClassFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1alpha1.SchedulingFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1alpha1.RuntimeClassSpecFluent$OverheadNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1.RuntimeClassBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1.RuntimeClassFluentImpl
[[1;33mWARNING[m]   - 68 more...
[[1;33mWARNING[m] jackson-databind-2.12.6.1.jar, crd-generator-0.29.0-SNAPSHOT.jar define 700 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.introspect.AnnotationCollector$NoAnnotations
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.jsontype.BasicPolymorphicTypeValidator$Builder
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.BeanDescription
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.deser.impl.BeanAsArrayBuilderDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.introspect.AnnotatedMethodMap
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.SerializerProvider
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.introspect.AnnotationCollector$OneAnnotation
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.ser.std.StaticListSerializerBase
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.ser.std.NumberSerializers$ShortSerializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.ser.BeanSerializerFactory
[[1;33mWARNING[m]   - 690 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, snakeyaml-1.27.jar define 216 overlapping classes: 
[[1;33mWARNING[m]   - org.yaml.snakeyaml.emitter.Emitter$ExpectBlockMappingValue
[[1;33mWARNING[m]   - org.yaml.snakeyaml.parser.ParserImpl$ParseBlockNode
[[1;33mWARNING[m]   - org.yaml.snakeyaml.emitter.Emitter$ExpectBlockMappingSimpleValue
[[1;33mWARNING[m]   - org.yaml.snakeyaml.emitter.Emitter$ExpectDocumentEnd
[[1;33mWARNING[m]   - org.yaml.snakeyaml.Yaml$3
[[1;33mWARNING[m]   - org.yaml.snakeyaml.emitter.Emitter$ExpectBlockSequenceItem
[[1;33mWARNING[m]   - org.yaml.snakeyaml.parser.ParserImpl$ParseBlockSequenceEntry
[[1;33mWARNING[m]   - org.yaml.snakeyaml.util.ArrayUtils
[[1;33mWARNING[m]   - org.yaml.snakeyaml.tokens.Token$ID
[[1;33mWARNING[m]   - org.yaml.snakeyaml.reader.StreamReader
[[1;33mWARNING[m]   - 206 more...
[[1;33mWARNING[m] kubernetes-client-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 536 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.internal.CertUtils
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.CustomResource
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.osgi.ManagedKubernetesClient
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.V1beta1ApiextensionAPIGroupDSL
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.internal.PatchUtils$SingletonHolder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.VersionInfo$1
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.utils.ReplaceValueStream
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.dsl.CreateFromServerGettable
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.dsl.ApiextensionsAPIGroupDSL
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.dsl.Containerable
[[1;33mWARNING[m]   - 526 more...
[[1;33mWARNING[m] kubernetes-model-scheduling-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 24 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassFluentImpl$MetadataNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassList
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1beta1.PriorityClassListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassListFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClass
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1beta1.PriorityClassBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1beta1.PriorityClassFluent$MetadataNested
[[1;33mWARNING[m]   - 14 more...
[[1;33mWARNING[m] kubernetes-model-policy-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 162 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1.PodDisruptionBudgetList
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.HostPortRangeBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.EvictionFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.PodSecurityPolicyFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.PodSecurityPolicySpecFluentImpl$AllowedCSIDriversNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.PodSecurityPolicyListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.AllowedFlexVolumeBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.IDRangeFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.SELinuxStrategyOptionsFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.PodSecurityPolicySpecFluentImpl$FsGroupNestedImpl
[[1;33mWARNING[m]   - 152 more...
[[1;33mWARNING[m] maven-shade-plugin has detected that some class files are
[[1;33mWARNING[m] present in two or more JARs. When this happens, only one
[[1;33mWARNING[m] single version of the class is copied to the uber jar.
[[1;33mWARNING[m] Usually this is not harmful and you can skip these warnings,
[[1;33mWARNING[m] otherwise try to manually exclude artifacts based on
[[1;33mWARNING[m] mvn dependency:tree -Ddetail=true and the above output.
[[1;33mWARNING[m] See http://maven.apache.org/plugins/maven-shade-plugin/
[[1;34mINFO[m] Replacing original artifact with shaded artifact.
[[1;34mINFO[m] Replacing /home/ec2-user/strimzi-kafka-operator/crd-generator/target/crd-generator-0.29.0-SNAPSHOT.jar with /home/ec2-user/strimzi-kafka-operator/crd-generator/target/crd-generator-0.29.0-SNAPSHOT-shaded.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m---------------------------< [0;36mio.strimzi:api[0;1m >---------------------------[m
[[1;34mINFO[m] [1mBuilding api 0.29.0-SNAPSHOT                                      [5/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/api/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/api/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mexec-maven-plugin:1.6.0:exec[m [1m(generate-crd-co-install-v1)[m @ [36mapi[0;1m ---[m
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mexec-maven-plugin:1.6.0:exec[m [1m(generate-crd-co-install-v1-eo)[m @ [36mapi[0;1m ---[m
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mexec-maven-plugin:1.6.0:exec[m [1m(generate-doc)[m @ [36mapi[0;1m ---[m
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 99 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-test-compile)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mapi[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/api/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mapi[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:test-jar[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m------------------------< [0;36mio.strimzi:mockkube[0;1m >-------------------------[m
[[1;34mINFO[m] [1mBuilding mockkube 0.29.0-SNAPSHOT                                 [6/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/mockkube/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/mockkube/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 1 resource
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mmockkube[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/mockkube/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mmockkube[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/mockkube/target/mockkube-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mmockkube[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m----------------------< [0;36mio.strimzi:config-model[0;1m >-----------------------[m
[[1;34mINFO[m] [1mBuilding config-model 0.29.0-SNAPSHOT                             [7/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/config-model/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/config-model/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/config-model/src/test/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mconfig-model[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/config-model/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mconfig-model[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/config-model/target/config-model-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mconfig-model[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m-------------------< [0;36mio.strimzi:certificate-manager[0;1m >-------------------[m
[[1;34mINFO[m] [1mBuilding certificate-manager 0.29.0-SNAPSHOT                      [8/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/certificate-manager/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 1 resource
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 1 resource
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mcertificate-manager[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/certificate-manager/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mcertificate-manager[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/certificate-manager/target/certificate-manager-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mcertificate-manager[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m---------------------< [0;36mio.strimzi:operator-common[0;1m >---------------------[m
[[1;34mINFO[m] [1mBuilding operator-common 0.29.0-SNAPSHOT                          [9/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/operator-common/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/operator-common/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 9 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36moperator-common[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/operator-common/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36moperator-common[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/operator-common/target/operator-common-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:test-jar[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m-----------------------< [0;36mio.strimzi:systemtest[0;1m >------------------------[m
[[1;34mINFO[m] [1mBuilding systemtest 0.29.0-SNAPSHOT                              [10/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/systemtest/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 3 resources
[[1;34mINFO[m] Copying 2 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Changes detected - recompiling the module!
[[1;34mINFO[m] Compiling 149 source files to /home/ec2-user/strimzi-kafka-operator/systemtest/target/classes
[2K  0% Generating: io.strimzi.systemtest.kafkaclients.internalClients.KafkaOauthClients[2K 17% Generating: io.strimzi.systemtest.kafkaclients.internalClients.BridgeClients[2K 33% Generating: io.strimzi.systemtest.kafkaclients.internalClients.BaseClients[2K 50% Generating: io.strimzi.systemtest.kafkaclients.internalClients.KafkaTracingClients[2K 67% Generating: io.strimzi.systemtest.kafkaclients.internalClients.KafkaClients[2K 83% Generating: io.strimzi.systemtest.kafkaclients.internalClients.KafkaAdminClients[[1;34mINFO[m] /home/ec2-user/strimzi-kafka-operator/systemtest/target/generated-sources/annotations/io/strimzi/systemtest/kafkaclients/internalClients/BaseClientsFluentImpl.java: Some input files use unchecked or unsafe operations.
[[1;34mINFO[m] /home/ec2-user/strimzi-kafka-operator/systemtest/target/generated-sources/annotations/io/strimzi/systemtest/kafkaclients/internalClients/BaseClientsFluentImpl.java: Recompile with -Xlint:unchecked for details.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 32 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Changes detected - recompiling the module!
[[1;34mINFO[m] Compiling 68 source files to /home/ec2-user/strimzi-kafka-operator/systemtest/target/test-classes
[[1;34mINFO[m] /home/ec2-user/strimzi-kafka-operator/systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthPlainIsolatedST.java: Some input files use or override a deprecated API.
[[1;34mINFO[m] /home/ec2-user/strimzi-kafka-operator/systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthPlainIsolatedST.java: Recompile with -Xlint:deprecation for details.
[[1;34mINFO[m] /home/ec2-user/strimzi-kafka-operator/systemtest/src/test/java/io/strimzi/systemtest/operators/CustomResourceStatusIsolatedST.java: /home/ec2-user/strimzi-kafka-operator/systemtest/src/test/java/io/strimzi/systemtest/operators/CustomResourceStatusIsolatedST.java uses unchecked or unsafe operations.
[[1;34mINFO[m] /home/ec2-user/strimzi-kafka-operator/systemtest/src/test/java/io/strimzi/systemtest/operators/CustomResourceStatusIsolatedST.java: Recompile with -Xlint:unchecked for details.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;33mWARNING[m] Corrupted STDOUT by directly writing to native stream in forked JVM 1. See FAQ web page and the dump file /home/ec2-user/strimzi-kafka-operator/systemtest/target/surefire-reports/2022-04-05T15-33-44_577-jvmRun1.dumpstream
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/systemtest/target/systemtest-0.29.0-SNAPSHOT.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36msystemtest[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/systemtest/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36msystemtest[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/systemtest/target/systemtest-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36msystemtest[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:29] =======================================================================
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:30] =======================================================================
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:31]                         Test run started
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:32] =======================================================================
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:33] =======================================================================
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:48] Following testclasses are selected for run:
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.user.UserST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.topic.ThrottlingQuotaST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.topic.TopicST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.ReconciliationST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.bridge.HttpBridgeScramShaST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.bridge.HttpBridgeTlsST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.tracing.TracingST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.cruisecontrol.CruiseControlApiST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.cruisecontrol.CruiseControlST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.listeners.ListenersST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.listeners.MultipleListenersST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.KafkaST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.ConfigProviderST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.custom.CustomAuthorizerST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.OpaIntegrationST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.SecurityST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.rollingupdate.RollingUpdateST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.log.LoggingChangeST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.log.LogSettingST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.FeatureGatesIsolatedST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.NamespaceRbacScopeOperatorIsolatedST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.RecoveryIsolatedST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.bridge.HttpBridgeIsolatedST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.specific.HelmChartIsolatedST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.specific.SpecificIsolatedST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.specific.DrainCleanerIsolatedST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.watcher.AllNamespaceIsolatedST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.connect.ConnectIsolatedST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.connect.ConnectBuilderIsolatedST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.metrics.MetricsIsolatedST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.metrics.JmxIsolatedST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.dump.LogDumpScriptIsolatedST
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:52] =======================================================================
2022-04-05 15:34:15 [main] [32mINFO [m [TestExecutionListener:53] =======================================================================
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.user.UserST
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:219] Used environment variables:
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:220] CONFIG: /home/ec2-user/strimzi-kafka-operator/systemtest/config.json
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] STRIMZI_RBAC_SCOPE: CLUSTER
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] OLM_APP_BUNDLE_PREFIX: strimzi-cluster-operator
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] TEST_CLIENTS_VERSION: 0.2.0
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] OLM_SOURCE_NAMESPACE: openshift-marketplace
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] CLUSTER_OPERATOR_INSTALL_TYPE: BUNDLE
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] STRIMZI_COMPONENTS_LOG_LEVEL: INFO
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] SKIP_TEARDOWN: false
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] LB_FINALIZERS: false
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] OLM_OPERATOR_DEPLOYMENT_NAME: strimzi-cluster-operator
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] DOCKER_ORG: strimzi
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] TEST_LOG_DIR: /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/target/logs/
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] COMPONENTS_IMAGE_PULL_POLICY: IfNotPresent
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] DOCKER_REGISTRY: quay.io
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] TEST_CLIENT_IMAGE: quay.io/strimzi/test-client:latest-kafka-3.1.0
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] SYSTEM_TEST_STRIMZI_IMAGE_PULL_SECRET: 
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] TEST_ADMIN_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-admin:0.2.0-kafka-3.1.0
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] TEST_HTTP_PRODUCER_IMAGE: quay.io/strimzi-test-clients/test-client-http-producer:0.2.0
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] OLM_OPERATOR_NAME: strimzi-kafka-operator
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] DOCKER_TAG: latest
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] OLM_SOURCE_NAME: community-operators
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] STRIMZI_FEATURE_GATES: 
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] CLIENTS_KAFKA_VERSION: 3.1.0
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] TEST_HTTP_CONSUMER_IMAGE: quay.io/strimzi-test-clients/test-client-http-consumer:0.2.0
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] STRIMZI_LOG_LEVEL: DEBUG
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] ST_KAFKA_VERSION: 3.1.0
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] OPERATOR_IMAGE_PULL_POLICY: Always
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] DEFAULT_TO_DENY_NETWORK_POLICIES: true
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] TEST_PRODUCER_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-producer:0.2.0-kafka-3.1.0
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] BRIDGE_IMAGE: latest-released
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] TEST_STREAMS_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-streams:0.2.0-kafka-3.1.0
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] TEST_CONSUMER_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-consumer:0.2.0-kafka-3.1.0
2022-04-05 15:34:15 [main] [32mINFO [m [Environment:221] OLM_OPERATOR_VERSION: 
2022-04-05 15:34:16 [main] [32mINFO [m [KubeCluster:87] Using cluster: minikube
2022-04-05 15:34:16 [main] [32mINFO [m [KubeClusterResource:60] Cluster default namespace is 'default'
2022-04-05 15:34:16 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-05 15:34:16 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-05 15:34:17 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-05 15:34:17 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 15:34:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 15:34:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 15:34:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 15:34:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 15:34:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 15:34:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 15:34:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 15:34:18 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 15:34:18 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 15:34:18 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 15:34:18 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 15:34:18 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 15:34:18 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 15:34:18 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 15:34:18 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 15:34:18 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 15:34:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 15:34:18 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-05 15:34:18 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 15:34:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 15:34:18 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-05 15:34:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 15:34:18 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-05 15:34:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 15:34:18 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 15:34:18 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 15:34:18 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-05 15:34:18 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 15:34:18 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 15:34:18 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 15:34:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 15:34:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 15:34:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 15:34:19 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-05 15:34:34 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-05 15:34:34 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-05 15:34:44 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-05 15:34:44 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: user-st
2022-04-05 15:34:44 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: user-st
2022-04-05 15:34:44 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: user-st
2022-04-05 15:34:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka user-cluster-name in namespace user-st
2022-04-05 15:34:44 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkas' with unstable version 'v1beta2'
2022-04-05 15:34:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: user-cluster-name will have desired state: Ready
2022-04-05 15:35:47 [main] [32mINFO [m [ResourceManager:444] Kafka: user-cluster-name is in desired state: Ready
2022-04-05 15:35:47 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 15:35:47 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testTlsExternalUserWithQuotas-STARTED
2022-04-05 15:35:47 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 15:35:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1155495614-133665974 in namespace user-st
2022-04-05 15:35:47 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkausers' with unstable version 'v1beta2'
2022-04-05 15:35:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1155495614-133665974 will have desired state: Ready
2022-04-05 15:35:48 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1155495614-133665974 is in desired state: Ready
2022-04-05 15:35:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace user-st exec user-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user CN=my-user-1155495614-133665974
2022-04-05 15:35:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 15:35:51 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion my-user-1155495614-133665974
2022-04-05 15:35:51 [main] [33mWARN [m [KafkaUserUtils:68] KafkaUser my-user-1155495614-133665974 is not deleted yet! Triggering force delete by cmd client!
2022-04-05 15:35:52 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser my-user-1155495614-133665974 deleted
2022-04-05 15:35:54 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace user-st exec user-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user CN=my-user-1155495614-133665974
2022-04-05 15:35:54 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 15:35:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 15:35:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTlsExternalUserWithQuotas
2022-04-05 15:35:54 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1155495614-133665974 in namespace user-st
2022-04-05 15:35:54 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 15:35:54 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testTlsExternalUserWithQuotas-FINISHED
2022-04-05 15:35:54 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 15:35:54 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 15:35:54 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testUserTemplate-STARTED
2022-04-05 15:35:54 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 15:35:54 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-2010519120-1565989627 in namespace user-st
2022-04-05 15:35:54 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-2010519120-1565989627 will have desired state: Ready
2022-04-05 15:35:55 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-2010519120-1565989627 is in desired state: Ready
2022-04-05 15:35:55 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 15:35:55 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUserTemplate
2022-04-05 15:35:55 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-2010519120-1565989627 in namespace user-st
2022-04-05 15:36:05 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 15:36:05 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testUserTemplate-FINISHED
2022-04-05 15:36:05 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 15:36:05 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 15:36:05 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testUpdateUser-STARTED
2022-04-05 15:36:05 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 15:36:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1262665635-1696981310 in namespace user-st
2022-04-05 15:36:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1262665635-1696981310 will have desired state: Ready
2022-04-05 15:36:06 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1262665635-1696981310 is in desired state: Ready
2022-04-05 15:36:08 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret my-user-1262665635-1696981310
2022-04-05 15:36:08 [main] [32mINFO [m [SecretUtils:50] Secret my-user-1262665635-1696981310 created
2022-04-05 15:36:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1262665635-1696981310 will have desired state: Ready
2022-04-05 15:36:08 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1262665635-1696981310 is in desired state: Ready
2022-04-05 15:36:08 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion my-user-1262665635-1696981310
2022-04-05 15:36:08 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser my-user-1262665635-1696981310 deleted
2022-04-05 15:36:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 15:36:08 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUpdateUser
2022-04-05 15:36:08 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1262665635-1696981310 in namespace user-st
2022-04-05 15:36:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 15:36:08 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testUpdateUser-FINISHED
2022-04-05 15:36:08 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 15:36:08 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 15:36:08 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testTlsExternalUser-STARTED
2022-04-05 15:36:08 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 15:36:08 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-0 for test case:testTlsExternalUser
2022-04-05 15:36:08 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-0
2022-04-05 15:36:08 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-0
2022-04-05 15:36:08 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-0
2022-04-05 15:36:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-09d6979d in namespace namespace-0
2022-04-05 15:36:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-0
2022-04-05 15:36:08 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-09d6979d will have desired state: Ready
2022-04-05 15:37:14 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-09d6979d is in desired state: Ready
2022-04-05 15:37:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-42918870-1699520234 in namespace namespace-0
2022-04-05 15:37:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-0
2022-04-05 15:37:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-42918870-1699520234 will have desired state: Ready
2022-04-05 15:37:15 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-42918870-1699520234 is in desired state: Ready
2022-04-05 15:37:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-42918870-1699520234 will have desired state: Ready
2022-04-05 15:37:15 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-42918870-1699520234 is in desired state: Ready
2022-04-05 15:37:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 15:37:15 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTlsExternalUser
2022-04-05 15:37:15 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-42918870-1699520234 in namespace namespace-0
2022-04-05 15:37:15 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-09d6979d in namespace namespace-0
2022-04-05 15:37:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 15:37:25 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-0 for test case:testTlsExternalUser
2022-04-05 15:37:31 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testTlsExternalUser-FINISHED
2022-04-05 15:37:31 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 15:37:31 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 15:37:31 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testUserWithNameMoreThan64Chars-STARTED
2022-04-05 15:37:31 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 15:37:31 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser user-with-correct-nameabcdefghijklmnopqrstuvxyzabcdefghijklmnopq in namespace user-st
2022-04-05 15:37:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: user-with-correct-nameabcdefghijklmnopqrstuvxyzabcdefghijklmnopq will have desired state: Ready
2022-04-05 15:37:32 [main] [32mINFO [m [ResourceManager:444] KafkaUser: user-with-correct-nameabcdefghijklmnopqrstuvxyzabcdefghijklmnopq is in desired state: Ready
2022-04-05 15:37:32 [main] [32mINFO [m [KafkaUserUtils:90] Wait until KafkaUser user-with-correct-nameabcdefghijklmnopqrstuvxyzabcdefghijklmnopq status is available
2022-04-05 15:37:32 [main] [32mINFO [m [KafkaUserUtils:95] KafkaUser user-with-correct-nameabcdefghijklmnopqrstuvxyzabcdefghijklmnopq status is available
2022-04-05 15:37:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser sasl-userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef in namespace user-st
2022-04-05 15:37:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: sasl-userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef will have desired state: Ready
2022-04-05 15:37:33 [main] [32mINFO [m [ResourceManager:444] KafkaUser: sasl-userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef is in desired state: Ready
2022-04-05 15:37:33 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdefghijk in namespace user-st
2022-04-05 15:37:33 [main] [32mINFO [m [KafkaUserUtils:90] Wait until KafkaUser userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdefghijk status is available
2022-04-05 15:37:34 [main] [32mINFO [m [KafkaUserUtils:95] KafkaUser userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdefghijk status is available
2022-04-05 15:37:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 15:37:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUserWithNameMoreThan64Chars
2022-04-05 15:37:34 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser sasl-userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef in namespace user-st
2022-04-05 15:37:34 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaUser user-with-correct-nameabcdefghijklmnopqrstuvxyzabcdefghijklmnopq in namespace user-st
2022-04-05 15:37:34 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdefghijk in namespace user-st
2022-04-05 15:37:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 15:37:44 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testUserWithNameMoreThan64Chars-FINISHED
2022-04-05 15:37:44 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 15:37:44 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 15:37:44 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testTlsUserWithQuotas-STARTED
2022-04-05 15:37:44 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 15:37:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser encrypted-arnost in namespace user-st
2022-04-05 15:37:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: encrypted-arnost will have desired state: Ready
2022-04-05 15:37:45 [main] [32mINFO [m [ResourceManager:444] KafkaUser: encrypted-arnost is in desired state: Ready
2022-04-05 15:37:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace user-st exec user-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user CN=encrypted-arnost
2022-04-05 15:37:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 15:37:47 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion encrypted-arnost
2022-04-05 15:37:47 [main] [33mWARN [m [KafkaUserUtils:68] KafkaUser encrypted-arnost is not deleted yet! Triggering force delete by cmd client!
2022-04-05 15:37:49 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser encrypted-arnost deleted
2022-04-05 15:37:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace user-st exec user-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user CN=encrypted-arnost
2022-04-05 15:37:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 15:37:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 15:37:51 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTlsUserWithQuotas
2022-04-05 15:37:51 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser encrypted-arnost in namespace user-st
2022-04-05 15:37:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 15:37:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testTlsUserWithQuotas-FINISHED
2022-04-05 15:37:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 15:37:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 15:37:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testScramUserWithQuotas-STARTED
2022-04-05 15:37:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 15:37:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser scramed-arnost in namespace user-st
2022-04-05 15:37:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: scramed-arnost will have desired state: Ready
2022-04-05 15:37:52 [main] [32mINFO [m [ResourceManager:444] KafkaUser: scramed-arnost is in desired state: Ready
2022-04-05 15:37:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace user-st exec user-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user scramed-arnost
2022-04-05 15:37:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 15:37:55 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion scramed-arnost
2022-04-05 15:37:55 [main] [33mWARN [m [KafkaUserUtils:68] KafkaUser scramed-arnost is not deleted yet! Triggering force delete by cmd client!
2022-04-05 15:37:56 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser scramed-arnost deleted
2022-04-05 15:37:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace user-st exec user-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user scramed-arnost
2022-04-05 15:37:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 15:37:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 15:37:59 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScramUserWithQuotas
2022-04-05 15:37:59 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser scramed-arnost in namespace user-st
2022-04-05 15:37:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 15:37:59 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testScramUserWithQuotas-FINISHED
2022-04-05 15:37:59 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 15:37:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 15:37:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testCreatingUsersWithSecretPrefix-STARTED
2022-04-05 15:37:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 15:37:59 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-1 for test case:testCreatingUsersWithSecretPrefix
2022-04-05 15:37:59 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-1
2022-04-05 15:37:59 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-1
2022-04-05 15:37:59 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-1
2022-04-05 15:37:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b95cdfb7 in namespace namespace-1
2022-04-05 15:37:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-04-05 15:37:59 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b95cdfb7 will have desired state: Ready
2022-04-05 15:39:15 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b95cdfb7 is in desired state: Ready
2022-04-05 15:39:15 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-925961989-504202631 in namespace namespace-1
2022-04-05 15:39:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-04-05 15:39:15 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkatopics' with unstable version 'v1beta2'
2022-04-05 15:39:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-925961989-504202631 will have desired state: Ready
2022-04-05 15:39:16 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-925961989-504202631 is in desired state: Ready
2022-04-05 15:39:16 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser encrypted-leopold in namespace namespace-1
2022-04-05 15:39:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-04-05 15:39:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: encrypted-leopold will have desired state: Ready
2022-04-05 15:39:17 [main] [32mINFO [m [ResourceManager:444] KafkaUser: encrypted-leopold is in desired state: Ready
2022-04-05 15:39:17 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser scramed-leopold in namespace namespace-1
2022-04-05 15:39:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-04-05 15:39:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: scramed-leopold will have desired state: Ready
2022-04-05 15:39:18 [main] [32mINFO [m [ResourceManager:444] KafkaUser: scramed-leopold is in desired state: Ready
2022-04-05 15:39:18 [main] [32mINFO [m [UserST:346] Deploying KafkaClients pod for TLS listener
2022-04-05 15:39:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b95cdfb7-tls-kafka-clients in namespace namespace-1
2022-04-05 15:39:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-04-05 15:39:18 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b95cdfb7-tls-kafka-clients will be ready
2022-04-05 15:39:20 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b95cdfb7-tls-kafka-clients is ready
2022-04-05 15:39:20 [main] [32mINFO [m [UserST:350] Deploying KafkaClients pod for PLAIN listener
2022-04-05 15:39:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b95cdfb7-plain-kafka-clients in namespace namespace-1
2022-04-05 15:39:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-04-05 15:39:20 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b95cdfb7-plain-kafka-clients will be ready
2022-04-05 15:39:21 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b95cdfb7-plain-kafka-clients is ready
2022-04-05 15:39:21 [main] [32mINFO [m [UserST:357] Checking if user secrets with secret prefixes exists
2022-04-05 15:39:21 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 15:39:21 [main] [32mINFO [m [UserST:373] Checking if TLS user is able to send messages
2022-04-05 15:39:21 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@44031e55, messages=[], arguments=[--max-messages, 100, --topic, my-topic-57885039-819052364, --bootstrap-server, my-cluster-b95cdfb7-kafka-bootstrap.namespace-1.svc:9093, USER=top_secret_encrypted_leopold], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b95cdfb7-tls-kafka-clients-5b6df59687-thv5p', podNamespace='namespace-1', bootstrapServer='my-cluster-b95cdfb7-kafka-bootstrap.namespace-1.svc:9093', topicName='my-topic-57885039-819052364', maxMessages=100, kafkaUsername='top-secret-encrypted-leopold', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@725560ef}
2022-04-05 15:39:21 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-b95cdfb7-kafka-bootstrap.namespace-1.svc:9093:my-topic-57885039-819052364 from pod my-cluster-b95cdfb7-tls-kafka-clients-5b6df59687-thv5p
2022-04-05 15:39:21 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b95cdfb7-tls-kafka-clients-5b6df59687-thv5p -n namespace-1 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-57885039-819052364 --bootstrap-server my-cluster-b95cdfb7-kafka-bootstrap.namespace-1.svc:9093 USER=top_secret_encrypted_leopold
2022-04-05 15:39:25 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 15:39:25 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 15:39:25 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4bf082f8, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1331466649, --group-instance-id, instance767747134, --topic, my-topic-57885039-819052364, --bootstrap-server, my-cluster-b95cdfb7-kafka-bootstrap.namespace-1.svc:9093, USER=top_secret_encrypted_leopold], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b95cdfb7-tls-kafka-clients-5b6df59687-thv5p', podNamespace='namespace-1', bootstrapServer='my-cluster-b95cdfb7-kafka-bootstrap.namespace-1.svc:9093', topicName='my-topic-57885039-819052364', maxMessages=100, kafkaUsername='top-secret-encrypted-leopold', consumerGroupName='my-consumer-group-1331466649', consumerInstanceId='instance767747134', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@12803992}
2022-04-05 15:39:25 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-b95cdfb7-kafka-bootstrap.namespace-1.svc:9093:my-topic-57885039-819052364 from pod my-cluster-b95cdfb7-tls-kafka-clients-5b6df59687-thv5p
2022-04-05 15:39:25 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b95cdfb7-tls-kafka-clients-5b6df59687-thv5p -n namespace-1 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1331466649 --group-instance-id instance767747134 --topic my-topic-57885039-819052364 --bootstrap-server my-cluster-b95cdfb7-kafka-bootstrap.namespace-1.svc:9093 USER=top_secret_encrypted_leopold
2022-04-05 15:39:32 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 15:39:32 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 15:39:32 [main] [32mINFO [m [UserST:386] Checking if SCRAM-SHA user is able to send messages
2022-04-05 15:39:32 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@4fae97d1, messages=[], arguments=[--max-messages, 100, --topic, my-topic-57885039-819052364, --bootstrap-server, my-cluster-b95cdfb7-kafka-bootstrap.namespace-1.svc:9092, USER=top_secret_scramed_leopold], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b95cdfb7-plain-kafka-clients-5f79b74df8-r65lf', podNamespace='namespace-1', bootstrapServer='my-cluster-b95cdfb7-kafka-bootstrap.namespace-1.svc:9092', topicName='my-topic-57885039-819052364', maxMessages=100, kafkaUsername='top-secret-scramed-leopold', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@63f878f9}
2022-04-05 15:39:32 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-b95cdfb7-kafka-bootstrap.namespace-1.svc:9092:my-topic-57885039-819052364 from pod my-cluster-b95cdfb7-plain-kafka-clients-5f79b74df8-r65lf
2022-04-05 15:39:32 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b95cdfb7-plain-kafka-clients-5f79b74df8-r65lf -n namespace-1 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-57885039-819052364 --bootstrap-server my-cluster-b95cdfb7-kafka-bootstrap.namespace-1.svc:9092 USER=top_secret_scramed_leopold
2022-04-05 15:39:35 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 15:39:35 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 15:39:35 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@13d9d53b, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1331466649, --group-instance-id, instance1490678644, --topic, my-topic-57885039-819052364, --bootstrap-server, my-cluster-b95cdfb7-kafka-bootstrap.namespace-1.svc:9092, USER=top_secret_scramed_leopold], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b95cdfb7-plain-kafka-clients-5f79b74df8-r65lf', podNamespace='namespace-1', bootstrapServer='my-cluster-b95cdfb7-kafka-bootstrap.namespace-1.svc:9092', topicName='my-topic-57885039-819052364', maxMessages=100, kafkaUsername='top-secret-scramed-leopold', consumerGroupName='my-consumer-group-1331466649', consumerInstanceId='instance1490678644', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5cf16b1f}
2022-04-05 15:39:35 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-b95cdfb7-kafka-bootstrap.namespace-1.svc:9092#my-topic-57885039-819052364 from pod my-cluster-b95cdfb7-plain-kafka-clients-5f79b74df8-r65lf
2022-04-05 15:39:35 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b95cdfb7-plain-kafka-clients-5f79b74df8-r65lf -n namespace-1 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1331466649 --group-instance-id instance1490678644 --topic my-topic-57885039-819052364 --bootstrap-server my-cluster-b95cdfb7-kafka-bootstrap.namespace-1.svc:9092 USER=top_secret_scramed_leopold
2022-04-05 15:40:02 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 15:40:02 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 15:40:02 [main] [32mINFO [m [UserST:392] Checking owner reference - if the secret will be deleted when we delete KafkaUser
2022-04-05 15:40:02 [main] [32mINFO [m [UserST:394] Deleting KafkaUser:encrypted-leopold
2022-04-05 15:40:02 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion encrypted-leopold
2022-04-05 15:40:02 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser encrypted-leopold deleted
2022-04-05 15:40:02 [main] [32mINFO [m [UserST:398] Deleting KafkaUser:scramed-leopold
2022-04-05 15:40:02 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion scramed-leopold
2022-04-05 15:40:02 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser scramed-leopold deleted
2022-04-05 15:40:02 [main] [32mINFO [m [UserST:402] Checking if secrets are deleted
2022-04-05 15:40:02 [main] [32mINFO [m [SecretUtils:54] Waiting for Secret deletion top-secret-encrypted-leopold
2022-04-05 15:40:03 [main] [32mINFO [m [SecretUtils:58] Secret top-secret-encrypted-leopold deleted
2022-04-05 15:40:03 [main] [32mINFO [m [SecretUtils:54] Waiting for Secret deletion top-secret-scramed-leopold
2022-04-05 15:40:03 [main] [32mINFO [m [SecretUtils:58] Secret top-secret-scramed-leopold deleted
2022-04-05 15:40:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 15:40:03 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCreatingUsersWithSecretPrefix
2022-04-05 15:40:03 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser scramed-leopold in namespace namespace-1
2022-04-05 15:40:03 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b95cdfb7-plain-kafka-clients in namespace namespace-1
2022-04-05 15:40:03 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b95cdfb7 in namespace namespace-1
2022-04-05 15:40:03 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaUser encrypted-leopold in namespace namespace-1
2022-04-05 15:40:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-925961989-504202631 in namespace namespace-1
2022-04-05 15:40:03 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b95cdfb7-tls-kafka-clients in namespace namespace-1
2022-04-05 15:40:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 15:40:53 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-1 for test case:testCreatingUsersWithSecretPrefix
2022-04-05 15:40:59 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testCreatingUsersWithSecretPrefix-FINISHED
2022-04-05 15:40:59 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 15:40:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 15:40:59 [main] [32mINFO [m [ResourceManager:348] Delete all resources for UserST
2022-04-05 15:40:59 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka user-cluster-name in namespace user-st
2022-04-05 15:41:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;33mWARNING[m] Tests run: 12, Failures: 0, Errors: 0, Skipped: 4, Time elapsed: 419.6 s - in io.strimzi.systemtest.operators.user.UserST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.topic.ThrottlingQuotaST
2022-04-05 15:41:15 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: throttling-quota-st
2022-04-05 15:41:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: throttling-quota-st
2022-04-05 15:41:15 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: throttling-quota-st
2022-04-05 15:41:15 [main] [32mINFO [m [ThrottlingQuotaST:304] Deploying shared Kafka across all test cases in throttling-quota-st namespace
2022-04-05 15:41:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka quota-cluster in namespace throttling-quota-st
2022-04-05 15:41:15 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: quota-cluster will have desired state: Ready
2022-04-05 15:42:18 [main] [32mINFO [m [ResourceManager:444] Kafka: quota-cluster is in desired state: Ready
2022-04-05 15:42:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 15:42:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testThrottlingQuotasCreateAlterPartitions-STARTED
2022-04-05 15:42:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 15:42:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1972059996-1003550282 in namespace throttling-quota-st
2022-04-05 15:42:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1972059996-1003550282 will have desired state: Ready
2022-04-05 15:42:19 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1972059996-1003550282 is in desired state: Ready
2022-04-05 15:42:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-eb35f08c-kafka-clients in namespace throttling-quota-st
2022-04-05 15:42:19 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-eb35f08c-kafka-clients will be in active state
2022-04-05 15:42:20 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-05 15:46:22 [main] [32mINFO [m [PodUtils:189] Message org.apache.kafka.common.errors.ThrottlingQuotaExceededException: The throttling quota has been exceeded. found in create-admin-my-cluster-eb35f08c-kafka-clients-gvk7p log
2022-04-05 15:46:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-eb35f08c-kafka-clients in namespace throttling-quota-st
2022-04-05 15:46:27 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-eb35f08c-kafka-clients will be in active state
2022-04-05 15:46:28 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-05 15:47:30 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-eb35f08c-kafka-clients-xflgz log
2022-04-05 15:47:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Job alter-admin-my-cluster-eb35f08c-kafka-clients in namespace throttling-quota-st
2022-04-05 15:47:35 [main] [32mINFO [m [JobUtils:81] Waiting for job: alter-admin-my-cluster-eb35f08c-kafka-clients will be in active state
2022-04-05 15:47:36 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-05 15:51:37 [main] [32mINFO [m [PodUtils:189] Message org.apache.kafka.common.errors.ThrottlingQuotaExceededException: The throttling quota has been exceeded. found in alter-admin-my-cluster-eb35f08c-kafka-clients-slmxj log
2022-04-05 15:51:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Job teardown-delete in namespace throttling-quota-st
2022-04-05 15:51:42 [main] [32mINFO [m [JobUtils:81] Waiting for job: teardown-delete will be in active state
2022-04-05 15:51:43 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:teardown-delete to finished
2022-04-05 15:52:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 15:52:51 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testThrottlingQuotasCreateAlterPartitions
2022-04-05 15:52:51 [main] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-eb35f08c-kafka-clients in namespace throttling-quota-st
2022-04-05 15:52:51 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job alter-admin-my-cluster-eb35f08c-kafka-clients in namespace throttling-quota-st
2022-04-05 15:52:51 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-eb35f08c-kafka-clients in namespace throttling-quota-st
2022-04-05 15:52:51 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job teardown-delete in namespace throttling-quota-st
2022-04-05 15:52:51 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1972059996-1003550282 in namespace throttling-quota-st
2022-04-05 15:53:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 15:53:01 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testThrottlingQuotasCreateAlterPartitions-FINISHED
2022-04-05 15:53:01 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 15:53:01 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 15:53:01 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testKafkaAdminTopicOperations-STARTED
2022-04-05 15:53:01 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 15:53:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-2111018271-496650204 in namespace throttling-quota-st
2022-04-05 15:53:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-2111018271-496650204 will have desired state: Ready
2022-04-05 15:53:02 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-2111018271-496650204 is in desired state: Ready
2022-04-05 15:53:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-d5e90447-kafka-clients in namespace throttling-quota-st
2022-04-05 15:53:02 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-d5e90447-kafka-clients will be in active state
2022-04-05 15:53:03 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-05 15:54:33 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-d5e90447-kafka-clients-kdcdf log
2022-04-05 15:54:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Job list-admin-my-cluster-d5e90447-kafka-clients in namespace throttling-quota-st
2022-04-05 15:54:48 [main] [32mINFO [m [JobUtils:81] Waiting for job: list-admin-my-cluster-d5e90447-kafka-clients will be in active state
2022-04-05 15:54:49 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-05 15:54:51 [main] [32mINFO [m [PodUtils:189] Message quota-topic-test-simple-99 found in list-admin-my-cluster-d5e90447-kafka-clients-g6rcj log
2022-04-05 15:55:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-d5e90447-kafka-clients in namespace throttling-quota-st
2022-04-05 15:55:06 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-d5e90447-kafka-clients will be in active state
2022-04-05 15:55:07 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-05 15:56:37 [main] [32mINFO [m [PodUtils:189] Message Successfully removed all 100 found in delete-admin-my-cluster-d5e90447-kafka-clients-vkrv4 log
2022-04-05 15:56:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Job list-admin-my-cluster-d5e90447-kafka-clients in namespace throttling-quota-st
2022-04-05 15:56:42 [main] [32mINFO [m [JobUtils:81] Waiting for job: list-admin-my-cluster-d5e90447-kafka-clients will be in active state
2022-04-05 15:56:43 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:list-admin-my-cluster-d5e90447-kafka-clients to finished
2022-04-05 15:56:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 15:56:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaAdminTopicOperations
2022-04-05 15:56:45 [main] [32mINFO [m [ResourceManager:241] Delete of Job list-admin-my-cluster-d5e90447-kafka-clients in namespace throttling-quota-st
2022-04-05 15:56:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-2111018271-496650204 in namespace throttling-quota-st
2022-04-05 15:56:45 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job list-admin-my-cluster-d5e90447-kafka-clients in namespace throttling-quota-st
2022-04-05 15:56:45 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-d5e90447-kafka-clients in namespace throttling-quota-st
2022-04-05 15:56:45 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-d5e90447-kafka-clients in namespace throttling-quota-st
2022-04-05 15:56:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 15:56:55 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testKafkaAdminTopicOperations-FINISHED
2022-04-05 15:56:55 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 15:56:55 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 15:56:55 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testThrottlingQuotasDeleteTopic-STARTED
2022-04-05 15:56:55 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 15:56:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-97386851-886355596 in namespace throttling-quota-st
2022-04-05 15:56:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-97386851-886355596 will have desired state: Ready
2022-04-05 15:56:56 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-97386851-886355596 is in desired state: Ready
2022-04-05 15:56:56 [main] [32mINFO [m [ThrottlingQuotaST:112] Executing 1/5 iteration.
2022-04-05 15:56:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-d5506edd-kafka-clients in namespace throttling-quota-st
2022-04-05 15:56:56 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-d5506edd-kafka-clients will be in active state
2022-04-05 15:56:56 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:create-admin-my-cluster-d5506edd-kafka-clients to finished
2022-04-05 15:58:28 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-05 15:58:28 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-d5506edd-kafka-clients-jkbv5 log
2022-04-05 15:58:33 [main] [32mINFO [m [ThrottlingQuotaST:112] Executing 2/5 iteration.
2022-04-05 15:58:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-d5506edd-kafka-clients in namespace throttling-quota-st
2022-04-05 15:58:33 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-d5506edd-kafka-clients will be in active state
2022-04-05 15:58:34 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:create-admin-my-cluster-d5506edd-kafka-clients to finished
2022-04-05 16:00:08 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-05 16:00:08 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-d5506edd-kafka-clients-fn5tp log
2022-04-05 16:00:13 [main] [32mINFO [m [ThrottlingQuotaST:112] Executing 3/5 iteration.
2022-04-05 16:00:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-d5506edd-kafka-clients in namespace throttling-quota-st
2022-04-05 16:00:13 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-d5506edd-kafka-clients will be in active state
2022-04-05 16:00:14 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:create-admin-my-cluster-d5506edd-kafka-clients to finished
2022-04-05 16:01:48 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-05 16:01:48 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-d5506edd-kafka-clients-rpnq9 log
2022-04-05 16:01:53 [main] [32mINFO [m [ThrottlingQuotaST:112] Executing 4/5 iteration.
2022-04-05 16:01:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-d5506edd-kafka-clients in namespace throttling-quota-st
2022-04-05 16:01:53 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-d5506edd-kafka-clients will be in active state
2022-04-05 16:01:54 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:create-admin-my-cluster-d5506edd-kafka-clients to finished
2022-04-05 16:03:28 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-05 16:03:29 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-d5506edd-kafka-clients-24df4 log
2022-04-05 16:03:34 [main] [32mINFO [m [ThrottlingQuotaST:112] Executing 5/5 iteration.
2022-04-05 16:03:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-d5506edd-kafka-clients in namespace throttling-quota-st
2022-04-05 16:03:34 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-d5506edd-kafka-clients will be in active state
2022-04-05 16:03:35 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:create-admin-my-cluster-d5506edd-kafka-clients to finished
2022-04-05 16:05:08 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-05 16:05:08 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-d5506edd-kafka-clients-f4w8k log
2022-04-05 16:05:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-d5506edd-kafka-clients in namespace throttling-quota-st
2022-04-05 16:05:13 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-d5506edd-kafka-clients will be in active state
2022-04-05 16:05:14 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-05 16:09:16 [main] [32mINFO [m [PodUtils:189] Message org.apache.kafka.common.errors.ThrottlingQuotaExceededException: The throttling quota has been exceeded. found in delete-admin-my-cluster-d5506edd-kafka-clients-rdlbf log
2022-04-05 16:09:21 [main] [32mINFO [m [ThrottlingQuotaST:144] Executing 1/5 iteration for delete-admin-my-cluster-d5506edd-kafka-clients.
2022-04-05 16:09:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-d5506edd-kafka-clients in namespace throttling-quota-st
2022-04-05 16:09:21 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-d5506edd-kafka-clients will be in active state
2022-04-05 16:09:22 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:delete-admin-my-cluster-d5506edd-kafka-clients to finished
2022-04-05 16:10:30 [main] [32mINFO [m [ThrottlingQuotaST:144] Executing 2/5 iteration for delete-admin-my-cluster-d5506edd-kafka-clients.
2022-04-05 16:10:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-d5506edd-kafka-clients in namespace throttling-quota-st
2022-04-05 16:10:30 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-d5506edd-kafka-clients will be in active state
2022-04-05 16:10:31 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:delete-admin-my-cluster-d5506edd-kafka-clients to finished
2022-04-05 16:11:38 [main] [32mINFO [m [ThrottlingQuotaST:144] Executing 3/5 iteration for delete-admin-my-cluster-d5506edd-kafka-clients.
2022-04-05 16:11:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-d5506edd-kafka-clients in namespace throttling-quota-st
2022-04-05 16:11:38 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-d5506edd-kafka-clients will be in active state
2022-04-05 16:11:39 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:delete-admin-my-cluster-d5506edd-kafka-clients to finished
2022-04-05 16:12:46 [main] [32mINFO [m [ThrottlingQuotaST:144] Executing 4/5 iteration for delete-admin-my-cluster-d5506edd-kafka-clients.
2022-04-05 16:12:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-d5506edd-kafka-clients in namespace throttling-quota-st
2022-04-05 16:12:46 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-d5506edd-kafka-clients will be in active state
2022-04-05 16:12:47 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:delete-admin-my-cluster-d5506edd-kafka-clients to finished
2022-04-05 16:13:55 [main] [32mINFO [m [ThrottlingQuotaST:144] Executing 5/5 iteration for delete-admin-my-cluster-d5506edd-kafka-clients.
2022-04-05 16:13:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-d5506edd-kafka-clients in namespace throttling-quota-st
2022-04-05 16:13:55 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-d5506edd-kafka-clients will be in active state
2022-04-05 16:13:56 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:delete-admin-my-cluster-d5506edd-kafka-clients to finished
2022-04-05 16:15:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:15:03 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testThrottlingQuotasDeleteTopic
2022-04-05 16:15:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-d5506edd-kafka-clients in namespace throttling-quota-st
2022-04-05 16:15:03 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-d5506edd-kafka-clients in namespace throttling-quota-st
2022-04-05 16:15:03 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-d5506edd-kafka-clients in namespace throttling-quota-st
2022-04-05 16:15:03 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-d5506edd-kafka-clients in namespace throttling-quota-st
2022-04-05 16:15:03 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-d5506edd-kafka-clients in namespace throttling-quota-st
2022-04-05 16:15:03 [main] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-d5506edd-kafka-clients in namespace throttling-quota-st
2022-04-05 16:15:03 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-d5506edd-kafka-clients in namespace throttling-quota-st
2022-04-05 16:15:03 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-d5506edd-kafka-clients in namespace throttling-quota-st
2022-04-05 16:15:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-d5506edd-kafka-clients in namespace throttling-quota-st
2022-04-05 16:15:03 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-d5506edd-kafka-clients in namespace throttling-quota-st
2022-04-05 16:15:03 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-d5506edd-kafka-clients in namespace throttling-quota-st
2022-04-05 16:15:03 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-97386851-886355596 in namespace throttling-quota-st
2022-04-05 16:15:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 16:15:13 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testThrottlingQuotasDeleteTopic-FINISHED
2022-04-05 16:15:13 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 16:15:13 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 16:15:13 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testThrottlingQuotasCreateTopic-STARTED
2022-04-05 16:15:13 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 16:15:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-312629073-1778696830 in namespace throttling-quota-st
2022-04-05 16:15:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-312629073-1778696830 will have desired state: Ready
2022-04-05 16:15:14 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-312629073-1778696830 is in desired state: Ready
2022-04-05 16:15:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-2e5b2cdb-kafka-clients in namespace throttling-quota-st
2022-04-05 16:15:14 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-2e5b2cdb-kafka-clients will be in active state
2022-04-05 16:15:15 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-05 16:19:17 [main] [32mINFO [m [PodUtils:189] Message org.apache.kafka.common.errors.ThrottlingQuotaExceededException: The throttling quota has been exceeded. found in create-admin-my-cluster-2e5b2cdb-kafka-clients-b6765 log
2022-04-05 16:19:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:19:43 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testThrottlingQuotasCreateTopic
2022-04-05 16:19:43 [main] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-2e5b2cdb-kafka-clients in namespace throttling-quota-st
2022-04-05 16:19:43 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-312629073-1778696830 in namespace throttling-quota-st
2022-04-05 16:19:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 16:19:53 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testThrottlingQuotasCreateTopic-FINISHED
2022-04-05 16:19:53 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 16:19:53 [main] [32mINFO [m [ThrottlingQuotaST:353] Tearing down resources after all test
2022-04-05 16:20:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:20:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for ThrottlingQuotaST
2022-04-05 16:20:16 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka quota-cluster in namespace throttling-quota-st
2022-04-05 16:20:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2,361.845 s - in io.strimzi.systemtest.operators.topic.ThrottlingQuotaST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.topic.TopicST
2022-04-05 16:20:36 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: topic-st
2022-04-05 16:20:36 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: topic-st
2022-04-05 16:20:36 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: topic-st
2022-04-05 16:20:36 [main] [32mINFO [m [TopicST:494] Deploying shared Kafka across all test cases in topic-st namespace
2022-04-05 16:20:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka topic-cluster-name in namespace topic-st
2022-04-05 16:20:36 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: topic-cluster-name will have desired state: Ready
2022-04-05 16:21:55 [main] [32mINFO [m [ResourceManager:444] Kafka: topic-cluster-name is in desired state: Ready
2022-04-05 16:21:55 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 16:21:55 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testTopicModificationOfReplicationFactor-STARTED
2022-04-05 16:21:55 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 16:21:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1867157014-571829957 in namespace topic-st
2022-04-05 16:21:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1867157014-571829957 will have desired state: Ready
2022-04-05 16:21:56 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1867157014-571829957 is in desired state: Ready
2022-04-05 16:21:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1867157014-571829957 will have desired state: NotReady
2022-04-05 16:21:57 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1867157014-571829957 is in desired state: NotReady
2022-04-05 16:21:57 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-1867157014-571829957 deletion
2022-04-05 16:21:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:21:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTopicModificationOfReplicationFactor
2022-04-05 16:21:57 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1867157014-571829957 in namespace topic-st
2022-04-05 16:21:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 16:21:57 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testTopicModificationOfReplicationFactor-FINISHED
2022-04-05 16:21:57 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 16:21:57 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 16:21:57 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testDeleteTopicEnableFalse-STARTED
2022-04-05 16:21:57 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 16:21:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-cf00467e-isolated in namespace topic-st
2022-04-05 16:21:57 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-cf00467e-isolated will have desired state: Ready
2022-04-05 16:23:12 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-cf00467e-isolated is in desired state: Ready
2022-04-05 16:23:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-cf00467e-isolated-kafka-clients in namespace topic-st
2022-04-05 16:23:12 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-cf00467e-isolated-kafka-clients will be ready
2022-04-05 16:23:14 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-cf00467e-isolated-kafka-clients is ready
2022-04-05 16:23:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-292953070-1816524302 in namespace topic-st
2022-04-05 16:23:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-292953070-1816524302 will have desired state: Ready
2022-04-05 16:23:15 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-292953070-1816524302 is in desired state: Ready
2022-04-05 16:23:15 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 16:23:15 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@63e35d10, messages=[], arguments=[--max-messages, 100, --topic, my-topic-292953070-1816524302, --bootstrap-server, my-cluster-cf00467e-isolated-kafka-bootstrap.topic-st.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-cf00467e-isolated-kafka-clients-566c8b98b6-x2bk9', podNamespace='topic-st', bootstrapServer='my-cluster-cf00467e-isolated-kafka-bootstrap.topic-st.svc:9092', topicName='my-topic-292953070-1816524302', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@58526be6}
2022-04-05 16:23:15 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-cf00467e-isolated-kafka-bootstrap.topic-st.svc:9092:my-topic-292953070-1816524302 from pod my-cluster-cf00467e-isolated-kafka-clients-566c8b98b6-x2bk9
2022-04-05 16:23:15 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-cf00467e-isolated-kafka-clients-566c8b98b6-x2bk9 -n topic-st -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-292953070-1816524302 --bootstrap-server my-cluster-cf00467e-isolated-kafka-bootstrap.topic-st.svc:9092
2022-04-05 16:23:18 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 16:23:18 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 16:23:18 [main] [32mINFO [m [TopicST:398] Deleting KafkaTopic: my-topic-292953070-1816524302
2022-04-05 16:23:18 [main] [32mINFO [m [TopicST:400] KafkaTopic my-topic-292953070-1816524302 deleted
2022-04-05 16:24:57 [main] [32mINFO [m [TopicST:404] Wait KafkaTopic my-topic-292953070-1816524302 recreation
2022-04-05 16:24:57 [main] [32mINFO [m [KafkaTopicUtils:78] Waiting for KafkaTopic my-topic-292953070-1816524302 creation 
2022-04-05 16:24:57 [main] [32mINFO [m [TopicST:406] KafkaTopic my-topic-292953070-1816524302 recreated
2022-04-05 16:24:57 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5c7a51e, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1781321513, --group-instance-id, instance545118621, --topic, my-topic-292953070-1816524302, --bootstrap-server, my-cluster-cf00467e-isolated-kafka-bootstrap.topic-st.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-cf00467e-isolated-kafka-clients-566c8b98b6-x2bk9', podNamespace='topic-st', bootstrapServer='my-cluster-cf00467e-isolated-kafka-bootstrap.topic-st.svc:9092', topicName='my-topic-292953070-1816524302', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1781321513', consumerInstanceId='instance545118621', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7f4916f3}
2022-04-05 16:24:57 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-cf00467e-isolated-kafka-bootstrap.topic-st.svc:9092#my-topic-292953070-1816524302 from pod my-cluster-cf00467e-isolated-kafka-clients-566c8b98b6-x2bk9
2022-04-05 16:24:57 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-cf00467e-isolated-kafka-clients-566c8b98b6-x2bk9 -n topic-st -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1781321513 --group-instance-id instance545118621 --topic my-topic-292953070-1816524302 --bootstrap-server my-cluster-cf00467e-isolated-kafka-bootstrap.topic-st.svc:9092
2022-04-05 16:25:03 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 16:25:03 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 16:25:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:25:03 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeleteTopicEnableFalse
2022-04-05 16:25:03 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-cf00467e-isolated-kafka-clients in namespace topic-st
2022-04-05 16:25:03 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-cf00467e-isolated in namespace topic-st
2022-04-05 16:25:03 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-292953070-1816524302 in namespace topic-st
2022-04-05 16:25:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 16:25:53 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testDeleteTopicEnableFalse-FINISHED
2022-04-05 16:25:53 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 16:25:53 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 16:25:53 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testSendingMessagesToNonExistingTopic-STARTED
2022-04-05 16:25:53 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 16:25:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment topic-cluster-name-kafka-clients in namespace topic-st
2022-04-05 16:25:53 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: topic-cluster-name-kafka-clients will be ready
2022-04-05 16:25:55 [main] [32mINFO [m [DeploymentUtils:168] Deployment: topic-cluster-name-kafka-clients is ready
2022-04-05 16:25:55 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 16:25:55 [main] [32mINFO [m [TopicST:323] Checking if my-topic-89876016-1814284254 is on topic list
2022-04-05 16:25:55 [main] [32mINFO [m [TopicST:459] Checking topic my-topic-89876016-1814284254 in Kafka
2022-04-05 16:25:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-05 16:25:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:25:57 [main] [32mINFO [m [TopicST:326] Topic with name my-topic-89876016-1814284254 is not created yet
2022-04-05 16:25:57 [main] [32mINFO [m [TopicST:328] Trying to send messages to non-existing topic my-topic-89876016-1814284254
2022-04-05 16:25:57 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@68459f3a, messages=[], arguments=[--max-messages, 100, --topic, my-topic-89876016-1814284254, --bootstrap-server, topic-cluster-name-kafka-bootstrap.topic-st.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='topic-cluster-name-kafka-clients-7dd7cb68d4-vlnl9', podNamespace='topic-st', bootstrapServer='topic-cluster-name-kafka-bootstrap.topic-st.svc:9092', topicName='my-topic-89876016-1814284254', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@23d78961}
2022-04-05 16:25:57 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to topic-cluster-name-kafka-bootstrap.topic-st.svc:9092:my-topic-89876016-1814284254 from pod topic-cluster-name-kafka-clients-7dd7cb68d4-vlnl9
2022-04-05 16:25:57 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec topic-cluster-name-kafka-clients-7dd7cb68d4-vlnl9 -n topic-st -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-89876016-1814284254 --bootstrap-server topic-cluster-name-kafka-bootstrap.topic-st.svc:9092
2022-04-05 16:26:00 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 16:26:00 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 16:26:00 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@471eb5f1, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-170833105, --group-instance-id, instance1443532961, --topic, my-topic-89876016-1814284254, --bootstrap-server, topic-cluster-name-kafka-bootstrap.topic-st.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='topic-cluster-name-kafka-clients-7dd7cb68d4-vlnl9', podNamespace='topic-st', bootstrapServer='topic-cluster-name-kafka-bootstrap.topic-st.svc:9092', topicName='my-topic-89876016-1814284254', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-170833105', consumerInstanceId='instance1443532961', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@53d73962}
2022-04-05 16:26:00 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from topic-cluster-name-kafka-bootstrap.topic-st.svc:9092#my-topic-89876016-1814284254 from pod topic-cluster-name-kafka-clients-7dd7cb68d4-vlnl9
2022-04-05 16:26:00 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec topic-cluster-name-kafka-clients-7dd7cb68d4-vlnl9 -n topic-st -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-170833105 --group-instance-id instance1443532961 --topic my-topic-89876016-1814284254 --bootstrap-server topic-cluster-name-kafka-bootstrap.topic-st.svc:9092
2022-04-05 16:26:06 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 16:26:06 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 16:26:06 [main] [32mINFO [m [TopicST:344] Checking if my-topic-89876016-1814284254 is on topic list
2022-04-05 16:26:06 [main] [32mINFO [m [TopicST:459] Checking topic my-topic-89876016-1814284254 in Kafka
2022-04-05 16:26:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-05 16:26:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:26:09 [main] [32mINFO [m [KafkaTopicUtils:78] Waiting for KafkaTopic my-topic-89876016-1814284254 creation 
2022-04-05 16:27:42 [main] [32mINFO [m [TopicST:356] Topic successfully created
2022-04-05 16:27:42 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:27:42 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendingMessagesToNonExistingTopic
2022-04-05 16:27:42 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment topic-cluster-name-kafka-clients in namespace topic-st
2022-04-05 16:28:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 16:28:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testSendingMessagesToNonExistingTopic-FINISHED
2022-04-05 16:28:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 16:28:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 16:28:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testMoreReplicasThanAvailableBrokers-STARTED
2022-04-05 16:28:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 16:28:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-531215957-913229866 in namespace topic-st
2022-04-05 16:28:22 [main] [32mINFO [m [TopicST:464] Checking in KafkaTopic CR that topic my-topic-531215957-913229866 exists
2022-04-05 16:28:22 [main] [32mINFO [m [TopicST:459] Checking topic my-topic-531215957-913229866 in Kafka
2022-04-05 16:28:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-05 16:28:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:28:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-531215957-913229866 will have desired state: NotReady
2022-04-05 16:28:25 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-531215957-913229866 is in desired state: NotReady
2022-04-05 16:28:25 [main] [32mINFO [m [TopicST:91] Delete topic my-topic-531215957-913229866
2022-04-05 16:28:25 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-531215957-913229866 deletion
2022-04-05 16:28:25 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic topic-example-new in namespace topic-st
2022-04-05 16:28:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: topic-example-new will have desired state: Ready
2022-04-05 16:28:26 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: topic-example-new is in desired state: Ready
2022-04-05 16:28:26 [main] [32mINFO [m [TopicST:459] Checking topic topic-example-new in Kafka
2022-04-05 16:28:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-05 16:28:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:28:28 [main] [32mINFO [m [TopicST:464] Checking in KafkaTopic CR that topic topic-example-new exists
2022-04-05 16:28:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:28:28 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMoreReplicasThanAvailableBrokers
2022-04-05 16:28:28 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic topic-example-new in namespace topic-st
2022-04-05 16:28:28 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-531215957-913229866 in namespace topic-st
2022-04-05 16:28:38 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 16:28:38 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testMoreReplicasThanAvailableBrokers-FINISHED
2022-04-05 16:28:38 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 16:28:38 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 16:28:38 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testCreateTopicViaKafka-STARTED
2022-04-05 16:28:38 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 16:28:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --create  --topic my-topic-964182670-1699703138 --replication-factor 3 --partitions 3
2022-04-05 16:28:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:28:41 [main] [32mINFO [m [KafkaTopicUtils:78] Waiting for KafkaTopic my-topic-964182670-1699703138 creation 
2022-04-05 16:28:42 [main] [32mINFO [m [TopicST:485] Checking in KafkaTopic CR that topic my-topic-964182670-1699703138 was created with expected settings
2022-04-05 16:28:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-05 16:28:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:28:45 [main] [32mINFO [m [TopicST:122] Editing topic via Kafka, settings to partitions 5
2022-04-05 16:28:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic my-topic-964182670-1699703138 --partitions 5
2022-04-05 16:28:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:28:48 [main] [32mINFO [m [KafkaTopicUtils:124] Waiting for KafkaTopic change my-topic-964182670-1699703138
2022-04-05 16:28:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic my-topic-964182670-1699703138
2022-04-05 16:28:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:28:50 [main] [32mINFO [m [TopicST:473] Checking topic my-topic-964182670-1699703138 in Kafka topic-cluster-name
2022-04-05 16:28:50 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:28:50 [main] [32mINFO [m [ResourceManager:346] In context testCreateTopicViaKafka is everything deleted.
2022-04-05 16:28:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 16:28:50 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testCreateTopicViaKafka-FINISHED
2022-04-05 16:28:50 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 16:28:50 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 16:28:50 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testCreateTopicAfterUnsupportedOperation-STARTED
2022-04-05 16:28:50 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 16:28:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic topic-with-replication-to-change in namespace topic-st
2022-04-05 16:28:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: topic-with-replication-to-change will have desired state: Ready
2022-04-05 16:28:51 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: topic-with-replication-to-change is in desired state: Ready
2022-04-05 16:28:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: topic-with-replication-to-change will have desired state: NotReady
2022-04-05 16:28:52 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: topic-with-replication-to-change is in desired state: NotReady
2022-04-05 16:28:52 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic another-topic in namespace topic-st
2022-04-05 16:28:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: another-topic will have desired state: Ready
2022-04-05 16:28:53 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: another-topic is in desired state: Ready
2022-04-05 16:28:53 [main] [32mINFO [m [TopicST:459] Checking topic topic-with-replication-to-change in Kafka
2022-04-05 16:28:56 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-05 16:28:56 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:28:56 [main] [32mINFO [m [TopicST:464] Checking in KafkaTopic CR that topic topic-with-replication-to-change exists
2022-04-05 16:28:56 [main] [32mINFO [m [TopicST:459] Checking topic another-topic in Kafka
2022-04-05 16:28:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-05 16:28:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:28:59 [main] [32mINFO [m [TopicST:464] Checking in KafkaTopic CR that topic another-topic exists
2022-04-05 16:28:59 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic topic-with-replication-to-change deletion
2022-04-05 16:28:59 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic another-topic deletion
2022-04-05 16:28:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:28:59 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCreateTopicAfterUnsupportedOperation
2022-04-05 16:28:59 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic another-topic in namespace topic-st
2022-04-05 16:28:59 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic topic-with-replication-to-change in namespace topic-st
2022-04-05 16:28:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 16:28:59 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testCreateTopicAfterUnsupportedOperation-FINISHED
2022-04-05 16:28:59 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 16:28:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:28:59 [main] [32mINFO [m [ResourceManager:348] Delete all resources for TopicST
2022-04-05 16:28:59 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka topic-cluster-name in namespace topic-st
2022-04-05 16:29:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;33mWARNING[m] Tests run: 8, Failures: 0, Errors: 0, Skipped: 2, Time elapsed: 539.854 s - in io.strimzi.systemtest.operators.topic.TopicST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.ReconciliationST
2022-04-05 16:29:36 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: reconciliation-st
2022-04-05 16:29:36 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: reconciliation-st
2022-04-05 16:29:36 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: reconciliation-st
2022-04-05 16:29:36 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 16:29:36 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.ReconciliationST.testPauseReconciliationInKafkaAndKafkaConnectWithConnector-STARTED
2022-04-05 16:29:36 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 16:29:36 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-2 for test case:testPauseReconciliationInKafkaAndKafkaConnectWithConnector
2022-04-05 16:29:36 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-2
2022-04-05 16:29:36 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-2
2022-04-05 16:29:36 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-2
2022-04-05 16:29:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0bc5c388 in namespace namespace-2
2022-04-05 16:29:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-04-05 16:29:36 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0bc5c388 will have desired state: Ready
2022-04-05 16:31:24 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0bc5c388 is in desired state: Ready
2022-04-05 16:31:24 [main] [32mINFO [m [ReconciliationST:80] Adding pause annotation into Kafka resource and also scaling replicas to 4, new pod should not appear
2022-04-05 16:31:24 [main] [32mINFO [m [ReconciliationST:86] Kafka should contain status with ReconciliationPaused
2022-04-05 16:31:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0bc5c388 will have desired state: ReconciliationPaused
2022-04-05 16:31:26 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0bc5c388 is in desired state: ReconciliationPaused
2022-04-05 16:31:26 [main] [32mINFO [m [PodUtils:209] Wait until Pod my-cluster-0bc5c388-kafka will have stable 3 replicas
2022-04-05 16:31:26 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 19 polls
2022-04-05 16:31:27 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 18 polls
2022-04-05 16:31:28 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 17 polls
2022-04-05 16:31:29 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 16 polls
2022-04-05 16:31:30 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 15 polls
2022-04-05 16:31:31 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 14 polls
2022-04-05 16:31:32 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 13 polls
2022-04-05 16:31:33 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 12 polls
2022-04-05 16:31:34 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 11 polls
2022-04-05 16:31:35 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 10 polls
2022-04-05 16:31:36 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 9 polls
2022-04-05 16:31:37 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 8 polls
2022-04-05 16:31:38 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 7 polls
2022-04-05 16:31:39 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 6 polls
2022-04-05 16:31:40 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 5 polls
2022-04-05 16:31:41 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 4 polls
2022-04-05 16:31:42 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 3 polls
2022-04-05 16:31:43 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 2 polls
2022-04-05 16:31:44 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 1 polls
2022-04-05 16:31:45 [main] [32mINFO [m [PodUtils:217] Pod replicas are stable for 20 polls intervals
2022-04-05 16:31:45 [main] [32mINFO [m [PodUtils:228] Pod my-cluster-0bc5c388-kafka has 3 replicas
2022-04-05 16:31:45 [main] [32mINFO [m [ReconciliationST:90] Setting annotation to "false", Kafka should be scaled to 4
2022-04-05 16:31:45 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 4 Pod(s) of my-cluster-0bc5c388-kafka to be ready
2022-04-05 16:33:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0bc5c388 will have desired state: Ready
2022-04-05 16:33:44 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0bc5c388 is in desired state: Ready
2022-04-05 16:33:44 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-0bc5c388 is ready
2022-04-05 16:33:44 [main] [32mINFO [m [ReconciliationST:94] Deploying KafkaConnect with pause annotation from the start, no pods should appear
2022-04-05 16:33:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-0bc5c388-kafka-clients in namespace namespace-2
2022-04-05 16:33:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-04-05 16:33:44 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-0bc5c388-kafka-clients will be ready
2022-04-05 16:33:46 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-0bc5c388-kafka-clients is ready
2022-04-05 16:33:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-0bc5c388-scraper in namespace namespace-2
2022-04-05 16:33:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-04-05 16:33:46 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-0bc5c388-scraper will be ready
2022-04-05 16:33:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-0bc5c388-scraper is ready
2022-04-05 16:33:48 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-0bc5c388-scraper to be ready
2022-04-05 16:33:58 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-0bc5c388-scraper is ready
2022-04-05 16:33:58 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-0bc5c388-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-05 16:33:58 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-0bc5c388-allow in namespace namespace-2
2022-04-05 16:33:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-04-05 16:33:58 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-05 16:33:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-0bc5c388 in namespace namespace-2
2022-04-05 16:33:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-04-05 16:33:58 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkaconnects' with unstable version 'v1beta2'
2022-04-05 16:33:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-0bc5c388 will have desired state: ReconciliationPaused
2022-04-05 16:33:59 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-0bc5c388 is in desired state: ReconciliationPaused
2022-04-05 16:33:59 [main] [32mINFO [m [PodUtils:209] Wait until Pod my-cluster-0bc5c388-connect will have stable 0 replicas
2022-04-05 16:33:59 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 19 polls
2022-04-05 16:34:00 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 18 polls
2022-04-05 16:34:01 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 17 polls
2022-04-05 16:34:02 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 16 polls
2022-04-05 16:34:03 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 15 polls
2022-04-05 16:34:04 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 14 polls
2022-04-05 16:34:05 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 13 polls
2022-04-05 16:34:06 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 12 polls
2022-04-05 16:34:07 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 11 polls
2022-04-05 16:34:08 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 10 polls
2022-04-05 16:34:09 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 9 polls
2022-04-05 16:34:10 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 8 polls
2022-04-05 16:34:11 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 7 polls
2022-04-05 16:34:12 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 6 polls
2022-04-05 16:34:13 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 5 polls
2022-04-05 16:34:14 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 4 polls
2022-04-05 16:34:15 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 3 polls
2022-04-05 16:34:16 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 2 polls
2022-04-05 16:34:17 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 1 polls
2022-04-05 16:34:18 [main] [32mINFO [m [PodUtils:217] Pod replicas are stable for 20 polls intervals
2022-04-05 16:34:18 [main] [32mINFO [m [PodUtils:228] Pod my-cluster-0bc5c388-connect has 0 replicas
2022-04-05 16:34:18 [main] [32mINFO [m [ReconciliationST:108] Setting annotation to "false" and creating KafkaConnector
2022-04-05 16:34:18 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-0bc5c388-connect will be ready
2022-04-05 16:35:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-0bc5c388-connect is ready
2022-04-05 16:35:27 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-0bc5c388-connect to be ready
2022-04-05 16:35:37 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-0bc5c388-connect is ready
2022-04-05 16:35:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-0bc5c388 in namespace namespace-2
2022-04-05 16:35:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-04-05 16:35:37 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkaconnectors' with unstable version 'v1beta2'
2022-04-05 16:35:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-0bc5c388 will have desired state: Ready
2022-04-05 16:35:38 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-0bc5c388 is in desired state: Ready
2022-04-05 16:35:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-0bc5c388-connect-675cdb9bcb-tpdrt -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-0bc5c388
2022-04-05 16:35:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:38 [main] [32mINFO [m [ReconciliationST:118] Adding pause annotation into the KafkaConnector and scaling taskMax to 4
2022-04-05 16:35:38 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-0bc5c388 will have desired state: ReconciliationPaused
2022-04-05 16:35:39 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-0bc5c388 is in desired state: ReconciliationPaused
2022-04-05 16:35:40 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-0bc5c388-connect-675cdb9bcb-tpdrt -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-0bc5c388
2022-04-05 16:35:40 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:40 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 19 polls
2022-04-05 16:35:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-0bc5c388-connect-675cdb9bcb-tpdrt -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-0bc5c388
2022-04-05 16:35:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:41 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 18 polls
2022-04-05 16:35:42 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-0bc5c388-connect-675cdb9bcb-tpdrt -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-0bc5c388
2022-04-05 16:35:42 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:42 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 17 polls
2022-04-05 16:35:43 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-0bc5c388-connect-675cdb9bcb-tpdrt -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-0bc5c388
2022-04-05 16:35:43 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:43 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 16 polls
2022-04-05 16:35:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-0bc5c388-connect-675cdb9bcb-tpdrt -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-0bc5c388
2022-04-05 16:35:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:44 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 15 polls
2022-04-05 16:35:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-0bc5c388-connect-675cdb9bcb-tpdrt -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-0bc5c388
2022-04-05 16:35:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:46 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 14 polls
2022-04-05 16:35:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-0bc5c388-connect-675cdb9bcb-tpdrt -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-0bc5c388
2022-04-05 16:35:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:47 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 13 polls
2022-04-05 16:35:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-0bc5c388-connect-675cdb9bcb-tpdrt -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-0bc5c388
2022-04-05 16:35:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:48 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 12 polls
2022-04-05 16:35:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-0bc5c388-connect-675cdb9bcb-tpdrt -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-0bc5c388
2022-04-05 16:35:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:49 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 11 polls
2022-04-05 16:35:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-0bc5c388-connect-675cdb9bcb-tpdrt -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-0bc5c388
2022-04-05 16:35:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:50 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 10 polls
2022-04-05 16:35:52 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-0bc5c388-connect-675cdb9bcb-tpdrt -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-0bc5c388
2022-04-05 16:35:52 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:52 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 9 polls
2022-04-05 16:35:53 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-0bc5c388-connect-675cdb9bcb-tpdrt -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-0bc5c388
2022-04-05 16:35:53 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:53 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 8 polls
2022-04-05 16:35:54 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-0bc5c388-connect-675cdb9bcb-tpdrt -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-0bc5c388
2022-04-05 16:35:54 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:54 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 7 polls
2022-04-05 16:35:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-0bc5c388-connect-675cdb9bcb-tpdrt -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-0bc5c388
2022-04-05 16:35:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:55 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 6 polls
2022-04-05 16:35:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-0bc5c388-connect-675cdb9bcb-tpdrt -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-0bc5c388
2022-04-05 16:35:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:57 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 5 polls
2022-04-05 16:35:58 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-0bc5c388-connect-675cdb9bcb-tpdrt -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-0bc5c388
2022-04-05 16:35:58 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:58 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 4 polls
2022-04-05 16:35:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-0bc5c388-connect-675cdb9bcb-tpdrt -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-0bc5c388
2022-04-05 16:35:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:59 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 3 polls
2022-04-05 16:36:00 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-0bc5c388-connect-675cdb9bcb-tpdrt -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-0bc5c388
2022-04-05 16:36:00 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:36:00 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 2 polls
2022-04-05 16:36:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-0bc5c388-connect-675cdb9bcb-tpdrt -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-0bc5c388
2022-04-05 16:36:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:36:01 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 1 polls
2022-04-05 16:36:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-0bc5c388-connect-675cdb9bcb-tpdrt -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-0bc5c388
2022-04-05 16:36:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:36:03 [main] [32mINFO [m [KafkaConnectorUtils:154] Connector's spec is stable for 20 polls intervals
2022-04-05 16:36:03 [main] [32mINFO [m [ReconciliationST:127] Setting annotation to "false", taskMax should be increased to 4
2022-04-05 16:36:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-0bc5c388-connect-675cdb9bcb-tpdrt -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-0bc5c388/config
2022-04-05 16:36:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:36:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-0bc5c388-connect-675cdb9bcb-tpdrt -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-0bc5c388/config
2022-04-05 16:36:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:36:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:36:03 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testPauseReconciliationInKafkaAndKafkaConnectWithConnector
2022-04-05 16:36:03 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-0bc5c388-allow in namespace namespace-2
2022-04-05 16:36:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-0bc5c388 in namespace namespace-2
2022-04-05 16:36:03 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-0bc5c388 in namespace namespace-2
2022-04-05 16:36:03 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-0bc5c388-kafka-clients in namespace namespace-2
2022-04-05 16:36:03 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0bc5c388 in namespace namespace-2
2022-04-05 16:36:03 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-0bc5c388-scraper in namespace namespace-2
2022-04-05 16:37:03 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 16:37:03 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-2 for test case:testPauseReconciliationInKafkaAndKafkaConnectWithConnector
2022-04-05 16:37:10 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.ReconciliationST.testPauseReconciliationInKafkaAndKafkaConnectWithConnector-FINISHED
2022-04-05 16:37:10 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 16:37:10 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 16:37:10 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.ReconciliationST.testPauseReconciliationInKafkaRebalanceAndTopic-STARTED
2022-04-05 16:37:10 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 16:37:10 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-3 for test case:testPauseReconciliationInKafkaRebalanceAndTopic
2022-04-05 16:37:10 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-3
2022-04-05 16:37:10 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-3
2022-04-05 16:37:10 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-3
2022-04-05 16:37:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-aeb37c2d in namespace namespace-3
2022-04-05 16:37:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-3
2022-04-05 16:37:10 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-aeb37c2d will have desired state: Ready
2022-04-05 16:38:48 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-aeb37c2d is in desired state: Ready
2022-04-05 16:38:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1069660884-1337276924 in namespace namespace-3
2022-04-05 16:38:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-3
2022-04-05 16:38:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1069660884-1337276924 will have desired state: Ready
2022-04-05 16:38:49 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1069660884-1337276924 is in desired state: Ready
2022-04-05 16:38:49 [main] [32mINFO [m [ReconciliationST:147] Adding pause annotation into KafkaTopic resource and changing replication factor
2022-04-05 16:38:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1069660884-1337276924 will have desired state: ReconciliationPaused
2022-04-05 16:38:50 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1069660884-1337276924 is in desired state: ReconciliationPaused
2022-04-05 16:38:53 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-aeb37c2d-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1069660884-1337276924 --describe --bootstrap-server my-cluster-aeb37c2d-kafka-bootstrap:9092
2022-04-05 16:38:53 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:38:56 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-aeb37c2d-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1069660884-1337276924 --describe --bootstrap-server my-cluster-aeb37c2d-kafka-bootstrap:9092
2022-04-05 16:38:56 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:38:56 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 19 polls
2022-04-05 16:38:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-aeb37c2d-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1069660884-1337276924 --describe --bootstrap-server my-cluster-aeb37c2d-kafka-bootstrap:9092
2022-04-05 16:38:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:38:59 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 18 polls
2022-04-05 16:39:04 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-aeb37c2d-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1069660884-1337276924 --describe --bootstrap-server my-cluster-aeb37c2d-kafka-bootstrap:9092
2022-04-05 16:39:04 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:39:04 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 17 polls
2022-04-05 16:39:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-aeb37c2d-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1069660884-1337276924 --describe --bootstrap-server my-cluster-aeb37c2d-kafka-bootstrap:9092
2022-04-05 16:39:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:39:08 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 16 polls
2022-04-05 16:39:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-aeb37c2d-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1069660884-1337276924 --describe --bootstrap-server my-cluster-aeb37c2d-kafka-bootstrap:9092
2022-04-05 16:39:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:39:12 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 15 polls
2022-04-05 16:39:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-aeb37c2d-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1069660884-1337276924 --describe --bootstrap-server my-cluster-aeb37c2d-kafka-bootstrap:9092
2022-04-05 16:39:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:39:16 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 14 polls
2022-04-05 16:39:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-aeb37c2d-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1069660884-1337276924 --describe --bootstrap-server my-cluster-aeb37c2d-kafka-bootstrap:9092
2022-04-05 16:39:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:39:27 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 13 polls
2022-04-05 16:39:31 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-aeb37c2d-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1069660884-1337276924 --describe --bootstrap-server my-cluster-aeb37c2d-kafka-bootstrap:9092
2022-04-05 16:39:31 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:39:31 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 12 polls
2022-04-05 16:39:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-aeb37c2d-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1069660884-1337276924 --describe --bootstrap-server my-cluster-aeb37c2d-kafka-bootstrap:9092
2022-04-05 16:39:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:39:35 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 11 polls
2022-04-05 16:39:40 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-aeb37c2d-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1069660884-1337276924 --describe --bootstrap-server my-cluster-aeb37c2d-kafka-bootstrap:9092
2022-04-05 16:39:40 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:39:40 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 10 polls
2022-04-05 16:39:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-aeb37c2d-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1069660884-1337276924 --describe --bootstrap-server my-cluster-aeb37c2d-kafka-bootstrap:9092
2022-04-05 16:39:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:39:44 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 9 polls
2022-04-05 16:39:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-aeb37c2d-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1069660884-1337276924 --describe --bootstrap-server my-cluster-aeb37c2d-kafka-bootstrap:9092
2022-04-05 16:39:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:39:49 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 8 polls
2022-04-05 16:39:56 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-aeb37c2d-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1069660884-1337276924 --describe --bootstrap-server my-cluster-aeb37c2d-kafka-bootstrap:9092
2022-04-05 16:39:56 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:39:56 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 7 polls
2022-04-05 16:40:00 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-aeb37c2d-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1069660884-1337276924 --describe --bootstrap-server my-cluster-aeb37c2d-kafka-bootstrap:9092
2022-04-05 16:40:00 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:40:00 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 6 polls
2022-04-05 16:40:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-aeb37c2d-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1069660884-1337276924 --describe --bootstrap-server my-cluster-aeb37c2d-kafka-bootstrap:9092
2022-04-05 16:40:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:40:06 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 5 polls
2022-04-05 16:40:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-aeb37c2d-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1069660884-1337276924 --describe --bootstrap-server my-cluster-aeb37c2d-kafka-bootstrap:9092
2022-04-05 16:40:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:40:11 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 4 polls
2022-04-05 16:40:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-aeb37c2d-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1069660884-1337276924 --describe --bootstrap-server my-cluster-aeb37c2d-kafka-bootstrap:9092
2022-04-05 16:40:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:40:15 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 3 polls
2022-04-05 16:40:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-aeb37c2d-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1069660884-1337276924 --describe --bootstrap-server my-cluster-aeb37c2d-kafka-bootstrap:9092
2022-04-05 16:40:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:40:19 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 2 polls
2022-04-05 16:40:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-aeb37c2d-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1069660884-1337276924 --describe --bootstrap-server my-cluster-aeb37c2d-kafka-bootstrap:9092
2022-04-05 16:40:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:40:22 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 1 polls
2022-04-05 16:40:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-aeb37c2d-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-1069660884-1337276924 --describe --bootstrap-server my-cluster-aeb37c2d-kafka-bootstrap:9092
2022-04-05 16:40:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:40:26 [main] [32mINFO [m [KafkaTopicUtils:197] KafkaTopic's spec is stable for 20 polls intervals
2022-04-05 16:40:26 [main] [32mINFO [m [ReconciliationST:156] Setting annotation to "false", partitions should be scaled to 4
2022-04-05 16:40:26 [main] [32mINFO [m [KafkaTopicUtils:124] Waiting for KafkaTopic change my-topic-1069660884-1337276924
2022-04-05 16:40:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-aeb37c2d in namespace namespace-3
2022-04-05 16:40:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-3
2022-04-05 16:40:26 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkarebalances' with unstable version 'v1beta2'
2022-04-05 16:40:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-aeb37c2d will have desired state: PendingProposal
2022-04-05 16:40:27 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-aeb37c2d is in desired state: PendingProposal
2022-04-05 16:40:27 [main] [32mINFO [m [ReconciliationST:164] Waiting for ProposalReady, then add pause and rebalance annotation, rebalancing should not be triggered
2022-04-05 16:40:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-aeb37c2d will have desired state: ProposalReady
2022-04-05 16:46:37 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-aeb37c2d is in desired state: ProposalReady
2022-04-05 16:46:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-aeb37c2d will have desired state: ReconciliationPaused
2022-04-05 16:46:38 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-aeb37c2d is in desired state: ReconciliationPaused
2022-04-05 16:46:38 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #1(test) KafkaRebalance(namespace-3/my-cluster-aeb37c2d): Annotating KafkaRebalance:my-cluster-aeb37c2d with annotation approve
2022-04-05 16:46:38 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-aeb37c2d): KafkaRebalance status gonna be stable in 19 polls
2022-04-05 16:46:39 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-aeb37c2d): KafkaRebalance status gonna be stable in 18 polls
2022-04-05 16:46:40 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-aeb37c2d): KafkaRebalance status gonna be stable in 17 polls
2022-04-05 16:46:41 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-aeb37c2d): KafkaRebalance status gonna be stable in 16 polls
2022-04-05 16:46:42 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-aeb37c2d): KafkaRebalance status gonna be stable in 15 polls
2022-04-05 16:46:43 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-aeb37c2d): KafkaRebalance status gonna be stable in 14 polls
2022-04-05 16:46:45 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-aeb37c2d): KafkaRebalance status gonna be stable in 13 polls
2022-04-05 16:46:46 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-aeb37c2d): KafkaRebalance status gonna be stable in 12 polls
2022-04-05 16:46:47 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-aeb37c2d): KafkaRebalance status gonna be stable in 11 polls
2022-04-05 16:46:48 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-aeb37c2d): KafkaRebalance status gonna be stable in 10 polls
2022-04-05 16:46:49 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-aeb37c2d): KafkaRebalance status gonna be stable in 9 polls
2022-04-05 16:46:50 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-aeb37c2d): KafkaRebalance status gonna be stable in 8 polls
2022-04-05 16:46:51 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-aeb37c2d): KafkaRebalance status gonna be stable in 7 polls
2022-04-05 16:46:52 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-aeb37c2d): KafkaRebalance status gonna be stable in 6 polls
2022-04-05 16:46:53 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-aeb37c2d): KafkaRebalance status gonna be stable in 5 polls
2022-04-05 16:46:54 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-aeb37c2d): KafkaRebalance status gonna be stable in 4 polls
2022-04-05 16:46:55 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-aeb37c2d): KafkaRebalance status gonna be stable in 3 polls
2022-04-05 16:46:56 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-aeb37c2d): KafkaRebalance status gonna be stable in 2 polls
2022-04-05 16:46:57 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-aeb37c2d): KafkaRebalance status gonna be stable in 1 polls
2022-04-05 16:46:58 [main] [32mINFO [m [KafkaRebalanceUtils:118] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-aeb37c2d): KafkaRebalance status is stable for 20 polls intervals
2022-04-05 16:46:58 [main] [32mINFO [m [ReconciliationST:178] Setting annotation to "false" and waiting for KafkaRebalance to be in Ready state
2022-04-05 16:46:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-aeb37c2d will have desired state: ProposalReady
2022-04-05 16:46:59 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-aeb37c2d is in desired state: ProposalReady
2022-04-05 16:46:59 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #3(test) KafkaRebalance(namespace-3/my-cluster-aeb37c2d): Annotating KafkaRebalance:my-cluster-aeb37c2d with annotation approve
2022-04-05 16:46:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-aeb37c2d will have desired state: Ready
2022-04-05 16:48:05 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-aeb37c2d is in desired state: Ready
2022-04-05 16:48:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:48:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testPauseReconciliationInKafkaRebalanceAndTopic
2022-04-05 16:48:05 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1069660884-1337276924 in namespace namespace-3
2022-04-05 16:48:05 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-aeb37c2d in namespace namespace-3
2022-04-05 16:48:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-aeb37c2d in namespace namespace-3
2022-04-05 16:48:05 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-3, for cruise control Kafka cluster my-cluster-aeb37c2d
2022-04-05 16:48:15 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 16:48:15 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-3 for test case:testPauseReconciliationInKafkaRebalanceAndTopic
2022-04-05 16:48:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.ReconciliationST.testPauseReconciliationInKafkaRebalanceAndTopic-FINISHED
2022-04-05 16:48:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 16:48:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:48:58 [main] [32mINFO [m [ResourceManager:346] In context ReconciliationST is everything deleted.
2022-04-05 16:48:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,167.217 s - in io.strimzi.systemtest.operators.ReconciliationST
[[1;34mINFO[m] Running io.strimzi.systemtest.bridge.HttpBridgeScramShaST
2022-04-05 16:49:03 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: http-bridge-scram-sha-st
2022-04-05 16:49:04 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: http-bridge-scram-sha-st
2022-04-05 16:49:04 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: http-bridge-scram-sha-st
2022-04-05 16:49:04 [main] [32mINFO [m [HttpBridgeScramShaST:123] Deploy Kafka and KafkaBridge before tests
2022-04-05 16:49:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka http-bridge-scram-sha-cluster-name in namespace http-bridge-scram-sha-st
2022-04-05 16:49:04 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: http-bridge-scram-sha-cluster-name will have desired state: Ready
2022-04-05 16:50:04 [main] [32mINFO [m [ResourceManager:444] Kafka: http-bridge-scram-sha-cluster-name is in desired state: Ready
2022-04-05 16:50:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-2091517169-1695277953 in namespace http-bridge-scram-sha-st
2022-04-05 16:50:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-2091517169-1695277953 will have desired state: Ready
2022-04-05 16:50:05 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-2091517169-1695277953 is in desired state: Ready
2022-04-05 16:50:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment http-bridge-scram-sha-st-shared-kafka-clients in namespace http-bridge-scram-sha-st
2022-04-05 16:50:05 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: http-bridge-scram-sha-st-shared-kafka-clients will be ready
2022-04-05 16:50:07 [main] [32mINFO [m [DeploymentUtils:168] Deployment: http-bridge-scram-sha-st-shared-kafka-clients is ready
2022-04-05 16:50:07 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge http-bridge-scram-sha-cluster-name in namespace http-bridge-scram-sha-st
2022-04-05 16:50:07 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkabridges' with unstable version 'v1beta2'
2022-04-05 16:50:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: http-bridge-scram-sha-cluster-name will have desired state: Ready
2022-04-05 16:50:32 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: http-bridge-scram-sha-cluster-name is in desired state: Ready
2022-04-05 16:50:32 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 16:50:32 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 16:50:32 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeScramShaST.testSendSimpleMessageTlsScramSha-STARTED
2022-04-05 16:50:32 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 16:50:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-464213923-2094461147 in namespace http-bridge-scram-sha-st
2022-04-05 16:50:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-464213923-2094461147 will have desired state: Ready
2022-04-05 16:50:33 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-464213923-2094461147 is in desired state: Ready
2022-04-05 16:50:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-337184138 in namespace http-bridge-scram-sha-st
2022-04-05 16:50:33 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-337184138 will be in active state
2022-04-05 16:50:34 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:producer-337184138 to finished
2022-04-05 16:50:43 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 16:50:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-1902039233 in namespace http-bridge-scram-sha-st
2022-04-05 16:50:43 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-1902039233 will be in active state
2022-04-05 16:50:44 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:consumer-1902039233 to finished
2022-04-05 16:50:55 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:50:55 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendSimpleMessageTlsScramSha
2022-04-05 16:50:55 [main] [32mINFO [m [ResourceManager:241] Delete of Job producer-337184138 in namespace http-bridge-scram-sha-st
2022-04-05 16:50:55 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job consumer-1902039233 in namespace http-bridge-scram-sha-st
2022-04-05 16:50:55 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-464213923-2094461147 in namespace http-bridge-scram-sha-st
2022-04-05 16:51:05 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 16:51:05 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeScramShaST.testSendSimpleMessageTlsScramSha-FINISHED
2022-04-05 16:51:05 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 16:51:05 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 16:51:05 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeScramShaST.testReceiveSimpleMessageTlsScramSha-STARTED
2022-04-05 16:51:05 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 16:51:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-57885039-819052364 in namespace http-bridge-scram-sha-st
2022-04-05 16:51:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-57885039-819052364 will have desired state: Ready
2022-04-05 16:51:06 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-57885039-819052364 is in desired state: Ready
2022-04-05 16:51:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-432451530 in namespace http-bridge-scram-sha-st
2022-04-05 16:51:06 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-432451530 will be in active state
2022-04-05 16:51:07 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 16:51:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-6439446 in namespace http-bridge-scram-sha-st
2022-04-05 16:51:07 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-6439446 will be in active state
2022-04-05 16:51:08 [main] [32mINFO [m [ClientUtils:61] Waiting till producer producer-6439446 and consumer consumer-432451530 finish
2022-04-05 16:51:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:51:18 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testReceiveSimpleMessageTlsScramSha
2022-04-05 16:51:18 [main] [32mINFO [m [ResourceManager:241] Delete of Job consumer-432451530 in namespace http-bridge-scram-sha-st
2022-04-05 16:51:18 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job producer-6439446 in namespace http-bridge-scram-sha-st
2022-04-05 16:51:18 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-57885039-819052364 in namespace http-bridge-scram-sha-st
2022-04-05 16:51:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 16:51:28 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeScramShaST.testReceiveSimpleMessageTlsScramSha-FINISHED
2022-04-05 16:51:28 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 16:51:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:51:28 [main] [32mINFO [m [ResourceManager:348] Delete all resources for HttpBridgeScramShaST
2022-04-05 16:51:28 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment http-bridge-scram-sha-st-shared-kafka-clients in namespace http-bridge-scram-sha-st
2022-04-05 16:51:28 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge http-bridge-scram-sha-cluster-name in namespace http-bridge-scram-sha-st
2022-04-05 16:51:28 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-2091517169-1695277953 in namespace http-bridge-scram-sha-st
2022-04-05 16:51:28 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka http-bridge-scram-sha-cluster-name in namespace http-bridge-scram-sha-st
2022-04-05 16:52:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 200.529 s - in io.strimzi.systemtest.bridge.HttpBridgeScramShaST
[[1;34mINFO[m] Running io.strimzi.systemtest.bridge.HttpBridgeTlsST
2022-04-05 16:52:24 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: http-bridge-tls-st
2022-04-05 16:52:24 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: http-bridge-tls-st
2022-04-05 16:52:24 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: http-bridge-tls-st
2022-04-05 16:52:24 [main] [32mINFO [m [HttpBridgeTlsST:129] Deploy Kafka and KafkaBridge before tests
2022-04-05 16:52:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka http-bridge-tls-cluster-name in namespace http-bridge-tls-st
2022-04-05 16:52:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: http-bridge-tls-cluster-name will have desired state: Ready
2022-04-05 16:53:30 [main] [32mINFO [m [ResourceManager:444] Kafka: http-bridge-tls-cluster-name is in desired state: Ready
2022-04-05 16:53:30 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1263414512-88479823 in namespace http-bridge-tls-st
2022-04-05 16:53:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1263414512-88479823 will have desired state: Ready
2022-04-05 16:53:31 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1263414512-88479823 is in desired state: Ready
2022-04-05 16:53:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment http-bridge-tls-st-kafka-clients in namespace http-bridge-tls-st
2022-04-05 16:53:31 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: http-bridge-tls-st-kafka-clients will be ready
2022-04-05 16:53:33 [main] [32mINFO [m [DeploymentUtils:168] Deployment: http-bridge-tls-st-kafka-clients is ready
2022-04-05 16:53:33 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge http-bridge-tls-cluster-name in namespace http-bridge-tls-st
2022-04-05 16:53:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: http-bridge-tls-cluster-name will have desired state: Ready
2022-04-05 16:53:52 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: http-bridge-tls-cluster-name is in desired state: Ready
2022-04-05 16:53:52 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 16:53:52 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 16:53:52 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeTlsST.testReceiveSimpleMessageTls-STARTED
2022-04-05 16:53:52 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 16:53:52 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-971472050-1076234130 in namespace http-bridge-tls-st
2022-04-05 16:53:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-971472050-1076234130 will have desired state: Ready
2022-04-05 16:53:53 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-971472050-1076234130 is in desired state: Ready
2022-04-05 16:53:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-1790651895 in namespace http-bridge-tls-st
2022-04-05 16:53:53 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-1790651895 will be in active state
2022-04-05 16:53:54 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 16:53:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-206513444 in namespace http-bridge-tls-st
2022-04-05 16:53:54 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-206513444 will be in active state
2022-04-05 16:53:56 [main] [32mINFO [m [ClientUtils:61] Waiting till producer producer-206513444 and consumer consumer-1790651895 finish
2022-04-05 16:54:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:54:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testReceiveSimpleMessageTls
2022-04-05 16:54:11 [main] [32mINFO [m [ResourceManager:241] Delete of Job consumer-1790651895 in namespace http-bridge-tls-st
2022-04-05 16:54:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job producer-206513444 in namespace http-bridge-tls-st
2022-04-05 16:54:11 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-971472050-1076234130 in namespace http-bridge-tls-st
2022-04-05 16:54:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 16:54:21 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeTlsST.testReceiveSimpleMessageTls-FINISHED
2022-04-05 16:54:21 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 16:54:21 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 16:54:21 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeTlsST.testSendSimpleMessageTls-STARTED
2022-04-05 16:54:21 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 16:54:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-389891730-1745685953 in namespace http-bridge-tls-st
2022-04-05 16:54:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-389891730-1745685953 will have desired state: Ready
2022-04-05 16:54:22 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-389891730-1745685953 is in desired state: Ready
2022-04-05 16:54:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-1309268466 in namespace http-bridge-tls-st
2022-04-05 16:54:22 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-1309268466 will be in active state
2022-04-05 16:54:23 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:producer-1309268466 to finished
2022-04-05 16:54:31 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 16:54:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-1299960527 in namespace http-bridge-tls-st
2022-04-05 16:54:31 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-1299960527 will be in active state
2022-04-05 16:54:32 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:consumer-1299960527 to finished
2022-04-05 16:54:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:54:43 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendSimpleMessageTls
2022-04-05 16:54:43 [main] [32mINFO [m [ResourceManager:241] Delete of Job producer-1309268466 in namespace http-bridge-tls-st
2022-04-05 16:54:43 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job consumer-1299960527 in namespace http-bridge-tls-st
2022-04-05 16:54:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-389891730-1745685953 in namespace http-bridge-tls-st
2022-04-05 16:54:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 16:54:53 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeTlsST.testSendSimpleMessageTls-FINISHED
2022-04-05 16:54:53 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 16:54:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:54:53 [main] [32mINFO [m [ResourceManager:348] Delete all resources for HttpBridgeTlsST
2022-04-05 16:54:53 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment http-bridge-tls-st-kafka-clients in namespace http-bridge-tls-st
2022-04-05 16:54:53 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge http-bridge-tls-cluster-name in namespace http-bridge-tls-st
2022-04-05 16:54:53 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1263414512-88479823 in namespace http-bridge-tls-st
2022-04-05 16:54:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka http-bridge-tls-cluster-name in namespace http-bridge-tls-st
2022-04-05 16:55:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 204.23 s - in io.strimzi.systemtest.bridge.HttpBridgeTlsST
[[1;34mINFO[m] Running io.strimzi.systemtest.tracing.TracingST
2022-04-05 16:55:48 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: tracing-st
2022-04-05 16:55:49 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: tracing-st
2022-04-05 16:55:49 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: tracing-st
2022-04-05 16:55:49 [main] [32mINFO [m [TracingST:497] === Applying jaeger operator install files ===
2022-04-05 16:55:49 [main] [32mINFO [m [TracingST:488] Creating jaeger-cluster-role-binding.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-cluster-role-binding.yaml
2022-04-05 16:55:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-05 16:55:49 [main] [32mINFO [m [Exec:417] Input: ---
kind: "ClusterRoleBinding"
apiVersion: "rbac.authorization.k8s.io/v1"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
subjects:
- kind: "ServiceAccount"
  name: "jaeger-operator"
  namespace: "tracing-st"
roleRef:
  kind: "ClusterRole"
  name: "jaeger-operator"
  apiGroup: "rbac.authorization.k8s.io"
2022-04-05 16:55:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:55:49 [main] [32mINFO [m [TracingST:488] Creating jaeger-cluster-role.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-cluster-role.yaml
2022-04-05 16:55:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-05 16:55:49 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "rbac.authorization.k8s.io/v1"
kind: "ClusterRole"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
rules:
- apiGroups:
  - "jaegertracing.io"
  resources:
  - "*"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resourceNames:
  - "jaeger-operator"
  resources:
  - "deployments/finalizers"
  verbs:
  - "update"
- apiGroups:
  - ""
  resources:
  - "configmaps"
  - "persistentvolumeclaims"
  - "pods"
  - "secrets"
  - "serviceaccounts"
  - "services"
  - "services/finalizers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  - "daemonsets"
  - "replicasets"
  - "statefulsets"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "extensions"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "networking.k8s.io"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "batch"
  resources:
  - "jobs"
  - "cronjobs"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "route.openshift.io"
  resources:
  - "routes"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "console.openshift.io"
  resources:
  - "consolelinks"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "autoscaling"
  resources:
  - "horizontalpodautoscalers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "monitoring.coreos.com"
  resources:
  - "servicemonitors"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "logging.openshift.io"
  resources:
  - "elasticsearches"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "kafka.strimzi.io"
  resources:
  - "kafkas"
  - "kafkausers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - ""
  resources:
  - "namespaces"
  verbs:
  - "get"
  - "list"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  verbs:
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "rbac.authorization.k8s.io"
  resources:
  - "clusterrolebindings"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
2022-04-05 16:55:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:55:49 [main] [32mINFO [m [TracingST:488] Creating jaeger-crd.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-crd.yaml
2022-04-05 16:55:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-05 16:55:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:55:49 [main] [32mINFO [m [TracingST:488] Creating jaeger-operator.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-operator.yaml
2022-04-05 16:55:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-05 16:55:50 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "apps/v1"
kind: "Deployment"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
spec:
  replicas: 1
  selector:
    matchLabels:
      name: "jaeger-operator"
  template:
    metadata:
      labels:
        name: "jaeger-operator"
    spec:
      serviceAccountName: "jaeger-operator"
      containers:
      - name: "jaeger-operator"
        image: "jaegertracing/jaeger-operator:1.20.0"
        ports:
        - containerPort: 8383
          name: "http-metrics"
        - containerPort: 8686
          name: "cr-metrics"
        args:
        - "start"
        - "--kafka-provision=no"
        imagePullPolicy: "Always"
        env:
        - name: "WATCH_NAMESPACE"
          value: ""
        - name: "POD_NAME"
          valueFrom:
            fieldRef:
              fieldPath: "metadata.name"
        - name: "POD_NAMESPACE"
          valueFrom:
            fieldRef:
              fieldPath: "metadata.namespace"
        - name: "OPERATOR_NAME"
          value: "jaeger-operator"
2022-04-05 16:55:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:55:50 [main] [32mINFO [m [TracingST:488] Creating jaeger-role-binding.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-role-binding.yaml
2022-04-05 16:55:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-05 16:55:50 [main] [32mINFO [m [Exec:417] Input: ---
kind: "RoleBinding"
apiVersion: "rbac.authorization.k8s.io/v1"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
subjects:
- kind: "ServiceAccount"
  name: "jaeger-operator"
roleRef:
  kind: "Role"
  name: "jaeger-operator"
  apiGroup: "rbac.authorization.k8s.io"
2022-04-05 16:55:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:55:50 [main] [32mINFO [m [TracingST:488] Creating jaeger-role.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-role.yaml
2022-04-05 16:55:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-05 16:55:50 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "rbac.authorization.k8s.io/v1"
kind: "Role"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
rules:
- apiGroups:
  - "jaegertracing.io"
  resources:
  - "*"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resourceNames:
  - "jaeger-operator"
  resources:
  - "deployments/finalizers"
  verbs:
  - "update"
- apiGroups:
  - ""
  resources:
  - "configmaps"
  - "persistentvolumeclaims"
  - "pods"
  - "secrets"
  - "serviceaccounts"
  - "services"
  - "services/finalizers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  - "daemonsets"
  - "replicasets"
  - "statefulsets"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "extensions"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "networking.k8s.io"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "batch"
  resources:
  - "jobs"
  - "cronjobs"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "route.openshift.io"
  resources:
  - "routes"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "image.openshift.io"
  resources:
  - "imagestreams"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "autoscaling"
  resources:
  - "horizontalpodautoscalers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "monitoring.coreos.com"
  resources:
  - "servicemonitors"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "logging.openshift.io"
  resources:
  - "elasticsearches"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "kafka.strimzi.io"
  resources:
  - "kafkas"
  - "kafkausers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
2022-04-05 16:55:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:55:50 [main] [32mINFO [m [TracingST:488] Creating jaeger-service-account.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-service-account.yaml
2022-04-05 16:55:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-05 16:55:50 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "v1"
kind: "ServiceAccount"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
2022-04-05 16:55:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:55:50 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: jaeger-operator will be ready
2022-04-05 16:55:52 [main] [32mINFO [m [DeploymentUtils:168] Deployment: jaeger-operator is ready
2022-04-05 16:55:52 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment jaeger-operator to be ready
2022-04-05 16:56:02 [main] [32mINFO [m [DeploymentUtils:197] Deployment jaeger-operator is ready
2022-04-05 16:56:02 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy jaeger-allow in namespace tracing-st
2022-04-05 16:56:02 [main] [32mINFO [m [TracingST:524] Network policy for jaeger successfully created
2022-04-05 16:56:02 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 16:56:02 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerStreamsConnectService-STARTED
2022-04-05 16:56:02 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 16:56:02 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-4 for test case:testProducerConsumerStreamsConnectService
2022-04-05 16:56:02 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-4
2022-04-05 16:56:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-4
2022-04-05 16:56:02 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-4
2022-04-05 16:56:02 [main] [32mINFO [m [TracingST:531] === Applying jaeger instance install file ===
2022-04-05 16:56:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 apply -f -
2022-04-05 16:56:03 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-05 16:56:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:56:03 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-jaeger will be ready
2022-04-05 16:56:09 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-jaeger is ready
2022-04-05 16:56:09 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-jaeger to be ready
2022-04-05 16:56:19 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-jaeger is ready
2022-04-05 16:56:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-0aee98bd-kafka-clients in namespace namespace-4
2022-04-05 16:56:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-05 16:56:19 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-0aee98bd-kafka-clients will be ready
2022-04-05 16:56:21 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-0aee98bd-kafka-clients is ready
2022-04-05 16:56:21 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 16:56:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0aee98bd in namespace namespace-4
2022-04-05 16:56:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-05 16:56:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0aee98bd will have desired state: Ready
2022-04-05 16:57:33 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0aee98bd is in desired state: Ready
2022-04-05 16:57:33 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1816822425-1839457817 in namespace namespace-4
2022-04-05 16:57:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-05 16:57:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1816822425-1839457817 will have desired state: Ready
2022-04-05 16:57:34 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1816822425-1839457817 is in desired state: Ready
2022-04-05 16:57:34 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2025722138-109787747 in namespace namespace-4
2022-04-05 16:57:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-05 16:57:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2025722138-109787747 will have desired state: Ready
2022-04-05 16:57:35 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2025722138-109787747 is in desired state: Ready
2022-04-05 16:57:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-0aee98bd-scraper in namespace namespace-4
2022-04-05 16:57:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-05 16:57:35 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-0aee98bd-scraper will be ready
2022-04-05 16:57:37 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-0aee98bd-scraper is ready
2022-04-05 16:57:37 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-0aee98bd-scraper to be ready
2022-04-05 16:57:47 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-0aee98bd-scraper is ready
2022-04-05 16:57:47 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-0aee98bd-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-05 16:57:47 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-0aee98bd-allow in namespace namespace-4
2022-04-05 16:57:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-05 16:57:47 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-05 16:57:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-0aee98bd in namespace namespace-4
2022-04-05 16:57:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-05 16:57:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-0aee98bd will have desired state: Ready
2022-04-05 16:58:50 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-0aee98bd is in desired state: Ready
2022-04-05 16:58:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-0aee98bd in namespace namespace-4
2022-04-05 16:58:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-05 16:58:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-0aee98bd will have desired state: Ready
2022-04-05 16:58:52 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-0aee98bd is in desired state: Ready
2022-04-05 16:58:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-0aee98bd-hello-world-producer in namespace namespace-4
2022-04-05 16:58:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-05 16:58:52 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-0aee98bd-hello-world-producer will be in active state
2022-04-05 16:58:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-0aee98bd-hello-world-consumer in namespace namespace-4
2022-04-05 16:58:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-05 16:58:53 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-0aee98bd-hello-world-consumer will be in active state
2022-04-05 16:58:54 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-0aee98bd-hello-world-producer and consumer my-cluster-0aee98bd-hello-world-consumer finish
2022-04-05 16:59:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-0aee98bd-kafka-clients-85986ff898-5nnrb -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 16:59:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:59:05 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-producer is present
2022-04-05 16:59:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-0aee98bd-kafka-clients-85986ff898-5nnrb -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-producer&operation=To_my-topic-1816822425-1839457817
2022-04-05 16:59:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:59:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-0aee98bd-kafka-clients-85986ff898-5nnrb -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 16:59:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:59:05 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-consumer is present
2022-04-05 16:59:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-0aee98bd-kafka-clients-85986ff898-5nnrb -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-consumer&operation=From_my-topic-1816822425-1839457817
2022-04-05 16:59:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:59:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-0aee98bd-kafka-clients-85986ff898-5nnrb -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 16:59:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:59:06 [main] [32mINFO [m [TracingUtils:47] Jaeger service my-connect is present
2022-04-05 16:59:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-0aee98bd-kafka-clients-85986ff898-5nnrb -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=my-connect&operation=From_my-topic-1816822425-1839457817
2022-04-05 16:59:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:59:06 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:59:06 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerStreamsConnectService
2022-04-05 16:59:06 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-0aee98bd-allow in namespace namespace-4
2022-04-05 16:59:06 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0aee98bd in namespace namespace-4
2022-04-05 16:59:06 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-0aee98bd-scraper in namespace namespace-4
2022-04-05 16:59:06 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-0aee98bd-hello-world-producer in namespace namespace-4
2022-04-05 16:59:06 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-0aee98bd-kafka-clients in namespace namespace-4
2022-04-05 16:59:06 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2025722138-109787747 in namespace namespace-4
2022-04-05 16:59:06 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1816822425-1839457817 in namespace namespace-4
2022-04-05 16:59:06 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-0aee98bd-hello-world-consumer in namespace namespace-4
2022-04-05 16:59:06 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-0aee98bd in namespace namespace-4
2022-04-05 16:59:06 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-0aee98bd in namespace namespace-4
2022-04-05 16:59:06 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 delete -f -
2022-04-05 16:59:06 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-05 16:59:06 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:59:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 16:59:56 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-4 for test case:testProducerConsumerStreamsConnectService
2022-04-05 17:00:02 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerStreamsConnectService-FINISHED
2022-04-05 17:00:02 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 17:00:02 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 17:00:02 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.tracing.TracingST.testKafkaBridgeService-STARTED
2022-04-05 17:00:02 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 17:00:02 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-5 for test case:testKafkaBridgeService
2022-04-05 17:00:02 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-5
2022-04-05 17:00:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-5
2022-04-05 17:00:02 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-5
2022-04-05 17:00:02 [main] [32mINFO [m [TracingST:531] === Applying jaeger instance install file ===
2022-04-05 17:00:02 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-5 apply -f -
2022-04-05 17:00:02 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-05 17:00:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:00:02 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-jaeger will be ready
2022-04-05 17:00:07 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-jaeger is ready
2022-04-05 17:00:07 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-jaeger to be ready
2022-04-05 17:00:17 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-jaeger is ready
2022-04-05 17:00:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-6165cc50-kafka-clients in namespace namespace-5
2022-04-05 17:00:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-04-05 17:00:17 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-6165cc50-kafka-clients will be ready
2022-04-05 17:00:19 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-6165cc50-kafka-clients is ready
2022-04-05 17:00:19 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 17:00:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-6165cc50 in namespace namespace-5
2022-04-05 17:00:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-04-05 17:00:19 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-6165cc50 will have desired state: Ready
2022-04-05 17:01:38 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-6165cc50 is in desired state: Ready
2022-04-05 17:01:38 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge my-cluster-6165cc50 in namespace namespace-5
2022-04-05 17:01:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-04-05 17:01:38 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: my-cluster-6165cc50 will have desired state: Ready
2022-04-05 17:02:00 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: my-cluster-6165cc50 is in desired state: Ready
2022-04-05 17:02:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-582845315-2113686809 in namespace namespace-5
2022-04-05 17:02:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-04-05 17:02:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-582845315-2113686809 will have desired state: Ready
2022-04-05 17:02:01 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-582845315-2113686809 is in desired state: Ready
2022-04-05 17:02:01 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 17:02:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Job bridge-producer in namespace namespace-5
2022-04-05 17:02:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-04-05 17:02:01 [main] [32mINFO [m [JobUtils:81] Waiting for job: bridge-producer will be in active state
2022-04-05 17:02:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-6165cc50-hello-world-consumer in namespace namespace-5
2022-04-05 17:02:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-04-05 17:02:03 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-6165cc50-hello-world-consumer will be in active state
2022-04-05 17:02:04 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:bridge-producer to finished
2022-04-05 17:03:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-5 exec my-cluster-6165cc50-kafka-clients-578c696fcb-m6krj -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:03:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:03:51 [main] [32mINFO [m [TracingUtils:47] Jaeger service my-kafka-bridge is present
2022-04-05 17:03:52 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-5 exec my-cluster-6165cc50-kafka-clients-578c696fcb-m6krj -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=my-kafka-bridge
2022-04-05 17:03:52 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:03:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:03:52 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaBridgeService
2022-04-05 17:03:52 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-582845315-2113686809 in namespace namespace-5
2022-04-05 17:03:52 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge my-cluster-6165cc50 in namespace namespace-5
2022-04-05 17:03:52 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-6165cc50-hello-world-consumer in namespace namespace-5
2022-04-05 17:03:52 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-6165cc50 in namespace namespace-5
2022-04-05 17:03:52 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-6165cc50-kafka-clients in namespace namespace-5
2022-04-05 17:03:52 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job bridge-producer in namespace namespace-5
2022-04-05 17:03:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-5 delete -f -
2022-04-05 17:03:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-05 17:03:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:04:32 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 17:04:32 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-5 for test case:testKafkaBridgeService
2022-04-05 17:04:37 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.tracing.TracingST.testKafkaBridgeService-FINISHED
2022-04-05 17:04:37 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 17:04:37 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 17:04:37 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerStreamsService-STARTED
2022-04-05 17:04:37 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 17:04:37 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-6 for test case:testProducerConsumerStreamsService
2022-04-05 17:04:37 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-6
2022-04-05 17:04:37 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-6
2022-04-05 17:04:37 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-6
2022-04-05 17:04:37 [main] [32mINFO [m [TracingST:531] === Applying jaeger instance install file ===
2022-04-05 17:04:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 apply -f -
2022-04-05 17:04:37 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-05 17:04:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:04:37 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-jaeger will be ready
2022-04-05 17:04:47 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-jaeger is ready
2022-04-05 17:04:47 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-jaeger to be ready
2022-04-05 17:04:57 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-jaeger is ready
2022-04-05 17:04:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-98add92b-kafka-clients in namespace namespace-6
2022-04-05 17:04:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-05 17:04:57 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-98add92b-kafka-clients will be ready
2022-04-05 17:04:59 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-98add92b-kafka-clients is ready
2022-04-05 17:04:59 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 17:04:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-98add92b in namespace namespace-6
2022-04-05 17:04:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-05 17:04:59 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-98add92b will have desired state: Ready
2022-04-05 17:06:03 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-98add92b is in desired state: Ready
2022-04-05 17:06:03 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-318569117-132855731 in namespace namespace-6
2022-04-05 17:06:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-05 17:06:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-318569117-132855731 will have desired state: Ready
2022-04-05 17:06:04 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-318569117-132855731 is in desired state: Ready
2022-04-05 17:06:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1050531120-1372624928 in namespace namespace-6
2022-04-05 17:06:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-05 17:06:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1050531120-1372624928 will have desired state: Ready
2022-04-05 17:06:05 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1050531120-1372624928 is in desired state: Ready
2022-04-05 17:06:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-98add92b-hello-world-producer in namespace namespace-6
2022-04-05 17:06:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-05 17:06:05 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-98add92b-hello-world-producer will be in active state
2022-04-05 17:06:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-98add92b-kafka-clients-5f6d87f8d4-hkgxm -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:06:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:06:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-98add92b-kafka-clients-5f6d87f8d4-hkgxm -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:06:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:06:07 [main] [32mINFO [m [TracingUtils:50] Jaeger service hello-world-producer is not present. Present services are ["jaeger-query"].
2022-04-05 17:06:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-98add92b-kafka-clients-5f6d87f8d4-hkgxm -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:06:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:06:08 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-producer is present
2022-04-05 17:06:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-98add92b-kafka-clients-5f6d87f8d4-hkgxm -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-producer
2022-04-05 17:06:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:06:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-98add92b-hello-world-consumer in namespace namespace-6
2022-04-05 17:06:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-05 17:06:09 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-98add92b-hello-world-consumer will be in active state
2022-04-05 17:06:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-98add92b-kafka-clients-5f6d87f8d4-hkgxm -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:06:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:06:10 [main] [32mINFO [m [TracingUtils:50] Jaeger service hello-world-consumer is not present. Present services are ["jaeger-query","hello-world-producer"].
2022-04-05 17:06:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-98add92b-kafka-clients-5f6d87f8d4-hkgxm -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:06:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:06:11 [main] [32mINFO [m [TracingUtils:50] Jaeger service hello-world-consumer is not present. Present services are ["jaeger-query","hello-world-producer"].
2022-04-05 17:06:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-98add92b-kafka-clients-5f6d87f8d4-hkgxm -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:06:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:06:12 [main] [32mINFO [m [TracingUtils:50] Jaeger service hello-world-consumer is not present. Present services are ["jaeger-query","hello-world-producer"].
2022-04-05 17:06:13 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-98add92b-kafka-clients-5f6d87f8d4-hkgxm -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:06:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:06:13 [main] [32mINFO [m [TracingUtils:50] Jaeger service hello-world-consumer is not present. Present services are ["jaeger-query","hello-world-producer"].
2022-04-05 17:06:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-98add92b-kafka-clients-5f6d87f8d4-hkgxm -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:06:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:06:15 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-consumer is present
2022-04-05 17:06:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-98add92b-kafka-clients-5f6d87f8d4-hkgxm -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-consumer
2022-04-05 17:06:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:06:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-streams in namespace namespace-6
2022-04-05 17:06:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-05 17:06:15 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-streams will be in active state
2022-04-05 17:06:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:06:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerStreamsService
2022-04-05 17:06:16 [main] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-98add92b-hello-world-producer in namespace namespace-6
2022-04-05 17:06:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-98add92b in namespace namespace-6
2022-04-05 17:06:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-98add92b-hello-world-consumer in namespace namespace-6
2022-04-05 17:06:16 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1050531120-1372624928 in namespace namespace-6
2022-04-05 17:06:16 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-98add92b-kafka-clients in namespace namespace-6
2022-04-05 17:06:16 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-318569117-132855731 in namespace namespace-6
2022-04-05 17:06:16 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-streams in namespace namespace-6
2022-04-05 17:06:16 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 delete -f -
2022-04-05 17:06:16 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-05 17:06:16 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:06:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 17:06:56 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-6 for test case:testProducerConsumerStreamsService
2022-04-05 17:07:01 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerStreamsService-FINISHED
2022-04-05 17:07:01 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 17:07:01 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 17:07:01 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerMirrorMakerService-STARTED
2022-04-05 17:07:01 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 17:07:01 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-7 for test case:testProducerConsumerMirrorMakerService
2022-04-05 17:07:01 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-7
2022-04-05 17:07:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-7
2022-04-05 17:07:02 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-7
2022-04-05 17:07:02 [main] [32mINFO [m [TracingST:531] === Applying jaeger instance install file ===
2022-04-05 17:07:02 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 apply -f -
2022-04-05 17:07:02 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-05 17:07:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:07:02 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-jaeger will be ready
2022-04-05 17:07:04 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-jaeger is ready
2022-04-05 17:07:04 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-jaeger to be ready
2022-04-05 17:07:14 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-jaeger is ready
2022-04-05 17:07:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-0e17f618-kafka-clients in namespace namespace-7
2022-04-05 17:07:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-05 17:07:14 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-0e17f618-kafka-clients will be ready
2022-04-05 17:07:16 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-0e17f618-kafka-clients is ready
2022-04-05 17:07:16 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 17:07:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0e17f618 in namespace namespace-7
2022-04-05 17:07:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-05 17:07:16 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0e17f618 will have desired state: Ready
2022-04-05 17:08:31 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0e17f618 is in desired state: Ready
2022-04-05 17:08:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0e17f618-target in namespace namespace-7
2022-04-05 17:08:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-05 17:08:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0e17f618-target will have desired state: Ready
2022-04-05 17:09:48 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0e17f618-target is in desired state: Ready
2022-04-05 17:09:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-729806101-432398385 in namespace namespace-7
2022-04-05 17:09:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-05 17:09:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-729806101-432398385 will have desired state: Ready
2022-04-05 17:09:49 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-729806101-432398385 is in desired state: Ready
2022-04-05 17:09:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-729806101-432398385-target in namespace namespace-7
2022-04-05 17:09:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-05 17:09:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-729806101-432398385-target will have desired state: Ready
2022-04-05 17:09:50 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-729806101-432398385-target is in desired state: Ready
2022-04-05 17:09:50 [main] [32mINFO [m [TracingST:267] Setting for kafka source plain bootstrap:my-cluster-0e17f618-kafka-bootstrap:9092
2022-04-05 17:09:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-0e17f618-hello-world-producer in namespace namespace-7
2022-04-05 17:09:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-05 17:09:50 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-0e17f618-hello-world-producer will be in active state
2022-04-05 17:09:51 [main] [32mINFO [m [TracingST:276] Setting for kafka target plain bootstrap:my-cluster-0e17f618-target-kafka-bootstrap:9092
2022-04-05 17:09:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-0e17f618-hello-world-consumer in namespace namespace-7
2022-04-05 17:09:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-05 17:09:51 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-0e17f618-hello-world-consumer will be in active state
2022-04-05 17:09:52 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-0e17f618 in namespace namespace-7
2022-04-05 17:09:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-05 17:09:52 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkamirrormakers' with unstable version 'v1beta2'
2022-04-05 17:09:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-0e17f618 will have desired state: Ready
2022-04-05 17:11:02 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-0e17f618 is in desired state: Ready
2022-04-05 17:11:02 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-0e17f618-kafka-clients-86c9b55dcd-hscjq -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:11:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:11:02 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-producer is present
2022-04-05 17:11:02 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-0e17f618-kafka-clients-86c9b55dcd-hscjq -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-producer&operation=To_my-topic-729806101-432398385
2022-04-05 17:11:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:11:02 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-0e17f618-kafka-clients-86c9b55dcd-hscjq -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:11:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:11:02 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-consumer is present
2022-04-05 17:11:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-0e17f618-kafka-clients-86c9b55dcd-hscjq -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-consumer&operation=From_my-topic-729806101-432398385
2022-04-05 17:11:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:11:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-0e17f618-kafka-clients-86c9b55dcd-hscjq -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:11:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:11:03 [main] [32mINFO [m [TracingUtils:47] Jaeger service my-mirror-maker is present
2022-04-05 17:11:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-0e17f618-kafka-clients-86c9b55dcd-hscjq -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=my-mirror-maker&operation=From_my-topic-729806101-432398385
2022-04-05 17:11:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:11:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-0e17f618-kafka-clients-86c9b55dcd-hscjq -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:11:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:11:03 [main] [32mINFO [m [TracingUtils:47] Jaeger service my-mirror-maker is present
2022-04-05 17:11:04 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-0e17f618-kafka-clients-86c9b55dcd-hscjq -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=my-mirror-maker&operation=To_my-topic-729806101-432398385
2022-04-05 17:11:04 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:11:04 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:11:04 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerMirrorMakerService
2022-04-05 17:11:04 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-729806101-432398385-target in namespace namespace-7
2022-04-05 17:11:04 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-729806101-432398385 in namespace namespace-7
2022-04-05 17:11:04 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-0e17f618-hello-world-consumer in namespace namespace-7
2022-04-05 17:11:04 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-0e17f618-kafka-clients in namespace namespace-7
2022-04-05 17:11:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0e17f618 in namespace namespace-7
2022-04-05 17:11:04 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-0e17f618-hello-world-producer in namespace namespace-7
2022-04-05 17:11:04 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0e17f618-target in namespace namespace-7
2022-04-05 17:11:04 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-0e17f618 in namespace namespace-7
2022-04-05 17:11:04 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 delete -f -
2022-04-05 17:11:04 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-05 17:11:04 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:12:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 17:12:04 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-7 for test case:testProducerConsumerMirrorMakerService
2022-04-05 17:12:10 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerMirrorMakerService-FINISHED
2022-04-05 17:12:10 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 17:12:10 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 17:12:10 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerMirrorMaker2Service-STARTED
2022-04-05 17:12:10 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 17:12:10 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-8 for test case:testProducerConsumerMirrorMaker2Service
2022-04-05 17:12:10 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-8
2022-04-05 17:12:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-8
2022-04-05 17:12:11 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-8
2022-04-05 17:12:11 [main] [32mINFO [m [TracingST:531] === Applying jaeger instance install file ===
2022-04-05 17:12:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 apply -f -
2022-04-05 17:12:11 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-05 17:12:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:12:11 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-jaeger will be ready
2022-04-05 17:12:19 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-jaeger is ready
2022-04-05 17:12:19 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-jaeger to be ready
2022-04-05 17:12:29 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-jaeger is ready
2022-04-05 17:12:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-be7b9aaf-kafka-clients in namespace namespace-8
2022-04-05 17:12:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-05 17:12:29 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-be7b9aaf-kafka-clients will be ready
2022-04-05 17:12:31 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-be7b9aaf-kafka-clients is ready
2022-04-05 17:12:31 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 17:12:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-be7b9aaf in namespace namespace-8
2022-04-05 17:12:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-05 17:12:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-be7b9aaf will have desired state: Ready
2022-04-05 17:13:44 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-be7b9aaf is in desired state: Ready
2022-04-05 17:13:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-be7b9aaf-target in namespace namespace-8
2022-04-05 17:13:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-05 17:13:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-be7b9aaf-target will have desired state: Ready
2022-04-05 17:14:56 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-be7b9aaf-target is in desired state: Ready
2022-04-05 17:14:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1359465312-1139365755 in namespace namespace-8
2022-04-05 17:14:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-05 17:14:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1359465312-1139365755 will have desired state: Ready
2022-04-05 17:14:57 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1359465312-1139365755 is in desired state: Ready
2022-04-05 17:14:57 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-cluster-be7b9aaf.my-topic-1359465312-1139365755 in namespace namespace-8
2022-04-05 17:14:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-05 17:14:57 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-cluster-be7b9aaf.my-topic-1359465312-1139365755 will have desired state: Ready
2022-04-05 17:14:58 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-cluster-be7b9aaf.my-topic-1359465312-1139365755 is in desired state: Ready
2022-04-05 17:14:58 [main] [32mINFO [m [TracingST:177] Setting for kafka source plain bootstrap:my-cluster-be7b9aaf-kafka-bootstrap:9092
2022-04-05 17:14:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-be7b9aaf-hello-world-producer in namespace namespace-8
2022-04-05 17:14:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-05 17:14:58 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-be7b9aaf-hello-world-producer will be in active state
2022-04-05 17:14:59 [main] [32mINFO [m [TracingST:186] Setting for kafka target plain bootstrap:my-cluster-be7b9aaf-target-kafka-bootstrap:9092
2022-04-05 17:14:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-be7b9aaf-hello-world-consumer in namespace namespace-8
2022-04-05 17:14:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-05 17:14:59 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-be7b9aaf-hello-world-consumer will be in active state
2022-04-05 17:15:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-be7b9aaf in namespace namespace-8
2022-04-05 17:15:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-05 17:15:00 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkamirrormaker2s' with unstable version 'v1beta2'
2022-04-05 17:15:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-be7b9aaf will have desired state: Ready
2022-04-05 17:16:12 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-be7b9aaf is in desired state: Ready
2022-04-05 17:16:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-be7b9aaf-kafka-clients-5f84f466d6-x2h4j -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:16:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:16:12 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-producer is present
2022-04-05 17:16:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-be7b9aaf-kafka-clients-5f84f466d6-x2h4j -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-producer&operation=To_my-topic-1359465312-1139365755
2022-04-05 17:16:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:16:13 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-be7b9aaf-kafka-clients-5f84f466d6-x2h4j -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:16:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:16:13 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-consumer is present
2022-04-05 17:16:13 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-be7b9aaf-kafka-clients-5f84f466d6-x2h4j -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-consumer&operation=From_my-cluster-be7b9aaf.my-topic-1359465312-1139365755
2022-04-05 17:16:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:16:13 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-be7b9aaf-kafka-clients-5f84f466d6-x2h4j -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:16:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:16:13 [main] [32mINFO [m [TracingUtils:47] Jaeger service my-mirror-maker2 is present
2022-04-05 17:16:13 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-be7b9aaf-kafka-clients-5f84f466d6-x2h4j -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=my-mirror-maker2&operation=From_my-topic-1359465312-1139365755
2022-04-05 17:16:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:16:14 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-be7b9aaf-kafka-clients-5f84f466d6-x2h4j -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:16:14 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:16:14 [main] [32mINFO [m [TracingUtils:47] Jaeger service my-mirror-maker2 is present
2022-04-05 17:16:14 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-be7b9aaf-kafka-clients-5f84f466d6-x2h4j -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=my-mirror-maker2&operation=To_my-cluster-be7b9aaf.my-topic-1359465312-1139365755
2022-04-05 17:16:14 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:16:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:16:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerMirrorMaker2Service
2022-04-05 17:16:14 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-cluster-be7b9aaf.my-topic-1359465312-1139365755 in namespace namespace-8
2022-04-05 17:16:14 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1359465312-1139365755 in namespace namespace-8
2022-04-05 17:16:14 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-be7b9aaf in namespace namespace-8
2022-04-05 17:16:14 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-be7b9aaf-hello-world-consumer in namespace namespace-8
2022-04-05 17:16:14 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-be7b9aaf-kafka-clients in namespace namespace-8
2022-04-05 17:16:14 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-be7b9aaf-target in namespace namespace-8
2022-04-05 17:16:14 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-be7b9aaf-hello-world-producer in namespace namespace-8
2022-04-05 17:16:14 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-be7b9aaf in namespace namespace-8
2022-04-05 17:16:14 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 delete -f -
2022-04-05 17:16:14 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-05 17:16:14 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:17:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 17:17:04 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-8 for test case:testProducerConsumerMirrorMaker2Service
2022-04-05 17:17:11 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerMirrorMaker2Service-FINISHED
2022-04-05 17:17:11 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 17:17:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:17:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for TracingST
2022-04-05 17:17:11 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy jaeger-allow in namespace tracing-st
2022-04-05 17:17:11 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-05 17:17:11 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [Exec:417] Input: ---
apiVersion: "v1"
kind: "ServiceAccount"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
2022-04-05 17:17:11 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:17:11 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-05 17:17:11 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [Exec:417] Input: ---
apiVersion: "rbac.authorization.k8s.io/v1"
kind: "Role"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
rules:
- apiGroups:
  - "jaegertracing.io"
  resources:
  - "*"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resourceNames:
  - "jaeger-operator"
  resources:
  - "deployments/finalizers"
  verbs:
  - "update"
- apiGroups:
  - ""
  resources:
  - "configmaps"
  - "persistentvolumeclaims"
  - "pods"
  - "secrets"
  - "serviceaccounts"
  - "services"
  - "services/finalizers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  - "daemonsets"
  - "replicasets"
  - "statefulsets"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "extensions"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "networking.k8s.io"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "batch"
  resources:
  - "jobs"
  - "cronjobs"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "route.openshift.io"
  resources:
  - "routes"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "image.openshift.io"
  resources:
  - "imagestreams"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "autoscaling"
  resources:
  - "horizontalpodautoscalers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "monitoring.coreos.com"
  resources:
  - "servicemonitors"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "logging.openshift.io"
  resources:
  - "elasticsearches"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "kafka.strimzi.io"
  resources:
  - "kafkas"
  - "kafkausers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
2022-04-05 17:17:11 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:17:11 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-05 17:17:11 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [Exec:417] Input: ---
kind: "RoleBinding"
apiVersion: "rbac.authorization.k8s.io/v1"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
subjects:
- kind: "ServiceAccount"
  name: "jaeger-operator"
roleRef:
  kind: "Role"
  name: "jaeger-operator"
  apiGroup: "rbac.authorization.k8s.io"
2022-04-05 17:17:11 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:17:11 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-05 17:17:11 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [Exec:417] Input: ---
apiVersion: "apps/v1"
kind: "Deployment"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
spec:
  replicas: 1
  selector:
    matchLabels:
      name: "jaeger-operator"
  template:
    metadata:
      labels:
        name: "jaeger-operator"
    spec:
      serviceAccountName: "jaeger-operator"
      containers:
      - name: "jaeger-operator"
        image: "jaegertracing/jaeger-operator:1.20.0"
        ports:
        - containerPort: 8383
          name: "http-metrics"
        - containerPort: 8686
          name: "cr-metrics"
        args:
        - "start"
        - "--kafka-provision=no"
        imagePullPolicy: "Always"
        env:
        - name: "WATCH_NAMESPACE"
          value: ""
        - name: "POD_NAME"
          valueFrom:
            fieldRef:
              fieldPath: "metadata.name"
        - name: "POD_NAMESPACE"
          valueFrom:
            fieldRef:
              fieldPath: "metadata.namespace"
        - name: "OPERATOR_NAME"
          value: "jaeger-operator"
2022-04-05 17:17:11 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:17:12 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-05 17:17:12 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:17:12 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-05 17:17:12 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [Exec:417] Input: ---
apiVersion: "rbac.authorization.k8s.io/v1"
kind: "ClusterRole"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
rules:
- apiGroups:
  - "jaegertracing.io"
  resources:
  - "*"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resourceNames:
  - "jaeger-operator"
  resources:
  - "deployments/finalizers"
  verbs:
  - "update"
- apiGroups:
  - ""
  resources:
  - "configmaps"
  - "persistentvolumeclaims"
  - "pods"
  - "secrets"
  - "serviceaccounts"
  - "services"
  - "services/finalizers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  - "daemonsets"
  - "replicasets"
  - "statefulsets"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "extensions"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "networking.k8s.io"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "batch"
  resources:
  - "jobs"
  - "cronjobs"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "route.openshift.io"
  resources:
  - "routes"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "console.openshift.io"
  resources:
  - "consolelinks"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "autoscaling"
  resources:
  - "horizontalpodautoscalers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "monitoring.coreos.com"
  resources:
  - "servicemonitors"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "logging.openshift.io"
  resources:
  - "elasticsearches"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "kafka.strimzi.io"
  resources:
  - "kafkas"
  - "kafkausers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - ""
  resources:
  - "namespaces"
  verbs:
  - "get"
  - "list"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  verbs:
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "rbac.authorization.k8s.io"
  resources:
  - "clusterrolebindings"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
2022-04-05 17:17:12 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:17:12 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-05 17:17:12 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [Exec:417] Input: ---
kind: "ClusterRoleBinding"
apiVersion: "rbac.authorization.k8s.io/v1"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
subjects:
- kind: "ServiceAccount"
  name: "jaeger-operator"
  namespace: "tracing-st"
roleRef:
  kind: "ClusterRole"
  name: "jaeger-operator"
  apiGroup: "rbac.authorization.k8s.io"
2022-04-05 17:17:12 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:17:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,305.06 s - in io.strimzi.systemtest.tracing.TracingST
[[1;34mINFO[m] Running io.strimzi.systemtest.cruisecontrol.CruiseControlApiST
2022-04-05 17:17:33 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: cruise-control-api-st
2022-04-05 17:17:33 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: cruise-control-api-st
2022-04-05 17:17:33 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: cruise-control-api-st
2022-04-05 17:17:33 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 17:17:33 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlApiST.testCruiseControlBasicAPIRequests-STARTED
2022-04-05 17:17:33 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 17:17:33 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-9 for test case:testCruiseControlBasicAPIRequests
2022-04-05 17:17:33 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-9
2022-04-05 17:17:33 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-9
2022-04-05 17:17:33 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-9
2022-04-05 17:17:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-df3260ce in namespace namespace-9
2022-04-05 17:17:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-9
2022-04-05 17:17:33 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-df3260ce will have desired state: Ready
2022-04-05 17:19:16 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-df3260ce is in desired state: Ready
2022-04-05 17:19:16 [main] [32mINFO [m [CruiseControlApiST:48] ----> CRUISE CONTROL DEPLOYMENT STATE ENDPOINT <----
2022-04-05 17:19:16 [main] [32mINFO [m [CruiseControlApiST:58] Verifying that Cruise Control REST API is available
2022-04-05 17:20:38 [main] [32mINFO [m [CruiseControlApiST:66] ----> KAFKA REBALANCE <----
2022-04-05 17:20:38 [main] [32mINFO [m [CruiseControlApiST:73] Waiting for CC will have for enough metrics to be recorded to make a proposal 
2022-04-05 17:21:05 [main] [32mINFO [m [CruiseControlApiST:97] ----> EXECUTION OF STOP PROPOSAL <----
2022-04-05 17:21:05 [main] [32mINFO [m [CruiseControlApiST:108] ----> USER TASKS <----
2022-04-05 17:21:06 [main] [32mINFO [m [CruiseControlApiST:126] Verifying that Cruise Control REST API doesn't allow HTTP requests
2022-04-05 17:21:06 [main] [32mINFO [m [CruiseControlApiST:132] Verifying that Cruise Control REST API doesn't allow unauthenticated requests
2022-04-05 17:21:06 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:21:06 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlBasicAPIRequests
2022-04-05 17:21:06 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-df3260ce in namespace namespace-9
2022-04-05 17:21:06 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-9, for cruise control Kafka cluster my-cluster-df3260ce
2022-04-05 17:21:16 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 17:21:16 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-9 for test case:testCruiseControlBasicAPIRequests
2022-04-05 17:21:59 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlApiST.testCruiseControlBasicAPIRequests-FINISHED
2022-04-05 17:21:59 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 17:21:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 17:21:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlApiST.testCruiseControlBasicAPIRequestsWithSecurityDisabled-STARTED
2022-04-05 17:21:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 17:21:59 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-10 for test case:testCruiseControlBasicAPIRequestsWithSecurityDisabled
2022-04-05 17:21:59 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-10
2022-04-05 17:21:59 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-10
2022-04-05 17:21:59 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-10
2022-04-05 17:21:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka cruise-control-api-cluster-name in namespace namespace-10
2022-04-05 17:21:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-10
2022-04-05 17:21:59 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: cruise-control-api-cluster-name will have desired state: Ready
2022-04-05 17:23:32 [main] [32mINFO [m [ResourceManager:444] Kafka: cruise-control-api-cluster-name is in desired state: Ready
2022-04-05 17:23:32 [main] [32mINFO [m [CruiseControlApiST:153] ----> CRUISE CONTROL DEPLOYMENT STATE ENDPOINT <----
2022-04-05 17:23:32 [main] [32mINFO [m [CruiseControlApiST:157] Verifying that Cruise Control REST API is available using HTTP request without credentials
2022-04-05 17:23:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:23:32 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlBasicAPIRequestsWithSecurityDisabled
2022-04-05 17:23:32 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka cruise-control-api-cluster-name in namespace namespace-10
2022-04-05 17:23:32 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-10, for cruise control Kafka cluster cruise-control-api-cluster-name
2022-04-05 17:23:42 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 17:23:42 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-10 for test case:testCruiseControlBasicAPIRequestsWithSecurityDisabled
2022-04-05 17:24:25 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlApiST.testCruiseControlBasicAPIRequestsWithSecurityDisabled-FINISHED
2022-04-05 17:24:25 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 17:24:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:24:25 [main] [32mINFO [m [ResourceManager:346] In context CruiseControlApiST is everything deleted.
2022-04-05 17:24:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 417.252 s - in io.strimzi.systemtest.cruisecontrol.CruiseControlApiST
[[1;34mINFO[m] Running io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST
2022-04-05 17:24:31 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: cruise-control-configuration-st
2022-04-05 17:24:31 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: cruise-control-configuration-st
2022-04-05 17:24:31 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: cruise-control-configuration-st
2022-04-05 17:24:31 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 17:24:31 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationFileIsCreated-STARTED
2022-04-05 17:24:31 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 17:24:31 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-11 for test case:testConfigurationFileIsCreated
2022-04-05 17:24:31 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-11
2022-04-05 17:24:31 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-11
2022-04-05 17:24:31 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-11
2022-04-05 17:24:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-202f75e6 in namespace namespace-11
2022-04-05 17:24:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-11
2022-04-05 17:24:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-202f75e6 will have desired state: Ready
2022-04-05 17:25:59 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-202f75e6 is in desired state: Ready
2022-04-05 17:25:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-11 exec my-cluster-202f75e6-cruise-control-84789f78bc-7c8fb -- /bin/bash -c cat /tmp/cruisecontrol.properties
2022-04-05 17:25:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:25:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:25:59 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigurationFileIsCreated
2022-04-05 17:25:59 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-202f75e6 in namespace namespace-11
2022-04-05 17:25:59 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-11, for cruise control Kafka cluster my-cluster-202f75e6
2022-04-05 17:26:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 17:26:09 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-11 for test case:testConfigurationFileIsCreated
2022-04-05 17:26:53 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationFileIsCreated-FINISHED
2022-04-05 17:26:53 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 17:26:53 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 17:26:53 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testDeployAndUnDeployCruiseControl-STARTED
2022-04-05 17:26:53 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 17:26:53 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-12 for test case:testDeployAndUnDeployCruiseControl
2022-04-05 17:26:53 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-12
2022-04-05 17:26:53 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-12
2022-04-05 17:26:53 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-12
2022-04-05 17:26:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ad2b9125 in namespace namespace-12
2022-04-05 17:26:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-12
2022-04-05 17:26:53 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ad2b9125 will have desired state: Ready
2022-04-05 17:28:35 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ad2b9125 is in desired state: Ready
2022-04-05 17:28:35 [main] [32mINFO [m [CruiseControlConfigurationST:111] Removing Cruise Control to the classic Kafka.
2022-04-05 17:28:35 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-ad2b9125-kafka rolling update
2022-04-05 17:29:55 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-ad2b9125-kafka has been successfully rolled
2022-04-05 17:29:55 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-ad2b9125-kafka to be ready
2022-04-05 17:30:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ad2b9125 will have desired state: Ready
2022-04-05 17:30:26 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ad2b9125 is in desired state: Ready
2022-04-05 17:30:26 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-ad2b9125 is ready
2022-04-05 17:30:26 [main] [32mINFO [m [CruiseControlConfigurationST:117] Verifying that in Cruise Control is not present in the Kafka cluster
2022-04-05 17:30:26 [main] [32mINFO [m [CruiseControlConfigurationST:120] Verifying that my-cluster-ad2b9125-cruise-control- pod is not present
2022-04-05 17:30:26 [main] [32mINFO [m [PodUtils:209] Wait until Pod my-cluster-ad2b9125-cruise-control- will have stable 0 replicas
2022-04-05 17:30:26 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 19 polls
2022-04-05 17:30:27 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 18 polls
2022-04-05 17:30:28 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 17 polls
2022-04-05 17:30:29 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 16 polls
2022-04-05 17:30:30 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 15 polls
2022-04-05 17:30:31 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 14 polls
2022-04-05 17:30:32 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 13 polls
2022-04-05 17:30:33 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 12 polls
2022-04-05 17:30:34 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 11 polls
2022-04-05 17:30:35 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 10 polls
2022-04-05 17:30:36 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 9 polls
2022-04-05 17:30:37 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 8 polls
2022-04-05 17:30:38 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 7 polls
2022-04-05 17:30:39 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 6 polls
2022-04-05 17:30:40 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 5 polls
2022-04-05 17:30:41 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 4 polls
2022-04-05 17:30:42 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 3 polls
2022-04-05 17:30:43 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 2 polls
2022-04-05 17:30:44 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 1 polls
2022-04-05 17:30:45 [main] [32mINFO [m [PodUtils:217] Pod replicas are stable for 20 polls intervals
2022-04-05 17:30:45 [main] [32mINFO [m [PodUtils:228] Pod my-cluster-ad2b9125-cruise-control- has 0 replicas
2022-04-05 17:30:45 [main] [32mINFO [m [CruiseControlConfigurationST:123] Verifying that in Kafka config map there is no configuration to cruise control metric reporter
2022-04-05 17:32:45 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Verify that kafka configuration {cluster-name=my-cluster-ad2b9125} has correct cruise control metric reporter properties, null
io.strimzi.test.WaitException: Timeout after 120000 ms waiting for Verify that kafka configuration {cluster-name=my-cluster-ad2b9125} has correct cruise control metric reporter properties
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.specific.CruiseControlUtils.verifyCruiseControlMetricReporterConfigurationInKafkaConfigMapIsPresent(CruiseControlUtils.java:83)
	at io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.lambda$testDeployAndUnDeployCruiseControl$1(CruiseControlConfigurationST.java:124)
	at org.junit.jupiter.api.AssertThrows.assertThrows(AssertThrows.java:55)
	at org.junit.jupiter.api.AssertThrows.assertThrows(AssertThrows.java:37)
	at org.junit.jupiter.api.Assertions.assertThrows(Assertions.java:3082)
	at io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testDeployAndUnDeployCruiseControl(CruiseControlConfigurationST.java:124)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-05 17:32:45 [main] [32mINFO [m [CruiseControlConfigurationST:126] Cruise Control topics will not be deleted and will stay in the Kafka cluster
2022-04-05 17:32:45 [main] [32mINFO [m [CruiseControlConfigurationST:130] Adding Cruise Control to the classic Kafka.
2022-04-05 17:32:45 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-ad2b9125-kafka rolling update
2022-04-05 17:33:46 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-ad2b9125-kafka has been successfully rolled
2022-04-05 17:33:46 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-ad2b9125-kafka to be ready
2022-04-05 17:34:17 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ad2b9125 will have desired state: Ready
2022-04-05 17:34:17 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ad2b9125 is in desired state: Ready
2022-04-05 17:34:17 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-ad2b9125 is ready
2022-04-05 17:34:17 [main] [32mINFO [m [CruiseControlConfigurationST:136] Verifying that in Kafka config map there is configuration to cruise control metric reporter
2022-04-05 17:34:17 [main] [32mINFO [m [CruiseControlConfigurationST:139] Verifying that Cruise Control topics are created after CC is instantiated.
2022-04-05 17:34:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:34:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeployAndUnDeployCruiseControl
2022-04-05 17:34:17 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ad2b9125 in namespace namespace-12
2022-04-05 17:34:17 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-12, for cruise control Kafka cluster my-cluster-ad2b9125
2022-04-05 17:34:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 17:34:27 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-12 for test case:testDeployAndUnDeployCruiseControl
2022-04-05 17:35:10 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testDeployAndUnDeployCruiseControl-FINISHED
2022-04-05 17:35:10 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 17:35:10 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 17:35:10 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationPerformanceOptions-STARTED
2022-04-05 17:35:10 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 17:35:10 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-13 for test case:testConfigurationPerformanceOptions
2022-04-05 17:35:10 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-13
2022-04-05 17:35:10 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-13
2022-04-05 17:35:10 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-13
2022-04-05 17:35:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c323131a in namespace namespace-13
2022-04-05 17:35:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-13
2022-04-05 17:35:10 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c323131a will have desired state: Ready
2022-04-05 17:36:49 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c323131a is in desired state: Ready
2022-04-05 17:36:49 [main] [32mINFO [m [CruiseControlConfigurationST:271] Changing cruise control performance tuning options
2022-04-05 17:36:49 [main] [32mINFO [m [CruiseControlConfigurationST:277] Verifying that CC pod is rolling, after changing options
2022-04-05 17:36:49 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-c323131a-cruise-control rolling update
2022-04-05 17:37:25 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c323131a-cruise-control will be ready
2022-04-05 17:37:25 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c323131a-cruise-control is ready
2022-04-05 17:37:35 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-c323131a-cruise-control rolling update finished
2022-04-05 17:37:35 [main] [32mINFO [m [CruiseControlConfigurationST:280] Verifying that Kafka pods did not roll
2022-04-05 17:37:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 50
2022-04-05 17:37:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 49
2022-04-05 17:37:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 48
2022-04-05 17:37:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 47
2022-04-05 17:37:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 46
2022-04-05 17:37:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 45
2022-04-05 17:37:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 44
2022-04-05 17:37:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 43
2022-04-05 17:37:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 42
2022-04-05 17:37:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 41
2022-04-05 17:37:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 40
2022-04-05 17:37:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 39
2022-04-05 17:37:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 38
2022-04-05 17:37:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 37
2022-04-05 17:37:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 36
2022-04-05 17:37:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 35
2022-04-05 17:37:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 34
2022-04-05 17:37:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 33
2022-04-05 17:37:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 32
2022-04-05 17:37:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 31
2022-04-05 17:37:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 30
2022-04-05 17:37:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 29
2022-04-05 17:37:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 28
2022-04-05 17:37:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 27
2022-04-05 17:37:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 26
2022-04-05 17:38:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 25
2022-04-05 17:38:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 24
2022-04-05 17:38:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 23
2022-04-05 17:38:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 22
2022-04-05 17:38:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 21
2022-04-05 17:38:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 20
2022-04-05 17:38:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 19
2022-04-05 17:38:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 18
2022-04-05 17:38:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 17
2022-04-05 17:38:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 16
2022-04-05 17:38:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 15
2022-04-05 17:38:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 14
2022-04-05 17:38:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 13
2022-04-05 17:38:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 12
2022-04-05 17:38:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 11
2022-04-05 17:38:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 10
2022-04-05 17:38:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 9
2022-04-05 17:38:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 8
2022-04-05 17:38:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 7
2022-04-05 17:38:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 6
2022-04-05 17:38:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 5
2022-04-05 17:38:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 4
2022-04-05 17:38:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 3
2022-04-05 17:38:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 2
2022-04-05 17:38:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 1
2022-04-05 17:38:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-c323131a-kafka-0=69549eaa-55e5-4e46-8099-2f671b94a224, my-cluster-c323131a-kafka-1=1a104caa-0520-4f38-a845-d4bd7ae54aeb, my-cluster-c323131a-kafka-2=73de48e8-4526-4b65-b6f5-293bc6c762bd} pods didn't roll. Remaining seconds for stability: 0
2022-04-05 17:38:25 [main] [32mINFO [m [CruiseControlConfigurationST:283] Verifying new configuration in the Kafka CR
2022-04-05 17:38:25 [main] [32mINFO [m [CruiseControlConfigurationST:300] Verifying Cruise control performance options are set in Kafka CR
2022-04-05 17:38:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:38:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigurationPerformanceOptions
2022-04-05 17:38:25 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c323131a in namespace namespace-13
2022-04-05 17:38:25 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-13, for cruise control Kafka cluster my-cluster-c323131a
2022-04-05 17:38:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 17:38:35 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-13 for test case:testConfigurationPerformanceOptions
2022-04-05 17:39:18 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationPerformanceOptions-FINISHED
2022-04-05 17:39:18 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 17:39:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 17:39:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationReflection-STARTED
2022-04-05 17:39:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 17:39:18 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-14 for test case:testConfigurationReflection
2022-04-05 17:39:18 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-14
2022-04-05 17:39:18 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-14
2022-04-05 17:39:18 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-14
2022-04-05 17:39:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3af32fe8 in namespace namespace-14
2022-04-05 17:39:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-14
2022-04-05 17:39:18 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3af32fe8 will have desired state: Ready
2022-04-05 17:40:53 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3af32fe8 is in desired state: Ready
2022-04-05 17:40:53 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-14 exec my-cluster-3af32fe8-cruise-control-7bcd58579d-xs9gt -- /bin/bash -c cat /tmp/cruisecontrol.properties
2022-04-05 17:40:53 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:40:53 [main] [32mINFO [m [CruiseControlConfigurationST:221] Verifying that all configuration in the cruise control container matching the cruise control file /tmp/cruisecontrol.properties properties
2022-04-05 17:40:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:40:53 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigurationReflection
2022-04-05 17:40:53 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3af32fe8 in namespace namespace-14
2022-04-05 17:40:53 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-14, for cruise control Kafka cluster my-cluster-3af32fe8
2022-04-05 17:41:03 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 17:41:03 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-14 for test case:testConfigurationReflection
2022-04-05 17:41:46 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationReflection-FINISHED
2022-04-05 17:41:46 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 17:41:46 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 17:41:46 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationDiskChangeDoNotTriggersRollingUpdateOfKafkaPods-STARTED
2022-04-05 17:41:46 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 17:41:46 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-15 for test case:testConfigurationDiskChangeDoNotTriggersRollingUpdateOfKafkaPods
2022-04-05 17:41:46 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-15
2022-04-05 17:41:46 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-15
2022-04-05 17:41:46 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-15
2022-04-05 17:41:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-6b9c423f in namespace namespace-15
2022-04-05 17:41:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-15
2022-04-05 17:41:46 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-6b9c423f will have desired state: Ready
2022-04-05 17:43:29 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-6b9c423f is in desired state: Ready
2022-04-05 17:43:29 [main] [32mINFO [m [CruiseControlConfigurationST:157] Changing the broker capacity of the cruise control
2022-04-05 17:43:29 [main] [32mINFO [m [CruiseControlConfigurationST:168] Verifying that CC pod is rolling, because of change size of disk
2022-04-05 17:43:29 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-6b9c423f-cruise-control rolling update
2022-04-05 17:44:05 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-6b9c423f-cruise-control will be ready
2022-04-05 17:44:05 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-6b9c423f-cruise-control is ready
2022-04-05 17:44:15 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-6b9c423f-cruise-control rolling update finished
2022-04-05 17:44:15 [main] [32mINFO [m [CruiseControlConfigurationST:171] Verifying that Kafka pods did not roll
2022-04-05 17:44:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 50
2022-04-05 17:44:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 49
2022-04-05 17:44:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 48
2022-04-05 17:44:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 47
2022-04-05 17:44:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 46
2022-04-05 17:44:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 45
2022-04-05 17:44:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 44
2022-04-05 17:44:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 43
2022-04-05 17:44:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 42
2022-04-05 17:44:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 41
2022-04-05 17:44:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 40
2022-04-05 17:44:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 39
2022-04-05 17:44:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 38
2022-04-05 17:44:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 37
2022-04-05 17:44:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 36
2022-04-05 17:44:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 35
2022-04-05 17:44:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 34
2022-04-05 17:44:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 33
2022-04-05 17:44:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 32
2022-04-05 17:44:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 31
2022-04-05 17:44:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 30
2022-04-05 17:44:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 29
2022-04-05 17:44:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 28
2022-04-05 17:44:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 27
2022-04-05 17:44:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 26
2022-04-05 17:44:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 25
2022-04-05 17:44:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 24
2022-04-05 17:44:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 23
2022-04-05 17:44:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 22
2022-04-05 17:44:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 21
2022-04-05 17:44:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 20
2022-04-05 17:44:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 19
2022-04-05 17:44:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 18
2022-04-05 17:44:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 17
2022-04-05 17:44:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 16
2022-04-05 17:44:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 15
2022-04-05 17:44:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 14
2022-04-05 17:44:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 13
2022-04-05 17:44:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 12
2022-04-05 17:44:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 11
2022-04-05 17:44:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 10
2022-04-05 17:44:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 9
2022-04-05 17:44:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 8
2022-04-05 17:44:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 7
2022-04-05 17:44:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 6
2022-04-05 17:45:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 5
2022-04-05 17:45:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 4
2022-04-05 17:45:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 3
2022-04-05 17:45:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 2
2022-04-05 17:45:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 1
2022-04-05 17:45:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-6b9c423f-kafka-0=f9185c7d-5ded-4ea8-9c10-fb1b9ccde88b, my-cluster-6b9c423f-kafka-1=bf5300b7-a858-4a86-9bd4-f1ffc5b86deb, my-cluster-6b9c423f-kafka-2=53dacde6-4351-4a13-8778-e8d644b01ac8} pods didn't roll. Remaining seconds for stability: 0
2022-04-05 17:45:05 [main] [32mINFO [m [CruiseControlConfigurationST:174] Verifying new configuration in the Kafka CR
2022-04-05 17:45:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:45:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigurationDiskChangeDoNotTriggersRollingUpdateOfKafkaPods
2022-04-05 17:45:05 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-6b9c423f in namespace namespace-15
2022-04-05 17:45:05 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-15, for cruise control Kafka cluster my-cluster-6b9c423f
2022-04-05 17:45:15 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 17:45:15 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-15 for test case:testConfigurationDiskChangeDoNotTriggersRollingUpdateOfKafkaPods
2022-04-05 17:45:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationDiskChangeDoNotTriggersRollingUpdateOfKafkaPods-FINISHED
2022-04-05 17:45:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 17:45:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 17:45:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testCapacityFile-STARTED
2022-04-05 17:45:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 17:45:58 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-16 for test case:testCapacityFile
2022-04-05 17:45:58 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-16
2022-04-05 17:45:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-16
2022-04-05 17:45:58 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-16
2022-04-05 17:45:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-fb0d3150 in namespace namespace-16
2022-04-05 17:45:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-16
2022-04-05 17:45:58 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-fb0d3150 will have desired state: Ready
2022-04-05 17:47:38 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-fb0d3150 is in desired state: Ready
2022-04-05 17:47:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-16 exec my-cluster-fb0d3150-cruise-control-77fb879889-62b4l -- /bin/bash -c cat /tmp/capacity.json
2022-04-05 17:47:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:47:38 [main] [32mINFO [m [CruiseControlConfigurationST:80] We got only one configuration of broker-capacities
2022-04-05 17:47:38 [main] [32mINFO [m [CruiseControlConfigurationST:83] Verifying cruise control configuration.
2022-04-05 17:47:38 [main] [32mINFO [m [CruiseControlConfigurationST:92] Verifying default cruise control capacities
2022-04-05 17:47:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:47:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCapacityFile
2022-04-05 17:47:38 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-fb0d3150 in namespace namespace-16
2022-04-05 17:47:38 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-16, for cruise control Kafka cluster my-cluster-fb0d3150
2022-04-05 17:47:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 17:47:48 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-16 for test case:testCapacityFile
2022-04-05 17:48:31 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testCapacityFile-FINISHED
2022-04-05 17:48:31 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 17:48:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:48:31 [main] [32mINFO [m [ResourceManager:346] In context CruiseControlConfigurationST is everything deleted.
2022-04-05 17:48:31 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,446.073 s - in io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST
[[1;34mINFO[m] Running io.strimzi.systemtest.cruisecontrol.CruiseControlST
2022-04-05 17:48:37 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: cruise-control-st
2022-04-05 17:48:37 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: cruise-control-st
2022-04-05 17:48:37 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: cruise-control-st
2022-04-05 17:48:37 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 17:48:37 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlTopicExclusion-STARTED
2022-04-05 17:48:37 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 17:48:37 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-17 for test case:testCruiseControlTopicExclusion
2022-04-05 17:48:37 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-17
2022-04-05 17:48:37 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-17
2022-04-05 17:48:37 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-17
2022-04-05 17:48:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-52a6fcc8 in namespace namespace-17
2022-04-05 17:48:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-17
2022-04-05 17:48:37 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-52a6fcc8 will have desired state: Ready
2022-04-05 17:50:20 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-52a6fcc8 is in desired state: Ready
2022-04-05 17:50:20 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic excluded-topic-1 in namespace namespace-17
2022-04-05 17:50:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-17
2022-04-05 17:50:20 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: excluded-topic-1 will have desired state: Ready
2022-04-05 17:50:21 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: excluded-topic-1 is in desired state: Ready
2022-04-05 17:50:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic excluded-topic-2 in namespace namespace-17
2022-04-05 17:50:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-17
2022-04-05 17:50:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: excluded-topic-2 will have desired state: Ready
2022-04-05 17:50:22 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: excluded-topic-2 is in desired state: Ready
2022-04-05 17:50:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic included-topic in namespace namespace-17
2022-04-05 17:50:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-17
2022-04-05 17:50:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: included-topic will have desired state: Ready
2022-04-05 17:50:23 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: included-topic is in desired state: Ready
2022-04-05 17:50:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-52a6fcc8 in namespace namespace-17
2022-04-05 17:50:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-17
2022-04-05 17:50:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-52a6fcc8 will have desired state: PendingProposal
2022-04-05 17:50:24 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-52a6fcc8 is in desired state: PendingProposal
2022-04-05 17:50:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-52a6fcc8 will have desired state: ProposalReady
2022-04-05 17:56:14 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-52a6fcc8 is in desired state: ProposalReady
2022-04-05 17:56:14 [main] [32mINFO [m [CruiseControlST:208] Checking status of KafkaRebalance
2022-04-05 17:56:14 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #4(test) KafkaRebalance(cruise-control-st/my-cluster-52a6fcc8): Annotating KafkaRebalance:my-cluster-52a6fcc8 with annotation approve
2022-04-05 17:56:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-52a6fcc8 will have desired state: Ready
2022-04-05 17:56:50 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-52a6fcc8 is in desired state: Ready
2022-04-05 17:56:50 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:56:50 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlTopicExclusion
2022-04-05 17:56:50 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic excluded-topic-2 in namespace namespace-17
2022-04-05 17:56:50 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic included-topic in namespace namespace-17
2022-04-05 17:56:50 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic excluded-topic-1 in namespace namespace-17
2022-04-05 17:56:50 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-52a6fcc8 in namespace namespace-17
2022-04-05 17:56:50 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-17, for cruise control Kafka cluster my-cluster-52a6fcc8
2022-04-05 17:56:50 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-52a6fcc8 in namespace namespace-17
2022-04-05 17:57:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 17:57:01 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-17 for test case:testCruiseControlTopicExclusion
2022-04-05 17:57:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlTopicExclusion-FINISHED
2022-04-05 17:57:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 17:57:34 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 17:57:34 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlIntraBrokerBalancingWithoutSpecifyingJBODStorage-STARTED
2022-04-05 17:57:34 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 17:57:34 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-18 for test case:testCruiseControlIntraBrokerBalancingWithoutSpecifyingJBODStorage
2022-04-05 17:57:34 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-18
2022-04-05 17:57:34 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-18
2022-04-05 17:57:34 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-18
2022-04-05 17:57:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3c9bee10 in namespace namespace-18
2022-04-05 17:57:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-18
2022-04-05 17:57:34 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3c9bee10 will have desired state: Ready
2022-04-05 17:59:10 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3c9bee10 is in desired state: Ready
2022-04-05 17:59:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-3c9bee10 in namespace namespace-18
2022-04-05 17:59:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-18
2022-04-05 17:59:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-3c9bee10 will have desired state: NotReady
2022-04-05 17:59:11 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-3c9bee10 is in desired state: NotReady
2022-04-05 17:59:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:59:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlIntraBrokerBalancingWithoutSpecifyingJBODStorage
2022-04-05 17:59:11 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-3c9bee10 in namespace namespace-18
2022-04-05 17:59:11 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3c9bee10 in namespace namespace-18
2022-04-05 17:59:11 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-18, for cruise control Kafka cluster my-cluster-3c9bee10
2022-04-05 17:59:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 17:59:21 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-18 for test case:testCruiseControlIntraBrokerBalancingWithoutSpecifyingJBODStorage
2022-04-05 18:00:05 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlIntraBrokerBalancingWithoutSpecifyingJBODStorage-FINISHED
2022-04-05 18:00:05 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:00:05 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:00:05 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testAutoCreationOfCruiseControlTopics-STARTED
2022-04-05 18:00:05 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:00:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b3e4cfff in namespace cruise-control-st
2022-04-05 18:00:05 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b3e4cfff will have desired state: Ready
2022-04-05 18:01:51 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b3e4cfff is in desired state: Ready
2022-04-05 18:01:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: strimzi.cruisecontrol.metrics will have desired state: Ready
2022-04-05 18:01:51 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: strimzi.cruisecontrol.metrics is in desired state: Ready
2022-04-05 18:01:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: strimzi.cruisecontrol.modeltrainingsamples will have desired state: Ready
2022-04-05 18:01:51 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: strimzi.cruisecontrol.modeltrainingsamples is in desired state: Ready
2022-04-05 18:01:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: strimzi.cruisecontrol.partitionmetricsamples will have desired state: Ready
2022-04-05 18:03:12 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: strimzi.cruisecontrol.partitionmetricsamples is in desired state: Ready
2022-04-05 18:03:12 [main] [32mINFO [m [CruiseControlST:96] Checking partitions and replicas for strimzi.cruisecontrol.metrics
2022-04-05 18:03:12 [main] [32mINFO [m [CruiseControlST:100] Checking partitions and replicas for strimzi.cruisecontrol.modeltrainingsamples
2022-04-05 18:03:12 [main] [32mINFO [m [CruiseControlST:104] Checking partitions and replicas for strimzi.cruisecontrol.partitionmetricsamples
2022-04-05 18:03:12 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:03:12 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoCreationOfCruiseControlTopics
2022-04-05 18:03:12 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b3e4cfff in namespace cruise-control-st
2022-04-05 18:03:12 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace cruise-control-st, for cruise control Kafka cluster my-cluster-b3e4cfff
2022-04-05 18:03:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:03:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testAutoCreationOfCruiseControlTopics-FINISHED
2022-04-05 18:03:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:03:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:03:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlReplicaMovementStrategy-STARTED
2022-04-05 18:03:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:03:22 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-19 for test case:testCruiseControlReplicaMovementStrategy
2022-04-05 18:03:22 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-19
2022-04-05 18:03:22 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-19
2022-04-05 18:03:22 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-19
2022-04-05 18:03:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-52f6b456 in namespace namespace-19
2022-04-05 18:03:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-19
2022-04-05 18:03:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-52f6b456 will have desired state: Ready
2022-04-05 18:06:02 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-52f6b456 is in desired state: Ready
2022-04-05 18:06:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-52f6b456-kafka-clients in namespace namespace-19
2022-04-05 18:06:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-19
2022-04-05 18:06:02 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-52f6b456-kafka-clients will be ready
2022-04-05 18:06:04 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-52f6b456-kafka-clients is ready
2022-04-05 18:06:04 [main] [32mINFO [m [CruiseControlST:234] Check for default CruiseControl replicaMovementStrategy in pod configuration file.
2022-04-05 18:06:04 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-19 exec my-cluster-52f6b456-cruise-control-794c84549-7zrr8 -c cruise-control -- cat /tmp/cruisecontrol.properties
2022-04-05 18:06:04 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 18:06:04 [main] [32mINFO [m [CruiseControlST:248] Set non-default CruiseControl replicaMovementStrategies to KafkaRebalance resource.
2022-04-05 18:06:04 [main] [32mINFO [m [CruiseControlST:252] Verifying that CC pod is rolling, because of change size of disk
2022-04-05 18:06:04 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-52f6b456-cruise-control rolling update
2022-04-05 18:06:44 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-52f6b456-cruise-control will be ready
2022-04-05 18:06:44 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-52f6b456-cruise-control is ready
2022-04-05 18:06:54 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-52f6b456-cruise-control rolling update finished
2022-04-05 18:06:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-19 exec my-cluster-52f6b456-cruise-control-7654d7b8b9-46dg7 -c cruise-control -- cat /tmp/cruisecontrol.properties
2022-04-05 18:06:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 18:06:55 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:06:55 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlReplicaMovementStrategy
2022-04-05 18:06:55 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-52f6b456-kafka-clients in namespace namespace-19
2022-04-05 18:06:55 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-52f6b456 in namespace namespace-19
2022-04-05 18:06:55 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-19, for cruise control Kafka cluster my-cluster-52f6b456
2022-04-05 18:07:45 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:07:45 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-19 for test case:testCruiseControlReplicaMovementStrategy
2022-04-05 18:07:50 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlReplicaMovementStrategy-FINISHED
2022-04-05 18:07:50 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:07:50 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:07:50 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithSingleNodeKafka-STARTED
2022-04-05 18:07:50 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:07:50 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-20 for test case:testCruiseControlWithSingleNodeKafka
2022-04-05 18:07:50 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-20
2022-04-05 18:07:50 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-20
2022-04-05 18:07:50 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-20
2022-04-05 18:07:50 [main] [32mINFO [m [CruiseControlST:169] Deploying single node Kafka with CruiseControl
2022-04-05 18:07:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ef8bd9fa in namespace namespace-20
2022-04-05 18:07:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-20
2022-04-05 18:07:53 [main] [32mINFO [m [CruiseControlST:178] Increasing Kafka nodes to 3
2022-04-05 18:07:53 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ef8bd9fa will have desired state: Ready
2022-04-05 18:09:15 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ef8bd9fa is in desired state: Ready
2022-04-05 18:09:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:09:15 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlWithSingleNodeKafka
2022-04-05 18:09:15 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ef8bd9fa in namespace namespace-20
2022-04-05 18:09:15 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-20, for cruise control Kafka cluster my-cluster-ef8bd9fa
2022-04-05 18:09:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:09:26 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-20 for test case:testCruiseControlWithSingleNodeKafka
2022-04-05 18:10:09 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithSingleNodeKafka-FINISHED
2022-04-05 18:10:09 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:10:09 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:10:09 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithRebalanceResourceAndRefreshAnnotation-STARTED
2022-04-05 18:10:09 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:10:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0e0036d1 in namespace cruise-control-st
2022-04-05 18:10:09 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0e0036d1 will have desired state: Ready
2022-04-05 18:11:48 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0e0036d1 is in desired state: Ready
2022-04-05 18:11:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-0e0036d1 in namespace cruise-control-st
2022-04-05 18:11:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-0e0036d1 will have desired state: PendingProposal
2022-04-05 18:11:49 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-0e0036d1 is in desired state: PendingProposal
2022-04-05 18:11:49 [main] [32mINFO [m [KafkaRebalanceUtils:75] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-0e0036d1): ============================================================================
2022-04-05 18:11:49 [main] [32mINFO [m [KafkaRebalanceUtils:76] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-0e0036d1): PendingProposal
2022-04-05 18:11:49 [main] [32mINFO [m [KafkaRebalanceUtils:77] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-0e0036d1): ============================================================================
2022-04-05 18:11:49 [main] [32mINFO [m [KafkaRebalanceUtils:81] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-0e0036d1): Verifying that KafkaRebalance resource is in PendingProposal state
2022-04-05 18:11:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-0e0036d1 will have desired state: PendingProposal
2022-04-05 18:11:49 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-0e0036d1 is in desired state: PendingProposal
2022-04-05 18:11:49 [main] [32mINFO [m [KafkaRebalanceUtils:85] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-0e0036d1): Verifying that KafkaRebalance resource is in ProposalReady state
2022-04-05 18:11:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-0e0036d1 will have desired state: ProposalReady
2022-04-05 18:16:39 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-0e0036d1 is in desired state: ProposalReady
2022-04-05 18:16:39 [main] [32mINFO [m [KafkaRebalanceUtils:90] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-0e0036d1): ============================================================================
2022-04-05 18:16:39 [main] [32mINFO [m [KafkaRebalanceUtils:91] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-0e0036d1): ProposalReady
2022-04-05 18:16:39 [main] [32mINFO [m [KafkaRebalanceUtils:92] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-0e0036d1): ============================================================================
2022-04-05 18:16:39 [main] [32mINFO [m [KafkaRebalanceUtils:94] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-0e0036d1): Triggering the rebalance with annotation strimzi.io/rebalance=approve of KafkaRebalance resource
2022-04-05 18:16:39 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-0e0036d1): Annotating KafkaRebalance:my-cluster-0e0036d1 with annotation approve
2022-04-05 18:16:39 [main] [32mINFO [m [KafkaRebalanceUtils:98] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-0e0036d1): Response from the annotation process kafkarebalance.kafka.strimzi.io/my-cluster-0e0036d1 annotated
2022-04-05 18:16:39 [main] [32mINFO [m [KafkaRebalanceUtils:100] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-0e0036d1): Verifying that annotation triggers the Rebalancing state
2022-04-05 18:16:39 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-0e0036d1 will have desired state: Rebalancing
2022-04-05 18:16:40 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-0e0036d1 is in desired state: Rebalancing
2022-04-05 18:16:40 [main] [32mINFO [m [KafkaRebalanceUtils:104] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-0e0036d1): Verifying that KafkaRebalance is in the Ready state
2022-04-05 18:16:40 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-0e0036d1 will have desired state: Ready
2022-04-05 18:17:45 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-0e0036d1 is in desired state: Ready
2022-04-05 18:17:45 [main] [32mINFO [m [CruiseControlST:152] Annotating KafkaRebalance: my-cluster-0e0036d1 with 'refresh' anno
2022-04-05 18:17:45 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #6(test) KafkaRebalance(cruise-control-st/my-cluster-0e0036d1): Annotating KafkaRebalance:my-cluster-0e0036d1 with annotation refresh
2022-04-05 18:17:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-0e0036d1 will have desired state: ProposalReady
2022-04-05 18:17:46 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-0e0036d1 is in desired state: ProposalReady
2022-04-05 18:17:46 [main] [32mINFO [m [CruiseControlST:156] Trying rebalancing process again
2022-04-05 18:17:46 [main] [32mINFO [m [KafkaRebalanceUtils:75] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-0e0036d1): ============================================================================
2022-04-05 18:17:46 [main] [32mINFO [m [KafkaRebalanceUtils:76] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-0e0036d1): ProposalReady
2022-04-05 18:17:46 [main] [32mINFO [m [KafkaRebalanceUtils:77] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-0e0036d1): ============================================================================
2022-04-05 18:17:46 [main] [32mINFO [m [KafkaRebalanceUtils:90] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-0e0036d1): ============================================================================
2022-04-05 18:17:46 [main] [32mINFO [m [KafkaRebalanceUtils:91] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-0e0036d1): ProposalReady
2022-04-05 18:17:46 [main] [32mINFO [m [KafkaRebalanceUtils:92] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-0e0036d1): ============================================================================
2022-04-05 18:17:46 [main] [32mINFO [m [KafkaRebalanceUtils:94] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-0e0036d1): Triggering the rebalance with annotation strimzi.io/rebalance=approve of KafkaRebalance resource
2022-04-05 18:17:46 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-0e0036d1): Annotating KafkaRebalance:my-cluster-0e0036d1 with annotation approve
2022-04-05 18:17:47 [main] [32mINFO [m [KafkaRebalanceUtils:98] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-0e0036d1): Response from the annotation process kafkarebalance.kafka.strimzi.io/my-cluster-0e0036d1 annotated
2022-04-05 18:17:47 [main] [32mINFO [m [KafkaRebalanceUtils:100] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-0e0036d1): Verifying that annotation triggers the Rebalancing state
2022-04-05 18:17:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-0e0036d1 will have desired state: Rebalancing
2022-04-05 18:17:48 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-0e0036d1 is in desired state: Rebalancing
2022-04-05 18:17:48 [main] [32mINFO [m [KafkaRebalanceUtils:104] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-0e0036d1): Verifying that KafkaRebalance is in the Ready state
2022-04-05 18:17:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-0e0036d1 will have desired state: Ready
2022-04-05 18:17:53 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-0e0036d1 is in desired state: Ready
2022-04-05 18:17:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:17:53 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlWithRebalanceResourceAndRefreshAnnotation
2022-04-05 18:17:53 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-0e0036d1 in namespace cruise-control-st
2022-04-05 18:17:53 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0e0036d1 in namespace cruise-control-st
2022-04-05 18:17:53 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace cruise-control-st, for cruise control Kafka cluster my-cluster-0e0036d1
2022-04-05 18:18:03 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:18:03 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithRebalanceResourceAndRefreshAnnotation-FINISHED
2022-04-05 18:18:03 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:18:03 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:18:03 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithApiSecurityDisabled-STARTED
2022-04-05 18:18:03 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:18:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-fb40a6b7 in namespace cruise-control-st
2022-04-05 18:18:03 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-fb40a6b7 will have desired state: Ready
2022-04-05 18:20:41 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-fb40a6b7 is in desired state: Ready
2022-04-05 18:20:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-fb40a6b7 in namespace cruise-control-st
2022-04-05 18:20:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-fb40a6b7 will have desired state: PendingProposal
2022-04-05 18:20:42 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-fb40a6b7 is in desired state: PendingProposal
2022-04-05 18:20:42 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-fb40a6b7 will have desired state: ProposalReady
2022-04-05 18:26:32 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-fb40a6b7 is in desired state: ProposalReady
2022-04-05 18:26:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:26:32 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlWithApiSecurityDisabled
2022-04-05 18:26:32 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-fb40a6b7 in namespace cruise-control-st
2022-04-05 18:26:32 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-fb40a6b7 in namespace cruise-control-st
2022-04-05 18:26:32 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace cruise-control-st, for cruise control Kafka cluster my-cluster-fb40a6b7
2022-04-05 18:26:42 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:26:42 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithApiSecurityDisabled-FINISHED
2022-04-05 18:26:42 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:26:42 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:26:42 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlIntraBrokerBalancing-STARTED
2022-04-05 18:26:42 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:26:42 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-21 for test case:testCruiseControlIntraBrokerBalancing
2022-04-05 18:26:42 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-21
2022-04-05 18:26:42 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-21
2022-04-05 18:26:42 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-21
2022-04-05 18:26:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ec7c000b in namespace namespace-21
2022-04-05 18:26:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-21
2022-04-05 18:26:42 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ec7c000b will have desired state: Ready
2022-04-05 18:29:14 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ec7c000b is in desired state: Ready
2022-04-05 18:29:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-ec7c000b in namespace namespace-21
2022-04-05 18:29:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-21
2022-04-05 18:29:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-ec7c000b will have desired state: PendingProposal
2022-04-05 18:29:15 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-ec7c000b is in desired state: PendingProposal
2022-04-05 18:29:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-ec7c000b will have desired state: ProposalReady
2022-04-05 18:31:09 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-ec7c000b is in desired state: ProposalReady
2022-04-05 18:31:09 [main] [32mINFO [m [CruiseControlST:292] Checking status of KafkaRebalance
2022-04-05 18:31:09 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:31:09 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlIntraBrokerBalancing
2022-04-05 18:31:09 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-ec7c000b in namespace namespace-21
2022-04-05 18:31:09 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ec7c000b in namespace namespace-21
2022-04-05 18:31:09 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-21, for cruise control Kafka cluster my-cluster-ec7c000b
2022-04-05 18:31:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:31:19 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-21 for test case:testCruiseControlIntraBrokerBalancing
2022-04-05 18:32:03 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlIntraBrokerBalancing-FINISHED
2022-04-05 18:32:03 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:32:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:32:03 [main] [32mINFO [m [ResourceManager:346] In context CruiseControlST is everything deleted.
2022-04-05 18:32:03 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2,612.45 s - in io.strimzi.systemtest.cruisecontrol.CruiseControlST
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.listeners.ListenersST
2022-04-05 18:32:11 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: listeners-st
2022-04-05 18:32:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: listeners-st
2022-04-05 18:32:11 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: listeners-st
2022-04-05 18:32:11 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:32:11 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesTlsAuthenticated-STARTED
2022-04-05 18:32:11 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:32:11 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-22 for test case:testSendMessagesTlsAuthenticated
2022-04-05 18:32:11 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-22
2022-04-05 18:32:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-22
2022-04-05 18:32:11 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-22
2022-04-05 18:32:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-da02bf03 in namespace namespace-22
2022-04-05 18:32:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-22
2022-04-05 18:32:11 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-da02bf03 will have desired state: Ready
2022-04-05 18:33:22 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-da02bf03 is in desired state: Ready
2022-04-05 18:33:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1038339991-236216218 in namespace namespace-22
2022-04-05 18:33:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-22
2022-04-05 18:33:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1038339991-236216218 will have desired state: Ready
2022-04-05 18:33:23 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1038339991-236216218 is in desired state: Ready
2022-04-05 18:33:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1353655216-1000353682 in namespace namespace-22
2022-04-05 18:33:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-22
2022-04-05 18:33:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1353655216-1000353682 will have desired state: Ready
2022-04-05 18:33:24 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1353655216-1000353682 is in desired state: Ready
2022-04-05 18:33:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-da02bf03-kafka-clients in namespace namespace-22
2022-04-05 18:33:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-22
2022-04-05 18:33:24 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-da02bf03-kafka-clients will be ready
2022-04-05 18:33:26 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-da02bf03-kafka-clients is ready
2022-04-05 18:33:26 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 18:33:26 [main] [32mINFO [m [ListenersST:221] Checking produced and consumed messages to pod:my-cluster-da02bf03-kafka-clients-6d6787496b-s9f4b
2022-04-05 18:33:26 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3f229ec8, messages=[], arguments=[--max-messages, 100, --topic, my-topic-1038339991-236216218, --bootstrap-server, my-cluster-da02bf03-kafka-bootstrap.namespace-22.svc:9093, USER=my_user_1353655216_1000353682], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-da02bf03-kafka-clients-6d6787496b-s9f4b', podNamespace='namespace-22', bootstrapServer='my-cluster-da02bf03-kafka-bootstrap.namespace-22.svc:9093', topicName='my-topic-1038339991-236216218', maxMessages=100, kafkaUsername='my-user-1353655216-1000353682', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@c27721c}
2022-04-05 18:33:26 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-da02bf03-kafka-bootstrap.namespace-22.svc:9093:my-topic-1038339991-236216218 from pod my-cluster-da02bf03-kafka-clients-6d6787496b-s9f4b
2022-04-05 18:33:26 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-da02bf03-kafka-clients-6d6787496b-s9f4b -n namespace-22 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-1038339991-236216218 --bootstrap-server my-cluster-da02bf03-kafka-bootstrap.namespace-22.svc:9093 USER=my_user_1353655216_1000353682
2022-04-05 18:33:29 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 18:33:29 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 18:33:29 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@e726321, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1549841431, --group-instance-id, instance492776533, --topic, my-topic-1038339991-236216218, --bootstrap-server, my-cluster-da02bf03-kafka-bootstrap.namespace-22.svc:9093, USER=my_user_1353655216_1000353682], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-da02bf03-kafka-clients-6d6787496b-s9f4b', podNamespace='namespace-22', bootstrapServer='my-cluster-da02bf03-kafka-bootstrap.namespace-22.svc:9093', topicName='my-topic-1038339991-236216218', maxMessages=100, kafkaUsername='my-user-1353655216-1000353682', consumerGroupName='my-consumer-group-1549841431', consumerInstanceId='instance492776533', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@39724181}
2022-04-05 18:33:29 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-da02bf03-kafka-bootstrap.namespace-22.svc:9093:my-topic-1038339991-236216218 from pod my-cluster-da02bf03-kafka-clients-6d6787496b-s9f4b
2022-04-05 18:33:29 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-da02bf03-kafka-clients-6d6787496b-s9f4b -n namespace-22 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1549841431 --group-instance-id instance492776533 --topic my-topic-1038339991-236216218 --bootstrap-server my-cluster-da02bf03-kafka-bootstrap.namespace-22.svc:9093 USER=my_user_1353655216_1000353682
2022-04-05 18:33:36 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 18:33:36 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 18:33:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:33:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendMessagesTlsAuthenticated
2022-04-05 18:33:36 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1353655216-1000353682 in namespace namespace-22
2022-04-05 18:33:36 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-da02bf03 in namespace namespace-22
2022-04-05 18:33:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1038339991-236216218 in namespace namespace-22
2022-04-05 18:33:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-da02bf03-kafka-clients in namespace namespace-22
2022-04-05 18:34:16 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:34:16 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-22 for test case:testSendMessagesTlsAuthenticated
2022-04-05 18:34:27 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesTlsAuthenticated-FINISHED
2022-04-05 18:34:27 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:34:27 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:34:27 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesCustomListenerTlsScramSha-STARTED
2022-04-05 18:34:27 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:34:27 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-23 for test case:testSendMessagesCustomListenerTlsScramSha
2022-04-05 18:34:27 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-23
2022-04-05 18:34:27 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-23
2022-04-05 18:34:27 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-23
2022-04-05 18:34:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a6d808e2 in namespace namespace-23
2022-04-05 18:34:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-23
2022-04-05 18:34:27 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a6d808e2 will have desired state: Ready
2022-04-05 18:35:40 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a6d808e2 is in desired state: Ready
2022-04-05 18:35:40 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-500756063-1546866045 in namespace namespace-23
2022-04-05 18:35:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-23
2022-04-05 18:35:40 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-500756063-1546866045 will have desired state: Ready
2022-04-05 18:35:41 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-500756063-1546866045 is in desired state: Ready
2022-04-05 18:35:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-2137461520-2074884019 in namespace namespace-23
2022-04-05 18:35:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-23
2022-04-05 18:35:42 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-2137461520-2074884019 will have desired state: Ready
2022-04-05 18:35:43 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-2137461520-2074884019 is in desired state: Ready
2022-04-05 18:35:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a6d808e2-kafka-clients in namespace namespace-23
2022-04-05 18:35:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-23
2022-04-05 18:35:43 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a6d808e2-kafka-clients will be ready
2022-04-05 18:35:44 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a6d808e2-kafka-clients is ready
2022-04-05 18:35:44 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 18:35:44 [main] [32mINFO [m [ListenersST:442] Checking produced and consumed messages to pod:my-cluster-a6d808e2-kafka-clients-599fddf7cc-j5w8t
2022-04-05 18:35:44 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1e8747bd, messages=[], arguments=[--max-messages, 100, --topic, my-topic-500756063-1546866045, --bootstrap-server, my-cluster-a6d808e2-kafka-bootstrap.namespace-23.svc:9122, USER=my_user_2137461520_2074884019], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-a6d808e2-kafka-clients-599fddf7cc-j5w8t', podNamespace='namespace-23', bootstrapServer='my-cluster-a6d808e2-kafka-bootstrap.namespace-23.svc:9122', topicName='my-topic-500756063-1546866045', maxMessages=100, kafkaUsername='my-user-2137461520-2074884019', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3179d2b3}
2022-04-05 18:35:44 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-a6d808e2-kafka-bootstrap.namespace-23.svc:9122:my-topic-500756063-1546866045 from pod my-cluster-a6d808e2-kafka-clients-599fddf7cc-j5w8t
2022-04-05 18:35:44 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a6d808e2-kafka-clients-599fddf7cc-j5w8t -n namespace-23 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-500756063-1546866045 --bootstrap-server my-cluster-a6d808e2-kafka-bootstrap.namespace-23.svc:9122 USER=my_user_2137461520_2074884019
2022-04-05 18:35:47 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 18:35:47 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 18:35:47 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@69e19a61, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1652674548, --group-instance-id, instance292005831, --topic, my-topic-500756063-1546866045, --bootstrap-server, my-cluster-a6d808e2-kafka-bootstrap.namespace-23.svc:9122, USER=my_user_2137461520_2074884019], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a6d808e2-kafka-clients-599fddf7cc-j5w8t', podNamespace='namespace-23', bootstrapServer='my-cluster-a6d808e2-kafka-bootstrap.namespace-23.svc:9122', topicName='my-topic-500756063-1546866045', maxMessages=100, kafkaUsername='my-user-2137461520-2074884019', consumerGroupName='my-consumer-group-1652674548', consumerInstanceId='instance292005831', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@16f22e46}
2022-04-05 18:35:47 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-a6d808e2-kafka-bootstrap.namespace-23.svc:9122:my-topic-500756063-1546866045 from pod my-cluster-a6d808e2-kafka-clients-599fddf7cc-j5w8t
2022-04-05 18:35:47 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a6d808e2-kafka-clients-599fddf7cc-j5w8t -n namespace-23 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1652674548 --group-instance-id instance292005831 --topic my-topic-500756063-1546866045 --bootstrap-server my-cluster-a6d808e2-kafka-bootstrap.namespace-23.svc:9122 USER=my_user_2137461520_2074884019
2022-04-05 18:35:54 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 18:35:54 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 18:35:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:35:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendMessagesCustomListenerTlsScramSha
2022-04-05 18:35:54 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-2137461520-2074884019 in namespace namespace-23
2022-04-05 18:35:54 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a6d808e2-kafka-clients in namespace namespace-23
2022-04-05 18:35:54 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-500756063-1546866045 in namespace namespace-23
2022-04-05 18:35:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a6d808e2 in namespace namespace-23
2022-04-05 18:36:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:36:34 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-23 for test case:testSendMessagesCustomListenerTlsScramSha
2022-04-05 18:36:45 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesCustomListenerTlsScramSha-FINISHED
2022-04-05 18:36:45 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:36:45 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:36:45 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testCertificateWithNonExistingDataCrt-STARTED
2022-04-05 18:36:45 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:36:45 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-24 for test case:testCertificateWithNonExistingDataCrt
2022-04-05 18:36:45 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-24
2022-04-05 18:36:46 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-24
2022-04-05 18:36:46 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-24
2022-04-05 18:36:46 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret my-cluster-14011db6-custom-certificate-server-1
2022-04-05 18:36:46 [main] [32mINFO [m [SecretUtils:50] Secret my-cluster-14011db6-custom-certificate-server-1 created
2022-04-05 18:36:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-14011db6 in namespace namespace-24
2022-04-05 18:36:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-24
2022-04-05 18:37:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:37:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCertificateWithNonExistingDataCrt
2022-04-05 18:37:19 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-14011db6 in namespace namespace-24
2022-04-05 18:37:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:37:19 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-24 for test case:testCertificateWithNonExistingDataCrt
2022-04-05 18:37:24 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testCertificateWithNonExistingDataCrt-FINISHED
2022-04-05 18:37:24 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:37:24 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:37:24 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testCertificateWithNonExistingDataKey-STARTED
2022-04-05 18:37:24 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:37:24 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-25 for test case:testCertificateWithNonExistingDataKey
2022-04-05 18:37:24 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-25
2022-04-05 18:37:24 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-25
2022-04-05 18:37:24 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-25
2022-04-05 18:37:24 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret my-cluster-682ed083-custom-certificate-server-1
2022-04-05 18:37:24 [main] [32mINFO [m [SecretUtils:50] Secret my-cluster-682ed083-custom-certificate-server-1 created
2022-04-05 18:37:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-682ed083 in namespace namespace-25
2022-04-05 18:37:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-25
2022-04-05 18:37:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:37:53 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCertificateWithNonExistingDataKey
2022-04-05 18:37:53 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-682ed083 in namespace namespace-25
2022-04-05 18:37:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:37:53 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-25 for test case:testCertificateWithNonExistingDataKey
2022-04-05 18:37:59 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testCertificateWithNonExistingDataKey-FINISHED
2022-04-05 18:37:59 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:37:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:37:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesPlainAnonymous-STARTED
2022-04-05 18:37:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:37:59 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-26 for test case:testSendMessagesPlainAnonymous
2022-04-05 18:37:59 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-26
2022-04-05 18:37:59 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-26
2022-04-05 18:37:59 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-26
2022-04-05 18:37:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-46b1459c in namespace namespace-26
2022-04-05 18:37:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-26
2022-04-05 18:37:59 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-46b1459c will have desired state: Ready
2022-04-05 18:39:07 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-46b1459c is in desired state: Ready
2022-04-05 18:39:07 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-279194488-1124064514 in namespace namespace-26
2022-04-05 18:39:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-26
2022-04-05 18:39:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-279194488-1124064514 will have desired state: Ready
2022-04-05 18:39:08 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-279194488-1124064514 is in desired state: Ready
2022-04-05 18:39:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-46b1459c-kafka-clients in namespace namespace-26
2022-04-05 18:39:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-26
2022-04-05 18:39:08 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-46b1459c-kafka-clients will be ready
2022-04-05 18:39:10 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-46b1459c-kafka-clients is ready
2022-04-05 18:39:10 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 18:39:10 [main] [32mINFO [m [ListenersST:152] Checking produced and consumed messages to pod:my-cluster-46b1459c-kafka-clients-6657d7d89c-6lgww
2022-04-05 18:39:10 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@76fc2878, messages=[], arguments=[--max-messages, 100, --topic, my-topic-279194488-1124064514, --bootstrap-server, my-cluster-46b1459c-kafka-bootstrap.namespace-26.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-46b1459c-kafka-clients-6657d7d89c-6lgww', podNamespace='namespace-26', bootstrapServer='my-cluster-46b1459c-kafka-bootstrap.namespace-26.svc:9092', topicName='my-topic-279194488-1124064514', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5dd0328b}
2022-04-05 18:39:10 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-46b1459c-kafka-bootstrap.namespace-26.svc:9092:my-topic-279194488-1124064514 from pod my-cluster-46b1459c-kafka-clients-6657d7d89c-6lgww
2022-04-05 18:39:10 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-46b1459c-kafka-clients-6657d7d89c-6lgww -n namespace-26 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-279194488-1124064514 --bootstrap-server my-cluster-46b1459c-kafka-bootstrap.namespace-26.svc:9092
2022-04-05 18:39:13 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 18:39:13 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 18:39:13 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3e2d1bad, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1380382036, --group-instance-id, instance154121147, --topic, my-topic-279194488-1124064514, --bootstrap-server, my-cluster-46b1459c-kafka-bootstrap.namespace-26.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-46b1459c-kafka-clients-6657d7d89c-6lgww', podNamespace='namespace-26', bootstrapServer='my-cluster-46b1459c-kafka-bootstrap.namespace-26.svc:9092', topicName='my-topic-279194488-1124064514', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1380382036', consumerInstanceId='instance154121147', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@62b5291a}
2022-04-05 18:39:13 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-46b1459c-kafka-bootstrap.namespace-26.svc:9092#my-topic-279194488-1124064514 from pod my-cluster-46b1459c-kafka-clients-6657d7d89c-6lgww
2022-04-05 18:39:13 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-46b1459c-kafka-clients-6657d7d89c-6lgww -n namespace-26 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1380382036 --group-instance-id instance154121147 --topic my-topic-279194488-1124064514 --bootstrap-server my-cluster-46b1459c-kafka-bootstrap.namespace-26.svc:9092
2022-04-05 18:39:18 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 18:39:18 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 18:39:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:39:18 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendMessagesPlainAnonymous
2022-04-05 18:39:18 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-279194488-1124064514 in namespace namespace-26
2022-04-05 18:39:18 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-46b1459c-kafka-clients in namespace namespace-26
2022-04-05 18:39:18 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-46b1459c in namespace namespace-26
2022-04-05 18:39:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:39:58 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-26 for test case:testSendMessagesPlainAnonymous
2022-04-05 18:40:04 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesPlainAnonymous-FINISHED
2022-04-05 18:40:04 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:40:04 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:40:04 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesPlainScramSha-STARTED
2022-04-05 18:40:04 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:40:04 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-27 for test case:testSendMessagesPlainScramSha
2022-04-05 18:40:04 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-27
2022-04-05 18:40:04 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-27
2022-04-05 18:40:04 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-27
2022-04-05 18:40:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c5105abc in namespace namespace-27
2022-04-05 18:40:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-27
2022-04-05 18:40:04 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c5105abc will have desired state: Ready
2022-04-05 18:41:16 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c5105abc is in desired state: Ready
2022-04-05 18:41:16 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1431592214-110896953 in namespace namespace-27
2022-04-05 18:41:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-27
2022-04-05 18:41:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1431592214-110896953 will have desired state: Ready
2022-04-05 18:41:17 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1431592214-110896953 is in desired state: Ready
2022-04-05 18:41:17 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-9512568-784762783 in namespace namespace-27
2022-04-05 18:41:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-27
2022-04-05 18:41:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-9512568-784762783 will have desired state: Ready
2022-04-05 18:41:18 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-9512568-784762783 is in desired state: Ready
2022-04-05 18:41:18 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-9512568-784762783: 2022-04-05 18:41:18,068 INFO Processing override for entityPath: users/my-user-9512568-784762783 with config: HashMap(SCRAM-SHA-512 -> [hidden]) (kafka.server.DynamicConfigManager) [/config/changes-event-process-thread]
2022-04-05 18:41:18 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-9512568-784762783: 2022-04-05 18:41:18,093 INFO Removing PRODUCE quota for user my-user-9512568-784762783 (kafka.server.ClientQuotaManager) [/config/changes-event-process-thread]
2022-04-05 18:41:18 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-9512568-784762783: 2022-04-05 18:41:18,096 INFO Removing FETCH quota for user my-user-9512568-784762783 (kafka.server.ClientQuotaManager) [/config/changes-event-process-thread]
2022-04-05 18:41:18 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-9512568-784762783: 2022-04-05 18:41:18,096 INFO Removing REQUEST quota for user my-user-9512568-784762783 (kafka.server.ClientRequestQuotaManager) [/config/changes-event-process-thread]
2022-04-05 18:41:18 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-9512568-784762783: 2022-04-05 18:41:18,096 INFO Removing CONTROLLER_MUTATION quota for user my-user-9512568-784762783 (kafka.server.ControllerMutationQuotaManager) [/config/changes-event-process-thread]
2022-04-05 18:41:18 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-9512568-784762783: 2022-04-05 18:41:18,288 INFO Processing override for entityPath: users/my-user-9512568-784762783 with config: HashMap(SCRAM-SHA-512 -> [hidden]) (kafka.server.DynamicConfigManager) [/config/changes-event-process-thread]
2022-04-05 18:41:18 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-9512568-784762783: 2022-04-05 18:41:18,288 INFO Removing PRODUCE quota for user my-user-9512568-784762783 (kafka.server.ClientQuotaManager) [/config/changes-event-process-thread]
2022-04-05 18:41:18 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-9512568-784762783: 2022-04-05 18:41:18,288 INFO Removing FETCH quota for user my-user-9512568-784762783 (kafka.server.ClientQuotaManager) [/config/changes-event-process-thread]
2022-04-05 18:41:18 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-9512568-784762783: 2022-04-05 18:41:18,288 INFO Removing REQUEST quota for user my-user-9512568-784762783 (kafka.server.ClientRequestQuotaManager) [/config/changes-event-process-thread]
2022-04-05 18:41:18 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-9512568-784762783: 2022-04-05 18:41:18,289 INFO Removing CONTROLLER_MUTATION quota for user my-user-9512568-784762783 (kafka.server.ControllerMutationQuotaManager) [/config/changes-event-process-thread]
2022-04-05 18:41:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-c5105abc-kafka-clients in namespace namespace-27
2022-04-05 18:41:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-27
2022-04-05 18:41:18 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c5105abc-kafka-clients will be ready
2022-04-05 18:41:20 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c5105abc-kafka-clients is ready
2022-04-05 18:41:20 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 18:41:20 [main] [32mINFO [m [ListenersST:296] Checking produced and consumed messages to pod:my-cluster-c5105abc-kafka-clients-745f768459-6p4hn
2022-04-05 18:41:20 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@79430c5b, messages=[], arguments=[--max-messages, 100, --topic, my-topic-1431592214-110896953, --bootstrap-server, my-cluster-c5105abc-kafka-bootstrap.namespace-27.svc:9095, USER=my_user_9512568_784762783], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-c5105abc-kafka-clients-745f768459-6p4hn', podNamespace='namespace-27', bootstrapServer='my-cluster-c5105abc-kafka-bootstrap.namespace-27.svc:9095', topicName='my-topic-1431592214-110896953', maxMessages=100, kafkaUsername='my-user-9512568-784762783', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2a36bfae}
2022-04-05 18:41:20 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-c5105abc-kafka-bootstrap.namespace-27.svc:9095:my-topic-1431592214-110896953 from pod my-cluster-c5105abc-kafka-clients-745f768459-6p4hn
2022-04-05 18:41:20 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c5105abc-kafka-clients-745f768459-6p4hn -n namespace-27 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-1431592214-110896953 --bootstrap-server my-cluster-c5105abc-kafka-bootstrap.namespace-27.svc:9095 USER=my_user_9512568_784762783
2022-04-05 18:41:23 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 18:41:23 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 18:41:23 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3b6ec620, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-498207254, --group-instance-id, instance1944856054, --topic, my-topic-1431592214-110896953, --bootstrap-server, my-cluster-c5105abc-kafka-bootstrap.namespace-27.svc:9095, USER=my_user_9512568_784762783], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-c5105abc-kafka-clients-745f768459-6p4hn', podNamespace='namespace-27', bootstrapServer='my-cluster-c5105abc-kafka-bootstrap.namespace-27.svc:9095', topicName='my-topic-1431592214-110896953', maxMessages=100, kafkaUsername='my-user-9512568-784762783', consumerGroupName='my-consumer-group-498207254', consumerInstanceId='instance1944856054', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@24bad6d6}
2022-04-05 18:41:23 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-c5105abc-kafka-bootstrap.namespace-27.svc:9095#my-topic-1431592214-110896953 from pod my-cluster-c5105abc-kafka-clients-745f768459-6p4hn
2022-04-05 18:41:23 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c5105abc-kafka-clients-745f768459-6p4hn -n namespace-27 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-498207254 --group-instance-id instance1944856054 --topic my-topic-1431592214-110896953 --bootstrap-server my-cluster-c5105abc-kafka-bootstrap.namespace-27.svc:9095 USER=my_user_9512568_784762783
2022-04-05 18:41:29 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 18:41:29 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 18:41:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:41:29 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendMessagesPlainScramSha
2022-04-05 18:41:29 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-9512568-784762783 in namespace namespace-27
2022-04-05 18:41:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-c5105abc-kafka-clients in namespace namespace-27
2022-04-05 18:41:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1431592214-110896953 in namespace namespace-27
2022-04-05 18:41:29 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c5105abc in namespace namespace-27
2022-04-05 18:42:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:42:19 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-27 for test case:testSendMessagesPlainScramSha
2022-04-05 18:42:24 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesPlainScramSha-FINISHED
2022-04-05 18:42:24 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:42:24 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:42:24 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesTlsScramSha-STARTED
2022-04-05 18:42:24 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:42:24 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-28 for test case:testSendMessagesTlsScramSha
2022-04-05 18:42:24 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-28
2022-04-05 18:42:24 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-28
2022-04-05 18:42:24 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-28
2022-04-05 18:42:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a353f1b4 in namespace namespace-28
2022-04-05 18:42:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-28
2022-04-05 18:42:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a353f1b4 will have desired state: Ready
2022-04-05 18:43:43 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a353f1b4 is in desired state: Ready
2022-04-05 18:43:43 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-488458006-244535815 in namespace namespace-28
2022-04-05 18:43:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-28
2022-04-05 18:43:43 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-488458006-244535815 will have desired state: Ready
2022-04-05 18:43:44 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-488458006-244535815 is in desired state: Ready
2022-04-05 18:43:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-870322768-1563820461 in namespace namespace-28
2022-04-05 18:43:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-28
2022-04-05 18:43:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-870322768-1563820461 will have desired state: Ready
2022-04-05 18:43:45 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-870322768-1563820461 is in desired state: Ready
2022-04-05 18:43:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a353f1b4-kafka-clients in namespace namespace-28
2022-04-05 18:43:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-28
2022-04-05 18:43:45 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a353f1b4-kafka-clients will be ready
2022-04-05 18:43:47 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a353f1b4-kafka-clients is ready
2022-04-05 18:43:47 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 18:43:47 [main] [32mINFO [m [ListenersST:370] Checking produced and consumed messages to pod:my-cluster-a353f1b4-kafka-clients-7665754744-gz8v7
2022-04-05 18:43:47 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@317b8359, messages=[], arguments=[--max-messages, 100, --topic, my-topic-488458006-244535815, --bootstrap-server, my-cluster-a353f1b4-kafka-bootstrap.namespace-28.svc:9096, USER=my_user_870322768_1563820461], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-a353f1b4-kafka-clients-7665754744-gz8v7', podNamespace='namespace-28', bootstrapServer='my-cluster-a353f1b4-kafka-bootstrap.namespace-28.svc:9096', topicName='my-topic-488458006-244535815', maxMessages=100, kafkaUsername='my-user-870322768-1563820461', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@343b232}
2022-04-05 18:43:47 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-a353f1b4-kafka-bootstrap.namespace-28.svc:9096:my-topic-488458006-244535815 from pod my-cluster-a353f1b4-kafka-clients-7665754744-gz8v7
2022-04-05 18:43:47 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a353f1b4-kafka-clients-7665754744-gz8v7 -n namespace-28 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-488458006-244535815 --bootstrap-server my-cluster-a353f1b4-kafka-bootstrap.namespace-28.svc:9096 USER=my_user_870322768_1563820461
2022-04-05 18:43:50 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 18:43:50 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 18:43:50 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7fc9609e, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1283841393, --group-instance-id, instance2060943303, --topic, my-topic-488458006-244535815, --bootstrap-server, my-cluster-a353f1b4-kafka-bootstrap.namespace-28.svc:9096, USER=my_user_870322768_1563820461], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a353f1b4-kafka-clients-7665754744-gz8v7', podNamespace='namespace-28', bootstrapServer='my-cluster-a353f1b4-kafka-bootstrap.namespace-28.svc:9096', topicName='my-topic-488458006-244535815', maxMessages=100, kafkaUsername='my-user-870322768-1563820461', consumerGroupName='my-consumer-group-1283841393', consumerInstanceId='instance2060943303', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@61058cae}
2022-04-05 18:43:50 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-a353f1b4-kafka-bootstrap.namespace-28.svc:9096:my-topic-488458006-244535815 from pod my-cluster-a353f1b4-kafka-clients-7665754744-gz8v7
2022-04-05 18:43:50 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a353f1b4-kafka-clients-7665754744-gz8v7 -n namespace-28 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1283841393 --group-instance-id instance2060943303 --topic my-topic-488458006-244535815 --bootstrap-server my-cluster-a353f1b4-kafka-bootstrap.namespace-28.svc:9096 USER=my_user_870322768_1563820461
2022-04-05 18:43:57 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 18:43:57 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 18:43:57 [main] [32mINFO [m [ListenersST:377] Checking if generated password has 25 characters
2022-04-05 18:43:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:43:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendMessagesTlsScramSha
2022-04-05 18:43:57 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-870322768-1563820461 in namespace namespace-28
2022-04-05 18:43:57 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a353f1b4-kafka-clients in namespace namespace-28
2022-04-05 18:43:57 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-488458006-244535815 in namespace namespace-28
2022-04-05 18:43:57 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a353f1b4 in namespace namespace-28
2022-04-05 18:44:37 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:44:37 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-28 for test case:testSendMessagesTlsScramSha
2022-04-05 18:44:43 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesTlsScramSha-FINISHED
2022-04-05 18:44:43 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:44:43 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:44:43 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testNonExistingCustomCertificate-STARTED
2022-04-05 18:44:43 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:44:43 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-29 for test case:testNonExistingCustomCertificate
2022-04-05 18:44:43 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-29
2022-04-05 18:44:43 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-29
2022-04-05 18:44:43 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-29
2022-04-05 18:44:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-cf39f9df in namespace namespace-29
2022-04-05 18:44:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-29
2022-04-05 18:45:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:45:13 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testNonExistingCustomCertificate
2022-04-05 18:45:13 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-cf39f9df in namespace namespace-29
2022-04-05 18:45:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:45:13 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-29 for test case:testNonExistingCustomCertificate
2022-04-05 18:45:19 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testNonExistingCustomCertificate-FINISHED
2022-04-05 18:45:19 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:45:19 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:45:19 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testAdvertisedHostNamesAppearsInBrokerCerts-STARTED
2022-04-05 18:45:19 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:45:19 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-30 for test case:testAdvertisedHostNamesAppearsInBrokerCerts
2022-04-05 18:45:19 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-30
2022-04-05 18:45:19 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-30
2022-04-05 18:45:19 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-30
2022-04-05 18:45:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a922e4aa in namespace namespace-30
2022-04-05 18:45:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-30
2022-04-05 18:45:19 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a922e4aa will have desired state: Ready
2022-04-05 18:46:39 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a922e4aa is in desired state: Ready
2022-04-05 18:46:39 [main] [32mINFO [m [ListenersST:2338] Encoding my-cluster-a922e4aa-kafka-0.crt
2022-04-05 18:46:39 [main] [32mINFO [m [ListenersST:2338] Encoding my-cluster-a922e4aa-kafka-1.crt
2022-04-05 18:46:39 [main] [32mINFO [m [ListenersST:2338] Encoding my-cluster-a922e4aa-kafka-2.crt
2022-04-05 18:46:39 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:46:39 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAdvertisedHostNamesAppearsInBrokerCerts
2022-04-05 18:46:39 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a922e4aa in namespace namespace-30
2022-04-05 18:46:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:46:49 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-30 for test case:testAdvertisedHostNamesAppearsInBrokerCerts
2022-04-05 18:47:32 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testAdvertisedHostNamesAppearsInBrokerCerts-FINISHED
2022-04-05 18:47:32 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:47:32 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:47:32 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testMessagesTlsScramShaWithPredefinedPassword-STARTED
2022-04-05 18:47:32 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:47:32 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-31 for test case:testMessagesTlsScramShaWithPredefinedPassword
2022-04-05 18:47:32 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-31
2022-04-05 18:47:32 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-31
2022-04-05 18:47:32 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-31
2022-04-05 18:47:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-62f0cfba in namespace namespace-31
2022-04-05 18:47:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-31
2022-04-05 18:47:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1370574592-1249849041 in namespace namespace-31
2022-04-05 18:47:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-31
2022-04-05 18:47:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2037098377-1088092635 in namespace namespace-31
2022-04-05 18:47:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-31
2022-04-05 18:47:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-62f0cfba will have desired state: Ready
2022-04-05 18:48:48 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-62f0cfba is in desired state: Ready
2022-04-05 18:48:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1370574592-1249849041 will have desired state: Ready
2022-04-05 18:48:48 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1370574592-1249849041 is in desired state: Ready
2022-04-05 18:48:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2037098377-1088092635 will have desired state: Ready
2022-04-05 18:48:48 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2037098377-1088092635 is in desired state: Ready
2022-04-05 18:48:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-62f0cfba-kafka-clients in namespace namespace-31
2022-04-05 18:48:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-31
2022-04-05 18:48:48 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-62f0cfba-kafka-clients will be ready
2022-04-05 18:48:50 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-62f0cfba-kafka-clients is ready
2022-04-05 18:48:50 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 18:48:50 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@38750ef7, messages=[], arguments=[--max-messages, 100, --topic, my-topic-2037098377-1088092635, --bootstrap-server, my-cluster-62f0cfba-kafka-bootstrap.namespace-31.svc:9096, USER=my_user_1370574592_1249849041], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-62f0cfba-kafka-clients-b94868bc8-s5swz', podNamespace='namespace-31', bootstrapServer='my-cluster-62f0cfba-kafka-bootstrap.namespace-31.svc:9096', topicName='my-topic-2037098377-1088092635', maxMessages=100, kafkaUsername='my-user-1370574592-1249849041', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1ef2ac0e}
2022-04-05 18:48:50 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-62f0cfba-kafka-bootstrap.namespace-31.svc:9096:my-topic-2037098377-1088092635 from pod my-cluster-62f0cfba-kafka-clients-b94868bc8-s5swz
2022-04-05 18:48:50 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-62f0cfba-kafka-clients-b94868bc8-s5swz -n namespace-31 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-2037098377-1088092635 --bootstrap-server my-cluster-62f0cfba-kafka-bootstrap.namespace-31.svc:9096 USER=my_user_1370574592_1249849041
2022-04-05 18:48:54 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 18:48:54 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 18:48:54 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@37de93c0, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1799018657, --group-instance-id, instance297887886, --topic, my-topic-2037098377-1088092635, --bootstrap-server, my-cluster-62f0cfba-kafka-bootstrap.namespace-31.svc:9096, USER=my_user_1370574592_1249849041], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-62f0cfba-kafka-clients-b94868bc8-s5swz', podNamespace='namespace-31', bootstrapServer='my-cluster-62f0cfba-kafka-bootstrap.namespace-31.svc:9096', topicName='my-topic-2037098377-1088092635', maxMessages=100, kafkaUsername='my-user-1370574592-1249849041', consumerGroupName='my-consumer-group-1799018657', consumerInstanceId='instance297887886', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3c47da9a}
2022-04-05 18:48:54 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-62f0cfba-kafka-bootstrap.namespace-31.svc:9096:my-topic-2037098377-1088092635 from pod my-cluster-62f0cfba-kafka-clients-b94868bc8-s5swz
2022-04-05 18:48:54 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-62f0cfba-kafka-clients-b94868bc8-s5swz -n namespace-31 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1799018657 --group-instance-id instance297887886 --topic my-topic-2037098377-1088092635 --bootstrap-server my-cluster-62f0cfba-kafka-bootstrap.namespace-31.svc:9096 USER=my_user_1370574592_1249849041
2022-04-05 18:49:01 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 18:49:01 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 18:49:01 [main] [32mINFO [m [ListenersST:2213] Changing password in secret: my-cluster-62f0cfba-secret, we should be able to send/receive messages
2022-04-05 18:49:01 [main] [32mINFO [m [SecretUtils:171] Waiting for user password will be changed to Y29tcGxldGVseV9kaWZmZXJlbnRfc2VjcmV0X3Bhc3N3b3Jk in secret: my-user-1370574592-1249849041
2022-04-05 18:50:33 [main] [32mINFO [m [ListenersST:2222] We need to recreate Kafka Clients deployment, so the correct password from secret will be taken
2022-04-05 18:50:33 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-62f0cfba-kafka-clients in namespace namespace-31
2022-04-05 18:51:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-62f0cfba-kafka-clients in namespace namespace-31
2022-04-05 18:51:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-31
2022-04-05 18:51:23 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-62f0cfba-kafka-clients will be ready
2022-04-05 18:51:25 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-62f0cfba-kafka-clients is ready
2022-04-05 18:51:25 [main] [32mINFO [m [ListenersST:2226] Receiving messages with new password
2022-04-05 18:51:25 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1ab6d306, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-637814036, --group-instance-id, instance1275515561, --topic, my-topic-2037098377-1088092635, --bootstrap-server, my-cluster-62f0cfba-kafka-bootstrap.namespace-31.svc:9096, USER=my_user_1370574592_1249849041], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-62f0cfba-kafka-clients-798586cfc4-5vnrp', podNamespace='namespace-31', bootstrapServer='my-cluster-62f0cfba-kafka-bootstrap.namespace-31.svc:9096', topicName='my-topic-2037098377-1088092635', maxMessages=100, kafkaUsername='my-user-1370574592-1249849041', consumerGroupName='my-consumer-group-637814036', consumerInstanceId='instance1275515561', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@18275992}
2022-04-05 18:51:25 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-62f0cfba-kafka-bootstrap.namespace-31.svc:9096:my-topic-2037098377-1088092635 from pod my-cluster-62f0cfba-kafka-clients-798586cfc4-5vnrp
2022-04-05 18:51:25 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-62f0cfba-kafka-clients-798586cfc4-5vnrp -n namespace-31 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-637814036 --group-instance-id instance1275515561 --topic my-topic-2037098377-1088092635 --bootstrap-server my-cluster-62f0cfba-kafka-bootstrap.namespace-31.svc:9096 USER=my_user_1370574592_1249849041
2022-04-05 18:51:32 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 18:51:32 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 18:51:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:51:32 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMessagesTlsScramShaWithPredefinedPassword
2022-04-05 18:51:32 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2037098377-1088092635 in namespace namespace-31
2022-04-05 18:51:32 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-62f0cfba-kafka-clients in namespace namespace-31
2022-04-05 18:51:32 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1370574592-1249849041 in namespace namespace-31
2022-04-05 18:51:32 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-62f0cfba-kafka-clients in namespace namespace-31
2022-04-05 18:51:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-62f0cfba in namespace namespace-31
2022-04-05 18:52:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:52:22 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-31 for test case:testMessagesTlsScramShaWithPredefinedPassword
2022-04-05 18:52:28 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testMessagesTlsScramShaWithPredefinedPassword-FINISHED
2022-04-05 18:52:28 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:52:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:52:28 [main] [32mINFO [m [ResourceManager:346] In context ListenersST is everything deleted.
2022-04-05 18:52:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,223.933 s - in io.strimzi.systemtest.kafka.listeners.ListenersST
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.listeners.MultipleListenersST
2022-04-05 18:52:33 [main] [32mINFO [m [MultipleListenersST:294] Starting to generate test cases for multiple listeners
2022-04-05 18:52:33 [main] [32mINFO [m [MultipleListenersST:300] Generating INTERNAL listener
2022-04-05 18:52:33 [main] [32mINFO [m [MultipleListenersST:363] Generating listeners with type INTERNAL -> [io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@b5ab4e0b, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@4035c19, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@385b2643]
2022-04-05 18:52:33 [main] [32mINFO [m [MultipleListenersST:300] Generating ROUTE listener
2022-04-05 18:52:33 [main] [32mINFO [m [MultipleListenersST:363] Generating listeners with type ROUTE -> [io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@67450585]
2022-04-05 18:52:33 [main] [32mINFO [m [MultipleListenersST:300] Generating LOADBALANCER listener
2022-04-05 18:52:33 [main] [32mINFO [m [MultipleListenersST:363] Generating listeners with type LOADBALANCER -> [io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@e500e504, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@3358f312]
2022-04-05 18:52:33 [main] [32mINFO [m [MultipleListenersST:300] Generating NODEPORT listener
2022-04-05 18:52:33 [main] [32mINFO [m [MultipleListenersST:363] Generating listeners with type NODEPORT -> [io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@d6fc4ccd, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@b5416f7]
2022-04-05 18:52:33 [main] [32mINFO [m [MultipleListenersST:300] Generating INGRESS listener
2022-04-05 18:52:33 [main] [32mINFO [m [MultipleListenersST:363] Generating listeners with type INGRESS -> []
2022-04-05 18:52:33 [main] [32mINFO [m [MultipleListenersST:367] Finished with generation of test cases for multiple listeners
2022-04-05 18:52:33 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: multiple-listeners-st
2022-04-05 18:52:33 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: multiple-listeners-st
2022-04-05 18:52:33 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: multiple-listeners-st
2022-04-05 18:52:33 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:52:33 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.MultipleListenersST.testMultipleInternal-STARTED
2022-04-05 18:52:33 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:52:33 [main] [32mINFO [m [MultipleListenersST:163] This is listeners [io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@b5ab4e0b, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@4035c19, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@385b2643], which will verified.
2022-04-05 18:52:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b3c18785 in namespace multiple-listeners-st
2022-04-05 18:52:33 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b3c18785 will have desired state: Ready
2022-04-05 18:53:44 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b3c18785 is in desired state: Ready
2022-04-05 18:53:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1256044708-1011944148 in namespace multiple-listeners-st
2022-04-05 18:53:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1256044708-1011944148 will have desired state: Ready
2022-04-05 18:53:45 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1256044708-1011944148 is in desired state: Ready
2022-04-05 18:53:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2010255544-1842055402 in namespace multiple-listeners-st
2022-04-05 18:53:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2010255544-1842055402 will have desired state: Ready
2022-04-05 18:53:46 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2010255544-1842055402 is in desired state: Ready
2022-04-05 18:53:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b3c18785-kafka-clients-tls in namespace multiple-listeners-st
2022-04-05 18:53:46 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b3c18785-kafka-clients-tls will be ready
2022-04-05 18:53:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b3c18785-kafka-clients-tls is ready
2022-04-05 18:53:48 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 18:53:48 [main] [32mINFO [m [MultipleListenersST:252] Checking produced and consumed messages to pod:my-cluster-b3c18785-kafka-clients-tls-776c6d565f-bdmlb
2022-04-05 18:53:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1283011956-1596014508 in namespace multiple-listeners-st
2022-04-05 18:53:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1283011956-1596014508 will have desired state: Ready
2022-04-05 18:53:49 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1283011956-1596014508 is in desired state: Ready
2022-04-05 18:53:49 [main] [32mINFO [m [ClientUtils:127] Sending messages to - topic my-topic-2010255544-1842055402, cluster my-cluster-b3c18785 and message count of 100
2022-04-05 18:53:49 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@54d2ad9a, messages=[], arguments=[--max-messages, 100, --topic, my-topic-1283011956-1596014508, --bootstrap-server, my-cluster-b3c18785-kafka-bootstrap.multiple-listeners-st.svc:13900, USER=my_user_1256044708_1011944148], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b3c18785-kafka-clients-tls-776c6d565f-bdmlb', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-b3c18785-kafka-bootstrap.multiple-listeners-st.svc:13900', topicName='my-topic-1283011956-1596014508', maxMessages=100, kafkaUsername='my-user-1256044708-1011944148', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6efce428}
2022-04-05 18:53:49 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-b3c18785-kafka-bootstrap.multiple-listeners-st.svc:13900:my-topic-1283011956-1596014508 from pod my-cluster-b3c18785-kafka-clients-tls-776c6d565f-bdmlb
2022-04-05 18:53:49 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b3c18785-kafka-clients-tls-776c6d565f-bdmlb -n multiple-listeners-st -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-1283011956-1596014508 --bootstrap-server my-cluster-b3c18785-kafka-bootstrap.multiple-listeners-st.svc:13900 USER=my_user_1256044708_1011944148
2022-04-05 18:53:53 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 18:53:53 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 18:53:53 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@23e6fe0d, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-561467430, --group-instance-id, instance374910518, --topic, my-topic-1283011956-1596014508, --bootstrap-server, my-cluster-b3c18785-kafka-bootstrap.multiple-listeners-st.svc:13900, USER=my_user_1256044708_1011944148], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b3c18785-kafka-clients-tls-776c6d565f-bdmlb', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-b3c18785-kafka-bootstrap.multiple-listeners-st.svc:13900', topicName='my-topic-1283011956-1596014508', maxMessages=100, kafkaUsername='my-user-1256044708-1011944148', consumerGroupName='my-consumer-group-561467430', consumerInstanceId='instance374910518', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2a3282c7}
2022-04-05 18:53:53 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-b3c18785-kafka-bootstrap.multiple-listeners-st.svc:13900:my-topic-1283011956-1596014508 from pod my-cluster-b3c18785-kafka-clients-tls-776c6d565f-bdmlb
2022-04-05 18:53:53 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b3c18785-kafka-clients-tls-776c6d565f-bdmlb -n multiple-listeners-st -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-561467430 --group-instance-id instance374910518 --topic my-topic-1283011956-1596014508 --bootstrap-server my-cluster-b3c18785-kafka-bootstrap.multiple-listeners-st.svc:13900 USER=my_user_1256044708_1011944148
2022-04-05 18:54:00 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 18:54:00 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 18:54:00 [main] [32mINFO [m [ClientUtils:133] Sent 100 and received 100
2022-04-05 18:54:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-484150611-1802966937 in namespace multiple-listeners-st
2022-04-05 18:54:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-484150611-1802966937 will have desired state: Ready
2022-04-05 18:54:01 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-484150611-1802966937 is in desired state: Ready
2022-04-05 18:54:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b3c18785-kafka-clients-plain in namespace multiple-listeners-st
2022-04-05 18:54:01 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b3c18785-kafka-clients-plain will be ready
2022-04-05 18:54:03 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b3c18785-kafka-clients-plain is ready
2022-04-05 18:54:03 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 18:54:03 [main] [32mINFO [m [MultipleListenersST:274] Checking produced and consumed messages to pod:my-cluster-b3c18785-kafka-clients-plain-65c9d84979-xs6gn
2022-04-05 18:54:03 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@79437ff0, messages=[], arguments=[--max-messages, 100, --topic, my-topic-484150611-1802966937, --bootstrap-server, my-cluster-b3c18785-kafka-bootstrap.multiple-listeners-st.svc:13901], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b3c18785-kafka-clients-plain-65c9d84979-xs6gn', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-b3c18785-kafka-bootstrap.multiple-listeners-st.svc:13901', topicName='my-topic-484150611-1802966937', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@62193996}
2022-04-05 18:54:03 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-b3c18785-kafka-bootstrap.multiple-listeners-st.svc:13901:my-topic-484150611-1802966937 from pod my-cluster-b3c18785-kafka-clients-plain-65c9d84979-xs6gn
2022-04-05 18:54:03 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b3c18785-kafka-clients-plain-65c9d84979-xs6gn -n multiple-listeners-st -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-484150611-1802966937 --bootstrap-server my-cluster-b3c18785-kafka-bootstrap.multiple-listeners-st.svc:13901
2022-04-05 18:54:05 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 18:54:05 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 18:54:05 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@53db76c5, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1480757246, --group-instance-id, instance1967818137, --topic, my-topic-484150611-1802966937, --bootstrap-server, my-cluster-b3c18785-kafka-bootstrap.multiple-listeners-st.svc:13901], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b3c18785-kafka-clients-plain-65c9d84979-xs6gn', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-b3c18785-kafka-bootstrap.multiple-listeners-st.svc:13901', topicName='my-topic-484150611-1802966937', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1480757246', consumerInstanceId='instance1967818137', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@47d9fea5}
2022-04-05 18:54:05 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-b3c18785-kafka-bootstrap.multiple-listeners-st.svc:13901#my-topic-484150611-1802966937 from pod my-cluster-b3c18785-kafka-clients-plain-65c9d84979-xs6gn
2022-04-05 18:54:05 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b3c18785-kafka-clients-plain-65c9d84979-xs6gn -n multiple-listeners-st -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1480757246 --group-instance-id instance1967818137 --topic my-topic-484150611-1802966937 --bootstrap-server my-cluster-b3c18785-kafka-bootstrap.multiple-listeners-st.svc:13901
2022-04-05 18:54:11 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 18:54:11 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 18:54:11 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-999574972-592851902 in namespace multiple-listeners-st
2022-04-05 18:54:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-999574972-592851902 will have desired state: Ready
2022-04-05 18:54:12 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-999574972-592851902 is in desired state: Ready
2022-04-05 18:54:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b3c18785-kafka-clients-tls in namespace multiple-listeners-st
2022-04-05 18:54:12 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b3c18785-kafka-clients-tls will be ready
2022-04-05 18:54:12 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b3c18785-kafka-clients-tls is ready
2022-04-05 18:54:12 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 18:54:12 [main] [32mINFO [m [MultipleListenersST:252] Checking produced and consumed messages to pod:my-cluster-b3c18785-kafka-clients-tls-776c6d565f-bdmlb
2022-04-05 18:54:12 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-985870166-363358827 in namespace multiple-listeners-st
2022-04-05 18:54:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-985870166-363358827 will have desired state: Ready
2022-04-05 18:54:13 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-985870166-363358827 is in desired state: Ready
2022-04-05 18:54:13 [main] [32mINFO [m [ClientUtils:127] Sending messages to - topic my-topic-999574972-592851902, cluster my-cluster-b3c18785 and message count of 100
2022-04-05 18:54:13 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1afb7cba, messages=[], arguments=[--max-messages, 100, --topic, my-topic-985870166-363358827, --bootstrap-server, my-cluster-b3c18785-kafka-bootstrap.multiple-listeners-st.svc:13902, USER=my_user_1256044708_1011944148], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b3c18785-kafka-clients-tls-776c6d565f-bdmlb', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-b3c18785-kafka-bootstrap.multiple-listeners-st.svc:13902', topicName='my-topic-985870166-363358827', maxMessages=100, kafkaUsername='my-user-1256044708-1011944148', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@78a520a1}
2022-04-05 18:54:13 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-b3c18785-kafka-bootstrap.multiple-listeners-st.svc:13902:my-topic-985870166-363358827 from pod my-cluster-b3c18785-kafka-clients-tls-776c6d565f-bdmlb
2022-04-05 18:54:13 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b3c18785-kafka-clients-tls-776c6d565f-bdmlb -n multiple-listeners-st -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-985870166-363358827 --bootstrap-server my-cluster-b3c18785-kafka-bootstrap.multiple-listeners-st.svc:13902 USER=my_user_1256044708_1011944148
2022-04-05 18:54:17 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 18:54:17 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 18:54:17 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1abaa446, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-60094405, --group-instance-id, instance1758602505, --topic, my-topic-985870166-363358827, --bootstrap-server, my-cluster-b3c18785-kafka-bootstrap.multiple-listeners-st.svc:13902, USER=my_user_1256044708_1011944148], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b3c18785-kafka-clients-tls-776c6d565f-bdmlb', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-b3c18785-kafka-bootstrap.multiple-listeners-st.svc:13902', topicName='my-topic-985870166-363358827', maxMessages=100, kafkaUsername='my-user-1256044708-1011944148', consumerGroupName='my-consumer-group-60094405', consumerInstanceId='instance1758602505', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@125f8596}
2022-04-05 18:54:17 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-b3c18785-kafka-bootstrap.multiple-listeners-st.svc:13902:my-topic-985870166-363358827 from pod my-cluster-b3c18785-kafka-clients-tls-776c6d565f-bdmlb
2022-04-05 18:54:17 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b3c18785-kafka-clients-tls-776c6d565f-bdmlb -n multiple-listeners-st -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-60094405 --group-instance-id instance1758602505 --topic my-topic-985870166-363358827 --bootstrap-server my-cluster-b3c18785-kafka-bootstrap.multiple-listeners-st.svc:13902 USER=my_user_1256044708_1011944148
2022-04-05 18:54:23 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 18:54:23 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 18:54:23 [main] [32mINFO [m [ClientUtils:133] Sent 100 and received 100
2022-04-05 18:54:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:54:23 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMultipleInternal
2022-04-05 18:54:23 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b3c18785-kafka-clients-plain in namespace multiple-listeners-st
2022-04-05 18:54:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-484150611-1802966937 in namespace multiple-listeners-st
2022-04-05 18:54:23 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-999574972-592851902 in namespace multiple-listeners-st
2022-04-05 18:54:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1256044708-1011944148 in namespace multiple-listeners-st
2022-04-05 18:54:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2010255544-1842055402 in namespace multiple-listeners-st
2022-04-05 18:54:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b3c18785-kafka-clients-tls in namespace multiple-listeners-st
2022-04-05 18:54:23 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b3c18785 in namespace multiple-listeners-st
2022-04-05 18:54:23 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-985870166-363358827 in namespace multiple-listeners-st
2022-04-05 18:54:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1283011956-1596014508 in namespace multiple-listeners-st
2022-04-05 18:54:33 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b3c18785-kafka-clients-tls in namespace multiple-listeners-st
2022-04-05 18:55:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:55:04 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.MultipleListenersST.testMultipleInternal-FINISHED
2022-04-05 18:55:04 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:55:04 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:55:04 [main] [32mINFO [m [ResourceManager:346] In context MultipleListenersST is everything deleted.
2022-04-05 18:55:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 156.027 s - in io.strimzi.systemtest.kafka.listeners.MultipleListenersST
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST
2022-04-05 18:55:09 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: dynamic-conf-st
2022-04-05 18:55:09 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: dynamic-conf-st
2022-04-05 18:55:09 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: dynamic-conf-st
2022-04-05 18:55:09 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:55:09 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST.testSimpleDynamicConfiguration-STARTED
2022-04-05 18:55:09 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3d34b512 in namespace dynamic-conf-st
2022-04-05 18:55:09 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3d34b512 will have desired state: Ready
2022-04-05 18:56:18 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3d34b512 is in desired state: Ready
2022-04-05 18:56:21 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-3d34b512-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 18:56:21 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 18:56:21 [main] [32mINFO [m [DynamicConfST:380] Updating configuration of Kafka cluster
2022-04-05 18:56:21 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-3d34b512-kafka are stable
2022-04-05 18:56:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 18:56:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 18:56:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 18:56:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 18:56:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 18:56:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 18:56:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 18:56:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 18:56:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 18:56:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 18:56:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 18:56:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 18:56:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 18:56:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 18:56:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 18:56:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 18:56:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 18:56:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 18:56:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 18:56:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 18:56:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 18:56:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 18:56:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 18:56:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 18:56:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 18:56:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 18:56:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 18:56:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 18:56:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 18:56:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 18:56:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 18:56:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 18:56:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 18:56:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 18:56:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 18:56:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 18:56:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 18:56:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 18:56:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 18:56:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 18:56:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 18:56:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 18:56:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 18:56:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 18:56:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 18:56:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 18:56:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 18:56:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 18:56:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 18:56:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 18:56:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 18:56:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 18:56:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 18:56:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 18:56:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 18:56:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 18:56:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 18:56:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 18:56:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 18:56:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 18:56:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 18:56:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 18:56:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 18:56:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 18:56:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 18:56:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 18:56:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 18:56:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 18:56:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 18:56:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 18:56:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 18:56:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 18:56:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 18:56:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 18:56:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 18:56:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 18:56:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 18:56:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 18:56:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 18:56:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 18:56:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 18:56:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 18:56:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 18:56:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 18:56:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 18:56:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 18:56:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 18:56:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 18:56:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 18:56:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 18:56:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 18:56:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 18:56:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 18:56:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 18:56:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 18:56:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 18:56:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 18:56:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 18:56:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 18:56:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 18:56:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 18:56:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 18:56:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 18:56:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 18:56:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 18:56:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 18:56:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 18:56:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 18:56:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 18:56:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 18:56:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 18:56:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 18:56:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 18:56:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 18:56:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 18:56:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 18:56:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 18:57:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 18:57:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 18:57:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 18:57:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 18:57:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 18:57:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 18:57:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 18:57:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 18:57:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 18:57:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 18:57:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 18:57:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 18:57:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 18:57:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 18:57:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 18:57:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 18:57:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 18:57:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 18:57:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 18:57:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 18:57:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 18:57:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 18:57:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 18:57:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 18:57:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 18:57:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 18:57:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 18:57:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 18:57:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 18:57:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 18:57:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 18:57:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 18:57:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3d34b512-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 18:57:10 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-3d34b512-kafka-0 ,my-cluster-3d34b512-kafka-1 ,my-cluster-3d34b512-kafka-2
2022-04-05 18:57:13 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-3d34b512-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 18:57:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 18:57:13 [main] [32mINFO [m [DynamicConfST:102] Verify values after update
2022-04-05 18:57:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:57:13 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSimpleDynamicConfiguration
2022-04-05 18:57:13 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3d34b512 in namespace dynamic-conf-st
2022-04-05 18:57:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:57:23 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST.testSimpleDynamicConfiguration-FINISHED
2022-04-05 18:57:23 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:57:23 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:57:23 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST.testUpdateToExternalListenerCausesRollingRestart-STARTED
2022-04-05 18:57:23 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:57:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-89900a13 in namespace dynamic-conf-st
2022-04-05 18:57:23 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-89900a13 will have desired state: Ready
2022-04-05 18:58:46 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-89900a13 is in desired state: Ready
2022-04-05 18:58:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-89900a13-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 18:58:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 18:58:48 [main] [32mINFO [m [DynamicConfST:380] Updating configuration of Kafka cluster
2022-04-05 18:58:48 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-89900a13-kafka are stable
2022-04-05 18:58:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 18:58:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 18:58:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 18:58:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 18:58:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 18:58:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 18:58:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 18:58:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 18:58:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 18:58:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 18:58:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 18:58:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 18:58:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 18:58:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 18:58:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 18:58:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 18:58:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 18:58:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 18:58:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 18:58:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 18:58:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 18:58:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 18:58:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 18:58:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 18:58:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 18:58:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 18:58:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 18:58:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 18:58:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 18:58:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 18:58:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 18:58:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 18:58:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 18:59:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 18:59:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 18:59:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 18:59:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 18:59:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 18:59:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 18:59:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 18:59:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 18:59:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 18:59:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 18:59:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 18:59:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 18:59:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 18:59:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 18:59:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 18:59:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 18:59:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 18:59:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 18:59:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 18:59:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 18:59:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 18:59:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 18:59:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 18:59:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 18:59:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 18:59:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 18:59:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 18:59:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 18:59:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 18:59:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 18:59:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 18:59:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 18:59:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 18:59:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 18:59:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 18:59:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 18:59:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 18:59:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 18:59:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 18:59:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 18:59:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 18:59:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 18:59:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 18:59:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 18:59:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 18:59:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 18:59:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 18:59:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 18:59:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 18:59:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 18:59:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 18:59:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 18:59:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 18:59:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 18:59:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 18:59:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 18:59:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 18:59:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 18:59:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 18:59:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 18:59:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 18:59:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 18:59:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 18:59:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 18:59:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 18:59:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 18:59:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 18:59:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 18:59:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 18:59:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 18:59:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 18:59:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 18:59:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 18:59:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 18:59:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 18:59:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 18:59:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 18:59:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 18:59:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 18:59:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 18:59:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 18:59:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 18:59:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 18:59:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 18:59:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 18:59:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 18:59:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 18:59:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 18:59:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 18:59:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 18:59:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 18:59:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 18:59:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 18:59:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 18:59:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 18:59:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 18:59:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 18:59:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 18:59:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 18:59:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 18:59:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 18:59:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 18:59:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 18:59:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 18:59:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 18:59:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 18:59:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 18:59:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 18:59:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 18:59:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 18:59:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 18:59:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 18:59:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 18:59:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 18:59:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 18:59:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 18:59:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 18:59:38 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-89900a13-kafka-0 ,my-cluster-89900a13-kafka-1 ,my-cluster-89900a13-kafka-2
2022-04-05 18:59:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-89900a13-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 18:59:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 18:59:41 [main] [32mINFO [m [DynamicConfST:163] Updating listeners of Kafka cluster
2022-04-05 18:59:41 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-89900a13-kafka rolling update
2022-04-05 19:00:56 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-89900a13-kafka has been successfully rolled
2022-04-05 19:00:56 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-89900a13-kafka to be ready
2022-04-05 19:01:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-89900a13 will have desired state: Ready
2022-04-05 19:01:22 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-89900a13 is in desired state: Ready
2022-04-05 19:01:22 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-89900a13 is ready
2022-04-05 19:01:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-89900a13-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 19:01:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:01:25 [main] [32mINFO [m [DynamicConfST:380] Updating configuration of Kafka cluster
2022-04-05 19:01:25 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-89900a13-kafka are stable
2022-04-05 19:01:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 19:01:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 19:01:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 19:01:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 19:01:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 19:01:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 19:01:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 19:01:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 19:01:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 19:01:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 19:01:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 19:01:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 19:01:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 19:01:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 19:01:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 19:01:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 19:01:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 19:01:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 19:01:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 19:01:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 19:01:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 19:01:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 19:01:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 19:01:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 19:01:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 19:01:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 19:01:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 19:01:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 19:01:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 19:01:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 19:01:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 19:01:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 19:01:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 19:01:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 19:01:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 19:01:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 19:01:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 19:01:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 19:01:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 19:01:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 19:01:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 19:01:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 19:01:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 19:01:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 19:01:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 19:01:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 19:01:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 19:01:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 19:01:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 19:01:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 19:01:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 19:01:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 19:01:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 19:01:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 19:01:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 19:01:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 19:01:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 19:01:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 19:01:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 19:01:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 19:01:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 19:01:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 19:01:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 19:01:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 19:01:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 19:01:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 19:01:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 19:01:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 19:01:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 19:01:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 19:01:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 19:01:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 19:01:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 19:01:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 19:01:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 19:01:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 19:01:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 19:01:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 19:01:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 19:01:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 19:01:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 19:01:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 19:01:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 19:01:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 19:01:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 19:01:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 19:01:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 19:01:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 19:01:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 19:01:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 19:01:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 19:01:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 19:01:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 19:01:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 19:01:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 19:01:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 19:01:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 19:01:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 19:01:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 19:01:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 19:01:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 19:01:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 19:01:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 19:01:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 19:01:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 19:02:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 19:02:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 19:02:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 19:02:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 19:02:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 19:02:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 19:02:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 19:02:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 19:02:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 19:02:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 19:02:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 19:02:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 19:02:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 19:02:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 19:02:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 19:02:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 19:02:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 19:02:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 19:02:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 19:02:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 19:02:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 19:02:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 19:02:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 19:02:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 19:02:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 19:02:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 19:02:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 19:02:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 19:02:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 19:02:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 19:02:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 19:02:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 19:02:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 19:02:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 19:02:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 19:02:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 19:02:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 19:02:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 19:02:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 19:02:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 19:02:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 19:02:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 19:02:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 19:02:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 19:02:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 19:02:14 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-89900a13-kafka-0 ,my-cluster-89900a13-kafka-1 ,my-cluster-89900a13-kafka-2
2022-04-05 19:02:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-89900a13-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 19:02:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:02:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-89900a13-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 19:02:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:02:20 [main] [32mINFO [m [DynamicConfST:380] Updating configuration of Kafka cluster
2022-04-05 19:02:20 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-89900a13-kafka are stable
2022-04-05 19:02:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 19:02:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 19:02:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 19:02:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 19:02:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 19:02:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 19:02:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 19:02:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 19:02:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 19:02:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 19:02:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 19:02:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 19:02:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 19:02:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 19:02:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 19:02:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 19:02:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 19:02:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 19:02:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 19:02:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 19:02:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 19:02:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 19:02:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 19:02:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 19:02:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 19:02:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 19:02:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 19:02:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 19:02:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 19:02:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 19:02:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 19:02:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 19:02:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 19:02:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 19:02:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 19:02:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 19:02:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 19:02:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 19:02:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 19:02:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 19:02:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 19:02:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 19:02:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 19:02:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 19:02:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 19:02:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 19:02:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 19:02:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 19:02:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 19:02:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 19:02:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 19:02:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 19:02:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 19:02:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 19:02:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 19:02:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 19:02:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 19:02:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 19:02:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 19:02:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 19:02:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 19:02:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 19:02:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 19:02:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 19:02:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 19:02:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 19:02:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 19:02:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 19:02:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 19:02:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 19:02:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 19:02:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 19:02:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 19:02:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 19:02:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 19:02:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 19:02:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 19:02:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 19:02:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 19:02:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 19:02:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 19:02:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 19:02:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 19:02:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 19:02:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 19:02:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 19:02:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 19:02:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 19:02:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 19:02:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 19:02:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 19:02:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 19:02:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 19:02:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 19:02:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 19:02:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 19:02:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 19:02:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 19:02:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 19:02:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 19:02:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 19:02:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 19:02:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 19:02:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 19:02:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 19:02:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 19:02:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 19:02:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 19:02:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 19:02:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 19:02:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 19:02:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 19:02:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 19:02:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 19:02:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 19:02:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 19:02:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 19:02:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 19:02:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 19:02:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 19:03:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 19:03:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 19:03:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 19:03:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 19:03:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 19:03:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 19:03:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 19:03:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 19:03:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 19:03:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 19:03:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 19:03:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 19:03:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 19:03:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 19:03:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 19:03:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 19:03:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 19:03:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 19:03:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 19:03:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 19:03:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 19:03:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 19:03:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 19:03:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 19:03:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 19:03:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 19:03:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 19:03:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 19:03:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 19:03:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 19:03:09 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-89900a13-kafka-0 ,my-cluster-89900a13-kafka-1 ,my-cluster-89900a13-kafka-2
2022-04-05 19:03:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-89900a13-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 19:03:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:03:12 [main] [32mINFO [m [DynamicConfST:214] Updating listeners of Kafka cluster
2022-04-05 19:03:12 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-89900a13-kafka rolling update
2022-04-05 19:04:27 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-89900a13-kafka has been successfully rolled
2022-04-05 19:04:27 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-89900a13-kafka to be ready
2022-04-05 19:04:54 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-89900a13 will have desired state: Ready
2022-04-05 19:04:54 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-89900a13 is in desired state: Ready
2022-04-05 19:04:54 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-89900a13 is ready
2022-04-05 19:04:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-89900a13-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 19:04:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:04:57 [main] [32mINFO [m [DynamicConfST:380] Updating configuration of Kafka cluster
2022-04-05 19:04:57 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-89900a13-kafka are stable
2022-04-05 19:04:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 19:04:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 19:04:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 19:04:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 19:04:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 19:04:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 19:04:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 19:04:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 19:04:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 19:05:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 19:05:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 19:05:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 19:05:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 19:05:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 19:05:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 19:05:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 19:05:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 19:05:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 19:05:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 19:05:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 19:05:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 19:05:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 19:05:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 19:05:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 19:05:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 19:05:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 19:05:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 19:05:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 19:05:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 19:05:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 19:05:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 19:05:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 19:05:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 19:05:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 19:05:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 19:05:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 19:05:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 19:05:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 19:05:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 19:05:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 19:05:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 19:05:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 19:05:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 19:05:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 19:05:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 19:05:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 19:05:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 19:05:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 19:05:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 19:05:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 19:05:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 19:05:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 19:05:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 19:05:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 19:05:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 19:05:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 19:05:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 19:05:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 19:05:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 19:05:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 19:05:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 19:05:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 19:05:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 19:05:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 19:05:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 19:05:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 19:05:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 19:05:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 19:05:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 19:05:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 19:05:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 19:05:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 19:05:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 19:05:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 19:05:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 19:05:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 19:05:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 19:05:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 19:05:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 19:05:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 19:05:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 19:05:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 19:05:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 19:05:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 19:05:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 19:05:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 19:05:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 19:05:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 19:05:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 19:05:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 19:05:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 19:05:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 19:05:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 19:05:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 19:05:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 19:05:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 19:05:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 19:05:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 19:05:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 19:05:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 19:05:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 19:05:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 19:05:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 19:05:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 19:05:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 19:05:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 19:05:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 19:05:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 19:05:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 19:05:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 19:05:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 19:05:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 19:05:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 19:05:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 19:05:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 19:05:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 19:05:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 19:05:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 19:05:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 19:05:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 19:05:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 19:05:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 19:05:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 19:05:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 19:05:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 19:05:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 19:05:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 19:05:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 19:05:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 19:05:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 19:05:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 19:05:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 19:05:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 19:05:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 19:05:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 19:05:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 19:05:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 19:05:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 19:05:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 19:05:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 19:05:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 19:05:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 19:05:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 19:05:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 19:05:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 19:05:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 19:05:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 19:05:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 19:05:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 19:05:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-89900a13-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 19:05:46 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-89900a13-kafka-0 ,my-cluster-89900a13-kafka-1 ,my-cluster-89900a13-kafka-2
2022-04-05 19:05:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-89900a13-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 19:05:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:05:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:05:49 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUpdateToExternalListenerCausesRollingRestart
2022-04-05 19:05:49 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-89900a13 in namespace dynamic-conf-st
2022-04-05 19:05:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:05:59 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST.testUpdateToExternalListenerCausesRollingRestart-FINISHED
2022-04-05 19:05:59 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:05:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:05:59 [main] [32mINFO [m [ResourceManager:346] In context DynamicConfST is everything deleted.
2022-04-05 19:05:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 693.125 s - in io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST
2022-04-05 19:06:42 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: dynamic-conf-shared-st
2022-04-05 19:06:42 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: dynamic-conf-shared-st
2022-04-05 19:06:42 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: dynamic-conf-shared-st
2022-04-05 19:06:42 [main] [32mINFO [m [DynamicConfSharedST:218] Deploying shared Kafka across all test cases!
2022-04-05 19:06:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka dynamic-configuration-shared-cluster-name in namespace dynamic-conf-shared-st
2022-04-05 19:06:42 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: dynamic-configuration-shared-cluster-name will have desired state: Ready
2022-04-05 19:07:59 [main] [32mINFO [m [ResourceManager:444] Kafka: dynamic-configuration-shared-cluster-name is in desired state: Ready
2022-04-05 19:07:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:07:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.testDynConfiguration-STARTED
2022-04-05 19:07:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:334] Kafka config {advertised.listeners=io.strimzi.kafka.config.model.ConfigModel@6524332f, alter.config.policy.class.name=io.strimzi.kafka.config.model.ConfigModel@3411c1c0, alter.log.dirs.replication.quota.window.num=io.strimzi.kafka.config.model.ConfigModel@7fac6621, alter.log.dirs.replication.quota.window.size.seconds=io.strimzi.kafka.config.model.ConfigModel@207837d7, authorizer.class.name=io.strimzi.kafka.config.model.ConfigModel@6481d5bc, auto.create.topics.enable=io.strimzi.kafka.config.model.ConfigModel@5e24172d, auto.leader.rebalance.enable=io.strimzi.kafka.config.model.ConfigModel@4225efa6, background.threads=io.strimzi.kafka.config.model.ConfigModel@2382beba, broker.heartbeat.interval.ms=io.strimzi.kafka.config.model.ConfigModel@4944b343, broker.id=io.strimzi.kafka.config.model.ConfigModel@37a75839, broker.id.generation.enable=io.strimzi.kafka.config.model.ConfigModel@5a12d9b4, broker.rack=io.strimzi.kafka.config.model.ConfigModel@6cd3db22, broker.session.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@61a350, client.quota.callback.class=io.strimzi.kafka.config.model.ConfigModel@d0a55f5, compression.type=io.strimzi.kafka.config.model.ConfigModel@4199f299, connection.failed.authentication.delay.ms=io.strimzi.kafka.config.model.ConfigModel@33613b43, connections.max.idle.ms=io.strimzi.kafka.config.model.ConfigModel@3e17755c, connections.max.reauth.ms=io.strimzi.kafka.config.model.ConfigModel@61ed3a96, control.plane.listener.name=io.strimzi.kafka.config.model.ConfigModel@6f6e1108, controlled.shutdown.enable=io.strimzi.kafka.config.model.ConfigModel@556f8485, controlled.shutdown.max.retries=io.strimzi.kafka.config.model.ConfigModel@50d7b6e1, controlled.shutdown.retry.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@58661fe7, controller.listener.names=io.strimzi.kafka.config.model.ConfigModel@479fa3b2, controller.quorum.append.linger.ms=io.strimzi.kafka.config.model.ConfigModel@6e7d4c68, controller.quorum.election.backoff.max.ms=io.strimzi.kafka.config.model.ConfigModel@3708ff8, controller.quorum.election.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@6b812156, controller.quorum.fetch.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@51b98da7, controller.quorum.request.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@55a395f4, controller.quorum.retry.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@52abdff7, controller.quota.window.num=io.strimzi.kafka.config.model.ConfigModel@30c2cf65, controller.quota.window.size.seconds=io.strimzi.kafka.config.model.ConfigModel@2d8bb86f, controller.socket.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@64ce841f, create.topic.policy.class.name=io.strimzi.kafka.config.model.ConfigModel@6896bb16, default.replication.factor=io.strimzi.kafka.config.model.ConfigModel@4e89e886, delegation.token.expiry.check.interval.ms=io.strimzi.kafka.config.model.ConfigModel@3eb179f8, delegation.token.expiry.time.ms=io.strimzi.kafka.config.model.ConfigModel@2e4ffc4d, delegation.token.master.key=io.strimzi.kafka.config.model.ConfigModel@73dcac99, delegation.token.max.lifetime.ms=io.strimzi.kafka.config.model.ConfigModel@7290b7bc, delegation.token.secret.key=io.strimzi.kafka.config.model.ConfigModel@47db6eaf, delete.records.purgatory.purge.interval.requests=io.strimzi.kafka.config.model.ConfigModel@16a74f8d, delete.topic.enable=io.strimzi.kafka.config.model.ConfigModel@8991a4, fetch.max.bytes=io.strimzi.kafka.config.model.ConfigModel@77d3fb5e, fetch.purgatory.purge.interval.requests=io.strimzi.kafka.config.model.ConfigModel@6b615d1d, group.initial.rebalance.delay.ms=io.strimzi.kafka.config.model.ConfigModel@4796bcdb, group.max.session.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@b5e113c, group.max.size=io.strimzi.kafka.config.model.ConfigModel@633f1202, group.min.session.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@25722cd, initial.broker.registration.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@70552638, inter.broker.listener.name=io.strimzi.kafka.config.model.ConfigModel@b791eff, inter.broker.protocol.version=io.strimzi.kafka.config.model.ConfigModel@104db290, kafka.metrics.polling.interval.secs=io.strimzi.kafka.config.model.ConfigModel@2b37ab1e, kafka.metrics.reporters=io.strimzi.kafka.config.model.ConfigModel@720a3ca6, leader.imbalance.check.interval.seconds=io.strimzi.kafka.config.model.ConfigModel@31474afe, leader.imbalance.per.broker.percentage=io.strimzi.kafka.config.model.ConfigModel@4c63a774, listener.security.protocol.map=io.strimzi.kafka.config.model.ConfigModel@5a1a8abd, listeners=io.strimzi.kafka.config.model.ConfigModel@79567254, log.cleaner.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@724dd73a, log.cleaner.dedupe.buffer.size=io.strimzi.kafka.config.model.ConfigModel@23c48600, log.cleaner.delete.retention.ms=io.strimzi.kafka.config.model.ConfigModel@2d85bfa7, log.cleaner.enable=io.strimzi.kafka.config.model.ConfigModel@678bbc91, log.cleaner.io.buffer.load.factor=io.strimzi.kafka.config.model.ConfigModel@7b63435d, log.cleaner.io.buffer.size=io.strimzi.kafka.config.model.ConfigModel@7c103eb7, log.cleaner.io.max.bytes.per.second=io.strimzi.kafka.config.model.ConfigModel@7ce8de15, log.cleaner.max.compaction.lag.ms=io.strimzi.kafka.config.model.ConfigModel@46bd8a2d, log.cleaner.min.cleanable.ratio=io.strimzi.kafka.config.model.ConfigModel@27a5500c, log.cleaner.min.compaction.lag.ms=io.strimzi.kafka.config.model.ConfigModel@5a3d37c9, log.cleaner.threads=io.strimzi.kafka.config.model.ConfigModel@601f52ed, log.cleanup.policy=io.strimzi.kafka.config.model.ConfigModel@4a595021, log.dir=io.strimzi.kafka.config.model.ConfigModel@47715c56, log.dirs=io.strimzi.kafka.config.model.ConfigModel@7441b80e, log.flush.interval.messages=io.strimzi.kafka.config.model.ConfigModel@6e530451, log.flush.interval.ms=io.strimzi.kafka.config.model.ConfigModel@6e8b99e2, log.flush.offset.checkpoint.interval.ms=io.strimzi.kafka.config.model.ConfigModel@2355fb89, log.flush.scheduler.interval.ms=io.strimzi.kafka.config.model.ConfigModel@5aada625, log.flush.start.offset.checkpoint.interval.ms=io.strimzi.kafka.config.model.ConfigModel@2caa40ad, log.index.interval.bytes=io.strimzi.kafka.config.model.ConfigModel@1e5c9853, log.index.size.max.bytes=io.strimzi.kafka.config.model.ConfigModel@12d9a1a2, log.message.downconversion.enable=io.strimzi.kafka.config.model.ConfigModel@25f2b152, log.message.format.version=io.strimzi.kafka.config.model.ConfigModel@5ba32269, log.message.timestamp.difference.max.ms=io.strimzi.kafka.config.model.ConfigModel@21c7b74e, log.message.timestamp.type=io.strimzi.kafka.config.model.ConfigModel@7eccc665, log.preallocate=io.strimzi.kafka.config.model.ConfigModel@4e8490cf, log.retention.bytes=io.strimzi.kafka.config.model.ConfigModel@c76431c, log.retention.check.interval.ms=io.strimzi.kafka.config.model.ConfigModel@1097f81b, log.retention.hours=io.strimzi.kafka.config.model.ConfigModel@870fb82, log.retention.minutes=io.strimzi.kafka.config.model.ConfigModel@621800ab, log.retention.ms=io.strimzi.kafka.config.model.ConfigModel@5cc8d157, log.roll.hours=io.strimzi.kafka.config.model.ConfigModel@73b0adf5, log.roll.jitter.hours=io.strimzi.kafka.config.model.ConfigModel@7c13e4ea, log.roll.jitter.ms=io.strimzi.kafka.config.model.ConfigModel@5e2cae9b, log.roll.ms=io.strimzi.kafka.config.model.ConfigModel@44748e60, log.segment.bytes=io.strimzi.kafka.config.model.ConfigModel@325d5c1e, log.segment.delete.delay.ms=io.strimzi.kafka.config.model.ConfigModel@518aca0b, max.connection.creation.rate=io.strimzi.kafka.config.model.ConfigModel@6ae9eed7, max.connections=io.strimzi.kafka.config.model.ConfigModel@a0e6a64, max.connections.per.ip=io.strimzi.kafka.config.model.ConfigModel@52eb6a97, max.connections.per.ip.overrides=io.strimzi.kafka.config.model.ConfigModel@55363853, max.incremental.fetch.session.cache.slots=io.strimzi.kafka.config.model.ConfigModel@708ceb74, message.max.bytes=io.strimzi.kafka.config.model.ConfigModel@928e24b, metadata.log.dir=io.strimzi.kafka.config.model.ConfigModel@1e8e2b, metadata.log.max.record.bytes.between.snapshots=io.strimzi.kafka.config.model.ConfigModel@648ecadb, metadata.log.segment.bytes=io.strimzi.kafka.config.model.ConfigModel@73ce4a75, metadata.log.segment.min.bytes=io.strimzi.kafka.config.model.ConfigModel@3dbac4fd, metadata.log.segment.ms=io.strimzi.kafka.config.model.ConfigModel@49a17ab7, metadata.max.retention.bytes=io.strimzi.kafka.config.model.ConfigModel@5bebb94a, metadata.max.retention.ms=io.strimzi.kafka.config.model.ConfigModel@5a77dda0, metric.reporters=io.strimzi.kafka.config.model.ConfigModel@3101773f, metrics.num.samples=io.strimzi.kafka.config.model.ConfigModel@7337c76a, metrics.recording.level=io.strimzi.kafka.config.model.ConfigModel@759001af, metrics.sample.window.ms=io.strimzi.kafka.config.model.ConfigModel@116e5860, min.insync.replicas=io.strimzi.kafka.config.model.ConfigModel@2bec7dfd, node.id=io.strimzi.kafka.config.model.ConfigModel@662df37d, num.io.threads=io.strimzi.kafka.config.model.ConfigModel@13c51b6e, num.network.threads=io.strimzi.kafka.config.model.ConfigModel@708bec2e, num.partitions=io.strimzi.kafka.config.model.ConfigModel@38406457, num.recovery.threads.per.data.dir=io.strimzi.kafka.config.model.ConfigModel@31ffce39, num.replica.alter.log.dirs.threads=io.strimzi.kafka.config.model.ConfigModel@adabd03, num.replica.fetchers=io.strimzi.kafka.config.model.ConfigModel@259fcaea, offset.metadata.max.bytes=io.strimzi.kafka.config.model.ConfigModel@1ec660d2, offsets.commit.required.acks=io.strimzi.kafka.config.model.ConfigModel@5187fb35, offsets.commit.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@e6a66a3, offsets.load.buffer.size=io.strimzi.kafka.config.model.ConfigModel@55f9251e, offsets.retention.check.interval.ms=io.strimzi.kafka.config.model.ConfigModel@78940f83, offsets.retention.minutes=io.strimzi.kafka.config.model.ConfigModel@16a40df7, offsets.topic.compression.codec=io.strimzi.kafka.config.model.ConfigModel@4b262efe, offsets.topic.num.partitions=io.strimzi.kafka.config.model.ConfigModel@57eb3351, offsets.topic.replication.factor=io.strimzi.kafka.config.model.ConfigModel@fdbd638, offsets.topic.segment.bytes=io.strimzi.kafka.config.model.ConfigModel@3926a981, password.encoder.cipher.algorithm=io.strimzi.kafka.config.model.ConfigModel@438d2185, password.encoder.iterations=io.strimzi.kafka.config.model.ConfigModel@4d72f31e, password.encoder.key.length=io.strimzi.kafka.config.model.ConfigModel@1cc9869e, password.encoder.keyfactory.algorithm=io.strimzi.kafka.config.model.ConfigModel@10af5e27, password.encoder.old.secret=io.strimzi.kafka.config.model.ConfigModel@3a84c4be, password.encoder.secret=io.strimzi.kafka.config.model.ConfigModel@60b42af3, principal.builder.class=io.strimzi.kafka.config.model.ConfigModel@3099bd0d, process.roles=io.strimzi.kafka.config.model.ConfigModel@5a2d835f, producer.purgatory.purge.interval.requests=io.strimzi.kafka.config.model.ConfigModel@46900d90, queued.max.request.bytes=io.strimzi.kafka.config.model.ConfigModel@7324403, queued.max.requests=io.strimzi.kafka.config.model.ConfigModel@7abef03d, quota.window.num=io.strimzi.kafka.config.model.ConfigModel@4c3fb34e, quota.window.size.seconds=io.strimzi.kafka.config.model.ConfigModel@a85dbd4, remote.log.index.file.cache.total.size.bytes=io.strimzi.kafka.config.model.ConfigModel@1f8284db, remote.log.manager.task.interval.ms=io.strimzi.kafka.config.model.ConfigModel@1230b00e, remote.log.manager.task.retry.backoff.max.ms=io.strimzi.kafka.config.model.ConfigModel@23a4d4c5, remote.log.manager.task.retry.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@75bf01e, remote.log.manager.task.retry.jitter=io.strimzi.kafka.config.model.ConfigModel@c741872, remote.log.manager.thread.pool.size=io.strimzi.kafka.config.model.ConfigModel@1b536932, remote.log.metadata.manager.class.name=io.strimzi.kafka.config.model.ConfigModel@1e548461, remote.log.metadata.manager.class.path=io.strimzi.kafka.config.model.ConfigModel@46d74cb5, remote.log.metadata.manager.impl.prefix=io.strimzi.kafka.config.model.ConfigModel@6acc6b95, remote.log.metadata.manager.listener.name=io.strimzi.kafka.config.model.ConfigModel@6ad68507, remote.log.reader.max.pending.tasks=io.strimzi.kafka.config.model.ConfigModel@509b73b0, remote.log.reader.threads=io.strimzi.kafka.config.model.ConfigModel@2c552ff2, remote.log.storage.manager.class.name=io.strimzi.kafka.config.model.ConfigModel@25cc792e, remote.log.storage.manager.class.path=io.strimzi.kafka.config.model.ConfigModel@7bec3e2d, remote.log.storage.manager.impl.prefix=io.strimzi.kafka.config.model.ConfigModel@7061d413, remote.log.storage.system.enable=io.strimzi.kafka.config.model.ConfigModel@75ce4f52, replica.fetch.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@338d5dcc, replica.fetch.max.bytes=io.strimzi.kafka.config.model.ConfigModel@290a00c6, replica.fetch.min.bytes=io.strimzi.kafka.config.model.ConfigModel@57b588b8, replica.fetch.response.max.bytes=io.strimzi.kafka.config.model.ConfigModel@5086e9c3, replica.fetch.wait.max.ms=io.strimzi.kafka.config.model.ConfigModel@93cad22, replica.high.watermark.checkpoint.interval.ms=io.strimzi.kafka.config.model.ConfigModel@704990f3, replica.lag.time.max.ms=io.strimzi.kafka.config.model.ConfigModel@b42260a, replica.selector.class=io.strimzi.kafka.config.model.ConfigModel@6c6d0e50, replica.socket.receive.buffer.bytes=io.strimzi.kafka.config.model.ConfigModel@d4eb42, replica.socket.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@3c263da3, replication.quota.window.num=io.strimzi.kafka.config.model.ConfigModel@26ce2e5b, replication.quota.window.size.seconds=io.strimzi.kafka.config.model.ConfigModel@22d5bb5c, request.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@57ccabf, reserved.broker.max.id=io.strimzi.kafka.config.model.ConfigModel@83a2496, sasl.client.callback.handler.class=io.strimzi.kafka.config.model.ConfigModel@5fd17f3c, sasl.enabled.mechanisms=io.strimzi.kafka.config.model.ConfigModel@505130c1, sasl.jaas.config=io.strimzi.kafka.config.model.ConfigModel@339b2146, sasl.kerberos.kinit.cmd=io.strimzi.kafka.config.model.ConfigModel@6adcbd37, sasl.kerberos.min.time.before.relogin=io.strimzi.kafka.config.model.ConfigModel@3ea017cf, sasl.kerberos.principal.to.local.rules=io.strimzi.kafka.config.model.ConfigModel@67aeefe2, sasl.kerberos.service.name=io.strimzi.kafka.config.model.ConfigModel@d556340, sasl.kerberos.ticket.renew.jitter=io.strimzi.kafka.config.model.ConfigModel@26f52d8, sasl.kerberos.ticket.renew.window.factor=io.strimzi.kafka.config.model.ConfigModel@3ccf2335, sasl.login.callback.handler.class=io.strimzi.kafka.config.model.ConfigModel@2c0e1ab1, sasl.login.class=io.strimzi.kafka.config.model.ConfigModel@ae72313, sasl.login.connect.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@72664905, sasl.login.read.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@37751af7, sasl.login.refresh.buffer.seconds=io.strimzi.kafka.config.model.ConfigModel@6b72453a, sasl.login.refresh.min.period.seconds=io.strimzi.kafka.config.model.ConfigModel@58be0cfc, sasl.login.refresh.window.factor=io.strimzi.kafka.config.model.ConfigModel@18d0488f, sasl.login.refresh.window.jitter=io.strimzi.kafka.config.model.ConfigModel@76d4bc0, sasl.login.retry.backoff.max.ms=io.strimzi.kafka.config.model.ConfigModel@7ecf8582, sasl.login.retry.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@56beaf4b, sasl.mechanism.controller.protocol=io.strimzi.kafka.config.model.ConfigModel@4cb00123, sasl.mechanism.inter.broker.protocol=io.strimzi.kafka.config.model.ConfigModel@21ee603e, sasl.oauthbearer.clock.skew.seconds=io.strimzi.kafka.config.model.ConfigModel@238f0214, sasl.oauthbearer.expected.audience=io.strimzi.kafka.config.model.ConfigModel@e835d9, sasl.oauthbearer.expected.issuer=io.strimzi.kafka.config.model.ConfigModel@4c1d85fe, sasl.oauthbearer.jwks.endpoint.refresh.ms=io.strimzi.kafka.config.model.ConfigModel@1e20e3d3, sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms=io.strimzi.kafka.config.model.ConfigModel@45e4dda1, sasl.oauthbearer.jwks.endpoint.retry.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@4636e39, sasl.oauthbearer.jwks.endpoint.url=io.strimzi.kafka.config.model.ConfigModel@2471393e, sasl.oauthbearer.scope.claim.name=io.strimzi.kafka.config.model.ConfigModel@3d566818, sasl.oauthbearer.sub.claim.name=io.strimzi.kafka.config.model.ConfigModel@5e3ca3c6, sasl.oauthbearer.token.endpoint.url=io.strimzi.kafka.config.model.ConfigModel@41b10c9e, sasl.server.callback.handler.class=io.strimzi.kafka.config.model.ConfigModel@6c24755f, security.inter.broker.protocol=io.strimzi.kafka.config.model.ConfigModel@623cc66b, security.providers=io.strimzi.kafka.config.model.ConfigModel@59257b79, socket.connection.setup.timeout.max.ms=io.strimzi.kafka.config.model.ConfigModel@1039593f, socket.connection.setup.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@5ff848ea, socket.receive.buffer.bytes=io.strimzi.kafka.config.model.ConfigModel@5b73c2e0, socket.request.max.bytes=io.strimzi.kafka.config.model.ConfigModel@29ff8444, socket.send.buffer.bytes=io.strimzi.kafka.config.model.ConfigModel@7355d0e5, ssl.cipher.suites=io.strimzi.kafka.config.model.ConfigModel@6ef7797d, ssl.client.auth=io.strimzi.kafka.config.model.ConfigModel@2b56d281, ssl.enabled.protocols=io.strimzi.kafka.config.model.ConfigModel@7e5ebe0b, ssl.endpoint.identification.algorithm=io.strimzi.kafka.config.model.ConfigModel@23519bdd, ssl.engine.factory.class=io.strimzi.kafka.config.model.ConfigModel@76b8225b, ssl.key.password=io.strimzi.kafka.config.model.ConfigModel@6b6734d7, ssl.keymanager.algorithm=io.strimzi.kafka.config.model.ConfigModel@60427156, ssl.keystore.certificate.chain=io.strimzi.kafka.config.model.ConfigModel@4fe291f0, ssl.keystore.key=io.strimzi.kafka.config.model.ConfigModel@78ffd8ad, ssl.keystore.location=io.strimzi.kafka.config.model.ConfigModel@2a6c9ae9, ssl.keystore.password=io.strimzi.kafka.config.model.ConfigModel@59579633, ssl.keystore.type=io.strimzi.kafka.config.model.ConfigModel@2e1f1f8, ssl.principal.mapping.rules=io.strimzi.kafka.config.model.ConfigModel@45d7bb9, ssl.protocol=io.strimzi.kafka.config.model.ConfigModel@4aa80209, ssl.provider=io.strimzi.kafka.config.model.ConfigModel@2f2bf361, ssl.secure.random.implementation=io.strimzi.kafka.config.model.ConfigModel@2248b94d, ssl.trustmanager.algorithm=io.strimzi.kafka.config.model.ConfigModel@4da79e0e, ssl.truststore.certificates=io.strimzi.kafka.config.model.ConfigModel@479575f9, ssl.truststore.location=io.strimzi.kafka.config.model.ConfigModel@37d53691, ssl.truststore.password=io.strimzi.kafka.config.model.ConfigModel@50b073f7, ssl.truststore.type=io.strimzi.kafka.config.model.ConfigModel@2116c001, transaction.abort.timed.out.transaction.cleanup.interval.ms=io.strimzi.kafka.config.model.ConfigModel@4dc05367, transaction.max.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@53bf85f0, transaction.remove.expired.transaction.cleanup.interval.ms=io.strimzi.kafka.config.model.ConfigModel@436bbb, transaction.state.log.load.buffer.size=io.strimzi.kafka.config.model.ConfigModel@1742a57a, transaction.state.log.min.isr=io.strimzi.kafka.config.model.ConfigModel@5856879e, transaction.state.log.num.partitions=io.strimzi.kafka.config.model.ConfigModel@77690961, transaction.state.log.replication.factor=io.strimzi.kafka.config.model.ConfigModel@6cecaa84, transaction.state.log.segment.bytes=io.strimzi.kafka.config.model.ConfigModel@6e07ab16, transactional.id.expiration.ms=io.strimzi.kafka.config.model.ConfigModel@201bb3f, unclean.leader.election.enable=io.strimzi.kafka.config.model.ConfigModel@3d1c981f, zookeeper.clientCnxnSocket=io.strimzi.kafka.config.model.ConfigModel@342dadb2, zookeeper.connect=io.strimzi.kafka.config.model.ConfigModel@6721ff3a, zookeeper.connection.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@68f678a2, zookeeper.max.in.flight.requests=io.strimzi.kafka.config.model.ConfigModel@31f3d9c3, zookeeper.session.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@686aa272, zookeeper.set.acl=io.strimzi.kafka.config.model.ConfigModel@5a486a, zookeeper.ssl.cipher.suites=io.strimzi.kafka.config.model.ConfigModel@5b3213ab, zookeeper.ssl.client.enable=io.strimzi.kafka.config.model.ConfigModel@74a0e4cf, zookeeper.ssl.crl.enable=io.strimzi.kafka.config.model.ConfigModel@4964b11b, zookeeper.ssl.enabled.protocols=io.strimzi.kafka.config.model.ConfigModel@1bafb945, zookeeper.ssl.endpoint.identification.algorithm=io.strimzi.kafka.config.model.ConfigModel@50cb4ed0, zookeeper.ssl.keystore.location=io.strimzi.kafka.config.model.ConfigModel@23be5e9a, zookeeper.ssl.keystore.password=io.strimzi.kafka.config.model.ConfigModel@4f3ecf9f, zookeeper.ssl.keystore.type=io.strimzi.kafka.config.model.ConfigModel@29bd22ac, zookeeper.ssl.ocsp.enable=io.strimzi.kafka.config.model.ConfigModel@230a5485, zookeeper.ssl.protocol=io.strimzi.kafka.config.model.ConfigModel@721194f0, zookeeper.ssl.truststore.location=io.strimzi.kafka.config.model.ConfigModel@4b6aef1a, zookeeper.ssl.truststore.password=io.strimzi.kafka.config.model.ConfigModel@b020c99, zookeeper.ssl.truststore.type=io.strimzi.kafka.config.model.ConfigModel@7addcf00, zookeeper.sync.time.ms=io.strimzi.kafka.config.model.ConfigModel@49572bf}
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:336] Number of all kafka configs 261
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:356] Number of dynamic-configs 40
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:364] Number of forbidden-exception-configs 7
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:371] Size of dynamic-configs with forbidden-exception-configs 46
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] compression.type -> CLUSTER_WIDE:STRING
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.min.compaction.lag.ms -> CLUSTER_WIDE:LONG
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] log.retention.ms -> CLUSTER_WIDE:LONG
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] max.connections.per.ip.overrides -> CLUSTER_WIDE:STRING
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] metric.reporters -> CLUSTER_WIDE:LIST
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] log.flush.interval.messages -> CLUSTER_WIDE:LONG
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] log.message.timestamp.difference.max.ms -> CLUSTER_WIDE:LONG
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] log.flush.interval.ms -> CLUSTER_WIDE:LONG
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] principal.builder.class -> PER_BROKER:CLASS
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.delete.retention.ms -> CLUSTER_WIDE:LONG
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.io.buffer.size -> CLUSTER_WIDE:INT
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] min.insync.replicas -> CLUSTER_WIDE:INT
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] zookeeper.connection.timeout.ms -> READ_ONLY:INT
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.threads -> CLUSTER_WIDE:INT
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.io.max.bytes.per.second -> CLUSTER_WIDE:DOUBLE
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.min.cleanable.ratio -> CLUSTER_WIDE:DOUBLE
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] num.recovery.threads.per.data.dir -> CLUSTER_WIDE:INT
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] log.retention.bytes -> CLUSTER_WIDE:LONG
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] num.network.threads -> CLUSTER_WIDE:INT
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] log.cleanup.policy -> CLUSTER_WIDE:LIST
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] log.message.timestamp.type -> CLUSTER_WIDE:STRING
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] log.preallocate -> CLUSTER_WIDE:BOOLEAN
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] log.roll.jitter.ms -> CLUSTER_WIDE:LONG
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] max.connections -> CLUSTER_WIDE:INT
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] max.connections.per.ip -> CLUSTER_WIDE:INT
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] background.threads -> CLUSTER_WIDE:INT
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] log.message.downconversion.enable -> CLUSTER_WIDE:BOOLEAN
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] message.max.bytes -> CLUSTER_WIDE:INT
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] ssl.protocol -> PER_BROKER:STRING
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] num.partitions -> READ_ONLY:INT
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] num.io.threads -> CLUSTER_WIDE:INT
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] ssl.enabled.protocols -> PER_BROKER:LIST
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] max.connection.creation.rate -> CLUSTER_WIDE:INT
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] log.roll.ms -> CLUSTER_WIDE:LONG
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] ssl.cipher.suites -> PER_BROKER:LIST
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] unclean.leader.election.enable -> CLUSTER_WIDE:BOOLEAN
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] log.index.interval.bytes -> CLUSTER_WIDE:INT
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.backoff.ms -> CLUSTER_WIDE:LONG
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] log.segment.bytes -> CLUSTER_WIDE:INT
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.io.buffer.load.factor -> CLUSTER_WIDE:DOUBLE
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] log.index.size.max.bytes -> CLUSTER_WIDE:INT
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] zookeeper.connect -> READ_ONLY:STRING
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] log.segment.delete.delay.ms -> CLUSTER_WIDE:LONG
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.max.compaction.lag.ms -> CLUSTER_WIDE:LONG
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] num.replica.fetchers -> CLUSTER_WIDE:INT
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.dedupe.buffer.size -> CLUSTER_WIDE:LONG
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:234] Kafka config before updating '{default.replication.factor=3, inter.broker.protocol.version=3.1, log.message.format.version=3.1, min.insync.replicas=2, offsets.topic.replication.factor=3, transaction.state.log.min.isr=2, transaction.state.log.replication.factor=3}'
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:238] Kafka config after updating '{default.replication.factor=3, inter.broker.protocol.version=3.1, log.message.format.version=3.1, min.insync.replicas=2, offsets.topic.replication.factor=3, transaction.state.log.min.isr=2, transaction.state.log.replication.factor=3, log.cleaner.min.cleanable.ratio=0.7411688846957893}'
2022-04-05 19:07:59 [main] [32mINFO [m [KafkaUtils:180] Waiting for cluster stability
2022-04-05 19:09:00 [main] [32mINFO [m [KafkaUtils:208] Kafka cluster is stable after 61 polls.
2022-04-05 19:09:00 [main] [32mINFO [m [KafkaUtils:262] Dynamic Configuration in Kafka CR is log.cleaner.min.cleanable.ratio=0.7411688846957893 and expected is log.cleaner.min.cleanable.ratio=0.7411688846957893
2022-04-05 19:09:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 19:09:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:09:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-1 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 19:09:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:09:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-2 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 19:09:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:09:09 [main] [32mINFO [m [KafkaUtils:234] Kafka config before updating '{default.replication.factor=3, inter.broker.protocol.version=3.1, log.cleaner.min.cleanable.ratio=0.7411688846957893, log.message.format.version=3.1, min.insync.replicas=2, offsets.topic.replication.factor=3, transaction.state.log.min.isr=2, transaction.state.log.replication.factor=3}'
2022-04-05 19:09:09 [main] [32mINFO [m [KafkaUtils:238] Kafka config after updating '{default.replication.factor=3, inter.broker.protocol.version=3.1, log.cleaner.min.cleanable.ratio=0.7411688846957893, log.message.format.version=3.1, min.insync.replicas=2, offsets.topic.replication.factor=3, transaction.state.log.min.isr=2, transaction.state.log.replication.factor=3, max.connections=7}'
2022-04-05 19:09:09 [main] [32mINFO [m [KafkaUtils:180] Waiting for cluster stability
2022-04-05 19:10:11 [main] [32mINFO [m [KafkaUtils:208] Kafka cluster is stable after 61 polls.
2022-04-05 19:10:11 [main] [32mINFO [m [KafkaUtils:262] Dynamic Configuration in Kafka CR is max.connections=7 and expected is max.connections=7
2022-04-05 19:11:43 [main] [32mINFO [m [Exec:417] Failed to exec command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 19:11:43 [main] [32mINFO [m [Exec:417] Return code: 1
2022-04-05 19:11:43 [main] [32mINFO [m [Exec:417] ======STDOUT START=======
2022-04-05 19:11:43 [main] [32mINFO [m [Exec:417] Dynamic configs for broker 0 are:
2022-04-05 19:11:43 [main] [32mINFO [m [Exec:417] ======STDOUT END======
2022-04-05 19:11:43 [main] [32mINFO [m [Exec:417] ======STDERR START=======
2022-04-05 19:11:43 [main] [32mINFO [m [Exec:417] Error while executing config command with args '--bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe'
java.util.concurrent.TimeoutException
	at java.base/java.util.concurrent.CompletableFuture.timedGet(CompletableFuture.java:1886)
	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2021)
	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:180)
	at kafka.admin.ConfigCommand$.getResourceConfig(ConfigCommand.scala:577)
	at kafka.admin.ConfigCommand$.$anonfun$describeResourceConfig$4(ConfigCommand.scala:537)
	at kafka.admin.ConfigCommand$.$anonfun$describeResourceConfig$4$adapted(ConfigCommand.scala:529)
	at scala.collection.immutable.List.foreach(List.scala:333)
	at kafka.admin.ConfigCommand$.describeResourceConfig(ConfigCommand.scala:529)
	at kafka.admin.ConfigCommand$.describeConfig(ConfigCommand.scala:509)
	at kafka.admin.ConfigCommand$.processCommand(ConfigCommand.scala:329)
	at kafka.admin.ConfigCommand$.main(ConfigCommand.scala:98)
	at kafka.admin.ConfigCommand.main(ConfigCommand.scala)
command terminated with exit code 1
2022-04-05 19:11:43 [main] [32mINFO [m [Exec:417] ======STDERR END======
io.strimzi.test.WaitException: Timeout after 40000 ms waiting for Wait until dyn.configuration is changed
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils.verifyPodDynamicConfiguration(KafkaUtils.java:287)
	at io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.lambda$testDynConfiguration$0(DynamicConfSharedST.java:69)
	at org.junit.jupiter.engine.descriptor.DynamicTestTestDescriptor.lambda$execute$0(DynamicTestTestDescriptor.java:53)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.api.extension.InvocationInterceptor.interceptDynamicTest(InvocationInterceptor.java:167)
	at org.junit.jupiter.api.extension.InvocationInterceptor.interceptDynamicTest(InvocationInterceptor.java:184)
	at org.junit.jupiter.engine.descriptor.DynamicTestTestDescriptor.lambda$execute$1(DynamicTestTestDescriptor.java:61)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptorCall.lambda$ofVoid$0(InvocationInterceptorChain.java:78)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.descriptor.DynamicTestTestDescriptor.execute(DynamicTestTestDescriptor.java:60)
	at org.junit.jupiter.engine.descriptor.DynamicTestTestDescriptor.execute(DynamicTestTestDescriptor.java:32)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:226)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:204)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.junit.jupiter.engine.descriptor.TestFactoryTestDescriptor.lambda$invokeTestMethod$1(TestFactoryTestDescriptor.java:108)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestFactoryTestDescriptor.invokeTestMethod(TestFactoryTestDescriptor.java:95)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-05 19:11:43 [main] [32mINFO [m [KafkaUtils:234] Kafka config before updating '{default.replication.factor=3, inter.broker.protocol.version=3.1, log.cleaner.min.cleanable.ratio=0.7411688846957893, log.message.format.version=3.1, max.connections=7, min.insync.replicas=2, offsets.topic.replication.factor=3, transaction.state.log.min.isr=2, transaction.state.log.replication.factor=3}'
2022-04-05 19:11:43 [main] [32mINFO [m [KafkaUtils:238] Kafka config after updating '{default.replication.factor=3, inter.broker.protocol.version=3.1, log.cleaner.min.cleanable.ratio=0.7411688846957893, log.message.format.version=3.1, max.connections=7, min.insync.replicas=2, offsets.topic.replication.factor=3, transaction.state.log.min.isr=2, transaction.state.log.replication.factor=3, log.cleaner.io.buffer.load.factor=17.46268825570648}'
2022-04-05 19:11:43 [main] [32mINFO [m [KafkaUtils:180] Waiting for cluster stability
2022-04-05 19:12:45 [main] [32mINFO [m [KafkaUtils:208] Kafka cluster is stable after 61 polls.
2022-04-05 19:12:45 [main] [32mINFO [m [KafkaUtils:262] Dynamic Configuration in Kafka CR is log.cleaner.io.buffer.load.factor=17.46268825570648 and expected is log.cleaner.io.buffer.load.factor=17.46268825570648
2022-04-05 19:14:17 [main] [32mINFO [m [Exec:417] Failed to exec command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 19:14:17 [main] [32mINFO [m [Exec:417] Return code: 1
2022-04-05 19:14:17 [main] [32mINFO [m [Exec:417] ======STDOUT START=======
2022-04-05 19:14:17 [main] [32mINFO [m [Exec:417] Dynamic configs for broker 0 are:
2022-04-05 19:14:17 [main] [32mINFO [m [Exec:417] ======STDOUT END======
2022-04-05 19:14:17 [main] [32mINFO [m [Exec:417] ======STDERR START=======
2022-04-05 19:14:17 [main] [32mINFO [m [Exec:417] Error while executing config command with args '--bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe'
java.util.concurrent.TimeoutException
	at java.base/java.util.concurrent.CompletableFuture.timedGet(CompletableFuture.java:1886)
	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2021)
	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:180)
	at kafka.admin.ConfigCommand$.getResourceConfig(ConfigCommand.scala:577)
	at kafka.admin.ConfigCommand$.$anonfun$describeResourceConfig$4(ConfigCommand.scala:537)
	at kafka.admin.ConfigCommand$.$anonfun$describeResourceConfig$4$adapted(ConfigCommand.scala:529)
	at scala.collection.immutable.List.foreach(List.scala:333)
	at kafka.admin.ConfigCommand$.describeResourceConfig(ConfigCommand.scala:529)
	at kafka.admin.ConfigCommand$.describeConfig(ConfigCommand.scala:509)
	at kafka.admin.ConfigCommand$.processCommand(ConfigCommand.scala:329)
	at kafka.admin.ConfigCommand$.main(ConfigCommand.scala:98)
	at kafka.admin.ConfigCommand.main(ConfigCommand.scala)
command terminated with exit code 1
2022-04-05 19:14:17 [main] [32mINFO [m [Exec:417] ======STDERR END======
io.strimzi.test.WaitException: Timeout after 40000 ms waiting for Wait until dyn.configuration is changed
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils.verifyPodDynamicConfiguration(KafkaUtils.java:287)
	at io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.lambda$testDynConfiguration$0(DynamicConfSharedST.java:69)
	at org.junit.jupiter.engine.descriptor.DynamicTestTestDescriptor.lambda$execute$0(DynamicTestTestDescriptor.java:53)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.api.extension.InvocationInterceptor.interceptDynamicTest(InvocationInterceptor.java:167)
	at org.junit.jupiter.api.extension.InvocationInterceptor.interceptDynamicTest(InvocationInterceptor.java:184)
	at org.junit.jupiter.engine.descriptor.DynamicTestTestDescriptor.lambda$execute$1(DynamicTestTestDescriptor.java:61)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptorCall.lambda$ofVoid$0(InvocationInterceptorChain.java:78)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.descriptor.DynamicTestTestDescriptor.execute(DynamicTestTestDescriptor.java:60)
	at org.junit.jupiter.engine.descriptor.DynamicTestTestDescriptor.execute(DynamicTestTestDescriptor.java:32)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:226)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:204)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.junit.jupiter.engine.descriptor.TestFactoryTestDescriptor.lambda$invokeTestMethod$1(TestFactoryTestDescriptor.java:108)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestFactoryTestDescriptor.invokeTestMethod(TestFactoryTestDescriptor.java:95)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-05 19:14:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:14:17 [main] [32mINFO [m [ResourceManager:346] In context testDynConfiguration is everything deleted.
2022-04-05 19:14:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:14:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.testDynConfiguration-FINISHED
2022-04-05 19:14:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:14:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:14:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for DynamicConfSharedST
2022-04-05 19:14:17 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka dynamic-configuration-shared-cluster-name in namespace dynamic-conf-shared-st
2022-04-05 19:14:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;31mERROR[m] Tests run: 3, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 508.31 s <<< FAILURE! - in io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST
[[1;31mERROR[m] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.testDynConfiguration  Time elapsed: 154.212 s  <<< ERROR!
io.strimzi.test.WaitException: Timeout after 40000 ms waiting for Wait until dyn.configuration is changed
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils.verifyPodDynamicConfiguration(KafkaUtils.java:287)
	at io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.lambda$testDynConfiguration$0(DynamicConfSharedST.java:69)
	at org.junit.jupiter.engine.descriptor.DynamicTestTestDescriptor.lambda$execute$0(DynamicTestTestDescriptor.java:53)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.api.extension.InvocationInterceptor.interceptDynamicTest(InvocationInterceptor.java:167)
	at org.junit.jupiter.api.extension.InvocationInterceptor.interceptDynamicTest(InvocationInterceptor.java:184)
	at org.junit.jupiter.engine.descriptor.DynamicTestTestDescriptor.lambda$execute$1(DynamicTestTestDescriptor.java:61)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptorCall.lambda$ofVoid$0(InvocationInterceptorChain.java:78)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.descriptor.DynamicTestTestDescriptor.execute(DynamicTestTestDescriptor.java:60)
	at org.junit.jupiter.engine.descriptor.DynamicTestTestDescriptor.execute(DynamicTestTestDescriptor.java:32)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:226)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:204)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.junit.jupiter.engine.descriptor.TestFactoryTestDescriptor.lambda$invokeTestMethod$1(TestFactoryTestDescriptor.java:108)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestFactoryTestDescriptor.invokeTestMethod(TestFactoryTestDescriptor.java:95)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)

[[1;31mERROR[m] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.testDynConfiguration  Time elapsed: 154.181 s  <<< ERROR!
io.strimzi.test.WaitException: Timeout after 40000 ms waiting for Wait until dyn.configuration is changed
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils.verifyPodDynamicConfiguration(KafkaUtils.java:287)
	at io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.lambda$testDynConfiguration$0(DynamicConfSharedST.java:69)
	at org.junit.jupiter.engine.descriptor.DynamicTestTestDescriptor.lambda$execute$0(DynamicTestTestDescriptor.java:53)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.api.extension.InvocationInterceptor.interceptDynamicTest(InvocationInterceptor.java:167)
	at org.junit.jupiter.api.extension.InvocationInterceptor.interceptDynamicTest(InvocationInterceptor.java:184)
	at org.junit.jupiter.engine.descriptor.DynamicTestTestDescriptor.lambda$execute$1(DynamicTestTestDescriptor.java:61)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptorCall.lambda$ofVoid$0(InvocationInterceptorChain.java:78)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.descriptor.DynamicTestTestDescriptor.execute(DynamicTestTestDescriptor.java:60)
	at org.junit.jupiter.engine.descriptor.DynamicTestTestDescriptor.execute(DynamicTestTestDescriptor.java:32)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:226)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:204)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.junit.jupiter.engine.descriptor.TestFactoryTestDescriptor.lambda$invokeTestMethod$1(TestFactoryTestDescriptor.java:108)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestFactoryTestDescriptor.invokeTestMethod(TestFactoryTestDescriptor.java:95)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)

[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.KafkaST
2022-04-05 19:15:11 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: kafka-st
2022-04-05 19:15:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: kafka-st
2022-04-05 19:15:11 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: kafka-st
2022-04-05 19:15:11 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:15:11 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testKafkaOffsetsReplicationFactorHigherThanReplicas-STARTED
2022-04-05 19:15:11 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:15:11 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-32 for test case:testKafkaOffsetsReplicationFactorHigherThanReplicas
2022-04-05 19:15:11 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-32
2022-04-05 19:15:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-32
2022-04-05 19:15:11 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-32
2022-04-05 19:15:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-57e68377 in namespace namespace-32
2022-04-05 19:15:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-32
2022-04-05 19:15:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:15:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaOffsetsReplicationFactorHigherThanReplicas
2022-04-05 19:15:17 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-57e68377 in namespace namespace-32
2022-04-05 19:15:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:15:27 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-32 for test case:testKafkaOffsetsReplicationFactorHigherThanReplicas
2022-04-05 19:15:32 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testKafkaOffsetsReplicationFactorHigherThanReplicas-FINISHED
2022-04-05 19:15:32 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:15:32 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:15:32 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testEntityOperatorWithoutUserOperator-STARTED
2022-04-05 19:15:32 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:15:32 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-33 for test case:testEntityOperatorWithoutUserOperator
2022-04-05 19:15:32 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-33
2022-04-05 19:15:32 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-33
2022-04-05 19:15:32 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-33
2022-04-05 19:15:32 [main] [32mINFO [m [KafkaST:787] Deploying Kafka cluster without UO in EO
2022-04-05 19:15:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-470cdbf7 in namespace namespace-33
2022-04-05 19:15:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-33
2022-04-05 19:15:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-470cdbf7 will have desired state: Ready
2022-04-05 19:16:48 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-470cdbf7 is in desired state: Ready
2022-04-05 19:16:48 [main] [32mINFO [m [AbstractST:478] Search in strimzi-cluster-operator log for errors in last 75 seconds
2022-04-05 19:16:48 [main] [32mINFO [m [BaseCmdKubeClient:481] Exception not found
2022-04-05 19:16:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:16:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testEntityOperatorWithoutUserOperator
2022-04-05 19:16:48 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-470cdbf7 in namespace namespace-33
2022-04-05 19:16:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:16:58 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-33 for test case:testEntityOperatorWithoutUserOperator
2022-04-05 19:17:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testEntityOperatorWithoutUserOperator-FINISHED
2022-04-05 19:17:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:17:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:17:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testEntityOperatorWithoutTopicOperator-STARTED
2022-04-05 19:17:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:17:35 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-34 for test case:testEntityOperatorWithoutTopicOperator
2022-04-05 19:17:35 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-34
2022-04-05 19:17:35 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-34
2022-04-05 19:17:35 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-34
2022-04-05 19:17:35 [main] [32mINFO [m [KafkaST:757] Deploying Kafka cluster without TO in EO
2022-04-05 19:17:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2001f5c4 in namespace namespace-34
2022-04-05 19:17:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-34
2022-04-05 19:17:35 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2001f5c4 will have desired state: Ready
2022-04-05 19:18:41 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2001f5c4 is in desired state: Ready
2022-04-05 19:18:41 [main] [32mINFO [m [AbstractST:478] Search in strimzi-cluster-operator log for errors in last 66 seconds
2022-04-05 19:18:41 [main] [32mINFO [m [BaseCmdKubeClient:481] Exception not found
2022-04-05 19:18:41 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:18:41 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testEntityOperatorWithoutTopicOperator
2022-04-05 19:18:41 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2001f5c4 in namespace namespace-34
2022-04-05 19:18:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:18:51 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-34 for test case:testEntityOperatorWithoutTopicOperator
2022-04-05 19:19:18 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testEntityOperatorWithoutTopicOperator-FINISHED
2022-04-05 19:19:18 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:19:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:19:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testTopicWithoutLabels-STARTED
2022-04-05 19:19:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:19:18 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-35 for test case:testTopicWithoutLabels
2022-04-05 19:19:18 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-35
2022-04-05 19:19:18 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-35
2022-04-05 19:19:18 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-35
2022-04-05 19:19:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5058f3cb in namespace namespace-35
2022-04-05 19:19:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-35
2022-04-05 19:19:18 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5058f3cb will have desired state: Ready
2022-04-05 19:20:37 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5058f3cb is in desired state: Ready
2022-04-05 19:20:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic topic-without-labels in namespace namespace-35
2022-04-05 19:20:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-35
2022-04-05 19:20:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-35 exec my-cluster-5058f3cb-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-05 19:20:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:20:40 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic topic-without-labels deletion
2022-04-05 19:20:42 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-35 exec my-cluster-5058f3cb-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-05 19:20:42 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:20:42 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:20:42 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTopicWithoutLabels
2022-04-05 19:20:42 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic topic-without-labels in namespace namespace-35
2022-04-05 19:20:42 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5058f3cb in namespace namespace-35
2022-04-05 19:20:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:20:52 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-35 for test case:testTopicWithoutLabels
2022-04-05 19:21:36 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testTopicWithoutLabels-FINISHED
2022-04-05 19:21:36 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:21:36 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:21:36 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testRemoveTopicOperatorFromEntityOperator-STARTED
2022-04-05 19:21:36 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:21:36 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-36 for test case:testRemoveTopicOperatorFromEntityOperator
2022-04-05 19:21:36 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-36
2022-04-05 19:21:36 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-36
2022-04-05 19:21:36 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-36
2022-04-05 19:21:36 [main] [32mINFO [m [KafkaST:623] Deploying Kafka cluster my-cluster-cbf77d09
2022-04-05 19:21:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-cbf77d09 in namespace namespace-36
2022-04-05 19:21:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-36
2022-04-05 19:21:36 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-cbf77d09 will have desired state: Ready
2022-04-05 19:22:54 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-cbf77d09 is in desired state: Ready
2022-04-05 19:22:54 [main] [32mINFO [m [PodUtils:154] Waiting when Pod my-cluster-cbf77d09-entity-operator-74dc6668b-mjzhn will be deleted
2022-04-05 19:23:04 [main] [32mINFO [m [PodUtils:171] Pod my-cluster-cbf77d09-entity-operator-74dc6668b-mjzhn deleted
2022-04-05 19:23:04 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-cbf77d09-entity-operator will be ready
2022-04-05 19:23:15 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-cbf77d09-entity-operator is ready
2022-04-05 19:23:15 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-cbf77d09-entity-operator to be ready
2022-04-05 19:23:25 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-cbf77d09-entity-operator is ready
2022-04-05 19:23:25 [main] [32mINFO [m [PodUtils:201] Wait until Pod my-cluster-cbf77d09-entity-operator will have 1 containers
2022-04-05 19:23:25 [main] [32mINFO [m [PodUtils:205] Pod my-cluster-cbf77d09-entity-operator has 1 containers
2022-04-05 19:23:25 [main] [32mINFO [m [PodUtils:154] Waiting when Pod my-cluster-cbf77d09-entity-operator-86f5cb6dc6-7wscn will be deleted
2022-04-05 19:23:35 [main] [32mINFO [m [PodUtils:171] Pod my-cluster-cbf77d09-entity-operator-86f5cb6dc6-7wscn deleted
2022-04-05 19:23:35 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-cbf77d09-entity-operator will be ready
2022-04-05 19:23:56 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-cbf77d09-entity-operator is ready
2022-04-05 19:23:56 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-cbf77d09-entity-operator to be ready
2022-04-05 19:24:06 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-cbf77d09-entity-operator is ready
2022-04-05 19:24:06 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:24:06 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRemoveTopicOperatorFromEntityOperator
2022-04-05 19:24:06 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-cbf77d09 in namespace namespace-36
2022-04-05 19:24:16 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:24:16 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-36 for test case:testRemoveTopicOperatorFromEntityOperator
2022-04-05 19:24:59 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testRemoveTopicOperatorFromEntityOperator-FINISHED
2022-04-05 19:24:59 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:24:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:24:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testEntityOperatorWithoutUserAndTopicOperators-STARTED
2022-04-05 19:24:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:24:59 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-37 for test case:testEntityOperatorWithoutUserAndTopicOperators
2022-04-05 19:24:59 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-37
2022-04-05 19:25:00 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-37
2022-04-05 19:25:00 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-37
2022-04-05 19:25:00 [main] [32mINFO [m [KafkaST:814] Deploying Kafka cluster without UO and TO in EO
2022-04-05 19:25:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-cd812c7b in namespace namespace-37
2022-04-05 19:25:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-37
2022-04-05 19:25:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-cd812c7b will have desired state: Ready
2022-04-05 19:25:51 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-cd812c7b is in desired state: Ready
2022-04-05 19:25:51 [main] [32mINFO [m [AbstractST:478] Search in strimzi-cluster-operator log for errors in last 51 seconds
2022-04-05 19:25:51 [main] [32mINFO [m [BaseCmdKubeClient:481] Exception not found
2022-04-05 19:25:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:25:51 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testEntityOperatorWithoutUserAndTopicOperators
2022-04-05 19:25:51 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-cd812c7b in namespace namespace-37
2022-04-05 19:26:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:26:01 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-37 for test case:testEntityOperatorWithoutUserAndTopicOperators
2022-04-05 19:26:28 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testEntityOperatorWithoutUserAndTopicOperators-FINISHED
2022-04-05 19:26:28 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:26:28 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:26:28 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testRemoveUserAndTopicOperatorsFromEntityOperator-STARTED
2022-04-05 19:26:28 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:26:28 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-38 for test case:testRemoveUserAndTopicOperatorsFromEntityOperator
2022-04-05 19:26:28 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-38
2022-04-05 19:26:28 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-38
2022-04-05 19:26:28 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-38
2022-04-05 19:26:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d786bada in namespace namespace-38
2022-04-05 19:26:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-38
2022-04-05 19:26:28 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d786bada will have desired state: Ready
2022-04-05 19:27:40 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d786bada is in desired state: Ready
2022-04-05 19:27:40 [main] [32mINFO [m [PodUtils:209] Wait until Pod my-cluster-d786bada-entity-operator will have stable 0 replicas
2022-04-05 19:27:40 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-05 19:27:41 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-05 19:27:42 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-05 19:27:43 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-05 19:27:44 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-05 19:27:45 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-05 19:27:46 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-05 19:27:47 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-05 19:27:48 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-05 19:27:49 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-05 19:27:50 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-05 19:27:51 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-05 19:27:52 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-05 19:27:53 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-05 19:27:54 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 19 polls
2022-04-05 19:27:55 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 18 polls
2022-04-05 19:27:56 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 17 polls
2022-04-05 19:27:57 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 16 polls
2022-04-05 19:27:58 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 15 polls
2022-04-05 19:27:59 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 14 polls
2022-04-05 19:28:00 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 13 polls
2022-04-05 19:28:01 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 12 polls
2022-04-05 19:28:02 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 11 polls
2022-04-05 19:28:03 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 10 polls
2022-04-05 19:28:04 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 9 polls
2022-04-05 19:28:05 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 8 polls
2022-04-05 19:28:06 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 7 polls
2022-04-05 19:28:07 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 6 polls
2022-04-05 19:28:08 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 5 polls
2022-04-05 19:28:09 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 4 polls
2022-04-05 19:28:10 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 3 polls
2022-04-05 19:28:11 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 2 polls
2022-04-05 19:28:12 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 1 polls
2022-04-05 19:28:13 [main] [32mINFO [m [PodUtils:217] Pod replicas are stable for 20 polls intervals
2022-04-05 19:28:13 [main] [32mINFO [m [PodUtils:228] Pod my-cluster-d786bada-entity-operator has 0 replicas
2022-04-05 19:28:13 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d786bada-entity-operator will be ready
2022-04-05 19:28:35 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d786bada-entity-operator is ready
2022-04-05 19:28:35 [main] [32mINFO [m [AbstractST:478] Search in strimzi-cluster-operator log for errors in last 126 seconds
2022-04-05 19:28:35 [main] [32mINFO [m [BaseCmdKubeClient:481] Exception not found
2022-04-05 19:28:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:28:35 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRemoveUserAndTopicOperatorsFromEntityOperator
2022-04-05 19:28:35 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d786bada in namespace namespace-38
2022-04-05 19:28:45 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:28:45 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-38 for test case:testRemoveUserAndTopicOperatorsFromEntityOperator
2022-04-05 19:29:28 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testRemoveUserAndTopicOperatorsFromEntityOperator-FINISHED
2022-04-05 19:29:28 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:29:28 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:29:28 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testConsumerOffsetFiles-STARTED
2022-04-05 19:29:28 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:29:28 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-39 for test case:testConsumerOffsetFiles
2022-04-05 19:29:28 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-39
2022-04-05 19:29:28 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-39
2022-04-05 19:29:28 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-39
2022-04-05 19:29:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1242351b in namespace namespace-39
2022-04-05 19:29:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-39
2022-04-05 19:29:28 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1242351b will have desired state: Ready
2022-04-05 19:30:49 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1242351b is in desired state: Ready
2022-04-05 19:30:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1480596706-1515483676 in namespace namespace-39
2022-04-05 19:30:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-39
2022-04-05 19:30:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1480596706-1515483676 will have desired state: Ready
2022-04-05 19:30:50 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1480596706-1515483676 is in desired state: Ready
2022-04-05 19:30:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-1242351b-kafka-clients in namespace namespace-39
2022-04-05 19:30:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-39
2022-04-05 19:30:50 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1242351b-kafka-clients will be ready
2022-04-05 19:30:52 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1242351b-kafka-clients is ready
2022-04-05 19:30:52 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 19:30:52 [main] [32mINFO [m [KafkaST:1415] Executing command cd /var/lib/kafka/data/kafka-log0/;ls -1 | sed -n "s#__consumer_offsets-\([0-9]*\)#\1#p" | sort -V in my-cluster-1242351b-kafka-0
2022-04-05 19:30:53 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-39 exec my-cluster-1242351b-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0/;ls -1 | sed -n "s#__consumer_offsets-\([0-9]*\)#\1#p" | sort -V
2022-04-05 19:30:53 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:30:53 [main] [32mINFO [m [KafkaST:1422] Result: 
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99

2022-04-05 19:30:53 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@228c9ae, messages=[], arguments=[--max-messages, 100, --topic, my-topic-1480596706-1515483676, --bootstrap-server, my-cluster-1242351b-kafka-bootstrap.namespace-39.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-1242351b-kafka-clients-848d598fc4-stcf2', podNamespace='namespace-39', bootstrapServer='my-cluster-1242351b-kafka-bootstrap.namespace-39.svc:9092', topicName='my-topic-1480596706-1515483676', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4f4151eb}
2022-04-05 19:30:53 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-1242351b-kafka-bootstrap.namespace-39.svc:9092:my-topic-1480596706-1515483676 from pod my-cluster-1242351b-kafka-clients-848d598fc4-stcf2
2022-04-05 19:30:53 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1242351b-kafka-clients-848d598fc4-stcf2 -n namespace-39 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-1480596706-1515483676 --bootstrap-server my-cluster-1242351b-kafka-bootstrap.namespace-39.svc:9092
2022-04-05 19:30:55 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 19:30:55 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 19:30:55 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6205b320, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-535353315, --group-instance-id, instance298813446, --topic, my-topic-1480596706-1515483676, --bootstrap-server, my-cluster-1242351b-kafka-bootstrap.namespace-39.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-1242351b-kafka-clients-848d598fc4-stcf2', podNamespace='namespace-39', bootstrapServer='my-cluster-1242351b-kafka-bootstrap.namespace-39.svc:9092', topicName='my-topic-1480596706-1515483676', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-535353315', consumerInstanceId='instance298813446', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@63b0c369}
2022-04-05 19:30:55 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-1242351b-kafka-bootstrap.namespace-39.svc:9092#my-topic-1480596706-1515483676 from pod my-cluster-1242351b-kafka-clients-848d598fc4-stcf2
2022-04-05 19:30:55 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1242351b-kafka-clients-848d598fc4-stcf2 -n namespace-39 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-535353315 --group-instance-id instance298813446 --topic my-topic-1480596706-1515483676 --bootstrap-server my-cluster-1242351b-kafka-bootstrap.namespace-39.svc:9092
2022-04-05 19:31:01 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 19:31:01 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 19:31:01 [main] [32mINFO [m [KafkaST:1429] Executing command cd /var/lib/kafka/data/kafka-log0/;ls -1 | sed -n "s#__consumer_offsets-\([0-9]*\)#\1#p" | sort -V in my-cluster-1242351b-kafka-0
2022-04-05 19:31:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-39 exec my-cluster-1242351b-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0/;ls -1 | sed -n "s#__consumer_offsets-\([0-9]*\)#\1#p" | sort -V
2022-04-05 19:31:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:31:01 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:31:01 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConsumerOffsetFiles
2022-04-05 19:31:01 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1480596706-1515483676 in namespace namespace-39
2022-04-05 19:31:01 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-1242351b-kafka-clients in namespace namespace-39
2022-04-05 19:31:01 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1242351b in namespace namespace-39
2022-04-05 19:31:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:31:51 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-39 for test case:testConsumerOffsetFiles
2022-04-05 19:31:57 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testConsumerOffsetFiles-FINISHED
2022-04-05 19:31:57 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:31:57 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:31:57 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testAppDomainLabels-STARTED
2022-04-05 19:31:57 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:31:57 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-40 for test case:testAppDomainLabels
2022-04-05 19:31:57 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-40
2022-04-05 19:31:57 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-40
2022-04-05 19:31:57 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-40
2022-04-05 19:31:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-bd209ca7 in namespace namespace-40
2022-04-05 19:31:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-40
2022-04-05 19:31:57 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-bd209ca7 will have desired state: Ready
2022-04-05 19:33:10 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-bd209ca7 is in desired state: Ready
2022-04-05 19:33:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-122596453-666425868 in namespace namespace-40
2022-04-05 19:33:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-40
2022-04-05 19:33:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-122596453-666425868 will have desired state: Ready
2022-04-05 19:33:11 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-122596453-666425868 is in desired state: Ready
2022-04-05 19:33:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-bd209ca7-kafka-clients in namespace namespace-40
2022-04-05 19:33:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-40
2022-04-05 19:33:11 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-bd209ca7-kafka-clients will be ready
2022-04-05 19:33:13 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-bd209ca7-kafka-clients is ready
2022-04-05 19:33:13 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1220] ---> PODS <---
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1232] ---> STATEFUL SETS <---
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1236] Getting labels from stateful set of kafka resource
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1765] Verifying labels {app.kubernetes.io/instance=my-cluster-bd209ca7, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-bd209ca7, strimzi.io/cluster=my-cluster-bd209ca7, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-bd209ca7-kafka, test.case=testAppDomainLabels}
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1241] Getting labels from stateful set of zookeeper resource
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1765] Verifying labels {app.kubernetes.io/instance=my-cluster-bd209ca7, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=zookeeper, app.kubernetes.io/part-of=strimzi-my-cluster-bd209ca7, strimzi.io/cluster=my-cluster-bd209ca7, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-bd209ca7-zookeeper, test.case=testAppDomainLabels}
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1244] ---> SERVICES <---
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1251] Getting labels from my-cluster-bd209ca7-kafka-bootstrap service
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1765] Verifying labels {app.kubernetes.io/instance=my-cluster-bd209ca7, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-bd209ca7, strimzi.io/cluster=my-cluster-bd209ca7, strimzi.io/discovery=true, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-bd209ca7-kafka, test.case=testAppDomainLabels}
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1251] Getting labels from my-cluster-bd209ca7-kafka-brokers service
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1765] Verifying labels {app.kubernetes.io/instance=my-cluster-bd209ca7, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-bd209ca7, strimzi.io/cluster=my-cluster-bd209ca7, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-bd209ca7-kafka, test.case=testAppDomainLabels}
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1251] Getting labels from my-cluster-bd209ca7-zookeeper-client service
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1765] Verifying labels {app.kubernetes.io/instance=my-cluster-bd209ca7, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=zookeeper, app.kubernetes.io/part-of=strimzi-my-cluster-bd209ca7, strimzi.io/cluster=my-cluster-bd209ca7, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-bd209ca7-zookeeper-client, test.case=testAppDomainLabels}
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1251] Getting labels from my-cluster-bd209ca7-zookeeper-nodes service
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1765] Verifying labels {app.kubernetes.io/instance=my-cluster-bd209ca7, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=zookeeper, app.kubernetes.io/part-of=strimzi-my-cluster-bd209ca7, strimzi.io/cluster=my-cluster-bd209ca7, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-bd209ca7-zookeeper, test.case=testAppDomainLabels}
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1255] ---> SECRETS <---
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-bd209ca7-clients-ca secret
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-bd209ca7, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-bd209ca7, strimzi.io/cluster=my-cluster-bd209ca7, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-bd209ca7-clients-ca-cert secret
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-bd209ca7, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-bd209ca7, strimzi.io/cluster=my-cluster-bd209ca7, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-bd209ca7-cluster-ca secret
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-bd209ca7, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-bd209ca7, strimzi.io/cluster=my-cluster-bd209ca7, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-bd209ca7-cluster-ca-cert secret
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-bd209ca7, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-bd209ca7, strimzi.io/cluster=my-cluster-bd209ca7, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-bd209ca7-cluster-operator-certs secret
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-bd209ca7, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-bd209ca7, strimzi.io/cluster=my-cluster-bd209ca7, strimzi.io/kind=Kafka, test.case=testAppDomainLabels}
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-bd209ca7-entity-topic-operator-certs secret
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-bd209ca7, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=entity-topic-operator, app.kubernetes.io/part-of=strimzi-my-cluster-bd209ca7, strimzi.io/cluster=my-cluster-bd209ca7, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-bd209ca7-entity-user-operator-certs secret
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-bd209ca7, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=entity-user-operator, app.kubernetes.io/part-of=strimzi-my-cluster-bd209ca7, strimzi.io/cluster=my-cluster-bd209ca7, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-bd209ca7-kafka-brokers secret
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-bd209ca7, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-bd209ca7, strimzi.io/cluster=my-cluster-bd209ca7, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-bd209ca7-zookeeper-nodes secret
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-bd209ca7, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=zookeeper, app.kubernetes.io/part-of=strimzi-my-cluster-bd209ca7, strimzi.io/cluster=my-cluster-bd209ca7, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1266] ---> CONFIG MAPS <---
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1271] Getting labels from my-cluster-bd209ca7-entity-topic-operator-config config map
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-bd209ca7, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=entity-topic-operator, app.kubernetes.io/part-of=strimzi-my-cluster-bd209ca7, strimzi.io/cluster=my-cluster-bd209ca7, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1271] Getting labels from my-cluster-bd209ca7-entity-user-operator-config config map
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-bd209ca7, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=entity-user-operator, app.kubernetes.io/part-of=strimzi-my-cluster-bd209ca7, strimzi.io/cluster=my-cluster-bd209ca7, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1271] Getting labels from my-cluster-bd209ca7-kafka-config config map
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-bd209ca7, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-bd209ca7, strimzi.io/cluster=my-cluster-bd209ca7, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-bd209ca7-kafka, test.case=testAppDomainLabels}
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1271] Getting labels from my-cluster-bd209ca7-zookeeper-config config map
2022-04-05 19:33:13 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-bd209ca7, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=zookeeper, app.kubernetes.io/part-of=strimzi-my-cluster-bd209ca7, strimzi.io/cluster=my-cluster-bd209ca7, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-05 19:33:13 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@501bef7, messages=[], arguments=[--max-messages, 100, --topic, my-topic-122596453-666425868, --bootstrap-server, my-cluster-bd209ca7-kafka-bootstrap.namespace-40.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-bd209ca7-kafka-clients-7d5496f56d-k6vbm', podNamespace='namespace-40', bootstrapServer='my-cluster-bd209ca7-kafka-bootstrap.namespace-40.svc:9092', topicName='my-topic-122596453-666425868', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@11f95c2a}
2022-04-05 19:33:13 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-bd209ca7-kafka-bootstrap.namespace-40.svc:9092:my-topic-122596453-666425868 from pod my-cluster-bd209ca7-kafka-clients-7d5496f56d-k6vbm
2022-04-05 19:33:13 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-bd209ca7-kafka-clients-7d5496f56d-k6vbm -n namespace-40 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-122596453-666425868 --bootstrap-server my-cluster-bd209ca7-kafka-bootstrap.namespace-40.svc:9092
2022-04-05 19:33:15 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 19:33:15 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 19:33:15 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@bc40714, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-747985727, --group-instance-id, instance1309507661, --topic, my-topic-122596453-666425868, --bootstrap-server, my-cluster-bd209ca7-kafka-bootstrap.namespace-40.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-bd209ca7-kafka-clients-7d5496f56d-k6vbm', podNamespace='namespace-40', bootstrapServer='my-cluster-bd209ca7-kafka-bootstrap.namespace-40.svc:9092', topicName='my-topic-122596453-666425868', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-747985727', consumerInstanceId='instance1309507661', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@50870922}
2022-04-05 19:33:15 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-bd209ca7-kafka-bootstrap.namespace-40.svc:9092#my-topic-122596453-666425868 from pod my-cluster-bd209ca7-kafka-clients-7d5496f56d-k6vbm
2022-04-05 19:33:15 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-bd209ca7-kafka-clients-7d5496f56d-k6vbm -n namespace-40 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-747985727 --group-instance-id instance1309507661 --topic my-topic-122596453-666425868 --bootstrap-server my-cluster-bd209ca7-kafka-bootstrap.namespace-40.svc:9092
2022-04-05 19:33:21 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 19:33:21 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 19:33:21 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:33:21 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAppDomainLabels
2022-04-05 19:33:21 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-122596453-666425868 in namespace namespace-40
2022-04-05 19:33:21 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-bd209ca7 in namespace namespace-40
2022-04-05 19:33:21 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-bd209ca7-kafka-clients in namespace namespace-40
2022-04-05 19:34:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:34:01 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-40 for test case:testAppDomainLabels
2022-04-05 19:34:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testAppDomainLabels-FINISHED
2022-04-05 19:34:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:34:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:34:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testRemoveUserOperatorFromEntityOperator-STARTED
2022-04-05 19:34:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:34:07 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-41 for test case:testRemoveUserOperatorFromEntityOperator
2022-04-05 19:34:07 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-41
2022-04-05 19:34:07 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-41
2022-04-05 19:34:07 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-41
2022-04-05 19:34:07 [main] [32mINFO [m [KafkaST:669] Deploying Kafka cluster my-cluster-3ab0a63d
2022-04-05 19:34:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3ab0a63d in namespace namespace-41
2022-04-05 19:34:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-41
2022-04-05 19:34:07 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3ab0a63d will have desired state: Ready
2022-04-05 19:35:22 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3ab0a63d is in desired state: Ready
2022-04-05 19:35:22 [main] [32mINFO [m [PodUtils:154] Waiting when Pod my-cluster-3ab0a63d-entity-operator-594f4fb6d6-htpmn will be deleted
2022-04-05 19:35:32 [main] [32mINFO [m [PodUtils:171] Pod my-cluster-3ab0a63d-entity-operator-594f4fb6d6-htpmn deleted
2022-04-05 19:35:32 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-3ab0a63d-entity-operator will be ready
2022-04-05 19:41:05 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-3ab0a63d-entity-operator is ready
2022-04-05 19:41:05 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-3ab0a63d-entity-operator to be ready
2022-04-05 19:41:15 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-3ab0a63d-entity-operator is ready
2022-04-05 19:41:15 [main] [32mINFO [m [PodUtils:201] Wait until Pod my-cluster-3ab0a63d-entity-operator will have 2 containers
2022-04-05 19:41:15 [main] [32mINFO [m [PodUtils:205] Pod my-cluster-3ab0a63d-entity-operator has 2 containers
2022-04-05 19:41:15 [main] [32mINFO [m [PodUtils:154] Waiting when Pod my-cluster-3ab0a63d-entity-operator-77497bc789-x84qr will be deleted
2022-04-05 19:41:20 [main] [32mINFO [m [PodUtils:171] Pod my-cluster-3ab0a63d-entity-operator-77497bc789-x84qr deleted
2022-04-05 19:41:20 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-3ab0a63d-entity-operator will be ready
2022-04-05 19:47:01 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-3ab0a63d-entity-operator is ready
2022-04-05 19:47:01 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-3ab0a63d-entity-operator to be ready
2022-04-05 19:47:11 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-3ab0a63d-entity-operator is ready
2022-04-05 19:47:11 [main] [32mINFO [m [AbstractST:478] Search in strimzi-cluster-operator log for errors in last 784 seconds
2022-04-05 19:47:11 [main] [32mINFO [m [BaseCmdKubeClient:481] Exception not found
2022-04-05 19:47:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:47:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRemoveUserOperatorFromEntityOperator
2022-04-05 19:47:11 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3ab0a63d in namespace namespace-41
2022-04-05 19:47:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:47:22 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-41 for test case:testRemoveUserOperatorFromEntityOperator
2022-04-05 19:48:05 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testRemoveUserOperatorFromEntityOperator-FINISHED
2022-04-05 19:48:05 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:48:05 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:48:05 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testUOListeningOnlyUsersInSameCluster-STARTED
2022-04-05 19:48:05 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:48:05 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-42 for test case:testUOListeningOnlyUsersInSameCluster
2022-04-05 19:48:05 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-42
2022-04-05 19:48:05 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-42
2022-04-05 19:48:05 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-42
2022-04-05 19:48:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1 in namespace namespace-42
2022-04-05 19:48:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-42
2022-04-05 19:48:05 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1 will have desired state: Ready
2022-04-05 19:49:23 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1 is in desired state: Ready
2022-04-05 19:49:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2 in namespace namespace-42
2022-04-05 19:49:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-42
2022-04-05 19:49:23 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2 will have desired state: Ready
2022-04-05 19:50:43 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2 is in desired state: Ready
2022-04-05 19:50:43 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-784347484-777141558 in namespace namespace-42
2022-04-05 19:50:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-42
2022-04-05 19:50:43 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-784347484-777141558 will have desired state: Ready
2022-04-05 19:50:44 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-784347484-777141558 is in desired state: Ready
2022-04-05 19:50:44 [main] [32mINFO [m [KafkaST:1292] Verifying that user my-user-784347484-777141558 in cluster my-cluster-1 is created
2022-04-05 19:50:44 [main] [32mINFO [m [KafkaST:1297] Verifying that user my-user-784347484-777141558 in cluster my-cluster-2 is not created
2022-04-05 19:50:44 [main] [32mINFO [m [KafkaST:1302] Verifying that user belongs to my-cluster-1 cluster
2022-04-05 19:50:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:50:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUOListeningOnlyUsersInSameCluster
2022-04-05 19:50:45 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2 in namespace namespace-42
2022-04-05 19:50:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-784347484-777141558 in namespace namespace-42
2022-04-05 19:50:45 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1 in namespace namespace-42
2022-04-05 19:51:05 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:51:05 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-42 for test case:testUOListeningOnlyUsersInSameCluster
2022-04-05 19:51:48 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testUOListeningOnlyUsersInSameCluster-FINISHED
2022-04-05 19:51:48 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:51:48 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:51:48 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testKafkaJBODDeleteClaimsTrueFalse-STARTED
2022-04-05 19:51:48 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:51:48 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-43 for test case:testKafkaJBODDeleteClaimsTrueFalse
2022-04-05 19:51:48 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-43
2022-04-05 19:51:48 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-43
2022-04-05 19:51:48 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-43
2022-04-05 19:51:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-039f9f82 in namespace namespace-43
2022-04-05 19:51:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-43
2022-04-05 19:51:48 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-039f9f82 will have desired state: Ready
2022-04-05 19:53:29 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-039f9f82 is in desired state: Ready
2022-04-05 19:53:29 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-0-my-cluster-039f9f82-kafka-0
2022-04-05 19:53:29 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-0-my-cluster-039f9f82-kafka-1
2022-04-05 19:53:29 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-1-my-cluster-039f9f82-kafka-0
2022-04-05 19:53:29 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-1-my-cluster-039f9f82-kafka-1
2022-04-05 19:53:29 [main] [32mINFO [m [KafkaST:1717] Checking PVC names included in JBOD array
2022-04-05 19:53:29 [main] [32mINFO [m [KafkaST:1724] Checking PVC on Kafka pods
2022-04-05 19:53:29 [main] [32mINFO [m [KafkaST:1729] Getting list of mounted data sources and PVCs on Kafka pod 0
2022-04-05 19:53:29 [main] [32mINFO [m [KafkaST:1737] Verifying mounted data sources and PVCs on Kafka pod 0
2022-04-05 19:53:29 [main] [32mINFO [m [KafkaST:1729] Getting list of mounted data sources and PVCs on Kafka pod 1
2022-04-05 19:53:29 [main] [32mINFO [m [KafkaST:1737] Verifying mounted data sources and PVCs on Kafka pod 1
2022-04-05 19:53:29 [main] [32mINFO [m [KafkaST:882] Deleting cluster
2022-04-05 19:53:29 [main] [32mINFO [m [KafkaST:885] Waiting for PVC deletion
2022-04-05 19:54:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:54:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaJBODDeleteClaimsTrueFalse
2022-04-05 19:54:14 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-039f9f82 in namespace namespace-43
2022-04-05 19:54:14 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:54:15 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-43 for test case:testKafkaJBODDeleteClaimsTrueFalse
2022-04-05 19:54:20 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testKafkaJBODDeleteClaimsTrueFalse-FINISHED
2022-04-05 19:54:20 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:54:20 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:54:20 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testLabelsAndAnnotationForPVC-STARTED
2022-04-05 19:54:20 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:54:20 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-44 for test case:testLabelsAndAnnotationForPVC
2022-04-05 19:54:20 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-44
2022-04-05 19:54:20 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-44
2022-04-05 19:54:20 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-44
2022-04-05 19:54:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d90acf6d in namespace namespace-44
2022-04-05 19:54:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-44
2022-04-05 19:54:20 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d90acf6d will have desired state: Ready
2022-04-05 19:55:25 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d90acf6d is in desired state: Ready
2022-04-05 19:55:25 [main] [32mINFO [m [KafkaST:1510] Check if Kubernetes labels are applied
2022-04-05 19:55:25 [main] [32mINFO [m [KafkaST:1517] Kubernetes labels are correctly set and present
2022-04-05 19:55:25 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-0-my-cluster-d90acf6d-kafka-0 - testValue = testValue
2022-04-05 19:55:25 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-0-my-cluster-d90acf6d-kafka-1 - testValue = testValue
2022-04-05 19:55:25 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-0-my-cluster-d90acf6d-kafka-2 - testValue = testValue
2022-04-05 19:55:25 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-1-my-cluster-d90acf6d-kafka-0 - testValue = testValue
2022-04-05 19:55:25 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-1-my-cluster-d90acf6d-kafka-1 - testValue = testValue
2022-04-05 19:55:25 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-1-my-cluster-d90acf6d-kafka-2 - testValue = testValue
2022-04-05 19:55:25 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-my-cluster-d90acf6d-zookeeper-0 - testValue = testValue
2022-04-05 19:55:25 [main] [32mINFO [m [KafkaST:1535] Replacing kafka && zookeeper labels and annotations from testKey to editedTestValue
2022-04-05 19:55:25 [main] [32mINFO [m [PersistentVolumeClaimUtils:30] Wait until PVC labels will change {testKey=editedTestValue}
2022-04-05 19:55:29 [main] [32mINFO [m [PersistentVolumeClaimUtils:46] PVC labels has changed {testKey=editedTestValue}
2022-04-05 19:55:29 [main] [32mINFO [m [PersistentVolumeClaimUtils:50] Wait until PVC annotation will change {testKey=editedTestValue}
2022-04-05 19:55:29 [main] [32mINFO [m [PersistentVolumeClaimUtils:66] PVC annotation has changed {testKey=editedTestValue}
2022-04-05 19:55:29 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d90acf6d will have desired state: Ready
2022-04-05 19:55:29 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d90acf6d is in desired state: Ready
2022-04-05 19:55:29 [main] [32mINFO [m [KafkaST:1549] [PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=false, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-05T19:54:42Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-d90acf6d, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-d90acf6d, strimzi.io/cluster=my-cluster-d90acf6d, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-d90acf6d-kafka, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-0-my-cluster-d90acf6d-kafka-0, namespace=namespace-44, ownerReferences=[], resourceVersion=278733, selfLink=/api/v1/namespaces/namespace-44/persistentvolumeclaims/data-0-my-cluster-d90acf6d-kafka-0, uid=f5b4327a-7cd9-4625-be57-0af52fb0d554, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=20Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-f5b4327a-7cd9-4625-be57-0af52fb0d554, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=20Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={}), PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=false, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-05T19:54:42Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-d90acf6d, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-d90acf6d, strimzi.io/cluster=my-cluster-d90acf6d, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-d90acf6d-kafka, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-0-my-cluster-d90acf6d-kafka-1, namespace=namespace-44, ownerReferences=[], resourceVersion=278737, selfLink=/api/v1/namespaces/namespace-44/persistentvolumeclaims/data-0-my-cluster-d90acf6d-kafka-1, uid=3c6c1654-dc2a-4057-937e-7ddd186d4274, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=20Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-3c6c1654-dc2a-4057-937e-7ddd186d4274, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=20Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={}), PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=false, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-05T19:54:42Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-d90acf6d, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-d90acf6d, strimzi.io/cluster=my-cluster-d90acf6d, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-d90acf6d-kafka, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-0-my-cluster-d90acf6d-kafka-2, namespace=namespace-44, ownerReferences=[], resourceVersion=278738, selfLink=/api/v1/namespaces/namespace-44/persistentvolumeclaims/data-0-my-cluster-d90acf6d-kafka-2, uid=46bcb48d-57d6-459f-8294-57d7a35434e2, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=20Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-46bcb48d-57d6-459f-8294-57d7a35434e2, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=20Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={}), PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=true, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-05T19:54:42Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-d90acf6d, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-d90acf6d, strimzi.io/cluster=my-cluster-d90acf6d, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-d90acf6d-kafka, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-1-my-cluster-d90acf6d-kafka-0, namespace=namespace-44, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=Kafka, name=my-cluster-d90acf6d, uid=25783342-943f-42d6-9815-2bc4aab011c0, additionalProperties={})], resourceVersion=278740, selfLink=/api/v1/namespaces/namespace-44/persistentvolumeclaims/data-1-my-cluster-d90acf6d-kafka-0, uid=3d3e901e-f8b0-49a4-a013-5588e2b63a37, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=10Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-3d3e901e-f8b0-49a4-a013-5588e2b63a37, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=10Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={}), PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=true, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-05T19:54:42Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-d90acf6d, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-d90acf6d, strimzi.io/cluster=my-cluster-d90acf6d, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-d90acf6d-kafka, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-1-my-cluster-d90acf6d-kafka-1, namespace=namespace-44, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=Kafka, name=my-cluster-d90acf6d, uid=25783342-943f-42d6-9815-2bc4aab011c0, additionalProperties={})], resourceVersion=278736, selfLink=/api/v1/namespaces/namespace-44/persistentvolumeclaims/data-1-my-cluster-d90acf6d-kafka-1, uid=e1d8038e-c327-4ecd-a958-6e28230780c5, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=10Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-e1d8038e-c327-4ecd-a958-6e28230780c5, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=10Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={}), PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=true, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-05T19:54:42Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-d90acf6d, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-d90acf6d, strimzi.io/cluster=my-cluster-d90acf6d, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-d90acf6d-kafka, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-1-my-cluster-d90acf6d-kafka-2, namespace=namespace-44, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=Kafka, name=my-cluster-d90acf6d, uid=25783342-943f-42d6-9815-2bc4aab011c0, additionalProperties={})], resourceVersion=278739, selfLink=/api/v1/namespaces/namespace-44/persistentvolumeclaims/data-1-my-cluster-d90acf6d-kafka-2, uid=5f027a36-1e85-4715-b219-376e93f8eead, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=10Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-5f027a36-1e85-4715-b219-376e93f8eead, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=10Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={}), PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=false, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-05T19:54:23Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-d90acf6d, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=zookeeper, app.kubernetes.io/part-of=strimzi-my-cluster-d90acf6d, strimzi.io/cluster=my-cluster-d90acf6d, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-d90acf6d-zookeeper, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-my-cluster-d90acf6d-zookeeper-0, namespace=namespace-44, ownerReferences=[], resourceVersion=278721, selfLink=/api/v1/namespaces/namespace-44/persistentvolumeclaims/data-my-cluster-d90acf6d-zookeeper-0, uid=484f3bd1-e078-496e-8772-ecc8e0822cd5, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=3Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-484f3bd1-e078-496e-8772-ecc8e0822cd5, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=3Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={})]
2022-04-05 19:55:29 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-0-my-cluster-d90acf6d-kafka-0 - testValue = editedTestValue
2022-04-05 19:55:29 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-0-my-cluster-d90acf6d-kafka-1 - testValue = editedTestValue
2022-04-05 19:55:29 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-0-my-cluster-d90acf6d-kafka-2 - testValue = editedTestValue
2022-04-05 19:55:29 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-1-my-cluster-d90acf6d-kafka-0 - testValue = editedTestValue
2022-04-05 19:55:29 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-1-my-cluster-d90acf6d-kafka-1 - testValue = editedTestValue
2022-04-05 19:55:29 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-1-my-cluster-d90acf6d-kafka-2 - testValue = editedTestValue
2022-04-05 19:55:29 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-my-cluster-d90acf6d-zookeeper-0 - testValue = editedTestValue
2022-04-05 19:55:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:55:29 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testLabelsAndAnnotationForPVC
2022-04-05 19:55:29 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d90acf6d in namespace namespace-44
2022-04-05 19:55:39 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:55:40 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-44 for test case:testLabelsAndAnnotationForPVC
2022-04-05 19:56:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testLabelsAndAnnotationForPVC-FINISHED
2022-04-05 19:56:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:56:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:56:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testMessagesAreStoredInDisk-STARTED
2022-04-05 19:56:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:56:07 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-45 for test case:testMessagesAreStoredInDisk
2022-04-05 19:56:07 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-45
2022-04-05 19:56:07 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-45
2022-04-05 19:56:07 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-45
2022-04-05 19:56:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-83790055 in namespace namespace-45
2022-04-05 19:56:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-45
2022-04-05 19:56:07 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-83790055 will have desired state: Ready
2022-04-05 19:57:20 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-83790055 is in desired state: Ready
2022-04-05 19:57:20 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-698241334-1574461286 in namespace namespace-45
2022-04-05 19:57:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-45
2022-04-05 19:57:20 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-698241334-1574461286 will have desired state: Ready
2022-04-05 19:57:21 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-698241334-1574461286 is in desired state: Ready
2022-04-05 19:57:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-83790055-kafka-clients in namespace namespace-45
2022-04-05 19:57:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-45
2022-04-05 19:57:21 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-83790055-kafka-clients will be ready
2022-04-05 19:57:23 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-83790055-kafka-clients is ready
2022-04-05 19:57:23 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 19:57:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-45 exec my-cluster-83790055-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0; ls -1
2022-04-05 19:57:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:57:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-45 exec my-cluster-83790055-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0; ls -1 | sed -n '/my-topic-698241334-1574461286/p'
2022-04-05 19:57:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:57:23 [main] [32mINFO [m [KafkaST:1344] Executing command cd /var/lib/kafka/data/kafka-log0/my-topic-698241334-1574461286-0
/;cat 00000000000000000000.log in my-cluster-83790055-kafka-0
2022-04-05 19:57:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-45 exec my-cluster-83790055-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0/my-topic-698241334-1574461286-0
/;cat 00000000000000000000.log
2022-04-05 19:57:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:57:24 [main] [32mINFO [m [KafkaST:1348] Topic my-topic-698241334-1574461286 is present in kafka broker my-cluster-83790055-kafka-0 with no data
2022-04-05 19:57:24 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5c6005c2, messages=[], arguments=[--max-messages, 100, --topic, my-topic-698241334-1574461286, --bootstrap-server, my-cluster-83790055-kafka-bootstrap.namespace-45.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-83790055-kafka-clients-6f48f48f8f-cvd89', podNamespace='namespace-45', bootstrapServer='my-cluster-83790055-kafka-bootstrap.namespace-45.svc:9092', topicName='my-topic-698241334-1574461286', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3e1ebf96}
2022-04-05 19:57:24 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-83790055-kafka-bootstrap.namespace-45.svc:9092:my-topic-698241334-1574461286 from pod my-cluster-83790055-kafka-clients-6f48f48f8f-cvd89
2022-04-05 19:57:24 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-83790055-kafka-clients-6f48f48f8f-cvd89 -n namespace-45 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-698241334-1574461286 --bootstrap-server my-cluster-83790055-kafka-bootstrap.namespace-45.svc:9092
2022-04-05 19:57:26 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 19:57:26 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 19:57:26 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@51e51f1d, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1900850046, --group-instance-id, instance82818781, --topic, my-topic-698241334-1574461286, --bootstrap-server, my-cluster-83790055-kafka-bootstrap.namespace-45.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-83790055-kafka-clients-6f48f48f8f-cvd89', podNamespace='namespace-45', bootstrapServer='my-cluster-83790055-kafka-bootstrap.namespace-45.svc:9092', topicName='my-topic-698241334-1574461286', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1900850046', consumerInstanceId='instance82818781', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@73ca6bc9}
2022-04-05 19:57:26 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-83790055-kafka-bootstrap.namespace-45.svc:9092#my-topic-698241334-1574461286 from pod my-cluster-83790055-kafka-clients-6f48f48f8f-cvd89
2022-04-05 19:57:26 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-83790055-kafka-clients-6f48f48f8f-cvd89 -n namespace-45 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1900850046 --group-instance-id instance82818781 --topic my-topic-698241334-1574461286 --bootstrap-server my-cluster-83790055-kafka-bootstrap.namespace-45.svc:9092
2022-04-05 19:57:32 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 19:57:32 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 19:57:32 [main] [32mINFO [m [KafkaST:1355] Executing command cd /var/lib/kafka/data/kafka-log0/my-topic-698241334-1574461286-0
/;cat 00000000000000000000.log in my-cluster-83790055-kafka-0
2022-04-05 19:57:32 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-45 exec my-cluster-83790055-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0/my-topic-698241334-1574461286-0
/;cat 00000000000000000000.log
2022-04-05 19:57:32 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:57:32 [main] [32mINFO [m [KafkaST:1364] Deleting kafka pod my-cluster-83790055-kafka-0
2022-04-05 19:57:32 [main] [32mINFO [m [KafkaST:1364] Deleting kafka pod my-cluster-83790055-kafka-clients-6f48f48f8f-cvd89
2022-04-05 19:57:32 [main] [32mINFO [m [KafkaST:1368] Wait for kafka to rolling restart ...
2022-04-05 19:57:32 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-83790055-kafka rolling update
2022-04-05 19:57:37 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-83790055-kafka has been successfully rolled
2022-04-05 19:57:37 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 1 Pod(s) of my-cluster-83790055-kafka to be ready
2022-04-05 19:58:05 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-83790055 will have desired state: Ready
2022-04-05 19:58:05 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-83790055 is in desired state: Ready
2022-04-05 19:58:05 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-83790055 is ready
2022-04-05 19:58:05 [main] [32mINFO [m [KafkaST:1371] Executing command cd /var/lib/kafka/data/kafka-log0/my-topic-698241334-1574461286-0
/;cat 00000000000000000000.log in my-cluster-83790055-kafka-0
2022-04-05 19:58:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-45 exec my-cluster-83790055-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0/my-topic-698241334-1574461286-0
/;cat 00000000000000000000.log
2022-04-05 19:58:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:58:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:58:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMessagesAreStoredInDisk
2022-04-05 19:58:05 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-698241334-1574461286 in namespace namespace-45
2022-04-05 19:58:05 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-83790055-kafka-clients in namespace namespace-45
2022-04-05 19:58:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-83790055 in namespace namespace-45
2022-04-05 19:58:45 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:58:45 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-45 for test case:testMessagesAreStoredInDisk
2022-04-05 19:58:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testMessagesAreStoredInDisk-FINISHED
2022-04-05 19:58:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:58:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:58:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testLabelModificationDoesNotBreakCluster-STARTED
2022-04-05 19:58:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:58:51 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-46 for test case:testLabelModificationDoesNotBreakCluster
2022-04-05 19:58:51 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-46
2022-04-05 19:58:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-46
2022-04-05 19:58:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-46
2022-04-05 19:58:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-498d5d2f in namespace namespace-46
2022-04-05 19:58:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-46
2022-04-05 19:58:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-498d5d2f will have desired state: Ready
2022-04-05 20:00:07 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-498d5d2f is in desired state: Ready
2022-04-05 20:00:07 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-82543548-1176128014 in namespace namespace-46
2022-04-05 20:00:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-46
2022-04-05 20:00:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-82543548-1176128014 will have desired state: Ready
2022-04-05 20:00:08 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-82543548-1176128014 is in desired state: Ready
2022-04-05 20:00:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-498d5d2f-kafka-clients in namespace namespace-46
2022-04-05 20:00:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-46
2022-04-05 20:00:08 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-498d5d2f-kafka-clients will be ready
2022-04-05 20:00:10 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-498d5d2f-kafka-clients is ready
2022-04-05 20:00:10 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 20:00:10 [main] [32mINFO [m [KafkaST:1078] Waiting for kafka stateful set labels changed {label-name-1=name-of-the-label-1, label-name-2=name-of-the-label-2}
2022-04-05 20:00:10 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-1 -> name-of-the-label-1
2022-04-05 20:00:10 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-2 -> name-of-the-label-2
2022-04-05 20:00:10 [main] [32mINFO [m [KafkaST:1081] Getting labels from stateful set resource
2022-04-05 20:00:10 [main] [32mINFO [m [KafkaST:1084] Verifying default labels in the Kafka CR
2022-04-05 20:00:10 [main] [32mINFO [m [KafkaST:1095] Setting new values of labels from name-of-the-label-1 to new-name-of-the-label-1 | from name-of-the-label-2 to new-name-of-the-label-2 and adding one label-name-3 with value name-of-the-label-3
2022-04-05 20:00:10 [main] [32mINFO [m [KafkaST:1098] Edit kafka labels in Kafka CR
2022-04-05 20:00:10 [main] [32mINFO [m [KafkaST:1109] Waiting for kafka service labels changed {label-name-1=new-name-of-the-label-1, label-name-2=new-name-of-the-label-2, label-name-3=name-of-the-label-3}
2022-04-05 20:00:10 [main] [32mINFO [m [ServiceUtils:33] Waiting for Service label change label-name-1 -> new-name-of-the-label-1
2022-04-05 20:00:35 [main] [32mINFO [m [ServiceUtils:33] Waiting for Service label change label-name-2 -> new-name-of-the-label-2
2022-04-05 20:00:35 [main] [32mINFO [m [ServiceUtils:33] Waiting for Service label change label-name-3 -> name-of-the-label-3
2022-04-05 20:00:35 [main] [32mINFO [m [KafkaST:1112] Verifying kafka labels via services
2022-04-05 20:00:35 [main] [32mINFO [m [KafkaST:1118] Waiting for Kafka ConfigMap my-cluster-498d5d2f-kafka-config in namespace namespace-46 to have new labels: {label-name-1=new-name-of-the-label-1, label-name-2=new-name-of-the-label-2, label-name-3=name-of-the-label-3}
2022-04-05 20:00:35 [main] [32mINFO [m [ConfigMapUtils:42] Waiting for ConfigMap my-cluster-498d5d2f-kafka-config label change label-name-1 -> new-name-of-the-label-1
2022-04-05 20:00:35 [main] [32mINFO [m [ConfigMapUtils:42] Waiting for ConfigMap my-cluster-498d5d2f-kafka-config label change label-name-2 -> new-name-of-the-label-2
2022-04-05 20:00:35 [main] [32mINFO [m [ConfigMapUtils:42] Waiting for ConfigMap my-cluster-498d5d2f-kafka-config label change label-name-3 -> name-of-the-label-3
2022-04-05 20:00:35 [main] [32mINFO [m [KafkaST:1121] Verifying Kafka labels on ConfigMap my-cluster-498d5d2f-kafka-config in namespace namespace-46
2022-04-05 20:00:35 [main] [32mINFO [m [KafkaST:1127] Waiting for kafka stateful set labels changed {label-name-1=new-name-of-the-label-1, label-name-2=new-name-of-the-label-2, label-name-3=name-of-the-label-3}
2022-04-05 20:00:35 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-1 -> new-name-of-the-label-1
2022-04-05 20:00:35 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-2 -> new-name-of-the-label-2
2022-04-05 20:00:35 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-3 -> name-of-the-label-3
2022-04-05 20:00:35 [main] [32mINFO [m [KafkaST:1130] Verifying kafka labels via stateful set
2022-04-05 20:00:35 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-498d5d2f-kafka rolling update
2022-04-05 20:01:55 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-498d5d2f-kafka has been successfully rolled
2022-04-05 20:01:55 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-498d5d2f-kafka to be ready
2022-04-05 20:02:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-498d5d2f will have desired state: Ready
2022-04-05 20:02:24 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-498d5d2f is in desired state: Ready
2022-04-05 20:02:24 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-498d5d2f is ready
2022-04-05 20:02:24 [main] [32mINFO [m [KafkaST:1136] Verifying via kafka pods
2022-04-05 20:02:24 [main] [32mINFO [m [KafkaST:1143] Removing labels: label-name-1 -> new-name-of-the-label-1, label-name-2 -> new-name-of-the-label-2, label-name-3 -> name-of-the-label-3
2022-04-05 20:02:24 [main] [32mINFO [m [KafkaST:1155] Waiting for kafka service labels deletion {app.kubernetes.io/instance=my-cluster-498d5d2f, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-498d5d2f, controller-revision-hash=my-cluster-498d5d2f-kafka-bcd9874c7, statefulset.kubernetes.io/pod-name=my-cluster-498d5d2f-kafka-0, strimzi.io/cluster=my-cluster-498d5d2f, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-498d5d2f-kafka, test.case=testLabelModificationDoesNotBreakCluster}
2022-04-05 20:02:24 [main] [32mINFO [m [ServiceUtils:44] Service label label-name-1 change to null
io.strimzi.test.WaitException: Timeout after 180000 ms waiting for Service labellabel-name-1 change to null
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.kubeUtils.objects.ServiceUtils.waitForServiceLabelsDeletion(ServiceUtils.java:45)
	at io.strimzi.systemtest.kafka.KafkaST.testLabelModificationDoesNotBreakCluster(KafkaST.java:1156)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-05 20:05:24 [main] [1;31mERROR[m [TestExecutionWatcher:28] KafkaST - Exception Timeout after 180000 ms waiting for Service labellabel-name-1 change to null has been thrown in @Test. Going to collect logs from components.
2022-04-05 20:05:24 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-04-05 20:05:25 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-04-05 20:05:25 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-04-05 20:05:33 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-04-05 20:05:33 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-04-05 20:05:33 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-04-05 20:05:33 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-04-05 20:05:33 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-05 20:05:33 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace kafka-st
2022-04-05 20:05:33 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace kafka-st
2022-04-05 20:05:33 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace kafka-st
2022-04-05 20:05:33 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace kafka-st
2022-04-05 20:05:33 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace kafka-st
2022-04-05 20:05:34 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace kafka-st
2022-04-05 20:05:34 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace kafka-st
2022-04-05 20:05:34 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-05 20:05:34 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace namespace-46
2022-04-05 20:05:34 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace namespace-46
2022-04-05 20:05:34 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace namespace-46
2022-04-05 20:05:36 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace namespace-46
2022-04-05 20:05:36 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace namespace-46
2022-04-05 20:05:36 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace namespace-46
2022-04-05 20:05:36 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace namespace-46
2022-04-05 20:05:36 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-05 20:05:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:05:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testLabelModificationDoesNotBreakCluster
2022-04-05 20:05:36 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-82543548-1176128014 in namespace namespace-46
2022-04-05 20:05:36 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-498d5d2f-kafka-clients in namespace namespace-46
2022-04-05 20:05:36 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-498d5d2f in namespace namespace-46
2022-04-05 20:06:16 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 20:06:16 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-46 for test case:testLabelModificationDoesNotBreakCluster
2022-04-05 20:06:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testLabelModificationDoesNotBreakCluster-FINISHED
2022-04-05 20:06:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 20:06:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 20:06:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testEODeletion-STARTED
2022-04-05 20:06:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 20:06:22 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-47 for test case:testEODeletion
2022-04-05 20:06:22 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-47
2022-04-05 20:06:22 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-47
2022-04-05 20:06:22 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-47
2022-04-05 20:06:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b28f29ec in namespace namespace-47
2022-04-05 20:06:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-47
2022-04-05 20:06:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b28f29ec will have desired state: Ready
2022-04-05 20:07:41 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b28f29ec is in desired state: Ready
2022-04-05 20:07:41 [main] [32mINFO [m [KafkaST:122] Setting entity operator to null
2022-04-05 20:07:41 [main] [33mWARN [m [DeploymentUtils:213] Deployment my-cluster-b28f29ec-entity-operator is not deleted yet! Triggering force delete by cmd client!
2022-04-05 20:07:46 [main] [33mWARN [m [DeploymentUtils:213] Deployment my-cluster-b28f29ec-entity-operator is not deleted yet! Triggering force delete by cmd client!
2022-04-05 20:07:51 [main] [32mINFO [m [PodUtils:154] Waiting when Pod my-cluster-b28f29ec-entity-operator-5887d79f88-rttrq will be deleted
2022-04-05 20:07:57 [main] [32mINFO [m [PodUtils:171] Pod my-cluster-b28f29ec-entity-operator-5887d79f88-rttrq deleted
2022-04-05 20:07:57 [main] [32mINFO [m [KafkaST:130] Entity operator was deleted
2022-04-05 20:07:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:07:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testEODeletion
2022-04-05 20:07:57 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b28f29ec in namespace namespace-47
2022-04-05 20:08:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 20:08:07 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-47 for test case:testEODeletion
2022-04-05 20:08:50 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testEODeletion-FINISHED
2022-04-05 20:08:50 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 20:08:50 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 20:08:50 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testJvmAndResources-STARTED
2022-04-05 20:08:50 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 20:08:50 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-48 for test case:testJvmAndResources
2022-04-05 20:08:50 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-48
2022-04-05 20:08:50 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-48
2022-04-05 20:08:50 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-48
2022-04-05 20:08:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-215fa7ce in namespace namespace-48
2022-04-05 20:08:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-48
2022-04-05 20:08:50 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-215fa7ce will have desired state: Ready
2022-04-05 20:10:08 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-215fa7ce is in desired state: Ready
2022-04-05 20:10:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-48 exec my-cluster-215fa7ce-kafka-0 -c kafka -- /bin/bash -c for proc in $(ls -1 /proc/ | grep [0-9]); do if echo "$(ls -lh /proc/$proc/exe 2>/dev/null || true)" | grep -q java; then cat /proc/$proc/cmdline; fi; done
2022-04-05 20:10:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:10:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-48 exec my-cluster-215fa7ce-zookeeper-0 -c zookeeper -- /bin/bash -c for proc in $(ls -1 /proc/ | grep [0-9]); do if echo "$(ls -lh /proc/$proc/exe 2>/dev/null || true)" | grep -q java; then cat /proc/$proc/cmdline; fi; done
2022-04-05 20:10:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:10:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-48 exec my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt -c topic-operator -- /bin/bash -c for proc in $(ls -1 /proc/ | grep [0-9]); do if echo "$(ls -lh /proc/$proc/exe 2>/dev/null || true)" | grep -q java; then cat /proc/$proc/cmdline; fi; done
2022-04-05 20:10:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:10:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-48 exec my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt -c user-operator -- /bin/bash -c for proc in $(ls -1 /proc/ | grep [0-9]); do if echo "$(ls -lh /proc/$proc/exe 2>/dev/null || true)" | grep -q java; then cat /proc/$proc/cmdline; fi; done
2022-04-05 20:10:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:10:09 [main] [32mINFO [m [KafkaST:533] Check if -D java options are present in topic-operator
2022-04-05 20:10:09 [main] [32mINFO [m [KafkaST:533] Check if -D java options are present in user-operator
2022-04-05 20:10:09 [main] [32mINFO [m [KafkaST:552] Checking no rolling update for Kafka cluster
2022-04-05 20:10:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 50
2022-04-05 20:10:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 49
2022-04-05 20:10:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 48
2022-04-05 20:10:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 47
2022-04-05 20:10:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 46
2022-04-05 20:10:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 45
2022-04-05 20:10:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 44
2022-04-05 20:10:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 43
2022-04-05 20:10:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 42
2022-04-05 20:10:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 41
2022-04-05 20:10:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 40
2022-04-05 20:10:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 39
2022-04-05 20:10:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 38
2022-04-05 20:10:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 37
2022-04-05 20:10:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 36
2022-04-05 20:10:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 35
2022-04-05 20:10:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 34
2022-04-05 20:10:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 33
2022-04-05 20:10:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 32
2022-04-05 20:10:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 31
2022-04-05 20:10:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 30
2022-04-05 20:10:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 29
2022-04-05 20:10:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 28
2022-04-05 20:10:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 27
2022-04-05 20:10:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 26
2022-04-05 20:10:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 25
2022-04-05 20:10:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 24
2022-04-05 20:10:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 23
2022-04-05 20:10:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 22
2022-04-05 20:10:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 21
2022-04-05 20:10:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 20
2022-04-05 20:10:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 19
2022-04-05 20:10:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 18
2022-04-05 20:10:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 17
2022-04-05 20:10:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 16
2022-04-05 20:10:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 15
2022-04-05 20:10:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 14
2022-04-05 20:10:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 13
2022-04-05 20:10:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 12
2022-04-05 20:10:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 11
2022-04-05 20:10:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 10
2022-04-05 20:10:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 9
2022-04-05 20:10:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 8
2022-04-05 20:10:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 7
2022-04-05 20:10:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 6
2022-04-05 20:10:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 5
2022-04-05 20:10:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 4
2022-04-05 20:10:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 3
2022-04-05 20:10:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 2
2022-04-05 20:10:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 1
2022-04-05 20:10:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-zookeeper-0=72d44a32-7c6a-4557-9f65-2ed1a4fd21a3} pods didn't roll. Remaining seconds for stability: 0
2022-04-05 20:10:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 50
2022-04-05 20:11:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 49
2022-04-05 20:11:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 48
2022-04-05 20:11:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 47
2022-04-05 20:11:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 46
2022-04-05 20:11:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 45
2022-04-05 20:11:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 44
2022-04-05 20:11:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 43
2022-04-05 20:11:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 42
2022-04-05 20:11:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 41
2022-04-05 20:11:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 40
2022-04-05 20:11:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 39
2022-04-05 20:11:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 38
2022-04-05 20:11:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 37
2022-04-05 20:11:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 36
2022-04-05 20:11:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 35
2022-04-05 20:11:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 34
2022-04-05 20:11:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 33
2022-04-05 20:11:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 32
2022-04-05 20:11:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 31
2022-04-05 20:11:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 30
2022-04-05 20:11:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 29
2022-04-05 20:11:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 28
2022-04-05 20:11:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 27
2022-04-05 20:11:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 26
2022-04-05 20:11:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 25
2022-04-05 20:11:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 24
2022-04-05 20:11:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 23
2022-04-05 20:11:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 22
2022-04-05 20:11:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 21
2022-04-05 20:11:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 20
2022-04-05 20:11:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 19
2022-04-05 20:11:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 18
2022-04-05 20:11:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 17
2022-04-05 20:11:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 16
2022-04-05 20:11:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 15
2022-04-05 20:11:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 14
2022-04-05 20:11:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 13
2022-04-05 20:11:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 12
2022-04-05 20:11:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 11
2022-04-05 20:11:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 10
2022-04-05 20:11:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 9
2022-04-05 20:11:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 8
2022-04-05 20:11:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 7
2022-04-05 20:11:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 6
2022-04-05 20:11:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 5
2022-04-05 20:11:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 4
2022-04-05 20:11:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 3
2022-04-05 20:11:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 2
2022-04-05 20:11:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 1
2022-04-05 20:11:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-215fa7ce-kafka-0=5555ae6a-b588-4b7a-8ccc-4d50996d7547} pods didn't roll. Remaining seconds for stability: 0
2022-04-05 20:11:50 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 50
2022-04-05 20:11:51 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 49
2022-04-05 20:11:52 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 48
2022-04-05 20:11:53 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 47
2022-04-05 20:11:54 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 46
2022-04-05 20:11:55 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 45
2022-04-05 20:11:56 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 44
2022-04-05 20:11:57 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 43
2022-04-05 20:11:58 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 42
2022-04-05 20:11:59 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 41
2022-04-05 20:12:00 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 40
2022-04-05 20:12:01 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 39
2022-04-05 20:12:02 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 38
2022-04-05 20:12:03 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 37
2022-04-05 20:12:04 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 36
2022-04-05 20:12:05 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 35
2022-04-05 20:12:06 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 34
2022-04-05 20:12:07 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 33
2022-04-05 20:12:08 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 32
2022-04-05 20:12:09 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 31
2022-04-05 20:12:10 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 30
2022-04-05 20:12:11 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 29
2022-04-05 20:12:12 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 28
2022-04-05 20:12:13 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 27
2022-04-05 20:12:14 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 26
2022-04-05 20:12:15 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 25
2022-04-05 20:12:16 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 24
2022-04-05 20:12:17 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 23
2022-04-05 20:12:18 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 22
2022-04-05 20:12:19 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 21
2022-04-05 20:12:20 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 20
2022-04-05 20:12:21 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 19
2022-04-05 20:12:22 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 18
2022-04-05 20:12:23 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 17
2022-04-05 20:12:24 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 16
2022-04-05 20:12:25 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 15
2022-04-05 20:12:26 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 14
2022-04-05 20:12:27 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 13
2022-04-05 20:12:28 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 12
2022-04-05 20:12:29 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 11
2022-04-05 20:12:30 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 10
2022-04-05 20:12:31 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 9
2022-04-05 20:12:32 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 8
2022-04-05 20:12:33 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 7
2022-04-05 20:12:34 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 6
2022-04-05 20:12:35 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 5
2022-04-05 20:12:36 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 4
2022-04-05 20:12:37 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 3
2022-04-05 20:12:38 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 2
2022-04-05 20:12:39 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 1
2022-04-05 20:12:40 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-215fa7ce-entity-operator-755cfc6bff-c2xgt=6c4e0877-3815-4e43-acc0-021097ff458a} pods not rolling waiting, remaining seconds for stability 0
2022-04-05 20:12:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:12:40 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testJvmAndResources
2022-04-05 20:12:40 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-215fa7ce in namespace namespace-48
2022-04-05 20:12:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 20:12:50 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-48 for test case:testJvmAndResources
2022-04-05 20:12:56 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testJvmAndResources-FINISHED
2022-04-05 20:12:56 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 20:12:56 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 20:12:56 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testPersistentStorageSize-STARTED
2022-04-05 20:12:56 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 20:12:56 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-49 for test case:testPersistentStorageSize
2022-04-05 20:12:56 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-49
2022-04-05 20:12:56 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-49
2022-04-05 20:12:56 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-49
2022-04-05 20:12:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-29edb199 in namespace namespace-49
2022-04-05 20:12:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-49
2022-04-05 20:12:56 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-29edb199 will have desired state: Ready
2022-04-05 20:14:09 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-29edb199 is in desired state: Ready
2022-04-05 20:14:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1725432711-907942224 in namespace namespace-49
2022-04-05 20:14:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-49
2022-04-05 20:14:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1725432711-907942224 will have desired state: Ready
2022-04-05 20:14:10 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1725432711-907942224 is in desired state: Ready
2022-04-05 20:14:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-29edb199-kafka-clients in namespace namespace-49
2022-04-05 20:14:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-49
2022-04-05 20:14:10 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-29edb199-kafka-clients will be ready
2022-04-05 20:14:12 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-29edb199-kafka-clients is ready
2022-04-05 20:14:12 [main] [32mINFO [m [KafkaST:1694] Checking volume data-0-my-cluster-29edb199-kafka-0 and size of storage 70Gi
2022-04-05 20:14:12 [main] [32mINFO [m [KafkaST:1694] Checking volume data-0-my-cluster-29edb199-kafka-1 and size of storage 70Gi
2022-04-05 20:14:12 [main] [32mINFO [m [KafkaST:1694] Checking volume data-1-my-cluster-29edb199-kafka-0 and size of storage 20Gi
2022-04-05 20:14:12 [main] [32mINFO [m [KafkaST:1694] Checking volume data-1-my-cluster-29edb199-kafka-1 and size of storage 20Gi
2022-04-05 20:14:12 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 20:14:12 [main] [32mINFO [m [KafkaST:983] Checking produced and consumed messages to pod:my-cluster-29edb199-kafka-clients-5c4c9bcf57-qvq6b
2022-04-05 20:14:12 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@59dc37e4, messages=[], arguments=[--max-messages, 100, --topic, my-topic-1725432711-907942224, --bootstrap-server, my-cluster-29edb199-kafka-bootstrap.namespace-49.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-29edb199-kafka-clients-5c4c9bcf57-qvq6b', podNamespace='namespace-49', bootstrapServer='my-cluster-29edb199-kafka-bootstrap.namespace-49.svc:9092', topicName='my-topic-1725432711-907942224', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@694fa225}
2022-04-05 20:14:12 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-29edb199-kafka-bootstrap.namespace-49.svc:9092:my-topic-1725432711-907942224 from pod my-cluster-29edb199-kafka-clients-5c4c9bcf57-qvq6b
2022-04-05 20:14:12 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-29edb199-kafka-clients-5c4c9bcf57-qvq6b -n namespace-49 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-1725432711-907942224 --bootstrap-server my-cluster-29edb199-kafka-bootstrap.namespace-49.svc:9092
2022-04-05 20:14:14 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 20:14:14 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 20:14:14 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5e271b8d, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-775881422, --group-instance-id, instance29260324, --topic, my-topic-1725432711-907942224, --bootstrap-server, my-cluster-29edb199-kafka-bootstrap.namespace-49.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-29edb199-kafka-clients-5c4c9bcf57-qvq6b', podNamespace='namespace-49', bootstrapServer='my-cluster-29edb199-kafka-bootstrap.namespace-49.svc:9092', topicName='my-topic-1725432711-907942224', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-775881422', consumerInstanceId='instance29260324', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4a6dc66f}
2022-04-05 20:14:14 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-29edb199-kafka-bootstrap.namespace-49.svc:9092#my-topic-1725432711-907942224 from pod my-cluster-29edb199-kafka-clients-5c4c9bcf57-qvq6b
2022-04-05 20:14:14 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-29edb199-kafka-clients-5c4c9bcf57-qvq6b -n namespace-49 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-775881422 --group-instance-id instance29260324 --topic my-topic-1725432711-907942224 --bootstrap-server my-cluster-29edb199-kafka-bootstrap.namespace-49.svc:9092
2022-04-05 20:14:20 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 20:14:20 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 20:14:20 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:14:20 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testPersistentStorageSize
2022-04-05 20:14:20 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1725432711-907942224 in namespace namespace-49
2022-04-05 20:14:20 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-29edb199-kafka-clients in namespace namespace-49
2022-04-05 20:14:20 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-29edb199 in namespace namespace-49
2022-04-05 20:15:00 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 20:15:00 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-49 for test case:testPersistentStorageSize
2022-04-05 20:15:06 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testPersistentStorageSize-FINISHED
2022-04-05 20:15:06 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 20:15:06 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 20:15:06 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testForTopicOperator-STARTED
2022-04-05 20:15:06 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 20:15:06 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-50 for test case:testForTopicOperator
2022-04-05 20:15:06 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-50
2022-04-05 20:15:06 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-50
2022-04-05 20:15:06 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-50
2022-04-05 20:15:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-8a62471c in namespace namespace-50
2022-04-05 20:15:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-50
2022-04-05 20:15:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8a62471c will have desired state: Ready
2022-04-05 20:16:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8a62471c is in desired state: Ready
2022-04-05 20:16:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-226225918-1502477846 in namespace namespace-50
2022-04-05 20:16:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-50
2022-04-05 20:16:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-226225918-1502477846 will have desired state: Ready
2022-04-05 20:16:22 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-226225918-1502477846 is in desired state: Ready
2022-04-05 20:16:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-226225918-1502477846 will have desired state: Ready
2022-04-05 20:16:22 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-226225918-1502477846 is in desired state: Ready
2022-04-05 20:16:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-50 exec my-cluster-8a62471c-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-05 20:16:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:16:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-50 exec my-cluster-8a62471c-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --create  --topic topic-from-cli --replication-factor 1 --partitions 1
2022-04-05 20:16:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:16:28 [main] [32mINFO [m [KafkaTopicUtils:78] Waiting for KafkaTopic topic-from-cli creation 
2022-04-05 20:16:31 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-50 exec my-cluster-8a62471c-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-05 20:16:31 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:16:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-50 exec my-cluster-8a62471c-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic my-topic-226225918-1502477846 --partitions 2
2022-04-05 20:16:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:16:34 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8a62471c will have desired state: Ready
2022-04-05 20:16:34 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8a62471c is in desired state: Ready
2022-04-05 20:16:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-50 exec my-cluster-8a62471c-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic my-topic-226225918-1502477846
2022-04-05 20:16:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:16:37 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8a62471c will have desired state: Ready
2022-04-05 20:16:37 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8a62471c is in desired state: Ready
2022-04-05 20:16:40 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-50 exec my-cluster-8a62471c-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic topic-from-cli
2022-04-05 20:16:40 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:16:43 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-50 exec my-cluster-8a62471c-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic my-topic-226225918-1502477846
2022-04-05 20:16:43 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:16:43 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-226225918-1502477846 deletion
2022-04-05 20:16:43 [main] [33mWARN [m [KafkaTopicUtils:110] KafkaTopic my-topic-226225918-1502477846 is not deleted yet! Triggering force delete by cmd client!
2022-04-05 20:16:56 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-50 exec my-cluster-8a62471c-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-05 20:16:56 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:16:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:16:56 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testForTopicOperator
2022-04-05 20:16:56 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-226225918-1502477846 in namespace namespace-50
2022-04-05 20:16:56 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-8a62471c in namespace namespace-50
2022-04-05 20:17:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 20:17:06 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-50 for test case:testForTopicOperator
2022-04-05 20:17:50 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testForTopicOperator-FINISHED
2022-04-05 20:17:50 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 20:17:50 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 20:17:50 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testReadOnlyRootFileSystem-STARTED
2022-04-05 20:17:50 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 20:17:50 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-51 for test case:testReadOnlyRootFileSystem
2022-04-05 20:17:50 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-51
2022-04-05 20:17:50 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-51
2022-04-05 20:17:50 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-51
2022-04-05 20:17:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-8fb5b1db in namespace namespace-51
2022-04-05 20:17:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-51
2022-04-05 20:17:50 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8fb5b1db will have desired state: Ready
2022-04-05 20:20:17 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8fb5b1db is in desired state: Ready
2022-04-05 20:20:17 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8fb5b1db will have desired state: Ready
2022-04-05 20:20:17 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8fb5b1db is in desired state: Ready
2022-04-05 20:20:17 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1554287772-1078586589 in namespace namespace-51
2022-04-05 20:20:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-51
2022-04-05 20:20:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1554287772-1078586589 will have desired state: Ready
2022-04-05 20:20:18 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1554287772-1078586589 is in desired state: Ready
2022-04-05 20:20:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-8fb5b1db-kafka-clients in namespace namespace-51
2022-04-05 20:20:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-51
2022-04-05 20:20:18 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-8fb5b1db-kafka-clients will be ready
2022-04-05 20:20:20 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-8fb5b1db-kafka-clients is ready
2022-04-05 20:20:20 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 20:20:20 [main] [32mINFO [m [KafkaST:1652] Checking produced and consumed messages to pod:my-cluster-8fb5b1db-kafka-clients-64ddc8b655-nqhkh
2022-04-05 20:20:20 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@14dfeb6d, messages=[], arguments=[--max-messages, 100, --topic, my-topic-1554287772-1078586589, --bootstrap-server, my-cluster-8fb5b1db-kafka-bootstrap.namespace-51.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-8fb5b1db-kafka-clients-64ddc8b655-nqhkh', podNamespace='namespace-51', bootstrapServer='my-cluster-8fb5b1db-kafka-bootstrap.namespace-51.svc:9092', topicName='my-topic-1554287772-1078586589', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@70f49dbb}
2022-04-05 20:20:20 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-8fb5b1db-kafka-bootstrap.namespace-51.svc:9092:my-topic-1554287772-1078586589 from pod my-cluster-8fb5b1db-kafka-clients-64ddc8b655-nqhkh
2022-04-05 20:20:20 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-8fb5b1db-kafka-clients-64ddc8b655-nqhkh -n namespace-51 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-1554287772-1078586589 --bootstrap-server my-cluster-8fb5b1db-kafka-bootstrap.namespace-51.svc:9092
2022-04-05 20:20:23 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 20:20:23 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 20:20:23 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@750af933, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-2135447968, --group-instance-id, instance1446316374, --topic, my-topic-1554287772-1078586589, --bootstrap-server, my-cluster-8fb5b1db-kafka-bootstrap.namespace-51.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-8fb5b1db-kafka-clients-64ddc8b655-nqhkh', podNamespace='namespace-51', bootstrapServer='my-cluster-8fb5b1db-kafka-bootstrap.namespace-51.svc:9092', topicName='my-topic-1554287772-1078586589', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-2135447968', consumerInstanceId='instance1446316374', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@21c7b1f5}
2022-04-05 20:20:23 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-8fb5b1db-kafka-bootstrap.namespace-51.svc:9092#my-topic-1554287772-1078586589 from pod my-cluster-8fb5b1db-kafka-clients-64ddc8b655-nqhkh
2022-04-05 20:20:23 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-8fb5b1db-kafka-clients-64ddc8b655-nqhkh -n namespace-51 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-2135447968 --group-instance-id instance1446316374 --topic my-topic-1554287772-1078586589 --bootstrap-server my-cluster-8fb5b1db-kafka-bootstrap.namespace-51.svc:9092
2022-04-05 20:20:28 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 20:20:28 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 20:20:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:20:28 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testReadOnlyRootFileSystem
2022-04-05 20:20:28 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1554287772-1078586589 in namespace namespace-51
2022-04-05 20:20:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-8fb5b1db in namespace namespace-51
2022-04-05 20:20:28 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-8fb5b1db-kafka-clients in namespace namespace-51
2022-04-05 20:20:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-51, for cruise control Kafka cluster my-cluster-8fb5b1db
2022-04-05 20:21:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 20:21:08 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-51 for test case:testReadOnlyRootFileSystem
2022-04-05 20:21:14 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testReadOnlyRootFileSystem-FINISHED
2022-04-05 20:21:14 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 20:21:14 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 20:21:14 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testCustomAndUpdatedValues-STARTED
2022-04-05 20:21:14 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 20:21:14 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-52 for test case:testCustomAndUpdatedValues
2022-04-05 20:21:14 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-52
2022-04-05 20:21:14 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-52
2022-04-05 20:21:14 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-52
2022-04-05 20:21:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-673aa122 in namespace namespace-52
2022-04-05 20:21:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-52
2022-04-05 20:21:14 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-673aa122 will have desired state: Ready
2022-04-05 20:23:50 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-673aa122 is in desired state: Ready
2022-04-05 20:23:50 [main] [32mINFO [m [KafkaST:290] Verify values before update
2022-04-05 20:23:50 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-673aa122-kafka in pod name
2022-04-05 20:23:50 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container kafka
2022-04-05 20:23:50 [main] [32mINFO [m [KafkaST:1661] Checking kafka configuration
2022-04-05 20:23:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-52 exec my-cluster-673aa122-kafka-0 -- /bin/bash -c cat /tmp/strimzi.properties
2022-04-05 20:23:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:23:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-52 exec my-cluster-673aa122-kafka-1 -- /bin/bash -c cat /tmp/strimzi.properties
2022-04-05 20:23:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:23:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-52 exec my-cluster-673aa122-kafka-2 -- /bin/bash -c cat /tmp/strimzi.properties
2022-04-05 20:23:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:23:50 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-673aa122-kafka
2022-04-05 20:23:50 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container kafka
2022-04-05 20:23:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-52 exec my-cluster-673aa122-kafka-0 -- cat /tmp/strimzi.properties
2022-04-05 20:23:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:23:50 [main] [32mINFO [m [KafkaST:308] Testing Zookeepers
2022-04-05 20:23:50 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-673aa122-zookeeper in pod name
2022-04-05 20:23:50 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container zookeeper
2022-04-05 20:23:50 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-673aa122-zookeeper
2022-04-05 20:23:50 [main] [32mINFO [m [AbstractST:194] Testing configuration for container zookeeper
2022-04-05 20:23:50 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-673aa122-zookeeper
2022-04-05 20:23:50 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container zookeeper
2022-04-05 20:23:50 [main] [32mINFO [m [KafkaST:315] Checking configuration of TO and UO
2022-04-05 20:23:50 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-673aa122-entity-operator in pod name
2022-04-05 20:23:50 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container topic-operator
2022-04-05 20:23:50 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-673aa122-entity-operator
2022-04-05 20:23:50 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container topic-operator
2022-04-05 20:23:50 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-673aa122-entity-operator in pod name
2022-04-05 20:23:50 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container user-operator
2022-04-05 20:23:50 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-673aa122-entity-operator
2022-04-05 20:23:50 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container user-operator
2022-04-05 20:23:50 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-673aa122-entity-operator in pod name
2022-04-05 20:23:50 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container tls-sidecar
2022-04-05 20:23:50 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-673aa122-entity-operator
2022-04-05 20:23:50 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container tls-sidecar
2022-04-05 20:23:50 [main] [32mINFO [m [KafkaST:326] Updating configuration of Kafka cluster
2022-04-05 20:23:50 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-673aa122-zookeeper rolling update
2022-04-05 20:25:36 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-673aa122-zookeeper has been successfully rolled
2022-04-05 20:25:36 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-673aa122-zookeeper to be ready
2022-04-05 20:26:18 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-673aa122 will have desired state: Ready
2022-04-05 20:26:18 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-673aa122 is in desired state: Ready
2022-04-05 20:26:18 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-673aa122 is ready
2022-04-05 20:26:18 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-673aa122-kafka rolling update
2022-04-05 20:27:38 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-673aa122-kafka has been successfully rolled
2022-04-05 20:27:38 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-673aa122-kafka to be ready
2022-04-05 20:28:19 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-673aa122 will have desired state: Ready
2022-04-05 20:28:19 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-673aa122 is in desired state: Ready
2022-04-05 20:28:19 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-673aa122 is ready
2022-04-05 20:28:19 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-673aa122-entity-operator rolling update
2022-04-05 20:28:19 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-673aa122-entity-operator will be ready
2022-04-05 20:30:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-673aa122-entity-operator is ready
2022-04-05 20:30:38 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-673aa122-entity-operator rolling update finished
2022-04-05 20:30:38 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-673aa122 will have desired state: Ready
2022-04-05 20:30:38 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-673aa122 is in desired state: Ready
2022-04-05 20:30:38 [main] [32mINFO [m [KafkaST:386] Verify values after update
2022-04-05 20:30:38 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-673aa122-kafka in pod name
2022-04-05 20:30:38 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container kafka
2022-04-05 20:30:38 [main] [32mINFO [m [KafkaST:1661] Checking kafka configuration
2022-04-05 20:30:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-52 exec my-cluster-673aa122-kafka-0 -- /bin/bash -c cat /tmp/strimzi.properties
2022-04-05 20:30:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:30:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-52 exec my-cluster-673aa122-kafka-1 -- /bin/bash -c cat /tmp/strimzi.properties
2022-04-05 20:30:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:30:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-52 exec my-cluster-673aa122-kafka-2 -- /bin/bash -c cat /tmp/strimzi.properties
2022-04-05 20:30:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:30:38 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-673aa122-kafka
2022-04-05 20:30:38 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container kafka
2022-04-05 20:30:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-52 exec my-cluster-673aa122-kafka-0 -- cat /tmp/strimzi.properties
2022-04-05 20:30:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:30:38 [main] [32mINFO [m [KafkaST:404] Testing Zookeepers
2022-04-05 20:30:38 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-673aa122-zookeeper in pod name
2022-04-05 20:30:38 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container zookeeper
2022-04-05 20:30:38 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-673aa122-zookeeper
2022-04-05 20:30:38 [main] [32mINFO [m [AbstractST:194] Testing configuration for container zookeeper
2022-04-05 20:30:38 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-673aa122-zookeeper
2022-04-05 20:30:38 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container zookeeper
2022-04-05 20:30:38 [main] [32mINFO [m [KafkaST:410] Getting entity operator to check configuration of TO and UO
2022-04-05 20:30:38 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-673aa122-entity-operator in pod name
2022-04-05 20:30:38 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container topic-operator
2022-04-05 20:30:38 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-673aa122-entity-operator
2022-04-05 20:30:38 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container topic-operator
2022-04-05 20:30:38 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-673aa122-entity-operator in pod name
2022-04-05 20:30:38 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container user-operator
2022-04-05 20:30:38 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-673aa122-entity-operator
2022-04-05 20:30:38 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container user-operator
2022-04-05 20:30:38 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-673aa122-entity-operator in pod name
2022-04-05 20:30:38 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container tls-sidecar
2022-04-05 20:30:38 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-673aa122-entity-operator
2022-04-05 20:30:38 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container tls-sidecar
2022-04-05 20:30:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:30:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCustomAndUpdatedValues
2022-04-05 20:30:38 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-673aa122 in namespace namespace-52
2022-04-05 20:30:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 20:30:49 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-52 for test case:testCustomAndUpdatedValues
2022-04-05 20:31:16 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testCustomAndUpdatedValues-FINISHED
2022-04-05 20:31:16 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 20:31:16 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 20:31:16 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testKafkaJBODDeleteClaimsTrue-STARTED
2022-04-05 20:31:16 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 20:31:16 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-53 for test case:testKafkaJBODDeleteClaimsTrue
2022-04-05 20:31:16 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-53
2022-04-05 20:31:16 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-53
2022-04-05 20:31:16 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-53
2022-04-05 20:31:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-86ae144b in namespace namespace-53
2022-04-05 20:31:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-53
2022-04-05 20:31:16 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-86ae144b will have desired state: Ready
2022-04-05 20:33:05 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-86ae144b is in desired state: Ready
2022-04-05 20:33:05 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-0-my-cluster-86ae144b-kafka-0
2022-04-05 20:33:05 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-0-my-cluster-86ae144b-kafka-1
2022-04-05 20:33:05 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-1-my-cluster-86ae144b-kafka-0
2022-04-05 20:33:05 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-1-my-cluster-86ae144b-kafka-1
2022-04-05 20:33:05 [main] [32mINFO [m [KafkaST:1717] Checking PVC names included in JBOD array
2022-04-05 20:33:05 [main] [32mINFO [m [KafkaST:1724] Checking PVC on Kafka pods
2022-04-05 20:33:05 [main] [32mINFO [m [KafkaST:1729] Getting list of mounted data sources and PVCs on Kafka pod 0
2022-04-05 20:33:05 [main] [32mINFO [m [KafkaST:1737] Verifying mounted data sources and PVCs on Kafka pod 0
2022-04-05 20:33:05 [main] [32mINFO [m [KafkaST:1729] Getting list of mounted data sources and PVCs on Kafka pod 1
2022-04-05 20:33:05 [main] [32mINFO [m [KafkaST:1737] Verifying mounted data sources and PVCs on Kafka pod 1
2022-04-05 20:33:05 [main] [32mINFO [m [KafkaST:906] Deleting cluster
2022-04-05 20:33:05 [main] [32mINFO [m [KafkaST:909] Waiting for PVC deletion
2022-04-05 20:33:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:33:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaJBODDeleteClaimsTrue
2022-04-05 20:33:45 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-86ae144b in namespace namespace-53
2022-04-05 20:33:45 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 20:33:45 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-53 for test case:testKafkaJBODDeleteClaimsTrue
2022-04-05 20:33:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testKafkaJBODDeleteClaimsTrue-FINISHED
2022-04-05 20:33:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 20:33:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 20:33:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testKafkaJBODDeleteClaimsFalse-STARTED
2022-04-05 20:33:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 20:33:51 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-54 for test case:testKafkaJBODDeleteClaimsFalse
2022-04-05 20:33:51 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-54
2022-04-05 20:33:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-54
2022-04-05 20:33:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-54
2022-04-05 20:33:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5f5c15eb in namespace namespace-54
2022-04-05 20:33:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-54
2022-04-05 20:33:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5f5c15eb will have desired state: Ready
2022-04-05 20:36:04 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5f5c15eb is in desired state: Ready
2022-04-05 20:36:04 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-0-my-cluster-5f5c15eb-kafka-0
2022-04-05 20:36:04 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-0-my-cluster-5f5c15eb-kafka-1
2022-04-05 20:36:04 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-1-my-cluster-5f5c15eb-kafka-0
2022-04-05 20:36:04 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-1-my-cluster-5f5c15eb-kafka-1
2022-04-05 20:36:04 [main] [32mINFO [m [KafkaST:1717] Checking PVC names included in JBOD array
2022-04-05 20:36:04 [main] [32mINFO [m [KafkaST:1724] Checking PVC on Kafka pods
2022-04-05 20:36:04 [main] [32mINFO [m [KafkaST:1729] Getting list of mounted data sources and PVCs on Kafka pod 0
2022-04-05 20:36:04 [main] [32mINFO [m [KafkaST:1737] Verifying mounted data sources and PVCs on Kafka pod 0
2022-04-05 20:36:04 [main] [32mINFO [m [KafkaST:1729] Getting list of mounted data sources and PVCs on Kafka pod 1
2022-04-05 20:36:04 [main] [32mINFO [m [KafkaST:1737] Verifying mounted data sources and PVCs on Kafka pod 1
2022-04-05 20:36:04 [main] [32mINFO [m [KafkaST:930] Deleting cluster
2022-04-05 20:36:04 [main] [32mINFO [m [KafkaST:933] Waiting for PVC deletion
2022-04-05 20:36:04 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:36:04 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaJBODDeleteClaimsFalse
2022-04-05 20:36:04 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5f5c15eb in namespace namespace-54
2022-04-05 20:36:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 20:36:04 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-54 for test case:testKafkaJBODDeleteClaimsFalse
2022-04-05 20:36:48 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testKafkaJBODDeleteClaimsFalse-FINISHED
2022-04-05 20:36:48 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 20:36:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:36:48 [main] [32mINFO [m [ResourceManager:346] In context KafkaST is everything deleted.
2022-04-05 20:36:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;31mERROR[m] Tests run: 23, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 4,902.65 s <<< FAILURE! - in io.strimzi.systemtest.kafka.KafkaST
[[1;31mERROR[m] io.strimzi.systemtest.kafka.KafkaST.testLabelModificationDoesNotBreakCluster(ExtensionContext)  Time elapsed: 451.199 s  <<< ERROR!
io.strimzi.test.WaitException: Timeout after 180000 ms waiting for Service labellabel-name-1 change to null
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.kubeUtils.objects.ServiceUtils.waitForServiceLabelsDeletion(ServiceUtils.java:45)
	at io.strimzi.systemtest.kafka.KafkaST.testLabelModificationDoesNotBreakCluster(KafkaST.java:1156)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)

[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.ConfigProviderST
2022-04-05 20:36:53 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: config-provider-st
2022-04-05 20:36:53 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: config-provider-st
2022-04-05 20:36:53 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: config-provider-st
2022-04-05 20:36:53 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 20:36:53 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.ConfigProviderST.testConnectWithConnectorUsingConfigAndEnvProvider-STARTED
2022-04-05 20:36:53 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 20:36:53 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-55 for test case:testConnectWithConnectorUsingConfigAndEnvProvider
2022-04-05 20:36:53 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-55
2022-04-05 20:36:53 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-55
2022-04-05 20:36:53 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-55
2022-04-05 20:36:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2750806a in namespace namespace-55
2022-04-05 20:36:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-55
2022-04-05 20:36:53 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2750806a will have desired state: Ready
2022-04-05 20:38:06 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2750806a is in desired state: Ready
2022-04-05 20:38:06 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-2750806a in namespace namespace-55
2022-04-05 20:38:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-55
2022-04-05 20:38:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-2750806a will have desired state: Ready
2022-04-05 20:39:13 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-2750806a is in desired state: Ready
2022-04-05 20:39:13 [main] [32mINFO [m [ConfigProviderST:100] Creating needed RoleBinding and Role for Kubernetes Config Provider
2022-04-05 20:39:13 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding connector-config-rb in namespace namespace-55
2022-04-05 20:39:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-55
2022-04-05 20:39:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-2750806a in namespace namespace-55
2022-04-05 20:39:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-55
2022-04-05 20:39:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-2750806a will have desired state: Ready
2022-04-05 20:39:14 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-2750806a is in desired state: Ready
2022-04-05 20:39:14 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 20:39:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-my-consumer-group-390617051 in namespace namespace-55
2022-04-05 20:39:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-55
2022-04-05 20:39:14 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-my-consumer-group-390617051 will be in active state
2022-04-05 20:39:15 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-2750806a-connect-7b689d57d6-chmdf
2022-04-05 20:39:20 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-2750806a-connect-7b689d57d6-chmdf
2022-04-05 20:39:20 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:39:20 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConnectWithConnectorUsingConfigAndEnvProvider
2022-04-05 20:39:20 [main] [32mINFO [m [ResourceManager:241] Delete of RoleBinding connector-config-rb in namespace namespace-55
2022-04-05 20:39:20 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2750806a in namespace namespace-55
2022-04-05 20:39:20 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-2750806a in namespace namespace-55
2022-04-05 20:39:20 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-2750806a in namespace namespace-55
2022-04-05 20:39:20 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job producer-my-consumer-group-390617051 in namespace namespace-55
2022-04-05 20:39:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 20:39:30 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-55 for test case:testConnectWithConnectorUsingConfigAndEnvProvider
2022-04-05 20:40:13 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.ConfigProviderST.testConnectWithConnectorUsingConfigAndEnvProvider-FINISHED
2022-04-05 20:40:13 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 20:40:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:40:13 [main] [32mINFO [m [ResourceManager:346] In context ConfigProviderST is everything deleted.
2022-04-05 20:40:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 205.439 s - in io.strimzi.systemtest.kafka.ConfigProviderST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.custom.CustomAuthorizerST
2022-04-05 20:40:19 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: custom-authorizer-st
2022-04-05 20:40:19 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: custom-authorizer-st
2022-04-05 20:40:19 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: custom-authorizer-st
2022-04-05 20:40:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka custom-authorizer in namespace custom-authorizer-st
2022-04-05 20:40:19 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: custom-authorizer will have desired state: Ready
2022-04-05 20:41:36 [main] [32mINFO [m [ResourceManager:444] Kafka: custom-authorizer is in desired state: Ready
2022-04-05 20:41:36 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 20:41:36 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.custom.CustomAuthorizerST.testAclWithSuperUser-STARTED
2022-04-05 20:41:36 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 20:41:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1923176365-1276757881 in namespace custom-authorizer-st
2022-04-05 20:41:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1923176365-1276757881 will have desired state: Ready
2022-04-05 20:41:37 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1923176365-1276757881 is in desired state: Ready
2022-04-05 20:41:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser sre-admin in namespace custom-authorizer-st
2022-04-05 20:41:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: sre-admin will have desired state: Ready
2022-04-05 20:41:38 [main] [32mINFO [m [ResourceManager:444] KafkaUser: sre-admin is in desired state: Ready
2022-04-05 20:41:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-170b437b-kafka-clients in namespace custom-authorizer-st
2022-04-05 20:41:38 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-170b437b-kafka-clients will be ready
2022-04-05 20:41:40 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-170b437b-kafka-clients is ready
2022-04-05 20:41:40 [main] [32mINFO [m [CustomAuthorizerST:173] Checking kafka super user:sre-admin that is able to send messages to topic:my-topic-1923176365-1276757881
2022-04-05 20:41:40 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 20:41:40 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@24c2ade5, messages=[], arguments=[--max-messages, 100, --topic, my-topic-1923176365-1276757881, --bootstrap-server, custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093, USER=sre_admin], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-170b437b-kafka-clients-69c54fc8-5phxb', podNamespace='custom-authorizer-st', bootstrapServer='custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093', topicName='my-topic-1923176365-1276757881', maxMessages=100, kafkaUsername='sre-admin', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5d700579}
2022-04-05 20:41:40 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093:my-topic-1923176365-1276757881 from pod my-cluster-170b437b-kafka-clients-69c54fc8-5phxb
2022-04-05 20:41:40 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-170b437b-kafka-clients-69c54fc8-5phxb -n custom-authorizer-st -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-1923176365-1276757881 --bootstrap-server custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093 USER=sre_admin
2022-04-05 20:41:44 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 20:41:44 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 20:41:44 [main] [32mINFO [m [CustomAuthorizerST:187] Checking kafka super user:sre-admin that is able to read messages to topic:my-topic-57885039-819052364 regardless that we configured Acls with only write operation
2022-04-05 20:41:44 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2a1bdf9a, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-2133407808, --group-instance-id, instance1342504145, --topic, my-topic-1923176365-1276757881, --bootstrap-server, custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093, USER=sre_admin], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-170b437b-kafka-clients-69c54fc8-5phxb', podNamespace='custom-authorizer-st', bootstrapServer='custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093', topicName='my-topic-1923176365-1276757881', maxMessages=100, kafkaUsername='sre-admin', consumerGroupName='my-consumer-group-2133407808', consumerInstanceId='instance1342504145', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@771d47cd}
2022-04-05 20:41:44 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093:my-topic-1923176365-1276757881 from pod my-cluster-170b437b-kafka-clients-69c54fc8-5phxb
2022-04-05 20:41:44 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-170b437b-kafka-clients-69c54fc8-5phxb -n custom-authorizer-st -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-2133407808 --group-instance-id instance1342504145 --topic my-topic-1923176365-1276757881 --bootstrap-server custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093 USER=sre_admin
2022-04-05 20:41:51 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 20:41:51 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 20:41:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:41:51 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAclWithSuperUser
2022-04-05 20:41:51 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser sre-admin in namespace custom-authorizer-st
2022-04-05 20:41:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1923176365-1276757881 in namespace custom-authorizer-st
2022-04-05 20:41:51 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-170b437b-kafka-clients in namespace custom-authorizer-st
2022-04-05 20:42:41 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 20:42:41 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.custom.CustomAuthorizerST.testAclWithSuperUser-FINISHED
2022-04-05 20:42:41 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 20:42:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 20:42:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.custom.CustomAuthorizerST.testAclRuleReadAndWrite-STARTED
2022-04-05 20:42:41 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 20:42:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1709746488-961593547 in namespace custom-authorizer-st
2022-04-05 20:42:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1709746488-961593547 will have desired state: Ready
2022-04-05 20:42:42 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1709746488-961593547 is in desired state: Ready
2022-04-05 20:42:42 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser kafka-user-write in namespace custom-authorizer-st
2022-04-05 20:42:42 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: kafka-user-write will have desired state: Ready
2022-04-05 20:42:43 [main] [32mINFO [m [ResourceManager:444] KafkaUser: kafka-user-write is in desired state: Ready
2022-04-05 20:42:43 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser kafka-user-read in namespace custom-authorizer-st
2022-04-05 20:42:43 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: kafka-user-read will have desired state: Ready
2022-04-05 20:42:44 [main] [32mINFO [m [ResourceManager:444] KafkaUser: kafka-user-read is in desired state: Ready
2022-04-05 20:42:44 [main] [32mINFO [m [CustomAuthorizerST:105] Checking KafkaUser kafka-user-write that is able to send messages to topic 'my-topic-1709746488-961593547'
2022-04-05 20:42:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-97cf789b-kafka-clients in namespace custom-authorizer-st
2022-04-05 20:42:44 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-97cf789b-kafka-clients will be ready
2022-04-05 20:42:46 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-97cf789b-kafka-clients is ready
2022-04-05 20:42:46 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 20:42:46 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5eb92a0f, messages=[], arguments=[--max-messages, 500, --topic, my-topic-1709746488-961593547, --bootstrap-server, custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093, USER=kafka_user_write], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-97cf789b-kafka-clients-5b6fc8b456-th8hx', podNamespace='custom-authorizer-st', bootstrapServer='custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093', topicName='my-topic-1709746488-961593547', maxMessages=500, kafkaUsername='kafka-user-write', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@756a5421}
2022-04-05 20:42:46 [main] [32mINFO [m [InternalKafkaClient:124] Producing 500 messages to custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093:my-topic-1709746488-961593547 from pod my-cluster-97cf789b-kafka-clients-5b6fc8b456-th8hx
2022-04-05 20:42:46 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-97cf789b-kafka-clients-5b6fc8b456-th8hx -n custom-authorizer-st -- /opt/kafka/producer.sh --max-messages 500 --topic my-topic-1709746488-961593547 --bootstrap-server custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093 USER=kafka_user_write
2022-04-05 20:42:49 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 20:42:49 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 500 messages
2022-04-05 20:42:49 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6260be51, messages=[], arguments=[--max-messages, 500, --group-id, my-consumer-group-1470167597, --group-instance-id, instance1445783878, --topic, my-topic-1709746488-961593547, --bootstrap-server, custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093, USER=kafka_user_write], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-97cf789b-kafka-clients-5b6fc8b456-th8hx', podNamespace='custom-authorizer-st', bootstrapServer='custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093', topicName='my-topic-1709746488-961593547', maxMessages=500, kafkaUsername='kafka-user-write', consumerGroupName='my-consumer-group-1470167597', consumerInstanceId='instance1445783878', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3c7034c0}
2022-04-05 20:42:49 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 500 messages from custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093:my-topic-1709746488-961593547 from pod my-cluster-97cf789b-kafka-clients-5b6fc8b456-th8hx
2022-04-05 20:42:49 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-97cf789b-kafka-clients-5b6fc8b456-th8hx -n custom-authorizer-st -- /opt/kafka/consumer.sh --max-messages 500 --group-id my-consumer-group-1470167597 --group-instance-id instance1445783878 --topic my-topic-1709746488-961593547 --bootstrap-server custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093 USER=kafka_user_write
2022-04-05 20:42:53 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 20:42:53 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 0 messages
2022-04-05 20:42:53 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5272869c, messages=[], arguments=[--max-messages, 500, --group-id, consumer-group-name-1, --group-instance-id, instance2042669885, --topic, my-topic-1709746488-961593547, --bootstrap-server, custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093, USER=kafka_user_read], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-97cf789b-kafka-clients-5b6fc8b456-th8hx', podNamespace='custom-authorizer-st', bootstrapServer='custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093', topicName='my-topic-1709746488-961593547', maxMessages=500, kafkaUsername='kafka-user-read', consumerGroupName='consumer-group-name-1', consumerInstanceId='instance2042669885', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@450c2560}
2022-04-05 20:42:53 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 500 messages from custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093:my-topic-1709746488-961593547 from pod my-cluster-97cf789b-kafka-clients-5b6fc8b456-th8hx
2022-04-05 20:42:53 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-97cf789b-kafka-clients-5b6fc8b456-th8hx -n custom-authorizer-st -- /opt/kafka/consumer.sh --max-messages 500 --group-id consumer-group-name-1 --group-instance-id instance2042669885 --topic my-topic-1709746488-961593547 --bootstrap-server custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093 USER=kafka_user_read
2022-04-05 20:43:00 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 20:43:00 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 500 messages
2022-04-05 20:43:00 [main] [32mINFO [m [CustomAuthorizerST:137] Checking KafkaUser kafka-user-read that is not able to send messages to topic 'my-topic-1709746488-961593547'
2022-04-05 20:43:00 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@86cc7b2, messages=[], arguments=[--max-messages, 500, --topic, my-topic-1709746488-961593547, --bootstrap-server, custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093, USER=kafka_user_read], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-97cf789b-kafka-clients-5b6fc8b456-th8hx', podNamespace='custom-authorizer-st', bootstrapServer='custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093', topicName='my-topic-1709746488-961593547', maxMessages=500, kafkaUsername='kafka-user-read', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6f996e26}
2022-04-05 20:43:00 [main] [32mINFO [m [InternalKafkaClient:124] Producing 500 messages to custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093:my-topic-1709746488-961593547 from pod my-cluster-97cf789b-kafka-clients-5b6fc8b456-th8hx
2022-04-05 20:43:00 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-97cf789b-kafka-clients-5b6fc8b456-th8hx -n custom-authorizer-st -- /opt/kafka/producer.sh --max-messages 500 --topic my-topic-1709746488-961593547 --bootstrap-server custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093 USER=kafka_user_read
2022-04-05 20:43:03 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 20:43:03 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced -1 messages
2022-04-05 20:43:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:43:03 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAclRuleReadAndWrite
2022-04-05 20:43:03 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser kafka-user-read in namespace custom-authorizer-st
2022-04-05 20:43:03 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-97cf789b-kafka-clients in namespace custom-authorizer-st
2022-04-05 20:43:03 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaUser kafka-user-write in namespace custom-authorizer-st
2022-04-05 20:43:03 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1709746488-961593547 in namespace custom-authorizer-st
2022-04-05 20:43:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 20:43:53 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.custom.CustomAuthorizerST.testAclRuleReadAndWrite-FINISHED
2022-04-05 20:43:53 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 20:43:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:43:53 [main] [32mINFO [m [ResourceManager:348] Delete all resources for CustomAuthorizerST
2022-04-05 20:43:53 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka custom-authorizer in namespace custom-authorizer-st
2022-04-05 20:44:03 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 230.345 s - in io.strimzi.systemtest.security.custom.CustomAuthorizerST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.OpaIntegrationST
2022-04-05 20:44:09 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: opa-integration-st
2022-04-05 20:44:09 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: opa-integration-st
2022-04-05 20:44:09 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: opa-integration-st
2022-04-05 20:44:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka opa-cluster in namespace opa-integration-st
2022-04-05 20:44:09 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: opa-cluster will have desired state: Ready
2022-04-05 20:45:29 [main] [32mINFO [m [ResourceManager:444] Kafka: opa-cluster is in desired state: Ready
2022-04-05 20:45:29 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 20:45:29 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.OpaIntegrationST.testOpaAuthorizationSuperUser-STARTED
2022-04-05 20:45:29 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 20:45:29 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-353224059-867586337 in namespace opa-integration-st
2022-04-05 20:45:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-353224059-867586337 will have desired state: Ready
2022-04-05 20:45:31 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-353224059-867586337 is in desired state: Ready
2022-04-05 20:45:31 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser arnost in namespace opa-integration-st
2022-04-05 20:45:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: arnost will have desired state: Ready
2022-04-05 20:45:32 [main] [32mINFO [m [ResourceManager:444] KafkaUser: arnost is in desired state: Ready
2022-04-05 20:45:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-181ec886-kafka-clients in namespace opa-integration-st
2022-04-05 20:45:32 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-181ec886-kafka-clients will be ready
2022-04-05 20:45:34 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-181ec886-kafka-clients is ready
2022-04-05 20:45:34 [main] [32mINFO [m [OpaIntegrationST:120] Checking KafkaUser good-user that is able to send and receive messages to/from topic 'my-topic-353224059-867586337'
2022-04-05 20:45:34 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@70cb39e7, messages=[], arguments=[--max-messages, 100, --topic, my-topic-353224059-867586337, --bootstrap-server, opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093, USER=arnost], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-181ec886-kafka-clients-7dfc6d5898-6bb4g', podNamespace='opa-integration-st', bootstrapServer='opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093', topicName='my-topic-353224059-867586337', maxMessages=100, kafkaUsername='arnost', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@709f99e2}
2022-04-05 20:45:34 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093:my-topic-353224059-867586337 from pod my-cluster-181ec886-kafka-clients-7dfc6d5898-6bb4g
2022-04-05 20:45:34 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-181ec886-kafka-clients-7dfc6d5898-6bb4g -n opa-integration-st -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-353224059-867586337 --bootstrap-server opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093 USER=arnost
2022-04-05 20:45:37 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 20:45:37 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 20:45:37 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@347e3681, messages=[], arguments=[--max-messages, 100, --group-id, consumer-group-name-2, --group-instance-id, instance650159771, --topic, my-topic-353224059-867586337, --bootstrap-server, opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093, USER=arnost], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-181ec886-kafka-clients-7dfc6d5898-6bb4g', podNamespace='opa-integration-st', bootstrapServer='opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093', topicName='my-topic-353224059-867586337', maxMessages=100, kafkaUsername='arnost', consumerGroupName='consumer-group-name-2', consumerInstanceId='instance650159771', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3822e8ee}
2022-04-05 20:45:37 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093:my-topic-353224059-867586337 from pod my-cluster-181ec886-kafka-clients-7dfc6d5898-6bb4g
2022-04-05 20:45:37 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-181ec886-kafka-clients-7dfc6d5898-6bb4g -n opa-integration-st -- /opt/kafka/consumer.sh --max-messages 100 --group-id consumer-group-name-2 --group-instance-id instance650159771 --topic my-topic-353224059-867586337 --bootstrap-server opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093 USER=arnost
2022-04-05 20:45:44 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 20:45:44 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 20:45:44 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:45:44 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testOpaAuthorizationSuperUser
2022-04-05 20:45:44 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser arnost in namespace opa-integration-st
2022-04-05 20:45:44 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-181ec886-kafka-clients in namespace opa-integration-st
2022-04-05 20:45:44 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-353224059-867586337 in namespace opa-integration-st
2022-04-05 20:46:24 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 20:46:24 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.OpaIntegrationST.testOpaAuthorizationSuperUser-FINISHED
2022-04-05 20:46:24 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 20:46:24 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 20:46:24 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.OpaIntegrationST.testOpaAuthorization-STARTED
2022-04-05 20:46:24 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 20:46:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser good-user in namespace opa-integration-st
2022-04-05 20:46:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: good-user will have desired state: Ready
2022-04-05 20:46:25 [main] [32mINFO [m [ResourceManager:444] KafkaUser: good-user is in desired state: Ready
2022-04-05 20:46:25 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser bad-user in namespace opa-integration-st
2022-04-05 20:46:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: bad-user will have desired state: Ready
2022-04-05 20:46:26 [main] [32mINFO [m [ResourceManager:444] KafkaUser: bad-user is in desired state: Ready
2022-04-05 20:46:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-856d38b4-kafka-clients in namespace opa-integration-st
2022-04-05 20:46:26 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-856d38b4-kafka-clients will be ready
2022-04-05 20:46:28 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-856d38b4-kafka-clients is ready
2022-04-05 20:46:28 [main] [32mINFO [m [OpaIntegrationST:72] Checking KafkaUser good-user that is able to send and receive messages to/from topic 'my-topic-100509629-1217768545'
2022-04-05 20:46:28 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@71f72c2c, messages=[], arguments=[--max-messages, 100, --topic, my-topic-100509629-1217768545, --bootstrap-server, opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093, USER=good_user], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-856d38b4-kafka-clients-8d49d5644-bfn9c', podNamespace='opa-integration-st', bootstrapServer='opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093', topicName='my-topic-100509629-1217768545', maxMessages=100, kafkaUsername='good-user', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4c45a48d}
2022-04-05 20:46:28 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093:my-topic-100509629-1217768545 from pod my-cluster-856d38b4-kafka-clients-8d49d5644-bfn9c
2022-04-05 20:46:28 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-856d38b4-kafka-clients-8d49d5644-bfn9c -n opa-integration-st -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-100509629-1217768545 --bootstrap-server opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093 USER=good_user
2022-04-05 20:46:33 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 20:46:33 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 20:46:33 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@318ed53a, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1769783148, --group-instance-id, instance1965500823, --topic, my-topic-100509629-1217768545, --bootstrap-server, opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093, USER=good_user], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-856d38b4-kafka-clients-8d49d5644-bfn9c', podNamespace='opa-integration-st', bootstrapServer='opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093', topicName='my-topic-100509629-1217768545', maxMessages=100, kafkaUsername='good-user', consumerGroupName='my-consumer-group-1769783148', consumerInstanceId='instance1965500823', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@769d6c3e}
2022-04-05 20:46:33 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093:my-topic-100509629-1217768545 from pod my-cluster-856d38b4-kafka-clients-8d49d5644-bfn9c
2022-04-05 20:46:33 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-856d38b4-kafka-clients-8d49d5644-bfn9c -n opa-integration-st -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1769783148 --group-instance-id instance1965500823 --topic my-topic-100509629-1217768545 --bootstrap-server opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093 USER=good_user
2022-04-05 20:46:40 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 20:46:40 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 20:46:40 [main] [32mINFO [m [OpaIntegrationST:89] Checking KafkaUser bad-user that is not able to send or receive messages to/from topic 'my-topic-100509629-1217768545'
2022-04-05 20:46:40 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@18d0be2b, messages=[], arguments=[--max-messages, 100, --topic, my-topic-100509629-1217768545, --bootstrap-server, opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093, USER=bad_user], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-856d38b4-kafka-clients-8d49d5644-bfn9c', podNamespace='opa-integration-st', bootstrapServer='opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093', topicName='my-topic-100509629-1217768545', maxMessages=100, kafkaUsername='bad-user', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@500e6e4a}
2022-04-05 20:46:40 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093:my-topic-100509629-1217768545 from pod my-cluster-856d38b4-kafka-clients-8d49d5644-bfn9c
2022-04-05 20:46:40 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-856d38b4-kafka-clients-8d49d5644-bfn9c -n opa-integration-st -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-100509629-1217768545 --bootstrap-server opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093 USER=bad_user
2022-04-05 20:46:43 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 20:46:43 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced -1 messages
2022-04-05 20:46:43 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4251ef1a, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1769783148, --group-instance-id, instance1512421450, --topic, my-topic-100509629-1217768545, --bootstrap-server, opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093, USER=bad_user], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-856d38b4-kafka-clients-8d49d5644-bfn9c', podNamespace='opa-integration-st', bootstrapServer='opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093', topicName='my-topic-100509629-1217768545', maxMessages=100, kafkaUsername='bad-user', consumerGroupName='my-consumer-group-1769783148', consumerInstanceId='instance1512421450', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5b1dd93}
2022-04-05 20:46:43 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093:my-topic-100509629-1217768545 from pod my-cluster-856d38b4-kafka-clients-8d49d5644-bfn9c
2022-04-05 20:46:43 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-856d38b4-kafka-clients-8d49d5644-bfn9c -n opa-integration-st -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1769783148 --group-instance-id instance1512421450 --topic my-topic-100509629-1217768545 --bootstrap-server opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093 USER=bad_user
2022-04-05 20:47:10 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 20:47:10 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 0 messages
2022-04-05 20:47:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:47:10 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testOpaAuthorization
2022-04-05 20:47:10 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser bad-user in namespace opa-integration-st
2022-04-05 20:47:10 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-856d38b4-kafka-clients in namespace opa-integration-st
2022-04-05 20:47:10 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser good-user in namespace opa-integration-st
2022-04-05 20:47:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 20:47:50 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.OpaIntegrationST.testOpaAuthorization-FINISHED
2022-04-05 20:47:50 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 20:47:50 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:47:50 [main] [32mINFO [m [ResourceManager:348] Delete all resources for OpaIntegrationST
2022-04-05 20:47:50 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka opa-cluster in namespace opa-integration-st
2022-04-05 20:48:00 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 274.531 s - in io.strimzi.systemtest.security.OpaIntegrationST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.SecurityST
2022-04-05 20:48:43 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: security-st
2022-04-05 20:48:44 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: security-st
2022-04-05 20:48:44 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: security-st
2022-04-05 20:48:44 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 20:48:44 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoRenewCaCertsTriggerByExpiredCertificate-STARTED
2022-04-05 20:48:44 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 20:48:44 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-56 for test case:testAutoRenewCaCertsTriggerByExpiredCertificate
2022-04-05 20:48:44 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-56
2022-04-05 20:48:44 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-56
2022-04-05 20:48:44 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-56
2022-04-05 20:48:44 [main] [32mINFO [m [SecretUtils:70] Creating secret my-cluster-f5b75302-cluster-ca-cert
2022-04-05 20:48:44 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-05 20:48:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-f5b75302 in namespace namespace-56
2022-04-05 20:48:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-56
2022-04-05 20:48:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f5b75302 will have desired state: Ready
2022-04-05 20:51:53 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f5b75302 is in desired state: Ready
2022-04-05 20:51:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-40821509-563089101 in namespace namespace-56
2022-04-05 20:51:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-56
2022-04-05 20:51:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-40821509-563089101 will have desired state: Ready
2022-04-05 20:51:54 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-40821509-563089101 is in desired state: Ready
2022-04-05 20:51:54 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-426413315-1494843305 in namespace namespace-56
2022-04-05 20:51:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-56
2022-04-05 20:51:54 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-426413315-1494843305 will have desired state: Ready
2022-04-05 20:51:55 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-426413315-1494843305 is in desired state: Ready
2022-04-05 20:51:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-f5b75302-kafka-clients in namespace namespace-56
2022-04-05 20:51:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-56
2022-04-05 20:51:55 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f5b75302-kafka-clients will be ready
2022-04-05 20:51:57 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f5b75302-kafka-clients is ready
2022-04-05 20:51:57 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 20:51:57 [main] [32mINFO [m [SecurityST:660] Checking produced and consumed messages to pod:my-cluster-f5b75302-kafka-clients-69b76fcd47-c95ks
2022-04-05 20:51:57 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1cfc802c, messages=[], arguments=[--max-messages, 100, --topic, my-topic-426413315-1494843305, --bootstrap-server, my-cluster-f5b75302-kafka-bootstrap.namespace-56.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-f5b75302-kafka-clients-69b76fcd47-c95ks', podNamespace='namespace-56', bootstrapServer='my-cluster-f5b75302-kafka-bootstrap.namespace-56.svc:9092', topicName='my-topic-426413315-1494843305', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@466380d4}
2022-04-05 20:51:57 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-f5b75302-kafka-bootstrap.namespace-56.svc:9092:my-topic-426413315-1494843305 from pod my-cluster-f5b75302-kafka-clients-69b76fcd47-c95ks
2022-04-05 20:51:57 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f5b75302-kafka-clients-69b76fcd47-c95ks -n namespace-56 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-426413315-1494843305 --bootstrap-server my-cluster-f5b75302-kafka-bootstrap.namespace-56.svc:9092
2022-04-05 20:52:00 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 20:52:00 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 20:52:00 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@38c39ed3, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1859134116, --group-instance-id, instance1684808963, --topic, my-topic-426413315-1494843305, --bootstrap-server, my-cluster-f5b75302-kafka-bootstrap.namespace-56.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-f5b75302-kafka-clients-69b76fcd47-c95ks', podNamespace='namespace-56', bootstrapServer='my-cluster-f5b75302-kafka-bootstrap.namespace-56.svc:9092', topicName='my-topic-426413315-1494843305', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1859134116', consumerInstanceId='instance1684808963', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@62fcc778}
2022-04-05 20:52:00 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-f5b75302-kafka-bootstrap.namespace-56.svc:9092#my-topic-426413315-1494843305 from pod my-cluster-f5b75302-kafka-clients-69b76fcd47-c95ks
2022-04-05 20:52:00 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f5b75302-kafka-clients-69b76fcd47-c95ks -n namespace-56 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1859134116 --group-instance-id instance1684808963 --topic my-topic-426413315-1494843305 --bootstrap-server my-cluster-f5b75302-kafka-bootstrap.namespace-56.svc:9092
2022-04-05 20:52:06 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 20:52:06 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 20:52:06 [main] [32mINFO [m [SecretUtils:131] Waiting for Secret my-cluster-f5b75302-cluster-ca-cert certificate change
2022-04-05 20:52:06 [main] [32mINFO [m [SecretUtils:138] Certificate in Secret my-cluster-f5b75302-cluster-ca-cert has changed, was -----BEGIN CERTIFICATE-----
MIIDKjCCAhKgAwIBAgIJAJBt0u1FFTG+MA0GCSqGSIb3DQEBCwUAMCoxEzARBgNV
BAoMCnN0cmltemkuaW8xEzARBgNVBAMMCmNsdXN0ZXItY2EwHhcNMTgxMDIzMTAw
MTExWhcNMTgxMDI0MTAwMTExWjAqMRMwEQYDVQQKDApzdHJpbXppLmlvMRMwEQYD
VQQDDApjbHVzdGVyLWNhMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA
xpuYrNXYHqw3ajwd12aAeuTlAX4rVwVdPuIex6A4NL8J3d2DV+ngXgNTH//RhiF5
If5KRWSsLei5BUIrwuQutOUNCQwyACmri9+yrx6+tevligiokAUwhHxcDHZpwC3T
+2dzk/BkI++vbSuvjFmBKGQi9gfyoTnStTEQ85KVJUS170hzwDjzaEiJsKpOPx/G
+KTdkAopLucoxr4sxhYeO4mQ2PkT0QL+R8Ohs6LD6v/bqalFP+rS8vibolfxjMNm
lXQCOd8UfXy8OEOaNoNCvhnn/cT/hbEG/ARbV3hHmUh9COV+TSV5dhsbmS5h4MKw
LzP449nGQBmLSkZMu984DQIDAQABo1MwUTAdBgNVHQ4EFgQUOXubcHBZJ7vSzjpi
pfXdFSP3dsEwHwYDVR0jBBgwFoAUOXubcHBZJ7vSzjpipfXdFSP3dsEwDwYDVR0T
AQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAQEAFFPGykbzUREDMzh+33i3a8TF
UTQnPMN/SuVbpLfQdpkpLO+aVWjVvJP6qMrI7jRO5zhj4MecAf7YKpe+dyRTTz9B
Dy9BZcujHYjCKdcKBnBFQ7B1xQm9tL1bw+a3ABzSTlhLiBcCxhJEawlWy1Gh18ab
3x/Kqnz0mk/jt5+n9HwlKHuBQVIxRCsfHWwq+WvIfoxM+N//akV8/29hLUf5TlYH
F5CX4G2pA5sSdaDHQ4ekQWuqM6tfvsGLl2KOmEFEgVR4GfaWI4BsUCzlpBNcCGWv
V7klZvBxQPG7MVy0cB8yzTDtUpR0jUFUkZOSp5Pr3yWcwPWEgWkaXYfO+FWETA==
-----END CERTIFICATE-----
, is now -----BEGIN CERTIFICATE-----
MIIFLTCCAxWgAwIBAgIUSogyUaQi94LFyxxQ5D2QQ3i+pRcwDQYJKoZIhvcNAQEN
BQAwLTETMBEGA1UECgwKaW8uc3RyaW16aTEWMBQGA1UEAwwNY2x1c3Rlci1jYSB2
MDAeFw0yMjA0MDUyMDQ4NDRaFw0yMzA0MDUyMDQ4NDRaMC0xEzARBgNVBAoMCmlv
LnN0cmltemkxFjAUBgNVBAMMDWNsdXN0ZXItY2EgdjAwggIiMA0GCSqGSIb3DQEB
AQUAA4ICDwAwggIKAoICAQDEE8Af1r4FqMs4+P4HmX9lPwHSXIxuIzGgRG3+m6W+
4f5914msb0wyRFvkIc4es3SQwvQXBcDM/PCnLKFCWD3QWw+rjLd6kGESUen3Gd/i
yDjwrfvQb1bV1AY4FRrMLOUahsElzO29hrhKP7O/ZqthEMhgMSytV/rbDIMDwX7X
C2VPoluzkitrpDb+WVoMxmE5jWFNcLiosSts5rld/68v2+vVggeCCEam/KQLRAVW
zPn6c5i0ta69BHiK0rweQrC/LF/THH6ZN2vCnr0D38O1xyjbS8juZl04VeGlVkX6
zBYIN8iFvigHZyfjf38WqqPWzT+dPvOsHbkSUKpphbcWKnthc2Mb4DzRNXbK5KyF
kfyTrHB8U4Q31JztmcAF1zch2EmuQBcCxeal3cTGCaCmNn70qVCsxPnpfDBntpwN
21fyclMn+ZWOUY2I/2tYIfHk3GtSWW71JXmQKiu51ToPHzwBMIBlVg4wFCvVaE5S
ViZgTp6BEkWs6nQxHCGE5OvCAn4rRHzxipI2vSnDKSqpwR7d5EFz6oIprXCUIwWn
eXlhtwBFyDv2yF3laooQrPT4fyaBKnbpJ9uWqBfqnNXTvl9aj43mWxB0YdN9peO8
UeACJGIwnSMMzg6dOVs00ajpJzpEbo1yqSjw9mr3IR9vSdxmSbX5LjZ66cMUIXsd
/QIDAQABo0UwQzAdBgNVHQ4EFgQUBzutBdNBl0dkv9XF8Y9AHvCP1wUwEgYDVR0T
AQH/BAgwBgEB/wIBADAOBgNVHQ8BAf8EBAMCAQYwDQYJKoZIhvcNAQENBQADggIB
AL2HYAiYZDj8hZNpMO5uj+/KBo+ZtCCxjpj+VVgpxV7oWA1i0dhO4fZsPlOWptGA
Idf42BaCSWD4eWOKh/IWKBbB4r0q230dgWNKdZKhwc+buvqYDlLQb/dBUWwT9qjC
m34ngUKXVz29QZSod1mJiv9A5KufaPS48X1Gw/ZT7BIdJNvTG2zmv4GLyJr8oqML
FexyC+PjF05Nrn5BSlKq8X5tEvzKL7U8TyHOZy6habXPmpu0W2ajSNwYPFTD/Qey
7eWCB1hI3oo+N0b9+rY6BNWykr4FD0pAY0qN10x69GIccRBFLeba1d8lrNhK77xU
eXyev5X1t/eUXZvPOtJQ/VC8BT1gzEn3HPTfCREen5MTFMSoNCh83ewqFuZ5gk47
fOcJKLN+frJXAnUmFNTcpWa1pXmhRGLxKwaQF+ssGiZXuDydFnPZVcg0fhiPWxPo
AOb3KeouH8QqID3jQn4AQK8UkyMzjqqJvBLCdaNaPNzpSXzjoee9upbkZKF5iOJU
Y0Cyj3gz0DUdK0cwCXjXtNOSFGXEERHdst6aq2+F5IHJF51mGjsQOtckSR4Gg4oX
3y9iOFBi0iibS+1MOMcjo3/OUpTx7uNOkGD/RPLNxbPl0OPqbyjo2Mys4/rJkwxH
ukyDQ++v3yFbzsxjq9bQVpmKWbYxQZpXb+RWxnkpU1WK
-----END CERTIFICATE-----

2022-04-05 20:52:06 [main] [32mINFO [m [KafkaUtils:180] Waiting for cluster stability
2022-04-05 20:53:08 [main] [32mINFO [m [KafkaUtils:208] Kafka cluster is stable after 61 polls.
2022-04-05 20:53:08 [main] [32mINFO [m [SecurityST:672] Checking produced and consumed messages to pod:my-cluster-f5b75302-kafka-clients-69b76fcd47-c95ks
2022-04-05 20:53:08 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@2a07a0cc, messages=[], arguments=[--max-messages, 100, --topic, my-topic-426413315-1494843305, --bootstrap-server, my-cluster-f5b75302-kafka-bootstrap.namespace-56.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-f5b75302-kafka-clients-69b76fcd47-c95ks', podNamespace='namespace-56', bootstrapServer='my-cluster-f5b75302-kafka-bootstrap.namespace-56.svc:9092', topicName='my-topic-426413315-1494843305', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2ec4756b}
2022-04-05 20:53:08 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-f5b75302-kafka-bootstrap.namespace-56.svc:9092:my-topic-426413315-1494843305 from pod my-cluster-f5b75302-kafka-clients-69b76fcd47-c95ks
2022-04-05 20:53:08 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f5b75302-kafka-clients-69b76fcd47-c95ks -n namespace-56 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-426413315-1494843305 --bootstrap-server my-cluster-f5b75302-kafka-bootstrap.namespace-56.svc:9092
2022-04-05 20:53:10 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 20:53:10 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 20:53:10 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@77669036, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1859134116, --group-instance-id, instance2139590796, --topic, my-topic-426413315-1494843305, --bootstrap-server, my-cluster-f5b75302-kafka-bootstrap.namespace-56.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-f5b75302-kafka-clients-69b76fcd47-c95ks', podNamespace='namespace-56', bootstrapServer='my-cluster-f5b75302-kafka-bootstrap.namespace-56.svc:9092', topicName='my-topic-426413315-1494843305', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1859134116', consumerInstanceId='instance2139590796', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7a84cd20}
2022-04-05 20:53:10 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-f5b75302-kafka-bootstrap.namespace-56.svc:9092#my-topic-426413315-1494843305 from pod my-cluster-f5b75302-kafka-clients-69b76fcd47-c95ks
2022-04-05 20:53:10 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f5b75302-kafka-clients-69b76fcd47-c95ks -n namespace-56 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1859134116 --group-instance-id instance2139590796 --topic my-topic-426413315-1494843305 --bootstrap-server my-cluster-f5b75302-kafka-bootstrap.namespace-56.svc:9092
2022-04-05 20:53:16 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 20:53:16 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 20:53:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:53:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoRenewCaCertsTriggerByExpiredCertificate
2022-04-05 20:53:16 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-426413315-1494843305 in namespace namespace-56
2022-04-05 20:53:16 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-f5b75302-kafka-clients in namespace namespace-56
2022-04-05 20:53:16 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-f5b75302 in namespace namespace-56
2022-04-05 20:53:16 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-40821509-563089101 in namespace namespace-56
2022-04-05 20:53:16 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-56, for cruise control Kafka cluster my-cluster-f5b75302
2022-04-05 20:54:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 20:54:06 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-56 for test case:testAutoRenewCaCertsTriggerByExpiredCertificate
2022-04-05 20:54:11 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoRenewCaCertsTriggerByExpiredCertificate-FINISHED
2022-04-05 20:54:11 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 20:54:11 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 20:54:11 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClientsCaKeysTriggeredByAnno-STARTED
2022-04-05 20:54:11 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 20:54:11 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-57 for test case:testAutoReplaceClientsCaKeysTriggeredByAnno
2022-04-05 20:54:11 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-57
2022-04-05 20:54:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-57
2022-04-05 20:54:11 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-57
2022-04-05 20:54:11 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-05 20:54:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c839c873 in namespace namespace-57
2022-04-05 20:54:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-57
2022-04-05 20:54:11 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c839c873 will have desired state: Ready
2022-04-05 20:56:32 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c839c873 is in desired state: Ready
2022-04-05 20:56:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-230851807-777259199 in namespace namespace-57
2022-04-05 20:56:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-57
2022-04-05 20:56:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-230851807-777259199 will have desired state: Ready
2022-04-05 20:56:33 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-230851807-777259199 is in desired state: Ready
2022-04-05 20:56:33 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1166869859-989881914 in namespace namespace-57
2022-04-05 20:56:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-57
2022-04-05 20:56:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1166869859-989881914 will have desired state: Ready
2022-04-05 20:56:34 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1166869859-989881914 is in desired state: Ready
2022-04-05 20:56:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-c839c873-kafka-clients in namespace namespace-57
2022-04-05 20:56:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-57
2022-04-05 20:56:34 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c839c873-kafka-clients will be ready
2022-04-05 20:56:36 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c839c873-kafka-clients is ready
2022-04-05 20:56:36 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 20:56:36 [main] [32mINFO [m [SecurityST:453] Checking produced and consumed messages to pod:my-cluster-c839c873-kafka-clients-7bb6cb4797-dkdbg
2022-04-05 20:56:36 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@afa8ef8, messages=[], arguments=[--max-messages, 100, --topic, my-topic-1166869859-989881914, --bootstrap-server, my-cluster-c839c873-kafka-bootstrap.namespace-57.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-c839c873-kafka-clients-7bb6cb4797-dkdbg', podNamespace='namespace-57', bootstrapServer='my-cluster-c839c873-kafka-bootstrap.namespace-57.svc:9092', topicName='my-topic-1166869859-989881914', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@66dd09d9}
2022-04-05 20:56:36 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-c839c873-kafka-bootstrap.namespace-57.svc:9092:my-topic-1166869859-989881914 from pod my-cluster-c839c873-kafka-clients-7bb6cb4797-dkdbg
2022-04-05 20:56:36 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c839c873-kafka-clients-7bb6cb4797-dkdbg -n namespace-57 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-1166869859-989881914 --bootstrap-server my-cluster-c839c873-kafka-bootstrap.namespace-57.svc:9092
2022-04-05 20:56:38 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 20:56:38 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 20:56:38 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@10df8f80, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-954288272, --group-instance-id, instance1507275874, --topic, my-topic-1166869859-989881914, --bootstrap-server, my-cluster-c839c873-kafka-bootstrap.namespace-57.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-c839c873-kafka-clients-7bb6cb4797-dkdbg', podNamespace='namespace-57', bootstrapServer='my-cluster-c839c873-kafka-bootstrap.namespace-57.svc:9092', topicName='my-topic-1166869859-989881914', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-954288272', consumerInstanceId='instance1507275874', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1ec2ce40}
2022-04-05 20:56:38 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-c839c873-kafka-bootstrap.namespace-57.svc:9092#my-topic-1166869859-989881914 from pod my-cluster-c839c873-kafka-clients-7bb6cb4797-dkdbg
2022-04-05 20:56:38 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c839c873-kafka-clients-7bb6cb4797-dkdbg -n namespace-57 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-954288272 --group-instance-id instance1507275874 --topic my-topic-1166869859-989881914 --bootstrap-server my-cluster-c839c873-kafka-bootstrap.namespace-57.svc:9092
2022-04-05 20:56:44 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 20:56:44 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 20:56:44 [main] [32mINFO [m [SecurityST:467] Triggering CA cert renewal by adding the annotation
2022-04-05 20:56:44 [main] [32mINFO [m [SecurityST:479] Patching secret my-cluster-c839c873-clients-ca with strimzi.io/force-replace
2022-04-05 20:56:44 [main] [32mINFO [m [SecurityST:489] Wait for kafka to rolling restart (1)...
2022-04-05 20:56:44 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-c839c873-kafka rolling update
2022-04-05 20:58:04 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-c839c873-kafka has been successfully rolled
2022-04-05 20:58:04 [main] [32mINFO [m [SecurityST:510] Wait for kafka to rolling restart (2)...
2022-04-05 20:58:04 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-c839c873-kafka rolling update
2022-04-05 20:59:44 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-c839c873-kafka has been successfully rolled
2022-04-05 20:59:44 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-c839c873-kafka to be ready
2022-04-05 21:00:20 [main] [32mINFO [m [SecurityST:525] Checking the certificates have been replaced
2022-04-05 21:00:20 [main] [32mINFO [m [SecurityST:536] Checking consumed messages to pod:my-cluster-c839c873-kafka-clients-7bb6cb4797-dkdbg
2022-04-05 21:00:20 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3fe11bea, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-804512814, --group-instance-id, instance830478066, --topic, my-topic-1166869859-989881914, --bootstrap-server, my-cluster-c839c873-kafka-bootstrap.namespace-57.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-c839c873-kafka-clients-7bb6cb4797-dkdbg', podNamespace='namespace-57', bootstrapServer='my-cluster-c839c873-kafka-bootstrap.namespace-57.svc:9092', topicName='my-topic-1166869859-989881914', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-804512814', consumerInstanceId='instance830478066', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@62c04a59}
2022-04-05 21:00:20 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-c839c873-kafka-bootstrap.namespace-57.svc:9092#my-topic-1166869859-989881914 from pod my-cluster-c839c873-kafka-clients-7bb6cb4797-dkdbg
2022-04-05 21:00:20 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c839c873-kafka-clients-7bb6cb4797-dkdbg -n namespace-57 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-804512814 --group-instance-id instance830478066 --topic my-topic-1166869859-989881914 --bootstrap-server my-cluster-c839c873-kafka-bootstrap.namespace-57.svc:9092
2022-04-05 21:00:25 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 21:00:25 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 21:00:25 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-119437170-1953235594 in namespace namespace-57
2022-04-05 21:00:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-57
2022-04-05 21:00:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-119437170-1953235594 will have desired state: Ready
2022-04-05 21:00:26 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-119437170-1953235594 is in desired state: Ready
2022-04-05 21:00:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-c839c873-kafka-clients-tls in namespace namespace-57
2022-04-05 21:00:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-57
2022-04-05 21:00:26 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c839c873-kafka-clients-tls will be ready
2022-04-05 21:00:28 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c839c873-kafka-clients-tls is ready
2022-04-05 21:00:28 [main] [32mINFO [m [SecurityST:561] Checking consumed messages to pod:my-cluster-c839c873-kafka-clients-tls-6d4fd6bc99-bq4q2
2022-04-05 21:00:28 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@13d1bdf6, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1384810911, --group-instance-id, instance1855130746, --topic, my-topic-1166869859-989881914, --bootstrap-server, my-cluster-c839c873-kafka-bootstrap.namespace-57.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-c839c873-kafka-clients-tls-6d4fd6bc99-bq4q2', podNamespace='namespace-57', bootstrapServer='my-cluster-c839c873-kafka-bootstrap.namespace-57.svc:9092', topicName='my-topic-1166869859-989881914', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1384810911', consumerInstanceId='instance1855130746', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7323a349}
2022-04-05 21:00:28 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-c839c873-kafka-bootstrap.namespace-57.svc:9092#my-topic-1166869859-989881914 from pod my-cluster-c839c873-kafka-clients-tls-6d4fd6bc99-bq4q2
2022-04-05 21:00:28 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c839c873-kafka-clients-tls-6d4fd6bc99-bq4q2 -n namespace-57 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1384810911 --group-instance-id instance1855130746 --topic my-topic-1166869859-989881914 --bootstrap-server my-cluster-c839c873-kafka-bootstrap.namespace-57.svc:9092
2022-04-05 21:00:34 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 21:00:34 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 21:00:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 21:00:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoReplaceClientsCaKeysTriggeredByAnno
2022-04-05 21:00:34 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-c839c873-kafka-clients in namespace namespace-57
2022-04-05 21:00:34 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-c839c873-kafka-clients-tls in namespace namespace-57
2022-04-05 21:00:34 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c839c873 in namespace namespace-57
2022-04-05 21:00:34 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-119437170-1953235594 in namespace namespace-57
2022-04-05 21:00:34 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-57, for cruise control Kafka cluster my-cluster-c839c873
2022-04-05 21:00:34 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-230851807-777259199 in namespace namespace-57
2022-04-05 21:00:34 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1166869859-989881914 in namespace namespace-57
2022-04-05 21:01:24 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 21:01:24 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-57 for test case:testAutoReplaceClientsCaKeysTriggeredByAnno
2022-04-05 21:01:31 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClientsCaKeysTriggeredByAnno-FINISHED
2022-04-05 21:01:31 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 21:01:31 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 21:01:31 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testTlsHostnameVerificationWithMirrorMaker-STARTED
2022-04-05 21:01:31 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 21:01:31 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-58 for test case:testTlsHostnameVerificationWithMirrorMaker
2022-04-05 21:01:31 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-58
2022-04-05 21:01:31 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-58
2022-04-05 21:01:31 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-58
2022-04-05 21:01:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-438797a2-source in namespace namespace-58
2022-04-05 21:01:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-58
2022-04-05 21:01:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-438797a2-source will have desired state: Ready
2022-04-05 21:02:47 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-438797a2-source is in desired state: Ready
2022-04-05 21:02:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-438797a2-target in namespace namespace-58
2022-04-05 21:02:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-58
2022-04-05 21:02:47 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-438797a2-target will have desired state: Ready
2022-04-05 21:03:53 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-438797a2-target is in desired state: Ready
2022-04-05 21:03:53 [main] [32mINFO [m [SecurityST:888] Getting IP of the source bootstrap service for consumer
2022-04-05 21:03:53 [main] [32mINFO [m [SecurityST:891] Getting IP of the target bootstrap service for producer
2022-04-05 21:03:53 [main] [32mINFO [m [SecurityST:894] KafkaMirrorMaker without config ssl.endpoint.identification.algorithm will not connect to consumer with address 10.97.24.81:9093
2022-04-05 21:03:53 [main] [32mINFO [m [SecurityST:895] KafkaMirrorMaker without config ssl.endpoint.identification.algorithm will not connect to producer with address 10.103.251.231:9093
2022-04-05 21:03:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-438797a2 in namespace namespace-58
2022-04-05 21:03:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-58
2022-04-05 21:03:53 [main] [32mINFO [m [PodUtils:245] Wait until Pod my-cluster-438797a2-mirror-maker is present
2022-04-05 21:03:54 [main] [32mINFO [m [PodUtils:249] Pod my-cluster-438797a2-mirror-maker is present
2022-04-05 21:03:54 [main] [32mINFO [m [PodUtils:236] Wait until Pod my-cluster-438797a2-mirror-maker-79b4665b9d-jw8kd is in CrashLoopBackOff state
2022-04-05 21:04:08 [main] [32mINFO [m [PodUtils:241] Pod my-cluster-438797a2-mirror-maker-79b4665b9d-jw8kd is in CrashLoopBackOff state
2022-04-05 21:04:08 [main] [32mINFO [m [SecurityST:930] KafkaMirrorMaker with config ssl.endpoint.identification.algorithm will connect to consumer with address 10.97.24.81:9093
2022-04-05 21:04:08 [main] [32mINFO [m [SecurityST:931] KafkaMirrorMaker with config ssl.endpoint.identification.algorithm will connect to producer with address 10.103.251.231:9093
2022-04-05 21:04:08 [main] [32mINFO [m [SecurityST:933] Adding configuration ssl.endpoint.identification.algorithm to the mirror maker...
2022-04-05 21:04:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-438797a2 will have desired state: Ready
2022-04-05 21:10:03 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-438797a2 is in desired state: Ready
2022-04-05 21:10:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 21:10:03 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTlsHostnameVerificationWithMirrorMaker
2022-04-05 21:10:03 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-438797a2-target in namespace namespace-58
2022-04-05 21:10:03 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-438797a2 in namespace namespace-58
2022-04-05 21:10:03 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-438797a2-source in namespace namespace-58
2022-04-05 21:10:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 21:10:23 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-58 for test case:testTlsHostnameVerificationWithMirrorMaker
2022-04-05 21:10:50 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testTlsHostnameVerificationWithMirrorMaker-FINISHED
2022-04-05 21:10:50 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 21:10:50 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 21:10:50 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoRenewClusterCaCertsTriggeredByAnno-STARTED
2022-04-05 21:10:50 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 21:10:50 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-59 for test case:testAutoRenewClusterCaCertsTriggeredByAnno
2022-04-05 21:10:50 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-59
2022-04-05 21:10:50 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-59
2022-04-05 21:10:50 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-59
2022-04-05 21:10:50 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-05 21:10:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-63c3c553 in namespace namespace-59
2022-04-05 21:10:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-59
2022-04-05 21:10:50 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-63c3c553 will have desired state: Ready
2022-04-05 21:13:00 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-63c3c553 is in desired state: Ready
2022-04-05 21:13:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1305656753-1466407405 in namespace namespace-59
2022-04-05 21:13:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-59
2022-04-05 21:13:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1305656753-1466407405 will have desired state: Ready
2022-04-05 21:13:01 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1305656753-1466407405 is in desired state: Ready
2022-04-05 21:13:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-670612877-224958575 in namespace namespace-59
2022-04-05 21:13:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-59
2022-04-05 21:13:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-670612877-224958575 will have desired state: Ready
2022-04-05 21:13:02 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-670612877-224958575 is in desired state: Ready
2022-04-05 21:13:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-63c3c553-kafka-clients in namespace namespace-59
2022-04-05 21:13:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-59
2022-04-05 21:13:02 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-63c3c553-kafka-clients will be ready
2022-04-05 21:13:04 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-63c3c553-kafka-clients is ready
2022-04-05 21:13:04 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 21:13:04 [main] [32mINFO [m [SecurityST:260] Checking produced and consumed messages to pod:my-cluster-63c3c553-kafka-clients-7758c98c85-r6n7k
2022-04-05 21:13:04 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@6c02b11e, messages=[], arguments=[--max-messages, 100, --topic, my-topic-670612877-224958575, --bootstrap-server, my-cluster-63c3c553-kafka-bootstrap.namespace-59.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-63c3c553-kafka-clients-7758c98c85-r6n7k', podNamespace='namespace-59', bootstrapServer='my-cluster-63c3c553-kafka-bootstrap.namespace-59.svc:9092', topicName='my-topic-670612877-224958575', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6c5eaa0a}
2022-04-05 21:13:04 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-63c3c553-kafka-bootstrap.namespace-59.svc:9092:my-topic-670612877-224958575 from pod my-cluster-63c3c553-kafka-clients-7758c98c85-r6n7k
2022-04-05 21:13:04 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-63c3c553-kafka-clients-7758c98c85-r6n7k -n namespace-59 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-670612877-224958575 --bootstrap-server my-cluster-63c3c553-kafka-bootstrap.namespace-59.svc:9092
2022-04-05 21:13:07 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 21:13:07 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 21:13:07 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@40ea1d00, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-2094721034, --group-instance-id, instance2000455797, --topic, my-topic-670612877-224958575, --bootstrap-server, my-cluster-63c3c553-kafka-bootstrap.namespace-59.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-63c3c553-kafka-clients-7758c98c85-r6n7k', podNamespace='namespace-59', bootstrapServer='my-cluster-63c3c553-kafka-bootstrap.namespace-59.svc:9092', topicName='my-topic-670612877-224958575', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-2094721034', consumerInstanceId='instance2000455797', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@597de2df}
2022-04-05 21:13:07 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-63c3c553-kafka-bootstrap.namespace-59.svc:9092#my-topic-670612877-224958575 from pod my-cluster-63c3c553-kafka-clients-7758c98c85-r6n7k
2022-04-05 21:13:07 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-63c3c553-kafka-clients-7758c98c85-r6n7k -n namespace-59 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-2094721034 --group-instance-id instance2000455797 --topic my-topic-670612877-224958575 --bootstrap-server my-cluster-63c3c553-kafka-bootstrap.namespace-59.svc:9092
2022-04-05 21:13:12 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 21:13:12 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 21:13:13 [main] [32mINFO [m [SecurityST:274] Triggering CA cert renewal by adding the annotation
2022-04-05 21:13:13 [main] [32mINFO [m [SecurityST:286] Patching secret my-cluster-63c3c553-cluster-ca-cert with strimzi.io/force-renew
2022-04-05 21:13:13 [main] [32mINFO [m [SecurityST:291] Wait for zk to rolling restart ...
2022-04-05 21:13:13 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-63c3c553-zookeeper rolling update
2022-04-05 21:14:23 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-63c3c553-zookeeper has been successfully rolled
2022-04-05 21:14:23 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-63c3c553-zookeeper to be ready
2022-04-05 21:14:56 [main] [32mINFO [m [SecurityST:295] Wait for kafka to rolling restart ...
2022-04-05 21:14:56 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-63c3c553-kafka rolling update
2022-04-05 21:15:51 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-63c3c553-kafka has been successfully rolled
2022-04-05 21:15:51 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-63c3c553-kafka to be ready
2022-04-05 21:16:21 [main] [32mINFO [m [SecurityST:299] Wait for EO to rolling restart ...
2022-04-05 21:16:21 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-63c3c553-entity-operator rolling update
2022-04-05 21:16:26 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-63c3c553-entity-operator will be ready
2022-04-05 21:17:05 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-63c3c553-entity-operator is ready
2022-04-05 21:17:15 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-63c3c553-entity-operator rolling update finished
2022-04-05 21:17:15 [main] [32mINFO [m [SecurityST:303] Wait for CC and KE to rolling restart ...
2022-04-05 21:17:15 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-63c3c553-kafka-exporter rolling update
2022-04-05 21:18:10 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-63c3c553-kafka-exporter will be ready
2022-04-05 21:18:10 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-63c3c553-kafka-exporter is ready
2022-04-05 21:18:20 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-63c3c553-kafka-exporter rolling update finished
2022-04-05 21:18:20 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-63c3c553-cruise-control rolling update
2022-04-05 21:18:20 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-63c3c553-cruise-control will be ready
2022-04-05 21:18:20 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-63c3c553-cruise-control is ready
2022-04-05 21:18:31 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-63c3c553-cruise-control rolling update finished
2022-04-05 21:18:31 [main] [32mINFO [m [SecurityST:308] Checking the certificates have been replaced
2022-04-05 21:18:31 [main] [32mINFO [m [SecurityST:322] Checking consumed messages to pod:my-cluster-63c3c553-kafka-clients-7758c98c85-r6n7k
2022-04-05 21:18:31 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7f8e9ed2, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-384416812, --group-instance-id, instance779169463, --topic, my-topic-670612877-224958575, --bootstrap-server, my-cluster-63c3c553-kafka-bootstrap.namespace-59.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-63c3c553-kafka-clients-7758c98c85-r6n7k', podNamespace='namespace-59', bootstrapServer='my-cluster-63c3c553-kafka-bootstrap.namespace-59.svc:9092', topicName='my-topic-670612877-224958575', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-384416812', consumerInstanceId='instance779169463', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3208d64}
2022-04-05 21:18:31 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-63c3c553-kafka-bootstrap.namespace-59.svc:9092#my-topic-670612877-224958575 from pod my-cluster-63c3c553-kafka-clients-7758c98c85-r6n7k
2022-04-05 21:18:31 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-63c3c553-kafka-clients-7758c98c85-r6n7k -n namespace-59 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-384416812 --group-instance-id instance779169463 --topic my-topic-670612877-224958575 --bootstrap-server my-cluster-63c3c553-kafka-bootstrap.namespace-59.svc:9092
2022-04-05 21:18:36 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 21:18:36 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 21:18:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser bob-my-cluster-63c3c553 in namespace namespace-59
2022-04-05 21:18:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-59
2022-04-05 21:18:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: bob-my-cluster-63c3c553 will have desired state: Ready
2022-04-05 21:18:37 [main] [32mINFO [m [ResourceManager:444] KafkaUser: bob-my-cluster-63c3c553 is in desired state: Ready
2022-04-05 21:18:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-63c3c553-kafka-clients-tls in namespace namespace-59
2022-04-05 21:18:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-59
2022-04-05 21:18:37 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-63c3c553-kafka-clients-tls will be ready
2022-04-05 21:18:39 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-63c3c553-kafka-clients-tls is ready
2022-04-05 21:18:39 [main] [32mINFO [m [SecurityST:346] Checking consumed messages to pod:my-cluster-63c3c553-kafka-clients-tls-c55f47db8-vbkd4
2022-04-05 21:18:39 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@bf2fffb, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-2019843033, --group-instance-id, instance709096513, --topic, my-topic-670612877-224958575, --bootstrap-server, my-cluster-63c3c553-kafka-bootstrap.namespace-59.svc:9093, USER=bob_my_cluster_63c3c553], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-63c3c553-kafka-clients-tls-c55f47db8-vbkd4', podNamespace='namespace-59', bootstrapServer='my-cluster-63c3c553-kafka-bootstrap.namespace-59.svc:9093', topicName='my-topic-670612877-224958575', maxMessages=100, kafkaUsername='bob-my-cluster-63c3c553', consumerGroupName='my-consumer-group-2019843033', consumerInstanceId='instance709096513', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@cbe08a5}
2022-04-05 21:18:39 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-63c3c553-kafka-bootstrap.namespace-59.svc:9093#my-topic-670612877-224958575 from pod my-cluster-63c3c553-kafka-clients-tls-c55f47db8-vbkd4
2022-04-05 21:18:39 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-63c3c553-kafka-clients-tls-c55f47db8-vbkd4 -n namespace-59 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-2019843033 --group-instance-id instance709096513 --topic my-topic-670612877-224958575 --bootstrap-server my-cluster-63c3c553-kafka-bootstrap.namespace-59.svc:9093 USER=bob_my_cluster_63c3c553
2022-04-05 21:18:46 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 21:18:46 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 21:18:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 21:18:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoRenewClusterCaCertsTriggeredByAnno
2022-04-05 21:18:46 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-63c3c553-kafka-clients in namespace namespace-59
2022-04-05 21:18:46 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-63c3c553 in namespace namespace-59
2022-04-05 21:18:46 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-59, for cruise control Kafka cluster my-cluster-63c3c553
2022-04-05 21:18:46 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-670612877-224958575 in namespace namespace-59
2022-04-05 21:18:46 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-63c3c553-kafka-clients-tls in namespace namespace-59
2022-04-05 21:18:46 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaUser bob-my-cluster-63c3c553 in namespace namespace-59
2022-04-05 21:18:46 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1305656753-1466407405 in namespace namespace-59
2022-04-05 21:19:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 21:19:36 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-59 for test case:testAutoRenewClusterCaCertsTriggeredByAnno
2022-04-05 21:19:47 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoRenewClusterCaCertsTriggeredByAnno-FINISHED
2022-04-05 21:19:47 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 21:19:47 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 21:19:47 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCaRenewalBreakInMiddle-STARTED
2022-04-05 21:19:47 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 21:19:47 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-60 for test case:testCaRenewalBreakInMiddle
2022-04-05 21:19:47 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-60
2022-04-05 21:19:47 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-60
2022-04-05 21:19:47 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-60
2022-04-05 21:19:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b76656e0 in namespace namespace-60
2022-04-05 21:19:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-60
2022-04-05 21:19:47 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b76656e0 will have desired state: Ready
2022-04-05 21:22:00 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b76656e0 is in desired state: Ready
2022-04-05 21:22:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-2112277316-849486734 in namespace namespace-60
2022-04-05 21:22:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-60
2022-04-05 21:22:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-2112277316-849486734 will have desired state: Ready
2022-04-05 21:22:01 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-2112277316-849486734 is in desired state: Ready
2022-04-05 21:22:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1173407732-299655588 in namespace namespace-60
2022-04-05 21:22:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-60
2022-04-05 21:22:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1173407732-299655588 will have desired state: Ready
2022-04-05 21:22:02 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1173407732-299655588 is in desired state: Ready
2022-04-05 21:22:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b76656e0-kafka-clients in namespace namespace-60
2022-04-05 21:22:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-60
2022-04-05 21:22:02 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b76656e0-kafka-clients will be ready
2022-04-05 21:22:03 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b76656e0-kafka-clients is ready
2022-04-05 21:22:03 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 21:22:03 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5f5ec933, messages=[], arguments=[--max-messages, 100, --topic, my-topic-1173407732-299655588, --bootstrap-server, my-cluster-b76656e0-kafka-bootstrap.namespace-60.svc:9093, USER=my_user_2112277316_849486734], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b76656e0-kafka-clients-5c78d68d76-rm9wd', podNamespace='namespace-60', bootstrapServer='my-cluster-b76656e0-kafka-bootstrap.namespace-60.svc:9093', topicName='my-topic-1173407732-299655588', maxMessages=100, kafkaUsername='my-user-2112277316-849486734', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@32c70389}
2022-04-05 21:22:03 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-b76656e0-kafka-bootstrap.namespace-60.svc:9093:my-topic-1173407732-299655588 from pod my-cluster-b76656e0-kafka-clients-5c78d68d76-rm9wd
2022-04-05 21:22:03 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b76656e0-kafka-clients-5c78d68d76-rm9wd -n namespace-60 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-1173407732-299655588 --bootstrap-server my-cluster-b76656e0-kafka-bootstrap.namespace-60.svc:9093 USER=my_user_2112277316_849486734
2022-04-05 21:22:06 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 21:22:06 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 21:22:06 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6fbeea1b, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-409864188, --group-instance-id, instance1643019290, --topic, my-topic-1173407732-299655588, --bootstrap-server, my-cluster-b76656e0-kafka-bootstrap.namespace-60.svc:9093, USER=my_user_2112277316_849486734], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b76656e0-kafka-clients-5c78d68d76-rm9wd', podNamespace='namespace-60', bootstrapServer='my-cluster-b76656e0-kafka-bootstrap.namespace-60.svc:9093', topicName='my-topic-1173407732-299655588', maxMessages=100, kafkaUsername='my-user-2112277316-849486734', consumerGroupName='my-consumer-group-409864188', consumerInstanceId='instance1643019290', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@656f6674}
2022-04-05 21:22:06 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-b76656e0-kafka-bootstrap.namespace-60.svc:9093:my-topic-1173407732-299655588 from pod my-cluster-b76656e0-kafka-clients-5c78d68d76-rm9wd
2022-04-05 21:22:06 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b76656e0-kafka-clients-5c78d68d76-rm9wd -n namespace-60 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-409864188 --group-instance-id instance1643019290 --topic my-topic-1173407732-299655588 --bootstrap-server my-cluster-b76656e0-kafka-bootstrap.namespace-60.svc:9093 USER=my_user_2112277316_849486734
2022-04-05 21:22:13 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 21:22:13 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 21:22:13 [main] [32mINFO [m [SecretUtils:70] Creating secret my-cluster-b76656e0-cluster-ca-cert
2022-04-05 21:22:13 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-b76656e0-zookeeper are in desired state
2022-04-05 21:22:14 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-b76656e0-zookeeper are in desired state
2022-04-05 21:22:15 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-b76656e0-zookeeper are in desired state
2022-04-05 21:22:17 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-b76656e0-zookeeper are in desired state
2022-04-05 21:22:18 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-b76656e0-zookeeper are in desired state
2022-04-05 21:22:19 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-b76656e0-zookeeper are in desired state
2022-04-05 21:22:20 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-b76656e0-zookeeper are in desired state
2022-04-05 21:22:21 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-b76656e0-zookeeper are in desired state
2022-04-05 21:22:22 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-b76656e0-zookeeper are in desired state
2022-04-05 21:22:23 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-b76656e0-zookeeper are in desired state
2022-04-05 21:22:24 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-b76656e0-zookeeper are in desired state
2022-04-05 21:22:25 [main] [32mINFO [m [SecurityST:1221] Pod in 'Pending' state: my-cluster-b76656e0-zookeeper-0
2022-04-05 21:22:25 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@67be62b9, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-681748223, --group-instance-id, instance1276539818, --topic, my-topic-1173407732-299655588, --bootstrap-server, my-cluster-b76656e0-kafka-bootstrap.namespace-60.svc:9093, USER=my_user_2112277316_849486734], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b76656e0-kafka-clients-5c78d68d76-rm9wd', podNamespace='namespace-60', bootstrapServer='my-cluster-b76656e0-kafka-bootstrap.namespace-60.svc:9093', topicName='my-topic-1173407732-299655588', maxMessages=100, kafkaUsername='my-user-2112277316-849486734', consumerGroupName='my-consumer-group-681748223', consumerInstanceId='instance1276539818', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@c0462f8}
2022-04-05 21:22:25 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-b76656e0-kafka-bootstrap.namespace-60.svc:9093:my-topic-1173407732-299655588 from pod my-cluster-b76656e0-kafka-clients-5c78d68d76-rm9wd
2022-04-05 21:22:25 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b76656e0-kafka-clients-5c78d68d76-rm9wd -n namespace-60 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-681748223 --group-instance-id instance1276539818 --topic my-topic-1173407732-299655588 --bootstrap-server my-cluster-b76656e0-kafka-bootstrap.namespace-60.svc:9093 USER=my_user_2112277316_849486734
2022-04-05 21:22:31 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 21:22:31 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 21:22:31 [main] [32mINFO [m [SecretUtils:131] Waiting for Secret my-cluster-b76656e0-cluster-ca-cert certificate change
2022-04-05 21:22:31 [main] [32mINFO [m [SecretUtils:138] Certificate in Secret my-cluster-b76656e0-cluster-ca-cert has changed, was -----BEGIN CERTIFICATE-----
MIIDKjCCAhKgAwIBAgIJAJBt0u1FFTG+MA0GCSqGSIb3DQEBCwUAMCoxEzARBgNV
BAoMCnN0cmltemkuaW8xEzARBgNVBAMMCmNsdXN0ZXItY2EwHhcNMTgxMDIzMTAw
MTExWhcNMTgxMDI0MTAwMTExWjAqMRMwEQYDVQQKDApzdHJpbXppLmlvMRMwEQYD
VQQDDApjbHVzdGVyLWNhMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA
xpuYrNXYHqw3ajwd12aAeuTlAX4rVwVdPuIex6A4NL8J3d2DV+ngXgNTH//RhiF5
If5KRWSsLei5BUIrwuQutOUNCQwyACmri9+yrx6+tevligiokAUwhHxcDHZpwC3T
+2dzk/BkI++vbSuvjFmBKGQi9gfyoTnStTEQ85KVJUS170hzwDjzaEiJsKpOPx/G
+KTdkAopLucoxr4sxhYeO4mQ2PkT0QL+R8Ohs6LD6v/bqalFP+rS8vibolfxjMNm
lXQCOd8UfXy8OEOaNoNCvhnn/cT/hbEG/ARbV3hHmUh9COV+TSV5dhsbmS5h4MKw
LzP449nGQBmLSkZMu984DQIDAQABo1MwUTAdBgNVHQ4EFgQUOXubcHBZJ7vSzjpi
pfXdFSP3dsEwHwYDVR0jBBgwFoAUOXubcHBZJ7vSzjpipfXdFSP3dsEwDwYDVR0T
AQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAQEAFFPGykbzUREDMzh+33i3a8TF
UTQnPMN/SuVbpLfQdpkpLO+aVWjVvJP6qMrI7jRO5zhj4MecAf7YKpe+dyRTTz9B
Dy9BZcujHYjCKdcKBnBFQ7B1xQm9tL1bw+a3ABzSTlhLiBcCxhJEawlWy1Gh18ab
3x/Kqnz0mk/jt5+n9HwlKHuBQVIxRCsfHWwq+WvIfoxM+N//akV8/29hLUf5TlYH
F5CX4G2pA5sSdaDHQ4ekQWuqM6tfvsGLl2KOmEFEgVR4GfaWI4BsUCzlpBNcCGWv
V7klZvBxQPG7MVy0cB8yzTDtUpR0jUFUkZOSp5Pr3yWcwPWEgWkaXYfO+FWETA==
-----END CERTIFICATE-----
, is now -----BEGIN CERTIFICATE-----
MIIFLTCCAxWgAwIBAgIUKyXznJlmnNhM6pA3a4D7sGCuZiEwDQYJKoZIhvcNAQEN
BQAwLTETMBEGA1UECgwKaW8uc3RyaW16aTEWMBQGA1UEAwwNY2x1c3Rlci1jYSB2
MDAeFw0yMjA0MDUyMTIyMTNaFw0yMjA0MTIyMTIyMTNaMC0xEzARBgNVBAoMCmlv
LnN0cmltemkxFjAUBgNVBAMMDWNsdXN0ZXItY2EgdjAwggIiMA0GCSqGSIb3DQEB
AQUAA4ICDwAwggIKAoICAQC0SZccxzTAiBfvh/jAOeif9EQ2qGyHPzWXce626Wjt
0tFp/Bv16m6lYUGnxfawe4fd1OB+EwPjrUeVfMDreoAUOhePB6ocRIENStRxFK08
OeSjJ0Oe7SYXaTmxoeK2hk7xP4UgK5tENnoxeKoW+Gn/Albt9VKe4w/4BfYbPg+F
pjPR+z3F28Ucv3btS7KdhEyF6SKvv++d8Czj1IFrp5o/IWmcgYcyckDoCSs+5N4m
3Ksd3kV6bnQOCUbgzlam5mIuV+PSveOQlSiJsZUcg2ctY9itzSBVZqHpVDL3KUb9
M5QLWIHQ3Ba4tgRWnw7IGXXqvDoXtW5lvoSKg7100Jm9JfuW8iAsfiPk4vDpgn0O
AZviNcVVdNwBAwQxSz0F+7rILvt0zLbcPkLSpvkzQkCMS3Wbvw8eKu9ESrB7Dc46
jPO3mxWFCRtZgNhjczMA56RvJPt/fqis1lrA90/hdZ+bBYEf9z8xNGlFyr60zPv4
mC8uB//CRmm9sp002W/P5aciF/b58P8GlO1AlxgGURby0iMCSlteNrU+o1OOyPA8
Bh05uNKTdAsXJMHhtS7weFBzGl4DhFeZxJhahMsPX4OjZMd2ew/NA1Ks+Zi92xEb
Z7ZiVUyQgDnby7hnr8/gNGnQiUlI/p3jgdCrX8GFePbvO4nrLJagkhZ/xaDunAmz
EQIDAQABo0UwQzAdBgNVHQ4EFgQUQKcrx0eIv9RIhW22eyIvIlIB4cQwEgYDVR0T
AQH/BAgwBgEB/wIBADAOBgNVHQ8BAf8EBAMCAQYwDQYJKoZIhvcNAQENBQADggIB
AGJUm/CKMuC9DwHNg6AhbslqS29TtOHxcDQaZFo9g3+yYSysp7sSh8gHPqCrA7S/
PJtm7Q/NkiAzFmi64Fpd+97MYO4iVBSkbpcPyBU6KFQs9Fz+MbGxivt7uITOL/yZ
KlUxtWJef9iLfXrjSPJ5aWPVmbhFt850B1Wt1gSa3cGY46W1wL7Gv84lpj7o8gHV
YtfATWI1aWFuFIXYHisYW9I0z881lNEv0g1XF9yj3lUIc4cxOuGIIBv2q7S3xwy6
rzKgD3KmdD8VZo6cC14My6ZbN8eiM5p4P1UYqiD3kLhhox4K4vdEJJbHKpjRiZVm
cevW3VWNYB3bKeeXlVarcEoBxFFz6gnkPAu5XYzidVFFnUYkjvtuD+AWXU+VG5An
9EXmiLEbG9pZvxR0jRdmSSAsY4iwjRzQMM7KZBrU+DQkim5etX0PAeDIu8AZoXP3
RsSeI1vUaeYQUObnWg0zZRxOL6ytBqBynCqOV87pUflYB0bfGi1TG9HKc951APeY
HLRN1uYGFTuAe3+xbqsj/ADt0ysT4XR/XrWKyt/GdDWorZKhgfgrqTGNM1RlonaU
piSmMd783kc1R4l5ER7vLHyFKX2nn5s7OwMvlOV25aRpaRjMBO4mlWH0FbNJasM+
OARNrIO8J5PXOe9tqxgPXFQnB6rYCUU2I/t5x33/bHNo
-----END CERTIFICATE-----

2022-04-05 21:22:31 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-b76656e0-zookeeper rolling update
2022-04-05 21:29:07 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-b76656e0-zookeeper has been successfully rolled
2022-04-05 21:29:07 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-b76656e0-zookeeper to be ready
2022-04-05 21:29:32 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-b76656e0-kafka rolling update
2022-04-05 21:30:27 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-b76656e0-kafka has been successfully rolled
2022-04-05 21:30:27 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-b76656e0-kafka to be ready
2022-04-05 21:30:53 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-b76656e0-entity-operator rolling update
2022-04-05 21:30:53 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b76656e0-entity-operator will be ready
2022-04-05 21:33:04 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b76656e0-entity-operator is ready
2022-04-05 21:33:14 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-b76656e0-entity-operator rolling update finished
2022-04-05 21:33:14 [main] [32mINFO [m [SecurityST:1252] Checking produced and consumed messages to pod:my-cluster-b76656e0-kafka-clients-5c78d68d76-rm9wd
2022-04-05 21:33:14 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@732ea4a6, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1843851172, --group-instance-id, instance510555340, --topic, my-topic-1173407732-299655588, --bootstrap-server, my-cluster-b76656e0-kafka-bootstrap.namespace-60.svc:9093, USER=my_user_2112277316_849486734], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b76656e0-kafka-clients-5c78d68d76-rm9wd', podNamespace='namespace-60', bootstrapServer='my-cluster-b76656e0-kafka-bootstrap.namespace-60.svc:9093', topicName='my-topic-1173407732-299655588', maxMessages=100, kafkaUsername='my-user-2112277316-849486734', consumerGroupName='my-consumer-group-1843851172', consumerInstanceId='instance510555340', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3c238e4a}
2022-04-05 21:33:14 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-b76656e0-kafka-bootstrap.namespace-60.svc:9093:my-topic-1173407732-299655588 from pod my-cluster-b76656e0-kafka-clients-5c78d68d76-rm9wd
2022-04-05 21:33:14 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b76656e0-kafka-clients-5c78d68d76-rm9wd -n namespace-60 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1843851172 --group-instance-id instance510555340 --topic my-topic-1173407732-299655588 --bootstrap-server my-cluster-b76656e0-kafka-bootstrap.namespace-60.svc:9093 USER=my_user_2112277316_849486734
2022-04-05 21:33:21 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 21:33:21 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 21:33:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-705536716-554602257 in namespace namespace-60
2022-04-05 21:33:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-60
2022-04-05 21:33:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-705536716-554602257 will have desired state: Ready
2022-04-05 21:33:22 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-705536716-554602257 is in desired state: Ready
2022-04-05 21:33:22 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@68b4d0c0, messages=[], arguments=[--max-messages, 100, --topic, my-topic-705536716-554602257, --bootstrap-server, my-cluster-b76656e0-kafka-bootstrap.namespace-60.svc:9093, USER=my_user_2112277316_849486734], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b76656e0-kafka-clients-5c78d68d76-rm9wd', podNamespace='namespace-60', bootstrapServer='my-cluster-b76656e0-kafka-bootstrap.namespace-60.svc:9093', topicName='my-topic-705536716-554602257', maxMessages=100, kafkaUsername='my-user-2112277316-849486734', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@48c5564c}
2022-04-05 21:33:22 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-b76656e0-kafka-bootstrap.namespace-60.svc:9093:my-topic-705536716-554602257 from pod my-cluster-b76656e0-kafka-clients-5c78d68d76-rm9wd
2022-04-05 21:33:22 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b76656e0-kafka-clients-5c78d68d76-rm9wd -n namespace-60 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-705536716-554602257 --bootstrap-server my-cluster-b76656e0-kafka-bootstrap.namespace-60.svc:9093 USER=my_user_2112277316_849486734
2022-04-05 21:33:25 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 21:33:25 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 21:33:25 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@46d091b1, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1009994970, --group-instance-id, instance569408575, --topic, my-topic-705536716-554602257, --bootstrap-server, my-cluster-b76656e0-kafka-bootstrap.namespace-60.svc:9093, USER=my_user_2112277316_849486734], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b76656e0-kafka-clients-5c78d68d76-rm9wd', podNamespace='namespace-60', bootstrapServer='my-cluster-b76656e0-kafka-bootstrap.namespace-60.svc:9093', topicName='my-topic-705536716-554602257', maxMessages=100, kafkaUsername='my-user-2112277316-849486734', consumerGroupName='my-consumer-group-1009994970', consumerInstanceId='instance569408575', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6eb942e4}
2022-04-05 21:33:25 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-b76656e0-kafka-bootstrap.namespace-60.svc:9093:my-topic-705536716-554602257 from pod my-cluster-b76656e0-kafka-clients-5c78d68d76-rm9wd
2022-04-05 21:33:25 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b76656e0-kafka-clients-5c78d68d76-rm9wd -n namespace-60 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1009994970 --group-instance-id instance569408575 --topic my-topic-705536716-554602257 --bootstrap-server my-cluster-b76656e0-kafka-bootstrap.namespace-60.svc:9093 USER=my_user_2112277316_849486734
2022-04-05 21:33:32 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 21:33:32 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 21:33:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 21:33:32 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCaRenewalBreakInMiddle
2022-04-05 21:33:32 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1173407732-299655588 in namespace namespace-60
2022-04-05 21:33:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b76656e0 in namespace namespace-60
2022-04-05 21:33:32 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-705536716-554602257 in namespace namespace-60
2022-04-05 21:33:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-2112277316-849486734 in namespace namespace-60
2022-04-05 21:33:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b76656e0-kafka-clients in namespace namespace-60
2022-04-05 21:34:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 21:34:22 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-60 for test case:testCaRenewalBreakInMiddle
2022-04-05 21:34:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCaRenewalBreakInMiddle-FINISHED
2022-04-05 21:34:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 21:34:29 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 21:34:29 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoRenewAllCaCertsTriggeredByAnno-STARTED
2022-04-05 21:34:29 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 21:34:29 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-61 for test case:testAutoRenewAllCaCertsTriggeredByAnno
2022-04-05 21:34:29 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-61
2022-04-05 21:34:29 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-61
2022-04-05 21:34:29 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-61
2022-04-05 21:34:29 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-05 21:34:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-203ee017 in namespace namespace-61
2022-04-05 21:34:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-61
2022-04-05 21:34:29 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-203ee017 will have desired state: Ready
2022-04-05 21:37:23 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-203ee017 is in desired state: Ready
2022-04-05 21:37:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1634807987-436878750 in namespace namespace-61
2022-04-05 21:37:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-61
2022-04-05 21:37:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1634807987-436878750 will have desired state: Ready
2022-04-05 21:37:24 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1634807987-436878750 is in desired state: Ready
2022-04-05 21:37:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-35365206-1912235927 in namespace namespace-61
2022-04-05 21:37:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-61
2022-04-05 21:37:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-35365206-1912235927 will have desired state: Ready
2022-04-05 21:37:25 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-35365206-1912235927 is in desired state: Ready
2022-04-05 21:37:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-203ee017-kafka-clients in namespace namespace-61
2022-04-05 21:37:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-61
2022-04-05 21:37:25 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-203ee017-kafka-clients will be ready
2022-04-05 21:37:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-203ee017-kafka-clients is ready
2022-04-05 21:37:27 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 21:37:27 [main] [32mINFO [m [SecurityST:260] Checking produced and consumed messages to pod:my-cluster-203ee017-kafka-clients-5c9fd978b8-8p8sp
2022-04-05 21:37:27 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@4e33ef58, messages=[], arguments=[--max-messages, 100, --topic, my-topic-35365206-1912235927, --bootstrap-server, my-cluster-203ee017-kafka-bootstrap.namespace-61.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-203ee017-kafka-clients-5c9fd978b8-8p8sp', podNamespace='namespace-61', bootstrapServer='my-cluster-203ee017-kafka-bootstrap.namespace-61.svc:9092', topicName='my-topic-35365206-1912235927', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6a393e99}
2022-04-05 21:37:27 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-203ee017-kafka-bootstrap.namespace-61.svc:9092:my-topic-35365206-1912235927 from pod my-cluster-203ee017-kafka-clients-5c9fd978b8-8p8sp
2022-04-05 21:37:27 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-203ee017-kafka-clients-5c9fd978b8-8p8sp -n namespace-61 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-35365206-1912235927 --bootstrap-server my-cluster-203ee017-kafka-bootstrap.namespace-61.svc:9092
2022-04-05 21:37:30 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 21:37:30 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 21:37:30 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@254dcd59, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1938659764, --group-instance-id, instance567423255, --topic, my-topic-35365206-1912235927, --bootstrap-server, my-cluster-203ee017-kafka-bootstrap.namespace-61.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-203ee017-kafka-clients-5c9fd978b8-8p8sp', podNamespace='namespace-61', bootstrapServer='my-cluster-203ee017-kafka-bootstrap.namespace-61.svc:9092', topicName='my-topic-35365206-1912235927', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1938659764', consumerInstanceId='instance567423255', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6a3e6e2}
2022-04-05 21:37:30 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-203ee017-kafka-bootstrap.namespace-61.svc:9092#my-topic-35365206-1912235927 from pod my-cluster-203ee017-kafka-clients-5c9fd978b8-8p8sp
2022-04-05 21:37:30 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-203ee017-kafka-clients-5c9fd978b8-8p8sp -n namespace-61 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1938659764 --group-instance-id instance567423255 --topic my-topic-35365206-1912235927 --bootstrap-server my-cluster-203ee017-kafka-bootstrap.namespace-61.svc:9092
2022-04-05 21:37:36 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 21:37:36 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 21:37:36 [main] [32mINFO [m [SecurityST:274] Triggering CA cert renewal by adding the annotation
2022-04-05 21:37:36 [main] [32mINFO [m [SecurityST:286] Patching secret my-cluster-203ee017-cluster-ca-cert with strimzi.io/force-renew
2022-04-05 21:37:36 [main] [32mINFO [m [SecurityST:286] Patching secret my-cluster-203ee017-clients-ca-cert with strimzi.io/force-renew
2022-04-05 21:37:36 [main] [32mINFO [m [SecurityST:291] Wait for zk to rolling restart ...
2022-04-05 21:37:36 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-203ee017-zookeeper rolling update
2022-04-05 21:38:56 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-203ee017-zookeeper has been successfully rolled
2022-04-05 21:38:56 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-203ee017-zookeeper to be ready
2022-04-05 21:39:23 [main] [32mINFO [m [SecurityST:295] Wait for kafka to rolling restart ...
2022-04-05 21:39:23 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-203ee017-kafka rolling update
2022-04-05 21:40:38 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-203ee017-kafka has been successfully rolled
2022-04-05 21:40:38 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-203ee017-kafka to be ready
2022-04-05 21:41:06 [main] [32mINFO [m [SecurityST:299] Wait for EO to rolling restart ...
2022-04-05 21:41:06 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-203ee017-entity-operator rolling update
2022-04-05 21:41:06 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-203ee017-entity-operator will be ready
2022-04-05 21:46:25 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-203ee017-entity-operator is ready
2022-04-05 21:46:35 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-203ee017-entity-operator rolling update finished
2022-04-05 21:46:35 [main] [32mINFO [m [SecurityST:303] Wait for CC and KE to rolling restart ...
2022-04-05 21:46:35 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-203ee017-kafka-exporter rolling update
2022-04-05 21:47:30 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-203ee017-kafka-exporter will be ready
2022-04-05 21:47:30 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-203ee017-kafka-exporter is ready
2022-04-05 21:47:40 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-203ee017-kafka-exporter rolling update finished
2022-04-05 21:47:40 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-203ee017-cruise-control rolling update
2022-04-05 21:47:40 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-203ee017-cruise-control will be ready
2022-04-05 21:47:40 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-203ee017-cruise-control is ready
2022-04-05 21:47:51 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-203ee017-cruise-control rolling update finished
2022-04-05 21:47:51 [main] [32mINFO [m [SecurityST:308] Checking the certificates have been replaced
2022-04-05 21:47:51 [main] [32mINFO [m [SecurityST:322] Checking consumed messages to pod:my-cluster-203ee017-kafka-clients-5c9fd978b8-8p8sp
2022-04-05 21:47:51 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@a3012ec, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1674778870, --group-instance-id, instance1590848681, --topic, my-topic-35365206-1912235927, --bootstrap-server, my-cluster-203ee017-kafka-bootstrap.namespace-61.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-203ee017-kafka-clients-5c9fd978b8-8p8sp', podNamespace='namespace-61', bootstrapServer='my-cluster-203ee017-kafka-bootstrap.namespace-61.svc:9092', topicName='my-topic-35365206-1912235927', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1674778870', consumerInstanceId='instance1590848681', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7dc4f6a0}
2022-04-05 21:47:51 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-203ee017-kafka-bootstrap.namespace-61.svc:9092#my-topic-35365206-1912235927 from pod my-cluster-203ee017-kafka-clients-5c9fd978b8-8p8sp
2022-04-05 21:47:51 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-203ee017-kafka-clients-5c9fd978b8-8p8sp -n namespace-61 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1674778870 --group-instance-id instance1590848681 --topic my-topic-35365206-1912235927 --bootstrap-server my-cluster-203ee017-kafka-bootstrap.namespace-61.svc:9092
2022-04-05 21:47:56 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 21:47:56 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 21:47:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser bob-my-cluster-203ee017 in namespace namespace-61
2022-04-05 21:47:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-61
2022-04-05 21:47:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: bob-my-cluster-203ee017 will have desired state: Ready
2022-04-05 21:47:57 [main] [32mINFO [m [ResourceManager:444] KafkaUser: bob-my-cluster-203ee017 is in desired state: Ready
2022-04-05 21:47:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-203ee017-kafka-clients-tls in namespace namespace-61
2022-04-05 21:47:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-61
2022-04-05 21:47:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-203ee017-kafka-clients-tls will be ready
2022-04-05 21:48:00 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-203ee017-kafka-clients-tls is ready
2022-04-05 21:48:00 [main] [32mINFO [m [SecurityST:346] Checking consumed messages to pod:my-cluster-203ee017-kafka-clients-tls-78c95dd9b5-p4lzh
2022-04-05 21:48:00 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@20d44525, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-431771976, --group-instance-id, instance1536971167, --topic, my-topic-35365206-1912235927, --bootstrap-server, my-cluster-203ee017-kafka-bootstrap.namespace-61.svc:9093, USER=bob_my_cluster_203ee017], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-203ee017-kafka-clients-tls-78c95dd9b5-p4lzh', podNamespace='namespace-61', bootstrapServer='my-cluster-203ee017-kafka-bootstrap.namespace-61.svc:9093', topicName='my-topic-35365206-1912235927', maxMessages=100, kafkaUsername='bob-my-cluster-203ee017', consumerGroupName='my-consumer-group-431771976', consumerInstanceId='instance1536971167', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7affdd2c}
2022-04-05 21:48:00 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-203ee017-kafka-bootstrap.namespace-61.svc:9093#my-topic-35365206-1912235927 from pod my-cluster-203ee017-kafka-clients-tls-78c95dd9b5-p4lzh
2022-04-05 21:48:00 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-203ee017-kafka-clients-tls-78c95dd9b5-p4lzh -n namespace-61 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-431771976 --group-instance-id instance1536971167 --topic my-topic-35365206-1912235927 --bootstrap-server my-cluster-203ee017-kafka-bootstrap.namespace-61.svc:9093 USER=bob_my_cluster_203ee017
2022-04-05 21:48:07 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 21:48:07 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 21:48:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 21:48:07 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoRenewAllCaCertsTriggeredByAnno
2022-04-05 21:48:07 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-203ee017-kafka-clients in namespace namespace-61
2022-04-05 21:48:07 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-203ee017 in namespace namespace-61
2022-04-05 21:48:07 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-35365206-1912235927 in namespace namespace-61
2022-04-05 21:48:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-203ee017-kafka-clients-tls in namespace namespace-61
2022-04-05 21:48:07 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-61, for cruise control Kafka cluster my-cluster-203ee017
2022-04-05 21:48:07 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1634807987-436878750 in namespace namespace-61
2022-04-05 21:48:07 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser bob-my-cluster-203ee017 in namespace namespace-61
2022-04-05 21:48:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 21:48:57 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-61 for test case:testAutoRenewAllCaCertsTriggeredByAnno
2022-04-05 21:49:03 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoRenewAllCaCertsTriggeredByAnno-FINISHED
2022-04-05 21:49:03 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 21:49:03 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 21:49:03 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCertRegeneratedAfterInternalCAisDeleted-STARTED
2022-04-05 21:49:03 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 21:49:03 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-62 for test case:testCertRegeneratedAfterInternalCAisDeleted
2022-04-05 21:49:03 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-62
2022-04-05 21:49:03 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-62
2022-04-05 21:49:03 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-62
2022-04-05 21:49:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-54edbed3 in namespace namespace-62
2022-04-05 21:49:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-62
2022-04-05 21:49:03 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-54edbed3 will have desired state: Ready
2022-04-05 21:50:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-54edbed3 is in desired state: Ready
2022-04-05 21:50:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1613874122-1269448048 in namespace namespace-62
2022-04-05 21:50:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-62
2022-04-05 21:50:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1613874122-1269448048 will have desired state: Ready
2022-04-05 21:50:22 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1613874122-1269448048 is in desired state: Ready
2022-04-05 21:50:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-723371508-697194234 in namespace namespace-62
2022-04-05 21:50:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-62
2022-04-05 21:50:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-723371508-697194234 will have desired state: Ready
2022-04-05 21:50:23 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-723371508-697194234 is in desired state: Ready
2022-04-05 21:50:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-54edbed3-kafka-clients in namespace namespace-62
2022-04-05 21:50:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-62
2022-04-05 21:50:23 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-54edbed3-kafka-clients will be ready
2022-04-05 21:50:25 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-54edbed3-kafka-clients is ready
2022-04-05 21:50:25 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 21:50:25 [main] [32mINFO [m [SecurityST:797] Verifying that secret Secret(apiVersion=v1, data={ca.crt=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, ca.p12=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, ca.password=VUJWOXAyOGQ4U0JM}, immutable=null, kind=Secret, metadata=ObjectMeta(annotations={strimzi.io/ca-cert-generation=0}, clusterName=null, creationTimestamp=2022-04-05T21:49:05Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-54edbed3, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-54edbed3, strimzi.io/cluster=my-cluster-54edbed3, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testCertRegeneratedAfterInternalCAisDeleted}, managedFields=[], name=my-cluster-54edbed3-clients-ca-cert, namespace=namespace-62, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=Kafka, name=my-cluster-54edbed3, uid=9286395e-6d72-4ae9-80c6-3c20348d97fb, additionalProperties={})], resourceVersion=296304, selfLink=/api/v1/namespaces/namespace-62/secrets/my-cluster-54edbed3-clients-ca-cert, uid=640bf8a2-4c21-418b-bb86-ebe2d3e323e2, additionalProperties={}), stringData=null, type=Opaque, additionalProperties={}) with name my-cluster-54edbed3-clients-ca-cert is present
2022-04-05 21:50:25 [main] [32mINFO [m [SecurityST:797] Verifying that secret Secret(apiVersion=v1, data={ca.crt=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, ca.p12=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, ca.password=ZXZUbEJhNXBnNGNh}, immutable=null, kind=Secret, metadata=ObjectMeta(annotations={strimzi.io/ca-cert-generation=0}, clusterName=null, creationTimestamp=2022-04-05T21:49:05Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-54edbed3, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-54edbed3, strimzi.io/cluster=my-cluster-54edbed3, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testCertRegeneratedAfterInternalCAisDeleted}, managedFields=[], name=my-cluster-54edbed3-cluster-ca-cert, namespace=namespace-62, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=Kafka, name=my-cluster-54edbed3, uid=9286395e-6d72-4ae9-80c6-3c20348d97fb, additionalProperties={})], resourceVersion=296305, selfLink=/api/v1/namespaces/namespace-62/secrets/my-cluster-54edbed3-cluster-ca-cert, uid=f76f3620-76d2-49ba-9b08-b6b59deebd19, additionalProperties={}), stringData=null, type=Opaque, additionalProperties={}) with name my-cluster-54edbed3-cluster-ca-cert is present
2022-04-05 21:50:25 [main] [32mINFO [m [SecurityST:802] Deleting secret my-cluster-54edbed3-clients-ca-cert
2022-04-05 21:50:25 [main] [32mINFO [m [SecurityST:802] Deleting secret my-cluster-54edbed3-cluster-ca-cert
2022-04-05 21:50:25 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-54edbed3-kafka are stable
2022-04-05 21:50:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 21:50:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 21:50:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 21:50:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 21:50:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 21:50:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 21:50:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 21:50:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 21:50:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 21:50:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 21:50:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 21:50:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 21:50:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 21:50:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 21:50:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 21:50:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 21:50:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 21:50:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 21:50:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 21:50:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 21:50:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 21:50:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 21:50:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 21:50:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 21:50:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 21:50:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 21:50:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 21:50:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 21:50:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 21:50:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 21:50:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 21:50:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 21:50:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 21:50:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 21:50:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 21:50:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 21:50:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 21:50:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 21:50:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 21:50:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 21:50:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 21:50:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 21:50:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 21:50:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 21:50:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 21:50:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 21:50:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 21:50:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 21:50:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 21:50:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 21:50:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 21:50:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 21:50:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 21:50:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 21:50:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 21:50:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 21:50:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 21:50:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 21:50:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 21:50:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 21:50:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 21:50:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 21:50:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 21:50:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 21:50:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 21:50:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 21:50:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 21:50:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 21:50:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 21:50:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 21:50:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 21:50:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 21:50:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 21:50:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 21:50:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 21:50:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 21:50:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 21:50:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 21:50:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 21:50:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 21:50:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 21:50:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 21:50:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 21:50:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 21:50:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 21:50:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 21:50:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 21:50:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 21:50:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 21:50:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 21:50:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 21:50:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 21:50:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 21:50:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 21:50:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 21:50:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 21:50:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 21:50:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 21:50:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 21:50:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 21:50:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 21:50:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 21:50:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 21:50:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 21:50:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 21:50:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 21:50:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 21:50:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 21:50:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 21:50:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 21:50:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 21:50:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 21:50:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 21:50:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 21:50:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 21:50:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 21:50:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 21:50:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 21:50:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 21:50:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 21:50:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 21:50:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 21:50:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 21:50:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 21:50:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 21:50:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 21:50:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 21:50:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 21:50:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 21:50:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 21:50:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 21:50:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 21:50:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 21:50:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 21:50:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 21:50:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 21:50:59 [main] [32mINFO [m [PodUtils:326] Pod my-cluster-54edbed3-kafka-0 is not stable in phase following phase Pending reset the stability counter from 34 to 0
2022-04-05 21:51:00 [main] [32mINFO [m [PodUtils:326] Pod my-cluster-54edbed3-kafka-0 is not stable in phase following phase Pending reset the stability counter from 0 to 0
2022-04-05 21:51:01 [main] [32mINFO [m [PodUtils:326] Pod my-cluster-54edbed3-kafka-0 is not stable in phase following phase Pending reset the stability counter from 0 to 0
2022-04-05 21:51:02 [main] [32mINFO [m [PodUtils:326] Pod my-cluster-54edbed3-kafka-0 is not stable in phase following phase Pending reset the stability counter from 0 to 0
2022-04-05 21:51:03 [main] [32mINFO [m [PodUtils:326] Pod my-cluster-54edbed3-kafka-0 is not stable in phase following phase Pending reset the stability counter from 0 to 0
2022-04-05 21:51:04 [main] [32mINFO [m [PodUtils:326] Pod my-cluster-54edbed3-kafka-0 is not stable in phase following phase Pending reset the stability counter from 0 to 0
2022-04-05 21:51:05 [main] [32mINFO [m [PodUtils:326] Pod my-cluster-54edbed3-kafka-0 is not stable in phase following phase Pending reset the stability counter from 0 to 0
2022-04-05 21:51:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 21:51:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 21:51:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 21:51:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 21:51:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 21:51:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 21:51:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 21:51:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 21:51:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 21:51:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 21:51:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 21:51:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 21:51:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 21:51:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 21:51:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 21:51:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 21:51:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 21:51:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 21:51:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 21:51:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 21:51:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 21:51:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 21:51:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 21:51:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 21:51:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 21:51:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 21:51:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 21:51:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 21:51:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 21:51:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 21:51:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 21:51:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 21:51:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 21:51:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 21:51:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 21:51:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 21:51:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 21:51:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 21:51:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 21:51:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 21:51:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 21:51:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 21:51:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 21:51:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 21:51:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 21:51:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 21:51:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 21:51:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 21:51:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 21:51:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 21:51:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 21:51:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 21:51:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 21:51:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 21:51:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 21:51:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 21:51:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 21:51:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 21:51:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 21:51:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 21:51:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 21:51:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 21:51:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 21:51:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 21:51:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 21:51:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 21:51:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 21:51:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 21:51:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 21:51:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 21:51:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 21:51:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 21:51:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 21:51:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 21:51:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 21:51:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 21:51:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 21:51:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 21:51:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 21:51:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 21:51:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 21:51:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 21:51:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 21:51:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 21:51:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 21:51:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 21:51:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 21:51:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 21:51:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 21:51:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 21:51:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 21:51:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 21:51:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 21:51:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 21:51:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 21:51:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 21:51:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 21:51:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 21:51:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 21:51:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 21:51:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 21:51:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 21:51:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 21:51:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 21:51:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 21:51:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 21:51:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 21:51:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 21:51:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 21:51:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 21:51:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 21:51:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 21:51:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 21:51:34 [main] [32mINFO [m [PodUtils:326] Pod my-cluster-54edbed3-kafka-1 is not stable in phase following phase Pending reset the stability counter from 28 to 0
2022-04-05 21:51:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 21:51:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 21:51:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 21:51:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 21:51:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 21:51:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 21:51:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 21:51:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 21:51:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 21:51:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 21:51:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 21:51:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 21:51:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 21:51:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 21:51:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 21:51:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 21:51:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 21:51:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 21:51:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 21:51:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 21:51:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 21:51:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 21:51:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 21:51:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 21:51:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 21:51:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 21:51:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 21:51:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 21:51:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 21:51:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 21:51:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 21:51:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 21:51:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 21:51:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 21:51:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 21:51:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 21:51:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 21:51:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 21:51:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 21:51:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 21:51:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 21:51:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 21:51:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 21:51:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 21:51:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 21:51:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 21:51:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 21:51:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 21:51:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 21:51:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 21:51:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 21:51:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 21:51:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 21:51:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 21:51:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 21:51:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 21:51:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 21:51:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 21:51:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 21:51:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 21:51:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 21:51:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 21:51:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 21:51:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 21:51:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 21:51:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 21:51:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 21:51:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 21:51:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 21:51:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 21:51:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 21:51:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 21:51:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 21:51:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 21:51:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 21:51:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 21:51:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 21:51:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 21:51:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 21:51:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 21:51:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 21:51:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 21:51:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 21:51:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 21:51:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 21:51:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 21:51:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 21:51:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 21:51:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 21:51:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 21:51:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 21:51:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 21:51:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 21:51:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 21:51:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 21:51:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 21:52:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 21:52:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 21:52:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 21:52:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 21:52:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 21:52:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 21:52:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 21:52:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 21:52:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 21:52:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 21:52:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 21:52:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 21:52:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 21:52:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 21:52:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 21:52:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 21:52:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 21:52:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 21:52:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 21:52:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 21:52:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 21:52:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 21:52:05 [main] [32mINFO [m [PodUtils:326] Pod my-cluster-54edbed3-kafka-2 is not stable in phase following phase Pending reset the stability counter from 29 to 0
2022-04-05 21:52:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 21:52:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 21:52:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 21:52:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 21:52:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 21:52:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 21:52:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 21:52:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 21:52:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 21:52:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 21:52:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 21:52:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 21:52:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 21:52:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 21:52:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 21:52:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 21:52:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 21:52:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 21:52:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 21:52:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 21:52:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 21:52:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 21:52:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 21:52:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 21:52:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 21:52:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 21:52:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 21:52:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 21:52:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 21:52:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 21:52:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 21:52:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 21:52:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 21:52:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 21:52:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 21:52:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 21:52:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 21:52:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 21:52:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 21:52:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 21:52:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 21:52:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 21:52:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 21:52:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 21:52:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 21:52:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 21:52:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 21:52:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 21:52:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 21:52:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 21:52:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 21:52:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 21:52:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 21:52:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 21:52:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 21:52:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 21:52:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 21:52:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 21:52:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 21:52:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 21:52:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 21:52:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 21:52:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 21:52:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 21:52:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 21:52:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 21:52:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 21:52:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 21:52:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 21:52:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 21:52:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 21:52:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 21:52:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 21:52:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 21:52:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 21:52:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 21:52:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 21:52:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 21:52:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 21:52:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 21:52:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 21:52:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 21:52:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 21:52:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 21:52:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 21:52:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 21:52:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 21:52:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 21:52:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 21:52:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 21:52:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 21:52:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 21:52:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 21:52:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 21:52:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 21:52:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 21:52:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 21:52:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 21:52:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 21:52:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 21:52:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 21:52:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 21:52:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 21:52:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 21:52:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 21:52:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 21:52:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 21:52:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 21:52:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 21:52:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 21:52:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 21:52:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 21:52:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 21:52:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 21:52:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 21:52:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 21:52:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 21:52:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 21:52:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 21:52:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 21:52:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 21:52:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 21:52:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 21:52:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 21:52:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 21:52:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 21:52:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 21:52:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 21:52:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 21:52:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 21:52:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 21:52:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 21:52:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 21:52:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 21:52:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 21:52:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 21:52:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 21:52:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 21:52:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 21:52:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 21:52:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 21:52:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 21:52:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 21:52:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 21:52:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 21:52:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 21:52:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 21:52:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 21:52:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 21:52:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 21:52:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 21:52:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 21:52:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 21:52:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 21:52:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 21:52:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 21:52:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 21:52:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 21:52:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 21:52:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 21:52:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 21:52:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 21:52:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 21:52:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 21:52:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 21:52:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 21:52:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 21:52:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 21:52:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 21:52:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 21:52:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 21:52:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 21:52:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 21:52:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 21:52:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 21:52:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 21:52:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 21:52:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 21:52:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 21:52:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 21:52:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 21:52:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 21:52:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 21:52:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 21:52:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 21:52:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 21:52:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 21:52:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 21:52:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 21:52:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 21:52:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 21:52:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 21:52:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 21:52:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 21:52:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 21:52:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 21:52:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 21:52:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 21:52:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 21:52:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 21:52:55 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-54edbed3-kafka-0 ,my-cluster-54edbed3-kafka-1 ,my-cluster-54edbed3-kafka-2 ,my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk
2022-04-05 21:52:55 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-54edbed3-kafka rolling update
2022-04-05 21:52:55 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-54edbed3-kafka has been successfully rolled
2022-04-05 21:52:55 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-54edbed3-kafka to be ready
2022-04-05 21:53:05 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-54edbed3 will have desired state: Ready
2022-04-05 21:53:05 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-54edbed3 is in desired state: Ready
2022-04-05 21:53:05 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-54edbed3 is ready
2022-04-05 21:53:05 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret my-cluster-54edbed3-clients-ca-cert
2022-04-05 21:53:05 [main] [32mINFO [m [SecretUtils:50] Secret my-cluster-54edbed3-clients-ca-cert created
2022-04-05 21:53:05 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret my-cluster-54edbed3-cluster-ca-cert
2022-04-05 21:53:05 [main] [32mINFO [m [SecretUtils:50] Secret my-cluster-54edbed3-cluster-ca-cert created
2022-04-05 21:53:05 [main] [32mINFO [m [SecurityST:821] Checking consumed messages to pod:my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk
2022-04-05 21:53:05 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1d01fc13, messages=[], arguments=[--max-messages, 100, --topic, my-topic-723371508-697194234, --bootstrap-server, my-cluster-54edbed3-kafka-bootstrap.namespace-62.svc:9093, USER=my_user_1613874122_1269448048], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk', podNamespace='namespace-62', bootstrapServer='my-cluster-54edbed3-kafka-bootstrap.namespace-62.svc:9093', topicName='my-topic-723371508-697194234', maxMessages=100, kafkaUsername='my-user-1613874122-1269448048', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7720664d}
2022-04-05 21:53:05 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-54edbed3-kafka-bootstrap.namespace-62.svc:9093:my-topic-723371508-697194234 from pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk
2022-04-05 21:53:05 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk -n namespace-62 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-723371508-697194234 --bootstrap-server my-cluster-54edbed3-kafka-bootstrap.namespace-62.svc:9093 USER=my_user_1613874122_1269448048
2022-04-05 21:53:09 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 21:53:09 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 21:53:09 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@54096b1e, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1647045695, --group-instance-id, instance1069555617, --topic, my-topic-723371508-697194234, --bootstrap-server, my-cluster-54edbed3-kafka-bootstrap.namespace-62.svc:9093, USER=my_user_1613874122_1269448048], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk', podNamespace='namespace-62', bootstrapServer='my-cluster-54edbed3-kafka-bootstrap.namespace-62.svc:9093', topicName='my-topic-723371508-697194234', maxMessages=100, kafkaUsername='my-user-1613874122-1269448048', consumerGroupName='my-consumer-group-1647045695', consumerInstanceId='instance1069555617', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@20ef7340}
2022-04-05 21:53:09 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-54edbed3-kafka-bootstrap.namespace-62.svc:9093:my-topic-723371508-697194234 from pod my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk
2022-04-05 21:53:09 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-54edbed3-kafka-clients-59dd757f9b-vr9qk -n namespace-62 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1647045695 --group-instance-id instance1069555617 --topic my-topic-723371508-697194234 --bootstrap-server my-cluster-54edbed3-kafka-bootstrap.namespace-62.svc:9093 USER=my_user_1613874122_1269448048
2022-04-05 21:53:16 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 21:53:16 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 21:53:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 21:53:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCertRegeneratedAfterInternalCAisDeleted
2022-04-05 21:53:16 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-723371508-697194234 in namespace namespace-62
2022-04-05 21:53:16 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1613874122-1269448048 in namespace namespace-62
2022-04-05 21:53:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-54edbed3-kafka-clients in namespace namespace-62
2022-04-05 21:53:16 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-54edbed3 in namespace namespace-62
2022-04-05 21:54:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 21:54:06 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-62 for test case:testCertRegeneratedAfterInternalCAisDeleted
2022-04-05 21:54:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCertRegeneratedAfterInternalCAisDeleted-FINISHED
2022-04-05 21:54:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 21:54:17 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 21:54:17 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testKafkaAndKafkaConnectCipherSuites-STARTED
2022-04-05 21:54:17 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 21:54:17 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-63 for test case:testKafkaAndKafkaConnectCipherSuites
2022-04-05 21:54:17 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-63
2022-04-05 21:54:17 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-63
2022-04-05 21:54:17 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-63
2022-04-05 21:54:17 [main] [32mINFO [m [SecurityST:1362] Deploying Kafka cluster with the support TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 cipher algorithms
2022-04-05 21:54:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-708502e6 in namespace namespace-63
2022-04-05 21:54:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-63
2022-04-05 21:54:17 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-708502e6 will have desired state: Ready
2022-04-05 21:55:37 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-708502e6 is in desired state: Ready
2022-04-05 21:55:37 [main] [32mINFO [m [SecurityST:1374] Verifying that Kafka Connect has the accepted configuration:
 ssl.cipher.suites -> TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
2022-04-05 21:55:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-708502e6-kafka-clients in namespace namespace-63
2022-04-05 21:55:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-63
2022-04-05 21:55:37 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-708502e6-kafka-clients will be ready
2022-04-05 21:55:39 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-708502e6-kafka-clients is ready
2022-04-05 21:55:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-708502e6-scraper in namespace namespace-63
2022-04-05 21:55:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-63
2022-04-05 21:55:39 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-708502e6-scraper will be ready
2022-04-05 21:55:41 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-708502e6-scraper is ready
2022-04-05 21:55:41 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-708502e6-scraper to be ready
2022-04-05 21:55:51 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-708502e6-scraper is ready
2022-04-05 21:55:51 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-708502e6-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-05 21:55:51 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-708502e6-allow in namespace namespace-63
2022-04-05 21:55:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-63
2022-04-05 21:55:51 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-05 21:55:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-708502e6 in namespace namespace-63
2022-04-05 21:55:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-63
2022-04-05 21:55:51 [main] [32mINFO [m [SecurityST:1391] Verifying that Kafka Connect status is NotReady because of different cipher suites complexity of algorithm
2022-04-05 21:55:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-708502e6 will have desired state: NotReady
2022-04-05 22:00:53 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-708502e6 is in desired state: NotReady
2022-04-05 22:00:53 [main] [32mINFO [m [SecurityST:1395] Replacing Kafka Connect config to the cipher suites same as the Kafka broker has.
2022-04-05 22:00:53 [main] [32mINFO [m [SecurityST:1399] Verifying that Kafka Connect has the accepted configuration:
 ssl.cipher.suites -> TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
2022-04-05 22:00:53 [main] [32mINFO [m [KafkaConnectUtils:101] Waiting for Kafka Connect property ssl.cipher.suites -> TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 change
2022-04-05 22:00:53 [main] [32mINFO [m [KafkaConnectUtils:109] Kafka Connect property ssl.cipher.suites -> TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 change
2022-04-05 22:00:53 [main] [32mINFO [m [SecurityST:1404] Verifying that Kafka Connect is stable
2022-04-05 22:00:53 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-708502e6-connect are stable
2022-04-05 22:00:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 22:00:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 22:00:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 22:00:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 22:00:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 22:00:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 22:00:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 22:01:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 22:01:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 22:01:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 22:01:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 22:01:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 22:01:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 22:01:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 22:01:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 22:01:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 22:01:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 22:01:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 22:01:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 22:01:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 22:01:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 22:01:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 22:01:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 22:01:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 22:01:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 22:01:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 22:01:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 22:01:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 22:01:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 22:01:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 22:01:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 22:01:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 22:01:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 22:01:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 22:01:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 22:01:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 22:01:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 22:01:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 22:01:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 22:01:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 22:01:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 22:01:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 22:01:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 22:01:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 22:01:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 22:01:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 22:01:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 22:01:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 22:01:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 22:01:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-708502e6-connect-c9f79f577-r6ghz is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 22:01:42 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-708502e6-connect-c9f79f577-r6ghz
2022-04-05 22:01:42 [main] [32mINFO [m [SecurityST:1408] Verifying that Kafka Connect status is Ready because of the same cipher suites complexity of algorithm
2022-04-05 22:01:42 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-708502e6 will have desired state: Ready
2022-04-05 22:06:58 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-708502e6 is in desired state: Ready
2022-04-05 22:06:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 22:06:58 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaAndKafkaConnectCipherSuites
2022-04-05 22:06:58 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-708502e6-scraper in namespace namespace-63
2022-04-05 22:06:58 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-708502e6 in namespace namespace-63
2022-04-05 22:06:58 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-708502e6 in namespace namespace-63
2022-04-05 22:06:58 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-708502e6-allow in namespace namespace-63
2022-04-05 22:06:58 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-708502e6-kafka-clients in namespace namespace-63
2022-04-05 22:07:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 22:07:48 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-63 for test case:testKafkaAndKafkaConnectCipherSuites
2022-04-05 22:07:54 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testKafkaAndKafkaConnectCipherSuites-FINISHED
2022-04-05 22:07:54 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 22:07:54 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 22:07:54 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCertRenewalInMaintenanceWindow-STARTED
2022-04-05 22:07:54 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 22:07:54 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-64 for test case:testCertRenewalInMaintenanceWindow
2022-04-05 22:07:54 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-64
2022-04-05 22:07:54 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-64
2022-04-05 22:07:54 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-64
2022-04-05 22:07:54 [main] [32mINFO [m [SecurityST:698] Maintenance window is: * 12-26 * * * ? *
2022-04-05 22:07:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-f077c4d6 in namespace namespace-64
2022-04-05 22:07:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-64
2022-04-05 22:07:54 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f077c4d6 will have desired state: Ready
2022-04-05 22:09:08 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f077c4d6 is in desired state: Ready
2022-04-05 22:09:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1624989503-412443202 in namespace namespace-64
2022-04-05 22:09:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-64
2022-04-05 22:09:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1624989503-412443202 will have desired state: Ready
2022-04-05 22:09:09 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1624989503-412443202 is in desired state: Ready
2022-04-05 22:09:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1245841706-592251930 in namespace namespace-64
2022-04-05 22:09:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-64
2022-04-05 22:09:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1245841706-592251930 will have desired state: Ready
2022-04-05 22:09:10 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1245841706-592251930 is in desired state: Ready
2022-04-05 22:09:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1245841706-592251930 in namespace namespace-64
2022-04-05 22:09:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-64
2022-04-05 22:09:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1245841706-592251930 will have desired state: Ready
2022-04-05 22:09:10 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1245841706-592251930 is in desired state: Ready
2022-04-05 22:09:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-f077c4d6-kafka-clients in namespace namespace-64
2022-04-05 22:09:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-64
2022-04-05 22:09:10 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f077c4d6-kafka-clients will be ready
2022-04-05 22:09:12 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f077c4d6-kafka-clients is ready
2022-04-05 22:09:12 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 22:09:12 [main] [32mINFO [m [SecurityST:728] Annotate secret my-cluster-f077c4d6-cluster-ca-cert with secret force-renew annotation
2022-04-05 22:09:12 [main] [32mINFO [m [SecurityST:735] Wait until maintenance windows starts
2022-04-05 22:12:00 [main] [32mINFO [m [SecurityST:741] Maintenance window starts
2022-04-05 22:12:00 [main] [32mINFO [m [SecurityST:745] Wait until rolling update is triggered during maintenance window
2022-04-05 22:12:00 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-f077c4d6-kafka rolling update
2022-04-05 22:14:06 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-f077c4d6-kafka has been successfully rolled
2022-04-05 22:14:06 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-f077c4d6-kafka to be ready
2022-04-05 22:14:35 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f077c4d6 will have desired state: Ready
2022-04-05 22:14:35 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f077c4d6 is in desired state: Ready
2022-04-05 22:14:35 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-f077c4d6 is ready
2022-04-05 22:14:35 [main] [32mINFO [m [SecurityST:750] Checking consumed messages to pod:my-cluster-f077c4d6-kafka-clients-85d99c7b7-vqkxp
2022-04-05 22:14:35 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@391fefb6, messages=[], arguments=[--max-messages, 100, --topic, my-topic-1245841706-592251930, --bootstrap-server, my-cluster-f077c4d6-kafka-bootstrap.namespace-64.svc:9093, USER=my_user_1624989503_412443202], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-f077c4d6-kafka-clients-85d99c7b7-vqkxp', podNamespace='namespace-64', bootstrapServer='my-cluster-f077c4d6-kafka-bootstrap.namespace-64.svc:9093', topicName='my-topic-1245841706-592251930', maxMessages=100, kafkaUsername='my-user-1624989503-412443202', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@599026f2}
2022-04-05 22:14:35 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-f077c4d6-kafka-bootstrap.namespace-64.svc:9093:my-topic-1245841706-592251930 from pod my-cluster-f077c4d6-kafka-clients-85d99c7b7-vqkxp
2022-04-05 22:14:35 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f077c4d6-kafka-clients-85d99c7b7-vqkxp -n namespace-64 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-1245841706-592251930 --bootstrap-server my-cluster-f077c4d6-kafka-bootstrap.namespace-64.svc:9093 USER=my_user_1624989503_412443202
2022-04-05 22:14:39 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 22:14:39 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 22:14:39 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6dd134ca, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-2121436055, --group-instance-id, instance364808892, --topic, my-topic-1245841706-592251930, --bootstrap-server, my-cluster-f077c4d6-kafka-bootstrap.namespace-64.svc:9093, USER=my_user_1624989503_412443202], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-f077c4d6-kafka-clients-85d99c7b7-vqkxp', podNamespace='namespace-64', bootstrapServer='my-cluster-f077c4d6-kafka-bootstrap.namespace-64.svc:9093', topicName='my-topic-1245841706-592251930', maxMessages=100, kafkaUsername='my-user-1624989503-412443202', consumerGroupName='my-consumer-group-2121436055', consumerInstanceId='instance364808892', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@35ae333b}
2022-04-05 22:14:39 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-f077c4d6-kafka-bootstrap.namespace-64.svc:9093:my-topic-1245841706-592251930 from pod my-cluster-f077c4d6-kafka-clients-85d99c7b7-vqkxp
2022-04-05 22:14:39 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f077c4d6-kafka-clients-85d99c7b7-vqkxp -n namespace-64 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-2121436055 --group-instance-id instance364808892 --topic my-topic-1245841706-592251930 --bootstrap-server my-cluster-f077c4d6-kafka-bootstrap.namespace-64.svc:9093 USER=my_user_1624989503_412443202
2022-04-05 22:14:46 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 22:14:46 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 22:14:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 22:14:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCertRenewalInMaintenanceWindow
2022-04-05 22:14:46 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1245841706-592251930 in namespace namespace-64
2022-04-05 22:14:46 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-f077c4d6-kafka-clients in namespace namespace-64
2022-04-05 22:14:46 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1624989503-412443202 in namespace namespace-64
2022-04-05 22:14:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-f077c4d6 in namespace namespace-64
2022-04-05 22:14:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1245841706-592251930 in namespace namespace-64
2022-04-05 22:15:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 22:15:26 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-64 for test case:testCertRenewalInMaintenanceWindow
2022-04-05 22:15:31 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCertRenewalInMaintenanceWindow-FINISHED
2022-04-05 22:15:31 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 22:15:31 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 22:15:31 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testOwnerReferenceOfCASecrets-STARTED
2022-04-05 22:15:31 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 22:15:31 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-65 for test case:testOwnerReferenceOfCASecrets
2022-04-05 22:15:31 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-65
2022-04-05 22:15:32 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-65
2022-04-05 22:15:32 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-65
2022-04-05 22:15:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a05bc4ee in namespace namespace-65
2022-04-05 22:15:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-65
2022-04-05 22:15:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a05bc4ee will have desired state: Ready
2022-04-05 22:16:47 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a05bc4ee is in desired state: Ready
2022-04-05 22:16:47 [main] [32mINFO [m [SecurityST:1432] Listing all cluster CAs for my-cluster-a05bc4ee
2022-04-05 22:16:47 [main] [32mINFO [m [SecurityST:1436] Deleting Kafka:my-cluster-a05bc4ee
2022-04-05 22:16:47 [main] [32mINFO [m [KafkaUtils:399] Waiting for deletion of Kafka:my-cluster-a05bc4ee
2022-04-05 22:16:49 [main] [32mINFO [m [SecurityST:1440] Checking actual secrets after Kafka deletion
2022-04-05 22:16:49 [main] [32mINFO [m [SecurityST:1443] Checking that my-cluster-a05bc4ee-clients-ca secret is still present
2022-04-05 22:16:49 [main] [32mINFO [m [SecurityST:1446] Deleting secret: my-cluster-a05bc4ee-clients-ca
2022-04-05 22:16:49 [main] [32mINFO [m [SecurityST:1443] Checking that my-cluster-a05bc4ee-clients-ca-cert secret is still present
2022-04-05 22:16:49 [main] [32mINFO [m [SecurityST:1446] Deleting secret: my-cluster-a05bc4ee-clients-ca-cert
2022-04-05 22:16:49 [main] [32mINFO [m [SecurityST:1443] Checking that my-cluster-a05bc4ee-cluster-ca secret is still present
2022-04-05 22:16:49 [main] [32mINFO [m [SecurityST:1446] Deleting secret: my-cluster-a05bc4ee-cluster-ca
2022-04-05 22:16:49 [main] [32mINFO [m [SecurityST:1443] Checking that my-cluster-a05bc4ee-cluster-ca-cert secret is still present
2022-04-05 22:16:49 [main] [32mINFO [m [SecurityST:1446] Deleting secret: my-cluster-a05bc4ee-cluster-ca-cert
2022-04-05 22:16:49 [main] [32mINFO [m [SecurityST:1450] Deploying Kafka with generateSecretOwnerReference set to true
2022-04-05 22:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-second-cluster-my-cluster-a05bc4ee in namespace namespace-65
2022-04-05 22:16:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-65
2022-04-05 22:16:49 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-second-cluster-my-cluster-a05bc4ee will have desired state: Ready
2022-04-05 22:18:58 [main] [32mINFO [m [ResourceManager:444] Kafka: my-second-cluster-my-cluster-a05bc4ee is in desired state: Ready
2022-04-05 22:18:58 [main] [32mINFO [m [SecurityST:1465] Deleting Kafka:my-second-cluster-my-cluster-a05bc4ee
2022-04-05 22:18:58 [main] [32mINFO [m [KafkaUtils:399] Waiting for deletion of Kafka:my-second-cluster-my-cluster-a05bc4ee
2022-04-05 22:19:01 [main] [32mINFO [m [SecurityST:1469] Checking actual secrets after Kafka deletion
2022-04-05 22:19:01 [main] [32mINFO [m [SecurityST:1472] Checking that my-second-cluster-my-cluster-a05bc4ee-clients-ca secret is deleted
2022-04-05 22:19:01 [main] [32mINFO [m [SecurityST:1472] Checking that my-second-cluster-my-cluster-a05bc4ee-clients-ca-cert secret is deleted
2022-04-05 22:19:01 [main] [32mINFO [m [SecurityST:1472] Checking that my-second-cluster-my-cluster-a05bc4ee-cluster-ca secret is deleted
2022-04-05 22:19:01 [main] [32mINFO [m [SecurityST:1472] Checking that my-second-cluster-my-cluster-a05bc4ee-cluster-ca-cert secret is deleted
2022-04-05 22:19:01 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 22:19:01 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testOwnerReferenceOfCASecrets
2022-04-05 22:19:01 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-second-cluster-my-cluster-a05bc4ee in namespace namespace-65
2022-04-05 22:19:01 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a05bc4ee in namespace namespace-65
2022-04-05 22:19:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 22:19:01 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-65 for test case:testOwnerReferenceOfCASecrets
2022-04-05 22:19:44 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testOwnerReferenceOfCASecrets-FINISHED
2022-04-05 22:19:44 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 22:19:44 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 22:19:44 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoRenewClientsCaCertsTriggeredByAnno-STARTED
2022-04-05 22:19:44 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 22:19:44 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-66 for test case:testAutoRenewClientsCaCertsTriggeredByAnno
2022-04-05 22:19:44 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-66
2022-04-05 22:19:44 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-66
2022-04-05 22:19:44 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-66
2022-04-05 22:19:44 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-05 22:19:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-16f3ff76 in namespace namespace-66
2022-04-05 22:19:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-66
2022-04-05 22:19:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-16f3ff76 will have desired state: Ready
2022-04-05 22:22:38 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-16f3ff76 is in desired state: Ready
2022-04-05 22:22:38 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-10035731-2099923831 in namespace namespace-66
2022-04-05 22:22:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-66
2022-04-05 22:22:38 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-10035731-2099923831 will have desired state: Ready
2022-04-05 22:22:39 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-10035731-2099923831 is in desired state: Ready
2022-04-05 22:22:39 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2125439053-1324860056 in namespace namespace-66
2022-04-05 22:22:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-66
2022-04-05 22:22:39 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2125439053-1324860056 will have desired state: Ready
2022-04-05 22:22:40 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2125439053-1324860056 is in desired state: Ready
2022-04-05 22:22:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-16f3ff76-kafka-clients in namespace namespace-66
2022-04-05 22:22:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-66
2022-04-05 22:22:40 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-16f3ff76-kafka-clients will be ready
2022-04-05 22:22:43 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-16f3ff76-kafka-clients is ready
2022-04-05 22:22:43 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 22:22:43 [main] [32mINFO [m [SecurityST:260] Checking produced and consumed messages to pod:my-cluster-16f3ff76-kafka-clients-5bb9f44dc9-m9cnx
2022-04-05 22:22:43 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@69841810, messages=[], arguments=[--max-messages, 100, --topic, my-topic-2125439053-1324860056, --bootstrap-server, my-cluster-16f3ff76-kafka-bootstrap.namespace-66.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-16f3ff76-kafka-clients-5bb9f44dc9-m9cnx', podNamespace='namespace-66', bootstrapServer='my-cluster-16f3ff76-kafka-bootstrap.namespace-66.svc:9092', topicName='my-topic-2125439053-1324860056', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@783afb45}
2022-04-05 22:22:43 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-16f3ff76-kafka-bootstrap.namespace-66.svc:9092:my-topic-2125439053-1324860056 from pod my-cluster-16f3ff76-kafka-clients-5bb9f44dc9-m9cnx
2022-04-05 22:22:43 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-16f3ff76-kafka-clients-5bb9f44dc9-m9cnx -n namespace-66 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-2125439053-1324860056 --bootstrap-server my-cluster-16f3ff76-kafka-bootstrap.namespace-66.svc:9092
2022-04-05 22:22:45 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 22:22:45 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 22:22:45 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@21b4bc3, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-25165056, --group-instance-id, instance682068939, --topic, my-topic-2125439053-1324860056, --bootstrap-server, my-cluster-16f3ff76-kafka-bootstrap.namespace-66.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-16f3ff76-kafka-clients-5bb9f44dc9-m9cnx', podNamespace='namespace-66', bootstrapServer='my-cluster-16f3ff76-kafka-bootstrap.namespace-66.svc:9092', topicName='my-topic-2125439053-1324860056', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-25165056', consumerInstanceId='instance682068939', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2dd46def}
2022-04-05 22:22:45 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-16f3ff76-kafka-bootstrap.namespace-66.svc:9092#my-topic-2125439053-1324860056 from pod my-cluster-16f3ff76-kafka-clients-5bb9f44dc9-m9cnx
2022-04-05 22:22:45 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-16f3ff76-kafka-clients-5bb9f44dc9-m9cnx -n namespace-66 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-25165056 --group-instance-id instance682068939 --topic my-topic-2125439053-1324860056 --bootstrap-server my-cluster-16f3ff76-kafka-bootstrap.namespace-66.svc:9092
2022-04-05 22:22:51 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 22:22:51 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 22:22:51 [main] [32mINFO [m [SecurityST:274] Triggering CA cert renewal by adding the annotation
2022-04-05 22:22:51 [main] [32mINFO [m [SecurityST:286] Patching secret my-cluster-16f3ff76-clients-ca-cert with strimzi.io/force-renew
2022-04-05 22:22:51 [main] [32mINFO [m [SecurityST:295] Wait for kafka to rolling restart ...
2022-04-05 22:22:51 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-16f3ff76-kafka rolling update
2022-04-05 22:24:26 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-16f3ff76-kafka has been successfully rolled
2022-04-05 22:24:26 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-16f3ff76-kafka to be ready
2022-04-05 22:24:49 [main] [32mINFO [m [SecurityST:308] Checking the certificates have been replaced
2022-04-05 22:24:49 [main] [32mINFO [m [SecurityST:322] Checking consumed messages to pod:my-cluster-16f3ff76-kafka-clients-5bb9f44dc9-m9cnx
2022-04-05 22:24:49 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5b30a14d, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-186183660, --group-instance-id, instance884445730, --topic, my-topic-2125439053-1324860056, --bootstrap-server, my-cluster-16f3ff76-kafka-bootstrap.namespace-66.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-16f3ff76-kafka-clients-5bb9f44dc9-m9cnx', podNamespace='namespace-66', bootstrapServer='my-cluster-16f3ff76-kafka-bootstrap.namespace-66.svc:9092', topicName='my-topic-2125439053-1324860056', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-186183660', consumerInstanceId='instance884445730', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1c9c1188}
2022-04-05 22:24:49 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-16f3ff76-kafka-bootstrap.namespace-66.svc:9092#my-topic-2125439053-1324860056 from pod my-cluster-16f3ff76-kafka-clients-5bb9f44dc9-m9cnx
2022-04-05 22:24:49 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-16f3ff76-kafka-clients-5bb9f44dc9-m9cnx -n namespace-66 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-186183660 --group-instance-id instance884445730 --topic my-topic-2125439053-1324860056 --bootstrap-server my-cluster-16f3ff76-kafka-bootstrap.namespace-66.svc:9092
2022-04-05 22:24:55 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 22:24:55 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 22:24:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser bob-my-cluster-16f3ff76 in namespace namespace-66
2022-04-05 22:24:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-66
2022-04-05 22:24:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: bob-my-cluster-16f3ff76 will have desired state: Ready
2022-04-05 22:24:56 [main] [32mINFO [m [ResourceManager:444] KafkaUser: bob-my-cluster-16f3ff76 is in desired state: Ready
2022-04-05 22:24:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-16f3ff76-kafka-clients-tls in namespace namespace-66
2022-04-05 22:24:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-66
2022-04-05 22:24:56 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-16f3ff76-kafka-clients-tls will be ready
2022-04-05 22:24:58 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-16f3ff76-kafka-clients-tls is ready
2022-04-05 22:24:58 [main] [32mINFO [m [SecurityST:346] Checking consumed messages to pod:my-cluster-16f3ff76-kafka-clients-tls-85c7d8985d-8fqsn
2022-04-05 22:24:58 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7bfc70b7, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-2094333984, --group-instance-id, instance1765616662, --topic, my-topic-2125439053-1324860056, --bootstrap-server, my-cluster-16f3ff76-kafka-bootstrap.namespace-66.svc:9093, USER=bob_my_cluster_16f3ff76], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-16f3ff76-kafka-clients-tls-85c7d8985d-8fqsn', podNamespace='namespace-66', bootstrapServer='my-cluster-16f3ff76-kafka-bootstrap.namespace-66.svc:9093', topicName='my-topic-2125439053-1324860056', maxMessages=100, kafkaUsername='bob-my-cluster-16f3ff76', consumerGroupName='my-consumer-group-2094333984', consumerInstanceId='instance1765616662', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@790319c}
2022-04-05 22:24:58 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-16f3ff76-kafka-bootstrap.namespace-66.svc:9093#my-topic-2125439053-1324860056 from pod my-cluster-16f3ff76-kafka-clients-tls-85c7d8985d-8fqsn
2022-04-05 22:24:58 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-16f3ff76-kafka-clients-tls-85c7d8985d-8fqsn -n namespace-66 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-2094333984 --group-instance-id instance1765616662 --topic my-topic-2125439053-1324860056 --bootstrap-server my-cluster-16f3ff76-kafka-bootstrap.namespace-66.svc:9093 USER=bob_my_cluster_16f3ff76
2022-04-05 22:25:05 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 22:25:05 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 22:25:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 22:25:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoRenewClientsCaCertsTriggeredByAnno
2022-04-05 22:25:05 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-16f3ff76-kafka-clients in namespace namespace-66
2022-04-05 22:25:05 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-16f3ff76-kafka-clients-tls in namespace namespace-66
2022-04-05 22:25:05 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-16f3ff76 in namespace namespace-66
2022-04-05 22:25:05 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaUser bob-my-cluster-16f3ff76 in namespace namespace-66
2022-04-05 22:25:05 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-66, for cruise control Kafka cluster my-cluster-16f3ff76
2022-04-05 22:25:05 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2125439053-1324860056 in namespace namespace-66
2022-04-05 22:25:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-10035731-2099923831 in namespace namespace-66
2022-04-05 22:25:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 22:25:55 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-66 for test case:testAutoRenewClientsCaCertsTriggeredByAnno
2022-04-05 22:26:01 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoRenewClientsCaCertsTriggeredByAnno-FINISHED
2022-04-05 22:26:01 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 22:26:01 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 22:26:01 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno-STARTED
2022-04-05 22:26:01 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 22:26:01 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-67 for test case:testAutoReplaceClusterCaKeysTriggeredByAnno
2022-04-05 22:26:01 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-67
2022-04-05 22:26:01 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-67
2022-04-05 22:26:01 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-67
2022-04-05 22:26:01 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-05 22:26:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-29fe1156 in namespace namespace-67
2022-04-05 22:26:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-67
2022-04-05 22:26:01 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-29fe1156 will have desired state: Ready
2022-04-05 22:28:49 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-29fe1156 is in desired state: Ready
2022-04-05 22:28:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-842422978-1999127785 in namespace namespace-67
2022-04-05 22:28:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-67
2022-04-05 22:28:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-842422978-1999127785 will have desired state: Ready
2022-04-05 22:28:50 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-842422978-1999127785 is in desired state: Ready
2022-04-05 22:28:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1212476928-1565302800 in namespace namespace-67
2022-04-05 22:28:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-67
2022-04-05 22:28:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1212476928-1565302800 will have desired state: Ready
2022-04-05 22:28:51 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1212476928-1565302800 is in desired state: Ready
2022-04-05 22:28:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-29fe1156-kafka-clients in namespace namespace-67
2022-04-05 22:28:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-67
2022-04-05 22:28:51 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-29fe1156-kafka-clients will be ready
2022-04-05 22:28:53 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-29fe1156-kafka-clients is ready
2022-04-05 22:28:53 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 22:28:53 [main] [32mINFO [m [SecurityST:453] Checking produced and consumed messages to pod:my-cluster-29fe1156-kafka-clients-685847c57c-sdht6
2022-04-05 22:28:53 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5083963f, messages=[], arguments=[--max-messages, 100, --topic, my-topic-1212476928-1565302800, --bootstrap-server, my-cluster-29fe1156-kafka-bootstrap.namespace-67.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-29fe1156-kafka-clients-685847c57c-sdht6', podNamespace='namespace-67', bootstrapServer='my-cluster-29fe1156-kafka-bootstrap.namespace-67.svc:9092', topicName='my-topic-1212476928-1565302800', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7905d6da}
2022-04-05 22:28:53 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-29fe1156-kafka-bootstrap.namespace-67.svc:9092:my-topic-1212476928-1565302800 from pod my-cluster-29fe1156-kafka-clients-685847c57c-sdht6
2022-04-05 22:28:53 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-29fe1156-kafka-clients-685847c57c-sdht6 -n namespace-67 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-1212476928-1565302800 --bootstrap-server my-cluster-29fe1156-kafka-bootstrap.namespace-67.svc:9092
2022-04-05 22:28:56 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 22:28:56 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 22:28:56 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@8ab9280, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-638454098, --group-instance-id, instance1571806705, --topic, my-topic-1212476928-1565302800, --bootstrap-server, my-cluster-29fe1156-kafka-bootstrap.namespace-67.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-29fe1156-kafka-clients-685847c57c-sdht6', podNamespace='namespace-67', bootstrapServer='my-cluster-29fe1156-kafka-bootstrap.namespace-67.svc:9092', topicName='my-topic-1212476928-1565302800', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-638454098', consumerInstanceId='instance1571806705', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5fcf2ca5}
2022-04-05 22:28:56 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-29fe1156-kafka-bootstrap.namespace-67.svc:9092#my-topic-1212476928-1565302800 from pod my-cluster-29fe1156-kafka-clients-685847c57c-sdht6
2022-04-05 22:28:56 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-29fe1156-kafka-clients-685847c57c-sdht6 -n namespace-67 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-638454098 --group-instance-id instance1571806705 --topic my-topic-1212476928-1565302800 --bootstrap-server my-cluster-29fe1156-kafka-bootstrap.namespace-67.svc:9092
2022-04-05 22:29:02 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 22:29:02 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 22:29:02 [main] [32mINFO [m [SecurityST:467] Triggering CA cert renewal by adding the annotation
2022-04-05 22:29:02 [main] [32mINFO [m [SecurityST:479] Patching secret my-cluster-29fe1156-cluster-ca with strimzi.io/force-replace
2022-04-05 22:29:02 [main] [32mINFO [m [SecurityST:484] Wait for zk to rolling restart (1)...
2022-04-05 22:29:02 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-29fe1156-zookeeper rolling update
2022-04-05 22:30:37 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-29fe1156-zookeeper has been successfully rolled
2022-04-05 22:30:37 [main] [32mINFO [m [SecurityST:489] Wait for kafka to rolling restart (1)...
2022-04-05 22:30:37 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-29fe1156-kafka rolling update
2022-04-05 22:31:57 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-29fe1156-kafka has been successfully rolled
2022-04-05 22:31:57 [main] [32mINFO [m [SecurityST:494] Wait for EO to rolling restart (1)...
2022-04-05 22:31:57 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-29fe1156-entity-operator rolling update
2022-04-05 22:32:17 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-29fe1156-entity-operator will be ready
2022-04-05 22:37:49 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-29fe1156-entity-operator is ready
2022-04-05 22:37:59 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-29fe1156-entity-operator rolling update finished
2022-04-05 22:37:59 [main] [32mINFO [m [SecurityST:499] Wait for KafkaExporter and CruiseControl to rolling restart (1)...
2022-04-05 22:37:59 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-29fe1156-kafka-exporter rolling update
io.strimzi.test.WaitException: Timeout after 300000 ms waiting for Deployment my-cluster-29fe1156-kafka-exporter rolling update in namespace:namespace-67
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils.waitTillDepHasRolled(DeploymentUtils.java:137)
	at io.strimzi.systemtest.security.SecurityST.autoReplaceSomeKeysTriggeredByAnno(SecurityST.java:500)
	at io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno(SecurityST.java:373)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-05 22:42:59 [main] [1;31mERROR[m [TestExecutionWatcher:28] SecurityST - Exception Timeout after 300000 ms waiting for Deployment my-cluster-29fe1156-kafka-exporter rolling update in namespace:namespace-67 has been thrown in @Test. Going to collect logs from components.
2022-04-05 22:42:59 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-04-05 22:42:59 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-04-05 22:42:59 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-04-05 22:43:09 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-04-05 22:43:09 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-04-05 22:43:09 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-04-05 22:43:09 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-04-05 22:43:10 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-05 22:43:10 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace namespace-67
2022-04-05 22:43:10 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace namespace-67
2022-04-05 22:43:10 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace namespace-67
2022-04-05 22:43:13 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace namespace-67
2022-04-05 22:43:13 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace namespace-67
2022-04-05 22:43:13 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace namespace-67
2022-04-05 22:43:13 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace namespace-67
2022-04-05 22:43:13 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-05 22:43:14 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace security-st
2022-04-05 22:43:14 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace security-st
2022-04-05 22:43:14 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace security-st
2022-04-05 22:43:14 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace security-st
2022-04-05 22:43:14 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace security-st
2022-04-05 22:43:14 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace security-st
2022-04-05 22:43:14 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace security-st
2022-04-05 22:43:14 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-05 22:43:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 22:43:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoReplaceClusterCaKeysTriggeredByAnno
2022-04-05 22:43:14 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1212476928-1565302800 in namespace namespace-67
2022-04-05 22:43:14 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-29fe1156-kafka-clients in namespace namespace-67
2022-04-05 22:43:14 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-29fe1156 in namespace namespace-67
2022-04-05 22:43:14 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-842422978-1999127785 in namespace namespace-67
2022-04-05 22:43:14 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-67, for cruise control Kafka cluster my-cluster-29fe1156
2022-04-05 22:44:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 22:44:04 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-67 for test case:testAutoReplaceClusterCaKeysTriggeredByAnno
2022-04-05 22:44:11 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno-FINISHED
2022-04-05 22:44:11 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 22:44:11 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 22:44:11 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoReplaceAllCaKeysTriggeredByAnno-STARTED
2022-04-05 22:44:11 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 22:44:11 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-68 for test case:testAutoReplaceAllCaKeysTriggeredByAnno
2022-04-05 22:44:11 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-68
2022-04-05 22:44:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-68
2022-04-05 22:44:11 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-68
2022-04-05 22:44:11 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-05 22:44:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7633fa88 in namespace namespace-68
2022-04-05 22:44:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-68
2022-04-05 22:44:11 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7633fa88 will have desired state: Ready
2022-04-05 22:46:40 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7633fa88 is in desired state: Ready
2022-04-05 22:46:40 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1878789942-1975392300 in namespace namespace-68
2022-04-05 22:46:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-68
2022-04-05 22:46:40 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1878789942-1975392300 will have desired state: Ready
2022-04-05 22:46:41 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1878789942-1975392300 is in desired state: Ready
2022-04-05 22:46:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1386407766-2100102907 in namespace namespace-68
2022-04-05 22:46:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-68
2022-04-05 22:46:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1386407766-2100102907 will have desired state: Ready
2022-04-05 22:46:42 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1386407766-2100102907 is in desired state: Ready
2022-04-05 22:46:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-7633fa88-kafka-clients in namespace namespace-68
2022-04-05 22:46:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-68
2022-04-05 22:46:42 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7633fa88-kafka-clients will be ready
2022-04-05 22:46:44 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7633fa88-kafka-clients is ready
2022-04-05 22:46:44 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 22:46:44 [main] [32mINFO [m [SecurityST:453] Checking produced and consumed messages to pod:my-cluster-7633fa88-kafka-clients-59bdb9db5d-wxbpp
2022-04-05 22:46:44 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@30b0a94d, messages=[], arguments=[--max-messages, 100, --topic, my-topic-1386407766-2100102907, --bootstrap-server, my-cluster-7633fa88-kafka-bootstrap.namespace-68.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-7633fa88-kafka-clients-59bdb9db5d-wxbpp', podNamespace='namespace-68', bootstrapServer='my-cluster-7633fa88-kafka-bootstrap.namespace-68.svc:9092', topicName='my-topic-1386407766-2100102907', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@43f651ff}
2022-04-05 22:46:44 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-7633fa88-kafka-bootstrap.namespace-68.svc:9092:my-topic-1386407766-2100102907 from pod my-cluster-7633fa88-kafka-clients-59bdb9db5d-wxbpp
2022-04-05 22:46:44 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7633fa88-kafka-clients-59bdb9db5d-wxbpp -n namespace-68 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-1386407766-2100102907 --bootstrap-server my-cluster-7633fa88-kafka-bootstrap.namespace-68.svc:9092
2022-04-05 22:46:47 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 22:46:47 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 22:46:47 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7d779949, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1214404905, --group-instance-id, instance2112635303, --topic, my-topic-1386407766-2100102907, --bootstrap-server, my-cluster-7633fa88-kafka-bootstrap.namespace-68.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-7633fa88-kafka-clients-59bdb9db5d-wxbpp', podNamespace='namespace-68', bootstrapServer='my-cluster-7633fa88-kafka-bootstrap.namespace-68.svc:9092', topicName='my-topic-1386407766-2100102907', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1214404905', consumerInstanceId='instance2112635303', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@c7f5890}
2022-04-05 22:46:47 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-7633fa88-kafka-bootstrap.namespace-68.svc:9092#my-topic-1386407766-2100102907 from pod my-cluster-7633fa88-kafka-clients-59bdb9db5d-wxbpp
2022-04-05 22:46:47 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7633fa88-kafka-clients-59bdb9db5d-wxbpp -n namespace-68 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1214404905 --group-instance-id instance2112635303 --topic my-topic-1386407766-2100102907 --bootstrap-server my-cluster-7633fa88-kafka-bootstrap.namespace-68.svc:9092
2022-04-05 22:46:53 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 22:46:53 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 22:46:53 [main] [32mINFO [m [SecurityST:467] Triggering CA cert renewal by adding the annotation
2022-04-05 22:46:53 [main] [32mINFO [m [SecurityST:479] Patching secret my-cluster-7633fa88-cluster-ca with strimzi.io/force-replace
2022-04-05 22:46:53 [main] [32mINFO [m [SecurityST:479] Patching secret my-cluster-7633fa88-clients-ca with strimzi.io/force-replace
2022-04-05 22:46:53 [main] [32mINFO [m [SecurityST:484] Wait for zk to rolling restart (1)...
2022-04-05 22:46:53 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-7633fa88-zookeeper rolling update
2022-04-05 22:48:03 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-7633fa88-zookeeper has been successfully rolled
2022-04-05 22:48:03 [main] [32mINFO [m [SecurityST:489] Wait for kafka to rolling restart (1)...
2022-04-05 22:48:03 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-7633fa88-kafka rolling update
2022-04-05 22:49:38 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-7633fa88-kafka has been successfully rolled
2022-04-05 22:49:38 [main] [32mINFO [m [SecurityST:494] Wait for EO to rolling restart (1)...
2022-04-05 22:49:38 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-7633fa88-entity-operator rolling update
2022-04-05 22:50:03 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7633fa88-entity-operator will be ready
2022-04-05 22:50:46 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7633fa88-entity-operator is ready
2022-04-05 22:50:56 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-7633fa88-entity-operator rolling update finished
2022-04-05 22:50:56 [main] [32mINFO [m [SecurityST:499] Wait for KafkaExporter and CruiseControl to rolling restart (1)...
2022-04-05 22:50:56 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-7633fa88-kafka-exporter rolling update
2022-04-05 22:50:56 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7633fa88-kafka-exporter will be ready
2022-04-05 22:51:31 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7633fa88-kafka-exporter is ready
2022-04-05 22:51:41 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-7633fa88-kafka-exporter rolling update finished
2022-04-05 22:51:41 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-7633fa88-cruise-control rolling update
2022-04-05 22:51:41 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7633fa88-cruise-control will be ready
2022-04-05 22:51:57 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7633fa88-cruise-control is ready
2022-04-05 22:52:07 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-7633fa88-cruise-control rolling update finished
2022-04-05 22:52:07 [main] [32mINFO [m [SecurityST:505] Wait for zk to rolling restart (2)...
2022-04-05 22:52:07 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-7633fa88-zookeeper rolling update
2022-04-05 22:53:07 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-7633fa88-zookeeper has been successfully rolled
2022-04-05 22:53:07 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-7633fa88-zookeeper to be ready
2022-04-05 22:53:36 [main] [32mINFO [m [SecurityST:510] Wait for kafka to rolling restart (2)...
2022-04-05 22:53:36 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-7633fa88-kafka rolling update
2022-04-05 22:54:36 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-7633fa88-kafka has been successfully rolled
2022-04-05 22:54:36 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-7633fa88-kafka to be ready
2022-04-05 22:55:06 [main] [32mINFO [m [SecurityST:515] Wait for EO to rolling restart (2)...
2022-04-05 22:55:06 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-7633fa88-entity-operator rolling update
2022-04-05 22:55:06 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7633fa88-entity-operator will be ready
2022-04-05 22:55:55 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7633fa88-entity-operator is ready
2022-04-05 22:56:05 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-7633fa88-entity-operator rolling update finished
2022-04-05 22:56:05 [main] [32mINFO [m [SecurityST:520] Wait for KafkaExporter and CruiseControl to rolling restart (2)...
2022-04-05 22:56:05 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-7633fa88-kafka-exporter rolling update
2022-04-05 22:57:00 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7633fa88-kafka-exporter will be ready
2022-04-05 22:57:00 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7633fa88-kafka-exporter is ready
2022-04-05 22:57:10 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-7633fa88-kafka-exporter rolling update finished
2022-04-05 22:57:10 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-7633fa88-cruise-control rolling update
2022-04-05 22:57:10 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7633fa88-cruise-control will be ready
2022-04-05 22:57:10 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7633fa88-cruise-control is ready
2022-04-05 22:57:20 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-7633fa88-cruise-control rolling update finished
2022-04-05 22:57:20 [main] [32mINFO [m [SecurityST:525] Checking the certificates have been replaced
2022-04-05 22:57:20 [main] [32mINFO [m [SecurityST:536] Checking consumed messages to pod:my-cluster-7633fa88-kafka-clients-59bdb9db5d-wxbpp
2022-04-05 22:57:20 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@19906e5d, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1125265940, --group-instance-id, instance1543035283, --topic, my-topic-1386407766-2100102907, --bootstrap-server, my-cluster-7633fa88-kafka-bootstrap.namespace-68.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-7633fa88-kafka-clients-59bdb9db5d-wxbpp', podNamespace='namespace-68', bootstrapServer='my-cluster-7633fa88-kafka-bootstrap.namespace-68.svc:9092', topicName='my-topic-1386407766-2100102907', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1125265940', consumerInstanceId='instance1543035283', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@25dd01cf}
2022-04-05 22:57:20 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-7633fa88-kafka-bootstrap.namespace-68.svc:9092#my-topic-1386407766-2100102907 from pod my-cluster-7633fa88-kafka-clients-59bdb9db5d-wxbpp
2022-04-05 22:57:20 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7633fa88-kafka-clients-59bdb9db5d-wxbpp -n namespace-68 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1125265940 --group-instance-id instance1543035283 --topic my-topic-1386407766-2100102907 --bootstrap-server my-cluster-7633fa88-kafka-bootstrap.namespace-68.svc:9092
2022-04-05 22:57:26 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 22:57:26 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 22:57:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-36746209-731345123 in namespace namespace-68
2022-04-05 22:57:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-68
2022-04-05 22:57:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-36746209-731345123 will have desired state: Ready
2022-04-05 22:57:27 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-36746209-731345123 is in desired state: Ready
2022-04-05 22:57:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-7633fa88-kafka-clients-tls in namespace namespace-68
2022-04-05 22:57:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-68
2022-04-05 22:57:27 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7633fa88-kafka-clients-tls will be ready
2022-04-05 22:57:29 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7633fa88-kafka-clients-tls is ready
2022-04-05 22:57:29 [main] [32mINFO [m [SecurityST:561] Checking consumed messages to pod:my-cluster-7633fa88-kafka-clients-tls-b7fb9b4f-mwwn7
2022-04-05 22:57:29 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@22a990c3, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-854670041, --group-instance-id, instance928735024, --topic, my-topic-1386407766-2100102907, --bootstrap-server, my-cluster-7633fa88-kafka-bootstrap.namespace-68.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-7633fa88-kafka-clients-tls-b7fb9b4f-mwwn7', podNamespace='namespace-68', bootstrapServer='my-cluster-7633fa88-kafka-bootstrap.namespace-68.svc:9092', topicName='my-topic-1386407766-2100102907', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-854670041', consumerInstanceId='instance928735024', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6fb73783}
2022-04-05 22:57:29 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-7633fa88-kafka-bootstrap.namespace-68.svc:9092#my-topic-1386407766-2100102907 from pod my-cluster-7633fa88-kafka-clients-tls-b7fb9b4f-mwwn7
2022-04-05 22:57:29 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7633fa88-kafka-clients-tls-b7fb9b4f-mwwn7 -n namespace-68 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-854670041 --group-instance-id instance928735024 --topic my-topic-1386407766-2100102907 --bootstrap-server my-cluster-7633fa88-kafka-bootstrap.namespace-68.svc:9092
2022-04-05 22:57:35 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 22:57:35 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 22:57:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 22:57:35 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoReplaceAllCaKeysTriggeredByAnno
2022-04-05 22:57:35 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-7633fa88-kafka-clients in namespace namespace-68
2022-04-05 22:57:35 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7633fa88 in namespace namespace-68
2022-04-05 22:57:35 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-68, for cruise control Kafka cluster my-cluster-7633fa88
2022-04-05 22:57:35 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1878789942-1975392300 in namespace namespace-68
2022-04-05 22:57:35 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-36746209-731345123 in namespace namespace-68
2022-04-05 22:57:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-7633fa88-kafka-clients-tls in namespace namespace-68
2022-04-05 22:57:35 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1386407766-2100102907 in namespace namespace-68
2022-04-05 22:58:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 22:58:25 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-68 for test case:testAutoReplaceAllCaKeysTriggeredByAnno
2022-04-05 22:58:32 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoReplaceAllCaKeysTriggeredByAnno-FINISHED
2022-04-05 22:58:32 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 22:58:32 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 22:58:32 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testClusterCACertRenew-STARTED
2022-04-05 22:58:32 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 22:58:32 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-69 for test case:testClusterCACertRenew
2022-04-05 22:58:32 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-69
2022-04-05 22:58:32 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-69
2022-04-05 22:58:32 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-69
2022-04-05 22:58:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2751a6bd in namespace namespace-69
2022-04-05 22:58:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-69
2022-04-05 22:58:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2751a6bd will have desired state: Ready
2022-04-05 22:59:46 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2751a6bd is in desired state: Ready
2022-04-05 22:59:46 [main] [32mINFO [m [SecurityST:1512] Change of kafka validity and renewal days - reconciliation should start.
2022-04-05 22:59:46 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-2751a6bd-zookeeper rolling update
2022-04-05 23:00:41 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-2751a6bd-zookeeper has been successfully rolled
2022-04-05 23:00:41 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-2751a6bd-zookeeper to be ready
2022-04-05 23:01:09 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-2751a6bd-kafka rolling update
2022-04-05 23:02:14 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-2751a6bd-kafka has been successfully rolled
2022-04-05 23:02:14 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-2751a6bd-kafka to be ready
2022-04-05 23:02:43 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-2751a6bd-entity-operator rolling update
2022-04-05 23:02:43 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-2751a6bd-entity-operator will be ready
2022-04-05 23:04:34 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-2751a6bd-entity-operator is ready
2022-04-05 23:04:44 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-2751a6bd-entity-operator rolling update finished
2022-04-05 23:04:44 [main] [32mINFO [m [SecurityST:1545] Initial ClusterCA cert dates: Tue Apr 05 22:58:32 UTC 2022 --> Mon Apr 25 22:58:32 UTC 2022
2022-04-05 23:04:44 [main] [32mINFO [m [SecurityST:1546] Changed ClusterCA cert dates: Tue Apr 05 22:59:47 UTC 2022 --> Sat Oct 22 22:59:47 UTC 2022
2022-04-05 23:04:44 [main] [32mINFO [m [SecurityST:1547] KafkaBroker cert creation dates: Tue Apr 05 22:58:58 UTC 2022 --> Mon Apr 25 22:58:58 UTC 2022
2022-04-05 23:04:44 [main] [32mINFO [m [SecurityST:1548] KafkaBroker cert changed dates:  Tue Apr 05 23:01:00 UTC 2022 --> Sat Oct 22 23:01:00 UTC 2022
2022-04-05 23:04:44 [main] [32mINFO [m [SecurityST:1549] Zookeeper cert creation dates: Tue Apr 05 22:58:34 UTC 2022 --> Mon Apr 25 22:58:34 UTC 2022
2022-04-05 23:04:44 [main] [32mINFO [m [SecurityST:1550] Zookeeper cert changed dates:  Tue Apr 05 22:59:48 UTC 2022 --> Sat Oct 22 22:59:48 UTC 2022
2022-04-05 23:04:44 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 23:04:44 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testClusterCACertRenew
2022-04-05 23:04:44 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2751a6bd in namespace namespace-69
2022-04-05 23:04:54 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 23:04:54 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-69 for test case:testClusterCACertRenew
2022-04-05 23:05:37 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testClusterCACertRenew-FINISHED
2022-04-05 23:05:37 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 23:05:37 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 23:05:37 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testKafkaAndKafkaConnectTlsVersion-STARTED
2022-04-05 23:05:37 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 23:05:37 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-70 for test case:testKafkaAndKafkaConnectTlsVersion
2022-04-05 23:05:37 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-70
2022-04-05 23:05:37 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-70
2022-04-05 23:05:37 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-70
2022-04-05 23:05:37 [main] [32mINFO [m [SecurityST:1287] Deploying Kafka cluster with the support TLSv1.2 TLS
2022-04-05 23:05:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-67b6ff7d in namespace namespace-70
2022-04-05 23:05:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-70
2022-04-05 23:05:37 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-67b6ff7d will have desired state: Ready
2022-04-05 23:06:42 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-67b6ff7d is in desired state: Ready
2022-04-05 23:06:42 [main] [32mINFO [m [SecurityST:1299] Verifying that Kafka cluster has the accepted configuration:
ssl.enabled.protocols -> TLSv1.2
ssl.protocol -> TLSv1.3
2022-04-05 23:06:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-67b6ff7d-kafka-clients in namespace namespace-70
2022-04-05 23:06:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-70
2022-04-05 23:06:42 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-67b6ff7d-kafka-clients will be ready
2022-04-05 23:06:43 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-67b6ff7d-kafka-clients is ready
2022-04-05 23:06:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-67b6ff7d-scraper in namespace namespace-70
2022-04-05 23:06:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-70
2022-04-05 23:06:43 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-67b6ff7d-scraper will be ready
2022-04-05 23:06:44 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-67b6ff7d-scraper is ready
2022-04-05 23:06:44 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-67b6ff7d-scraper to be ready
2022-04-05 23:06:54 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-67b6ff7d-scraper is ready
2022-04-05 23:06:54 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-67b6ff7d-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-05 23:06:54 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-67b6ff7d-allow in namespace namespace-70
2022-04-05 23:06:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-70
2022-04-05 23:06:54 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-05 23:06:54 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-67b6ff7d in namespace namespace-70
2022-04-05 23:06:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-70
2022-04-05 23:06:54 [main] [32mINFO [m [SecurityST:1322] Verifying that Kafka Connect status is NotReady because of different TLS version
2022-04-05 23:06:54 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-67b6ff7d will have desired state: NotReady
2022-04-05 23:11:55 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-67b6ff7d is in desired state: NotReady
2022-04-05 23:11:55 [main] [32mINFO [m [SecurityST:1326] Replacing Kafka Connect config to the newest(TLSv1.2) one same as the Kafka broker has.
2022-04-05 23:11:55 [main] [32mINFO [m [SecurityST:1330] Verifying that Kafka Connect has the accepted configuration:
 ssl.enabled.protocols -> TLSv1.2
 ssl.protocol -> TLSv1.3
2022-04-05 23:11:55 [main] [32mINFO [m [KafkaConnectUtils:101] Waiting for Kafka Connect property ssl.enabled.protocols -> TLSv1.2 change
2022-04-05 23:11:55 [main] [32mINFO [m [KafkaConnectUtils:109] Kafka Connect property ssl.enabled.protocols -> TLSv1.2 change
2022-04-05 23:11:55 [main] [32mINFO [m [KafkaConnectUtils:101] Waiting for Kafka Connect property ssl.protocol -> TLSv1.3 change
2022-04-05 23:11:55 [main] [32mINFO [m [KafkaConnectUtils:109] Kafka Connect property ssl.protocol -> TLSv1.3 change
2022-04-05 23:11:55 [main] [32mINFO [m [SecurityST:1339] Verifying that Kafka Connect is stable
2022-04-05 23:11:55 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-67b6ff7d-connect are stable
2022-04-05 23:11:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 23:11:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 23:11:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 23:11:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 23:11:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 23:12:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 23:12:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 23:12:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 23:12:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 23:12:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 23:12:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 23:12:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 23:12:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 23:12:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 23:12:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 23:12:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 23:12:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 23:12:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 23:12:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 23:12:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 23:12:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 23:12:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 23:12:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 23:12:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 23:12:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 23:12:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 23:12:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 23:12:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 23:12:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 23:12:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 23:12:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 23:12:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 23:12:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 23:12:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 23:12:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 23:12:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 23:12:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 23:12:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 23:12:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 23:12:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 23:12:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 23:12:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 23:12:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 23:12:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 23:12:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 23:12:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 23:12:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 23:12:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 23:12:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 23:12:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 23:12:45 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-67b6ff7d-connect-6d58bc9c5d-p5df8
2022-04-05 23:12:45 [main] [32mINFO [m [SecurityST:1343] Verifying that Kafka Connect status is Ready because of same TLS version
2022-04-05 23:12:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-67b6ff7d will have desired state: Ready
2022-04-05 23:18:01 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-67b6ff7d is in desired state: Ready
2022-04-05 23:18:01 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 23:18:01 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaAndKafkaConnectTlsVersion
2022-04-05 23:18:01 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-67b6ff7d-scraper in namespace namespace-70
2022-04-05 23:18:02 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-67b6ff7d in namespace namespace-70
2022-04-05 23:18:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-67b6ff7d-kafka-clients in namespace namespace-70
2022-04-05 23:18:02 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-67b6ff7d-allow in namespace namespace-70
2022-04-05 23:18:02 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-67b6ff7d in namespace namespace-70
2022-04-05 23:19:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 23:19:02 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-70 for test case:testKafkaAndKafkaConnectTlsVersion
2022-04-05 23:19:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testKafkaAndKafkaConnectTlsVersion-FINISHED
2022-04-05 23:19:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 23:19:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 23:19:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testTlsHostnameVerificationWithKafkaConnect-STARTED
2022-04-05 23:19:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 23:19:07 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-71 for test case:testTlsHostnameVerificationWithKafkaConnect
2022-04-05 23:19:07 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-71
2022-04-05 23:19:07 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-71
2022-04-05 23:19:07 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-71
2022-04-05 23:19:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2b482e9e in namespace namespace-71
2022-04-05 23:19:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-71
2022-04-05 23:19:07 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2b482e9e will have desired state: Ready
2022-04-05 23:20:16 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2b482e9e is in desired state: Ready
2022-04-05 23:20:16 [main] [32mINFO [m [SecurityST:838] Getting IP of the bootstrap service
2022-04-05 23:20:16 [main] [32mINFO [m [SecurityST:842] KafkaConnect without config ssl.endpoint.identification.algorithm will not connect to 10.105.178.145:9093
2022-04-05 23:20:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-2b482e9e-kafka-clients in namespace namespace-71
2022-04-05 23:20:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-71
2022-04-05 23:20:16 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-2b482e9e-kafka-clients will be ready
2022-04-05 23:20:19 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-2b482e9e-kafka-clients is ready
2022-04-05 23:20:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-2b482e9e-scraper in namespace namespace-71
2022-04-05 23:20:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-71
2022-04-05 23:20:19 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-2b482e9e-scraper will be ready
2022-04-05 23:20:21 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-2b482e9e-scraper is ready
2022-04-05 23:20:21 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-2b482e9e-scraper to be ready
2022-04-05 23:20:31 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-2b482e9e-scraper is ready
2022-04-05 23:20:31 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-2b482e9e-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-05 23:20:31 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-2b482e9e-allow in namespace namespace-71
2022-04-05 23:20:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-71
2022-04-05 23:20:31 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-05 23:20:31 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-2b482e9e in namespace namespace-71
2022-04-05 23:20:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-71
2022-04-05 23:20:31 [main] [32mINFO [m [PodUtils:245] Wait until Pod my-cluster-2b482e9e-connect is present
2022-04-05 23:20:32 [main] [32mINFO [m [PodUtils:249] Pod my-cluster-2b482e9e-connect is present
2022-04-05 23:20:32 [main] [32mINFO [m [PodUtils:236] Wait until Pod my-cluster-2b482e9e-connect-f5b6897c7-nq4s2 is in CrashLoopBackOff state
2022-04-05 23:20:52 [main] [32mINFO [m [PodUtils:241] Pod my-cluster-2b482e9e-connect-f5b6897c7-nq4s2 is in CrashLoopBackOff state
2022-04-05 23:20:52 [main] [32mINFO [m [SecurityST:872] KafkaConnect with config ssl.endpoint.identification.algorithm will connect to 10.105.178.145:9093
2022-04-05 23:20:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-2b482e9e will have desired state: Ready
2022-04-05 23:26:37 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-2b482e9e is in desired state: Ready
2022-04-05 23:26:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 23:26:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTlsHostnameVerificationWithKafkaConnect
2022-04-05 23:26:37 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-2b482e9e-scraper in namespace namespace-71
2022-04-05 23:26:37 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-2b482e9e in namespace namespace-71
2022-04-05 23:26:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2b482e9e in namespace namespace-71
2022-04-05 23:26:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-2b482e9e-kafka-clients in namespace namespace-71
2022-04-05 23:26:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-2b482e9e-allow in namespace namespace-71
2022-04-05 23:27:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 23:27:17 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-71 for test case:testTlsHostnameVerificationWithKafkaConnect
2022-04-05 23:27:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testTlsHostnameVerificationWithKafkaConnect-FINISHED
2022-04-05 23:27:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 23:27:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 23:27:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testClientsCACertRenew-STARTED
2022-04-05 23:27:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 23:27:22 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-72 for test case:testClientsCACertRenew
2022-04-05 23:27:22 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-72
2022-04-05 23:27:22 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-72
2022-04-05 23:27:22 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-72
2022-04-05 23:27:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d0521360 in namespace namespace-72
2022-04-05 23:27:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-72
2022-04-05 23:27:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d0521360 will have desired state: Ready
2022-04-05 23:28:40 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d0521360 is in desired state: Ready
2022-04-05 23:28:40 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser strimzi-tls-user-1078534008 in namespace namespace-72
2022-04-05 23:28:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-72
2022-04-05 23:28:40 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: strimzi-tls-user-1078534008 will have desired state: Ready
2022-04-05 23:28:41 [main] [32mINFO [m [ResourceManager:444] KafkaUser: strimzi-tls-user-1078534008 is in desired state: Ready
2022-04-05 23:28:41 [main] [32mINFO [m [SecurityST:1596] Change of kafka validity and renewal days - reconciliation should start.
2022-04-05 23:28:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 50
2022-04-05 23:28:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 49
2022-04-05 23:28:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 48
2022-04-05 23:28:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 47
2022-04-05 23:28:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 46
2022-04-05 23:28:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 45
2022-04-05 23:28:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 44
2022-04-05 23:28:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 43
2022-04-05 23:28:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 42
2022-04-05 23:28:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 41
2022-04-05 23:28:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 40
2022-04-05 23:28:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 39
2022-04-05 23:28:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 38
2022-04-05 23:28:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 37
2022-04-05 23:28:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 36
2022-04-05 23:28:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 35
2022-04-05 23:28:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 34
2022-04-05 23:28:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 33
2022-04-05 23:28:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 32
2022-04-05 23:29:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 31
2022-04-05 23:29:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 30
2022-04-05 23:29:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 29
2022-04-05 23:29:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 28
2022-04-05 23:29:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 27
2022-04-05 23:29:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 26
2022-04-05 23:29:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 25
2022-04-05 23:29:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 24
2022-04-05 23:29:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 23
2022-04-05 23:29:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 22
2022-04-05 23:29:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 21
2022-04-05 23:29:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 20
2022-04-05 23:29:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 19
2022-04-05 23:29:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 18
2022-04-05 23:29:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 17
2022-04-05 23:29:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 16
2022-04-05 23:29:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 15
2022-04-05 23:29:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 14
2022-04-05 23:29:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 13
2022-04-05 23:29:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 12
2022-04-05 23:29:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 11
2022-04-05 23:29:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 10
2022-04-05 23:29:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 9
2022-04-05 23:29:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 8
2022-04-05 23:29:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 7
2022-04-05 23:29:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 6
2022-04-05 23:29:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 5
2022-04-05 23:29:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 4
2022-04-05 23:29:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 3
2022-04-05 23:29:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 2
2022-04-05 23:29:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 1
2022-04-05 23:29:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d0521360-zookeeper-0=900b5269-9b07-4818-b882-3302fe35d003, my-cluster-d0521360-zookeeper-2=e1cae54b-d1e1-411d-89fb-30d50c13981d, my-cluster-d0521360-zookeeper-1=aad622f6-1f84-4346-a3ce-7bdaaa6bbdf4} pods didn't roll. Remaining seconds for stability: 0
2022-04-05 23:29:31 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-d0521360-kafka rolling update
2022-04-05 23:29:56 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-d0521360-kafka has been successfully rolled
2022-04-05 23:29:56 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-d0521360-kafka to be ready
2022-04-05 23:30:23 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-d0521360-entity-operator rolling update
2022-04-05 23:30:28 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d0521360-entity-operator will be ready
2022-04-05 23:30:58 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d0521360-entity-operator is ready
2022-04-05 23:31:08 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-d0521360-entity-operator rolling update finished
2022-04-05 23:31:08 [main] [32mINFO [m [SecurityST:1624] Initial ClientsCA cert dates: Tue Apr 05 23:27:24 UTC 2022 --> Mon Apr 25 23:27:24 UTC 2022
2022-04-05 23:31:08 [main] [32mINFO [m [SecurityST:1625] Changed ClientsCA cert dates: Tue Apr 05 23:28:41 UTC 2022 --> Sat Oct 22 23:28:41 UTC 2022
2022-04-05 23:31:08 [main] [32mINFO [m [SecurityST:1626] Initial userCert dates: Tue Apr 05 23:28:40 UTC 2022 --> Mon Apr 25 23:28:40 UTC 2022
2022-04-05 23:31:08 [main] [32mINFO [m [SecurityST:1627] Changed userCert dates: Tue Apr 05 23:30:28 UTC 2022 --> Sat Oct 22 23:30:28 UTC 2022
2022-04-05 23:31:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 23:31:08 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testClientsCACertRenew
2022-04-05 23:31:08 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser strimzi-tls-user-1078534008 in namespace namespace-72
2022-04-05 23:31:08 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d0521360 in namespace namespace-72
2022-04-05 23:31:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 23:31:18 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-72 for test case:testClientsCACertRenew
2022-04-05 23:32:02 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testClientsCACertRenew-FINISHED
2022-04-05 23:32:02 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 23:32:02 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 23:32:02 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCertificates-STARTED
2022-04-05 23:32:02 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 23:32:02 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-73 for test case:testCertificates
2022-04-05 23:32:02 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-73
2022-04-05 23:32:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-73
2022-04-05 23:32:02 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-73
2022-04-05 23:32:02 [main] [32mINFO [m [SecurityST:118] Running testCertificates my-cluster-9237195f
2022-04-05 23:32:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-9237195f in namespace namespace-73
2022-04-05 23:32:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-73
2022-04-05 23:32:02 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-9237195f will have desired state: Ready
2022-04-05 23:33:20 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-9237195f is in desired state: Ready
2022-04-05 23:33:20 [main] [32mINFO [m [SecurityST:122] Check Kafka bootstrap certificate
2022-04-05 23:33:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-9237195f-kafka-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-9237195f-kafka-bootstrap:9093 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-9237195f-kafka-bootstrap
2022-04-05 23:33:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 23:33:23 [main] [32mINFO [m [SecurityST:125] OPENSSL OUTPUT: 

CONNECTED(00000003)
---
Certificate chain
 0 s:O = io.strimzi, CN = my-cluster-9237195f-kafka
   i:O = io.strimzi, CN = cluster-ca v0
-----BEGIN CERTIFICATE-----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-----END CERTIFICATE-----
 1 s:O = io.strimzi, CN = cluster-ca v0
   i:O = io.strimzi, CN = cluster-ca v0
-----BEGIN CERTIFICATE-----
MIIFLTCCAxWgAwIBAgIUKnVXtrXhIpNHuhbG+t8oEAYneAYwDQYJKoZIhvcNAQEN
BQAwLTETMBEGA1UECgwKaW8uc3RyaW16aTEWMBQGA1UEAwwNY2x1c3Rlci1jYSB2
MDAeFw0yMjA0MDUyMzMyMDJaFw0yMzA0MDUyMzMyMDJaMC0xEzARBgNVBAoMCmlv
LnN0cmltemkxFjAUBgNVBAMMDWNsdXN0ZXItY2EgdjAwggIiMA0GCSqGSIb3DQEB
AQUAA4ICDwAwggIKAoICAQDfkXLADRoKBmGFVCqB1zJYeBmQQ94Bciyi3ZxefwJ9
kjSnN62iXcRpRnSPKeNkL8ZIf8/Y6nfDVRboYt0aG/j4GkIPhV2Fxr0VhoHPv5C3
spdJRwl0DBIvgIExMF/ltUpJB2t1ItVQsyRCpqixyvhglNzXckPvQyIQt4hXCVSo
qlT39C7WZt49sXSkzFNGIUkWWeSLKB+7Zwbz0qrhiitvclYdJMzjdex1i1b6VbAk
HpsaAvx0Ak9wQyhtnb0jpZ2D+IHTlMVb1nHn5oDVV07kyx3HV2d2kXOaJRshM9ya
A3cNjargeBhQ5VIj49hLfY7vqob42+tuK9qyrBNoo5aUBvCpVCthWQO4aK75tBxk
ZWqxi8ndnpfDb5dLBjRZ3aRDunXlUAvYfCgj5ROCIiryjZvptewU3ouVfMhIe6wE
WqM6mOD8NiIaA/RAfyrUUnBsn7eLmkJwYryYLg7v61CQJ02E0wRqMlMSU4T496l/
2yeeKcPJ8j3FjsF/bcauCUVzHSxVFaO/I1IgdcqqzVqkGxdP+4mRmVFf3VOatqS9
wRWx8RAjVfNnmnLWihIn2vW5eor7H9l/kEp5fLCd7Oxwa5jbcEwK8BvtXHLAohR1
Lr0I6qzMPKECyds6bVUTYYky6bYdf3YM2jQQu3p+nr/WcCiLUaY/bRvE10C2ZqI3
PwIDAQABo0UwQzAdBgNVHQ4EFgQUZwiFeAVtLgik9KuUmwHTvBiAwIYwEgYDVR0T
AQH/BAgwBgEB/wIBADAOBgNVHQ8BAf8EBAMCAQYwDQYJKoZIhvcNAQENBQADggIB
AMjElA9CYFDJplZUr+3vsMoPkqfJlXkd47GEMTF6KO4yl3ns8T469uOq8cTt3XaD
5wOqsU0W9YFKcRUxTzgPcWrcIb7DcUvIDmo5MnoXIA1boQfwAp8igtsQM0jB45tw
K8183kf5R4wGlhHbQn05RSj3BZBHA7bOM0j755A035C8seNjIaY2wtCX4qVe7JMC
x+ZIkj0TR6fExhrjjmsvdDsVlsM1agF9/eRipQE0YA9T2DN5hQdXwQQDabWQDhdN
H1ujRxl5XgQj+I2c89z/E7dJcyjhTRPHlAfBAJi+JmajfZCzyKg9Oktp/+eW59oR
Yu+JFSQNjglLaMle8Af1K/NvCz+wLG23dhawe09M4qgUppigdvgvBMow48rRc/WH
ARXJJrMpX+QEP6spK7KsyXCB0rE0UUX7IYjwt1oc8RpeOtmp4YW1b08ICF3WbLbT
A1TzPy+/u3rIoDviTDy+hjIPG51Z5df7t3VtEaBOIb5OWRAQBwtZbxyT1nHmn+Qq
Knk4vnQt2GSrKtKADAMSDuThMjqMhTFQnlvXcDTvhgJ6eUntft3Vo8Bv62xzPJtG
HS16uyT3WaiJiG8XZzJ8NNDyavUgWmGC69ggW7+AZJWKm46WQl+2jgxE9Oia2F1m
fHtpfPbYOxcUTNa/DHZ4LNQ85WiMlhD8YW9s4o8jtDZv
-----END CERTIFICATE-----
---
Server certificate
subject=O = io.strimzi, CN = my-cluster-9237195f-kafka

issuer=O = io.strimzi, CN = cluster-ca v0

---
No client certificate CA names sent
Peer signing digest: SHA256
Peer signature type: RSA-PSS
Server Temp Key: X25519, 253 bits
---
SSL handshake has read 3489 bytes and written 369 bytes
Verification: OK
Verified peername: my-cluster-9237195f-kafka-bootstrap
---
New, TLSv1.3, Cipher is TLS_AES_256_GCM_SHA384
Server public key is 2048 bit
Secure Renegotiation IS NOT supported
Compression: NONE
Expansion: NONE
No ALPN negotiated
Early data was not sent
Verify return code: 0 (ok)
---



2022-04-05 23:33:23 [main] [32mINFO [m [SecurityST:128] Check zookeeper client certificate
2022-04-05 23:33:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-9237195f-kafka-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-9237195f-zookeeper-client:2181 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-9237195f-zookeeper-client -cert /opt/kafka/broker-certs/my-cluster-9237195f-kafka-0.crt -key /opt/kafka/broker-certs/my-cluster-9237195f-kafka-0.key
2022-04-05 23:33:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 23:33:23 [main] [32mINFO [m [SecurityST:139] Checking certificates for podId 0
2022-04-05 23:33:23 [main] [32mINFO [m [SecurityST:141] Check kafka certificate for port 9091
2022-04-05 23:33:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-9237195f-kafka-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-9237195f-kafka-0.my-cluster-9237195f-kafka-brokers:9091 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-9237195f-kafka-0.my-cluster-9237195f-kafka-brokers.namespace-73.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-9237195f-kafka-0.crt -key /opt/kafka/broker-certs/my-cluster-9237195f-kafka-0.key
2022-04-05 23:33:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 23:33:24 [main] [32mINFO [m [SecurityST:141] Check kafka certificate for port 9093
2022-04-05 23:33:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-9237195f-kafka-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-9237195f-kafka-0.my-cluster-9237195f-kafka-brokers:9093 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-9237195f-kafka-0.my-cluster-9237195f-kafka-brokers.namespace-73.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-9237195f-kafka-0.crt -key /opt/kafka/broker-certs/my-cluster-9237195f-kafka-0.key
2022-04-05 23:33:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 23:33:24 [main] [32mINFO [m [SecurityST:148] Check zookeeper certificate for port 2181
2022-04-05 23:33:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-9237195f-zookeeper-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-9237195f-zookeeper-0.my-cluster-9237195f-zookeeper-nodes:2181 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-9237195f-zookeeper-0.my-cluster-9237195f-zookeeper-nodes.namespace-73.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-9237195f-zookeeper-0.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-9237195f-zookeeper-0.key
2022-04-05 23:33:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 23:33:24 [main] [32mINFO [m [SecurityST:148] Check zookeeper certificate for port 3888
2022-04-05 23:33:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-9237195f-zookeeper-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-9237195f-zookeeper-0.my-cluster-9237195f-zookeeper-nodes:3888 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-9237195f-zookeeper-0.my-cluster-9237195f-zookeeper-nodes.namespace-73.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-9237195f-zookeeper-0.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-9237195f-zookeeper-0.key
2022-04-05 23:33:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 23:33:24 [main] [32mINFO [m [SecurityST:139] Checking certificates for podId 1
2022-04-05 23:33:24 [main] [32mINFO [m [SecurityST:141] Check kafka certificate for port 9091
2022-04-05 23:33:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-9237195f-kafka-1 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-9237195f-kafka-1.my-cluster-9237195f-kafka-brokers:9091 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-9237195f-kafka-1.my-cluster-9237195f-kafka-brokers.namespace-73.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-9237195f-kafka-1.crt -key /opt/kafka/broker-certs/my-cluster-9237195f-kafka-1.key
2022-04-05 23:33:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 23:33:24 [main] [32mINFO [m [SecurityST:141] Check kafka certificate for port 9093
2022-04-05 23:33:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-9237195f-kafka-1 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-9237195f-kafka-1.my-cluster-9237195f-kafka-brokers:9093 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-9237195f-kafka-1.my-cluster-9237195f-kafka-brokers.namespace-73.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-9237195f-kafka-1.crt -key /opt/kafka/broker-certs/my-cluster-9237195f-kafka-1.key
2022-04-05 23:33:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 23:33:25 [main] [32mINFO [m [SecurityST:148] Check zookeeper certificate for port 2181
2022-04-05 23:33:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-9237195f-zookeeper-1 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-9237195f-zookeeper-1.my-cluster-9237195f-zookeeper-nodes:2181 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-9237195f-zookeeper-1.my-cluster-9237195f-zookeeper-nodes.namespace-73.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-9237195f-zookeeper-1.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-9237195f-zookeeper-1.key
2022-04-05 23:33:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 23:33:25 [main] [32mINFO [m [SecurityST:148] Check zookeeper certificate for port 3888
2022-04-05 23:33:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-9237195f-zookeeper-1 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-9237195f-zookeeper-1.my-cluster-9237195f-zookeeper-nodes:3888 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-9237195f-zookeeper-1.my-cluster-9237195f-zookeeper-nodes.namespace-73.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-9237195f-zookeeper-1.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-9237195f-zookeeper-1.key
2022-04-05 23:33:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 23:33:25 [main] [32mINFO [m [SecurityST:139] Checking certificates for podId 2
2022-04-05 23:33:25 [main] [32mINFO [m [SecurityST:141] Check kafka certificate for port 9091
2022-04-05 23:33:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-9237195f-kafka-2 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-9237195f-kafka-2.my-cluster-9237195f-kafka-brokers:9091 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-9237195f-kafka-2.my-cluster-9237195f-kafka-brokers.namespace-73.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-9237195f-kafka-2.crt -key /opt/kafka/broker-certs/my-cluster-9237195f-kafka-2.key
2022-04-05 23:33:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 23:33:25 [main] [32mINFO [m [SecurityST:141] Check kafka certificate for port 9093
2022-04-05 23:33:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-9237195f-kafka-2 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-9237195f-kafka-2.my-cluster-9237195f-kafka-brokers:9093 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-9237195f-kafka-2.my-cluster-9237195f-kafka-brokers.namespace-73.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-9237195f-kafka-2.crt -key /opt/kafka/broker-certs/my-cluster-9237195f-kafka-2.key
2022-04-05 23:33:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 23:33:26 [main] [32mINFO [m [SecurityST:148] Check zookeeper certificate for port 2181
2022-04-05 23:33:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-9237195f-zookeeper-2 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-9237195f-zookeeper-2.my-cluster-9237195f-zookeeper-nodes:2181 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-9237195f-zookeeper-2.my-cluster-9237195f-zookeeper-nodes.namespace-73.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-9237195f-zookeeper-2.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-9237195f-zookeeper-2.key
2022-04-05 23:33:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 23:33:26 [main] [32mINFO [m [SecurityST:148] Check zookeeper certificate for port 3888
2022-04-05 23:33:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-9237195f-zookeeper-2 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-9237195f-zookeeper-2.my-cluster-9237195f-zookeeper-nodes:3888 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-9237195f-zookeeper-2.my-cluster-9237195f-zookeeper-nodes.namespace-73.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-9237195f-zookeeper-2.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-9237195f-zookeeper-2.key
2022-04-05 23:33:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 23:33:26 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 23:33:26 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCertificates
2022-04-05 23:33:26 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-9237195f in namespace namespace-73
2022-04-05 23:33:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 23:33:36 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-73 for test case:testCertificates
2022-04-05 23:34:19 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCertificates-FINISHED
2022-04-05 23:34:19 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 23:34:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 23:34:19 [main] [32mINFO [m [ResourceManager:346] In context SecurityST is everything deleted.
2022-04-05 23:34:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;31mERROR[m] Tests run: 18, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 9,941.184 s <<< FAILURE! - in io.strimzi.systemtest.security.SecurityST
[[1;31mERROR[m] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno(ExtensionContext)  Time elapsed: 1,090.102 s  <<< ERROR!
io.strimzi.test.WaitException: Timeout after 300000 ms waiting for Deployment my-cluster-29fe1156-kafka-exporter rolling update in namespace:namespace-67
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils.waitTillDepHasRolled(DeploymentUtils.java:137)
	at io.strimzi.systemtest.security.SecurityST.autoReplaceSomeKeysTriggeredByAnno(SecurityST.java:500)
	at io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno(SecurityST.java:373)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)

[[1;34mINFO[m] Running io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST
2022-04-05 23:34:25 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: alternative-reconcile-triggers-st
2022-04-05 23:34:25 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: alternative-reconcile-triggers-st
2022-04-05 23:34:25 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: alternative-reconcile-triggers-st
2022-04-05 23:34:25 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 23:34:25 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testManualRollingUpdateForSinglePod-STARTED
2022-04-05 23:34:25 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 23:34:25 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-74 for test case:testManualRollingUpdateForSinglePod
2022-04-05 23:34:25 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-74
2022-04-05 23:34:25 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-74
2022-04-05 23:34:25 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-74
2022-04-05 23:34:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-29fa8a4f in namespace namespace-74
2022-04-05 23:34:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-74
2022-04-05 23:34:25 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-29fa8a4f will have desired state: Ready
2022-04-05 23:35:44 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-29fa8a4f is in desired state: Ready
2022-04-05 23:35:44 [main] [32mINFO [m [AlternativeReconcileTriggersST:290] Trying to roll just single Kafka and single ZK pod
2022-04-05 23:35:44 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-29fa8a4f-kafka rolling update
2022-04-05 23:35:54 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-29fa8a4f-kafka has been successfully rolled
2022-04-05 23:35:54 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-29fa8a4f-kafka to be ready
2022-04-05 23:36:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-29fa8a4f will have desired state: Ready
2022-04-05 23:36:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-29fa8a4f is in desired state: Ready
2022-04-05 23:36:21 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-29fa8a4f is ready
2022-04-05 23:36:21 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-29fa8a4f-zookeeper rolling update
2022-04-05 23:36:31 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-29fa8a4f-zookeeper has been successfully rolled
2022-04-05 23:36:31 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-29fa8a4f-zookeeper to be ready
2022-04-05 23:37:01 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-29fa8a4f will have desired state: Ready
2022-04-05 23:37:02 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-29fa8a4f is in desired state: Ready
2022-04-05 23:37:02 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-29fa8a4f is ready
2022-04-05 23:37:02 [main] [32mINFO [m [AlternativeReconcileTriggersST:311] Adding anno to all ZK and Kafka pods
2022-04-05 23:37:02 [main] [32mINFO [m [AlternativeReconcileTriggersST:320] Checking if the rolling update will be successful for Kafka
2022-04-05 23:37:02 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-29fa8a4f-kafka rolling update
2022-04-05 23:38:57 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-29fa8a4f-kafka has been successfully rolled
2022-04-05 23:38:57 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-29fa8a4f-kafka to be ready
2022-04-05 23:39:29 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-29fa8a4f will have desired state: Ready
2022-04-05 23:39:29 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-29fa8a4f is in desired state: Ready
2022-04-05 23:39:29 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-29fa8a4f is ready
2022-04-05 23:39:29 [main] [32mINFO [m [AlternativeReconcileTriggersST:331] Checking if the rolling update will be successful for ZK
2022-04-05 23:39:29 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-29fa8a4f-zookeeper rolling update
2022-04-05 23:40:54 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-29fa8a4f-zookeeper has been successfully rolled
2022-04-05 23:40:54 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-29fa8a4f-zookeeper to be ready
2022-04-05 23:41:28 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-29fa8a4f will have desired state: Ready
2022-04-05 23:41:28 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-29fa8a4f is in desired state: Ready
2022-04-05 23:41:28 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-29fa8a4f is ready
2022-04-05 23:41:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 23:41:28 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testManualRollingUpdateForSinglePod
2022-04-05 23:41:28 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-29fa8a4f in namespace namespace-74
2022-04-05 23:41:38 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 23:41:38 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-74 for test case:testManualRollingUpdateForSinglePod
2022-04-05 23:42:21 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testManualRollingUpdateForSinglePod-FINISHED
2022-04-05 23:42:21 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 23:42:21 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 23:42:21 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testManualTriggeringRollingUpdate-STARTED
2022-04-05 23:42:21 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 23:42:21 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-75 for test case:testManualTriggeringRollingUpdate
2022-04-05 23:42:22 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-75
2022-04-05 23:42:22 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-75
2022-04-05 23:42:22 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-75
2022-04-05 23:42:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ddb6488f in namespace namespace-75
2022-04-05 23:42:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-05 23:42:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ddb6488f will have desired state: Ready
2022-04-05 23:44:13 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ddb6488f is in desired state: Ready
2022-04-05 23:44:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-358738625-1796968442 in namespace namespace-75
2022-04-05 23:44:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-05 23:44:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-358738625-1796968442 will have desired state: Ready
2022-04-05 23:44:14 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-358738625-1796968442 is in desired state: Ready
2022-04-05 23:44:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic continuous-topic in namespace namespace-75
2022-04-05 23:44:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-05 23:44:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: continuous-topic will have desired state: Ready
2022-04-05 23:44:15 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: continuous-topic is in desired state: Ready
2022-04-05 23:44:15 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 23:44:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-producer in namespace namespace-75
2022-04-05 23:44:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-05 23:44:15 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-producer will be in active state
2022-04-05 23:44:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-consumer in namespace namespace-75
2022-04-05 23:44:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-05 23:44:16 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-consumer will be in active state
2022-04-05 23:44:17 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-2074416072-1662612334 in namespace namespace-75
2022-04-05 23:44:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-05 23:44:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-2074416072-1662612334 will have desired state: Ready
2022-04-05 23:44:18 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-2074416072-1662612334 is in desired state: Ready
2022-04-05 23:44:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-ddb6488f-kafka-clients in namespace namespace-75
2022-04-05 23:44:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-05 23:44:28 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 23:44:28 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@53830d3f, messages=[], arguments=[--max-messages, 100, --topic, my-topic-358738625-1796968442, --bootstrap-server, my-cluster-ddb6488f-kafka-bootstrap.namespace-75.svc:9093, USER=my_user_2074416072_1662612334], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-ddb6488f-kafka-clients-566954985b-zvq9p', podNamespace='namespace-75', bootstrapServer='my-cluster-ddb6488f-kafka-bootstrap.namespace-75.svc:9093', topicName='my-topic-358738625-1796968442', maxMessages=100, kafkaUsername='my-user-2074416072-1662612334', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@b8b1661}
2022-04-05 23:44:28 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-ddb6488f-kafka-bootstrap.namespace-75.svc:9093:my-topic-358738625-1796968442 from pod my-cluster-ddb6488f-kafka-clients-566954985b-zvq9p
2022-04-05 23:44:28 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-ddb6488f-kafka-clients-566954985b-zvq9p -n namespace-75 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-358738625-1796968442 --bootstrap-server my-cluster-ddb6488f-kafka-bootstrap.namespace-75.svc:9093 USER=my_user_2074416072_1662612334
2022-04-05 23:44:32 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 23:44:32 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 23:44:32 [main] [32mINFO [m [AlternativeReconcileTriggersST:145] Annotate Kafka StatefulSet my-cluster-ddb6488f-kafka with manual rolling update annotation
2022-04-05 23:44:32 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-ddb6488f-kafka rolling update
2022-04-05 23:46:17 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-ddb6488f-kafka has been successfully rolled
2022-04-05 23:46:17 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-ddb6488f-kafka to be ready
2022-04-05 23:46:43 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ddb6488f will have desired state: Ready
2022-04-05 23:46:43 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ddb6488f is in desired state: Ready
2022-04-05 23:46:43 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-ddb6488f is ready
2022-04-05 23:46:43 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1f4177d0, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1368234763, --group-instance-id, instance62406363, --topic, my-topic-358738625-1796968442, --bootstrap-server, my-cluster-ddb6488f-kafka-bootstrap.namespace-75.svc:9093, USER=my_user_2074416072_1662612334], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-ddb6488f-kafka-clients-566954985b-zvq9p', podNamespace='namespace-75', bootstrapServer='my-cluster-ddb6488f-kafka-bootstrap.namespace-75.svc:9093', topicName='my-topic-358738625-1796968442', maxMessages=100, kafkaUsername='my-user-2074416072-1662612334', consumerGroupName='my-consumer-group-1368234763', consumerInstanceId='instance62406363', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@404acf73}
2022-04-05 23:46:43 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-ddb6488f-kafka-bootstrap.namespace-75.svc:9093:my-topic-358738625-1796968442 from pod my-cluster-ddb6488f-kafka-clients-566954985b-zvq9p
2022-04-05 23:46:43 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-ddb6488f-kafka-clients-566954985b-zvq9p -n namespace-75 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1368234763 --group-instance-id instance62406363 --topic my-topic-358738625-1796968442 --bootstrap-server my-cluster-ddb6488f-kafka-bootstrap.namespace-75.svc:9093 USER=my_user_2074416072_1662612334
2022-04-05 23:46:50 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 23:46:50 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 23:46:50 [main] [32mINFO [m [AlternativeReconcileTriggersST:166] Annotate Zookeeper StatefulSet my-cluster-ddb6488f-zookeeper with manual rolling update annotation
2022-04-05 23:46:50 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-ddb6488f-zookeeper rolling update
2022-04-05 23:47:50 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-ddb6488f-zookeeper has been successfully rolled
2022-04-05 23:47:50 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-ddb6488f-zookeeper to be ready
2022-04-05 23:48:16 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ddb6488f will have desired state: Ready
2022-04-05 23:48:16 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ddb6488f is in desired state: Ready
2022-04-05 23:48:16 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-ddb6488f is ready
2022-04-05 23:48:16 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@779f25cc, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-69066775, --group-instance-id, instance890289412, --topic, my-topic-358738625-1796968442, --bootstrap-server, my-cluster-ddb6488f-kafka-bootstrap.namespace-75.svc:9093, USER=my_user_2074416072_1662612334], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-ddb6488f-kafka-clients-566954985b-zvq9p', podNamespace='namespace-75', bootstrapServer='my-cluster-ddb6488f-kafka-bootstrap.namespace-75.svc:9093', topicName='my-topic-358738625-1796968442', maxMessages=100, kafkaUsername='my-user-2074416072-1662612334', consumerGroupName='my-consumer-group-69066775', consumerInstanceId='instance890289412', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@76971c60}
2022-04-05 23:48:16 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-ddb6488f-kafka-bootstrap.namespace-75.svc:9093:my-topic-358738625-1796968442 from pod my-cluster-ddb6488f-kafka-clients-566954985b-zvq9p
2022-04-05 23:48:16 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-ddb6488f-kafka-clients-566954985b-zvq9p -n namespace-75 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-69066775 --group-instance-id instance890289412 --topic my-topic-358738625-1796968442 --bootstrap-server my-cluster-ddb6488f-kafka-bootstrap.namespace-75.svc:9093 USER=my_user_2074416072_1662612334
2022-04-05 23:48:23 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 23:48:23 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 23:48:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-103014955-255766193 in namespace namespace-75
2022-04-05 23:48:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-05 23:48:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-103014955-255766193 will have desired state: Ready
2022-04-05 23:48:24 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-103014955-255766193 is in desired state: Ready
2022-04-05 23:48:24 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@552a1f90, messages=[], arguments=[--max-messages, 100, --topic, my-topic-103014955-255766193, --bootstrap-server, my-cluster-ddb6488f-kafka-bootstrap.namespace-75.svc:9093, USER=my_user_2074416072_1662612334], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-ddb6488f-kafka-clients-566954985b-zvq9p', podNamespace='namespace-75', bootstrapServer='my-cluster-ddb6488f-kafka-bootstrap.namespace-75.svc:9093', topicName='my-topic-103014955-255766193', maxMessages=100, kafkaUsername='my-user-2074416072-1662612334', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1b10748e}
2022-04-05 23:48:24 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-ddb6488f-kafka-bootstrap.namespace-75.svc:9093:my-topic-103014955-255766193 from pod my-cluster-ddb6488f-kafka-clients-566954985b-zvq9p
2022-04-05 23:48:24 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-ddb6488f-kafka-clients-566954985b-zvq9p -n namespace-75 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-103014955-255766193 --bootstrap-server my-cluster-ddb6488f-kafka-bootstrap.namespace-75.svc:9093 USER=my_user_2074416072_1662612334
2022-04-05 23:48:27 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 23:48:27 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 23:48:27 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@662e4149, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-164580070, --group-instance-id, instance1170778346, --topic, my-topic-103014955-255766193, --bootstrap-server, my-cluster-ddb6488f-kafka-bootstrap.namespace-75.svc:9093, USER=my_user_2074416072_1662612334], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-ddb6488f-kafka-clients-566954985b-zvq9p', podNamespace='namespace-75', bootstrapServer='my-cluster-ddb6488f-kafka-bootstrap.namespace-75.svc:9093', topicName='my-topic-103014955-255766193', maxMessages=100, kafkaUsername='my-user-2074416072-1662612334', consumerGroupName='my-consumer-group-164580070', consumerInstanceId='instance1170778346', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5b15e1bc}
2022-04-05 23:48:27 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-ddb6488f-kafka-bootstrap.namespace-75.svc:9093:my-topic-103014955-255766193 from pod my-cluster-ddb6488f-kafka-clients-566954985b-zvq9p
2022-04-05 23:48:27 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-ddb6488f-kafka-clients-566954985b-zvq9p -n namespace-75 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-164580070 --group-instance-id instance1170778346 --topic my-topic-103014955-255766193 --bootstrap-server my-cluster-ddb6488f-kafka-bootstrap.namespace-75.svc:9093 USER=my_user_2074416072_1662612334
2022-04-05 23:48:34 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 23:48:34 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 23:48:34 [main] [32mINFO [m [ClientUtils:61] Waiting till producer hello-world-producer and consumer hello-world-consumer finish
2022-04-05 23:53:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 23:53:00 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testManualTriggeringRollingUpdate
2022-04-05 23:53:00 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-2074416072-1662612334 in namespace namespace-75
2022-04-05 23:53:00 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-103014955-255766193 in namespace namespace-75
2022-04-05 23:53:00 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-consumer in namespace namespace-75
2022-04-05 23:53:00 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-ddb6488f-kafka-clients in namespace namespace-75
2022-04-05 23:53:00 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic continuous-topic in namespace namespace-75
2022-04-05 23:53:00 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-producer in namespace namespace-75
2022-04-05 23:53:00 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-358738625-1796968442 in namespace namespace-75
2022-04-05 23:53:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ddb6488f in namespace namespace-75
2022-04-05 23:53:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 23:53:50 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-75 for test case:testManualTriggeringRollingUpdate
2022-04-05 23:53:56 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testManualTriggeringRollingUpdate-FINISHED
2022-04-05 23:53:56 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 23:53:56 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 23:53:56 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testAddingAndRemovingJbodVolumes-STARTED
2022-04-05 23:53:56 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 23:53:56 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-76 for test case:testAddingAndRemovingJbodVolumes
2022-04-05 23:53:56 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-76
2022-04-05 23:53:56 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-76
2022-04-05 23:53:56 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-76
2022-04-05 23:53:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-929ceaa1 in namespace namespace-76
2022-04-05 23:53:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-05 23:53:56 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-929ceaa1 will have desired state: Ready
2022-04-05 23:55:08 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-929ceaa1 is in desired state: Ready
2022-04-05 23:55:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-275071481-74019389 in namespace namespace-76
2022-04-05 23:55:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-05 23:55:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-275071481-74019389 will have desired state: Ready
2022-04-05 23:55:09 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-275071481-74019389 is in desired state: Ready
2022-04-05 23:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic continuous-topic in namespace namespace-76
2022-04-05 23:55:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-05 23:55:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: continuous-topic will have desired state: Ready
2022-04-05 23:55:10 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: continuous-topic is in desired state: Ready
2022-04-05 23:55:10 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 23:55:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-producer in namespace namespace-76
2022-04-05 23:55:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-05 23:55:10 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-producer will be in active state
2022-04-05 23:55:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-consumer in namespace namespace-76
2022-04-05 23:55:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-05 23:55:11 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-consumer will be in active state
2022-04-05 23:55:12 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-584718972-1420953373 in namespace namespace-76
2022-04-05 23:55:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-05 23:55:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-584718972-1420953373 will have desired state: Ready
2022-04-05 23:55:13 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-584718972-1420953373 is in desired state: Ready
2022-04-05 23:55:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-929ceaa1-kafka-clients in namespace namespace-76
2022-04-05 23:55:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-05 23:55:23 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 23:55:23 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@67660f0f, messages=[], arguments=[--max-messages, 100, --topic, my-topic-275071481-74019389, --bootstrap-server, my-cluster-929ceaa1-kafka-bootstrap.namespace-76.svc:9093, USER=my_user_584718972_1420953373], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-929ceaa1-kafka-clients-cbb696955-lf4zv', podNamespace='namespace-76', bootstrapServer='my-cluster-929ceaa1-kafka-bootstrap.namespace-76.svc:9093', topicName='my-topic-275071481-74019389', maxMessages=100, kafkaUsername='my-user-584718972-1420953373', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@e557fb9}
2022-04-05 23:55:23 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-929ceaa1-kafka-bootstrap.namespace-76.svc:9093:my-topic-275071481-74019389 from pod my-cluster-929ceaa1-kafka-clients-cbb696955-lf4zv
2022-04-05 23:55:23 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-929ceaa1-kafka-clients-cbb696955-lf4zv -n namespace-76 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-275071481-74019389 --bootstrap-server my-cluster-929ceaa1-kafka-bootstrap.namespace-76.svc:9093 USER=my_user_584718972_1420953373
2022-04-05 23:55:27 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 23:55:27 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 23:55:27 [main] [32mINFO [m [AlternativeReconcileTriggersST:408] Add JBOD volume to the Kafka cluster my-cluster-929ceaa1-kafka
2022-04-05 23:55:27 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-929ceaa1-kafka rolling update
2022-04-05 23:56:37 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-929ceaa1-kafka has been successfully rolled
2022-04-05 23:56:37 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-929ceaa1-kafka to be ready
2022-04-05 23:57:04 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-929ceaa1 will have desired state: Ready
2022-04-05 23:57:04 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-929ceaa1 is in desired state: Ready
2022-04-05 23:57:04 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-929ceaa1 is ready
2022-04-05 23:57:04 [main] [32mINFO [m [AlternativeReconcileTriggersST:419] Remove JBOD volume to the Kafka cluster my-cluster-929ceaa1-kafka
2022-04-05 23:57:04 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-929ceaa1-kafka rolling update
2022-04-05 23:58:04 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-929ceaa1-kafka has been successfully rolled
2022-04-05 23:58:04 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-929ceaa1-kafka to be ready
2022-04-05 23:58:37 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-929ceaa1 will have desired state: Ready
2022-04-05 23:58:37 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-929ceaa1 is in desired state: Ready
2022-04-05 23:58:37 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-929ceaa1 is ready
2022-04-05 23:58:37 [main] [32mINFO [m [ClientUtils:61] Waiting till producer hello-world-producer and consumer hello-world-consumer finish
2022-04-06 00:03:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 00:03:58 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAddingAndRemovingJbodVolumes
2022-04-06 00:03:58 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-producer in namespace namespace-76
2022-04-06 00:03:58 [main] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-consumer in namespace namespace-76
2022-04-06 00:03:58 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-929ceaa1 in namespace namespace-76
2022-04-06 00:03:58 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-584718972-1420953373 in namespace namespace-76
2022-04-06 00:03:58 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-929ceaa1-kafka-clients in namespace namespace-76
2022-04-06 00:03:58 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-275071481-74019389 in namespace namespace-76
2022-04-06 00:03:58 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic continuous-topic in namespace namespace-76
2022-04-06 00:04:38 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 00:04:38 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-76 for test case:testAddingAndRemovingJbodVolumes
2022-04-06 00:04:49 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testAddingAndRemovingJbodVolumes-FINISHED
2022-04-06 00:04:49 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 00:04:49 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 00:04:49 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testTriggerRollingUpdateAfterOverrideBootstrap-STARTED
2022-04-06 00:04:49 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 00:04:49 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-77 for test case:testTriggerRollingUpdateAfterOverrideBootstrap
2022-04-06 00:04:49 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-77
2022-04-06 00:04:49 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-77
2022-04-06 00:04:49 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-77
2022-04-06 00:04:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b84003f8 in namespace namespace-77
2022-04-06 00:04:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-77
2022-04-06 00:04:49 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b84003f8 will have desired state: Ready
2022-04-06 00:06:43 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b84003f8 is in desired state: Ready
2022-04-06 00:06:43 [main] [32mINFO [m [AlternativeReconcileTriggersST:228] Adding new bootstrap dns: kafka-test.XXXX.azure.XXXX.net to external listeners
2022-04-06 00:06:43 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-b84003f8-kafka rolling update
2022-04-06 00:07:53 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-b84003f8-kafka has been successfully rolled
2022-04-06 00:07:53 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-b84003f8-kafka to be ready
2022-04-06 00:08:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b84003f8 will have desired state: Ready
2022-04-06 00:08:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b84003f8 is in desired state: Ready
2022-04-06 00:08:21 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-b84003f8 is ready
2022-04-06 00:08:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b84003f8 will have desired state: Ready
2022-04-06 00:08:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b84003f8 is in desired state: Ready
2022-04-06 00:08:21 [main] [32mINFO [m [AlternativeReconcileTriggersST:258] Encoding my-cluster-b84003f8-kafka-0.crt cert
2022-04-06 00:08:21 [main] [32mINFO [m [AlternativeReconcileTriggersST:263] Verifying that new DNS is in certificate subject alternative names
2022-04-06 00:08:21 [main] [32mINFO [m [AlternativeReconcileTriggersST:258] Encoding my-cluster-b84003f8-kafka-1.crt cert
2022-04-06 00:08:21 [main] [32mINFO [m [AlternativeReconcileTriggersST:263] Verifying that new DNS is in certificate subject alternative names
2022-04-06 00:08:21 [main] [32mINFO [m [AlternativeReconcileTriggersST:258] Encoding my-cluster-b84003f8-kafka-2.crt cert
2022-04-06 00:08:21 [main] [32mINFO [m [AlternativeReconcileTriggersST:263] Verifying that new DNS is in certificate subject alternative names
2022-04-06 00:08:21 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 00:08:21 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTriggerRollingUpdateAfterOverrideBootstrap
2022-04-06 00:08:21 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b84003f8 in namespace namespace-77
2022-04-06 00:08:31 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 00:08:31 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-77 for test case:testTriggerRollingUpdateAfterOverrideBootstrap
2022-04-06 00:08:36 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testTriggerRollingUpdateAfterOverrideBootstrap-FINISHED
2022-04-06 00:08:36 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 00:08:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 00:08:36 [main] [32mINFO [m [ResourceManager:346] In context AlternativeReconcileTriggersST is everything deleted.
2022-04-06 00:08:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2,057.033 s - in io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST
[[1;34mINFO[m] Running io.strimzi.systemtest.rollingupdate.RollingUpdateST
2022-04-06 00:08:42 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: rolling-update-st
2022-04-06 00:08:42 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: rolling-update-st
2022-04-06 00:08:42 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: rolling-update-st
2022-04-06 00:08:42 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 00:08:42 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testMetricsChange-STARTED
2022-04-06 00:08:42 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 00:08:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-173d8c6d in namespace rolling-update-st
2022-04-06 00:08:42 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-173d8c6d will have desired state: Ready
2022-04-06 00:10:42 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-173d8c6d is in desired state: Ready
2022-04-06 00:10:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-173d8c6d-kafka-clients in namespace rolling-update-st
2022-04-06 00:10:52 [main] [32mINFO [m [RollingUpdateST:755] Check if metrics are present in pod of Kafka and Zookeeper
2022-04-06 00:10:53 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.10 from Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s finished with return code: 0
2022-04-06 00:10:54 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.11 from Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s finished with return code: 0
2022-04-06 00:10:54 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.12 from Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s finished with return code: 0
2022-04-06 00:10:55 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.8 from Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s finished with return code: 0
2022-04-06 00:10:55 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.7 from Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s finished with return code: 0
2022-04-06 00:10:56 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.9 from Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s finished with return code: 0
2022-04-06 00:10:56 [main] [32mINFO [m [RollingUpdateST:765] Changing metrics to something else
2022-04-06 00:10:56 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-173d8c6d-zookeeper are stable
2022-04-06 00:10:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:10:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:10:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:10:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:10:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:10:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:10:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:10:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:10:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:10:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:10:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:10:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:11:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:11:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:11:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:11:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:11:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:11:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:11:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:11:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:11:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:11:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:11:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:11:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:11:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:11:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:11:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:11:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:11:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:11:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:11:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:11:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:11:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:11:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:11:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:11:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:11:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:11:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:11:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:11:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:11:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:11:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:11:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:11:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:11:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:11:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:11:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:11:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:11:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:11:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:11:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:11:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:11:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:11:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:11:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:11:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:11:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:11:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:11:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:11:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:11:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:11:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:11:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:11:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:11:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:11:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:11:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:11:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:11:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:11:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:11:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:11:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:11:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:11:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:11:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:11:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:11:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:11:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:11:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:11:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:11:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:11:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:11:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:11:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:11:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:11:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:11:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:11:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:11:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:11:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:11:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:11:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:11:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:11:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:11:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:11:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:11:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:11:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:11:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:11:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:11:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:11:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:11:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:11:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:11:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:11:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:11:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:11:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:11:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:11:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:11:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:11:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:11:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:11:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:11:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:11:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:11:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:11:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:11:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:11:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:11:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:11:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:11:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:11:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:11:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:11:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:11:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:11:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:11:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:11:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:11:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:11:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:11:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:11:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:11:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:11:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:11:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:11:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:11:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:11:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:11:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:11:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:11:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:11:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:11:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:11:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:11:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:11:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:11:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:11:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:11:45 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-173d8c6d-zookeeper-0 ,my-cluster-173d8c6d-zookeeper-1 ,my-cluster-173d8c6d-zookeeper-2
2022-04-06 00:11:45 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-173d8c6d-kafka are stable
2022-04-06 00:11:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:11:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:11:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:11:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:11:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:11:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:11:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:11:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:11:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:11:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:11:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:11:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:11:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:11:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:11:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:11:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:11:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:11:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:11:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:11:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:11:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:11:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:11:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:11:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:11:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:11:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:11:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:11:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:11:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:11:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:11:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:11:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:11:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:11:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:11:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:11:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:11:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:11:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:11:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:11:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:11:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:11:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:11:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:11:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:11:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:11:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:11:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:11:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:11:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:11:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:11:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:11:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:11:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:11:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:11:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:11:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:11:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:11:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:11:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:11:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:11:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:11:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:11:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:11:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:11:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:11:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:11:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:11:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:11:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:11:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:11:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:11:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:11:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:11:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:11:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:12:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:12:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:12:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:12:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:12:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:12:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:12:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:12:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:12:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:12:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:12:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:12:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:12:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:12:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:12:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:12:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:12:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:12:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:12:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:12:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:12:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:12:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:12:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:12:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:12:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:12:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:12:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:12:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:12:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:12:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:12:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:12:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:12:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:12:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:12:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:12:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:12:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:12:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:12:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:12:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:12:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:12:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:12:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:12:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:12:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:12:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:12:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:12:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:12:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:12:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:12:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:12:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:12:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:12:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:12:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:12:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:12:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:12:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:12:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:12:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:12:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:12:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:12:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:12:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:12:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:12:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:12:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:12:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:12:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:12:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:12:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:12:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:12:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:12:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:12:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:12:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:12:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:12:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:12:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:12:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:12:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:12:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:12:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:12:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:12:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:12:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:12:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:12:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:12:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:12:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:12:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:12:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:12:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:12:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:12:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:12:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:12:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:12:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:12:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:12:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:12:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:12:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:12:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:12:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:12:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:12:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:12:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:12:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:12:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:12:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:12:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:12:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:12:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:12:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:12:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:12:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:12:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:12:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:12:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:12:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:12:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:12:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:12:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:12:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:12:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:12:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:12:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:12:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:12:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:12:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:12:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:12:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:12:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:12:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:12:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:12:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:12:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:12:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:12:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:12:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:12:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:12:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:12:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:12:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:12:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:12:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:12:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:12:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:12:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:12:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:12:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:12:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:12:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:12:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:12:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:12:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:12:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:12:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:12:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:12:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:12:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:12:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:12:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:12:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:12:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:12:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:12:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:12:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:12:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:12:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:12:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:12:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:12:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:12:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:12:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:12:35 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-173d8c6d-kafka-0 ,my-cluster-173d8c6d-kafka-1 ,my-cluster-173d8c6d-kafka-2 ,my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s ,my-cluster-173d8c6d-kafka-exporter-7945c76cd8-dl7qt
2022-04-06 00:12:35 [main] [32mINFO [m [RollingUpdateST:800] Check if Kafka and Zookeeper pods didn't roll
2022-04-06 00:12:35 [main] [32mINFO [m [RollingUpdateST:804] Check if Kafka and Zookeeper metrics are changed
2022-04-06 00:12:35 [main] [32mINFO [m [RollingUpdateST:818] Check if metrics are present in pod of Kafka and Zookeeper
2022-04-06 00:12:35 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.10 from Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s finished with return code: 0
2022-04-06 00:12:36 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.11 from Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s finished with return code: 0
2022-04-06 00:12:36 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.12 from Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s finished with return code: 0
2022-04-06 00:12:36 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.8 from Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s finished with return code: 0
2022-04-06 00:12:37 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.7 from Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s finished with return code: 0
2022-04-06 00:12:37 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.9 from Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s finished with return code: 0
2022-04-06 00:12:37 [main] [32mINFO [m [RollingUpdateST:829] Removing metrics from Kafka and Zookeeper and setting them to null
2022-04-06 00:12:37 [main] [32mINFO [m [RollingUpdateST:836] Wait if Kafka and Zookeeper pods will roll
2022-04-06 00:12:37 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-173d8c6d-zookeeper rolling update
2022-04-06 00:13:47 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-173d8c6d-zookeeper has been successfully rolled
2022-04-06 00:13:47 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-173d8c6d-zookeeper to be ready
2022-04-06 00:14:11 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-173d8c6d-kafka rolling update
2022-04-06 00:15:16 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-173d8c6d-kafka has been successfully rolled
2022-04-06 00:15:16 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-173d8c6d-kafka to be ready
2022-04-06 00:15:48 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-173d8c6d will have desired state: Ready
2022-04-06 00:15:48 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-173d8c6d is in desired state: Ready
2022-04-06 00:15:48 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-173d8c6d is ready
2022-04-06 00:15:48 [main] [32mINFO [m [RollingUpdateST:840] Check if metrics are not existing in pods
2022-04-06 00:15:49 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.10 from Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s finished with return code: 7
2022-04-06 00:15:49 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.11 from Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s finished with return code: 7
2022-04-06 00:15:49 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.12 from Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s finished with return code: 7
2022-04-06 00:15:49 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.8 from Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s finished with return code: 7
2022-04-06 00:15:49 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.7 from Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s finished with return code: 7
2022-04-06 00:15:50 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.9 from Pod my-cluster-173d8c6d-kafka-clients-6b8696c455-f2p2s finished with return code: 7
2022-04-06 00:15:50 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 00:15:50 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMetricsChange
2022-04-06 00:15:50 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-173d8c6d-kafka-clients in namespace rolling-update-st
2022-04-06 00:15:50 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-173d8c6d in namespace rolling-update-st
2022-04-06 00:16:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 00:16:30 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testMetricsChange-FINISHED
2022-04-06 00:16:30 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 00:16:30 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 00:16:30 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testExternalLoggingChangeTriggerRollingUpdate-STARTED
2022-04-06 00:16:30 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 00:16:30 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-78 for test case:testExternalLoggingChangeTriggerRollingUpdate
2022-04-06 00:16:30 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-78
2022-04-06 00:16:30 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-78
2022-04-06 00:16:30 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-78
2022-04-06 00:16:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c3508bfc in namespace namespace-78
2022-04-06 00:16:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-78
2022-04-06 00:16:30 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c3508bfc will have desired state: Ready
2022-04-06 00:17:42 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c3508bfc is in desired state: Ready
2022-04-06 00:17:42 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-c3508bfc-zookeeper rolling update
2022-04-06 00:18:52 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-c3508bfc-zookeeper has been successfully rolled
2022-04-06 00:18:52 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-c3508bfc-zookeeper to be ready
2022-04-06 00:19:23 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-c3508bfc-kafka rolling update
2022-04-06 00:20:38 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-c3508bfc-kafka has been successfully rolled
2022-04-06 00:20:38 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-c3508bfc-kafka to be ready
2022-04-06 00:21:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c3508bfc will have desired state: Ready
2022-04-06 00:21:06 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c3508bfc is in desired state: Ready
2022-04-06 00:21:06 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-c3508bfc is ready
2022-04-06 00:21:06 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-c3508bfc-zookeeper rolling update
2022-04-06 00:22:36 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-c3508bfc-zookeeper has been successfully rolled
2022-04-06 00:22:36 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-c3508bfc-zookeeper to be ready
2022-04-06 00:23:05 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-c3508bfc-kafka rolling update
2022-04-06 00:24:25 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-c3508bfc-kafka has been successfully rolled
2022-04-06 00:24:25 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-c3508bfc-kafka to be ready
2022-04-06 00:24:52 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c3508bfc will have desired state: Ready
2022-04-06 00:24:52 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c3508bfc is in desired state: Ready
2022-04-06 00:24:52 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-c3508bfc is ready
2022-04-06 00:24:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 00:24:52 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testExternalLoggingChangeTriggerRollingUpdate
2022-04-06 00:24:52 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c3508bfc in namespace namespace-78
2022-04-06 00:25:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 00:25:02 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-78 for test case:testExternalLoggingChangeTriggerRollingUpdate
2022-04-06 00:25:45 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testExternalLoggingChangeTriggerRollingUpdate-FINISHED
2022-04-06 00:25:45 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 00:25:45 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 00:25:45 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testBrokerConfigurationChangeTriggerRollingUpdate-STARTED
2022-04-06 00:25:45 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 00:25:45 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-79 for test case:testBrokerConfigurationChangeTriggerRollingUpdate
2022-04-06 00:25:45 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-79
2022-04-06 00:25:45 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-79
2022-04-06 00:25:45 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-79
2022-04-06 00:25:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-4856108d in namespace namespace-79
2022-04-06 00:25:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-79
2022-04-06 00:25:45 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4856108d will have desired state: Ready
2022-04-06 00:27:56 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4856108d is in desired state: Ready
2022-04-06 00:27:56 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-4856108d-kafka rolling update
2022-04-06 00:29:06 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-4856108d-kafka has been successfully rolled
2022-04-06 00:29:06 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-4856108d-kafka to be ready
2022-04-06 00:29:35 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4856108d will have desired state: Ready
2022-04-06 00:29:35 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4856108d is in desired state: Ready
2022-04-06 00:29:35 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-4856108d is ready
2022-04-06 00:29:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 00:29:35 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBrokerConfigurationChangeTriggerRollingUpdate
2022-04-06 00:29:35 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-4856108d in namespace namespace-79
2022-04-06 00:29:45 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 00:29:45 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-79 for test case:testBrokerConfigurationChangeTriggerRollingUpdate
2022-04-06 00:30:28 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testBrokerConfigurationChangeTriggerRollingUpdate-FINISHED
2022-04-06 00:30:28 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 00:30:28 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 00:30:28 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testManualKafkaConfigMapChangeDontTriggerRollingUpdate-STARTED
2022-04-06 00:30:28 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 00:30:28 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-80 for test case:testManualKafkaConfigMapChangeDontTriggerRollingUpdate
2022-04-06 00:30:28 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-80
2022-04-06 00:30:28 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-80
2022-04-06 00:30:28 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-80
2022-04-06 00:30:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0d49a521 in namespace namespace-80
2022-04-06 00:30:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-80
2022-04-06 00:30:28 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0d49a521 will have desired state: Ready
2022-04-06 00:31:49 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0d49a521 is in desired state: Ready
2022-04-06 00:31:49 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-0d49a521 are stable
2022-04-06 00:31:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:31:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:31:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:31:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:31:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:31:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:31:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:31:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:31:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:31:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:31:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:31:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:31:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:31:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:31:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:31:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:31:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:31:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:31:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:31:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:31:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:31:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:31:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:31:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:31:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:31:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:31:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:31:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:31:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:31:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:31:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:31:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:31:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:31:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:31:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:31:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:31:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:31:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:31:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:31:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:31:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:31:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:31:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:31:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:31:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:31:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:31:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:31:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:31:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:31:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:31:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:31:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:31:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:31:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:31:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:31:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:31:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:31:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:31:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:31:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:31:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:31:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:31:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:31:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:31:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:31:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:31:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:31:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:31:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:31:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:31:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:31:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:31:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:31:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:31:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:31:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:31:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:32:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:32:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:32:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:32:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:32:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:32:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:32:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:32:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:32:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:32:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:32:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:32:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:32:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:32:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:32:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:32:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:32:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:32:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:32:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:32:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:32:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:32:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:32:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:32:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:32:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:32:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:32:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:32:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:32:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:32:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:32:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:32:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:32:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:32:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:32:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:32:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:32:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:32:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:32:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:32:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:32:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:32:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:32:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:32:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:32:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:32:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:32:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:32:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:32:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:32:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:32:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:32:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:32:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:32:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:32:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:32:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:32:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:32:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:32:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:32:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:32:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:32:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:32:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:32:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:32:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:32:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:32:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:32:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:32:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:32:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:32:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:32:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:32:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:32:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:32:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:32:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:32:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:32:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:32:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:32:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:32:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:32:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:32:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:32:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:32:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:32:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:32:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:32:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:32:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:32:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:32:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:32:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:32:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:32:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:32:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:32:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:32:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:32:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:32:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:32:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:32:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:32:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:32:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:32:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:32:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:32:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:32:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:32:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:32:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:32:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:32:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:32:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:32:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:32:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:32:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:32:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:32:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:32:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:32:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:32:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:32:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:32:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:32:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:32:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:32:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:32:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:32:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:32:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:32:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:32:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:32:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:32:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:32:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:32:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:32:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:32:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:32:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:32:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:32:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:32:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:32:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:32:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:32:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:32:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:32:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:32:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:32:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:32:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:32:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:32:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:32:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:32:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:32:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:32:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:32:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:32:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:32:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:32:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:32:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:32:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:32:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:32:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:32:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:32:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:32:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:32:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:32:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:32:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:32:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:32:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:32:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:32:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:32:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:32:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:32:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:32:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:32:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:32:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:32:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:32:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:32:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:32:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:32:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:32:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:32:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:32:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:32:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:32:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:32:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:32:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:32:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:32:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:32:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:32:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:32:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:32:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:32:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:32:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:32:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:32:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:32:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:32:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:32:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:32:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:32:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:32:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:32:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:32:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:32:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:32:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:32:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:32:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:32:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:32:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:32:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:32:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:32:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:32:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:32:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:32:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:32:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:32:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:32:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:32:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:32:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:32:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:32:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:32:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:32:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:32:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:32:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:32:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:32:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:32:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:32:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:32:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:32:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:32:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:32:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:32:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:32:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:32:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:32:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:32:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:32:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:32:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:32:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:32:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:32:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:32:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:32:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:32:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:32:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:32:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:32:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:32:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:32:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:32:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:32:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:32:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:32:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:32:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:32:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:32:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:32:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:32:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:32:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:32:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:32:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:32:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:32:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:32:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:32:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0d49a521-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:32:39 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-0d49a521-entity-operator-7dc9db8968-gh482 ,my-cluster-0d49a521-kafka-0 ,my-cluster-0d49a521-kafka-1 ,my-cluster-0d49a521-kafka-2 ,my-cluster-0d49a521-zookeeper-0 ,my-cluster-0d49a521-zookeeper-1 ,my-cluster-0d49a521-zookeeper-2
2022-04-06 00:32:39 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 00:32:39 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testManualKafkaConfigMapChangeDontTriggerRollingUpdate
2022-04-06 00:32:39 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0d49a521 in namespace namespace-80
2022-04-06 00:32:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 00:32:49 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-80 for test case:testManualKafkaConfigMapChangeDontTriggerRollingUpdate
2022-04-06 00:33:32 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testManualKafkaConfigMapChangeDontTriggerRollingUpdate-FINISHED
2022-04-06 00:33:32 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 00:33:32 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 00:33:32 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testZookeeperScaleUpScaleDown-STARTED
2022-04-06 00:33:32 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 00:33:32 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-81 for test case:testZookeeperScaleUpScaleDown
2022-04-06 00:33:32 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-81
2022-04-06 00:33:32 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-81
2022-04-06 00:33:32 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-81
2022-04-06 00:33:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2d6fd136 in namespace namespace-81
2022-04-06 00:33:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-81
2022-04-06 00:33:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2d6fd136 will have desired state: Ready
2022-04-06 00:35:28 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2d6fd136 is in desired state: Ready
2022-04-06 00:35:28 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1293339117-830442571 in namespace namespace-81
2022-04-06 00:35:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-81
2022-04-06 00:35:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1293339117-830442571 will have desired state: Ready
2022-04-06 00:35:29 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1293339117-830442571 is in desired state: Ready
2022-04-06 00:35:29 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-882165826-336528684 in namespace namespace-81
2022-04-06 00:35:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-81
2022-04-06 00:35:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-882165826-336528684 will have desired state: Ready
2022-04-06 00:35:30 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-882165826-336528684 is in desired state: Ready
2022-04-06 00:35:30 [main] [32mINFO [m [RollingUpdateST:398] Running zookeeperScaleUpScaleDown with cluster my-cluster-2d6fd136
2022-04-06 00:35:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-2d6fd136-kafka-clients in namespace namespace-81
2022-04-06 00:35:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-81
2022-04-06 00:35:40 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 00:35:40 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@4124e55c, messages=[], arguments=[--max-messages, 100, --topic, my-topic-1293339117-830442571, --bootstrap-server, my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093, USER=my_user_882165826_336528684], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-2d6fd136-kafka-clients-54fcbf7699-7xgws', podNamespace='namespace-81', bootstrapServer='my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-1293339117-830442571', maxMessages=100, kafkaUsername='my-user-882165826-336528684', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6fe51a7f}
2022-04-06 00:35:40 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093:my-topic-1293339117-830442571 from pod my-cluster-2d6fd136-kafka-clients-54fcbf7699-7xgws
2022-04-06 00:35:40 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2d6fd136-kafka-clients-54fcbf7699-7xgws -n namespace-81 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-1293339117-830442571 --bootstrap-server my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093 USER=my_user_882165826_336528684
2022-04-06 00:35:44 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 00:35:44 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-06 00:35:44 [main] [32mINFO [m [RollingUpdateST:426] Scale up Zookeeper to 7
2022-04-06 00:35:44 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@54861668, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-564815599, --group-instance-id, instance1088912877, --topic, my-topic-1293339117-830442571, --bootstrap-server, my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093, USER=my_user_882165826_336528684], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-2d6fd136-kafka-clients-54fcbf7699-7xgws', podNamespace='namespace-81', bootstrapServer='my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-1293339117-830442571', maxMessages=100, kafkaUsername='my-user-882165826-336528684', consumerGroupName='my-consumer-group-564815599', consumerInstanceId='instance1088912877', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@61b629de}
2022-04-06 00:35:44 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093:my-topic-1293339117-830442571 from pod my-cluster-2d6fd136-kafka-clients-54fcbf7699-7xgws
2022-04-06 00:35:44 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2d6fd136-kafka-clients-54fcbf7699-7xgws -n namespace-81 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-564815599 --group-instance-id instance1088912877 --topic my-topic-1293339117-830442571 --bootstrap-server my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093 USER=my_user_882165826_336528684
2022-04-06 00:35:51 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 00:35:51 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 00:35:51 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 7 Pod(s) of my-cluster-2d6fd136-zookeeper to be ready
2022-04-06 00:38:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2d6fd136 will have desired state: Ready
2022-04-06 00:38:06 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2d6fd136 is in desired state: Ready
2022-04-06 00:38:06 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-2d6fd136 is ready
2022-04-06 00:38:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-2d6fd136-zookeeper-0 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-06 00:38:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 00:38:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-2d6fd136-zookeeper-1 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-06 00:38:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 00:38:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-2d6fd136-zookeeper-2 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-06 00:38:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 00:38:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-2d6fd136-zookeeper-3 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-06 00:38:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 00:38:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-2d6fd136-zookeeper-4 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-06 00:38:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 00:38:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-2d6fd136-zookeeper-5 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-06 00:38:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 00:38:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-2d6fd136-zookeeper-6 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-06 00:38:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 00:38:07 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@60c915d8, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1668177941, --group-instance-id, instance1323369122, --topic, my-topic-1293339117-830442571, --bootstrap-server, my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093, USER=my_user_882165826_336528684], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-2d6fd136-kafka-clients-54fcbf7699-7xgws', podNamespace='namespace-81', bootstrapServer='my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-1293339117-830442571', maxMessages=100, kafkaUsername='my-user-882165826-336528684', consumerGroupName='my-consumer-group-1668177941', consumerInstanceId='instance1323369122', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@30fe9c58}
2022-04-06 00:38:07 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093:my-topic-1293339117-830442571 from pod my-cluster-2d6fd136-kafka-clients-54fcbf7699-7xgws
2022-04-06 00:38:07 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2d6fd136-kafka-clients-54fcbf7699-7xgws -n namespace-81 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1668177941 --group-instance-id instance1323369122 --topic my-topic-1293339117-830442571 --bootstrap-server my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093 USER=my_user_882165826_336528684
2022-04-06 00:38:14 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 00:38:14 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 00:38:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-772352181-39577610 in namespace namespace-81
2022-04-06 00:38:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-81
2022-04-06 00:38:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-772352181-39577610 will have desired state: Ready
2022-04-06 00:38:15 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-772352181-39577610 is in desired state: Ready
2022-04-06 00:38:15 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@fcca8ce, messages=[], arguments=[--max-messages, 100, --topic, my-topic-772352181-39577610, --bootstrap-server, my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093, USER=my_user_882165826_336528684], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-2d6fd136-kafka-clients-54fcbf7699-7xgws', podNamespace='namespace-81', bootstrapServer='my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-772352181-39577610', maxMessages=100, kafkaUsername='my-user-882165826-336528684', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@213d33f2}
2022-04-06 00:38:15 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093:my-topic-772352181-39577610 from pod my-cluster-2d6fd136-kafka-clients-54fcbf7699-7xgws
2022-04-06 00:38:15 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2d6fd136-kafka-clients-54fcbf7699-7xgws -n namespace-81 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-772352181-39577610 --bootstrap-server my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093 USER=my_user_882165826_336528684
2022-04-06 00:38:18 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 00:38:18 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-06 00:38:18 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@635b425c, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-716979616, --group-instance-id, instance1712289400, --topic, my-topic-772352181-39577610, --bootstrap-server, my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093, USER=my_user_882165826_336528684], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-2d6fd136-kafka-clients-54fcbf7699-7xgws', podNamespace='namespace-81', bootstrapServer='my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-772352181-39577610', maxMessages=100, kafkaUsername='my-user-882165826-336528684', consumerGroupName='my-consumer-group-716979616', consumerInstanceId='instance1712289400', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4b14f933}
2022-04-06 00:38:18 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093:my-topic-772352181-39577610 from pod my-cluster-2d6fd136-kafka-clients-54fcbf7699-7xgws
2022-04-06 00:38:18 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2d6fd136-kafka-clients-54fcbf7699-7xgws -n namespace-81 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-716979616 --group-instance-id instance1712289400 --topic my-topic-772352181-39577610 --bootstrap-server my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093 USER=my_user_882165826_336528684
2022-04-06 00:38:25 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 00:38:25 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 00:38:25 [main] [32mINFO [m [RollingUpdateST:453] Scale down Zookeeper to 3
2022-04-06 00:38:25 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-2d6fd136-zookeeper to be ready
2022-04-06 00:38:54 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2d6fd136 will have desired state: Ready
2022-04-06 00:38:54 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2d6fd136 is in desired state: Ready
2022-04-06 00:38:54 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-2d6fd136 is ready
2022-04-06 00:38:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-2d6fd136-zookeeper-0 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-06 00:38:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 00:38:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-2d6fd136-zookeeper-1 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-06 00:38:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 00:38:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-2d6fd136-zookeeper-2 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-06 00:38:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 00:38:55 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2de0bc6e, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-781044513, --group-instance-id, instance118434668, --topic, my-topic-772352181-39577610, --bootstrap-server, my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093, USER=my_user_882165826_336528684], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-2d6fd136-kafka-clients-54fcbf7699-7xgws', podNamespace='namespace-81', bootstrapServer='my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-772352181-39577610', maxMessages=100, kafkaUsername='my-user-882165826-336528684', consumerGroupName='my-consumer-group-781044513', consumerInstanceId='instance118434668', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@41d11806}
2022-04-06 00:38:55 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093:my-topic-772352181-39577610 from pod my-cluster-2d6fd136-kafka-clients-54fcbf7699-7xgws
2022-04-06 00:38:55 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2d6fd136-kafka-clients-54fcbf7699-7xgws -n namespace-81 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-781044513 --group-instance-id instance118434668 --topic my-topic-772352181-39577610 --bootstrap-server my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093 USER=my_user_882165826_336528684
2022-04-06 00:39:02 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 00:39:02 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 00:39:02 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1532242959-561299973 in namespace namespace-81
2022-04-06 00:39:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-81
2022-04-06 00:39:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1532242959-561299973 will have desired state: Ready
2022-04-06 00:39:03 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1532242959-561299973 is in desired state: Ready
2022-04-06 00:39:03 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@357bf5b7, messages=[], arguments=[--max-messages, 100, --topic, my-topic-1532242959-561299973, --bootstrap-server, my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093, USER=my_user_882165826_336528684], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-2d6fd136-kafka-clients-54fcbf7699-7xgws', podNamespace='namespace-81', bootstrapServer='my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-1532242959-561299973', maxMessages=100, kafkaUsername='my-user-882165826-336528684', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1410522c}
2022-04-06 00:39:03 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093:my-topic-1532242959-561299973 from pod my-cluster-2d6fd136-kafka-clients-54fcbf7699-7xgws
2022-04-06 00:39:03 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2d6fd136-kafka-clients-54fcbf7699-7xgws -n namespace-81 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-1532242959-561299973 --bootstrap-server my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093 USER=my_user_882165826_336528684
2022-04-06 00:39:06 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 00:39:06 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-06 00:39:06 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@54080a10, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1530656579, --group-instance-id, instance652516066, --topic, my-topic-1532242959-561299973, --bootstrap-server, my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093, USER=my_user_882165826_336528684], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-2d6fd136-kafka-clients-54fcbf7699-7xgws', podNamespace='namespace-81', bootstrapServer='my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-1532242959-561299973', maxMessages=100, kafkaUsername='my-user-882165826-336528684', consumerGroupName='my-consumer-group-1530656579', consumerInstanceId='instance652516066', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7c23ca36}
2022-04-06 00:39:06 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093:my-topic-1532242959-561299973 from pod my-cluster-2d6fd136-kafka-clients-54fcbf7699-7xgws
2022-04-06 00:39:06 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2d6fd136-kafka-clients-54fcbf7699-7xgws -n namespace-81 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1530656579 --group-instance-id instance652516066 --topic my-topic-1532242959-561299973 --bootstrap-server my-cluster-2d6fd136-kafka-bootstrap.namespace-81.svc:9093 USER=my_user_882165826_336528684
2022-04-06 00:39:13 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 00:39:13 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 00:39:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 00:39:13 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testZookeeperScaleUpScaleDown
2022-04-06 00:39:13 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-2d6fd136-kafka-clients in namespace namespace-81
2022-04-06 00:39:13 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1532242959-561299973 in namespace namespace-81
2022-04-06 00:39:13 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-772352181-39577610 in namespace namespace-81
2022-04-06 00:39:13 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-882165826-336528684 in namespace namespace-81
2022-04-06 00:39:13 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1293339117-830442571 in namespace namespace-81
2022-04-06 00:39:13 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2d6fd136 in namespace namespace-81
2022-04-06 00:39:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 00:39:53 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-81 for test case:testZookeeperScaleUpScaleDown
2022-04-06 00:39:59 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testZookeeperScaleUpScaleDown-FINISHED
2022-04-06 00:39:59 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 00:39:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 00:39:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testRecoveryDuringZookeeperRollingUpdate-STARTED
2022-04-06 00:39:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 00:39:59 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-82 for test case:testRecoveryDuringZookeeperRollingUpdate
2022-04-06 00:39:59 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-82
2022-04-06 00:39:59 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-82
2022-04-06 00:39:59 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-82
2022-04-06 00:39:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d99323cb in namespace namespace-82
2022-04-06 00:39:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-82
2022-04-06 00:39:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1165755108-796943628 in namespace namespace-82
2022-04-06 00:39:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-82
2022-04-06 00:39:59 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d99323cb will have desired state: Ready
2022-04-06 00:41:18 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d99323cb is in desired state: Ready
2022-04-06 00:41:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1165755108-796943628 will have desired state: Ready
2022-04-06 00:41:18 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1165755108-796943628 is in desired state: Ready
2022-04-06 00:41:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1953806782-986486316 in namespace namespace-82
2022-04-06 00:41:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-82
2022-04-06 00:41:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1953806782-986486316 will have desired state: Ready
2022-04-06 00:41:19 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1953806782-986486316 is in desired state: Ready
2022-04-06 00:41:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-d99323cb-kafka-clients in namespace namespace-82
2022-04-06 00:41:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-82
2022-04-06 00:41:29 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 00:41:29 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@7daa0fe1, messages=[], arguments=[--max-messages, 100, --topic, my-topic-1165755108-796943628, --bootstrap-server, my-cluster-d99323cb-kafka-bootstrap.namespace-82.svc:9093, USER=my_user_1953806782_986486316], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz', podNamespace='namespace-82', bootstrapServer='my-cluster-d99323cb-kafka-bootstrap.namespace-82.svc:9093', topicName='my-topic-1165755108-796943628', maxMessages=100, kafkaUsername='my-user-1953806782-986486316', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@42724ee0}
2022-04-06 00:41:29 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-d99323cb-kafka-bootstrap.namespace-82.svc:9093:my-topic-1165755108-796943628 from pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz
2022-04-06 00:41:29 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz -n namespace-82 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-1165755108-796943628 --bootstrap-server my-cluster-d99323cb-kafka-bootstrap.namespace-82.svc:9093 USER=my_user_1953806782_986486316
2022-04-06 00:41:33 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 00:41:33 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-06 00:41:33 [main] [32mINFO [m [RollingUpdateST:117] Update resources for pods
2022-04-06 00:41:33 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@287c4ab3, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-200647403, --group-instance-id, instance1856199502, --topic, my-topic-1165755108-796943628, --bootstrap-server, my-cluster-d99323cb-kafka-bootstrap.namespace-82.svc:9093, USER=my_user_1953806782_986486316], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz', podNamespace='namespace-82', bootstrapServer='my-cluster-d99323cb-kafka-bootstrap.namespace-82.svc:9093', topicName='my-topic-1165755108-796943628', maxMessages=100, kafkaUsername='my-user-1953806782-986486316', consumerGroupName='my-consumer-group-200647403', consumerInstanceId='instance1856199502', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@50498f5}
2022-04-06 00:41:33 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-d99323cb-kafka-bootstrap.namespace-82.svc:9093:my-topic-1165755108-796943628 from pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz
2022-04-06 00:41:33 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz -n namespace-82 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-200647403 --group-instance-id instance1856199502 --topic my-topic-1165755108-796943628 --bootstrap-server my-cluster-d99323cb-kafka-bootstrap.namespace-82.svc:9093 USER=my_user_1953806782_986486316
2022-04-06 00:41:40 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 00:41:40 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 00:41:40 [main] [32mINFO [m [ClientUtils:45] Consumer successfully consumed 100 messages for the 1 time
2022-04-06 00:41:40 [main] [32mINFO [m [PodUtils:277] Wait for at least one pod with prefix: my-cluster-d99323cb-zookeeper will be in pending phase
2022-04-06 00:41:40 [main] [32mINFO [m [RollingUpdateST:130] Verifying stability of zookeeper pods except the one, which is in pending phase
2022-04-06 00:41:40 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-d99323cb-zookeeper are stable
2022-04-06 00:41:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:41:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:41:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:41:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:41:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:41:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:41:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:41:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:41:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:41:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:41:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:41:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:41:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:41:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:41:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:41:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:41:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:41:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:41:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:41:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:41:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:41:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:41:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:41:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:41:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:41:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:41:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:41:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:41:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:41:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:41:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:41:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:41:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:41:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:41:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:41:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:41:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:41:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:41:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:41:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:42:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:42:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:42:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:42:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:42:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:42:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:42:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:42:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:42:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:42:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:42:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:42:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:42:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:42:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:42:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:42:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:42:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:42:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:42:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:42:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:42:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:42:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:42:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:42:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:42:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:42:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:42:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:42:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:42:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:42:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:42:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:42:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:42:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:42:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:42:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:42:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:42:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:42:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:42:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:42:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:42:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:42:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:42:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:42:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:42:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:42:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:42:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:42:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:42:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:42:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:42:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:42:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:42:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:42:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:42:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:42:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:42:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:42:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:42:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:42:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:42:29 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-d99323cb-zookeeper-0 ,my-cluster-d99323cb-zookeeper-1
2022-04-06 00:42:29 [main] [32mINFO [m [RollingUpdateST:133] Verifying stability of kafka pods
2022-04-06 00:42:29 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-d99323cb-kafka are stable
2022-04-06 00:42:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:42:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:42:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:42:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:42:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:42:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:42:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:42:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:42:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:42:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:42:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:42:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:42:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:42:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:42:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:42:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:42:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:42:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:42:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:42:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:42:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:42:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:42:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:42:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:42:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:42:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:42:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:42:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:42:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:42:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:42:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:42:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:42:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:42:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:42:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:42:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:42:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:42:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:42:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:42:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:42:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:42:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:42:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:42:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:42:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:42:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:42:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:42:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:42:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:42:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:42:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:42:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:42:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:42:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:42:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:42:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:42:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:42:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:42:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:42:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:42:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:42:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:42:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:42:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:42:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:42:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:42:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:42:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:42:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:42:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:42:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:42:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:42:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:42:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:42:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:42:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:42:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:42:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:42:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:42:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:42:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:42:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:42:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:42:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:42:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:42:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:42:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:42:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:42:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:42:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:42:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:42:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:42:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:42:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:42:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:42:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:42:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:42:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:42:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:42:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:42:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:42:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:42:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:42:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:42:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:42:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:42:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:42:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:42:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:42:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:42:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:42:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:42:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:42:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:42:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:42:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:42:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:42:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:42:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:42:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:42:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:42:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:42:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:42:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:43:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:43:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:43:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:43:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:43:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:43:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:43:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:43:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:43:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:43:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:43:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:43:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:43:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:43:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:43:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:43:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:43:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:43:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:43:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:43:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:43:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:43:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:43:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:43:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:43:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:43:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:43:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:43:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:43:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:43:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:43:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:43:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:43:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:43:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:43:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:43:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:43:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:43:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:43:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:43:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:43:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:43:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:43:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:43:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:43:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:43:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:43:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:43:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:43:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:43:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:43:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:43:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:43:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:43:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:43:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:43:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:43:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:43:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:43:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:43:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:43:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:43:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:43:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:43:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:43:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:43:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:43:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:43:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:43:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:43:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:43:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:43:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:43:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:43:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:43:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:43:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:43:19 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-d99323cb-kafka-0 ,my-cluster-d99323cb-kafka-1 ,my-cluster-d99323cb-kafka-2 ,my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz
2022-04-06 00:43:19 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-d99323cb-zookeeper to be ready
2022-04-06 00:48:41 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d99323cb will have desired state: Ready
2022-04-06 00:48:41 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d99323cb is in desired state: Ready
2022-04-06 00:48:41 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-d99323cb is ready
2022-04-06 00:48:41 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@f6f760f, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1254880792, --group-instance-id, instance2032966561, --topic, my-topic-1165755108-796943628, --bootstrap-server, my-cluster-d99323cb-kafka-bootstrap.namespace-82.svc:9093, USER=my_user_1953806782_986486316], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz', podNamespace='namespace-82', bootstrapServer='my-cluster-d99323cb-kafka-bootstrap.namespace-82.svc:9093', topicName='my-topic-1165755108-796943628', maxMessages=100, kafkaUsername='my-user-1953806782-986486316', consumerGroupName='my-consumer-group-1254880792', consumerInstanceId='instance2032966561', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@180331bb}
2022-04-06 00:48:41 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-d99323cb-kafka-bootstrap.namespace-82.svc:9093:my-topic-1165755108-796943628 from pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz
2022-04-06 00:48:41 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz -n namespace-82 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1254880792 --group-instance-id instance2032966561 --topic my-topic-1165755108-796943628 --bootstrap-server my-cluster-d99323cb-kafka-bootstrap.namespace-82.svc:9093 USER=my_user_1953806782_986486316
2022-04-06 00:48:48 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 00:48:48 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 00:48:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-414947260-1922460487 in namespace namespace-82
2022-04-06 00:48:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-82
2022-04-06 00:48:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-414947260-1922460487 will have desired state: Ready
2022-04-06 00:48:49 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-414947260-1922460487 is in desired state: Ready
2022-04-06 00:48:49 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@38d9d0c6, messages=[], arguments=[--max-messages, 100, --topic, my-topic-414947260-1922460487, --bootstrap-server, my-cluster-d99323cb-kafka-bootstrap.namespace-82.svc:9093, USER=my_user_1953806782_986486316], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz', podNamespace='namespace-82', bootstrapServer='my-cluster-d99323cb-kafka-bootstrap.namespace-82.svc:9093', topicName='my-topic-414947260-1922460487', maxMessages=100, kafkaUsername='my-user-1953806782-986486316', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@39d6a0ae}
2022-04-06 00:48:49 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-d99323cb-kafka-bootstrap.namespace-82.svc:9093:my-topic-414947260-1922460487 from pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz
2022-04-06 00:48:49 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz -n namespace-82 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-414947260-1922460487 --bootstrap-server my-cluster-d99323cb-kafka-bootstrap.namespace-82.svc:9093 USER=my_user_1953806782_986486316
2022-04-06 00:48:53 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 00:48:53 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-06 00:48:53 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1007bfaf, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1462710897, --group-instance-id, instance1015216733, --topic, my-topic-414947260-1922460487, --bootstrap-server, my-cluster-d99323cb-kafka-bootstrap.namespace-82.svc:9093, USER=my_user_1953806782_986486316], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz', podNamespace='namespace-82', bootstrapServer='my-cluster-d99323cb-kafka-bootstrap.namespace-82.svc:9093', topicName='my-topic-414947260-1922460487', maxMessages=100, kafkaUsername='my-user-1953806782-986486316', consumerGroupName='my-consumer-group-1462710897', consumerInstanceId='instance1015216733', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4cf206dc}
2022-04-06 00:48:53 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-d99323cb-kafka-bootstrap.namespace-82.svc:9093:my-topic-414947260-1922460487 from pod my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz
2022-04-06 00:48:53 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d99323cb-kafka-clients-86c554c6-qxvbz -n namespace-82 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1462710897 --group-instance-id instance1015216733 --topic my-topic-414947260-1922460487 --bootstrap-server my-cluster-d99323cb-kafka-bootstrap.namespace-82.svc:9093 USER=my_user_1953806782_986486316
2022-04-06 00:48:59 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 00:48:59 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 00:48:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 00:48:59 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryDuringZookeeperRollingUpdate
2022-04-06 00:48:59 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1953806782-986486316 in namespace namespace-82
2022-04-06 00:48:59 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d99323cb in namespace namespace-82
2022-04-06 00:48:59 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1165755108-796943628 in namespace namespace-82
2022-04-06 00:48:59 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-414947260-1922460487 in namespace namespace-82
2022-04-06 00:48:59 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-d99323cb-kafka-clients in namespace namespace-82
2022-04-06 00:49:39 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 00:49:39 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-82 for test case:testRecoveryDuringZookeeperRollingUpdate
2022-04-06 00:49:45 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testRecoveryDuringZookeeperRollingUpdate-FINISHED
2022-04-06 00:49:45 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 00:49:45 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 00:49:45 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testRecoveryDuringKafkaRollingUpdate-STARTED
2022-04-06 00:49:45 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 00:49:45 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-83 for test case:testRecoveryDuringKafkaRollingUpdate
2022-04-06 00:49:45 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-83
2022-04-06 00:49:45 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-83
2022-04-06 00:49:45 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-83
2022-04-06 00:49:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-fff691e3 in namespace namespace-83
2022-04-06 00:49:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-83
2022-04-06 00:49:45 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-fff691e3 will have desired state: Ready
2022-04-06 00:51:02 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-fff691e3 is in desired state: Ready
2022-04-06 00:51:02 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1735576604-1606158221 in namespace namespace-83
2022-04-06 00:51:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-83
2022-04-06 00:51:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1735576604-1606158221 will have desired state: Ready
2022-04-06 00:51:03 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1735576604-1606158221 is in desired state: Ready
2022-04-06 00:51:03 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-507649863-658822862 in namespace namespace-83
2022-04-06 00:51:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-83
2022-04-06 00:51:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-507649863-658822862 will have desired state: Ready
2022-04-06 00:51:04 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-507649863-658822862 is in desired state: Ready
2022-04-06 00:51:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-fff691e3-kafka-clients in namespace namespace-83
2022-04-06 00:51:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-83
2022-04-06 00:51:14 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 00:51:14 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@4e808a1d, messages=[], arguments=[--max-messages, 100, --topic, my-topic-1735576604-1606158221, --bootstrap-server, my-cluster-fff691e3-kafka-bootstrap.namespace-83.svc:9093, USER=my_user_507649863_658822862], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj', podNamespace='namespace-83', bootstrapServer='my-cluster-fff691e3-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-1735576604-1606158221', maxMessages=100, kafkaUsername='my-user-507649863-658822862', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3e0eabe5}
2022-04-06 00:51:14 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-fff691e3-kafka-bootstrap.namespace-83.svc:9093:my-topic-1735576604-1606158221 from pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj
2022-04-06 00:51:14 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj -n namespace-83 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-1735576604-1606158221 --bootstrap-server my-cluster-fff691e3-kafka-bootstrap.namespace-83.svc:9093 USER=my_user_507649863_658822862
2022-04-06 00:51:18 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 00:51:18 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-06 00:51:18 [main] [32mINFO [m [RollingUpdateST:203] Update resources for pods
2022-04-06 00:51:18 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@77670565, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1519332271, --group-instance-id, instance419386627, --topic, my-topic-1735576604-1606158221, --bootstrap-server, my-cluster-fff691e3-kafka-bootstrap.namespace-83.svc:9093, USER=my_user_507649863_658822862], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj', podNamespace='namespace-83', bootstrapServer='my-cluster-fff691e3-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-1735576604-1606158221', maxMessages=100, kafkaUsername='my-user-507649863-658822862', consumerGroupName='my-consumer-group-1519332271', consumerInstanceId='instance419386627', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3d7db0b5}
2022-04-06 00:51:18 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-fff691e3-kafka-bootstrap.namespace-83.svc:9093:my-topic-1735576604-1606158221 from pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj
2022-04-06 00:51:18 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj -n namespace-83 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1519332271 --group-instance-id instance419386627 --topic my-topic-1735576604-1606158221 --bootstrap-server my-cluster-fff691e3-kafka-bootstrap.namespace-83.svc:9093 USER=my_user_507649863_658822862
2022-04-06 00:51:25 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 00:51:25 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 00:51:25 [main] [32mINFO [m [ClientUtils:45] Consumer successfully consumed 100 messages for the 1 time
2022-04-06 00:51:25 [main] [32mINFO [m [PodUtils:277] Wait for at least one pod with prefix: my-cluster-fff691e3-kafka will be in pending phase
2022-04-06 00:51:25 [main] [32mINFO [m [RollingUpdateST:220] Verifying stability of kafka pods except the one, which is in pending phase
2022-04-06 00:51:25 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-fff691e3-kafka are stable
2022-04-06 00:51:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:51:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:51:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:51:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:51:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:51:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:51:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:51:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:51:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:51:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:51:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:51:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:51:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:51:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:51:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:51:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:51:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:51:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:51:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:51:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:51:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:51:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:51:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:51:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:51:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:51:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:51:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:51:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:51:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:51:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:51:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:51:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:51:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:51:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:51:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:51:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:51:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:51:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:51:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:51:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:51:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:51:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:51:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:51:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:51:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:51:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:51:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:51:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:51:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:51:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:51:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:51:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:51:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:51:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:51:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:51:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:51:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:51:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:51:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:51:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:51:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:51:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:51:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:51:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:51:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:51:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:51:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:51:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:51:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:51:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:51:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:51:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:51:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:51:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:51:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:51:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:51:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:51:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:51:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:51:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:51:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:51:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:51:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:51:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:51:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:51:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:51:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:51:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:51:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:51:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:51:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:51:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:51:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:51:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:51:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:51:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:51:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:51:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:51:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:51:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:51:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:51:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:51:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:51:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:51:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:52:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:52:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:52:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:52:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:52:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:52:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:52:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:52:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:52:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:52:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:52:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:52:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:52:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:52:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:52:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:52:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:52:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:52:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:52:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:52:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:52:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:52:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:52:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:52:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:52:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:52:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:52:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:52:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:52:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:52:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:52:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:52:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:52:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:52:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:52:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:52:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:52:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:52:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:52:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:52:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:52:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:52:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:52:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:52:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:52:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:52:14 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-fff691e3-kafka-0 ,my-cluster-fff691e3-kafka-2 ,my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj
2022-04-06 00:52:14 [main] [32mINFO [m [RollingUpdateST:223] Verifying stability of zookeeper pods
2022-04-06 00:52:14 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-fff691e3-zookeeper are stable
2022-04-06 00:52:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:52:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:52:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:52:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:52:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:52:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:52:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:52:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:52:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:52:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:52:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:52:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:52:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:52:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:52:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:52:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:52:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:52:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:52:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:52:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:52:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:52:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:52:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:52:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:52:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:52:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:52:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:52:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:52:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:52:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:52:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:52:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:52:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:52:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:52:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:52:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:52:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:52:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:52:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:52:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:52:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:52:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:52:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:52:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:52:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:52:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:52:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:52:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:52:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:52:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:52:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:52:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:52:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:52:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:52:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:52:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:52:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:52:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:52:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:52:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:52:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:52:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:52:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:52:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:52:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:52:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:52:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:52:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:52:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:52:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:52:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:52:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:52:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:52:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:52:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:52:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:52:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:52:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:52:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:52:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:52:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:52:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:52:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:52:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:52:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:52:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:52:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:52:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:52:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:52:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:52:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:52:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:52:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:52:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:52:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:52:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:52:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:52:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:52:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:52:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:52:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:52:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:52:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:52:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:52:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:52:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:52:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:52:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:52:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:52:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:52:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:52:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:52:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:52:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:52:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:52:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:52:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:52:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:52:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:52:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:52:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:52:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:52:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:52:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:52:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:52:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:52:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:52:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:52:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:52:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:52:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:52:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:52:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:52:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:52:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:53:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:53:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:53:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:53:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:53:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:53:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:53:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:53:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:53:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:53:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:53:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:53:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:53:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:53:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:53:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fff691e3-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:53:04 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-fff691e3-zookeeper-0 ,my-cluster-fff691e3-zookeeper-1 ,my-cluster-fff691e3-zookeeper-2
2022-04-06 00:53:04 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6d85cf03, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1962448564, --group-instance-id, instance2023460810, --topic, my-topic-1735576604-1606158221, --bootstrap-server, my-cluster-fff691e3-kafka-bootstrap.namespace-83.svc:9093, USER=my_user_507649863_658822862], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj', podNamespace='namespace-83', bootstrapServer='my-cluster-fff691e3-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-1735576604-1606158221', maxMessages=100, kafkaUsername='my-user-507649863-658822862', consumerGroupName='my-consumer-group-1962448564', consumerInstanceId='instance2023460810', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@204fd801}
2022-04-06 00:53:04 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-fff691e3-kafka-bootstrap.namespace-83.svc:9093:my-topic-1735576604-1606158221 from pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj
2022-04-06 00:53:04 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj -n namespace-83 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1962448564 --group-instance-id instance2023460810 --topic my-topic-1735576604-1606158221 --bootstrap-server my-cluster-fff691e3-kafka-bootstrap.namespace-83.svc:9093 USER=my_user_507649863_658822862
2022-04-06 00:53:11 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 00:53:11 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 00:53:11 [main] [32mINFO [m [ClientUtils:45] Consumer successfully consumed 100 messages for the 1 time
2022-04-06 00:53:11 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-fff691e3-kafka to be ready
2022-04-06 00:58:27 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-fff691e3 will have desired state: Ready
2022-04-06 00:58:27 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-fff691e3 is in desired state: Ready
2022-04-06 00:58:27 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-fff691e3 is ready
2022-04-06 00:58:27 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6fc13a2c, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1392136157, --group-instance-id, instance242136063, --topic, my-topic-1735576604-1606158221, --bootstrap-server, my-cluster-fff691e3-kafka-bootstrap.namespace-83.svc:9093, USER=my_user_507649863_658822862], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj', podNamespace='namespace-83', bootstrapServer='my-cluster-fff691e3-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-1735576604-1606158221', maxMessages=100, kafkaUsername='my-user-507649863-658822862', consumerGroupName='my-consumer-group-1392136157', consumerInstanceId='instance242136063', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2c7f0577}
2022-04-06 00:58:27 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-fff691e3-kafka-bootstrap.namespace-83.svc:9093:my-topic-1735576604-1606158221 from pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj
2022-04-06 00:58:27 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj -n namespace-83 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1392136157 --group-instance-id instance242136063 --topic my-topic-1735576604-1606158221 --bootstrap-server my-cluster-fff691e3-kafka-bootstrap.namespace-83.svc:9093 USER=my_user_507649863_658822862
2022-04-06 00:58:34 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 00:58:34 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 00:58:34 [main] [32mINFO [m [ClientUtils:45] Consumer successfully consumed 100 messages for the 1 time
2022-04-06 00:58:34 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-54813874-1797896035 in namespace namespace-83
2022-04-06 00:58:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-83
2022-04-06 00:58:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-54813874-1797896035 will have desired state: Ready
2022-04-06 00:58:35 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-54813874-1797896035 is in desired state: Ready
2022-04-06 00:58:35 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@6f21646c, messages=[], arguments=[--max-messages, 100, --topic, my-topic-54813874-1797896035, --bootstrap-server, my-cluster-fff691e3-kafka-bootstrap.namespace-83.svc:9093, USER=my_user_507649863_658822862], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj', podNamespace='namespace-83', bootstrapServer='my-cluster-fff691e3-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-54813874-1797896035', maxMessages=100, kafkaUsername='my-user-507649863-658822862', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3b218ac2}
2022-04-06 00:58:35 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-fff691e3-kafka-bootstrap.namespace-83.svc:9093:my-topic-54813874-1797896035 from pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj
2022-04-06 00:58:35 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj -n namespace-83 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-54813874-1797896035 --bootstrap-server my-cluster-fff691e3-kafka-bootstrap.namespace-83.svc:9093 USER=my_user_507649863_658822862
2022-04-06 00:58:39 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 00:58:39 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-06 00:58:39 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@70465254, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-625934530, --group-instance-id, instance35334610, --topic, my-topic-54813874-1797896035, --bootstrap-server, my-cluster-fff691e3-kafka-bootstrap.namespace-83.svc:9093, USER=my_user_507649863_658822862], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj', podNamespace='namespace-83', bootstrapServer='my-cluster-fff691e3-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-54813874-1797896035', maxMessages=100, kafkaUsername='my-user-507649863-658822862', consumerGroupName='my-consumer-group-625934530', consumerInstanceId='instance35334610', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@9d723fe}
2022-04-06 00:58:39 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-fff691e3-kafka-bootstrap.namespace-83.svc:9093:my-topic-54813874-1797896035 from pod my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj
2022-04-06 00:58:39 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fff691e3-kafka-clients-57b964778d-k9xfj -n namespace-83 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-625934530 --group-instance-id instance35334610 --topic my-topic-54813874-1797896035 --bootstrap-server my-cluster-fff691e3-kafka-bootstrap.namespace-83.svc:9093 USER=my_user_507649863_658822862
2022-04-06 00:58:45 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 00:58:45 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 00:58:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 00:58:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryDuringKafkaRollingUpdate
2022-04-06 00:58:45 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-507649863-658822862 in namespace namespace-83
2022-04-06 00:58:45 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1735576604-1606158221 in namespace namespace-83
2022-04-06 00:58:45 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-fff691e3 in namespace namespace-83
2022-04-06 00:58:45 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-54813874-1797896035 in namespace namespace-83
2022-04-06 00:58:45 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-fff691e3-kafka-clients in namespace namespace-83
2022-04-06 00:59:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 00:59:35 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-83 for test case:testRecoveryDuringKafkaRollingUpdate
2022-04-06 00:59:41 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testRecoveryDuringKafkaRollingUpdate-FINISHED
2022-04-06 00:59:41 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 00:59:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 00:59:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testClusterOperatorFinishAllRollingUpdates-STARTED
2022-04-06 00:59:41 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 00:59:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0335fdd7 in namespace rolling-update-st
2022-04-06 00:59:41 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0335fdd7 will have desired state: Ready
2022-04-06 01:02:00 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0335fdd7 is in desired state: Ready
2022-04-06 01:02:15 [main] [32mINFO [m [RollingUpdateST:630] Deleting Cluster Operator pod with labels LabelSelector(matchExpressions=[], matchLabels={name=strimzi-cluster-operator}, additionalProperties={})
2022-04-06 01:02:15 [main] [32mINFO [m [RollingUpdateST:632] Cluster Operator pod deleted
2022-04-06 01:02:15 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-0335fdd7-zookeeper rolling update
2022-04-06 01:03:05 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-0335fdd7-zookeeper has been successfully rolled
2022-04-06 01:03:05 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-0335fdd7-zookeeper to be ready
2022-04-06 01:03:40 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0335fdd7 will have desired state: Ready
2022-04-06 01:03:40 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0335fdd7 is in desired state: Ready
2022-04-06 01:03:40 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-0335fdd7 is ready
2022-04-06 01:03:44 [main] [32mINFO [m [RollingUpdateST:639] Deleting Cluster Operator pod with labels LabelSelector(matchExpressions=[], matchLabels={name=strimzi-cluster-operator}, additionalProperties={})
2022-04-06 01:03:44 [main] [32mINFO [m [RollingUpdateST:641] Cluster Operator pod deleted
2022-04-06 01:03:44 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-0335fdd7-kafka rolling update
2022-04-06 01:05:14 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-0335fdd7-kafka has been successfully rolled
2022-04-06 01:05:14 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-0335fdd7-kafka to be ready
2022-04-06 01:05:43 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0335fdd7 will have desired state: Ready
2022-04-06 01:05:43 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0335fdd7 is in desired state: Ready
2022-04-06 01:05:43 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-0335fdd7 is ready
2022-04-06 01:05:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:05:43 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testClusterOperatorFinishAllRollingUpdates
2022-04-06 01:05:43 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0335fdd7 in namespace rolling-update-st
2022-04-06 01:05:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 01:05:53 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testClusterOperatorFinishAllRollingUpdates-FINISHED
2022-04-06 01:05:53 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 01:05:53 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 01:05:53 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testKafkaAndZookeeperScaleUpScaleDown-STARTED
2022-04-06 01:05:53 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 01:05:53 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-84 for test case:testKafkaAndZookeeperScaleUpScaleDown
2022-04-06 01:05:53 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-84
2022-04-06 01:05:53 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-84
2022-04-06 01:05:53 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-84
2022-04-06 01:05:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0989314e in namespace namespace-84
2022-04-06 01:05:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-84
2022-04-06 01:05:53 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0989314e will have desired state: Ready
2022-04-06 01:07:42 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0989314e is in desired state: Ready
2022-04-06 01:07:42 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-980423676-1058498212 in namespace namespace-84
2022-04-06 01:07:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-84
2022-04-06 01:07:42 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-980423676-1058498212 will have desired state: Ready
2022-04-06 01:07:43 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-980423676-1058498212 is in desired state: Ready
2022-04-06 01:07:43 [main] [32mINFO [m [AbstractST:489] Verifying docker image names
2022-04-06 01:07:43 [main] [32mINFO [m [AbstractST:172] strimzi-cluster-operator
2022-04-06 01:07:43 [main] [32mINFO [m [AbstractST:525] Docker images verified
2022-04-06 01:07:43 [main] [32mINFO [m [RollingUpdateST:292] Running kafkaScaleUpScaleDown my-cluster-0989314e
2022-04-06 01:07:43 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1026106785-680035404 in namespace namespace-84
2022-04-06 01:07:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-84
2022-04-06 01:07:43 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1026106785-680035404 will have desired state: Ready
2022-04-06 01:07:44 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1026106785-680035404 is in desired state: Ready
2022-04-06 01:07:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-0989314e-kafka-clients in namespace namespace-84
2022-04-06 01:07:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-84
2022-04-06 01:07:54 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 01:07:54 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@75224fd7, messages=[], arguments=[--max-messages, 100, --topic, my-topic-1026106785-680035404, --bootstrap-server, my-cluster-0989314e-kafka-bootstrap.namespace-84.svc:9093, USER=my_user_980423676_1058498212], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-0989314e-kafka-clients-574c89fc59-2px2b', podNamespace='namespace-84', bootstrapServer='my-cluster-0989314e-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-1026106785-680035404', maxMessages=100, kafkaUsername='my-user-980423676-1058498212', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5a43a285}
2022-04-06 01:07:54 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-0989314e-kafka-bootstrap.namespace-84.svc:9093:my-topic-1026106785-680035404 from pod my-cluster-0989314e-kafka-clients-574c89fc59-2px2b
2022-04-06 01:07:54 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0989314e-kafka-clients-574c89fc59-2px2b -n namespace-84 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-1026106785-680035404 --bootstrap-server my-cluster-0989314e-kafka-bootstrap.namespace-84.svc:9093 USER=my_user_980423676_1058498212
2022-04-06 01:07:57 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 01:07:57 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-06 01:07:57 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4e5359e4, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-727179039, --group-instance-id, instance372898065, --topic, my-topic-1026106785-680035404, --bootstrap-server, my-cluster-0989314e-kafka-bootstrap.namespace-84.svc:9093, USER=my_user_980423676_1058498212], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-0989314e-kafka-clients-574c89fc59-2px2b', podNamespace='namespace-84', bootstrapServer='my-cluster-0989314e-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-1026106785-680035404', maxMessages=100, kafkaUsername='my-user-980423676-1058498212', consumerGroupName='my-consumer-group-727179039', consumerInstanceId='instance372898065', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@676da2fc}
2022-04-06 01:07:57 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-0989314e-kafka-bootstrap.namespace-84.svc:9093:my-topic-1026106785-680035404 from pod my-cluster-0989314e-kafka-clients-574c89fc59-2px2b
2022-04-06 01:07:57 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0989314e-kafka-clients-574c89fc59-2px2b -n namespace-84 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-727179039 --group-instance-id instance372898065 --topic my-topic-1026106785-680035404 --bootstrap-server my-cluster-0989314e-kafka-bootstrap.namespace-84.svc:9093 USER=my_user_980423676_1058498212
2022-04-06 01:08:04 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 01:08:04 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 01:08:04 [main] [32mINFO [m [RollingUpdateST:317] Scale up Kafka to 7
2022-04-06 01:08:04 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-0989314e-kafka rolling update
2022-04-06 01:09:14 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-0989314e-kafka has been successfully rolled
2022-04-06 01:09:14 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 7 Pod(s) of my-cluster-0989314e-kafka to be ready
2022-04-06 01:10:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0989314e will have desired state: Ready
2022-04-06 01:10:06 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0989314e is in desired state: Ready
2022-04-06 01:10:06 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-0989314e is ready
2022-04-06 01:10:06 [main] [32mINFO [m [RollingUpdateST:327] Kafka scale up to 7 finished
2022-04-06 01:10:06 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@37958ff7, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1309785681, --group-instance-id, instance1368420875, --topic, my-topic-1026106785-680035404, --bootstrap-server, my-cluster-0989314e-kafka-bootstrap.namespace-84.svc:9093, USER=my_user_980423676_1058498212], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-0989314e-kafka-clients-574c89fc59-2px2b', podNamespace='namespace-84', bootstrapServer='my-cluster-0989314e-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-1026106785-680035404', maxMessages=100, kafkaUsername='my-user-980423676-1058498212', consumerGroupName='my-consumer-group-1309785681', consumerInstanceId='instance1368420875', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@627f99cb}
2022-04-06 01:10:06 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-0989314e-kafka-bootstrap.namespace-84.svc:9093:my-topic-1026106785-680035404 from pod my-cluster-0989314e-kafka-clients-574c89fc59-2px2b
2022-04-06 01:10:06 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0989314e-kafka-clients-574c89fc59-2px2b -n namespace-84 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1309785681 --group-instance-id instance1368420875 --topic my-topic-1026106785-680035404 --bootstrap-server my-cluster-0989314e-kafka-bootstrap.namespace-84.svc:9093 USER=my_user_980423676_1058498212
2022-04-06 01:10:13 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 01:10:13 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 01:10:13 [main] [32mINFO [m [RollingUpdateST:339] Scale up Zookeeper to 5
2022-04-06 01:10:13 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 5 Pod(s) of my-cluster-0989314e-zookeeper to be ready
2022-04-06 01:11:14 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0989314e will have desired state: Ready
2022-04-06 01:11:14 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0989314e is in desired state: Ready
2022-04-06 01:11:14 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-0989314e is ready
2022-04-06 01:11:14 [main] [32mINFO [m [RollingUpdateST:342] Kafka scale up to 5 finished
2022-04-06 01:11:14 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@34e2e62a, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1942360399, --group-instance-id, instance1296464237, --topic, my-topic-1026106785-680035404, --bootstrap-server, my-cluster-0989314e-kafka-bootstrap.namespace-84.svc:9093, USER=my_user_980423676_1058498212], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-0989314e-kafka-clients-574c89fc59-2px2b', podNamespace='namespace-84', bootstrapServer='my-cluster-0989314e-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-1026106785-680035404', maxMessages=100, kafkaUsername='my-user-980423676-1058498212', consumerGroupName='my-consumer-group-1942360399', consumerInstanceId='instance1296464237', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7a97d5b9}
2022-04-06 01:11:14 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-0989314e-kafka-bootstrap.namespace-84.svc:9093:my-topic-1026106785-680035404 from pod my-cluster-0989314e-kafka-clients-574c89fc59-2px2b
2022-04-06 01:11:14 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0989314e-kafka-clients-574c89fc59-2px2b -n namespace-84 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1942360399 --group-instance-id instance1296464237 --topic my-topic-1026106785-680035404 --bootstrap-server my-cluster-0989314e-kafka-bootstrap.namespace-84.svc:9093 USER=my_user_980423676_1058498212
2022-04-06 01:11:21 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 01:11:21 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 01:11:21 [main] [32mINFO [m [RollingUpdateST:351] Scale down Kafka to 3
2022-04-06 01:11:21 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-0989314e-kafka rolling update
2022-04-06 01:13:26 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-0989314e-kafka has been successfully rolled
2022-04-06 01:13:26 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-0989314e-kafka to be ready
2022-04-06 01:13:54 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0989314e will have desired state: Ready
2022-04-06 01:13:54 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0989314e is in desired state: Ready
2022-04-06 01:13:54 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-0989314e is ready
2022-04-06 01:13:54 [main] [32mINFO [m [RollingUpdateST:356] Kafka scale down to 3 finished
2022-04-06 01:13:54 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@64f6511c, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1256814250, --group-instance-id, instance108794020, --topic, my-topic-1026106785-680035404, --bootstrap-server, my-cluster-0989314e-kafka-bootstrap.namespace-84.svc:9093, USER=my_user_980423676_1058498212], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-0989314e-kafka-clients-574c89fc59-2px2b', podNamespace='namespace-84', bootstrapServer='my-cluster-0989314e-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-1026106785-680035404', maxMessages=100, kafkaUsername='my-user-980423676-1058498212', consumerGroupName='my-consumer-group-1256814250', consumerInstanceId='instance108794020', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7c1b697b}
2022-04-06 01:13:54 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-0989314e-kafka-bootstrap.namespace-84.svc:9093:my-topic-1026106785-680035404 from pod my-cluster-0989314e-kafka-clients-574c89fc59-2px2b
2022-04-06 01:13:54 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0989314e-kafka-clients-574c89fc59-2px2b -n namespace-84 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1256814250 --group-instance-id instance108794020 --topic my-topic-1026106785-680035404 --bootstrap-server my-cluster-0989314e-kafka-bootstrap.namespace-84.svc:9093 USER=my_user_980423676_1058498212
2022-04-06 01:14:01 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 01:14:01 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 01:14:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-581012218-100923752 in namespace namespace-84
2022-04-06 01:14:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-84
2022-04-06 01:14:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-581012218-100923752 will have desired state: Ready
2022-04-06 01:15:35 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-581012218-100923752 is in desired state: Ready
2022-04-06 01:15:35 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@43c33080, messages=[], arguments=[--max-messages, 100, --topic, my-topic-581012218-100923752, --bootstrap-server, my-cluster-0989314e-kafka-bootstrap.namespace-84.svc:9093, USER=my_user_980423676_1058498212], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-0989314e-kafka-clients-574c89fc59-2px2b', podNamespace='namespace-84', bootstrapServer='my-cluster-0989314e-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-581012218-100923752', maxMessages=100, kafkaUsername='my-user-980423676-1058498212', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@15ebfd90}
2022-04-06 01:15:35 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-0989314e-kafka-bootstrap.namespace-84.svc:9093:my-topic-581012218-100923752 from pod my-cluster-0989314e-kafka-clients-574c89fc59-2px2b
2022-04-06 01:15:35 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0989314e-kafka-clients-574c89fc59-2px2b -n namespace-84 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-581012218-100923752 --bootstrap-server my-cluster-0989314e-kafka-bootstrap.namespace-84.svc:9093 USER=my_user_980423676_1058498212
2022-04-06 01:15:39 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 01:15:39 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-06 01:15:39 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@40b1abcd, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-2131836732, --group-instance-id, instance486084512, --topic, my-topic-581012218-100923752, --bootstrap-server, my-cluster-0989314e-kafka-bootstrap.namespace-84.svc:9093, USER=my_user_980423676_1058498212], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-0989314e-kafka-clients-574c89fc59-2px2b', podNamespace='namespace-84', bootstrapServer='my-cluster-0989314e-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-581012218-100923752', maxMessages=100, kafkaUsername='my-user-980423676-1058498212', consumerGroupName='my-consumer-group-2131836732', consumerInstanceId='instance486084512', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@afcd07f}
2022-04-06 01:15:39 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-0989314e-kafka-bootstrap.namespace-84.svc:9093:my-topic-581012218-100923752 from pod my-cluster-0989314e-kafka-clients-574c89fc59-2px2b
2022-04-06 01:15:39 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0989314e-kafka-clients-574c89fc59-2px2b -n namespace-84 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-2131836732 --group-instance-id instance486084512 --topic my-topic-581012218-100923752 --bootstrap-server my-cluster-0989314e-kafka-bootstrap.namespace-84.svc:9093 USER=my_user_980423676_1058498212
2022-04-06 01:15:46 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 01:15:46 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 01:15:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:15:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaAndZookeeperScaleUpScaleDown
2022-04-06 01:15:46 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1026106785-680035404 in namespace namespace-84
2022-04-06 01:15:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0989314e in namespace namespace-84
2022-04-06 01:15:46 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-581012218-100923752 in namespace namespace-84
2022-04-06 01:15:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-0989314e-kafka-clients in namespace namespace-84
2022-04-06 01:15:46 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-980423676-1058498212 in namespace namespace-84
2022-04-06 01:16:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 01:16:26 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-84 for test case:testKafkaAndZookeeperScaleUpScaleDown
2022-04-06 01:16:37 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testKafkaAndZookeeperScaleUpScaleDown-FINISHED
2022-04-06 01:16:37 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 01:16:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:16:37 [main] [32mINFO [m [ResourceManager:346] In context RollingUpdateST is everything deleted.
2022-04-06 01:16:37 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4,081.866 s - in io.strimzi.systemtest.rollingupdate.RollingUpdateST
[[1;34mINFO[m] Running io.strimzi.systemtest.log.LoggingChangeST
2022-04-06 01:16:44 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: logging-change-st
2022-04-06 01:16:44 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: logging-change-st
2022-04-06 01:16:44 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: logging-change-st
2022-04-06 01:16:44 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 01:16:44 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetClusterOperatorLoggingLevels-STARTED
2022-04-06 01:16:44 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 01:16:44 [main] [32mINFO [m [LoggingChangeST:618] Checking that original logging config is different from the new one
2022-04-06 01:16:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:16:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:16:44 [main] [32mINFO [m [LoggingChangeST:621] Changing logging for cluster-operator
2022-04-06 01:16:44 [main] [32mINFO [m [LoggingChangeST:624] Waiting for log4j2.properties will contain desired settings
2022-04-06 01:16:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:16:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:16:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:16:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:16:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:16:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:16:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:16:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:16:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:16:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:16:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:16:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:16:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:16:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:16:52 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:16:52 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:16:54 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:16:54 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:16:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:16:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:16:56 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:16:56 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:16:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:16:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:16:58 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:16:58 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:16:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:16:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:02 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:04 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:04 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:14 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:14 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:21 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:21 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:30 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:31 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:31 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:40 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:40 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:42 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:42 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:43 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:43 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:48 [main] [32mINFO [m [LoggingChangeST:629] Checking log4j2.properties in CO pod
2022-04-06 01:17:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:17:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:17:48 [main] [32mINFO [m [LoggingChangeST:633] Checking if CO rolled its pod
2022-04-06 01:17:48 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:21 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress

2022-04-06 01:17:49 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:21 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress

2022-04-06 01:17:49 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:21 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress

2022-04-06 01:17:49 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:21 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress

2022-04-06 01:17:49 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:21 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress

2022-04-06 01:17:50 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:21 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress

2022-04-06 01:17:50 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:21 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress

2022-04-06 01:17:50 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:21 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress

2022-04-06 01:17:50 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:21 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress

2022-04-06 01:17:51 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:21 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:51 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:51 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:51 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:52 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:52 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:52 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:52 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:53 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:53 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:53 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:53 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:54 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:54 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:54 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:54 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:55 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:55 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:55 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:55 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:56 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:56 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:56 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:56 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:57 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:57 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:57 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:57 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:58 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:58 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:58 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:58 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:59 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:59 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:59 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:17:59 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:00 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:00 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:00 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:00 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:01 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:01 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:01 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:01 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:02 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:02 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:02 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:02 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:03 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:03 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:03 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:03 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:04 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:04 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:04 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:04 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:05 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:05 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:05 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:05 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:06 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:06 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:06 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:06 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:07 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:07 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:07 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:07 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:08 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:08 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:08 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:08 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:09 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:09 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:09 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:09 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:10 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:10 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:10 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:10 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:11 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:11 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:11 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:11 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:12 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:12 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:12 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:12 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:13 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:13 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:13 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:13 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:14 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:14 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:14 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:14 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:15 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:15 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:15 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:15 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:16 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:16 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:16 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:16 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:17 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:17 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:17 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:17 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:47 INFO  AbstractOperator:373 - Reconciliation #37(watch) Kafka(namespace-84/my-cluster-0989314e): Reconciliation is in progress
2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:18 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:18 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:18 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:18 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:19 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:19 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:19 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:19 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:20 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:20 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:20 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:20 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:21 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:17:51 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-06 01:18:21 [main] [33mWARN [m [LoggingChangeST:639] 
2022-04-06 01:18:21 [main] [32mINFO [m [LoggingChangeST:643] Changing all levels from OFF to INFO/WARN
2022-04-06 01:18:21 [main] [32mINFO [m [LoggingChangeST:647] Changing logging for cluster-operator
2022-04-06 01:18:21 [main] [32mINFO [m [LoggingChangeST:650] Waiting for log4j2.properties will contain desired settings
2022-04-06 01:18:21 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:21 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:30 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:32 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:32 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:40 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:40 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:42 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:42 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:43 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:43 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:52 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:52 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:53 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:53 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:54 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:54 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:56 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:56 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:58 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:58 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:18:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:19:00 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:19:00 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:19:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:19:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:19:02 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:19:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:19:04 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:19:04 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:19:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:19:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:19:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:19:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:19:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:19:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:19:07 [main] [32mINFO [m [LoggingChangeST:655] Checking log4j2.properties in CO pod
2022-04-06 01:19:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-w429g -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:19:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:19:07 [main] [32mINFO [m [LoggingChangeST:659] Checking if CO rolled its pod
2022-04-06 01:19:21 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:19:21 [main] [32mINFO [m [ResourceManager:346] In context testDynamicallySetClusterOperatorLoggingLevels is everything deleted.
2022-04-06 01:19:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 01:19:21 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetClusterOperatorLoggingLevels-FINISHED
2022-04-06 01:19:21 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 01:19:21 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 01:19:21 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetUnknownKafkaLogger-STARTED
2022-04-06 01:19:21 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 01:19:21 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-85 for test case:testDynamicallySetUnknownKafkaLogger
2022-04-06 01:19:21 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-85
2022-04-06 01:19:21 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-85
2022-04-06 01:19:21 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-85
2022-04-06 01:19:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-f4f35a8e in namespace namespace-85
2022-04-06 01:19:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-85
2022-04-06 01:19:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f4f35a8e will have desired state: Ready
2022-04-06 01:20:40 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f4f35a8e is in desired state: Ready
2022-04-06 01:20:40 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-f4f35a8e-kafka rolling update
2022-04-06 01:21:50 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-f4f35a8e-kafka has been successfully rolled
2022-04-06 01:21:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:21:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetUnknownKafkaLogger
2022-04-06 01:21:57 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-f4f35a8e in namespace namespace-85
2022-04-06 01:22:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 01:22:07 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-85 for test case:testDynamicallySetUnknownKafkaLogger
2022-04-06 01:22:50 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetUnknownKafkaLogger-FINISHED
2022-04-06 01:22:50 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 01:22:50 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 01:22:50 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetKafkaExternalLogging-STARTED
2022-04-06 01:22:50 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 01:22:50 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-86 for test case:testDynamicallySetKafkaExternalLogging
2022-04-06 01:22:50 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-86
2022-04-06 01:22:50 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-86
2022-04-06 01:22:50 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-86
2022-04-06 01:22:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d022b201 in namespace namespace-86
2022-04-06 01:22:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-86
2022-04-06 01:22:50 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d022b201 will have desired state: Ready
2022-04-06 01:24:04 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d022b201 is in desired state: Ready
2022-04-06 01:24:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 50
2022-04-06 01:24:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 49
2022-04-06 01:24:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 48
2022-04-06 01:24:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 47
2022-04-06 01:24:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 46
2022-04-06 01:24:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 45
2022-04-06 01:24:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 44
2022-04-06 01:24:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 43
2022-04-06 01:24:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 42
2022-04-06 01:24:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 41
2022-04-06 01:24:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 40
2022-04-06 01:24:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 39
2022-04-06 01:24:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 38
2022-04-06 01:24:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 37
2022-04-06 01:24:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 36
2022-04-06 01:24:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 35
2022-04-06 01:24:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 34
2022-04-06 01:24:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 33
2022-04-06 01:24:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 32
2022-04-06 01:24:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 31
2022-04-06 01:24:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 30
2022-04-06 01:24:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 29
2022-04-06 01:24:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 28
2022-04-06 01:24:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 27
2022-04-06 01:24:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 26
2022-04-06 01:24:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 25
2022-04-06 01:24:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 24
2022-04-06 01:24:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 23
2022-04-06 01:24:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 22
2022-04-06 01:24:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 21
2022-04-06 01:24:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 20
2022-04-06 01:24:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 19
2022-04-06 01:24:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 18
2022-04-06 01:24:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 17
2022-04-06 01:24:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 16
2022-04-06 01:24:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 15
2022-04-06 01:24:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 14
2022-04-06 01:24:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 13
2022-04-06 01:24:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 12
2022-04-06 01:24:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 11
2022-04-06 01:24:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 10
2022-04-06 01:24:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 9
2022-04-06 01:24:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 8
2022-04-06 01:24:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 7
2022-04-06 01:24:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 6
2022-04-06 01:24:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 5
2022-04-06 01:24:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 4
2022-04-06 01:24:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 3
2022-04-06 01:24:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 2
2022-04-06 01:24:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 1
2022-04-06 01:24:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d022b201-kafka-0=74d8ec69-cf8b-4781-988e-1c43538ec542, my-cluster-d022b201-kafka-1=e065dc44-0ec9-41b4-88b7-2e255907b6d3, my-cluster-d022b201-kafka-2=68dba88b-5e55-47c3-a664-c08985555300} pods didn't roll. Remaining seconds for stability: 0
2022-04-06 01:24:57 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-d022b201-kafka rolling update
2022-04-06 01:26:37 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-d022b201-kafka has been successfully rolled
2022-04-06 01:26:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:26:40 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetKafkaExternalLogging
2022-04-06 01:26:40 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d022b201 in namespace namespace-86
2022-04-06 01:26:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 01:26:50 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-86 for test case:testDynamicallySetKafkaExternalLogging
2022-04-06 01:27:33 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetKafkaExternalLogging-FINISHED
2022-04-06 01:27:33 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 01:27:33 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 01:27:33 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testNotExistingCMSetsDefaultLogging-STARTED
2022-04-06 01:27:33 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 01:27:33 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-87 for test case:testNotExistingCMSetsDefaultLogging
2022-04-06 01:27:33 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-87
2022-04-06 01:27:33 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-87
2022-04-06 01:27:33 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-87
2022-04-06 01:27:33 [main] [32mINFO [m [TestUtils:197] /home/ec2-user/strimzi-kafka-operator/systemtest/../cluster-operator/src/main/resources/kafkaDefaultLoggingProperties
2022-04-06 01:27:33 [main] [32mINFO [m [LoggingChangeST:1320] Deploying Kafka with custom logging
2022-04-06 01:27:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-91706c32 in namespace namespace-87
2022-04-06 01:27:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-87
2022-04-06 01:27:33 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-91706c32 will have desired state: Ready
2022-04-06 01:28:49 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-91706c32 is in desired state: Ready
2022-04-06 01:28:49 [main] [32mINFO [m [LoggingChangeST:1344] Changing external logging's CM to not existing one
2022-04-06 01:28:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 50
2022-04-06 01:28:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 49
2022-04-06 01:28:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 48
2022-04-06 01:28:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 47
2022-04-06 01:28:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 46
2022-04-06 01:28:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 45
2022-04-06 01:28:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 44
2022-04-06 01:28:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 43
2022-04-06 01:28:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 42
2022-04-06 01:28:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 41
2022-04-06 01:29:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 40
2022-04-06 01:29:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 39
2022-04-06 01:29:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 38
2022-04-06 01:29:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 37
2022-04-06 01:29:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 36
2022-04-06 01:29:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 35
2022-04-06 01:29:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 34
2022-04-06 01:29:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 33
2022-04-06 01:29:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 32
2022-04-06 01:29:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 31
2022-04-06 01:29:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 30
2022-04-06 01:29:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 29
2022-04-06 01:29:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 28
2022-04-06 01:29:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 27
2022-04-06 01:29:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 26
2022-04-06 01:29:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 25
2022-04-06 01:29:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 24
2022-04-06 01:29:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 23
2022-04-06 01:29:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 22
2022-04-06 01:29:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 21
2022-04-06 01:29:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 20
2022-04-06 01:29:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 19
2022-04-06 01:29:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 18
2022-04-06 01:29:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 17
2022-04-06 01:29:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 16
2022-04-06 01:29:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 15
2022-04-06 01:29:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 14
2022-04-06 01:29:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 13
2022-04-06 01:29:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 12
2022-04-06 01:29:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 11
2022-04-06 01:29:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 10
2022-04-06 01:29:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 9
2022-04-06 01:29:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 8
2022-04-06 01:29:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 7
2022-04-06 01:29:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 6
2022-04-06 01:29:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 5
2022-04-06 01:29:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 4
2022-04-06 01:29:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 3
2022-04-06 01:29:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 2
2022-04-06 01:29:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 1
2022-04-06 01:29:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-91706c32-kafka-0=e2ad4e0a-5177-4e77-a432-e9074bead22c, my-cluster-91706c32-kafka-2=ecc74be9-9e14-4c74-b778-786cf67be1e7, my-cluster-91706c32-kafka-1=6c6c3c99-dd9a-4c5d-b68a-cbc26dd2620b} pods didn't roll. Remaining seconds for stability: 0
2022-04-06 01:29:40 [main] [32mINFO [m [LoggingChangeST:1358] Checking that log4j.properties in custom-config isn't empty and configuration is default
2022-04-06 01:29:40 [main] [32mINFO [m [LoggingChangeST:1366] Checking if Kafka:my-cluster-91706c32 contains error about non-existing CM
2022-04-06 01:29:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:29:40 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testNotExistingCMSetsDefaultLogging
2022-04-06 01:29:40 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-91706c32 in namespace namespace-87
2022-04-06 01:29:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 01:29:50 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-87 for test case:testNotExistingCMSetsDefaultLogging
2022-04-06 01:30:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testNotExistingCMSetsDefaultLogging-FINISHED
2022-04-06 01:30:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 01:30:17 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 01:30:17 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetConnectLoggingLevels-STARTED
2022-04-06 01:30:17 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 01:30:17 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-88 for test case:testDynamicallySetConnectLoggingLevels
2022-04-06 01:30:17 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-88
2022-04-06 01:30:17 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-88
2022-04-06 01:30:17 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-88
2022-04-06 01:30:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0014634b in namespace namespace-88
2022-04-06 01:30:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-88
2022-04-06 01:30:17 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0014634b will have desired state: Ready
2022-04-06 01:31:36 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0014634b is in desired state: Ready
2022-04-06 01:31:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-0014634b-scraper in namespace namespace-88
2022-04-06 01:31:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-88
2022-04-06 01:31:36 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-0014634b-scraper will be ready
2022-04-06 01:31:38 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-0014634b-scraper is ready
2022-04-06 01:31:38 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-0014634b-scraper to be ready
2022-04-06 01:31:48 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-0014634b-scraper is ready
2022-04-06 01:31:48 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-0014634b-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 01:31:48 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-0014634b-allow in namespace namespace-88
2022-04-06 01:31:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-88
2022-04-06 01:31:48 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 01:31:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-0014634b in namespace namespace-88
2022-04-06 01:31:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-88
2022-04-06 01:31:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-0014634b will have desired state: Ready
2022-04-06 01:32:53 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-0014634b is in desired state: Ready
2022-04-06 01:32:53 [main] [32mINFO [m [LoggingChangeST:703] Asserting if log is without records
2022-04-06 01:32:53 [main] [32mINFO [m [LoggingChangeST:706] Changing rootLogger level to DEBUG with inline logging
2022-04-06 01:32:53 [main] [32mINFO [m [LoggingChangeST:715] Waiting for log4j.properties will contain desired settings
2022-04-06 01:32:53 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-88 exec my-cluster-0014634b-scraper-5c788b595b-g4b5g -- curl http://my-cluster-0014634b-connect-api:8083/admin/loggers/root
2022-04-06 01:32:53 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:32:53 [main] [32mINFO [m [LoggingChangeST:760] Setting log level of Connect to OFF
2022-04-06 01:32:53 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-88 exec my-cluster-0014634b-scraper-5c788b595b-g4b5g -- curl http://my-cluster-0014634b-connect-api:8083/admin/loggers/root
2022-04-06 01:32:53 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:32:54 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-88 exec my-cluster-0014634b-scraper-5c788b595b-g4b5g -- curl http://my-cluster-0014634b-connect-api:8083/admin/loggers/root
2022-04-06 01:32:54 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:33:24 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:33:24 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetConnectLoggingLevels
2022-04-06 01:33:24 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-0014634b-allow in namespace namespace-88
2022-04-06 01:33:24 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-0014634b in namespace namespace-88
2022-04-06 01:33:24 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-0014634b-scraper in namespace namespace-88
2022-04-06 01:33:24 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0014634b in namespace namespace-88
2022-04-06 01:34:14 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 01:34:14 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-88 for test case:testDynamicallySetConnectLoggingLevels
2022-04-06 01:34:19 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetConnectLoggingLevels-FINISHED
2022-04-06 01:34:19 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 01:34:19 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 01:34:19 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testMM2LoggingLevelsHierarchy-STARTED
2022-04-06 01:34:19 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 01:34:19 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-89 for test case:testMM2LoggingLevelsHierarchy
2022-04-06 01:34:19 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-89
2022-04-06 01:34:19 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-89
2022-04-06 01:34:19 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-89
2022-04-06 01:34:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e0cfd1aa-source in namespace namespace-89
2022-04-06 01:34:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-89
2022-04-06 01:34:19 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e0cfd1aa-source will have desired state: Ready
2022-04-06 01:35:30 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e0cfd1aa-source is in desired state: Ready
2022-04-06 01:35:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e0cfd1aa-target in namespace namespace-89
2022-04-06 01:35:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-89
2022-04-06 01:35:30 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e0cfd1aa-target will have desired state: Ready
2022-04-06 01:36:47 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e0cfd1aa-target is in desired state: Ready
2022-04-06 01:36:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-e0cfd1aa-kafka-clients in namespace namespace-89
2022-04-06 01:36:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-89
2022-04-06 01:36:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-e0cfd1aa in namespace namespace-89
2022-04-06 01:36:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-89
2022-04-06 01:36:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-e0cfd1aa will have desired state: Ready
2022-04-06 01:37:51 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-e0cfd1aa is in desired state: Ready
2022-04-06 01:37:51 [main] [32mINFO [m [LoggingChangeST:1253] Waiting for log4j.properties will contain desired settings
2022-04-06 01:37:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e0cfd1aa-mirrormaker2-765f78989f-mqfcv -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:37:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:37:51 [main] [32mINFO [m [LoggingChangeST:1258] Changing log levels
2022-04-06 01:37:52 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e0cfd1aa-mirrormaker2-765f78989f-mqfcv -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:37:52 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:37:53 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e0cfd1aa-mirrormaker2-765f78989f-mqfcv -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:37:53 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:37:54 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e0cfd1aa-mirrormaker2-765f78989f-mqfcv -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:37:54 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:37:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e0cfd1aa-mirrormaker2-765f78989f-mqfcv -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:37:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:37:56 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e0cfd1aa-mirrormaker2-765f78989f-mqfcv -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:37:56 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:37:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e0cfd1aa-mirrormaker2-765f78989f-mqfcv -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:37:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:37:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e0cfd1aa-mirrormaker2-765f78989f-mqfcv -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:37:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:38:00 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e0cfd1aa-mirrormaker2-765f78989f-mqfcv -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:38:00 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:38:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e0cfd1aa-mirrormaker2-765f78989f-mqfcv -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:38:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:38:02 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e0cfd1aa-mirrormaker2-765f78989f-mqfcv -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:38:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:38:04 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e0cfd1aa-mirrormaker2-765f78989f-mqfcv -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:38:04 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:38:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e0cfd1aa-mirrormaker2-765f78989f-mqfcv -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:38:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:38:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e0cfd1aa-mirrormaker2-765f78989f-mqfcv -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:38:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:38:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e0cfd1aa-mirrormaker2-765f78989f-mqfcv -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:38:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:38:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e0cfd1aa-mirrormaker2-765f78989f-mqfcv -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:38:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:38:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e0cfd1aa-mirrormaker2-765f78989f-mqfcv -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:38:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:38:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e0cfd1aa-mirrormaker2-765f78989f-mqfcv -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:38:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:38:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e0cfd1aa-mirrormaker2-765f78989f-mqfcv -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:38:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:38:13 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e0cfd1aa-mirrormaker2-765f78989f-mqfcv -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:38:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:38:14 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e0cfd1aa-mirrormaker2-765f78989f-mqfcv -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:38:14 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:38:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e0cfd1aa-mirrormaker2-765f78989f-mqfcv -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:38:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:38:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e0cfd1aa-mirrormaker2-765f78989f-mqfcv -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:38:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:38:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e0cfd1aa-mirrormaker2-765f78989f-mqfcv -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:38:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:38:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e0cfd1aa-mirrormaker2-765f78989f-mqfcv -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:38:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:38:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e0cfd1aa-mirrormaker2-765f78989f-mqfcv -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:38:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:38:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e0cfd1aa-mirrormaker2-765f78989f-mqfcv -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:38:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:38:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e0cfd1aa-mirrormaker2-765f78989f-mqfcv -- curl http://localhost:8083/admin/loggers/org.eclipse.jetty.util.thread.strategy.EatWhatYouKill
2022-04-06 01:38:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:38:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e0cfd1aa-mirrormaker2-765f78989f-mqfcv -- curl http://localhost:8083/admin/loggers/org.apache.kafka.connect.runtime.WorkerTask
2022-04-06 01:38:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:38:22 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:38:22 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMM2LoggingLevelsHierarchy
2022-04-06 01:38:22 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-e0cfd1aa-kafka-clients in namespace namespace-89
2022-04-06 01:38:22 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-e0cfd1aa in namespace namespace-89
2022-04-06 01:38:22 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e0cfd1aa-source in namespace namespace-89
2022-04-06 01:38:22 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e0cfd1aa-target in namespace namespace-89
2022-04-06 01:39:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 01:39:12 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-89 for test case:testMM2LoggingLevelsHierarchy
2022-04-06 01:39:19 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testMM2LoggingLevelsHierarchy-FINISHED
2022-04-06 01:39:19 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 01:39:19 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 01:39:19 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testLoggingHierarchy-STARTED
2022-04-06 01:39:19 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 01:39:19 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-90 for test case:testLoggingHierarchy
2022-04-06 01:39:19 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-90
2022-04-06 01:39:19 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-90
2022-04-06 01:39:19 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-90
2022-04-06 01:39:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a8970e8a in namespace namespace-90
2022-04-06 01:39:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-90
2022-04-06 01:39:19 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a8970e8a will have desired state: Ready
2022-04-06 01:40:29 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a8970e8a is in desired state: Ready
2022-04-06 01:40:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a8970e8a-scraper in namespace namespace-90
2022-04-06 01:40:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-90
2022-04-06 01:40:29 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a8970e8a-scraper will be ready
2022-04-06 01:40:31 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a8970e8a-scraper is ready
2022-04-06 01:40:31 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-a8970e8a-scraper to be ready
2022-04-06 01:40:41 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-a8970e8a-scraper is ready
2022-04-06 01:40:41 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-a8970e8a-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 01:40:41 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-a8970e8a-allow in namespace namespace-90
2022-04-06 01:40:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-90
2022-04-06 01:40:41 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 01:40:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-a8970e8a in namespace namespace-90
2022-04-06 01:40:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-90
2022-04-06 01:40:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-a8970e8a in namespace namespace-90
2022-04-06 01:40:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-90
2022-04-06 01:40:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-a8970e8a will have desired state: Ready
2022-04-06 01:41:47 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-a8970e8a is in desired state: Ready
2022-04-06 01:41:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-a8970e8a will have desired state: Ready
2022-04-06 01:41:47 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-a8970e8a is in desired state: Ready
2022-04-06 01:41:47 [main] [32mINFO [m [LoggingChangeST:1398] Changing rootLogger level in KafkaConnector to ERROR with inline logging
2022-04-06 01:41:47 [main] [32mINFO [m [LoggingChangeST:1404] Waiting for Connect API loggers will contain desired settings
2022-04-06 01:41:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:41:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:41:47 [main] [32mINFO [m [LoggingChangeST:1410] Restarting Kafka connector my-cluster-a8970e8a with class name org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:41:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl -X POST http://my-cluster-a8970e8a-connect-api:8083/connectors/my-cluster-a8970e8a/restart
2022-04-06 01:41:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:41:48 [main] [32mINFO [m [KafkaConnectorUtils:168] Wait until KafkaConnector my-cluster-a8970e8a's worker will be in RUNNING state
2022-04-06 01:41:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl GET http://my-cluster-a8970e8a-connect-api:8083/connectors/my-cluster-a8970e8a/status
2022-04-06 01:41:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:41:48 [main] [32mINFO [m [LoggingChangeST:1417] Checking that logger is same for connector with class name org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:41:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:41:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:41:48 [main] [32mINFO [m [LoggingChangeST:1423] Changing KafkaConnect's root logger to WARN, KafkaConnector: my-cluster-a8970e8a shouldn't inherit it
2022-04-06 01:41:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/root
2022-04-06 01:41:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:41:48 [main] [32mINFO [m [LoggingChangeST:1437] Checking if KafkaConnector org.apache.kafka.connect.file.FileStreamSourceConnector doesn't inherit logger from KafkaConnect
2022-04-06 01:41:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:41:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:41:48 [main] [33mWARN [m [KafkaConnectorUtils:191] Logger level has changed: {"level":"WARN"}
. Reseting counter from 0 to 0
2022-04-06 01:41:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:41:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:41:50 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 49
2022-04-06 01:41:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:41:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:41:51 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 48
2022-04-06 01:41:52 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:41:52 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:41:52 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 47
2022-04-06 01:41:53 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:41:53 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:41:53 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 46
2022-04-06 01:41:54 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:41:54 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:41:54 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 45
2022-04-06 01:41:56 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:41:56 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:41:56 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 44
2022-04-06 01:41:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:41:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:41:57 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 43
2022-04-06 01:41:58 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:41:58 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:41:58 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 42
2022-04-06 01:41:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:41:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:41:59 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 41
2022-04-06 01:42:00 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:00 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:00 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 40
2022-04-06 01:42:02 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:02 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 39
2022-04-06 01:42:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:03 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 38
2022-04-06 01:42:04 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:04 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:04 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 37
2022-04-06 01:42:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:05 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 36
2022-04-06 01:42:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:06 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 35
2022-04-06 01:42:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:08 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 34
2022-04-06 01:42:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:09 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 33
2022-04-06 01:42:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:10 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 32
2022-04-06 01:42:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:11 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 31
2022-04-06 01:42:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:12 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 30
2022-04-06 01:42:13 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:13 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 29
2022-04-06 01:42:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:15 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 28
2022-04-06 01:42:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:16 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 27
2022-04-06 01:42:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:17 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 26
2022-04-06 01:42:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:18 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 25
2022-04-06 01:42:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:19 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 24
2022-04-06 01:42:21 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:21 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:21 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 23
2022-04-06 01:42:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:22 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 22
2022-04-06 01:42:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:23 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 21
2022-04-06 01:42:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:24 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 20
2022-04-06 01:42:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:25 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 19
2022-04-06 01:42:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:27 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 18
2022-04-06 01:42:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:28 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 17
2022-04-06 01:42:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:29 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 16
2022-04-06 01:42:30 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:30 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 15
2022-04-06 01:42:31 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:31 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:31 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 14
2022-04-06 01:42:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:33 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 13
2022-04-06 01:42:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:34 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 12
2022-04-06 01:42:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:35 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 11
2022-04-06 01:42:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:36 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 10
2022-04-06 01:42:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:37 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 9
2022-04-06 01:42:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:39 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 8
2022-04-06 01:42:40 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:40 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:40 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 7
2022-04-06 01:42:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:41 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 6
2022-04-06 01:42:42 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:42 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:42 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 5
2022-04-06 01:42:43 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:43 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:43 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 4
2022-04-06 01:42:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:45 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 3
2022-04-06 01:42:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:46 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 2
2022-04-06 01:42:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:47 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 1
2022-04-06 01:42:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-a8970e8a-scraper-6b99dcf6f-q7lqh -- curl http://my-cluster-a8970e8a-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:42:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:42:48 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 0
2022-04-06 01:42:48 [main] [32mINFO [m [KafkaConnectorUtils:196] Logger for connector org.apache.kafka.connect.file.FileStreamSourceConnector is stable
2022-04-06 01:42:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:42:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testLoggingHierarchy
2022-04-06 01:42:48 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-a8970e8a-allow in namespace namespace-90
2022-04-06 01:42:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a8970e8a-scraper in namespace namespace-90
2022-04-06 01:42:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-a8970e8a in namespace namespace-90
2022-04-06 01:42:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-a8970e8a in namespace namespace-90
2022-04-06 01:42:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a8970e8a in namespace namespace-90
2022-04-06 01:43:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 01:43:28 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-90 for test case:testLoggingHierarchy
2022-04-06 01:43:39 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testLoggingHierarchy-FINISHED
2022-04-06 01:43:39 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 01:43:39 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 01:43:39 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testJSONFormatLogging-STARTED
2022-04-06 01:43:39 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 01:43:39 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-91 for test case:testJSONFormatLogging
2022-04-06 01:43:39 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-91
2022-04-06 01:43:39 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-91
2022-04-06 01:43:39 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-91
2022-04-06 01:43:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e4d2f1b9 in namespace namespace-91
2022-04-06 01:43:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-91
2022-04-06 01:43:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e4d2f1b9 will have desired state: Ready
2022-04-06 01:45:00 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e4d2f1b9 is in desired state: Ready
2022-04-06 01:45:01 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: strimzi-cluster-operator-78689684d4-w429g
2022-04-06 01:45:01 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-e4d2f1b9-kafka-0
2022-04-06 01:45:01 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-e4d2f1b9-kafka-2
2022-04-06 01:45:01 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-e4d2f1b9-kafka-1
2022-04-06 01:45:01 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-e4d2f1b9-zookeeper-0
2022-04-06 01:45:01 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-e4d2f1b9-zookeeper-1
2022-04-06 01:45:01 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-e4d2f1b9-zookeeper-2
2022-04-06 01:45:01 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-e4d2f1b9-entity-operator-6675945475-2kc9l
2022-04-06 01:45:01 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-e4d2f1b9-entity-operator-6675945475-2kc9l
2022-04-06 01:45:01 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:45:01 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testJSONFormatLogging
2022-04-06 01:45:01 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e4d2f1b9 in namespace namespace-91
2022-04-06 01:45:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 01:45:11 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-91 for test case:testJSONFormatLogging
2022-04-06 01:45:55 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testJSONFormatLogging-FINISHED
2022-04-06 01:45:55 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 01:45:55 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 01:45:55 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetKafkaLoggingLevels-STARTED
2022-04-06 01:45:55 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 01:45:55 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-92 for test case:testDynamicallySetKafkaLoggingLevels
2022-04-06 01:45:55 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-92
2022-04-06 01:45:55 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-92
2022-04-06 01:45:55 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-92
2022-04-06 01:45:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a6452f75 in namespace namespace-92
2022-04-06 01:45:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-92
2022-04-06 01:45:55 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a6452f75 will have desired state: Ready
2022-04-06 01:47:04 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a6452f75 is in desired state: Ready
2022-04-06 01:47:04 [main] [32mINFO [m [LoggingChangeST:828] Changing rootLogger level to DEBUG with inline logging
2022-04-06 01:47:04 [main] [32mINFO [m [LoggingChangeST:835] Waiting for dynamic change in the kafka pod
2022-04-06 01:47:07 [main] [32mINFO [m [LoggingChangeST:853] Setting external logging INFO
2022-04-06 01:47:07 [main] [32mINFO [m [LoggingChangeST:889] Setting log level of kafka INFO
2022-04-06 01:47:07 [main] [32mINFO [m [LoggingChangeST:895] Waiting for dynamic change in the kafka pod
2022-04-06 01:47:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:47:10 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetKafkaLoggingLevels
2022-04-06 01:47:10 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a6452f75 in namespace namespace-92
2022-04-06 01:47:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 01:47:21 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-92 for test case:testDynamicallySetKafkaLoggingLevels
2022-04-06 01:48:04 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetKafkaLoggingLevels-FINISHED
2022-04-06 01:48:04 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 01:48:04 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 01:48:04 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetEOloggingLevels-STARTED
2022-04-06 01:48:04 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 01:48:04 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-93 for test case:testDynamicallySetEOloggingLevels
2022-04-06 01:48:04 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-93
2022-04-06 01:48:04 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-93
2022-04-06 01:48:04 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-93
2022-04-06 01:48:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-6cfbe075 in namespace namespace-93
2022-04-06 01:48:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-93
2022-04-06 01:48:04 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-6cfbe075 will have desired state: Ready
2022-04-06 01:49:10 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-6cfbe075 is in desired state: Ready
2022-04-06 01:49:10 [main] [32mINFO [m [LoggingChangeST:285] Checking if EO pod contains any log (except configuration)
2022-04-06 01:49:10 [main] [32mINFO [m [LoggingChangeST:288] Changing rootLogger level to DEBUG with inline logging
2022-04-06 01:49:10 [main] [32mINFO [m [LoggingChangeST:296] Waiting for log4j2.properties will contain desired settings
2022-04-06 01:50:27 [main] [32mINFO [m [LoggingChangeST:313] Setting external logging OFF
2022-04-06 01:50:27 [main] [32mINFO [m [LoggingChangeST:371] Setting log level of TO and UO to OFF - records should not appear in log
2022-04-06 01:50:27 [main] [32mINFO [m [LoggingChangeST:378] Waiting for log4j2.properties will contain desired settings
2022-04-06 01:52:21 [main] [32mINFO [m [LoggingChangeST:396] Setting external logging OFF
2022-04-06 01:52:21 [main] [32mINFO [m [LoggingChangeST:432] Waiting for log4j2.properties will contain desired settings
2022-04-06 01:52:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:52:56 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetEOloggingLevels
2022-04-06 01:52:56 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-6cfbe075 in namespace namespace-93
2022-04-06 01:53:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 01:53:06 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-93 for test case:testDynamicallySetEOloggingLevels
2022-04-06 01:53:33 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetEOloggingLevels-FINISHED
2022-04-06 01:53:33 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 01:53:33 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 01:53:33 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetUnknownKafkaLoggerValue-STARTED
2022-04-06 01:53:33 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 01:53:33 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-94 for test case:testDynamicallySetUnknownKafkaLoggerValue
2022-04-06 01:53:33 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-94
2022-04-06 01:53:33 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-94
2022-04-06 01:53:33 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-94
2022-04-06 01:53:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5602eaac in namespace namespace-94
2022-04-06 01:53:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-94
2022-04-06 01:53:33 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5602eaac will have desired state: Ready
2022-04-06 01:54:46 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5602eaac is in desired state: Ready
2022-04-06 01:54:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 50
2022-04-06 01:54:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 49
2022-04-06 01:54:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 48
2022-04-06 01:54:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 47
2022-04-06 01:54:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 46
2022-04-06 01:54:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 45
2022-04-06 01:54:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 44
2022-04-06 01:54:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 43
2022-04-06 01:54:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 42
2022-04-06 01:54:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 41
2022-04-06 01:54:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 40
2022-04-06 01:54:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 39
2022-04-06 01:54:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 38
2022-04-06 01:54:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 37
2022-04-06 01:55:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 36
2022-04-06 01:55:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 35
2022-04-06 01:55:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 34
2022-04-06 01:55:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 33
2022-04-06 01:55:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 32
2022-04-06 01:55:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 31
2022-04-06 01:55:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 30
2022-04-06 01:55:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 29
2022-04-06 01:55:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 28
2022-04-06 01:55:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 27
2022-04-06 01:55:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 26
2022-04-06 01:55:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 25
2022-04-06 01:55:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 24
2022-04-06 01:55:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 23
2022-04-06 01:55:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 22
2022-04-06 01:55:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 21
2022-04-06 01:55:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 20
2022-04-06 01:55:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 19
2022-04-06 01:55:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 18
2022-04-06 01:55:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 17
2022-04-06 01:55:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 16
2022-04-06 01:55:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 15
2022-04-06 01:55:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 14
2022-04-06 01:55:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 13
2022-04-06 01:55:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 12
2022-04-06 01:55:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 11
2022-04-06 01:55:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 10
2022-04-06 01:55:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 9
2022-04-06 01:55:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 8
2022-04-06 01:55:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 7
2022-04-06 01:55:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 6
2022-04-06 01:55:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 5
2022-04-06 01:55:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 4
2022-04-06 01:55:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 3
2022-04-06 01:55:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 2
2022-04-06 01:55:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 1
2022-04-06 01:55:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-5602eaac-kafka-0=af499135-dea7-4963-9518-3b26d6b9a659, my-cluster-5602eaac-kafka-1=d3344a17-97d3-4ef0-b1b8-57b9122500b3, my-cluster-5602eaac-kafka-2=aafeabed-7e0c-452e-a0f2-23b4d7314d6d} pods didn't roll. Remaining seconds for stability: 0
2022-04-06 01:55:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:55:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetUnknownKafkaLoggerValue
2022-04-06 01:55:36 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5602eaac in namespace namespace-94
2022-04-06 01:55:46 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 01:55:46 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-94 for test case:testDynamicallySetUnknownKafkaLoggerValue
2022-04-06 01:56:13 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetUnknownKafkaLoggerValue-FINISHED
2022-04-06 01:56:13 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 01:56:13 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 01:56:13 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetBridgeLoggingLevels-STARTED
2022-04-06 01:56:13 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 01:56:13 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-95 for test case:testDynamicallySetBridgeLoggingLevels
2022-04-06 01:56:13 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-95
2022-04-06 01:56:13 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-95
2022-04-06 01:56:13 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-95
2022-04-06 01:56:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b3ec1412 in namespace namespace-95
2022-04-06 01:56:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-95
2022-04-06 01:56:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b3ec1412-kafka-clients in namespace namespace-95
2022-04-06 01:56:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-95
2022-04-06 01:56:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge my-cluster-b3ec1412 in namespace namespace-95
2022-04-06 01:56:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-95
2022-04-06 01:56:13 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b3ec1412 will have desired state: Ready
2022-04-06 01:57:17 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b3ec1412 is in desired state: Ready
2022-04-06 01:57:17 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b3ec1412-kafka-clients will be ready
2022-04-06 01:57:17 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b3ec1412-kafka-clients is ready
2022-04-06 01:57:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: my-cluster-b3ec1412 will have desired state: Ready
2022-04-06 01:57:17 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: my-cluster-b3ec1412 is in desired state: Ready
2022-04-06 01:57:17 [main] [32mINFO [m [LoggingChangeST:485] Asserting if log is without records
2022-04-06 01:57:17 [main] [32mINFO [m [LoggingChangeST:488] Changing rootLogger level to DEBUG with inline logging
2022-04-06 01:57:17 [main] [32mINFO [m [LoggingChangeST:500] Waiting for log4j2.properties will contain desired settings
2022-04-06 01:58:23 [main] [32mINFO [m [LoggingChangeST:557] Setting log level of Bridge to OFF - records should not appear in the log
2022-04-06 01:58:23 [main] [32mINFO [m [LoggingChangeST:563] Waiting for log4j2.properties will contain desired settings
2022-04-06 02:00:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:00:23 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetBridgeLoggingLevels
2022-04-06 02:00:23 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b3ec1412-kafka-clients in namespace namespace-95
2022-04-06 02:00:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge my-cluster-b3ec1412 in namespace namespace-95
2022-04-06 02:00:23 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b3ec1412 in namespace namespace-95
2022-04-06 02:01:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:01:13 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-95 for test case:testDynamicallySetBridgeLoggingLevels
2022-04-06 02:01:18 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetBridgeLoggingLevels-FINISHED
2022-04-06 02:01:18 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 02:01:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 02:01:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetMM2LoggingLevels-STARTED
2022-04-06 02:01:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 02:01:18 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-96 for test case:testDynamicallySetMM2LoggingLevels
2022-04-06 02:01:18 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-96
2022-04-06 02:01:18 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-96
2022-04-06 02:01:18 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-96
2022-04-06 02:01:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ca1900a6-source in namespace namespace-96
2022-04-06 02:01:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-96
2022-04-06 02:01:18 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ca1900a6-source will have desired state: Ready
2022-04-06 02:02:32 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ca1900a6-source is in desired state: Ready
2022-04-06 02:02:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ca1900a6-target in namespace namespace-96
2022-04-06 02:02:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-96
2022-04-06 02:02:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ca1900a6-target will have desired state: Ready
2022-04-06 02:03:50 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ca1900a6-target is in desired state: Ready
2022-04-06 02:03:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-ca1900a6-kafka-clients in namespace namespace-96
2022-04-06 02:03:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-96
2022-04-06 02:03:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-ca1900a6 in namespace namespace-96
2022-04-06 02:03:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-96
2022-04-06 02:03:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-ca1900a6 will have desired state: Ready
2022-04-06 02:04:57 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-ca1900a6 is in desired state: Ready
2022-04-06 02:04:57 [main] [32mINFO [m [LoggingChangeST:1123] Changing rootLogger level to DEBUG with inline logging
2022-04-06 02:04:57 [main] [32mINFO [m [LoggingChangeST:1132] Waiting for log4j.properties will contain desired settings
2022-04-06 02:04:58 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-96 exec my-cluster-ca1900a6-mirrormaker2-86d9f6b9-q5v9w -- curl http://localhost:8083/admin/loggers/root
2022-04-06 02:04:58 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 02:04:58 [main] [32mINFO [m [LoggingChangeST:1176] Setting log level of MM2 to OFF
2022-04-06 02:04:58 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-96 exec my-cluster-ca1900a6-mirrormaker2-86d9f6b9-q5v9w -- curl http://localhost:8083/admin/loggers/root
2022-04-06 02:04:58 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 02:04:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-96 exec my-cluster-ca1900a6-mirrormaker2-86d9f6b9-q5v9w -- curl http://localhost:8083/admin/loggers/root
2022-04-06 02:04:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 02:05:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:05:00 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetMM2LoggingLevels
2022-04-06 02:05:00 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-ca1900a6-kafka-clients in namespace namespace-96
2022-04-06 02:05:00 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ca1900a6-target in namespace namespace-96
2022-04-06 02:05:00 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-ca1900a6 in namespace namespace-96
2022-04-06 02:05:00 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ca1900a6-source in namespace namespace-96
2022-04-06 02:05:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:05:50 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-96 for test case:testDynamicallySetMM2LoggingLevels
2022-04-06 02:05:56 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetMM2LoggingLevels-FINISHED
2022-04-06 02:05:56 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 02:05:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:05:56 [main] [32mINFO [m [ResourceManager:346] In context LoggingChangeST is everything deleted.
2022-04-06 02:05:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2,958.006 s - in io.strimzi.systemtest.log.LoggingChangeST
[[1;34mINFO[m] Running io.strimzi.systemtest.log.LogSettingST
2022-04-06 02:06:02 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: log-setting-st
2022-04-06 02:06:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: log-setting-st
2022-04-06 02:06:02 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: log-setting-st
2022-04-06 02:06:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka log-setting-cluster-name in namespace log-setting-st
2022-04-06 02:06:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka gc-set-logging in namespace log-setting-st
2022-04-06 02:06:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment shared-kafka-clients in namespace log-setting-st
2022-04-06 02:06:02 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: log-setting-cluster-name will have desired state: Ready
2022-04-06 02:08:18 [main] [32mINFO [m [ResourceManager:444] Kafka: log-setting-cluster-name is in desired state: Ready
2022-04-06 02:08:18 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: gc-set-logging will have desired state: Ready
2022-04-06 02:08:18 [main] [32mINFO [m [ResourceManager:444] Kafka: gc-set-logging is in desired state: Ready
2022-04-06 02:08:18 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: shared-kafka-clients will be ready
2022-04-06 02:08:18 [main] [32mINFO [m [DeploymentUtils:168] Deployment: shared-kafka-clients is ready
2022-04-06 02:08:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 02:08:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LogSettingST.testMirrorMaker2LogSetting-STARTED
2022-04-06 02:08:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 02:08:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-1a754a61-mirror-maker-2 in namespace log-setting-st
2022-04-06 02:08:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-1a754a61-mirror-maker-2 will have desired state: Ready
2022-04-06 02:09:28 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-1a754a61-mirror-maker-2 is in desired state: Ready
2022-04-06 02:09:28 [main] [32mINFO [m [LogSettingST:357] Checking if MirrorMaker2 has log level set properly
2022-04-06 02:09:28 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: mirrormaker.root.logger Expected: TRACE
2022-04-06 02:09:28 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.mirrormaker.logger.level Expected: TRACE
2022-04-06 02:09:28 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-1a754a61-mirror-maker-2-mirrormaker2
2022-04-06 02:09:28 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-1a754a61-mirror-maker-2-mirrormaker2
2022-04-06 02:09:28 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-06 02:09:28 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-1a754a61-mirror-maker-2-mirrormaker2 rolling update
2022-04-06 02:10:49 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1a754a61-mirror-maker-2-mirrormaker2 will be ready
2022-04-06 02:10:49 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1a754a61-mirror-maker-2-mirrormaker2 is ready
2022-04-06 02:10:59 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-1a754a61-mirror-maker-2-mirrormaker2 rolling update finished
2022-04-06 02:10:59 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-1a754a61-mirror-maker-2-mirrormaker2
2022-04-06 02:10:59 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-1a754a61-mirror-maker-2-mirrormaker2
2022-04-06 02:10:59 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-06 02:10:59 [main] [32mINFO [m [PodUtils:343] Waiting for Pod my-cluster-1a754a61-mirror-maker-2-mirrormaker2-9cc78b567-n2psc container my-cluster-1a754a61-mirror-maker-2-mirrormaker2 will be ready
2022-04-06 02:10:59 [main] [32mINFO [m [PodUtils:347] Pod my-cluster-1a754a61-mirror-maker-2-mirrormaker2-9cc78b567-n2psc container my-cluster-1a754a61-mirror-maker-2-mirrormaker2 is ready
2022-04-06 02:10:59 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod my-cluster-1a754a61-mirror-maker-2-mirrormaker2-9cc78b567-n2psc with container my-cluster-1a754a61-mirror-maker-2-mirrormaker2
2022-04-06 02:10:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:10:59 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker2LogSetting
2022-04-06 02:10:59 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-1a754a61-mirror-maker-2 in namespace log-setting-st
2022-04-06 02:11:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:11:09 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LogSettingST.testMirrorMaker2LogSetting-FINISHED
2022-04-06 02:11:09 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 02:11:09 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 02:11:09 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LogSettingST.testCruiseControlLogChange-STARTED
2022-04-06 02:11:09 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 02:11:09 [main] [32mINFO [m [LogSettingST:409] Check that default/actual root logging level is info
2022-04-06 02:11:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-7588db9f8b-bglzz -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-06 02:11:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 02:11:09 [main] [32mINFO [m [LogSettingST:414] Check logs in CruiseControl - make sure no DEBUG is found there.
2022-04-06 02:11:10 [main] [32mINFO [m [LogSettingST:422] Wait for change of root logger in log-setting-cluster-name-cruise-control-7588db9f8b-bglzz.
2022-04-06 02:11:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-7588db9f8b-bglzz -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-06 02:11:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 02:11:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-7588db9f8b-bglzz -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-06 02:11:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 02:11:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-7588db9f8b-bglzz -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-06 02:11:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 02:11:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-7588db9f8b-bglzz -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-06 02:11:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 02:11:31 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-7588db9f8b-bglzz -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-06 02:11:31 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 02:11:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-7588db9f8b-bglzz -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-06 02:11:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 02:11:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-7588db9f8b-bglzz -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-06 02:11:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 02:11:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-7588db9f8b-bglzz -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-06 02:11:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 02:11:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-7588db9f8b-bglzz -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-06 02:11:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 02:11:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-7588db9f8b-bglzz -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-06 02:11:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 02:12:02 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-7588db9f8b-bglzz -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-06 02:12:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 02:12:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-7588db9f8b-bglzz -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-06 02:12:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 02:12:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-7588db9f8b-bglzz -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-06 02:12:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 02:12:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-7588db9f8b-bglzz -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-06 02:12:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 02:12:17 [main] [32mINFO [m [LogSettingST:428] Check cruise control logs in pod log-setting-cluster-name-cruise-control-7588db9f8b-bglzz and it's container cruise-control .
2022-04-06 02:12:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:12:48 [main] [32mINFO [m [ResourceManager:346] In context testCruiseControlLogChange is everything deleted.
2022-04-06 02:12:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:12:48 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LogSettingST.testCruiseControlLogChange-FINISHED
2022-04-06 02:12:48 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 02:12:48 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 02:12:48 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LogSettingST.testMirrorMakerLogSetting-STARTED
2022-04-06 02:12:48 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 02:12:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-0f37501e-mirror-maker in namespace log-setting-st
2022-04-06 02:12:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-0f37501e-mirror-maker will have desired state: Ready
2022-04-06 02:13:50 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-0f37501e-mirror-maker is in desired state: Ready
2022-04-06 02:13:50 [main] [32mINFO [m [LogSettingST:322] Checking if MirrorMaker has log level set properly
2022-04-06 02:13:50 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: mirrormaker.root.logger Expected: TRACE
2022-04-06 02:13:50 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.mirrormaker.logger.level Expected: TRACE
2022-04-06 02:13:50 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-0f37501e-mirror-maker-mirror-maker
2022-04-06 02:13:50 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-0f37501e-mirror-maker-mirror-maker
2022-04-06 02:13:50 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-06 02:13:50 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-0f37501e-mirror-maker-mirror-maker rolling update
2022-04-06 02:15:06 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-0f37501e-mirror-maker-mirror-maker will be ready
2022-04-06 02:15:06 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-0f37501e-mirror-maker-mirror-maker is ready
2022-04-06 02:15:16 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-0f37501e-mirror-maker-mirror-maker rolling update finished
2022-04-06 02:15:16 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-0f37501e-mirror-maker-mirror-maker
2022-04-06 02:15:16 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-0f37501e-mirror-maker-mirror-maker
2022-04-06 02:15:16 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-06 02:15:16 [main] [32mINFO [m [PodUtils:343] Waiting for Pod my-cluster-0f37501e-mirror-maker-mirror-maker-66fb448cdc-wwds5 container my-cluster-0f37501e-mirror-maker-mirror-maker will be ready
2022-04-06 02:15:16 [main] [32mINFO [m [PodUtils:347] Pod my-cluster-0f37501e-mirror-maker-mirror-maker-66fb448cdc-wwds5 container my-cluster-0f37501e-mirror-maker-mirror-maker is ready
2022-04-06 02:15:16 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod my-cluster-0f37501e-mirror-maker-mirror-maker-66fb448cdc-wwds5 with container my-cluster-0f37501e-mirror-maker-mirror-maker
2022-04-06 02:15:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:15:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMakerLogSetting
2022-04-06 02:15:16 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-0f37501e-mirror-maker in namespace log-setting-st
2022-04-06 02:15:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:15:26 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LogSettingST.testMirrorMakerLogSetting-FINISHED
2022-04-06 02:15:26 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 02:15:26 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 02:15:26 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LogSettingST.testConnectLogSetting-STARTED
2022-04-06 02:15:26 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 02:15:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-7da3229d-connect-scraper in namespace log-setting-st
2022-04-06 02:15:26 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7da3229d-connect-scraper will be ready
2022-04-06 02:15:28 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7da3229d-connect-scraper is ready
2022-04-06 02:15:28 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-7da3229d-connect-scraper to be ready
2022-04-06 02:15:38 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-7da3229d-connect-scraper is ready
2022-04-06 02:15:38 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-7da3229d-connect-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 02:15:38 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-7da3229d-connect-allow in namespace log-setting-st
2022-04-06 02:15:38 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 02:15:38 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-7da3229d-connect in namespace log-setting-st
2022-04-06 02:15:38 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-7da3229d-connect will have desired state: Ready
2022-04-06 02:16:46 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-7da3229d-connect is in desired state: Ready
2022-04-06 02:16:46 [main] [32mINFO [m [LogSettingST:287] Checking if Connect has log level set properly
2022-04-06 02:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.org.I0Itec.zkclient Expected: ERROR
2022-04-06 02:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: connect.root.logger.level Expected: INFO
2022-04-06 02:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.connect.logger.level Expected: DEBUG
2022-04-06 02:16:46 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.org.reflections Expected: WARN
2022-04-06 02:16:46 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-7da3229d-connect-connect
2022-04-06 02:16:46 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-7da3229d-connect-connect
2022-04-06 02:16:46 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-06 02:16:46 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-7da3229d-connect-connect rolling update
2022-04-06 02:17:56 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7da3229d-connect-connect will be ready
2022-04-06 02:17:56 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7da3229d-connect-connect is ready
2022-04-06 02:18:06 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-7da3229d-connect-connect rolling update finished
2022-04-06 02:18:06 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-7da3229d-connect-connect
2022-04-06 02:18:06 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-7da3229d-connect-connect
2022-04-06 02:18:06 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-06 02:18:06 [main] [32mINFO [m [PodUtils:343] Waiting for Pod my-cluster-7da3229d-connect-connect-7cccc9856b-bc6l2 container my-cluster-7da3229d-connect-connect will be ready
2022-04-06 02:18:06 [main] [32mINFO [m [PodUtils:347] Pod my-cluster-7da3229d-connect-connect-7cccc9856b-bc6l2 container my-cluster-7da3229d-connect-connect is ready
2022-04-06 02:18:06 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod my-cluster-7da3229d-connect-connect-7cccc9856b-bc6l2 with container my-cluster-7da3229d-connect-connect
2022-04-06 02:18:06 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:18:06 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConnectLogSetting
2022-04-06 02:18:06 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-7da3229d-connect-allow in namespace log-setting-st
2022-04-06 02:18:06 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-7da3229d-connect in namespace log-setting-st
2022-04-06 02:18:06 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-7da3229d-connect-scraper in namespace log-setting-st
2022-04-06 02:18:46 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:18:46 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LogSettingST.testConnectLogSetting-FINISHED
2022-04-06 02:18:46 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 02:18:46 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 02:18:46 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LogSettingST.testKafkaLogSetting-STARTED
2022-04-06 02:18:46 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 02:18:46 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-867237584-1790498779 in namespace log-setting-st
2022-04-06 02:18:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-867237584-1790498779 will have desired state: Ready
2022-04-06 02:18:48 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-867237584-1790498779 is in desired state: Ready
2022-04-06 02:18:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1670677896-656267100 in namespace log-setting-st
2022-04-06 02:18:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1670677896-656267100 will have desired state: Ready
2022-04-06 02:18:49 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1670677896-656267100 is in desired state: Ready
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:217] Checking if Kafka, Zookeeper, TO and UO of cluster:log-setting-cluster-name has log level set properly
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.org.apache.zookeeper Expected: WARN
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.network.Processor Expected: OFF
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.request.logger Expected: FATAL
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.controller Expected: WARN
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: kafka.root.logger.level Expected: INFO
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.state.change.logger Expected: DEBUG
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.network.RequestChannel$ Expected: ERROR
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.server.KafkaApis Expected: INFO
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka Expected: TRACE
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.org.apache.kafka Expected: DEBUG
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.authorizer.logger Expected: FATAL
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.log.LogCleaner Expected: TRACE
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.org.I0Itec.zkclient.ZkClient Expected: ERROR
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.kafka.logger.level Expected: INFO
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: zookeeper.root.logger Expected: OFF
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.zookeeper.logger.level Expected: DEBUG
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: rootLogger.level Expected: DEBUG
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.operator.logger.level Expected: DEBUG
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: rootLogger.level Expected: DEBUG
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.operator.logger.level Expected: DEBUG
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:226] Checking if Kafka, Zookeeper, TO and UO of cluster:log-setting-cluster-name has GC logging enabled in stateful sets/deployments
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:512] Checking pods with selector: LabelSelector(matchExpressions=[], matchLabels={strimzi.io/name=log-setting-cluster-name-kafka, strimzi.io/cluster=log-setting-cluster-name, strimzi.io/kind=Kafka}, additionalProperties={})
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-0, container: kafka
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-1, container: kafka
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-2, container: kafka
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:512] Checking pods with selector: LabelSelector(matchExpressions=[], matchLabels={strimzi.io/name=log-setting-cluster-name-zookeeper, strimzi.io/cluster=log-setting-cluster-name, strimzi.io/kind=Kafka}, additionalProperties={})
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-zookeeper-0, container: zookeeper
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:490] Checking deployment: log-setting-cluster-name-entity-operator
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:493] Checking container with name: topic-operator
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=true
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:490] Checking deployment: log-setting-cluster-name-entity-operator
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:493] Checking container with name: user-operator
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=true
2022-04-06 02:18:49 [main] [32mINFO [m [LogSettingST:232] Changing JVM options - setting GC logging to false
2022-04-06 02:18:49 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: log-setting-cluster-name-zookeeper rolling update
2022-04-06 02:18:54 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: log-setting-cluster-name-zookeeper has been successfully rolled
2022-04-06 02:18:54 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 1 Pod(s) of log-setting-cluster-name-zookeeper to be ready
2022-04-06 02:19:20 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: log-setting-cluster-name-kafka rolling update
2022-04-06 02:20:46 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: log-setting-cluster-name-kafka has been successfully rolled
2022-04-06 02:20:46 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of log-setting-cluster-name-kafka to be ready
2022-04-06 02:21:19 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment log-setting-cluster-name-entity-operator rolling update
2022-04-06 02:21:19 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: log-setting-cluster-name-entity-operator will be ready
2022-04-06 02:22:51 [main] [32mINFO [m [DeploymentUtils:168] Deployment: log-setting-cluster-name-entity-operator is ready
2022-04-06 02:23:01 [main] [32mINFO [m [DeploymentUtils:141] Deployment log-setting-cluster-name-entity-operator rolling update finished
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:244] Checking if Kafka, Zookeeper, TO and UO of cluster: log-setting-cluster-name has GC logging disabled in stateful sets/deployments
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:512] Checking pods with selector: LabelSelector(matchExpressions=[], matchLabels={strimzi.io/name=log-setting-cluster-name-kafka, strimzi.io/cluster=log-setting-cluster-name, strimzi.io/kind=Kafka}, additionalProperties={})
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-0, container: kafka
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-1, container: kafka
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-2, container: kafka
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:512] Checking pods with selector: LabelSelector(matchExpressions=[], matchLabels={strimzi.io/name=log-setting-cluster-name-zookeeper, strimzi.io/cluster=log-setting-cluster-name, strimzi.io/kind=Kafka}, additionalProperties={})
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-zookeeper-0, container: zookeeper
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:490] Checking deployment: log-setting-cluster-name-entity-operator
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:493] Checking container with name: topic-operator
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=false
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:490] Checking deployment: log-setting-cluster-name-entity-operator
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:493] Checking container with name: user-operator
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=false
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:250] Checking if Kafka, Zookeeper, TO and UO of cluster: gc-set-logging has GC logging disabled in stateful sets/deployments
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:512] Checking pods with selector: LabelSelector(matchExpressions=[], matchLabels={strimzi.io/name=log-setting-cluster-name-kafka, strimzi.io/cluster=log-setting-cluster-name, strimzi.io/kind=Kafka}, additionalProperties={})
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-0, container: kafka
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-1, container: kafka
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-2, container: kafka
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:512] Checking pods with selector: LabelSelector(matchExpressions=[], matchLabels={strimzi.io/name=log-setting-cluster-name-zookeeper, strimzi.io/cluster=log-setting-cluster-name, strimzi.io/kind=Kafka}, additionalProperties={})
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-zookeeper-0, container: zookeeper
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:490] Checking deployment: log-setting-cluster-name-entity-operator
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:493] Checking container with name: topic-operator
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=false
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:490] Checking deployment: log-setting-cluster-name-entity-operator
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:493] Checking container with name: user-operator
2022-04-06 02:23:01 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=false
2022-04-06 02:23:02 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-cruise-control-7588db9f8b-bglzz container cruise-control will be ready
2022-04-06 02:23:02 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-cruise-control-7588db9f8b-bglzz container cruise-control is ready
2022-04-06 02:23:02 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-cruise-control-7588db9f8b-bglzz with container cruise-control
2022-04-06 02:23:02 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-cruise-control-7588db9f8b-bglzz container tls-sidecar will be ready
2022-04-06 02:23:02 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-cruise-control-7588db9f8b-bglzz container tls-sidecar is ready
2022-04-06 02:23:02 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-cruise-control-7588db9f8b-bglzz with container tls-sidecar
2022-04-06 02:23:02 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-entity-operator-d78c874cf-6hvf8 container topic-operator will be ready
2022-04-06 02:23:02 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-entity-operator-d78c874cf-6hvf8 container topic-operator is ready
2022-04-06 02:23:02 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-entity-operator-d78c874cf-6hvf8 with container topic-operator
2022-04-06 02:23:02 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-entity-operator-d78c874cf-6hvf8 container user-operator will be ready
2022-04-06 02:23:02 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-entity-operator-d78c874cf-6hvf8 container user-operator is ready
2022-04-06 02:23:02 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-entity-operator-d78c874cf-6hvf8 with container user-operator
2022-04-06 02:23:02 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-entity-operator-d78c874cf-6hvf8 container tls-sidecar will be ready
2022-04-06 02:23:02 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-entity-operator-d78c874cf-6hvf8 container tls-sidecar is ready
2022-04-06 02:23:02 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-entity-operator-d78c874cf-6hvf8 with container tls-sidecar
2022-04-06 02:23:03 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-kafka-0 container kafka will be ready
2022-04-06 02:23:03 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-kafka-0 container kafka is ready
2022-04-06 02:23:03 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-kafka-0 with container kafka
2022-04-06 02:23:03 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-kafka-1 container kafka will be ready
2022-04-06 02:23:03 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-kafka-1 container kafka is ready
2022-04-06 02:23:03 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-kafka-1 with container kafka
2022-04-06 02:23:03 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-kafka-2 container kafka will be ready
2022-04-06 02:23:03 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-kafka-2 container kafka is ready
2022-04-06 02:23:03 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-kafka-2 with container kafka
2022-04-06 02:23:03 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-kafka-exporter-7b59f7cd48-q45d2 container log-setting-cluster-name-kafka-exporter will be ready
2022-04-06 02:23:03 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-kafka-exporter-7b59f7cd48-q45d2 container log-setting-cluster-name-kafka-exporter is ready
2022-04-06 02:23:03 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-kafka-exporter-7b59f7cd48-q45d2 with container log-setting-cluster-name-kafka-exporter
2022-04-06 02:23:03 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-zookeeper-0 container zookeeper will be ready
2022-04-06 02:23:03 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-zookeeper-0 container zookeeper is ready
2022-04-06 02:23:03 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-zookeeper-0 with container zookeeper
2022-04-06 02:23:04 [main] [32mINFO [m [PodUtils:343] Waiting for Pod gc-set-logging-entity-operator-6dccd5cb65-ksc4r container topic-operator will be ready
2022-04-06 02:23:04 [main] [32mINFO [m [PodUtils:347] Pod gc-set-logging-entity-operator-6dccd5cb65-ksc4r container topic-operator is ready
2022-04-06 02:23:04 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod gc-set-logging-entity-operator-6dccd5cb65-ksc4r with container topic-operator
2022-04-06 02:23:04 [main] [32mINFO [m [PodUtils:343] Waiting for Pod gc-set-logging-entity-operator-6dccd5cb65-ksc4r container user-operator will be ready
2022-04-06 02:23:04 [main] [32mINFO [m [PodUtils:347] Pod gc-set-logging-entity-operator-6dccd5cb65-ksc4r container user-operator is ready
2022-04-06 02:23:04 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod gc-set-logging-entity-operator-6dccd5cb65-ksc4r with container user-operator
2022-04-06 02:23:04 [main] [32mINFO [m [PodUtils:343] Waiting for Pod gc-set-logging-entity-operator-6dccd5cb65-ksc4r container tls-sidecar will be ready
2022-04-06 02:23:04 [main] [32mINFO [m [PodUtils:347] Pod gc-set-logging-entity-operator-6dccd5cb65-ksc4r container tls-sidecar is ready
2022-04-06 02:23:04 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod gc-set-logging-entity-operator-6dccd5cb65-ksc4r with container tls-sidecar
2022-04-06 02:23:04 [main] [32mINFO [m [PodUtils:343] Waiting for Pod gc-set-logging-kafka-0 container kafka will be ready
2022-04-06 02:23:04 [main] [32mINFO [m [PodUtils:347] Pod gc-set-logging-kafka-0 container kafka is ready
2022-04-06 02:23:04 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod gc-set-logging-kafka-0 with container kafka
2022-04-06 02:23:04 [main] [32mINFO [m [PodUtils:343] Waiting for Pod gc-set-logging-zookeeper-0 container zookeeper will be ready
2022-04-06 02:23:04 [main] [32mINFO [m [PodUtils:347] Pod gc-set-logging-zookeeper-0 container zookeeper is ready
2022-04-06 02:23:04 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod gc-set-logging-zookeeper-0 with container zookeeper
2022-04-06 02:23:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:23:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaLogSetting
2022-04-06 02:23:05 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1670677896-656267100 in namespace log-setting-st
2022-04-06 02:23:05 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-867237584-1790498779 in namespace log-setting-st
2022-04-06 02:23:15 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:23:15 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LogSettingST.testKafkaLogSetting-FINISHED
2022-04-06 02:23:15 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 02:23:15 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 02:23:15 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LogSettingST.testBridgeLogSetting-STARTED
2022-04-06 02:23:15 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 02:23:15 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge my-cluster-c1c54861-bridge in namespace log-setting-st
2022-04-06 02:23:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: my-cluster-c1c54861-bridge will have desired state: Ready
2022-04-06 02:23:41 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: my-cluster-c1c54861-bridge is in desired state: Ready
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:392] Checking if Bridge has log level set properly
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.subscribe.name Expected: http.openapi.operation.subscribe
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.createConsumer.name Expected: http.openapi.operation.createConsumer
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.createConsumer.level Expected: INFO
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.deleteConsumer.name Expected: http.openapi.operation.deleteConsumer
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.poll.name Expected: http.openapi.operation.poll
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.sendToPartition.level Expected: TRACE
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.unsubscribe.name Expected: http.openapi.operation.unsubscribe
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.unsubscribe.level Expected: DEBUG
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.ready.level Expected: WARN
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.assign.name Expected: http.openapi.operation.assign
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.seekToEnd.name Expected: http.openapi.operation.seekToEnd
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.poll.level Expected: INFO
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.deleteConsumer.level Expected: DEBUG
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.subscribe.level Expected: TRACE
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.openapi.level Expected: TRACE
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.commit.name Expected: http.openapi.operation.commit
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.send.level Expected: ERROR
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.seek.name Expected: http.openapi.operation.seek
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.healthy.level Expected: ERROR
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.ready.name Expected: http.openapi.operation.ready
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.logger.bridge.level Expected: ERROR
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.seek.level Expected: INFO
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.assign.level Expected: TRACE
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.sendToPartition.name Expected: http.openapi.operation.sendToPartition
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.send.name Expected: http.openapi.operation.send
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.openapi.name Expected: http.openapi.operation.openapi
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.healthy.name Expected: http.openapi.operation.healthy
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.commit.level Expected: DEBUG
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.seekToEnd.level Expected: WARN
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.seekToBeginning.name Expected: http.openapi.operation.seekToBeginning
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.seekToBeginning.level Expected: DEBUG
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-c1c54861-bridge-bridge
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-c1c54861-bridge-bridge
2022-04-06 02:23:41 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=true
2022-04-06 02:23:41 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-c1c54861-bridge-bridge rolling update
2022-04-06 02:24:06 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c1c54861-bridge-bridge will be ready
2022-04-06 02:24:06 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c1c54861-bridge-bridge is ready
2022-04-06 02:24:16 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-c1c54861-bridge-bridge rolling update finished
2022-04-06 02:24:16 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-c1c54861-bridge-bridge
2022-04-06 02:24:16 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-c1c54861-bridge-bridge
2022-04-06 02:24:16 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=false
2022-04-06 02:24:16 [main] [32mINFO [m [PodUtils:343] Waiting for Pod my-cluster-c1c54861-bridge-bridge-68d576866b-rpvh4 container my-cluster-c1c54861-bridge-bridge will be ready
2022-04-06 02:24:16 [main] [32mINFO [m [PodUtils:347] Pod my-cluster-c1c54861-bridge-bridge-68d576866b-rpvh4 container my-cluster-c1c54861-bridge-bridge is ready
2022-04-06 02:24:16 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod my-cluster-c1c54861-bridge-bridge-68d576866b-rpvh4 with container my-cluster-c1c54861-bridge-bridge
2022-04-06 02:24:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:24:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBridgeLogSetting
2022-04-06 02:24:16 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge my-cluster-c1c54861-bridge in namespace log-setting-st
2022-04-06 02:24:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:24:26 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LogSettingST.testBridgeLogSetting-FINISHED
2022-04-06 02:24:26 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 02:24:26 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:24:26 [main] [32mINFO [m [ResourceManager:348] Delete all resources for LogSettingST
2022-04-06 02:24:26 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka gc-set-logging in namespace log-setting-st
2022-04-06 02:24:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka log-setting-cluster-name in namespace log-setting-st
2022-04-06 02:24:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace log-setting-st, for cruise control Kafka cluster log-setting-cluster-name
2022-04-06 02:24:26 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment shared-kafka-clients in namespace log-setting-st
2022-04-06 02:25:16 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,161.341 s - in io.strimzi.systemtest.log.LogSettingST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.FeatureGatesIsolatedST
2022-04-06 02:25:23 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 02:25:48 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 02:25:48 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.FeatureGatesIsolatedST.testSwitchingStrimziPodSetFeatureGateOnAndOff-STARTED
2022-04-06 02:25:48 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 02:25:48 [main] [32mINFO [m [FeatureGatesIsolatedST:270] Deploying CO with STS - SPS is disabled
2022-04-06 02:25:48 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 02:25:48 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 02:25:48 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 02:25:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:25:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 02:25:48 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 02:25:48 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:25:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 02:25:48 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:25:48 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:25:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 02:25:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 02:25:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 02:25:48 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 02:25:48 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 02:25:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 02:25:48 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:25:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 02:25:48 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:25:48 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 02:25:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 02:25:58 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:25:58 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 02:25:58 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:25:58 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 02:25:58 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 02:25:58 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 02:25:58 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 02:25:58 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 02:25:58 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:26:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:26:13 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
, extraEnvVars=[EnvVar(name=STRIMZI_FEATURE_GATES, value=-UseStrimziPodSets, valueFrom=null, additionalProperties={})]
2022-04-06 02:26:13 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 02:26:13 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 02:26:13 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 02:26:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:26:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:26:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 02:26:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 02:26:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 02:26:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 02:26:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 02:26:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 02:26:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 02:26:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 02:26:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:26:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:26:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 02:26:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 02:26:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 02:26:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 02:26:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:26:14 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 02:26:14 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 02:26:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 02:26:14 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 02:26:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 02:26:14 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 02:26:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 02:26:14 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 02:26:14 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:26:14 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 02:26:14 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 02:26:14 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 02:26:14 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 02:26:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:26:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 02:26:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:26:14 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 02:26:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 02:26:27 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 02:26:37 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 02:26:37 [main] [32mINFO [m [FeatureGatesIsolatedST:281] Deploying Kafka
2022-04-06 02:26:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d074a7dc in namespace infra-namespace
2022-04-06 02:26:37 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d074a7dc will have desired state: Ready
2022-04-06 02:28:02 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d074a7dc is in desired state: Ready
2022-04-06 02:28:02 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-51612497-241992462 in namespace infra-namespace
2022-04-06 02:28:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-51612497-241992462 will have desired state: Ready
2022-04-06 02:28:03 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-51612497-241992462 is in desired state: Ready
2022-04-06 02:28:03 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 02:28:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-test-1768438204 in namespace infra-namespace
2022-04-06 02:28:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-test-1486196008 in namespace infra-namespace
2022-04-06 02:28:03 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-test-1768438204 will be in active state
2022-04-06 02:28:05 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-test-1486196008 will be in active state
2022-04-06 02:28:05 [main] [32mINFO [m [FeatureGatesIsolatedST:304] Changing FG env variable to enable SPS
2022-04-06 02:28:05 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment strimzi-cluster-operator rolling update
2022-04-06 02:28:10 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 02:28:19 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 02:28:29 [main] [32mINFO [m [DeploymentUtils:141] Deployment strimzi-cluster-operator rolling update finished
2022-04-06 02:28:29 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-d074a7dc-zookeeper rolling update
2022-04-06 02:29:19 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-d074a7dc-zookeeper has been successfully rolled
2022-04-06 02:29:19 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-d074a7dc-zookeeper to be ready
2022-04-06 02:29:43 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d074a7dc will have desired state: Ready
2022-04-06 02:29:43 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d074a7dc is in desired state: Ready
2022-04-06 02:29:43 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-d074a7dc is ready
2022-04-06 02:29:43 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-d074a7dc-kafka rolling update
2022-04-06 02:30:48 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-d074a7dc-kafka has been successfully rolled
2022-04-06 02:30:48 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-d074a7dc-kafka to be ready
2022-04-06 02:31:17 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d074a7dc will have desired state: Ready
2022-04-06 02:31:17 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d074a7dc is in desired state: Ready
2022-04-06 02:31:17 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-d074a7dc is ready
2022-04-06 02:31:17 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d074a7dc will have desired state: Ready
2022-04-06 02:31:17 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d074a7dc is in desired state: Ready
2022-04-06 02:31:17 [main] [32mINFO [m [FeatureGatesIsolatedST:319] Changing FG env variable to disable again SPS
2022-04-06 02:31:17 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment strimzi-cluster-operator rolling update
2022-04-06 02:31:27 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 02:31:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 02:31:58 [main] [32mINFO [m [DeploymentUtils:141] Deployment strimzi-cluster-operator rolling update finished
2022-04-06 02:31:58 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-d074a7dc-zookeeper rolling update
2022-04-06 02:32:48 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-d074a7dc-zookeeper has been successfully rolled
2022-04-06 02:32:48 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-d074a7dc-zookeeper to be ready
2022-04-06 02:33:19 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d074a7dc will have desired state: Ready
2022-04-06 02:33:19 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d074a7dc is in desired state: Ready
2022-04-06 02:33:19 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-d074a7dc is ready
2022-04-06 02:33:19 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-d074a7dc-kafka rolling update
2022-04-06 02:34:24 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-d074a7dc-kafka has been successfully rolled
2022-04-06 02:34:24 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-d074a7dc-kafka to be ready
2022-04-06 02:34:52 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d074a7dc will have desired state: Ready
2022-04-06 02:34:52 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d074a7dc is in desired state: Ready
2022-04-06 02:34:52 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-d074a7dc is ready
2022-04-06 02:34:52 [main] [32mINFO [m [ClientUtils:61] Waiting till producer producer-test-1768438204 and consumer consumer-test-1486196008 finish
2022-04-06 02:37:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:37:15 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSwitchingStrimziPodSetFeatureGateOnAndOff
2022-04-06 02:37:15 [main] [32mINFO [m [ResourceManager:241] Delete of Job producer-test-1768438204 in namespace infra-namespace
2022-04-06 02:37:15 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job consumer-test-1486196008 in namespace infra-namespace
2022-04-06 02:37:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-51612497-241992462 in namespace infra-namespace
2022-04-06 02:37:15 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d074a7dc in namespace infra-namespace
2022-04-06 02:37:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:37:25 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.FeatureGatesIsolatedST.testSwitchingStrimziPodSetFeatureGateOnAndOff-FINISHED
2022-04-06 02:37:25 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 02:37:25 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 02:37:25 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.FeatureGatesIsolatedST.testControlPlaneListenerFeatureGate-STARTED
2022-04-06 02:37:25 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 02:37:25 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 02:37:25 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 02:37:25 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 02:37:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:37:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 02:37:25 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 02:37:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 02:37:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:37:25 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 02:37:25 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 02:37:25 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 02:37:25 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:37:25 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:37:25 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 02:37:25 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:37:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 02:37:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 02:37:25 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 02:37:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 02:37:25 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 02:37:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:37:25 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:37:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:37:25 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 02:37:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 02:37:25 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 02:37:35 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 02:37:35 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 02:37:35 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:37:35 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 02:37:45 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:37:56 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
, extraEnvVars=[EnvVar(name=STRIMZI_FEATURE_GATES, value=-ControlPlaneListener, valueFrom=null, additionalProperties={})]
2022-04-06 02:37:56 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 02:37:56 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 02:37:56 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 02:37:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:37:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:37:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 02:37:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 02:37:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 02:37:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 02:37:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 02:37:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 02:37:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 02:37:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 02:37:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:37:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:37:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 02:37:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 02:37:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 02:37:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 02:37:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:37:57 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 02:37:57 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 02:37:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 02:37:57 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 02:37:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 02:37:57 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 02:37:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 02:37:57 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 02:37:57 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:37:57 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 02:37:57 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 02:37:57 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 02:37:57 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 02:37:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:37:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 02:37:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:37:57 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 02:38:11 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 02:38:11 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 02:38:21 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 02:38:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-cca12adb in namespace infra-namespace
2022-04-06 02:38:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-cca12adb will have desired state: Ready
2022-04-06 02:40:09 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-cca12adb is in desired state: Ready
2022-04-06 02:40:09 [main] [32mINFO [m [FeatureGatesIsolatedST:96] Check for presence of ContainerPort 9090/tcp (tcp-ctrlplane) in first Kafka pod.
2022-04-06 02:40:09 [main] [32mINFO [m [FeatureGatesIsolatedST:104] Try to send some messages to Kafka over next few minutes.
2022-04-06 02:40:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1686465185-1704568113 in namespace infra-namespace
2022-04-06 02:40:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1686465185-1704568113 will have desired state: Ready
2022-04-06 02:40:10 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1686465185-1704568113 is in desired state: Ready
2022-04-06 02:40:10 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 02:40:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-test-1003351540 in namespace infra-namespace
2022-04-06 02:40:10 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-test-1003351540 will be in active state
2022-04-06 02:40:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-test-1837151407 in namespace infra-namespace
2022-04-06 02:40:11 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-test-1837151407 will be in active state
2022-04-06 02:40:12 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-test-1837151407 will be in active state
2022-04-06 02:40:12 [main] [32mINFO [m [FeatureGatesIsolatedST:127] Delete first found Kafka broker pod.
2022-04-06 02:40:12 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-cca12adb-zookeeper to be ready
2022-04-06 02:40:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-cca12adb will have desired state: Ready
2022-04-06 02:40:22 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-cca12adb is in desired state: Ready
2022-04-06 02:40:22 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-cca12adb is ready
2022-04-06 02:40:22 [main] [32mINFO [m [FeatureGatesIsolatedST:131] Force Rolling Update of Kafka via annotation.
2022-04-06 02:40:22 [main] [32mINFO [m [FeatureGatesIsolatedST:139] Wait for next reconciliation to happen.
2022-04-06 02:40:22 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-cca12adb-zookeeper rolling update
2022-04-06 02:41:57 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-cca12adb-zookeeper has been successfully rolled
2022-04-06 02:41:57 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-cca12adb-zookeeper to be ready
2022-04-06 02:42:28 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-cca12adb will have desired state: Ready
2022-04-06 02:42:28 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-cca12adb is in desired state: Ready
2022-04-06 02:42:28 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-cca12adb is ready
2022-04-06 02:42:28 [main] [32mINFO [m [FeatureGatesIsolatedST:142] Waiting for clients to finish sending/receiving messages.
2022-04-06 02:42:28 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:producer-test-1003351540 to finished
2022-04-06 02:42:52 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:consumer-test-1837151407 to finished
2022-04-06 02:42:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:42:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testControlPlaneListenerFeatureGate
2022-04-06 02:42:57 [main] [32mINFO [m [ResourceManager:241] Delete of Job producer-test-1003351540 in namespace infra-namespace
2022-04-06 02:42:57 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job consumer-test-1837151407 in namespace infra-namespace
2022-04-06 02:42:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-cca12adb in namespace infra-namespace
2022-04-06 02:42:57 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1686465185-1704568113 in namespace infra-namespace
2022-04-06 02:43:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:43:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.FeatureGatesIsolatedST.testControlPlaneListenerFeatureGate-FINISHED
2022-04-06 02:43:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 02:43:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 02:43:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.FeatureGatesIsolatedST.testStrimziPodSetsFeatureGate-STARTED
2022-04-06 02:43:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 02:43:07 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 02:43:07 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 02:43:07 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 02:43:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:43:07 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 02:43:07 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 02:43:07 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 02:43:07 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 02:43:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 02:43:07 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:43:07 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:43:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 02:43:07 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:43:07 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 02:43:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:43:07 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 02:43:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 02:43:07 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 02:43:07 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 02:43:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 02:43:07 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:43:07 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 02:43:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:43:07 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:43:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 02:43:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 02:43:07 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 02:43:17 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 02:43:17 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 02:43:17 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:43:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:43:32 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
, extraEnvVars=[EnvVar(name=STRIMZI_FEATURE_GATES, value=+UseStrimziPodSets, valueFrom=null, additionalProperties={})]
2022-04-06 02:43:32 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 02:43:32 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 02:43:32 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 02:43:32 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:43:32 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:43:32 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 02:43:32 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 02:43:32 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 02:43:32 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 02:43:32 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 02:43:32 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 02:43:32 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 02:43:33 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 02:43:33 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:43:33 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:43:33 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 02:43:33 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 02:43:33 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 02:43:33 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 02:43:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:43:33 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 02:43:33 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 02:43:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 02:43:33 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 02:43:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 02:43:33 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 02:43:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 02:43:33 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 02:43:33 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:43:33 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 02:43:33 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 02:43:33 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 02:43:33 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 02:43:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:43:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 02:43:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:43:33 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 02:44:13 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 02:44:13 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 02:44:23 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 02:44:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2076bcd1 in namespace infra-namespace
2022-04-06 02:44:23 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2076bcd1 will have desired state: Ready
2022-04-06 02:46:25 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2076bcd1 is in desired state: Ready
2022-04-06 02:46:25 [main] [32mINFO [m [FeatureGatesIsolatedST:182] Try to send some messages to Kafka over next few minutes.
2022-04-06 02:46:25 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-244146360-835038322 in namespace infra-namespace
2022-04-06 02:46:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-244146360-835038322 will have desired state: Ready
2022-04-06 02:46:26 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-244146360-835038322 is in desired state: Ready
2022-04-06 02:46:26 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 02:46:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-test-863835979 in namespace infra-namespace
2022-04-06 02:46:26 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-test-863835979 will be in active state
2022-04-06 02:46:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-test-1961878206 in namespace infra-namespace
2022-04-06 02:46:27 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-test-1961878206 will be in active state
2022-04-06 02:46:28 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-test-1961878206 will be in active state
2022-04-06 02:46:28 [main] [32mINFO [m [FeatureGatesIsolatedST:207] Delete first found ZooKeeper pod my-cluster-2076bcd1-zookeeper-0
2022-04-06 02:46:28 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-2076bcd1-zookeeper to be ready
2022-04-06 02:46:59 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2076bcd1 will have desired state: Ready
2022-04-06 02:46:59 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2076bcd1 is in desired state: Ready
2022-04-06 02:46:59 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-2076bcd1 is ready
2022-04-06 02:46:59 [main] [32mINFO [m [FeatureGatesIsolatedST:213] Delete first found Kafka broker pod my-cluster-2076bcd1-kafka-0
2022-04-06 02:46:59 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-2076bcd1-kafka to be ready
2022-04-06 02:47:45 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2076bcd1 will have desired state: Ready
2022-04-06 02:47:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2076bcd1 is in desired state: Ready
2022-04-06 02:47:45 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-2076bcd1 is ready
2022-04-06 02:47:45 [main] [32mINFO [m [FeatureGatesIsolatedST:218] Force Rolling Update of ZooKeeper via annotation.
2022-04-06 02:47:45 [main] [32mINFO [m [FeatureGatesIsolatedST:228] Wait for next reconciliation to happen.
2022-04-06 02:47:45 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-2076bcd1-zookeeper rolling update
2022-04-06 02:49:25 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-2076bcd1-zookeeper has been successfully rolled
2022-04-06 02:49:25 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-2076bcd1-zookeeper to be ready
2022-04-06 02:49:59 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2076bcd1 will have desired state: Ready
2022-04-06 02:49:59 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2076bcd1 is in desired state: Ready
2022-04-06 02:49:59 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-2076bcd1 is ready
2022-04-06 02:49:59 [main] [32mINFO [m [FeatureGatesIsolatedST:232] Force Rolling Update of Kafka via annotation.
2022-04-06 02:49:59 [main] [32mINFO [m [FeatureGatesIsolatedST:242] Wait for next reconciliation to happen.
2022-04-06 02:49:59 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-2076bcd1-kafka rolling update
2022-04-06 02:51:34 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-2076bcd1-kafka has been successfully rolled
2022-04-06 02:51:34 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-2076bcd1-kafka to be ready
2022-04-06 02:52:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2076bcd1 will have desired state: Ready
2022-04-06 02:52:00 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2076bcd1 is in desired state: Ready
2022-04-06 02:52:00 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-2076bcd1 is ready
2022-04-06 02:52:00 [main] [32mINFO [m [FeatureGatesIsolatedST:245] Waiting for clients to finish sending/receiving messages.
2022-04-06 02:52:00 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:producer-test-863835979 to finished
2022-04-06 02:52:05 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:consumer-test-1961878206 to finished
2022-04-06 02:52:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:52:10 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testStrimziPodSetsFeatureGate
2022-04-06 02:52:10 [main] [32mINFO [m [ResourceManager:241] Delete of Job producer-test-863835979 in namespace infra-namespace
2022-04-06 02:52:10 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job consumer-test-1961878206 in namespace infra-namespace
2022-04-06 02:52:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-244146360-835038322 in namespace infra-namespace
2022-04-06 02:52:10 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2076bcd1 in namespace infra-namespace
2022-04-06 02:52:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:52:21 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.FeatureGatesIsolatedST.testStrimziPodSetsFeatureGate-FINISHED
2022-04-06 02:52:21 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 02:52:21 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:52:21 [main] [32mINFO [m [ResourceManager:346] In context FeatureGatesIsolatedST is everything deleted.
2022-04-06 02:52:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,617.579 s - in io.strimzi.systemtest.operators.FeatureGatesIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.NamespaceRbacScopeOperatorIsolatedST
2022-04-06 02:52:21 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 02:52:46 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 02:52:46 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.NamespaceRbacScopeOperatorIsolatedST.testNamespacedRbacScopeDeploysRoles-STARTED
2022-04-06 02:52:46 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 02:52:46 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 02:52:46 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 02:52:46 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 02:52:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:52:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 02:52:46 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 02:52:46 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 02:52:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 02:52:46 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:52:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 02:52:46 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 02:52:46 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:52:46 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 02:52:46 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 02:52:46 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 02:52:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:52:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 02:52:46 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:52:46 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 02:52:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 02:52:46 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:52:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:52:46 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 02:52:46 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:52:46 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 02:52:56 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 02:52:56 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 02:52:56 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 02:52:56 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:52:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 02:53:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:53:11 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
, extraEnvVars=[EnvVar(name=STRIMZI_RBAC_SCOPE, value=NAMESPACE, valueFrom=null, additionalProperties={})]
2022-04-06 02:53:11 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 02:53:11 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 02:53:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 02:53:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:53:11 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-06 02:53:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-06 02:53:11 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-06 02:53:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-06 02:53:11 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRole-strimzi-kafka-broker.yaml
2022-04-06 02:53:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-broker in namespace infra-namespace
2022-04-06 02:53:11 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-ClusterRole-strimzi-entity-operator.yaml
2022-04-06 02:53:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-entity-operator in namespace infra-namespace
2022-04-06 02:53:11 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRole-strimzi-kafka-client.yaml
2022-04-06 02:53:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-client in namespace infra-namespace
2022-04-06 02:53:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 02:53:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 02:53:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 02:53:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 02:53:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:53:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:53:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 02:53:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 02:53:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 02:53:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 02:53:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:53:12 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 02:53:12 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 02:53:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 02:53:12 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 02:53:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 02:53:12 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 02:53:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 02:53:12 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml
2022-04-06 02:53:12 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/020-Role-strimzi-cluster-operator10497198070377771176.yaml in namespace infra-namespace
2022-04-06 02:53:12 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:53:12 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml
2022-04-06 02:53:12 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/031-Role-strimzi-cluster-operator-entity-operator-delegation6723581714946062962.yaml in namespace infra-namespace
2022-04-06 02:53:12 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 02:53:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:53:12 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 02:53:24 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 02:53:24 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 02:53:34 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 02:53:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0b48a773 in namespace infra-namespace
2022-04-06 02:53:34 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0b48a773 will have desired state: Ready
2022-04-06 02:54:52 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0b48a773 is in desired state: Ready
2022-04-06 02:54:52 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0b48a773 will have desired state: Ready
2022-04-06 02:54:52 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0b48a773 is in desired state: Ready
2022-04-06 02:54:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:54:52 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testNamespacedRbacScopeDeploysRoles
2022-04-06 02:54:52 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0b48a773 in namespace infra-namespace
2022-04-06 02:55:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:55:02 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.NamespaceRbacScopeOperatorIsolatedST.testNamespacedRbacScopeDeploysRoles-FINISHED
2022-04-06 02:55:02 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 02:55:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:55:02 [main] [32mINFO [m [ResourceManager:346] In context NamespaceRbacScopeOperatorIsolatedST is everything deleted.
2022-04-06 02:55:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 161.752 s - in io.strimzi.systemtest.operators.NamespaceRbacScopeOperatorIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.RecoveryIsolatedST
2022-04-06 02:55:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 02:55:27 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 02:55:27 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperMetricsConfigDeletion-STARTED
2022-04-06 02:55:27 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 02:55:27 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 02:55:27 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 02:55:27 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 02:55:27 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:55:27 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 02:55:27 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 02:55:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:55:27 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 02:55:27 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 02:55:27 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 02:55:27 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-06 02:55:27 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 02:55:27 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 02:55:27 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-entity-operator in namespace infra-namespace
2022-04-06 02:55:27 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 02:55:27 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:55:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 02:55:27 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:55:27 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-broker in namespace infra-namespace
2022-04-06 02:55:27 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-06 02:55:27 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:55:27 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-client in namespace infra-namespace
2022-04-06 02:55:28 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 02:55:37 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:55:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 02:55:37 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 02:55:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:55:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 02:55:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:55:53 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 02:55:53 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 02:55:53 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 02:55:53 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 02:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 02:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 02:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 02:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 02:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 02:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 02:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 02:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 02:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 02:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 02:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 02:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 02:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:55:53 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 02:55:53 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 02:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 02:55:53 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 02:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 02:55:53 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 02:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 02:55:53 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 02:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:55:53 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 02:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 02:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:55:53 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 02:56:22 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 02:56:22 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 02:56:32 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 02:56:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1283312737 in namespace infra-namespace
2022-04-06 02:56:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1283312737 will have desired state: Ready
2022-04-06 02:58:55 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1283312737 is in desired state: Ready
2022-04-06 02:58:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1283312737 in namespace infra-namespace
2022-04-06 02:58:55 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1283312737 will be ready
2022-04-06 02:58:57 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1283312737 is ready
2022-04-06 02:58:57 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1283312737 in namespace infra-namespace
2022-04-06 02:58:57 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1283312737 will have desired state: Ready
2022-04-06 02:59:19 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1283312737 is in desired state: Ready
2022-04-06 02:59:19 [main] [32mINFO [m [RecoveryIsolatedST:191] Running deleteZookeeperMetricsConfig with cluster recovery-cluster-1283312737
2022-04-06 02:59:19 [main] [32mINFO [m [RecoveryIsolatedST:199] Waiting for creation recovery-cluster-1283312737-zookeeper-config
2022-04-06 02:59:19 [main] [32mINFO [m [ConfigMapUtils:30] Waiting for config map recovery-cluster-1283312737-zookeeper-config-afc76e0f-eac9-4a1f-97a1-f76549584143 recovery in namespace infra-namespace
2022-04-06 02:59:31 [main] [32mINFO [m [ConfigMapUtils:33] Config map recovery-cluster-1283312737-zookeeper-config was recovered
2022-04-06 02:59:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:59:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromZookeeperMetricsConfigDeletion
2022-04-06 02:59:31 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1283312737 in namespace infra-namespace
2022-04-06 02:59:31 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1283312737 in namespace infra-namespace
2022-04-06 02:59:31 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1283312737 in namespace infra-namespace
2022-04-06 03:00:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:00:21 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperMetricsConfigDeletion-FINISHED
2022-04-06 03:00:21 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 03:00:21 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 03:00:21 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaBridgeServiceDeletion-STARTED
2022-04-06 03:00:21 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 03:00:21 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 03:00:21 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 03:00:21 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 03:00:21 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:00:21 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 03:00:21 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:00:21 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:00:21 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:00:21 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:00:21 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:00:21 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:00:21 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:00:21 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:00:21 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:00:21 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:00:21 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:00:21 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:00:21 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:00:21 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:00:21 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:00:31 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:00:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:00:31 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:00:31 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:00:31 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:00:31 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:00:31 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:00:31 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:00:41 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:00:47 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 03:00:47 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 03:00:47 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 03:00:47 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 03:00:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:00:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:00:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:00:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:00:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:00:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:00:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:00:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:00:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:00:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:00:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:00:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:00:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:00:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:00:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:00:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:00:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:00:47 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 03:00:47 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:00:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:00:47 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 03:00:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:00:47 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 03:00:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:00:47 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:00:47 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:00:47 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 03:00:47 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:00:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:00:47 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 03:01:15 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 03:01:15 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 03:01:25 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 03:01:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-730661074 in namespace infra-namespace
2022-04-06 03:01:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-730661074 will have desired state: Ready
2022-04-06 03:03:46 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-730661074 is in desired state: Ready
2022-04-06 03:03:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-730661074 in namespace infra-namespace
2022-04-06 03:03:46 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-730661074 will be ready
2022-04-06 03:03:47 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-730661074 is ready
2022-04-06 03:03:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-730661074 in namespace infra-namespace
2022-04-06 03:03:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-730661074 will have desired state: Ready
2022-04-06 03:04:05 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-730661074 is in desired state: Ready
2022-04-06 03:04:05 [main] [32mINFO [m [RecoveryIsolatedST:222] Running deleteKafkaBridgeService with cluster recovery-cluster-730661074
2022-04-06 03:04:05 [main] [32mINFO [m [RecoveryIsolatedST:227] Waiting for service recovery-cluster-730661074-bridge-service recovery
2022-04-06 03:04:05 [main] [32mINFO [m [ServiceUtils:58] Waiting when Service recovery-cluster-730661074-bridge-service-6762d240-76ea-4615-8967-8dd5c7c7121a in namespace infra-namespace will be recovered
2022-04-06 03:04:24 [main] [32mINFO [m [ServiceUtils:62] recovery-cluster-730661074-bridge-service in namespace infra-namespace is recovered
2022-04-06 03:04:24 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:04:24 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaBridgeServiceDeletion
2022-04-06 03:04:24 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-730661074 in namespace infra-namespace
2022-04-06 03:04:24 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-730661074 in namespace infra-namespace
2022-04-06 03:04:24 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-730661074 in namespace infra-namespace
2022-04-06 03:05:14 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:05:14 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaBridgeServiceDeletion-FINISHED
2022-04-06 03:05:14 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 03:05:14 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 03:05:14 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaHeadlessServiceDeletion-STARTED
2022-04-06 03:05:14 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 03:05:14 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 03:05:14 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 03:05:14 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 03:05:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:05:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 03:05:14 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:05:14 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:05:14 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:05:14 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:05:14 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:05:14 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:05:14 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:05:14 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:05:14 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:05:14 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:05:14 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:05:14 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:05:14 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:05:14 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:05:14 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:05:14 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:05:14 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:05:14 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:05:14 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:05:24 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:05:24 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:05:24 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:05:24 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:05:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:05:40 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 03:05:40 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 03:05:40 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 03:05:40 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 03:05:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:05:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:05:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:05:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:05:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:05:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:05:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:05:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:05:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:05:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:05:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:05:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:05:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:05:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:05:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:05:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:05:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:05:40 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 03:05:40 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:05:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:05:40 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 03:05:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:05:40 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 03:05:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:05:40 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:05:40 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:05:40 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 03:05:40 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:05:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:05:40 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 03:06:17 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 03:06:17 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 03:06:27 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 03:06:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-248249740 in namespace infra-namespace
2022-04-06 03:06:27 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-248249740 will have desired state: Ready
2022-04-06 03:08:14 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-248249740 is in desired state: Ready
2022-04-06 03:08:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-248249740 in namespace infra-namespace
2022-04-06 03:08:14 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-248249740 will be ready
2022-04-06 03:08:16 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-248249740 is ready
2022-04-06 03:08:16 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-248249740 in namespace infra-namespace
2022-04-06 03:08:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-248249740 will have desired state: Ready
2022-04-06 03:08:38 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-248249740 is in desired state: Ready
2022-04-06 03:08:38 [main] [32mINFO [m [RecoveryIsolatedST:143] Running deleteKafkaHeadlessService with cluster recovery-cluster-248249740
2022-04-06 03:08:38 [main] [32mINFO [m [RecoveryIsolatedST:150] Waiting for creation recovery-cluster-248249740-kafka-brokers
2022-04-06 03:08:38 [main] [32mINFO [m [ServiceUtils:58] Waiting when Service recovery-cluster-248249740-kafka-brokers-52d1f156-3deb-4fba-afca-666d20523fd0 in namespace infra-namespace will be recovered
2022-04-06 03:08:49 [main] [32mINFO [m [ServiceUtils:62] recovery-cluster-248249740-kafka-brokers in namespace infra-namespace is recovered
2022-04-06 03:08:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:08:49 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaHeadlessServiceDeletion
2022-04-06 03:08:49 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-248249740 in namespace infra-namespace
2022-04-06 03:08:49 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-248249740 in namespace infra-namespace
2022-04-06 03:08:49 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-248249740 in namespace infra-namespace
2022-04-06 03:09:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:09:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaHeadlessServiceDeletion-FINISHED
2022-04-06 03:09:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 03:09:29 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 03:09:29 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaStatefulSetDeletion-STARTED
2022-04-06 03:09:29 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 03:09:29 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 03:09:29 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 03:09:29 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 03:09:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:09:29 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 03:09:29 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:09:29 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:09:29 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:09:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:09:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:09:29 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:09:29 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:09:29 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:09:29 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:09:29 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:09:29 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:09:29 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:09:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:09:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:09:29 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:09:29 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:09:29 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:09:29 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:09:29 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:09:29 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:09:39 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:09:39 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:09:39 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:09:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:09:55 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 03:09:55 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 03:09:55 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 03:09:55 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 03:09:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:09:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:09:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:09:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:09:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:09:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:09:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:09:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:09:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:09:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:09:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:09:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:09:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:09:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:09:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:09:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:09:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:09:55 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 03:09:55 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:09:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:09:55 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 03:09:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:09:55 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 03:09:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:09:55 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:09:55 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:09:55 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 03:09:55 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:09:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:09:55 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 03:10:07 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 03:10:07 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 03:10:17 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 03:10:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-781323658 in namespace infra-namespace
2022-04-06 03:10:17 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-781323658 will have desired state: Ready
2022-04-06 03:11:43 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-781323658 is in desired state: Ready
2022-04-06 03:11:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-781323658 in namespace infra-namespace
2022-04-06 03:11:43 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-781323658 will be ready
2022-04-06 03:11:45 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-781323658 is ready
2022-04-06 03:11:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-781323658 in namespace infra-namespace
2022-04-06 03:11:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-781323658 will have desired state: Ready
2022-04-06 03:12:06 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-781323658 is in desired state: Ready
2022-04-06 03:12:06 [main] [32mINFO [m [PodUtils:121] Waiting when all Pods with prefix recovery-cluster-781323658-kafka will be deleted
2022-04-06 03:12:06 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-781323658-kafka-0 will be deleted
2022-04-06 03:12:16 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-781323658-kafka-0 deleted
2022-04-06 03:12:16 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-781323658-kafka-1 will be deleted
2022-04-06 03:12:16 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-781323658-kafka-1 deleted
2022-04-06 03:12:16 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-781323658-kafka-2 will be deleted
2022-04-06 03:12:26 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-781323658-kafka-2 deleted
2022-04-06 03:12:26 [main] [32mINFO [m [RecoveryIsolatedST:90] Waiting for recovery recovery-cluster-781323658-kafka
2022-04-06 03:12:26 [main] [32mINFO [m [StatefulSetUtils:73] Waiting for StatefulSet recovery-cluster-781323658-kafka-b542a96f-f330-4a27-8658-3233d47b8dcb recovery in namespace infra-namespace
2022-04-06 03:12:38 [main] [32mINFO [m [StatefulSetUtils:76] StatefulSet recovery-cluster-781323658-kafka was recovered
2022-04-06 03:12:38 [main] [32mINFO [m [StatefulSetUtils:39] Waiting for StatefulSet recovery-cluster-781323658-kafka to be ready
2022-04-06 03:13:02 [main] [32mINFO [m [StatefulSetUtils:44] Waiting for 3 Pod(s) of StatefulSet recovery-cluster-781323658-kafka to be ready
2022-04-06 03:13:12 [main] [32mINFO [m [StatefulSetUtils:47] StatefulSet recovery-cluster-781323658-kafka is ready
2022-04-06 03:13:12 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:13:12 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaStatefulSetDeletion
2022-04-06 03:13:12 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-781323658 in namespace infra-namespace
2022-04-06 03:13:12 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-781323658 in namespace infra-namespace
2022-04-06 03:13:12 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-781323658 in namespace infra-namespace
2022-04-06 03:14:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:14:02 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaStatefulSetDeletion-FINISHED
2022-04-06 03:14:02 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 03:14:02 [main] [32mINFO [m [StrimziPodSetTestCondition:23] According to STRIMZI_FEATURE_GATES env variable with value: , the StatefulSets are used, skipping this StrimziPodSet related test
2022-04-06 03:14:02 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 03:14:02 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromEntityOperatorDeletion-STARTED
2022-04-06 03:14:02 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 03:14:02 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 03:14:02 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 03:14:02 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 03:14:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:14:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 03:14:02 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:14:02 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:14:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:14:02 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:14:02 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:14:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:14:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:14:02 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:14:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:14:02 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:14:02 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:14:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:14:02 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:14:02 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:14:02 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:14:02 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:14:02 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:14:02 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:14:02 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:14:12 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:14:12 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:14:12 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:14:12 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:14:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:14:28 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 03:14:28 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 03:14:28 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 03:14:28 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 03:14:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:14:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:14:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:14:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:14:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:14:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:14:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:14:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:14:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:14:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:14:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:14:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:14:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:14:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:14:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:14:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:14:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:14:28 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 03:14:28 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:14:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:14:28 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 03:14:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:14:28 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 03:14:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:14:28 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:14:28 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:14:29 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 03:14:29 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:14:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:14:29 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 03:15:00 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 03:15:00 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 03:15:10 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 03:15:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-994619520 in namespace infra-namespace
2022-04-06 03:15:10 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-994619520 will have desired state: Ready
2022-04-06 03:16:57 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-994619520 is in desired state: Ready
2022-04-06 03:16:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-994619520 in namespace infra-namespace
2022-04-06 03:16:57 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-994619520 will be ready
2022-04-06 03:16:59 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-994619520 is ready
2022-04-06 03:16:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-994619520 in namespace infra-namespace
2022-04-06 03:16:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-994619520 will have desired state: Ready
2022-04-06 03:17:24 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-994619520 is in desired state: Ready
2022-04-06 03:17:24 [main] [32mINFO [m [RecoveryIsolatedST:64] Running testRecoveryFromEntityOperatorDeletion with cluster recovery-cluster-994619520
2022-04-06 03:17:24 [main] [32mINFO [m [PodUtils:121] Waiting when all Pods with prefix recovery-cluster-994619520-entity-operator will be deleted
2022-04-06 03:17:24 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-994619520-entity-operator-5599696f95-4fpft will be deleted
2022-04-06 03:17:29 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-994619520-entity-operator-5599696f95-4fpft deleted
2022-04-06 03:17:29 [main] [32mINFO [m [RecoveryIsolatedST:72] Waiting for recovery recovery-cluster-994619520-entity-operator
2022-04-06 03:17:29 [main] [32mINFO [m [DeploymentUtils:154] Waiting for Deployment recovery-cluster-994619520-entity-operator-324ca08f-9276-42e8-961a-622b9ecc5706 recovery in namespace infra-namespace
2022-04-06 03:17:37 [main] [32mINFO [m [DeploymentUtils:157] Deployment recovery-cluster-994619520-entity-operator was recovered
2022-04-06 03:17:37 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: recovery-cluster-994619520-entity-operator will be ready
2022-04-06 03:18:10 [main] [32mINFO [m [DeploymentUtils:168] Deployment: recovery-cluster-994619520-entity-operator is ready
2022-04-06 03:18:10 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment recovery-cluster-994619520-entity-operator to be ready
2022-04-06 03:18:20 [main] [32mINFO [m [DeploymentUtils:197] Deployment recovery-cluster-994619520-entity-operator is ready
2022-04-06 03:18:20 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:18:20 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromEntityOperatorDeletion
2022-04-06 03:18:20 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-994619520 in namespace infra-namespace
2022-04-06 03:18:20 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-994619520 in namespace infra-namespace
2022-04-06 03:18:20 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-994619520 in namespace infra-namespace
2022-04-06 03:19:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:19:11 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromEntityOperatorDeletion-FINISHED
2022-04-06 03:19:11 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 03:19:11 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 03:19:11 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaBridgeDeploymentDeletion-STARTED
2022-04-06 03:19:11 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 03:19:11 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 03:19:11 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 03:19:11 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 03:19:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:19:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 03:19:11 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:19:11 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:19:11 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:19:11 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:19:11 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:19:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:19:11 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:19:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:19:11 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:19:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:19:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:19:11 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:19:11 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:19:11 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:19:11 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:19:21 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:19:21 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:19:21 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:19:21 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:19:21 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:19:21 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:19:21 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:19:21 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:19:31 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:19:36 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 03:19:36 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 03:19:36 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 03:19:36 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 03:19:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:19:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:19:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:19:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:19:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:19:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:19:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:19:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:19:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:19:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:19:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:19:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:19:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:19:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:19:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:19:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:19:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:19:37 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 03:19:37 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:19:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:19:37 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 03:19:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:19:37 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 03:19:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:19:37 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:19:37 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:19:37 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 03:19:37 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:19:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:19:37 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 03:20:03 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 03:20:03 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 03:20:13 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 03:20:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1586212781 in namespace infra-namespace
2022-04-06 03:20:13 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1586212781 will have desired state: Ready
2022-04-06 03:22:34 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1586212781 is in desired state: Ready
2022-04-06 03:22:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1586212781 in namespace infra-namespace
2022-04-06 03:22:34 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1586212781 will be ready
2022-04-06 03:22:35 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1586212781 is ready
2022-04-06 03:22:35 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1586212781 in namespace infra-namespace
2022-04-06 03:22:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1586212781 will have desired state: Ready
2022-04-06 03:22:57 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1586212781 is in desired state: Ready
2022-04-06 03:22:57 [main] [32mINFO [m [RecoveryIsolatedST:206] Running deleteKafkaBridgeDeployment with cluster recovery-cluster-1586212781
2022-04-06 03:22:57 [main] [32mINFO [m [PodUtils:121] Waiting when all Pods with prefix recovery-cluster-1586212781-bridge will be deleted
2022-04-06 03:22:57 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-1586212781-bridge-7bc67d6955-9sdk2 will be deleted
2022-04-06 03:23:07 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-1586212781-bridge-7bc67d6955-9sdk2 deleted
2022-04-06 03:23:07 [main] [32mINFO [m [RecoveryIsolatedST:215] Waiting for deployment recovery-cluster-1586212781-bridge recovery
2022-04-06 03:23:07 [main] [32mINFO [m [DeploymentUtils:154] Waiting for Deployment recovery-cluster-1586212781-bridge-60db729f-f1ab-4133-9b98-07052a83dd8e recovery in namespace infra-namespace
2022-04-06 03:23:14 [main] [32mINFO [m [DeploymentUtils:157] Deployment recovery-cluster-1586212781-bridge was recovered
2022-04-06 03:23:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:23:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaBridgeDeploymentDeletion
2022-04-06 03:23:14 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1586212781 in namespace infra-namespace
2022-04-06 03:23:14 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1586212781 in namespace infra-namespace
2022-04-06 03:23:14 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1586212781 in namespace infra-namespace
2022-04-06 03:24:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:24:04 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaBridgeDeploymentDeletion-FINISHED
2022-04-06 03:24:04 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 03:24:04 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 03:24:04 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaServiceDeletion-STARTED
2022-04-06 03:24:04 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 03:24:04 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 03:24:04 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 03:24:04 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 03:24:04 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:24:04 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 03:24:04 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:24:04 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:24:04 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:24:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:24:04 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:24:04 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:24:04 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:24:04 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:24:04 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:24:04 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:24:04 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:24:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:24:04 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:24:04 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:24:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:24:04 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:24:04 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:24:04 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:24:04 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:24:04 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:24:14 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:24:14 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:24:14 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:24:24 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:24:29 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 03:24:29 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 03:24:29 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 03:24:29 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 03:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:24:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:24:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:24:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:24:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:24:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:24:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:24:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:24:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:24:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:24:30 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 03:24:30 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:24:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:24:30 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 03:24:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:24:30 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 03:24:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:24:30 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:24:30 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:24:30 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 03:24:30 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:24:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:24:30 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 03:24:47 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 03:24:47 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 03:24:57 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 03:24:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-296881351 in namespace infra-namespace
2022-04-06 03:24:57 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-296881351 will have desired state: Ready
2022-04-06 03:26:51 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-296881351 is in desired state: Ready
2022-04-06 03:26:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-296881351 in namespace infra-namespace
2022-04-06 03:26:51 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-296881351 will be ready
2022-04-06 03:26:53 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-296881351 is ready
2022-04-06 03:26:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-296881351 in namespace infra-namespace
2022-04-06 03:26:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-296881351 will have desired state: Ready
2022-04-06 03:27:18 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-296881351 is in desired state: Ready
2022-04-06 03:27:18 [main] [32mINFO [m [RecoveryIsolatedST:115] Running deleteKafkaService with cluster recovery-cluster-296881351
2022-04-06 03:27:18 [main] [32mINFO [m [RecoveryIsolatedST:122] Waiting for creation recovery-cluster-296881351-kafka-bootstrap
2022-04-06 03:27:18 [main] [32mINFO [m [ServiceUtils:58] Waiting when Service recovery-cluster-296881351-kafka-bootstrap-92c9b7ae-4b3f-4299-9897-c564a39b9e3b in namespace infra-namespace will be recovered
2022-04-06 03:27:39 [main] [32mINFO [m [ServiceUtils:62] recovery-cluster-296881351-kafka-bootstrap in namespace infra-namespace is recovered
2022-04-06 03:27:39 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:27:39 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaServiceDeletion
2022-04-06 03:27:39 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-296881351 in namespace infra-namespace
2022-04-06 03:27:39 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-296881351 in namespace infra-namespace
2022-04-06 03:27:39 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-296881351 in namespace infra-namespace
2022-04-06 03:28:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:28:19 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaServiceDeletion-FINISHED
2022-04-06 03:28:19 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 03:28:19 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 03:28:19 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperStatefulSetDeletion-STARTED
2022-04-06 03:28:19 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 03:28:19 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 03:28:19 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 03:28:19 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 03:28:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:28:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 03:28:19 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:28:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:28:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:28:19 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:28:19 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:28:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:28:19 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:28:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:28:19 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:28:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:28:19 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:28:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:28:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:28:19 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:28:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:28:19 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:28:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:28:19 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:28:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:28:29 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:28:29 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:28:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:28:29 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:28:39 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:28:44 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 03:28:44 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 03:28:44 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 03:28:44 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 03:28:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:28:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:28:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:28:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:28:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:28:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:28:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:28:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:28:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:28:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:28:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:28:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:28:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:28:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:28:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:28:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:28:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:28:45 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 03:28:45 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:28:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:28:45 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 03:28:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:28:45 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 03:28:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:28:45 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:28:45 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:28:45 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 03:28:45 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:28:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:28:45 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 03:29:06 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 03:29:06 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 03:29:16 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 03:29:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1032159604 in namespace infra-namespace
2022-04-06 03:29:16 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1032159604 will have desired state: Ready
2022-04-06 03:30:39 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1032159604 is in desired state: Ready
2022-04-06 03:30:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1032159604 in namespace infra-namespace
2022-04-06 03:30:39 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1032159604 will be ready
2022-04-06 03:30:41 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1032159604 is ready
2022-04-06 03:30:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1032159604 in namespace infra-namespace
2022-04-06 03:30:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1032159604 will have desired state: Ready
2022-04-06 03:30:59 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1032159604 is in desired state: Ready
2022-04-06 03:30:59 [main] [32mINFO [m [PodUtils:121] Waiting when all Pods with prefix recovery-cluster-1032159604-zookeeper will be deleted
2022-04-06 03:30:59 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-1032159604-zookeeper-0 will be deleted
2022-04-06 03:31:14 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-1032159604-zookeeper-0 deleted
2022-04-06 03:31:14 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-1032159604-zookeeper-1 will be deleted
2022-04-06 03:31:14 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-1032159604-zookeeper-1 deleted
2022-04-06 03:31:14 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-1032159604-zookeeper-2 will be deleted
2022-04-06 03:31:14 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-1032159604-zookeeper-2 deleted
2022-04-06 03:31:14 [main] [32mINFO [m [RecoveryIsolatedST:107] Waiting for recovery recovery-cluster-1032159604-zookeeper
2022-04-06 03:31:14 [main] [32mINFO [m [StatefulSetUtils:73] Waiting for StatefulSet recovery-cluster-1032159604-zookeeper-2c711466-f22f-4cb8-904c-cdca9b445a90 recovery in namespace infra-namespace
2022-04-06 03:31:23 [main] [32mINFO [m [StatefulSetUtils:76] StatefulSet recovery-cluster-1032159604-zookeeper was recovered
2022-04-06 03:31:23 [main] [32mINFO [m [StatefulSetUtils:39] Waiting for StatefulSet recovery-cluster-1032159604-zookeeper to be ready
2022-04-06 03:32:22 [main] [32mINFO [m [StatefulSetUtils:44] Waiting for 3 Pod(s) of StatefulSet recovery-cluster-1032159604-zookeeper to be ready
2022-04-06 03:32:32 [main] [32mINFO [m [StatefulSetUtils:47] StatefulSet recovery-cluster-1032159604-zookeeper is ready
2022-04-06 03:32:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:32:32 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromZookeeperStatefulSetDeletion
2022-04-06 03:32:32 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1032159604 in namespace infra-namespace
2022-04-06 03:32:32 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1032159604 in namespace infra-namespace
2022-04-06 03:32:32 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1032159604 in namespace infra-namespace
2022-04-06 03:33:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:33:12 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperStatefulSetDeletion-FINISHED
2022-04-06 03:33:12 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 03:33:12 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 03:33:12 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaBridgeMetricsConfigDeletion-STARTED
2022-04-06 03:33:12 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 03:33:12 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 03:33:12 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 03:33:12 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 03:33:12 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:33:12 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 03:33:12 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:33:12 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:33:12 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:33:12 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:33:12 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:33:12 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:33:12 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:33:12 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:33:12 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:33:12 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:33:12 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:33:12 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:33:12 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:33:12 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:33:12 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:33:12 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:33:12 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:33:12 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:33:12 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:33:12 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:33:22 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:33:22 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:33:22 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:33:32 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:33:37 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 03:33:37 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 03:33:37 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 03:33:37 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 03:33:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:33:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:33:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:33:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:33:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:33:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:33:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:33:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:33:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:33:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:33:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:33:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:33:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:33:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:33:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:33:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:33:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:33:38 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 03:33:38 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:33:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:33:38 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 03:33:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:33:38 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 03:33:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:33:38 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:33:38 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:33:38 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 03:33:38 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:33:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:33:38 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 03:34:10 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 03:34:10 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 03:34:20 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 03:34:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1507874245 in namespace infra-namespace
2022-04-06 03:34:20 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1507874245 will have desired state: Ready
2022-04-06 03:36:40 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1507874245 is in desired state: Ready
2022-04-06 03:36:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1507874245 in namespace infra-namespace
2022-04-06 03:36:40 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1507874245 will be ready
2022-04-06 03:36:41 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1507874245 is ready
2022-04-06 03:36:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1507874245 in namespace infra-namespace
2022-04-06 03:36:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1507874245 will have desired state: Ready
2022-04-06 03:37:07 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1507874245 is in desired state: Ready
2022-04-06 03:37:07 [main] [32mINFO [m [RecoveryIsolatedST:234] Running deleteKafkaBridgeMetricsConfig with cluster recovery-cluster-1507874245
2022-04-06 03:37:07 [main] [32mINFO [m [RecoveryIsolatedST:239] Waiting for metric config recovery-cluster-1507874245-bridge-config re-creation
2022-04-06 03:37:07 [main] [32mINFO [m [ConfigMapUtils:30] Waiting for config map recovery-cluster-1507874245-bridge-config-1ea5589c-9aa2-4f02-9974-b789d96e67d7 recovery in namespace infra-namespace
2022-04-06 03:37:15 [main] [32mINFO [m [ConfigMapUtils:33] Config map recovery-cluster-1507874245-bridge-config was recovered
2022-04-06 03:37:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:37:15 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaBridgeMetricsConfigDeletion
2022-04-06 03:37:15 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1507874245 in namespace infra-namespace
2022-04-06 03:37:15 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1507874245 in namespace infra-namespace
2022-04-06 03:37:15 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1507874245 in namespace infra-namespace
2022-04-06 03:38:05 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:38:05 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaBridgeMetricsConfigDeletion-FINISHED
2022-04-06 03:38:05 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 03:38:05 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 03:38:05 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperHeadlessServiceDeletion-STARTED
2022-04-06 03:38:05 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 03:38:05 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 03:38:05 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 03:38:05 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 03:38:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:38:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 03:38:05 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:38:05 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:38:05 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:38:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:38:05 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:38:05 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:38:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:38:05 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:38:05 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:38:05 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:38:05 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:38:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:38:05 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:38:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:38:05 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:38:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:38:05 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:38:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:38:05 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:38:05 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:38:15 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:38:15 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:38:15 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:38:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:38:30 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 03:38:30 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 03:38:30 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 03:38:30 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 03:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:38:31 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:38:31 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:38:31 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:38:31 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:38:31 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:38:31 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:38:31 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:38:31 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:38:31 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:38:31 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:38:31 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 03:38:31 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:38:31 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:38:31 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 03:38:31 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:38:31 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 03:38:31 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:38:31 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:38:31 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:38:31 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 03:38:31 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:38:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:38:31 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 03:39:07 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 03:39:07 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 03:39:17 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 03:39:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-89044038 in namespace infra-namespace
2022-04-06 03:39:17 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-89044038 will have desired state: Ready
2022-04-06 03:41:35 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-89044038 is in desired state: Ready
2022-04-06 03:41:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-89044038 in namespace infra-namespace
2022-04-06 03:41:35 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-89044038 will be ready
2022-04-06 03:41:37 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-89044038 is ready
2022-04-06 03:41:38 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-89044038 in namespace infra-namespace
2022-04-06 03:41:38 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-89044038 will have desired state: Ready
2022-04-06 03:42:03 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-89044038 is in desired state: Ready
2022-04-06 03:42:03 [main] [32mINFO [m [RecoveryIsolatedST:157] Running deleteKafkaHeadlessService with cluster recovery-cluster-89044038
2022-04-06 03:42:03 [main] [32mINFO [m [RecoveryIsolatedST:164] Waiting for creation recovery-cluster-89044038-zookeeper-nodes
2022-04-06 03:42:03 [main] [32mINFO [m [ServiceUtils:58] Waiting when Service recovery-cluster-89044038-zookeeper-nodes-0f21a34e-bd3c-42d5-a06d-be7be9abd18a in namespace infra-namespace will be recovered
2022-04-06 03:42:08 [main] [32mINFO [m [ServiceUtils:62] recovery-cluster-89044038-zookeeper-nodes in namespace infra-namespace is recovered
2022-04-06 03:42:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:42:08 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromZookeeperHeadlessServiceDeletion
2022-04-06 03:42:08 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-89044038 in namespace infra-namespace
2022-04-06 03:42:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-89044038 in namespace infra-namespace
2022-04-06 03:42:08 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-89044038 in namespace infra-namespace
2022-04-06 03:42:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:42:48 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperHeadlessServiceDeletion-FINISHED
2022-04-06 03:42:48 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 03:42:48 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 03:42:48 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaMetricsConfigDeletion-STARTED
2022-04-06 03:42:48 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 03:42:48 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 03:42:48 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 03:42:48 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 03:42:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:42:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 03:42:48 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:42:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:42:48 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:42:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:42:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:42:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:42:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:42:48 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:42:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:42:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:42:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:42:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:42:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:42:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:42:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:42:58 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:42:58 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:42:58 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:42:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:42:58 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:42:58 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:42:58 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:42:58 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:43:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:43:13 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 03:43:13 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 03:43:13 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 03:43:13 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 03:43:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:43:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:43:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:43:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:43:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:43:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:43:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:43:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:43:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:43:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:43:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:43:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:43:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:43:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:43:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:43:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:43:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:43:14 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 03:43:14 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:43:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:43:14 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 03:43:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:43:14 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 03:43:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:43:14 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:43:14 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:43:14 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 03:43:14 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:43:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:43:14 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 03:43:38 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 03:43:38 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 03:43:48 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 03:43:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1834314962 in namespace infra-namespace
2022-04-06 03:43:48 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1834314962 will have desired state: Ready
2022-04-06 03:46:08 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1834314962 is in desired state: Ready
2022-04-06 03:46:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1834314962 in namespace infra-namespace
2022-04-06 03:46:08 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1834314962 will be ready
2022-04-06 03:46:09 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1834314962 is ready
2022-04-06 03:46:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1834314962 in namespace infra-namespace
2022-04-06 03:46:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1834314962 will have desired state: Ready
2022-04-06 03:46:34 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1834314962 is in desired state: Ready
2022-04-06 03:46:34 [main] [32mINFO [m [RecoveryIsolatedST:171] Running deleteKafkaMetricsConfig with cluster recovery-cluster-1834314962
2022-04-06 03:46:35 [main] [32mINFO [m [RecoveryIsolatedST:185] Waiting for creation recovery-cluster-1834314962-kafka-config
2022-04-06 03:46:35 [main] [32mINFO [m [ConfigMapUtils:30] Waiting for config map recovery-cluster-1834314962-kafka-config-56449e88-6e34-4cee-b8fe-dac66cd12b09 recovery in namespace infra-namespace
2022-04-06 03:46:53 [main] [32mINFO [m [ConfigMapUtils:33] Config map recovery-cluster-1834314962-kafka-config was recovered
2022-04-06 03:46:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:46:53 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaMetricsConfigDeletion
2022-04-06 03:46:53 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1834314962 in namespace infra-namespace
2022-04-06 03:46:53 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1834314962 in namespace infra-namespace
2022-04-06 03:46:53 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1834314962 in namespace infra-namespace
2022-04-06 03:47:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:47:43 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaMetricsConfigDeletion-FINISHED
2022-04-06 03:47:43 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 03:47:43 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 03:47:43 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperServiceDeletion-STARTED
2022-04-06 03:47:43 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 03:47:43 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 03:47:43 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 03:47:43 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 03:47:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:47:43 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 03:47:43 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:47:43 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:47:43 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:47:43 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:47:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:47:43 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:47:43 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:47:43 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:47:43 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:47:43 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:47:43 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:47:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:47:43 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:47:43 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:47:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:47:43 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:47:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:47:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:47:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:47:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:47:53 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:47:53 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:47:53 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:48:03 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:48:08 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 03:48:08 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 03:48:08 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 03:48:08 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 03:48:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:48:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:48:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:48:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:48:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:48:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:48:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:48:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:48:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:48:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:48:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:48:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:48:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:48:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:48:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:48:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:48:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:48:09 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 03:48:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:48:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:48:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 03:48:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:48:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 03:48:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:48:09 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:48:09 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:48:09 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 03:48:09 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:48:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:48:09 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 03:48:23 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 03:48:23 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 03:48:33 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 03:48:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1354889679 in namespace infra-namespace
2022-04-06 03:48:33 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1354889679 will have desired state: Ready
2022-04-06 03:50:03 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1354889679 is in desired state: Ready
2022-04-06 03:50:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1354889679 in namespace infra-namespace
2022-04-06 03:50:03 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1354889679 will be ready
2022-04-06 03:50:05 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1354889679 is ready
2022-04-06 03:50:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1354889679 in namespace infra-namespace
2022-04-06 03:50:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1354889679 will have desired state: Ready
2022-04-06 03:50:25 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1354889679 is in desired state: Ready
2022-04-06 03:50:25 [main] [32mINFO [m [RecoveryIsolatedST:129] Running deleteKafkaService with cluster recovery-cluster-1354889679
2022-04-06 03:50:25 [main] [32mINFO [m [RecoveryIsolatedST:136] Waiting for creation recovery-cluster-1354889679-zookeeper-client
2022-04-06 03:50:25 [main] [32mINFO [m [ServiceUtils:58] Waiting when Service recovery-cluster-1354889679-zookeeper-client-b099d171-a30d-45d4-9117-a04f94c31a27 in namespace infra-namespace will be recovered
2022-04-06 03:50:46 [main] [32mINFO [m [ServiceUtils:62] recovery-cluster-1354889679-zookeeper-client in namespace infra-namespace is recovered
2022-04-06 03:50:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:50:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromZookeeperServiceDeletion
2022-04-06 03:50:46 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1354889679 in namespace infra-namespace
2022-04-06 03:50:46 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1354889679 in namespace infra-namespace
2022-04-06 03:50:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1354889679 in namespace infra-namespace
2022-04-06 03:51:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:51:36 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperServiceDeletion-FINISHED
2022-04-06 03:51:36 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 03:51:36 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 03:51:36 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromImpossibleMemoryRequest-STARTED
2022-04-06 03:51:36 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 03:51:36 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 03:51:36 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 03:51:36 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 03:51:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:51:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 03:51:36 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:51:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:51:36 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:51:36 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:51:36 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:51:36 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:51:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:51:36 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:51:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:51:36 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:51:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:51:37 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:51:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:51:37 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:51:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:51:37 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:51:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:51:37 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:51:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:51:47 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:51:47 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:51:47 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:51:47 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:51:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:52:02 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 03:52:02 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 03:52:02 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 03:52:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 03:52:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:52:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:52:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:52:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:52:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:52:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:52:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:52:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:52:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:52:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:52:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:52:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:52:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:52:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:52:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:52:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:52:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:52:03 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 03:52:03 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:52:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:52:03 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 03:52:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:52:03 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 03:52:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:52:03 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:52:03 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:52:03 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 03:52:03 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:52:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:52:03 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 03:52:37 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 03:52:37 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 03:52:47 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 03:52:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1774469671 in namespace infra-namespace
2022-04-06 03:52:47 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1774469671 will have desired state: Ready
2022-04-06 03:54:16 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1774469671 is in desired state: Ready
2022-04-06 03:54:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1774469671 in namespace infra-namespace
2022-04-06 03:54:16 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1774469671 will be ready
2022-04-06 03:54:18 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1774469671 is ready
2022-04-06 03:54:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1774469671 in namespace infra-namespace
2022-04-06 03:54:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1774469671 will have desired state: Ready
2022-04-06 03:54:37 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1774469671 is in desired state: Ready
2022-04-06 03:54:37 [main] [32mINFO [m [PodUtils:277] Wait for at least one pod with prefix: recovery-cluster-1774469671-kafka will be in pending phase
2022-04-06 03:54:54 [main] [32mINFO [m [PodUtils:306] Verify that all pods with prefix: recovery-cluster-1774469671-kafka are stable in pending phase
2022-04-06 03:54:54 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 50
2022-04-06 03:54:55 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 49
2022-04-06 03:54:56 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 48
2022-04-06 03:54:57 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 47
2022-04-06 03:54:58 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 46
2022-04-06 03:54:59 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 45
2022-04-06 03:55:00 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 44
2022-04-06 03:55:01 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 43
2022-04-06 03:55:02 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 42
2022-04-06 03:55:03 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 41
2022-04-06 03:55:04 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 40
2022-04-06 03:55:05 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 39
2022-04-06 03:55:06 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 38
2022-04-06 03:55:07 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 37
2022-04-06 03:55:08 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 36
2022-04-06 03:55:09 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 35
2022-04-06 03:55:10 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 34
2022-04-06 03:55:11 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 33
2022-04-06 03:55:12 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 32
2022-04-06 03:55:13 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 31
2022-04-06 03:55:14 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 30
2022-04-06 03:55:15 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 29
2022-04-06 03:55:16 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 28
2022-04-06 03:55:17 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 27
2022-04-06 03:55:18 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 26
2022-04-06 03:55:19 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 25
2022-04-06 03:55:20 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 24
2022-04-06 03:55:21 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 23
2022-04-06 03:55:22 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 22
2022-04-06 03:55:23 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 21
2022-04-06 03:55:24 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 20
2022-04-06 03:55:25 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 19
2022-04-06 03:55:26 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 18
2022-04-06 03:55:27 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 17
2022-04-06 03:55:28 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 16
2022-04-06 03:55:29 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 15
2022-04-06 03:55:30 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 14
2022-04-06 03:55:31 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 13
2022-04-06 03:55:32 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 12
2022-04-06 03:55:33 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 11
2022-04-06 03:55:34 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 10
2022-04-06 03:55:35 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 9
2022-04-06 03:55:37 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 8
2022-04-06 03:55:38 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 7
2022-04-06 03:55:39 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 6
2022-04-06 03:55:40 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 5
2022-04-06 03:55:41 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 4
2022-04-06 03:55:42 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 3
2022-04-06 03:55:43 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 2
2022-04-06 03:55:44 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1774469671-kafka-1 is in the Pending state. Remaining seconds pod to be stable 1
2022-04-06 03:55:44 [main] [32mINFO [m [PodUtils:335] All pods are stable recovery-cluster-1774469671-kafka-1
2022-04-06 03:55:44 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of recovery-cluster-1774469671-kafka to be ready
2022-04-06 04:02:03 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1774469671 will have desired state: Ready
2022-04-06 04:02:03 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1774469671 is in desired state: Ready
2022-04-06 04:02:03 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: recovery-cluster-1774469671 is ready
2022-04-06 04:02:03 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1774469671 will have desired state: Ready
2022-04-06 04:02:03 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1774469671 is in desired state: Ready
2022-04-06 04:02:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:02:03 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromImpossibleMemoryRequest
2022-04-06 04:02:03 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1774469671 in namespace infra-namespace
2022-04-06 04:02:03 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1774469671 in namespace infra-namespace
2022-04-06 04:02:03 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1774469671 in namespace infra-namespace
2022-04-06 04:02:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:02:53 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromImpossibleMemoryRequest-FINISHED
2022-04-06 04:02:53 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:02:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:02:53 [main] [32mINFO [m [ResourceManager:346] In context RecoveryIsolatedST is everything deleted.
2022-04-06 04:02:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;33mWARNING[m] Tests run: 14, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 4,071.091 s - in io.strimzi.systemtest.operators.RecoveryIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST
2022-04-06 04:02:53 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 04:03:18 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 04:03:18 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 04:03:18 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 04:03:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:03:18 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 04:03:18 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:03:18 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:03:18 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 04:03:18 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 04:03:18 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:03:18 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:03:18 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:03:18 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 04:03:18 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 04:03:18 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:03:18 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 04:03:18 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 04:03:18 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 04:03:18 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:03:18 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:03:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:03:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:03:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 04:03:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:03:28 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:03:29 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:03:29 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:03:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:03:39 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:03:44 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=30000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 04:03:44 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 04:03:44 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 04:03:44 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 04:03:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:03:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:03:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 04:03:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 04:03:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 04:03:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 04:03:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:03:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:03:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:03:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:03:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:03:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:03:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:03:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:03:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:03:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:03:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:03:45 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 04:03:45 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 04:03:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 04:03:45 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 04:03:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 04:03:45 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 04:03:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 04:03:45 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 04:03:45 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:03:45 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 04:03:45 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 04:03:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:03:45 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 04:04:04 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 04:04:04 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 04:04:14 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 04:04:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka custom-resource-status-cluster-name in namespace infra-namespace
2022-04-06 04:04:14 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: custom-resource-status-cluster-name will have desired state: Ready
2022-04-06 04:05:32 [main] [32mINFO [m [ResourceManager:444] Kafka: custom-resource-status-cluster-name is in desired state: Ready
2022-04-06 04:05:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-57885039-819052364 in namespace infra-namespace
2022-04-06 04:05:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-57885039-819052364 will have desired state: Ready
2022-04-06 04:05:33 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-57885039-819052364 is in desired state: Ready
2022-04-06 04:05:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment infra-namespace-shared-kafka-clients in namespace infra-namespace
2022-04-06 04:05:33 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: infra-namespace-shared-kafka-clients will be ready
2022-04-06 04:05:35 [main] [32mINFO [m [DeploymentUtils:168] Deployment: infra-namespace-shared-kafka-clients is ready
2022-04-06 04:05:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:05:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicChangingInSyncReplicasStatus-STARTED
2022-04-06 04:05:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:05:35 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2077170631-900757109 in namespace infra-namespace
2022-04-06 04:05:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2077170631-900757109 will have desired state: Ready
2022-04-06 04:05:36 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2077170631-900757109 is in desired state: Ready
2022-04-06 04:05:36 [main] [32mINFO [m [CustomResourceStatusIsolatedST:481] Changing min.insync.replicas to random char
2022-04-06 04:05:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2077170631-900757109 will have desired state: NotReady
2022-04-06 04:05:37 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2077170631-900757109 is in desired state: NotReady
2022-04-06 04:05:37 [main] [32mINFO [m [CustomResourceStatusIsolatedST:488] Wait 245000 ms for next reconciliation
2022-04-06 04:09:42 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:09:42 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaTopicChangingInSyncReplicasStatus
2022-04-06 04:09:42 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2077170631-900757109 in namespace infra-namespace
2022-04-06 04:09:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:09:52 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicChangingInSyncReplicasStatus-FINISHED
2022-04-06 04:09:52 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:09:52 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:09:52 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaUserStatusNotReady-STARTED
2022-04-06 04:09:52 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:09:52 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef in namespace infra-namespace
2022-04-06 04:09:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef will have desired state: NotReady
2022-04-06 04:09:53 [main] [32mINFO [m [ResourceManager:444] KafkaUser: sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef is in desired state: NotReady
2022-04-06 04:09:53 [main] [32mINFO [m [CustomResourceStatusIsolatedST:179] Checking status of deployed KafkaUser sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef
2022-04-06 04:09:53 [main] [32mINFO [m [CustomResourceStatusIsolatedST:181] KafkaUser Status: True
2022-04-06 04:09:53 [main] [32mINFO [m [CustomResourceStatusIsolatedST:182] KafkaUser Type: NotReady
2022-04-06 04:09:53 [main] [32mINFO [m [CustomResourceStatusIsolatedST:183] KafkaUser Message: Spec cannot be null
2022-04-06 04:09:53 [main] [32mINFO [m [CustomResourceStatusIsolatedST:184] KafkaUser Reason: InvalidResourceException
2022-04-06 04:09:53 [main] [32mINFO [m [CustomResourceStatusIsolatedST:186] KafkaUser sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef is in desired state: NotReady
2022-04-06 04:09:53 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef
2022-04-06 04:09:53 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef deleted
2022-04-06 04:09:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:09:53 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaUserStatusNotReady
2022-04-06 04:09:53 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef in namespace infra-namespace
2022-04-06 04:09:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:09:53 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaUserStatusNotReady-FINISHED
2022-04-06 04:09:53 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:09:53 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:09:53 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaUserStatus-STARTED
2022-04-06 04:09:53 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:09:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1676091106-1462754848 in namespace infra-namespace
2022-04-06 04:09:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1676091106-1462754848 will have desired state: Ready
2022-04-06 04:09:54 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1676091106-1462754848 is in desired state: Ready
2022-04-06 04:09:54 [main] [32mINFO [m [CustomResourceStatusIsolatedST:162] Checking status of deployed KafkaUser
2022-04-06 04:09:54 [main] [32mINFO [m [CustomResourceStatusIsolatedST:164] KafkaUser Status: True
2022-04-06 04:09:54 [main] [32mINFO [m [CustomResourceStatusIsolatedST:165] KafkaUser Type: Ready
2022-04-06 04:09:54 [main] [32mINFO [m [CustomResourceStatusIsolatedST:167] KafkaUser is in desired state: Ready
2022-04-06 04:09:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:09:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaUserStatus
2022-04-06 04:09:54 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1676091106-1462754848 in namespace infra-namespace
2022-04-06 04:10:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:10:04 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaUserStatus-FINISHED
2022-04-06 04:10:04 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:10:04 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:10:04 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicStatusNotReady-STARTED
2022-04-06 04:10:04 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:10:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1851297245-1103880992 in namespace infra-namespace
2022-04-06 04:10:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1851297245-1103880992 will have desired state: NotReady
2022-04-06 04:10:05 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1851297245-1103880992 is in desired state: NotReady
2022-04-06 04:10:06 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-1851297245-1103880992 deletion
2022-04-06 04:10:06 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:10:06 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaTopicStatusNotReady
2022-04-06 04:10:06 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1851297245-1103880992 in namespace infra-namespace
2022-04-06 04:10:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:10:06 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicStatusNotReady-FINISHED
2022-04-06 04:10:06 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:10:06 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:10:06 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaStatusCertificate-STARTED
2022-04-06 04:10:06 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:10:06 [main] [32mINFO [m [CustomResourceStatusIsolatedST:381] Check if KafkaStatus certificates are the same as secret certificates
2022-04-06 04:10:06 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:10:06 [main] [32mINFO [m [ResourceManager:346] In context testKafkaStatusCertificate is everything deleted.
2022-04-06 04:10:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:10:06 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaStatusCertificate-FINISHED
2022-04-06 04:10:06 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:10:06 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:10:06 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaBridgeStatus-STARTED
2022-04-06 04:10:06 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:10:06 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge custom-resource-status-cluster-name in namespace infra-namespace
2022-04-06 04:10:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: custom-resource-status-cluster-name will have desired state: Ready
2022-04-06 04:10:23 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: custom-resource-status-cluster-name is in desired state: Ready
2022-04-06 04:10:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: custom-resource-status-cluster-name will have desired state: Ready
2022-04-06 04:10:23 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: custom-resource-status-cluster-name is in desired state: Ready
2022-04-06 04:10:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: custom-resource-status-cluster-name will have desired state: NotReady
2022-04-06 04:10:54 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: custom-resource-status-cluster-name is in desired state: NotReady
2022-04-06 04:10:54 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: custom-resource-status-cluster-name will have desired state: Ready
2022-04-06 04:11:46 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: custom-resource-status-cluster-name is in desired state: Ready
2022-04-06 04:11:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:11:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaBridgeStatus
2022-04-06 04:11:46 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge custom-resource-status-cluster-name in namespace infra-namespace
2022-04-06 04:11:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:11:56 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaBridgeStatus-FINISHED
2022-04-06 04:11:56 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:11:56 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:11:56 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicStatus-STARTED
2022-04-06 04:11:56 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:11:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-38941833-2145853322 in namespace infra-namespace
2022-04-06 04:11:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-38941833-2145853322 will have desired state: Ready
2022-04-06 04:11:57 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-38941833-2145853322 is in desired state: Ready
2022-04-06 04:11:57 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-38941833-2145853322 will have desired state: Ready
2022-04-06 04:11:57 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-38941833-2145853322 is in desired state: Ready
2022-04-06 04:11:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:11:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaTopicStatus
2022-04-06 04:11:57 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-38941833-2145853322 in namespace infra-namespace
2022-04-06 04:12:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:12:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicStatus-FINISHED
2022-04-06 04:12:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:12:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:12:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMaker2Status-STARTED
2022-04-06 04:12:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:12:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-9e4ddeca in namespace infra-namespace
2022-04-06 04:12:07 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-9e4ddeca will have desired state: Ready
2022-04-06 04:13:11 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-9e4ddeca is in desired state: Ready
2022-04-06 04:13:11 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-9e4ddeca-mirror-maker-2 in namespace infra-namespace
2022-04-06 04:13:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-9e4ddeca-mirror-maker-2 will have desired state: Ready
2022-04-06 04:14:23 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-9e4ddeca-mirror-maker-2 is in desired state: Ready
2022-04-06 04:14:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-9e4ddeca-mirror-maker-2 will have desired state: Ready
2022-04-06 04:14:23 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-9e4ddeca-mirror-maker-2 is in desired state: Ready
2022-04-06 04:14:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-9e4ddeca-mirror-maker-2 will have desired state: NotReady
2022-04-06 04:14:54 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-9e4ddeca-mirror-maker-2 is in desired state: NotReady
2022-04-06 04:14:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-9e4ddeca-mirror-maker-2 will have desired state: Ready
2022-04-06 04:16:30 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-9e4ddeca-mirror-maker-2 is in desired state: Ready
2022-04-06 04:16:52 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2 are stable
2022-04-06 04:16:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 04:16:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 04:16:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 04:16:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 04:16:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 04:16:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 04:16:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 04:16:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 04:17:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 04:17:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 04:17:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 04:17:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 04:17:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 04:17:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 04:17:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 04:17:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 04:17:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 04:17:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 04:17:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 04:17:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 04:17:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 04:17:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 04:17:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 04:17:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 04:17:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 04:17:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 04:17:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 04:17:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 04:17:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 04:17:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 04:17:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 04:17:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 04:17:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 04:17:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 04:17:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 04:17:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 04:17:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 04:17:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 04:17:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 04:17:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 04:17:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 04:17:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 04:17:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 04:17:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 04:17:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 04:17:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 04:17:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 04:17:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 04:17:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 04:17:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 04:17:41 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-9e4ddeca-mirror-maker-2-mirrormaker2-7895d8db88h2xgx
2022-04-06 04:17:41 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:17:41 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaMirrorMaker2Status
2022-04-06 04:17:41 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-9e4ddeca-mirror-maker-2 in namespace infra-namespace
2022-04-06 04:17:41 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-9e4ddeca in namespace infra-namespace
2022-04-06 04:17:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:17:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMaker2Status-FINISHED
2022-04-06 04:17:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:17:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:17:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaConnectorWithoutClusterConfig-STARTED
2022-04-06 04:17:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:17:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-37fa2eab in namespace infra-namespace
2022-04-06 04:17:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-37fa2eab will have desired state: NotReady
2022-04-06 04:17:52 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-37fa2eab is in desired state: NotReady
2022-04-06 04:17:52 [main] [32mINFO [m [KafkaConnectorUtils:98] KafkaConnector: my-cluster-37fa2eab is not deleted yet, triggering force delete
2022-04-06 04:17:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:17:53 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectorWithoutClusterConfig
2022-04-06 04:17:53 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-37fa2eab in namespace infra-namespace
2022-04-06 04:17:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:17:53 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaConnectorWithoutClusterConfig-FINISHED
2022-04-06 04:17:53 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:17:53 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:17:53 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMakerStatusWrongBootstrap-STARTED
2022-04-06 04:17:53 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:17:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-46bc7c52 in namespace infra-namespace
2022-04-06 04:17:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-46bc7c52 will have desired state: Ready
2022-04-06 04:19:00 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-46bc7c52 is in desired state: Ready
2022-04-06 04:19:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-46bc7c52 will have desired state: Ready
2022-04-06 04:19:00 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-46bc7c52 is in desired state: Ready
2022-04-06 04:19:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-46bc7c52 will have desired state: NotReady
2022-04-06 04:19:33 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-46bc7c52 is in desired state: NotReady
2022-04-06 04:19:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-46bc7c52 will have desired state: Ready
2022-04-06 04:20:23 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-46bc7c52 is in desired state: Ready
2022-04-06 04:20:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:20:23 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaMirrorMakerStatusWrongBootstrap
2022-04-06 04:20:23 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-46bc7c52 in namespace infra-namespace
2022-04-06 04:20:33 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:20:33 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMakerStatusWrongBootstrap-FINISHED
2022-04-06 04:20:33 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:20:33 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:20:33 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaConnectAndConnectorStatus-STARTED
2022-04-06 04:20:33 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:20:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment custom-resource-status-cluster-name-scraper in namespace infra-namespace
2022-04-06 04:20:33 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: custom-resource-status-cluster-name-scraper will be ready
2022-04-06 04:20:34 [main] [32mINFO [m [DeploymentUtils:168] Deployment: custom-resource-status-cluster-name-scraper is ready
2022-04-06 04:20:34 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment custom-resource-status-cluster-name-scraper to be ready
2022-04-06 04:20:44 [main] [32mINFO [m [DeploymentUtils:197] Deployment custom-resource-status-cluster-name-scraper is ready
2022-04-06 04:20:44 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to custom-resource-status-cluster-name-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 04:20:44 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy custom-resource-status-cluster-name-allow in namespace infra-namespace
2022-04-06 04:20:44 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 04:20:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect custom-resource-status-cluster-name in namespace infra-namespace
2022-04-06 04:20:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: custom-resource-status-cluster-name will have desired state: Ready
2022-04-06 04:21:52 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: custom-resource-status-cluster-name is in desired state: Ready
2022-04-06 04:21:52 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector custom-resource-status-cluster-name in namespace infra-namespace
2022-04-06 04:21:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: custom-resource-status-cluster-name will have desired state: Ready
2022-04-06 04:21:53 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: custom-resource-status-cluster-name is in desired state: Ready
2022-04-06 04:21:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: custom-resource-status-cluster-name will have desired state: NotReady
2022-04-06 04:22:24 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: custom-resource-status-cluster-name is in desired state: NotReady
2022-04-06 04:22:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: custom-resource-status-cluster-name will have desired state: Ready
2022-04-06 04:24:03 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: custom-resource-status-cluster-name is in desired state: Ready
2022-04-06 04:24:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: custom-resource-status-cluster-name will have desired state: NotReady
2022-04-06 04:24:04 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: custom-resource-status-cluster-name is in desired state: NotReady
2022-04-06 04:24:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: custom-resource-status-cluster-name will have desired state: Ready
2022-04-06 04:24:05 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: custom-resource-status-cluster-name is in desired state: Ready
2022-04-06 04:24:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: custom-resource-status-cluster-name will have desired state: NotReady
2022-04-06 04:24:06 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: custom-resource-status-cluster-name is in desired state: NotReady
2022-04-06 04:24:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: custom-resource-status-cluster-name will have desired state: Ready
2022-04-06 04:24:07 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: custom-resource-status-cluster-name is in desired state: Ready
2022-04-06 04:24:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:24:07 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectAndConnectorStatus
2022-04-06 04:24:07 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect custom-resource-status-cluster-name in namespace infra-namespace
2022-04-06 04:24:07 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector custom-resource-status-cluster-name in namespace infra-namespace
2022-04-06 04:24:07 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment custom-resource-status-cluster-name-scraper in namespace infra-namespace
2022-04-06 04:24:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy custom-resource-status-cluster-name-allow in namespace infra-namespace
2022-04-06 04:24:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:24:47 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaConnectAndConnectorStatus-FINISHED
2022-04-06 04:24:47 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:24:47 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:24:47 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMaker2WrongBootstrap-STARTED
2022-04-06 04:24:47 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:24:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-ab5d6822-mirror-maker-2 in namespace infra-namespace
2022-04-06 04:24:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-ab5d6822-mirror-maker-2 will have desired state: NotReady
2022-04-06 04:25:18 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-ab5d6822-mirror-maker-2 is in desired state: NotReady
2022-04-06 04:25:18 [main] [33mWARN [m [DeploymentUtils:213] Deployment my-cluster-ab5d6822-mirror-maker-2-mirrormaker2 is not deleted yet! Triggering force delete by cmd client!
2022-04-06 04:25:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:25:23 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaMirrorMaker2WrongBootstrap
2022-04-06 04:25:23 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-ab5d6822-mirror-maker-2 in namespace infra-namespace
2022-04-06 04:25:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:25:23 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMaker2WrongBootstrap-FINISHED
2022-04-06 04:25:23 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:25:23 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:25:23 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicDecreaseStatus-STARTED
2022-04-06 04:25:23 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:25:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1700350957-169833571 in namespace infra-namespace
2022-04-06 04:25:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1700350957-169833571 will have desired state: Ready
2022-04-06 04:25:24 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1700350957-169833571 is in desired state: Ready
2022-04-06 04:25:24 [main] [32mINFO [m [CustomResourceStatusIsolatedST:457] Decreasing number of partitions to 1
2022-04-06 04:25:24 [main] [32mINFO [m [KafkaTopicUtils:124] Waiting for KafkaTopic change my-topic-1700350957-169833571
2022-04-06 04:25:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1700350957-169833571 will have desired state: NotReady
2022-04-06 04:25:25 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1700350957-169833571 is in desired state: NotReady
2022-04-06 04:25:25 [main] [32mINFO [m [CustomResourceStatusIsolatedST:465] Wait 245000 ms for next reconciliation
2022-04-06 04:29:30 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:29:30 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaTopicDecreaseStatus
2022-04-06 04:29:30 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1700350957-169833571 in namespace infra-namespace
2022-04-06 04:29:40 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:29:40 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicDecreaseStatus-FINISHED
2022-04-06 04:29:40 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:29:40 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:29:40 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMakerStatus-STARTED
2022-04-06 04:29:40 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:29:40 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-90293793-mirror-maker in namespace infra-namespace
2022-04-06 04:29:40 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-90293793-mirror-maker will have desired state: Ready
2022-04-06 04:30:51 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-90293793-mirror-maker is in desired state: Ready
2022-04-06 04:30:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-90293793-mirror-maker will have desired state: Ready
2022-04-06 04:30:51 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-90293793-mirror-maker is in desired state: Ready
2022-04-06 04:30:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-90293793-mirror-maker will have desired state: NotReady
2022-04-06 04:31:23 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-90293793-mirror-maker is in desired state: NotReady
2022-04-06 04:31:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-90293793-mirror-maker will have desired state: Ready
2022-04-06 04:33:10 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-90293793-mirror-maker is in desired state: Ready
2022-04-06 04:33:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:33:10 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaMirrorMakerStatus
2022-04-06 04:33:10 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-90293793-mirror-maker in namespace infra-namespace
2022-04-06 04:33:20 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:33:20 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMakerStatus-FINISHED
2022-04-06 04:33:20 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:33:20 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:33:20 [main] [32mINFO [m [ResourceManager:348] Delete all resources for CustomResourceStatusIsolatedST
2022-04-06 04:33:20 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-57885039-819052364 in namespace infra-namespace
2022-04-06 04:33:20 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka custom-resource-status-cluster-name in namespace infra-namespace
2022-04-06 04:33:20 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment infra-namespace-shared-kafka-clients in namespace infra-namespace
2022-04-06 04:34:00 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,866.612 s - in io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST
2022-04-06 04:34:00 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 04:34:25 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 04:34:25 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 04:34:25 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 04:34:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:34:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 04:34:25 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:34:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:34:25 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:34:25 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 04:34:25 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 04:34:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:34:25 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:34:25 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:34:25 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 04:34:25 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:34:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 04:34:25 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:34:25 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:34:25 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:34:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:34:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:34:35 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:34:35 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 04:34:35 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:34:35 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 04:34:35 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 04:34:35 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:34:35 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 04:34:45 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:34:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:34:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testKafkaCCAndRebalanceWithMultipleCOs-STARTED
2022-04-06 04:34:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:34:51 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:230] Creating first-strimzi-cluster-operator in multiple-co-cluster-test namespace
2022-04-06 04:34:51 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@51a38e96, extensionContext=org.junit.jupiter.engine.descriptor.MethodExtensionContext@4ef4702e, clusterOperatorName='first-strimzi-cluster-operator', namespaceInstallTo='multiple-co-cluster-test', namespaceToWatch='multiple-co-cluster-test', bindingsNamespaces=[multiple-co-cluster-test], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[EnvVar(name=STRIMZI_CUSTOM_RESOURCE_SELECTOR, value=app.kubernetes.io/operator=first-strimzi-cluster-operator, valueFrom=null, additionalProperties={})], extraLabels={app.kubernetes.io/operator=first-strimzi-cluster-operator}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-06 04:34:51 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 04:34:51 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: multiple-co-cluster-test
2022-04-06 04:34:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: multiple-co-cluster-test
2022-04-06 04:34:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:34:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:34:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 04:34:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 04:34:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 04:34:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 04:34:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:34:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:34:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:34:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:34:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:34:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:34:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:34:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:34:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:34:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:34:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:34:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: multiple-co-cluster-test
2022-04-06 04:34:51 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace multiple-co-cluster-test
2022-04-06 04:34:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 04:34:51 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace multiple-co-cluster-test
2022-04-06 04:34:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 04:34:51 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace multiple-co-cluster-test
2022-04-06 04:34:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 04:34:51 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace multiple-co-cluster-test
2022-04-06 04:34:51 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:34:51 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace multiple-co-cluster-test
2022-04-06 04:34:51 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace multiple-co-cluster-test
2022-04-06 04:34:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment first-strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:34:52 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: first-strimzi-cluster-operator will be ready
2022-04-06 04:35:14 [main] [32mINFO [m [DeploymentUtils:168] Deployment: first-strimzi-cluster-operator is ready
2022-04-06 04:35:14 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment first-strimzi-cluster-operator to be ready
2022-04-06 04:35:24 [main] [32mINFO [m [DeploymentUtils:197] Deployment first-strimzi-cluster-operator is ready
2022-04-06 04:35:24 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:230] Creating second-strimzi-cluster-operator in multiple-co-cluster-test namespace
2022-04-06 04:35:24 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@51a38e96, extensionContext=org.junit.jupiter.engine.descriptor.MethodExtensionContext@4ef4702e, clusterOperatorName='second-strimzi-cluster-operator', namespaceInstallTo='multiple-co-cluster-test', namespaceToWatch='multiple-co-cluster-test', bindingsNamespaces=[multiple-co-cluster-test], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[EnvVar(name=STRIMZI_CUSTOM_RESOURCE_SELECTOR, value=app.kubernetes.io/operator=second-strimzi-cluster-operator, valueFrom=null, additionalProperties={})], extraLabels={app.kubernetes.io/operator=second-strimzi-cluster-operator}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-06 04:35:24 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 04:35:24 [main] [32mINFO [m [SetupClusterOperator:254] Environment for ClusterOperator was already prepared! Going to install it now.
2022-04-06 04:35:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:35:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:35:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 04:35:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 04:35:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 04:35:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 04:35:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:35:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:35:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:35:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:35:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:35:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:35:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:35:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:35:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:35:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:35:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:35:24 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: multiple-co-cluster-test
2022-04-06 04:35:24 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace multiple-co-cluster-test
2022-04-06 04:35:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 04:35:24 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace multiple-co-cluster-test
2022-04-06 04:35:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 04:35:24 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace multiple-co-cluster-test
2022-04-06 04:35:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 04:35:24 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace multiple-co-cluster-test
2022-04-06 04:35:24 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:35:24 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace multiple-co-cluster-test
2022-04-06 04:35:24 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace multiple-co-cluster-test
2022-04-06 04:35:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment second-strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:35:24 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: second-strimzi-cluster-operator will be ready
2022-04-06 04:36:03 [main] [32mINFO [m [DeploymentUtils:168] Deployment: second-strimzi-cluster-operator is ready
2022-04-06 04:36:03 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment second-strimzi-cluster-operator to be ready
2022-04-06 04:36:13 [main] [32mINFO [m [DeploymentUtils:197] Deployment second-strimzi-cluster-operator is ready
2022-04-06 04:36:13 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:171] Deploying Kafka with {app.kubernetes.io/operator=first-strimzi-cluster-operator} selector of first-strimzi-cluster-operator
2022-04-06 04:36:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d50f2d11 in namespace multiple-co-cluster-test
2022-04-06 04:36:13 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d50f2d11 will have desired state: Ready
2022-04-06 04:38:00 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d50f2d11 is in desired state: Ready
2022-04-06 04:38:00 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:180] Removing CR selector from Kafka and increasing number of replicas to 4, new pod should not appear
2022-04-06 04:38:00 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:188] Creating KafkaRebalance when CC doesn't have label for CO, the KR should be ignored
2022-04-06 04:38:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-d50f2d11 in namespace multiple-co-cluster-test
2022-04-06 04:38:00 [main] [32mINFO [m [KafkaUtils:180] Waiting for cluster stability
2022-04-06 04:39:02 [main] [32mINFO [m [KafkaUtils:208] Kafka cluster is stable after 61 polls.
2022-04-06 04:39:02 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:204] Checking if KafkaRebalance is still ignored, after the cluster stability wait
2022-04-06 04:39:02 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:209] Adding {app.kubernetes.io/operator=second-strimzi-cluster-operator} selector of second-strimzi-cluster-operator to Kafka
2022-04-06 04:39:02 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:212] Waiting for Kafka to scales pods to 4
2022-04-06 04:39:02 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 4 Pod(s) of my-cluster-d50f2d11-kafka to be ready
2022-04-06 04:42:47 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d50f2d11 will have desired state: Ready
2022-04-06 04:42:47 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d50f2d11 is in desired state: Ready
2022-04-06 04:42:47 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-d50f2d11 is ready
2022-04-06 04:42:47 [main] [32mINFO [m [KafkaRebalanceUtils:75] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-d50f2d11): ============================================================================
2022-04-06 04:42:47 [main] [32mINFO [m [KafkaRebalanceUtils:76] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-d50f2d11): NotReady
2022-04-06 04:42:47 [main] [32mINFO [m [KafkaRebalanceUtils:77] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-d50f2d11): ============================================================================
2022-04-06 04:42:47 [main] [32mINFO [m [KafkaRebalanceUtils:81] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-d50f2d11): Verifying that KafkaRebalance resource is in PendingProposal state
2022-04-06 04:42:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-d50f2d11 will have desired state: PendingProposal
2022-04-06 04:48:47 [main] [32mINFO [m [ResourceManager:414] KafkaRebalance status:

Conditions:

Pods with conditions and messages:

my-cluster-d50f2d11-cruise-control-69579fb9c7-ht7lv:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-d50f2d11-entity-operator-7976748c66-qbn4r:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-d50f2d11-kafka-0:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-d50f2d11-kafka-1:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-d50f2d11-kafka-2:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-d50f2d11-kafka-3:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-d50f2d11-zookeeper-0:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-d50f2d11-zookeeper-1:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-d50f2d11-zookeeper-2:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>
io.strimzi.test.WaitException: Timeout after 360000 ms waiting for KafkaRebalance: my-cluster-d50f2d11 will have desired state: PendingProposal
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.systemtest.resources.ResourceManager.waitForResourceStatus(ResourceManager.java:435)
	at io.strimzi.systemtest.resources.ResourceManager.waitForResourceStatus(ResourceManager.java:428)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaRebalanceUtils.waitForKafkaRebalanceCustomResourceState(KafkaRebalanceUtils.java:55)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaRebalanceUtils.doRebalancingProcess(KafkaRebalanceUtils.java:83)
	at io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testKafkaCCAndRebalanceWithMultipleCOs(MultipleClusterOperatorsIsolatedST.java:217)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-06 04:48:47 [main] [1;31mERROR[m [TestExecutionWatcher:28] MultipleClusterOperatorsIsolatedST - Exception Timeout after 360000 ms waiting for KafkaRebalance: my-cluster-d50f2d11 will have desired state: PendingProposal has been thrown in @Test. Going to collect logs from components.
2022-04-06 04:48:47 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace multiple-co-cluster-test
2022-04-06 04:48:47 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace multiple-co-cluster-test
2022-04-06 04:48:47 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace multiple-co-cluster-test
2022-04-06 04:48:51 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace multiple-co-cluster-test
2022-04-06 04:48:51 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace multiple-co-cluster-test
2022-04-06 04:48:51 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace multiple-co-cluster-test
2022-04-06 04:48:51 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace multiple-co-cluster-test
2022-04-06 04:48:51 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-06 04:48:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:48:51 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaCCAndRebalanceWithMultipleCOs
2022-04-06 04:48:51 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:48:51 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:48:51 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 04:48:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:48:51 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 04:48:51 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:48:51 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d50f2d11 in namespace multiple-co-cluster-test
2022-04-06 04:48:51 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace multiple-co-cluster-test, for cruise control Kafka cluster my-cluster-d50f2d11
2022-04-06 04:48:51 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:48:51 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 04:48:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace multiple-co-cluster-test
2022-04-06 04:48:51 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 04:48:51 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:48:51 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment second-strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:48:51 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 04:48:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 04:48:51 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:48:51 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 04:48:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:48:51 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:49:01 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 04:49:01 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:49:01 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:49:01 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:49:02 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-d50f2d11 in namespace multiple-co-cluster-test
2022-04-06 04:49:02 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:49:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:49:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:49:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:49:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:49:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 04:49:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:49:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:49:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:49:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:49:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 04:49:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:49:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:49:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 04:49:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 04:49:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:49:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace multiple-co-cluster-test
2022-04-06 04:49:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 04:49:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:49:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:49:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment first-strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:49:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 04:49:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:49:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:49:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:49:12 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testKafkaCCAndRebalanceWithMultipleCOs-FINISHED
2022-04-06 04:49:12 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:49:12 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:49:12 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testMultipleCOsInDifferentNamespaces-STARTED
2022-04-06 04:49:12 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:49:12 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 04:49:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding first-strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:49:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding first-strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 04:49:12 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:230] Creating first-strimzi-cluster-operator in first-co-namespace namespace
2022-04-06 04:49:12 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@51a38e96, extensionContext=org.junit.jupiter.engine.descriptor.MethodExtensionContext@194a1fd6, clusterOperatorName='first-strimzi-cluster-operator', namespaceInstallTo='first-co-namespace', namespaceToWatch='*', bindingsNamespaces=[first-co-namespace], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[EnvVar(name=STRIMZI_CUSTOM_RESOURCE_SELECTOR, value=app.kubernetes.io/operator=first-strimzi-cluster-operator, valueFrom=null, additionalProperties={})], extraLabels={app.kubernetes.io/operator=first-strimzi-cluster-operator}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-06 04:49:12 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 04:49:12 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: first-co-namespace
2022-04-06 04:49:12 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: first-co-namespace
2022-04-06 04:49:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace first-co-namespace
2022-04-06 04:49:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:49:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 04:49:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 04:49:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 04:49:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 04:49:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:49:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:49:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:49:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:49:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:49:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:49:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:49:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:49:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:49:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:49:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace first-co-namespace
2022-04-06 04:49:12 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: first-co-namespace
2022-04-06 04:49:12 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace first-co-namespace
2022-04-06 04:49:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 04:49:12 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace first-co-namespace
2022-04-06 04:49:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 04:49:12 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace first-co-namespace
2022-04-06 04:49:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 04:49:12 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace first-co-namespace
2022-04-06 04:49:12 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace first-co-namespace
2022-04-06 04:49:12 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace first-co-namespace
2022-04-06 04:49:12 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace first-co-namespace
2022-04-06 04:49:12 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 04:49:12 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 04:49:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:49:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 04:49:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment first-strimzi-cluster-operator in namespace first-co-namespace
2022-04-06 04:49:13 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: first-strimzi-cluster-operator will be ready
2022-04-06 04:49:53 [main] [32mINFO [m [DeploymentUtils:168] Deployment: first-strimzi-cluster-operator is ready
2022-04-06 04:49:53 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment first-strimzi-cluster-operator to be ready
2022-04-06 04:50:03 [main] [32mINFO [m [DeploymentUtils:197] Deployment first-strimzi-cluster-operator is ready
2022-04-06 04:50:03 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 04:50:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding second-strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:50:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding second-strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 04:50:03 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:230] Creating second-strimzi-cluster-operator in second-co-namespace namespace
2022-04-06 04:50:03 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@51a38e96, extensionContext=org.junit.jupiter.engine.descriptor.MethodExtensionContext@194a1fd6, clusterOperatorName='second-strimzi-cluster-operator', namespaceInstallTo='second-co-namespace', namespaceToWatch='*', bindingsNamespaces=[second-co-namespace], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[EnvVar(name=STRIMZI_CUSTOM_RESOURCE_SELECTOR, value=app.kubernetes.io/operator=second-strimzi-cluster-operator, valueFrom=null, additionalProperties={})], extraLabels={app.kubernetes.io/operator=second-strimzi-cluster-operator}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-06 04:50:03 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 04:50:03 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: second-co-namespace
2022-04-06 04:50:03 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-co-namespace
2022-04-06 04:50:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace second-co-namespace
2022-04-06 04:50:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:50:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 04:50:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 04:50:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 04:50:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 04:50:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:50:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:50:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:50:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:50:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:50:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:50:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:50:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:50:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:50:04 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:50:04 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace second-co-namespace
2022-04-06 04:50:04 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: second-co-namespace
2022-04-06 04:50:04 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace second-co-namespace
2022-04-06 04:50:04 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 04:50:04 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace second-co-namespace
2022-04-06 04:50:04 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 04:50:04 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace second-co-namespace
2022-04-06 04:50:04 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 04:50:04 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace second-co-namespace
2022-04-06 04:50:04 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace second-co-namespace
2022-04-06 04:50:04 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace second-co-namespace
2022-04-06 04:50:04 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-co-namespace
2022-04-06 04:50:04 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 04:50:04 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 04:50:04 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:50:04 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 04:50:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment second-strimzi-cluster-operator in namespace second-co-namespace
2022-04-06 04:50:04 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: second-strimzi-cluster-operator will be ready
2022-04-06 04:50:16 [main] [32mINFO [m [DeploymentUtils:168] Deployment: second-strimzi-cluster-operator is ready
2022-04-06 04:50:16 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment second-strimzi-cluster-operator to be ready
2022-04-06 04:50:26 [main] [32mINFO [m [DeploymentUtils:197] Deployment second-strimzi-cluster-operator is ready
2022-04-06 04:50:26 [main] [33mWARN [m [KubeClusterResource:151] Namespace multiple-co-cluster-test is already created, going to delete it
2022-04-06 04:50:32 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: multiple-co-cluster-test
2022-04-06 04:50:32 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: multiple-co-cluster-test
2022-04-06 04:50:32 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: multiple-co-cluster-test
2022-04-06 04:50:32 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:100] Deploying Kafka without CR selector
2022-04-06 04:50:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d6fbbb6e in namespace multiple-co-cluster-test
2022-04-06 04:50:32 [main] [32mINFO [m [PodUtils:209] Wait until Pod my-cluster-d6fbbb6e will have stable 0 replicas
2022-04-06 04:50:32 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 19 polls
2022-04-06 04:50:33 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 18 polls
2022-04-06 04:50:34 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 17 polls
2022-04-06 04:50:35 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 16 polls
2022-04-06 04:50:36 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 15 polls
2022-04-06 04:50:37 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 14 polls
2022-04-06 04:50:38 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 13 polls
2022-04-06 04:50:39 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 12 polls
2022-04-06 04:50:40 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 11 polls
2022-04-06 04:50:41 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 10 polls
2022-04-06 04:50:42 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 9 polls
2022-04-06 04:50:43 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 8 polls
2022-04-06 04:50:44 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 7 polls
2022-04-06 04:50:45 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 6 polls
2022-04-06 04:50:46 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 5 polls
2022-04-06 04:50:47 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 4 polls
2022-04-06 04:50:48 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 3 polls
2022-04-06 04:50:49 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 2 polls
2022-04-06 04:50:50 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 1 polls
2022-04-06 04:50:51 [main] [32mINFO [m [PodUtils:217] Pod replicas are stable for 20 polls intervals
2022-04-06 04:50:51 [main] [32mINFO [m [PodUtils:228] Pod my-cluster-d6fbbb6e has 0 replicas
2022-04-06 04:50:51 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:110] Adding {app.kubernetes.io/operator=first-strimzi-cluster-operator} selector of first-strimzi-cluster-operator into Kafka CR
2022-04-06 04:50:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d6fbbb6e will have desired state: Ready
2022-04-06 04:52:14 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d6fbbb6e is in desired state: Ready
2022-04-06 04:52:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1485246696-1680293809 in namespace multiple-co-cluster-test
2022-04-06 04:52:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-d6fbbb6e in namespace multiple-co-cluster-test
2022-04-06 04:52:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1485246696-1680293809 will have desired state: Ready
2022-04-06 04:52:15 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1485246696-1680293809 is in desired state: Ready
2022-04-06 04:52:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-d6fbbb6e will have desired state: Ready
2022-04-06 04:53:19 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-d6fbbb6e is in desired state: Ready
2022-04-06 04:53:19 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:130] Deploying KafkaConnector with file sink and CR selector - {app.kubernetes.io/operator=second-strimzi-cluster-operator} - different than selector in Kafka
2022-04-06 04:53:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-d6fbbb6e in namespace multiple-co-cluster-test
2022-04-06 04:53:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-d6fbbb6e will have desired state: Ready
2022-04-06 04:53:20 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-d6fbbb6e is in desired state: Ready
2022-04-06 04:53:20 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 04:53:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-producer in namespace multiple-co-cluster-test
2022-04-06 04:53:20 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-producer will be in active state
2022-04-06 04:53:21 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:hello-world-producer to finished
2022-04-06 04:53:29 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-d6fbbb6e-connect-69bb946c6c-894j8
2022-04-06 04:53:29 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-d6fbbb6e-connect-69bb946c6c-894j8
2022-04-06 04:53:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:53:29 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMultipleCOsInDifferentNamespaces
2022-04-06 04:53:29 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:53:29 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:53:29 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 04:53:29 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:53:29 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:53:29 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 04:53:29 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment second-strimzi-cluster-operator in namespace second-co-namespace
2022-04-06 04:53:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:53:29 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 04:53:29 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d6fbbb6e in namespace multiple-co-cluster-test
2022-04-06 04:53:29 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 04:53:29 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace second-co-namespace
2022-04-06 04:53:29 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 04:53:29 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-co-namespace
2022-04-06 04:53:29 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace second-co-namespace
2022-04-06 04:53:29 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:53:29 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 04:53:29 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:53:29 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-d6fbbb6e in namespace multiple-co-cluster-test
2022-04-06 04:53:30 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-producer in namespace multiple-co-cluster-test
2022-04-06 04:53:30 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1485246696-1680293809 in namespace multiple-co-cluster-test
2022-04-06 04:53:30 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-d6fbbb6e in namespace multiple-co-cluster-test
2022-04-06 04:53:30 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:53:30 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 04:53:30 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:53:39 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:53:39 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:53:39 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 04:53:39 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace first-co-namespace
2022-04-06 04:53:39 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 04:53:39 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 04:53:39 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 04:53:39 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 04:53:39 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding first-strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 04:53:39 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:53:39 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:53:39 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:53:39 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:53:39 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace first-co-namespace
2022-04-06 04:53:39 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding first-strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:53:39 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:53:39 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:53:39 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:53:39 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:53:39 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 04:53:39 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 04:53:39 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment first-strimzi-cluster-operator in namespace first-co-namespace
2022-04-06 04:53:39 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding second-strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:53:40 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding second-strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 04:53:40 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace first-co-namespace
2022-04-06 04:53:40 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:53:40 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 04:53:40 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:53:40 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace first-co-namespace
2022-04-06 04:53:40 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:53:40 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:53:40 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 04:53:40 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace second-co-namespace
2022-04-06 04:53:40 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:53:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:53:50 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testMultipleCOsInDifferentNamespaces-FINISHED
2022-04-06 04:53:50 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:53:50 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:53:50 [main] [32mINFO [m [ResourceManager:346] In context MultipleClusterOperatorsIsolatedST is everything deleted.
2022-04-06 04:53:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;31mERROR[m] Tests run: 2, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 1,189.643 s <<< FAILURE! - in io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST
[[1;31mERROR[m] io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testKafkaCCAndRebalanceWithMultipleCOs(ExtensionContext)  Time elapsed: 861.013 s  <<< ERROR!
io.strimzi.test.WaitException: Timeout after 360000 ms waiting for KafkaRebalance: my-cluster-d50f2d11 will have desired state: PendingProposal
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.systemtest.resources.ResourceManager.waitForResourceStatus(ResourceManager.java:435)
	at io.strimzi.systemtest.resources.ResourceManager.waitForResourceStatus(ResourceManager.java:428)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaRebalanceUtils.waitForKafkaRebalanceCustomResourceState(KafkaRebalanceUtils.java:55)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaRebalanceUtils.doRebalancingProcess(KafkaRebalanceUtils.java:83)
	at io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testKafkaCCAndRebalanceWithMultipleCOs(MultipleClusterOperatorsIsolatedST.java:217)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)

[[1;34mINFO[m] Running io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST
2022-04-06 04:53:50 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 04:54:15 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:54:15 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST.testCRBDeletionErrorsWhenRackAwarenessIsEnabled-STARTED
2022-04-06 04:54:15 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:54:15 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 04:54:15 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 04:54:15 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 04:54:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:54:15 [main] [32mINFO [m [ResourceManager:346] In context JUnit Jupiter is everything deleted.
2022-04-06 04:54:15 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:54:40 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@51a38e96, extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e, clusterOperatorName='strimzi-cluster-operator', namespaceInstallTo='infra-namespace', namespaceToWatch='infra-namespace', bindingsNamespaces=[infra-namespace], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[], extraLabels={}, clusterOperatorRBACType=NAMESPACE, testClassName='null', testMethodName='null'}
2022-04-06 04:54:40 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 04:54:40 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 04:54:40 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 04:54:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:54:40 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-06 04:54:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-06 04:54:41 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-06 04:54:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-06 04:54:41 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRole-strimzi-kafka-broker.yaml
2022-04-06 04:54:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-broker in namespace infra-namespace
2022-04-06 04:54:41 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-ClusterRole-strimzi-entity-operator.yaml
2022-04-06 04:54:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-entity-operator in namespace infra-namespace
2022-04-06 04:54:41 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRole-strimzi-kafka-client.yaml
2022-04-06 04:54:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-client in namespace infra-namespace
2022-04-06 04:54:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:54:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:54:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:54:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:54:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:54:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:54:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:54:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:54:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:54:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:54:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:54:41 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 04:54:41 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-06 04:54:41 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/020-Role-strimzi-cluster-operator-role11651966118680274406.yaml in namespace infra-namespace
2022-04-06 04:54:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-06 04:54:41 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-06 04:54:41 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/021-Role-strimzi-cluster-operator-role8835455988650806962.yaml in namespace infra-namespace
2022-04-06 04:54:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-06 04:54:41 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRole-strimzi-kafka-broker.yaml
2022-04-06 04:54:41 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/030-Role-strimzi-kafka-broker13546855255886907093.yaml in namespace infra-namespace
2022-04-06 04:54:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-broker in namespace infra-namespace
2022-04-06 04:54:41 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-ClusterRole-strimzi-entity-operator.yaml
2022-04-06 04:54:41 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/031-Role-strimzi-entity-operator382495644159121369.yaml in namespace infra-namespace
2022-04-06 04:54:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-entity-operator in namespace infra-namespace
2022-04-06 04:54:41 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRole-strimzi-kafka-client.yaml
2022-04-06 04:54:41 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/033-Role-strimzi-kafka-client4138132755539912015.yaml in namespace infra-namespace
2022-04-06 04:54:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-client in namespace infra-namespace
2022-04-06 04:54:41 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml
2022-04-06 04:54:41 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/020-Role-strimzi-cluster-operator5422018712397121432.yaml in namespace infra-namespace
2022-04-06 04:54:41 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:54:41 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml
2022-04-06 04:54:41 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/031-Role-strimzi-cluster-operator-entity-operator-delegation1546261274594823460.yaml in namespace infra-namespace
2022-04-06 04:54:41 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 04:54:41 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml
2022-04-06 04:54:41 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/020-Role-strimzi-cluster-operator14301124613973608281.yaml in namespace infra-namespace
2022-04-06 04:54:41 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:54:41 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml
2022-04-06 04:54:41 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/031-Role-strimzi-cluster-operator-entity-operator-delegation5081619334894990671.yaml in namespace infra-namespace
2022-04-06 04:54:41 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 04:54:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:54:41 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 04:55:02 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 04:55:02 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 04:55:12 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 04:55:12 [main] [32mINFO [m [ClusterOperatorRbacIsolatedST:99] Deploying Kafka: my-cluster-e0b3bbfb, which should not be deployed and error should be present in CR status message
2022-04-06 04:55:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e0b3bbfb in namespace infra-namespace
2022-04-06 04:55:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-e0b3bbfb-kafka-clients in namespace infra-namespace
2022-04-06 04:55:45 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-e0b3bbfb-kafka-clients will be ready
2022-04-06 04:55:47 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-e0b3bbfb-kafka-clients is ready
2022-04-06 04:55:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-e0b3bbfb-scraper in namespace infra-namespace
2022-04-06 04:55:47 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-e0b3bbfb-scraper will be ready
2022-04-06 04:55:49 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-e0b3bbfb-scraper is ready
2022-04-06 04:55:49 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-e0b3bbfb-scraper to be ready
2022-04-06 04:55:59 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-e0b3bbfb-scraper is ready
2022-04-06 04:55:59 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-e0b3bbfb-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 04:55:59 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-e0b3bbfb-allow in namespace infra-namespace
2022-04-06 04:55:59 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 04:55:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-e0b3bbfb in namespace infra-namespace
2022-04-06 04:56:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:56:00 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCRBDeletionErrorsWhenRackAwarenessIsEnabled
2022-04-06 04:56:00 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-e0b3bbfb-scraper in namespace infra-namespace
2022-04-06 04:56:00 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-e0b3bbfb-kafka-clients in namespace infra-namespace
2022-04-06 04:56:00 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-e0b3bbfb-allow in namespace infra-namespace
2022-04-06 04:56:00 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e0b3bbfb in namespace infra-namespace
2022-04-06 04:56:00 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-e0b3bbfb in namespace infra-namespace
2022-04-06 04:56:41 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:56:41 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST.testCRBDeletionErrorsWhenRackAwarenessIsEnabled-FINISHED
2022-04-06 04:56:41 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:56:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:56:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST.testCRBDeletionErrorIsIgnoredWhenRackAwarenessIsNotEnabled-STARTED
2022-04-06 04:56:41 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:56:41 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 04:56:41 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 04:56:41 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 04:56:41 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:56:41 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 04:56:41 [main] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-06 04:56:41 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-client in namespace infra-namespace
2022-04-06 04:56:41 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:56:41 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:56:41 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:56:41 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 04:56:41 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:56:41 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-entity-operator in namespace infra-namespace
2022-04-06 04:56:41 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:56:41 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 04:56:41 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:56:41 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-broker in namespace infra-namespace
2022-04-06 04:56:41 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-broker in namespace infra-namespace
2022-04-06 04:56:41 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-06 04:56:41 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-client in namespace infra-namespace
2022-04-06 04:56:41 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:56:41 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-06 04:56:41 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-06 04:56:41 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-entity-operator in namespace infra-namespace
2022-04-06 04:56:41 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:56:41 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:56:41 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:56:41 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:56:51 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:56:51 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:56:51 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:56:51 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:57:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:57:06 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@51a38e96, extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e, clusterOperatorName='strimzi-cluster-operator', namespaceInstallTo='infra-namespace', namespaceToWatch='infra-namespace', bindingsNamespaces=[infra-namespace], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[], extraLabels={}, clusterOperatorRBACType=NAMESPACE, testClassName='null', testMethodName='null'}
2022-04-06 04:57:06 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 04:57:06 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 04:57:06 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 04:57:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:57:06 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-06 04:57:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-06 04:57:06 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-06 04:57:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-06 04:57:06 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRole-strimzi-kafka-broker.yaml
2022-04-06 04:57:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-broker in namespace infra-namespace
2022-04-06 04:57:06 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-ClusterRole-strimzi-entity-operator.yaml
2022-04-06 04:57:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-entity-operator in namespace infra-namespace
2022-04-06 04:57:06 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRole-strimzi-kafka-client.yaml
2022-04-06 04:57:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-client in namespace infra-namespace
2022-04-06 04:57:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:57:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:57:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:57:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:57:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:57:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:57:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:57:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:57:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:57:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:57:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:57:06 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 04:57:06 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-06 04:57:06 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/020-Role-strimzi-cluster-operator-role7772296844983352315.yaml in namespace infra-namespace
2022-04-06 04:57:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-06 04:57:06 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-06 04:57:06 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/021-Role-strimzi-cluster-operator-role6045676272055602022.yaml in namespace infra-namespace
2022-04-06 04:57:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-06 04:57:06 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRole-strimzi-kafka-broker.yaml
2022-04-06 04:57:06 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/030-Role-strimzi-kafka-broker15685661728231274878.yaml in namespace infra-namespace
2022-04-06 04:57:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-broker in namespace infra-namespace
2022-04-06 04:57:06 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-ClusterRole-strimzi-entity-operator.yaml
2022-04-06 04:57:06 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/031-Role-strimzi-entity-operator1583965016465692453.yaml in namespace infra-namespace
2022-04-06 04:57:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-entity-operator in namespace infra-namespace
2022-04-06 04:57:06 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRole-strimzi-kafka-client.yaml
2022-04-06 04:57:06 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/033-Role-strimzi-kafka-client5456962852463418566.yaml in namespace infra-namespace
2022-04-06 04:57:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-client in namespace infra-namespace
2022-04-06 04:57:06 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml
2022-04-06 04:57:06 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/020-Role-strimzi-cluster-operator4402100156427868170.yaml in namespace infra-namespace
2022-04-06 04:57:06 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:57:06 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml
2022-04-06 04:57:06 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/031-Role-strimzi-cluster-operator-entity-operator-delegation15757343736225791042.yaml in namespace infra-namespace
2022-04-06 04:57:06 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 04:57:06 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml
2022-04-06 04:57:06 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/020-Role-strimzi-cluster-operator376320622124027302.yaml in namespace infra-namespace
2022-04-06 04:57:06 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:57:07 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml
2022-04-06 04:57:07 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/031-Role-strimzi-cluster-operator-entity-operator-delegation1601499401647740837.yaml in namespace infra-namespace
2022-04-06 04:57:07 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 04:57:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:57:07 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 04:57:34 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 04:57:34 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 04:57:44 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 04:57:44 [main] [32mINFO [m [ClusterOperatorRbacIsolatedST:63] Deploying Kafka: my-cluster-ff5f3576, which should be deployed even the CRBs are not present
2022-04-06 04:57:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ff5f3576 in namespace infra-namespace
2022-04-06 04:57:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ff5f3576 will have desired state: Ready
2022-04-06 04:59:08 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ff5f3576 is in desired state: Ready
2022-04-06 04:59:08 [main] [32mINFO [m [ClusterOperatorRbacIsolatedST:67] CO log should contain some information about ignoring forbidden access to CRB for Kafka
2022-04-06 04:59:08 [main] [32mINFO [m [ClusterOperatorRbacIsolatedST:71] Deploying KafkaConnect: my-cluster-ff5f3576 without rack awareness, the CR should be deployed without error
2022-04-06 04:59:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-ff5f3576 in namespace infra-namespace
2022-04-06 04:59:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-ff5f3576 will have desired state: Ready
2022-04-06 05:00:16 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-ff5f3576 is in desired state: Ready
2022-04-06 05:00:16 [main] [32mINFO [m [ClusterOperatorRbacIsolatedST:74] CO log should contain some information about ignoring forbidden access to CRB for KafkaConnect
2022-04-06 05:00:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:00:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCRBDeletionErrorIsIgnoredWhenRackAwarenessIsNotEnabled
2022-04-06 05:00:17 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-ff5f3576 in namespace infra-namespace
2022-04-06 05:00:17 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ff5f3576 in namespace infra-namespace
2022-04-06 05:00:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:00:27 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST.testCRBDeletionErrorIsIgnoredWhenRackAwarenessIsNotEnabled-FINISHED
2022-04-06 05:00:27 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:00:27 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:00:27 [main] [32mINFO [m [ResourceManager:346] In context ClusterOperatorRbacIsolatedST is everything deleted.
2022-04-06 05:00:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 396.963 s - in io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.bridge.HttpBridgeIsolatedST
2022-04-06 05:00:27 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:00:52 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 05:00:52 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 05:00:52 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 05:00:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:00:52 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 05:00:52 [main] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-06 05:00:52 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-broker in namespace infra-namespace
2022-04-06 05:00:52 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 05:00:52 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:00:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-broker in namespace infra-namespace
2022-04-06 05:00:52 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-06 05:00:52 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 05:00:52 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:00:52 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 05:00:52 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-06 05:00:52 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-06 05:00:52 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:00:52 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-client in namespace infra-namespace
2022-04-06 05:00:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:00:52 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:00:52 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:00:52 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-entity-operator in namespace infra-namespace
2022-04-06 05:00:52 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 05:00:52 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-client in namespace infra-namespace
2022-04-06 05:00:52 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:00:52 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-entity-operator in namespace infra-namespace
2022-04-06 05:00:52 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 05:00:52 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:02 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 05:01:02 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:02 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:01:17 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
, extraEnvVars=[EnvVar(name=STRIMZI_CUSTOM_KAFKA_BRIDGE_SERVICE_LABELS, value=app=bar, valueFrom=null, additionalProperties={}), EnvVar(name=STRIMZI_CUSTOM_KAFKA_BRIDGE_SERVICE_ANNOTATIONS, value=bar=app, valueFrom=null, additionalProperties={})]
2022-04-06 05:01:17 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 05:01:17 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 05:01:17 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:01:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:01:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:01:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 05:01:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 05:01:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 05:01:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 05:01:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 05:01:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:18 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:18 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:18 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:01:18 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 05:01:18 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:01:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:01:18 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 05:01:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:01:18 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 05:01:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:01:18 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:01:18 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:01:18 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 05:01:18 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 05:01:18 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 05:01:18 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 05:01:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:01:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 05:01:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:01:18 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 05:01:59 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 05:01:59 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 05:02:09 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 05:02:09 [main] [32mINFO [m [HttpBridgeIsolatedST:434] Deploy Kafka and KafkaBridge before tests
2022-04-06 05:02:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka http-bridge-cluster-name in namespace infra-namespace
2022-04-06 05:02:09 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: http-bridge-cluster-name will have desired state: Ready
2022-04-06 05:03:19 [main] [32mINFO [m [ResourceManager:444] Kafka: http-bridge-cluster-name is in desired state: Ready
2022-04-06 05:03:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment infra-namespace-shared-kafka-clients in namespace infra-namespace
2022-04-06 05:03:19 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: infra-namespace-shared-kafka-clients will be ready
2022-04-06 05:03:21 [main] [32mINFO [m [DeploymentUtils:168] Deployment: infra-namespace-shared-kafka-clients is ready
2022-04-06 05:03:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge http-bridge-cluster-name in namespace infra-namespace
2022-04-06 05:03:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: http-bridge-cluster-name will have desired state: Ready
2022-04-06 05:03:47 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: http-bridge-cluster-name is in desired state: Ready
2022-04-06 05:03:47 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:03:47 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testReceiveSimpleMessage-STARTED
2022-04-06 05:03:47 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:03:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1599947192-979875850 in namespace infra-namespace
2022-04-06 05:03:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1599947192-979875850 will have desired state: Ready
2022-04-06 05:03:48 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1599947192-979875850 is in desired state: Ready
2022-04-06 05:03:48 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 05:03:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-313646063 in namespace infra-namespace
2022-04-06 05:03:48 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-313646063 will be in active state
2022-04-06 05:03:49 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 05:03:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-1892882593 in namespace infra-namespace
2022-04-06 05:03:49 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-1892882593 will be in active state
2022-04-06 05:03:50 [main] [32mINFO [m [ClientUtils:61] Waiting till producer producer-1892882593 and consumer consumer-313646063 finish
2022-04-06 05:04:01 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:04:01 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testReceiveSimpleMessage
2022-04-06 05:04:01 [main] [32mINFO [m [ResourceManager:241] Delete of Job consumer-313646063 in namespace infra-namespace
2022-04-06 05:04:01 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1599947192-979875850 in namespace infra-namespace
2022-04-06 05:04:01 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job producer-1892882593 in namespace infra-namespace
2022-04-06 05:04:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:04:11 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testReceiveSimpleMessage-FINISHED
2022-04-06 05:04:11 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:04:11 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:04:11 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testConfigureDeploymentStrategy-STARTED
2022-04-06 05:04:11 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:04:11 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge example-bridge in namespace infra-namespace
2022-04-06 05:04:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: example-bridge will have desired state: Ready
2022-04-06 05:04:35 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: example-bridge is in desired state: Ready
2022-04-06 05:04:35 [main] [32mINFO [m [HttpBridgeIsolatedST:351] Adding label to KafkaBridge resource, the CR should be recreated
2022-04-06 05:04:35 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: example-bridge-bridge will be ready
2022-04-06 05:04:35 [main] [32mINFO [m [DeploymentUtils:168] Deployment: example-bridge-bridge is ready
2022-04-06 05:04:35 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment example-bridge-bridge to be ready
2022-04-06 05:05:11 [main] [32mINFO [m [DeploymentUtils:197] Deployment example-bridge-bridge is ready
2022-04-06 05:05:11 [main] [32mINFO [m [HttpBridgeIsolatedST:358] Checking that observed gen. is still on 1 (recreation) and new label is present
2022-04-06 05:05:11 [main] [32mINFO [m [HttpBridgeIsolatedST:363] Changing deployment strategy to ROLLING_UPDATE
2022-04-06 05:05:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: example-bridge will have desired state: Ready
2022-04-06 05:05:11 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: example-bridge is in desired state: Ready
2022-04-06 05:05:11 [main] [32mINFO [m [HttpBridgeIsolatedST:368] Adding another label to KafkaBridge resource, pods should be rolled
2022-04-06 05:05:11 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: example-bridge-bridge will be ready
2022-04-06 05:05:11 [main] [32mINFO [m [DeploymentUtils:168] Deployment: example-bridge-bridge is ready
2022-04-06 05:05:11 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment example-bridge-bridge to be ready
2022-04-06 05:05:54 [main] [32mINFO [m [DeploymentUtils:197] Deployment example-bridge-bridge is ready
2022-04-06 05:05:54 [main] [32mINFO [m [HttpBridgeIsolatedST:372] Checking that observed gen. higher (rolling update) and label is changed
2022-04-06 05:05:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:05:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigureDeploymentStrategy
2022-04-06 05:05:54 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge example-bridge in namespace infra-namespace
2022-04-06 05:06:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:06:04 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testConfigureDeploymentStrategy-FINISHED
2022-04-06 05:06:04 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:06:04 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:06:04 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testScaleBridgeToZero-STARTED
2022-04-06 05:06:04 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:06:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge scaling-bridge-down in namespace infra-namespace
2022-04-06 05:06:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: scaling-bridge-down will have desired state: Ready
2022-04-06 05:06:24 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: scaling-bridge-down is in desired state: Ready
2022-04-06 05:06:24 [main] [32mINFO [m [HttpBridgeIsolatedST:285] Scaling KafkaBridge to zero replicas
2022-04-06 05:06:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: http-bridge-cluster-name will have desired state: Ready
2022-04-06 05:06:24 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: http-bridge-cluster-name is in desired state: Ready
2022-04-06 05:06:27 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:06:27 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleBridgeToZero
2022-04-06 05:06:27 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge scaling-bridge-down in namespace infra-namespace
2022-04-06 05:06:37 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:06:37 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testScaleBridgeToZero-FINISHED
2022-04-06 05:06:37 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:06:37 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:06:37 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testDiscoveryAnnotation-STARTED
2022-04-06 05:06:37 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:06:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:06:37 [main] [32mINFO [m [ResourceManager:346] In context testDiscoveryAnnotation is everything deleted.
2022-04-06 05:06:37 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:06:37 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testDiscoveryAnnotation-FINISHED
2022-04-06 05:06:37 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:06:37 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:06:37 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testCustomBridgeLabelsAreProperlySet-STARTED
2022-04-06 05:06:37 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:06:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge bridge-my-cluster-8ed18dcb in namespace infra-namespace
2022-04-06 05:06:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: bridge-my-cluster-8ed18dcb will have desired state: Ready
2022-04-06 05:06:59 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: bridge-my-cluster-8ed18dcb is in desired state: Ready
2022-04-06 05:06:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:06:59 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCustomBridgeLabelsAreProperlySet
2022-04-06 05:06:59 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge bridge-my-cluster-8ed18dcb in namespace infra-namespace
2022-04-06 05:07:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:07:09 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testCustomBridgeLabelsAreProperlySet-FINISHED
2022-04-06 05:07:09 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:07:09 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:07:09 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testScaleBridgeSubresource-STARTED
2022-04-06 05:07:09 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:07:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge scaling-bridge-up in namespace infra-namespace
2022-04-06 05:07:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: scaling-bridge-up will have desired state: Ready
2022-04-06 05:07:29 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: scaling-bridge-up is in desired state: Ready
2022-04-06 05:07:29 [main] [32mINFO [m [HttpBridgeIsolatedST:312] -------> Scaling KafkaBridge subresource <-------
2022-04-06 05:07:29 [main] [32mINFO [m [HttpBridgeIsolatedST:313] Scaling subresource replicas to 4
2022-04-06 05:07:29 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: scaling-bridge-up-bridge will be ready
2022-04-06 05:07:29 [main] [32mINFO [m [DeploymentUtils:168] Deployment: scaling-bridge-up-bridge is ready
2022-04-06 05:07:29 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 4 Pod(s) of Deployment scaling-bridge-up-bridge to be ready
2022-04-06 05:08:03 [main] [32mINFO [m [DeploymentUtils:197] Deployment scaling-bridge-up-bridge is ready
2022-04-06 05:08:03 [main] [32mINFO [m [HttpBridgeIsolatedST:317] Check if replicas is set to 4, naming prefix should be same and observed generation higher
2022-04-06 05:08:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:08:03 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleBridgeSubresource
2022-04-06 05:08:03 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge scaling-bridge-up in namespace infra-namespace
2022-04-06 05:08:14 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:08:14 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testScaleBridgeSubresource-FINISHED
2022-04-06 05:08:14 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:08:14 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:08:14 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testCustomAndUpdatedValues-STARTED
2022-04-06 05:08:14 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:08:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge custom-bridge in namespace infra-namespace
2022-04-06 05:08:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: custom-bridge will have desired state: Ready
2022-04-06 05:08:53 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: custom-bridge is in desired state: Ready
2022-04-06 05:08:53 [main] [32mINFO [m [HttpBridgeIsolatedST:225] Verify values before update
2022-04-06 05:08:53 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix custom-bridge-bridge in pod name
2022-04-06 05:08:53 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container custom-bridge-bridge
2022-04-06 05:08:53 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name custom-bridge-bridge
2022-04-06 05:08:53 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container custom-bridge-bridge
2022-04-06 05:08:53 [main] [32mINFO [m [HttpBridgeIsolatedST:230] Check if actual env variable KAFKA_BRIDGE_PRODUCER_CONFIG has different value than test.value
2022-04-06 05:08:53 [main] [32mINFO [m [HttpBridgeIsolatedST:236] Updating values in Bridge container
2022-04-06 05:08:53 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment custom-bridge-bridge rolling update
2022-04-06 05:09:33 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: custom-bridge-bridge will be ready
2022-04-06 05:09:33 [main] [32mINFO [m [DeploymentUtils:168] Deployment: custom-bridge-bridge is ready
2022-04-06 05:09:43 [main] [32mINFO [m [DeploymentUtils:141] Deployment custom-bridge-bridge rolling update finished
2022-04-06 05:09:43 [main] [32mINFO [m [HttpBridgeIsolatedST:253] Verify values after update
2022-04-06 05:09:43 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix custom-bridge-bridge in pod name
2022-04-06 05:09:43 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container custom-bridge-bridge
2022-04-06 05:09:43 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name custom-bridge-bridge
2022-04-06 05:09:43 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container custom-bridge-bridge
2022-04-06 05:09:43 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name custom-bridge-bridge
2022-04-06 05:09:43 [main] [32mINFO [m [AbstractST:194] Testing configuration for container custom-bridge-bridge
2022-04-06 05:09:43 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name custom-bridge-bridge
2022-04-06 05:09:43 [main] [32mINFO [m [AbstractST:194] Testing configuration for container custom-bridge-bridge
2022-04-06 05:09:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:09:43 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCustomAndUpdatedValues
2022-04-06 05:09:43 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge custom-bridge in namespace infra-namespace
2022-04-06 05:09:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:09:53 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testCustomAndUpdatedValues-FINISHED
2022-04-06 05:09:53 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:09:53 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:09:53 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testSendSimpleMessage-STARTED
2022-04-06 05:09:53 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:09:53 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 05:09:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1759552423-801571654 in namespace infra-namespace
2022-04-06 05:09:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1759552423-801571654 will have desired state: Ready
2022-04-06 05:09:54 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1759552423-801571654 is in desired state: Ready
2022-04-06 05:09:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-125487360 in namespace infra-namespace
2022-04-06 05:09:54 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-125487360 will be in active state
2022-04-06 05:09:55 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:producer-125487360 to finished
2022-04-06 05:11:43 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 05:11:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-519568280 in namespace infra-namespace
2022-04-06 05:11:43 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-519568280 will be in active state
2022-04-06 05:11:44 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:consumer-519568280 to finished
2022-04-06 05:11:54 [main] [32mINFO [m [AbstractST:311] Verifying labels on pod type my-bridge
2022-04-06 05:11:54 [main] [32mINFO [m [AbstractST:356] Verifying labels for Kafka Connect Services
2022-04-06 05:11:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:11:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendSimpleMessage
2022-04-06 05:11:54 [main] [32mINFO [m [ResourceManager:241] Delete of Job producer-125487360 in namespace infra-namespace
2022-04-06 05:11:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job consumer-519568280 in namespace infra-namespace
2022-04-06 05:11:54 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1759552423-801571654 in namespace infra-namespace
2022-04-06 05:12:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:12:04 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testSendSimpleMessage-FINISHED
2022-04-06 05:12:04 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:12:04 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:12:04 [main] [32mINFO [m [ResourceManager:348] Delete all resources for HttpBridgeIsolatedST
2022-04-06 05:12:04 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment infra-namespace-shared-kafka-clients in namespace infra-namespace
2022-04-06 05:12:04 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge http-bridge-cluster-name in namespace infra-namespace
2022-04-06 05:12:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka http-bridge-cluster-name in namespace infra-namespace
2022-04-06 05:12:45 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 737.928 s - in io.strimzi.systemtest.bridge.HttpBridgeIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.specific.HelmChartIsolatedST
2022-04-06 05:12:45 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:13:10 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 05:13:10 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 05:13:10 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 05:13:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:13:10 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 05:13:10 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 05:13:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:13:10 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 05:13:10 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 05:13:10 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 05:13:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:13:10 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:13:10 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:13:10 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:13:10 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 05:13:10 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:13:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 05:13:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 05:13:10 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 05:13:10 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:13:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:13:10 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 05:13:10 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:13:10 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 05:13:10 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:13:10 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:13:10 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 05:13:10 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 05:13:20 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 05:13:20 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 05:13:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:13:35 [main] [32mINFO [m [HelmChartIsolatedST:67] Creating resources before the test class
2022-04-06 05:13:35 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 05:13:36 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:13:36 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: kube-system
2022-04-06 05:13:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace kube-system apply -f -
2022-04-06 05:13:36 [main] [32mINFO [m [Exec:417] Input: apiVersion: v1
kind: ServiceAccount
metadata:
  name: tiller
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: tiller
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
  - kind: ServiceAccount
    name: tiller
    namespace: kube-system
2022-04-06 05:13:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 05:13:36 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:13:36 [main] [32mINFO [m [HelmClient:44] Installing helm-chart strimzi-systemtests
2022-04-06 05:13:51 [main] [32mINFO [m [Exec:417] Command: helm install strimzi-systemtests --set defaultImageRegistry=quay.io,defaultImageRepository=strimzi,fullReconciliationIntervalMs=30000,kafkaBridge.image.tag=latest,resources.limits.memory=512Mi,kafkaBridge.image.repository=strimzi,featureGates=,image.imagePullPolicy=Always,watchAnyNamespace=false,resources.requests.memory=512Mi,operationTimeoutMs=300000,resources.limits.cpu=1000m,logLevelOverride=DEBUG,defaultImageTag=latest,resources.requests.cpu=200m,kafkaBridge.image.registry=quay.io --timeout 120s --debug /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/helm-charts/helm3/strimzi-kafka-operator --namespace infra-namespace --wait
2022-04-06 05:13:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 05:13:51 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 05:13:51 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 05:13:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:13:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.specific.HelmChartIsolatedST.testStrimziComponentsViaHelmChart-STARTED
2022-04-06 05:13:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:13:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-f2f59ece-kafka-clients in namespace infra-namespace
2022-04-06 05:13:51 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f2f59ece-kafka-clients will be ready
2022-04-06 05:13:53 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f2f59ece-kafka-clients is ready
2022-04-06 05:13:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-f2f59ece in namespace infra-namespace
2022-04-06 05:13:53 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f2f59ece will have desired state: Ready
2022-04-06 05:15:22 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f2f59ece is in desired state: Ready
2022-04-06 05:15:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-f2f59ece-scraper in namespace infra-namespace
2022-04-06 05:15:22 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f2f59ece-scraper will be ready
2022-04-06 05:15:24 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f2f59ece-scraper is ready
2022-04-06 05:15:24 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-f2f59ece-scraper to be ready
2022-04-06 05:15:34 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-f2f59ece-scraper is ready
2022-04-06 05:15:34 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-f2f59ece-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 05:15:34 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-f2f59ece-allow in namespace infra-namespace
2022-04-06 05:15:34 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 05:15:35 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-281159040-1771917530 in namespace infra-namespace
2022-04-06 05:15:35 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-f2f59ece in namespace infra-namespace
2022-04-06 05:15:35 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge my-cluster-f2f59ece in namespace infra-namespace
2022-04-06 05:15:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-281159040-1771917530 will have desired state: Ready
2022-04-06 05:15:36 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-281159040-1771917530 is in desired state: Ready
2022-04-06 05:15:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-f2f59ece will have desired state: Ready
2022-04-06 05:16:44 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-f2f59ece is in desired state: Ready
2022-04-06 05:16:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: my-cluster-f2f59ece will have desired state: Ready
2022-04-06 05:16:44 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: my-cluster-f2f59ece is in desired state: Ready
2022-04-06 05:16:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-f2f59ece in namespace infra-namespace
2022-04-06 05:16:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-f2f59ece will have desired state: Ready
2022-04-06 05:16:45 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-f2f59ece is in desired state: Ready
2022-04-06 05:16:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:16:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testStrimziComponentsViaHelmChart
2022-04-06 05:16:45 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-f2f59ece in namespace infra-namespace
2022-04-06 05:16:45 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-281159040-1771917530 in namespace infra-namespace
2022-04-06 05:16:45 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-f2f59ece-scraper in namespace infra-namespace
2022-04-06 05:16:45 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-f2f59ece-allow in namespace infra-namespace
2022-04-06 05:16:45 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-f2f59ece in namespace infra-namespace
2022-04-06 05:16:45 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-f2f59ece in namespace infra-namespace
2022-04-06 05:16:45 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge my-cluster-f2f59ece in namespace infra-namespace
2022-04-06 05:16:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-f2f59ece-kafka-clients in namespace infra-namespace
2022-04-06 05:17:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:17:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.specific.HelmChartIsolatedST.testStrimziComponentsViaHelmChart-FINISHED
2022-04-06 05:17:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:17:35 [main] [32mINFO [m [HelmClient:71] Deleting helm-chart:strimzi-systemtests in namespace:infra-namespace
2022-04-06 05:17:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:17:35 [main] [32mINFO [m [ResourceManager:348] Delete all resources for HelmChartIsolatedST
2022-04-06 05:17:35 [main] [32mINFO [m [HelmClient:71] Deleting helm-chart:strimzi-systemtests in namespace:infra-namespace
2022-04-06 05:17:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:17:35 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 05:17:35 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 05:17:35 [main] [33mWARN [m [KubeClusterResource:151] Namespace infra-namespace is already created, going to delete it
2022-04-06 05:17:46 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 05:17:46 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:17:46 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:17:46 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:17:46 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 05:17:46 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 05:17:46 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 05:17:46 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 05:17:46 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 05:17:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 05:17:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 05:17:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 05:17:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:17:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:17:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 05:17:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 05:17:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 05:17:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 05:17:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:17:47 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 05:17:47 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:17:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:17:47 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 05:17:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:17:47 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 05:17:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:17:47 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:17:47 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:17:47 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 05:17:47 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 05:17:47 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 05:17:47 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 05:17:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:17:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 05:17:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:17:47 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 05:18:19 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 05:18:19 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 05:18:29 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 344.769 s - in io.strimzi.systemtest.specific.HelmChartIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.specific.SpecificIsolatedST
2022-04-06 05:18:29 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:18:54 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 05:18:54 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 05:18:54 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 05:18:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:18:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 05:18:54 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 05:18:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:18:54 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:18:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:18:54 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 05:18:54 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 05:18:54 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 05:18:54 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:18:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 05:18:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:18:54 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:18:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 05:18:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 05:18:54 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:18:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 05:18:54 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:18:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 05:18:54 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 05:18:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 05:18:54 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:18:54 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:18:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 05:18:55 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:19:04 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 05:19:04 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 05:19:05 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:19:10 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 05:19:10 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 05:19:10 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 05:19:10 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:19:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:19:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:19:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 05:19:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 05:19:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 05:19:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 05:19:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 05:19:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 05:19:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 05:19:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 05:19:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:19:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:19:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 05:19:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 05:19:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 05:19:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 05:19:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:19:10 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 05:19:10 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:19:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:19:10 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 05:19:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:19:10 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 05:19:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:19:10 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:19:10 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:19:10 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 05:19:10 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 05:19:10 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 05:19:10 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 05:19:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:19:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 05:19:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:19:11 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 05:19:45 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 05:19:45 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 05:19:55 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 05:19:55 [main] [32mINFO [m [SpecificIsolatedST:508] 0.21.4
2022-04-06 05:19:55 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:19:55 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.specific.SpecificIsolatedST.testRackAware-STARTED
2022-04-06 05:19:55 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:19:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-90470944 in namespace infra-namespace
2022-04-06 05:19:55 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-90470944 will have desired state: Ready
2022-04-06 05:21:13 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-90470944 is in desired state: Ready
2022-04-06 05:21:13 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-90470944-kafka-0 -- /bin/bash -c cat /opt/kafka/init/rack.id
2022-04-06 05:21:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 05:21:13 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-90470944-kafka-0 -- /bin/bash -c cat /tmp/strimzi.properties | grep broker.rack
2022-04-06 05:21:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 05:21:13 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 05:21:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-producer in namespace infra-namespace
2022-04-06 05:21:13 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-producer will be in active state
2022-04-06 05:21:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-consumer in namespace infra-namespace
2022-04-06 05:21:14 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-consumer will be in active state
2022-04-06 05:21:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:21:15 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRackAware
2022-04-06 05:21:15 [main] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-producer in namespace infra-namespace
2022-04-06 05:21:15 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-90470944 in namespace infra-namespace
2022-04-06 05:21:15 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-consumer in namespace infra-namespace
2022-04-06 05:21:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:21:25 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.specific.SpecificIsolatedST.testRackAware-FINISHED
2022-04-06 05:21:25 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:21:25 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:21:25 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.specific.SpecificIsolatedST.testRackAwareConnectWrongDeployment-STARTED
2022-04-06 05:21:25 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:21:25 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 05:21:25 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 05:21:25 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 05:21:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:21:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 05:21:25 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 05:21:25 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 05:21:25 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 05:21:25 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:21:25 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:21:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 05:21:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:21:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:21:25 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:21:25 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 05:21:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 05:21:25 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 05:21:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:21:25 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:21:25 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:21:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 05:21:25 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 05:21:25 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:21:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 05:21:25 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:21:26 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 05:21:26 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 05:21:35 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 05:21:35 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 05:21:35 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:21:46 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:21:51 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@51a38e96, extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e, clusterOperatorName='strimzi-cluster-operator', namespaceInstallTo='infra-namespace', namespaceToWatch='infra-namespace', bindingsNamespaces=[infra-namespace], operationTimeout=30000, reconciliationInterval=30000, extraEnvVars=[], extraLabels={}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-06 05:21:51 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 05:21:51 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 05:21:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:21:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:21:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:21:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 05:21:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 05:21:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 05:21:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 05:21:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 05:21:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 05:21:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 05:21:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 05:21:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:21:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:21:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 05:21:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 05:21:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 05:21:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 05:21:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:21:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 05:21:51 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:21:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:21:51 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 05:21:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:21:51 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 05:21:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:21:51 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:21:51 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:21:51 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 05:21:51 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 05:21:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:21:51 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 05:22:30 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 05:22:30 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 05:22:40 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 05:22:40 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment strimzi-cluster-operator rolling update
2022-04-06 05:22:40 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 05:22:40 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 05:22:50 [main] [32mINFO [m [DeploymentUtils:141] Deployment strimzi-cluster-operator rolling update finished
2022-04-06 05:22:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-8fc466f2 in namespace infra-namespace
2022-04-06 05:22:50 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8fc466f2 will have desired state: Ready
2022-04-06 05:24:17 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8fc466f2 is in desired state: Ready
2022-04-06 05:24:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-8fc466f2-kafka-clients in namespace infra-namespace
2022-04-06 05:24:17 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-8fc466f2-kafka-clients will be ready
2022-04-06 05:24:19 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-8fc466f2-kafka-clients is ready
2022-04-06 05:24:19 [main] [32mINFO [m [SpecificIsolatedST:196] Deploy KafkaConnect with wrong rack-aware topology key: wrong-key
2022-04-06 05:24:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-8fc466f2-scraper in namespace infra-namespace
2022-04-06 05:24:19 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-8fc466f2-scraper will be ready
2022-04-06 05:24:20 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-8fc466f2-scraper is ready
2022-04-06 05:24:20 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-8fc466f2-scraper to be ready
2022-04-06 05:24:30 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-8fc466f2-scraper is ready
2022-04-06 05:24:30 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-8fc466f2-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 05:24:30 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-8fc466f2-allow in namespace infra-namespace
2022-04-06 05:24:30 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 05:24:30 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-8fc466f2 in namespace infra-namespace
2022-04-06 05:24:30 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-8fc466f2-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 05:24:30 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-8fc466f2-allow in namespace infra-namespace
2022-04-06 05:24:30 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 05:24:30 [main] [32mINFO [m [PodUtils:277] Wait for at least one pod with prefix: my-cluster-8fc466f2-connect will be in pending phase
2022-04-06 05:24:31 [main] [32mINFO [m [SpecificIsolatedST:227] Waiting for ClusterOperator to get timeout operation of incorrectly set up KafkaConnect
2022-04-06 05:25:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-8fc466f2 will have desired state: Ready
2022-04-06 05:26:39 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-8fc466f2 is in desired state: Ready
2022-04-06 05:26:39 [main] [32mINFO [m [SpecificIsolatedST:238] KafkaConnect is ready with changed rack key: 'rack-key'.
2022-04-06 05:26:39 [main] [32mINFO [m [SpecificIsolatedST:239] Verify KafkaConnect rack key update
2022-04-06 05:26:39 [main] [32mINFO [m [KafkaConnectUtils:156] Send and receive messages through KafkaConnect
2022-04-06 05:26:39 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-06 05:26:40 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-8fc466f2-connect-5655cfdbd7-wcmpv -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-06 05:26:40 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 05:26:40 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-06 05:26:40 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-8fc466f2-scraper-7c54f66866-qvxnp -- /bin/bash -c curl -X POST -H "Content-Type: application/json" --data '{ "name": "sink-test", "config": { "connector.class": "FileStreamSink", "tasks.max": "1", "topics": "my-topic-57885039-819052364", "file": "/tmp/test-file-sink.txt" } }' http://my-cluster-8fc466f2-connect-api.infra-namespace.svc:8083/connectors
2022-04-06 05:26:40 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 05:26:40 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 05:26:40 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@34b20646, messages=[], arguments=[--max-messages, 100, --topic, my-topic-57885039-819052364, --bootstrap-server, my-cluster-8fc466f2-kafka-bootstrap.infra-namespace.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-8fc466f2-kafka-clients-b99b7bd5-zx877', podNamespace='infra-namespace', bootstrapServer='my-cluster-8fc466f2-kafka-bootstrap.infra-namespace.svc:9092', topicName='my-topic-57885039-819052364', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@266c5ea3}
2022-04-06 05:26:40 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-8fc466f2-kafka-bootstrap.infra-namespace.svc:9092:my-topic-57885039-819052364 from pod my-cluster-8fc466f2-kafka-clients-b99b7bd5-zx877
2022-04-06 05:26:40 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-8fc466f2-kafka-clients-b99b7bd5-zx877 -n infra-namespace -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-57885039-819052364 --bootstrap-server my-cluster-8fc466f2-kafka-bootstrap.infra-namespace.svc:9092
2022-04-06 05:26:42 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 05:26:42 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-06 05:26:42 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2cf2a9be, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-627144741, --group-instance-id, instance127980874, --topic, my-topic-57885039-819052364, --bootstrap-server, my-cluster-8fc466f2-kafka-bootstrap.infra-namespace.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-8fc466f2-kafka-clients-b99b7bd5-zx877', podNamespace='infra-namespace', bootstrapServer='my-cluster-8fc466f2-kafka-bootstrap.infra-namespace.svc:9092', topicName='my-topic-57885039-819052364', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-627144741', consumerInstanceId='instance127980874', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@437f4bf0}
2022-04-06 05:26:42 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-8fc466f2-kafka-bootstrap.infra-namespace.svc:9092#my-topic-57885039-819052364 from pod my-cluster-8fc466f2-kafka-clients-b99b7bd5-zx877
2022-04-06 05:26:42 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-8fc466f2-kafka-clients-b99b7bd5-zx877 -n infra-namespace -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-627144741 --group-instance-id instance127980874 --topic my-topic-57885039-819052364 --bootstrap-server my-cluster-8fc466f2-kafka-bootstrap.infra-namespace.svc:9092
2022-04-06 05:26:48 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 05:26:48 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-06 05:26:48 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-8fc466f2-connect-5655cfdbd7-wcmpv
2022-04-06 05:26:48 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-8fc466f2-connect-5655cfdbd7-wcmpv
2022-04-06 05:26:48 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 05:26:48 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 05:26:48 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 05:26:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:26:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 05:26:48 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 05:26:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 05:26:48 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:26:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:26:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 05:26:48 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 05:26:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 05:26:48 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:26:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 05:26:48 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 05:26:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:26:48 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:26:48 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:26:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 05:26:49 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:26:49 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 05:26:49 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 05:26:49 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 05:26:49 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:26:49 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 05:26:58 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:26:58 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:26:59 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 05:27:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:27:55 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@51a38e96, extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e, clusterOperatorName='strimzi-cluster-operator', namespaceInstallTo='infra-namespace', namespaceToWatch='infra-namespace', bindingsNamespaces=[infra-namespace], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[], extraLabels={}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-06 05:27:55 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 05:27:55 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 05:27:56 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:27:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:27:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:27:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 05:27:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 05:27:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 05:27:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 05:27:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 05:27:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 05:27:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 05:27:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 05:27:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:27:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:27:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 05:27:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 05:27:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 05:27:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 05:27:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:27:56 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 05:27:56 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:27:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:27:56 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 05:27:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:27:56 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 05:27:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:27:56 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:27:56 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:27:56 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 05:27:56 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 05:27:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:27:56 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 05:28:23 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 05:28:23 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 05:28:33 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 05:28:33 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment strimzi-cluster-operator rolling update
2022-04-06 05:28:33 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 05:28:33 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 05:28:43 [main] [32mINFO [m [DeploymentUtils:141] Deployment strimzi-cluster-operator rolling update finished
2022-04-06 05:28:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:28:43 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRackAwareConnectWrongDeployment
2022-04-06 05:28:43 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-8fc466f2-allow in namespace infra-namespace
2022-04-06 05:28:43 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-8fc466f2-allow in namespace infra-namespace
2022-04-06 05:28:43 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-8fc466f2-scraper in namespace infra-namespace
2022-04-06 05:28:43 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-8fc466f2-kafka-clients in namespace infra-namespace
2022-04-06 05:28:43 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-8fc466f2 in namespace infra-namespace
2022-04-06 05:28:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-8fc466f2 in namespace infra-namespace
2022-04-06 05:28:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:28:43 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.specific.SpecificIsolatedST.testRackAwareConnectWrongDeployment-FINISHED
2022-04-06 05:28:43 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:28:43 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:28:43 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.specific.SpecificIsolatedST.testDeployUnsupportedKafka-STARTED
2022-04-06 05:28:43 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:28:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d7a1c425 in namespace infra-namespace
2022-04-06 05:28:43 [main] [32mINFO [m [SpecificIsolatedST:414] Kafka with version 6.6.6 deployed.
2022-04-06 05:28:43 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d7a1c425 will have desired state: NotReady
2022-04-06 05:28:44 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d7a1c425 is in desired state: NotReady
2022-04-06 05:28:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:28:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeployUnsupportedKafka
2022-04-06 05:28:46 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d7a1c425 in namespace infra-namespace
2022-04-06 05:28:46 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:28:46 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.specific.SpecificIsolatedST.testDeployUnsupportedKafka-FINISHED
2022-04-06 05:28:46 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:28:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:28:46 [main] [32mINFO [m [ResourceManager:346] In context SpecificIsolatedST is everything deleted.
2022-04-06 05:28:46 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 617.047 s - in io.strimzi.systemtest.specific.SpecificIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.specific.DrainCleanerIsolatedST
2022-04-06 05:28:46 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:29:11 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 05:29:11 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 05:29:11 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 05:29:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:29:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 05:29:11 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 05:29:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 05:29:11 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 05:29:11 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:29:11 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 05:29:11 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:29:11 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:29:11 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 05:29:11 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:29:11 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:29:11 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 05:29:11 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 05:29:11 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 05:29:11 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:29:11 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 05:29:11 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:29:11 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 05:29:12 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:29:12 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 05:29:12 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:29:21 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:29:21 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 05:29:21 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 05:29:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:29:27 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=strimzi-drain-cleaner
namespaceToWatch=strimzi-drain-cleaner
bindingsNamespaces=[strimzi-drain-cleaner]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 05:29:27 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 05:29:27 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: strimzi-drain-cleaner
2022-04-06 05:29:27 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: strimzi-drain-cleaner
2022-04-06 05:29:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-06 05:29:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:29:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 05:29:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 05:29:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 05:29:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 05:29:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 05:29:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 05:29:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 05:29:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 05:29:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:29:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:29:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 05:29:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 05:29:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 05:29:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 05:29:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-06 05:29:27 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: strimzi-drain-cleaner
2022-04-06 05:29:27 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace strimzi-drain-cleaner
2022-04-06 05:29:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:29:27 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace strimzi-drain-cleaner
2022-04-06 05:29:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:29:27 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace strimzi-drain-cleaner
2022-04-06 05:29:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:29:27 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace strimzi-drain-cleaner
2022-04-06 05:29:27 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-06 05:29:27 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace strimzi-drain-cleaner
2022-04-06 05:29:27 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace strimzi-drain-cleaner
2022-04-06 05:29:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-06 05:29:27 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 05:29:57 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 05:29:57 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 05:30:07 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 05:30:07 [main] [32mINFO [m [RequiredMinKubeApiVersionCondition:30] testDrainCleanerWithComponents is @RequiredMinKubeApiVersion with version 1.17, but the running on cluster with 1.16: Ignoring testDrainCleanerWithComponents
2022-04-06 05:30:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:30:07 [main] [32mINFO [m [ResourceManager:346] In context DrainCleanerIsolatedST is everything deleted.
2022-04-06 05:30:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;33mWARNING[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 2, Time elapsed: 80.429 s - in io.strimzi.systemtest.specific.DrainCleanerIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST
2022-04-06 05:30:07 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:30:32 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 05:30:32 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 05:30:32 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 05:30:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:30:32 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 05:30:32 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 05:30:32 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-06 05:30:32 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 05:30:32 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 05:30:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:30:32 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 05:30:32 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 05:30:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:30:32 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-06 05:30:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:30:32 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 05:30:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-06 05:30:32 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace strimzi-drain-cleaner
2022-04-06 05:30:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:30:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 05:30:32 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 05:30:32 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-06 05:30:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:30:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 05:30:32 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 05:30:32 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 05:30:42 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:30:42 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 05:30:42 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:31:08 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace,second-namespace-test
bindingsNamespaces=[infra-namespace, second-namespace-test]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 05:31:08 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 05:31:08 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 05:31:09 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: second-namespace-test
2022-04-06 05:31:09 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:31:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:31:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:31:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 05:31:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 05:31:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 05:31:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 05:31:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 05:31:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 05:31:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 05:31:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 05:31:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:31:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:31:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 05:31:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 05:31:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 05:31:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 05:31:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:31:09 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 05:31:09 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: second-namespace-test
2022-04-06 05:31:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:31:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:31:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 05:31:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:31:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 05:31:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:31:09 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:31:09 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:31:09 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 05:31:09 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 05:31:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:31:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:31:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 05:31:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:31:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 05:31:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:31:09 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:31:09 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace second-namespace-test
2022-04-06 05:31:09 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 05:31:09 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-namespace-test
2022-04-06 05:31:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:31:09 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 05:31:39 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 05:31:39 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 05:31:49 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 05:31:49 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-06 05:31:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster in namespace second-namespace-test
2022-04-06 05:31:49 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster will have desired state: Ready
2022-04-06 05:33:09 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster is in desired state: Ready
2022-04-06 05:33:09 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:33:09 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:33:09 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST.testKafkaInDifferentNsThanClusterOperator-STARTED
2022-04-06 05:33:09 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:33:09 [main] [32mINFO [m [MultipleNamespaceIsolatedST:59] Deploying Kafka in different namespace than CO when CO watches multiple namespaces
2022-04-06 05:33:09 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-06 05:33:09 [main] [32mINFO [m [AbstractNamespaceST:46] Check if Kafka Cluster my-cluster in namespace second-namespace-test
2022-04-06 05:33:09 [main] [32mINFO [m [AbstractNamespaceST:51] Kafka condition status: True
2022-04-06 05:33:09 [main] [32mINFO [m [AbstractNamespaceST:52] Kafka condition type: Ready
2022-04-06 05:33:09 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:33:09 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:33:09 [main] [32mINFO [m [ResourceManager:346] In context testKafkaInDifferentNsThanClusterOperator is everything deleted.
2022-04-06 05:33:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:33:09 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST.testKafkaInDifferentNsThanClusterOperator-FINISHED
2022-04-06 05:33:09 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:33:09 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:33:09 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST.testTopicOperatorWatchingOtherNamespace-STARTED
2022-04-06 05:33:09 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:33:09 [main] [32mINFO [m [MultipleNamespaceIsolatedST:45] Deploying TO to watch a different namespace that it is deployed in
2022-04-06 05:33:09 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-06 05:33:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace second-namespace-test exec my-cluster-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-06 05:33:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 05:33:11 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-159176149-1784461398 in namespace infra-namespace
2022-04-06 05:33:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-159176149-1784461398 will have desired state: Ready
2022-04-06 05:33:12 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-159176149-1784461398 is in desired state: Ready
2022-04-06 05:33:12 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:33:12 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTopicOperatorWatchingOtherNamespace
2022-04-06 05:33:12 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-159176149-1784461398 in namespace infra-namespace
2022-04-06 05:33:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:33:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST.testTopicOperatorWatchingOtherNamespace-FINISHED
2022-04-06 05:33:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:33:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:33:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST.testDeployMirrorMakerAcrossMultipleNamespace-STARTED
2022-04-06 05:33:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:33:22 [main] [32mINFO [m [MultipleNamespaceIsolatedST:69] Deploying KafkaMirrorMaker in different namespace than CO when CO watches multiple namespaces
2022-04-06 05:33:22 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-06 05:33:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-target in namespace second-namespace-test
2022-04-06 05:33:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-target will have desired state: Ready
2022-04-06 05:34:36 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-target is in desired state: Ready
2022-04-06 05:34:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster in namespace second-namespace-test
2022-04-06 05:34:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster will have desired state: Ready
2022-04-06 05:35:46 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster is in desired state: Ready
2022-04-06 05:35:46 [main] [32mINFO [m [AbstractNamespaceST:71] Waiting for creation my-cluster-mirror-maker in namespace second-namespace-test
2022-04-06 05:35:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster will have desired state: Ready
2022-04-06 05:35:46 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster is in desired state: Ready
2022-04-06 05:35:46 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-06 05:35:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:35:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeployMirrorMakerAcrossMultipleNamespace
2022-04-06 05:35:46 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster in namespace second-namespace-test
2022-04-06 05:35:46 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-target in namespace second-namespace-test
2022-04-06 05:35:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:35:56 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST.testDeployMirrorMakerAcrossMultipleNamespace-FINISHED
2022-04-06 05:35:56 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:35:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:35:56 [main] [32mINFO [m [ResourceManager:348] Delete all resources for MultipleNamespaceIsolatedST
2022-04-06 05:35:56 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster in namespace second-namespace-test
2022-04-06 05:36:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 359.091 s - in io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.watcher.AllNamespaceIsolatedST
2022-04-06 05:36:06 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:36:31 [main] [32mINFO [m [AllNamespaceIsolatedST:190] Creating resources before the test class
2022-04-06 05:36:31 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 05:36:31 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 05:36:31 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 05:36:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:36:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 05:36:31 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:36:31 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:36:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 05:36:31 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 05:36:31 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 05:36:31 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace second-namespace-test
2022-04-06 05:36:31 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 05:36:31 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:36:31 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:36:31 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:36:31 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:36:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:36:31 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:36:31 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 05:36:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:36:31 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:36:31 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 05:36:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 05:36:31 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 05:36:31 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:36:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 05:36:31 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 05:36:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 05:36:41 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 05:36:41 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:36:41 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:36:41 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 05:36:41 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-namespace-test
2022-04-06 05:36:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:36:56 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace, second-namespace-test, third-namespace-test]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 05:36:56 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 05:36:56 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 05:36:56 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: second-namespace-test
2022-04-06 05:36:57 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: third-namespace-test
2022-04-06 05:36:57 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:36:57 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 05:36:57 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: second-namespace-test
2022-04-06 05:36:57 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: third-namespace-test
2022-04-06 05:36:57 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:36:57 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:36:57 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:36:57 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:36:57 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 05:36:57 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:36:57 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:36:57 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:36:57 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace second-namespace-test
2022-04-06 05:36:57 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-namespace-test
2022-04-06 05:36:57 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:36:57 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:36:57 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:36:57 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace third-namespace-test
2022-04-06 05:36:57 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace third-namespace-test
2022-04-06 05:36:57 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 05:36:57 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 05:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:36:57 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 05:37:28 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 05:37:28 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 05:37:38 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 05:37:38 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: third-namespace-test
2022-04-06 05:37:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster in namespace third-namespace-test
2022-04-06 05:37:38 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster will have desired state: Ready
2022-04-06 05:39:01 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster is in desired state: Ready
2022-04-06 05:39:01 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-06 05:39:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-second in namespace second-namespace-test
2022-04-06 05:39:01 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-second will have desired state: Ready
2022-04-06 05:40:15 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-second is in desired state: Ready
2022-04-06 05:40:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:40:15 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:40:15 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testKafkaInDifferentNsThanClusterOperator-STARTED
2022-04-06 05:40:15 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:40:15 [main] [32mINFO [m [AllNamespaceIsolatedST:82] Deploying Kafka cluster in different namespace than CO when CO watches all namespaces
2022-04-06 05:40:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-06 05:40:15 [main] [32mINFO [m [AbstractNamespaceST:46] Check if Kafka Cluster my-cluster-second in namespace second-namespace-test
2022-04-06 05:40:15 [main] [32mINFO [m [AbstractNamespaceST:51] Kafka condition status: True
2022-04-06 05:40:15 [main] [32mINFO [m [AbstractNamespaceST:52] Kafka condition type: Ready
2022-04-06 05:40:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:40:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:40:15 [main] [32mINFO [m [ResourceManager:346] In context testKafkaInDifferentNsThanClusterOperator is everything deleted.
2022-04-06 05:40:15 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:40:15 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testKafkaInDifferentNsThanClusterOperator-FINISHED
2022-04-06 05:40:15 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:40:15 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:40:15 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testTopicOperatorWatchingOtherNamespace-STARTED
2022-04-06 05:40:15 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:40:15 [main] [32mINFO [m [AllNamespaceIsolatedST:66] Deploying TO to watch a different namespace that it is deployed in
2022-04-06 05:40:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: third-namespace-test
2022-04-06 05:40:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace third-namespace-test exec my-cluster-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-06 05:40:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 05:40:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-629500873-22642268 in namespace second-namespace-test
2022-04-06 05:40:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-629500873-22642268 will have desired state: Ready
2022-04-06 05:40:19 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-629500873-22642268 is in desired state: Ready
2022-04-06 05:40:19 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:40:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:40:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTopicOperatorWatchingOtherNamespace
2022-04-06 05:40:19 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-629500873-22642268 in namespace second-namespace-test
2022-04-06 05:40:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:40:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testTopicOperatorWatchingOtherNamespace-FINISHED
2022-04-06 05:40:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:40:29 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:40:29 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testUOWatchingOtherNamespace-STARTED
2022-04-06 05:40:29 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:40:29 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-06 05:40:29 [main] [32mINFO [m [AllNamespaceIsolatedST:121] Creating user in other namespace than CO and Kafka cluster with UO
2022-04-06 05:40:29 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-2091517169-1695277953 in namespace second-namespace-test
2022-04-06 05:40:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-2091517169-1695277953 will have desired state: Ready
2022-04-06 05:40:30 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-2091517169-1695277953 is in desired state: Ready
2022-04-06 05:40:30 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:40:30 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:40:30 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUOWatchingOtherNamespace
2022-04-06 05:40:30 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-2091517169-1695277953 in namespace second-namespace-test
2022-04-06 05:40:40 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:40:40 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testUOWatchingOtherNamespace-FINISHED
2022-04-06 05:40:40 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:40:40 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:40:40 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testUserInDifferentNamespace-STARTED
2022-04-06 05:40:40 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:40:40 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-06 05:40:40 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-2091517169-1695277953 in namespace second-namespace-test
2022-04-06 05:40:40 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-2091517169-1695277953 will have desired state: Ready
2022-04-06 05:40:41 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-2091517169-1695277953 is in desired state: Ready
2022-04-06 05:40:41 [main] [32mINFO [m [AllNamespaceIsolatedST:137] KafkaUser condition status: True
2022-04-06 05:40:41 [main] [32mINFO [m [AllNamespaceIsolatedST:138] KafkaUser condition type: Ready
2022-04-06 05:40:41 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: third-namespace-test
2022-04-06 05:40:41 [main] [32mINFO [m [AllNamespaceIsolatedST:148] Copying secret Secret(apiVersion=v1, data={ca.crt=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, user.crt=LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUVJakNDQWdxZ0F3SUJBZ0lVTnk4RUt0Z3ZFRjBIMlhWemVBSlNadWlTUDdjd0RRWUpLb1pJaHZjTkFRRU4KQlFBd0xURVRNQkVHQTFVRUNnd0thVzh1YzNSeWFXMTZhVEVXTUJRR0ExVUVBd3dOWTJ4cFpXNTBjeTFqWVNCMgpNREFlRncweU1qQTBNRFl3TlRRd05EQmFGdzB5TXpBME1EWXdOVFF3TkRCYU1DZ3hKakFrQmdOVkJBTU1IVzE1CkxYVnpaWEl0TWpBNU1UVXhOekUyT1MweE5qazFNamMzT1RVek1JSUJJakFOQmdrcWhraUc5dzBCQVFFRkFBT0MKQVE4QU1JSUJDZ0tDQVFFQTA5UEhhRG5odm84d240eFJLUS85eldmdVZ3RTNRWnp2cjl2ek9Zbm5EY1FjVldyNwpmZ3hVMjhjRkV3bmJDZERmL2l5dXNnbHgxVElRd0xmeWJvUFgyeWp6QTFXa3ZWY1ExMmdlMm1uVmJxZ1V4T2p3CitvYm84OEZZR1hVZk9kRVJ2bGFXRUJKOEtmOHNVNnZMOHNXVG1rWWxaVkZxTU5Gb25DaXlvajlYZzZDV1U2OFYKcjZwZlYwNjFMQWFjYjVEWHk1TEJwNC9vRU1DWllINEtzSytnNldwaDFmbjZUV3lkeFNaRklCWUxBRnByYkRIcQp1MTJMSUlLMVlYRDhVVC9uL2dZV1A0RHpqOVVhSUdNQTVSZ21meHEvTDZ4VnZSNXhiRUdGSjlzMzNoSTdUNDVCCm5DUWZtZDAxdE80SFF2citjZWtnWUxwUFZMRXArSEtwdXA5ZW5RSURBUUFCb3o4d1BUQWRCZ05WSFE0RUZnUVUKaGZmelVuelBnQUZjSkdXN2Mya2JtbVhsQUJNd0RBWURWUjBUQVFIL0JBSXdBREFPQmdOVkhROEJBZjhFQkFNQwpCYUF3RFFZSktvWklodmNOQVFFTkJRQURnZ0lCQUx2R3NhcUxFdWFISzNkRHlTb1QyN3draWZHVG5kWWV0SE9XCkY3QXZCWWYvc3dMaG1YN3hpS20xenQrU2JPMlF3ZE1NTU9vNDdvZ1pqSHU4Y01nR0Z0RlFJWExVTzdJaWVFY1IKWmF3S3hWOElJcnJOdUpsb0R6aWkyempiaTQxSjFVY2k0aWFTdCtWcGZ0cmJNMkpmNzc4NVZWV0xqSGxtY3BaRgoyZXpoeVJnWFdzcGJlT1FVSVVCb1d6Mmt4SWtIQ25aa2loY0FkTnVnbHRBSlJDZy8zZlBwbmpHeDF2enZQdHdQCkdwK3A1TFFzMVhnN3JIS2F2bzhxZXpYcjg2Vy9HVDcrYUsvTVFvWFdzRTUvbGdwUzlOc1VJR3QwSFdicC8wcWwKQnF2VTQvZjY0Mmh3aVR3TSs4Sm0weWJmQzdHUlFVMGxaNFlKWUJiYXRNK2pFN2daNkpZdThvR2dzZ081TEZKZwpXdDh2VEdVTjlxYmgydVFWMUVqR3V4M0RaTGRyanlOZ1VFNHgvWkV5OWUzZU5XRjBhQnpjajduZSsrdkV6VFJ4CnlHZDFzSW1wbzM3V1MycFJML0d0RXV0a1l3Nk9DYm1ySFQ2bzdjei9lYVc4ZWtOdE9xdTdsdWMxcDAzNFVyYW4KTHJPS1lMYytNOEd2bWJESmNhZ3dtdWw0YTFNdkQyUWs0anVic1BTTWhocWZtK3pLR2dkVlduamhhVGYxckJtRAo5bnFLVU5KenR4cjVSdkNhc0p0MS8xSm42MC9wS3hMcFlxeHZlYWtYZjRqMzVsbVRueGdnWlB2bnhQaVZialVxClFrK0xOVEMrNjRmNkwvUkQwSVZGZ1lFWDRURjE3WnNWck10OVV0Zk1hc1ZaTXVkT1Q1dlArdEV0ZVh4NmJWRGIKWTRCK2lRdWQKLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=, user.key=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, user.p12=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, user.password=RlhVYk9uaUxJMDNE}, immutable=null, kind=Secret, metadata=ObjectMeta(annotations=null, clusterName=null, creationTimestamp=2022-04-06T05:40:40Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-user-2091517169-1695277953, app.kubernetes.io/managed-by=strimzi-user-operator, app.kubernetes.io/name=strimzi-user-operator, app.kubernetes.io/part-of=strimzi-my-user-2091517169-1695277953, strimzi.io/cluster=my-cluster, strimzi.io/kind=KafkaUser, test.case=testUserInDifferentNamespace}, managedFields=[], name=my-user-2091517169-1695277953, namespace=second-namespace-test, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=KafkaUser, name=my-user-2091517169-1695277953, uid=079789e4-0370-46ab-a1b5-9e11cd5518d0, additionalProperties={})], resourceVersion=369862, selfLink=/api/v1/namespaces/second-namespace-test/secrets/my-user-2091517169-1695277953, uid=13bc85ac-5bc5-47f6-a70f-41a7fa59b775, additionalProperties={}), stringData=null, type=Opaque, additionalProperties={}) from namespace second-namespace-test to namespace third-namespace-test
2022-04-06 05:40:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-kafka-clients in namespace third-namespace-test
2022-04-06 05:40:41 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-kafka-clients will be ready
2022-04-06 05:40:43 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-kafka-clients is ready
2022-04-06 05:40:43 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 05:40:43 [main] [32mINFO [m [AllNamespaceIsolatedST:168] Checking produced and consumed messages to pod:my-cluster-kafka-clients-d59d7f589-zwzzj
2022-04-06 05:40:43 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@31b2434d, messages=[], arguments=[--max-messages, 100, --topic, my-topic-57885039-819052364, --bootstrap-server, my-cluster-kafka-bootstrap.third-namespace-test.svc:9093, USER=my_user_2091517169_1695277953], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-kafka-clients-d59d7f589-zwzzj', podNamespace='third-namespace-test', bootstrapServer='my-cluster-kafka-bootstrap.third-namespace-test.svc:9093', topicName='my-topic-57885039-819052364', maxMessages=100, kafkaUsername='my-user-2091517169-1695277953', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6e421653}
2022-04-06 05:40:43 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-kafka-bootstrap.third-namespace-test.svc:9093:my-topic-57885039-819052364 from pod my-cluster-kafka-clients-d59d7f589-zwzzj
2022-04-06 05:40:43 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-kafka-clients-d59d7f589-zwzzj -n third-namespace-test -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-57885039-819052364 --bootstrap-server my-cluster-kafka-bootstrap.third-namespace-test.svc:9093 USER=my_user_2091517169_1695277953
2022-04-06 05:40:47 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 05:40:47 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-06 05:40:47 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3ff4b7af, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1489277607, --group-instance-id, instance1661042234, --topic, my-topic-57885039-819052364, --bootstrap-server, my-cluster-kafka-bootstrap.third-namespace-test.svc:9093, USER=my_user_2091517169_1695277953], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-kafka-clients-d59d7f589-zwzzj', podNamespace='third-namespace-test', bootstrapServer='my-cluster-kafka-bootstrap.third-namespace-test.svc:9093', topicName='my-topic-57885039-819052364', maxMessages=100, kafkaUsername='my-user-2091517169-1695277953', consumerGroupName='my-consumer-group-1489277607', consumerInstanceId='instance1661042234', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@65a1c6e0}
2022-04-06 05:40:47 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-kafka-bootstrap.third-namespace-test.svc:9093:my-topic-57885039-819052364 from pod my-cluster-kafka-clients-d59d7f589-zwzzj
2022-04-06 05:40:47 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-kafka-clients-d59d7f589-zwzzj -n third-namespace-test -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1489277607 --group-instance-id instance1661042234 --topic my-topic-57885039-819052364 --bootstrap-server my-cluster-kafka-bootstrap.third-namespace-test.svc:9093 USER=my_user_2091517169_1695277953
2022-04-06 05:40:53 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 05:40:53 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 05:40:53 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:40:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:40:53 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUserInDifferentNamespace
2022-04-06 05:40:53 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-kafka-clients in namespace third-namespace-test
2022-04-06 05:40:53 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-2091517169-1695277953 in namespace second-namespace-test
2022-04-06 05:41:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:41:44 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testUserInDifferentNamespace-FINISHED
2022-04-06 05:41:44 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:41:44 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:41:44 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testDeployMirrorMakerAcrossMultipleNamespace-STARTED
2022-04-06 05:41:44 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:41:44 [main] [32mINFO [m [AllNamespaceIsolatedST:92] Deploying KafkaMirrorMaker in different namespace than CO when CO watches all namespaces
2022-04-06 05:41:44 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-06 05:41:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-target in namespace second-namespace-test
2022-04-06 05:41:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-target will have desired state: Ready
2022-04-06 05:42:47 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-target is in desired state: Ready
2022-04-06 05:42:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster in namespace second-namespace-test
2022-04-06 05:42:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster will have desired state: Ready
2022-04-06 05:43:56 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster is in desired state: Ready
2022-04-06 05:43:56 [main] [32mINFO [m [AbstractNamespaceST:71] Waiting for creation my-cluster-mirror-maker in namespace second-namespace-test
2022-04-06 05:43:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster will have desired state: Ready
2022-04-06 05:43:56 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster is in desired state: Ready
2022-04-06 05:43:56 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:43:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:43:56 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeployMirrorMakerAcrossMultipleNamespace
2022-04-06 05:43:56 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster in namespace second-namespace-test
2022-04-06 05:43:56 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-target in namespace second-namespace-test
2022-04-06 05:44:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:44:06 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testDeployMirrorMakerAcrossMultipleNamespace-FINISHED
2022-04-06 05:44:06 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:44:06 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:44:06 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testDeployKafkaConnectAndKafkaConnectorInOtherNamespaceThanCO-STARTED
2022-04-06 05:44:06 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:44:06 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-06 05:44:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-fe4d3e53-kafka-clients in namespace second-namespace-test
2022-04-06 05:44:06 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-fe4d3e53-kafka-clients will be ready
2022-04-06 05:44:07 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-fe4d3e53-kafka-clients is ready
2022-04-06 05:44:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-fe4d3e53kafka-connect-scraper in namespace second-namespace-test
2022-04-06 05:44:07 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-fe4d3e53kafka-connect-scraper will be ready
2022-04-06 05:44:08 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-fe4d3e53kafka-connect-scraper is ready
2022-04-06 05:44:08 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-fe4d3e53kafka-connect-scraper to be ready
2022-04-06 05:44:18 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-fe4d3e53kafka-connect-scraper is ready
2022-04-06 05:44:18 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-fe4d3e53kafka-connect-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 05:44:18 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-fe4d3e53kafka-connect-allow in namespace second-namespace-test
2022-04-06 05:44:18 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 05:44:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-fe4d3e53kafka-connect in namespace second-namespace-test
2022-04-06 05:44:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-fe4d3e53kafka-connect will have desired state: Ready
2022-04-06 05:45:23 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-fe4d3e53kafka-connect is in desired state: Ready
2022-04-06 05:45:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-fe4d3e53kafka-connect in namespace second-namespace-test
2022-04-06 05:45:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-fe4d3e53kafka-connect will have desired state: Ready
2022-04-06 05:45:24 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-fe4d3e53kafka-connect is in desired state: Ready
2022-04-06 05:45:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-fe4d3e53kafka-connect will have desired state: Ready
2022-04-06 05:45:24 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-fe4d3e53kafka-connect is in desired state: Ready
2022-04-06 05:45:24 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-06 05:45:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace second-namespace-test exec my-cluster-fe4d3e53kafka-connect-connect-855589bcc9-xsd4d -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-06 05:45:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 05:45:25 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-06 05:45:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-fe4d3e53kafka-connect-kafka-clients in namespace second-namespace-test
2022-04-06 05:45:25 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-fe4d3e53kafka-connect-kafka-clients will be ready
2022-04-06 05:45:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-fe4d3e53kafka-connect-kafka-clients is ready
2022-04-06 05:45:27 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 05:45:27 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@77a7c082, messages=[], arguments=[--max-messages, 100, --topic, my-topic-57885039-819052364, --bootstrap-server, my-cluster-second-kafka-bootstrap.second-namespace-test.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-fe4d3e53-kafka-clients-7b7d88d5fd-xbjlq', podNamespace='second-namespace-test', bootstrapServer='my-cluster-second-kafka-bootstrap.second-namespace-test.svc:9092', topicName='my-topic-57885039-819052364', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6eca06f8}
2022-04-06 05:45:27 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-second-kafka-bootstrap.second-namespace-test.svc:9092:my-topic-57885039-819052364 from pod my-cluster-fe4d3e53-kafka-clients-7b7d88d5fd-xbjlq
2022-04-06 05:45:27 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fe4d3e53-kafka-clients-7b7d88d5fd-xbjlq -n second-namespace-test -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-57885039-819052364 --bootstrap-server my-cluster-second-kafka-bootstrap.second-namespace-test.svc:9092
2022-04-06 05:45:29 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 05:45:29 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-06 05:45:29 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-fe4d3e53kafka-connect-connect-855589bcc9-xsd4d
2022-04-06 05:45:30 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-fe4d3e53kafka-connect-connect-855589bcc9-xsd4d
2022-04-06 05:45:30 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:45:30 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:45:30 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeployKafkaConnectAndKafkaConnectorInOtherNamespaceThanCO
2022-04-06 05:45:30 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-fe4d3e53kafka-connect in namespace second-namespace-test
2022-04-06 05:45:30 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-fe4d3e53kafka-connect in namespace second-namespace-test
2022-04-06 05:45:30 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-fe4d3e53kafka-connect-kafka-clients in namespace second-namespace-test
2022-04-06 05:45:30 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-fe4d3e53-kafka-clients in namespace second-namespace-test
2022-04-06 05:45:30 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-fe4d3e53kafka-connect-scraper in namespace second-namespace-test
2022-04-06 05:45:30 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-fe4d3e53kafka-connect-allow in namespace second-namespace-test
2022-04-06 05:46:20 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:46:20 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testDeployKafkaConnectAndKafkaConnectorInOtherNamespaceThanCO-FINISHED
2022-04-06 05:46:20 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:46:20 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:46:20 [main] [32mINFO [m [ResourceManager:348] Delete all resources for AllNamespaceIsolatedST
2022-04-06 05:46:20 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-second in namespace second-namespace-test
2022-04-06 05:46:20 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster in namespace third-namespace-test
2022-04-06 05:46:40 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 634.579 s - in io.strimzi.systemtest.watcher.AllNamespaceIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST
2022-04-06 05:46:40 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:47:05 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 05:47:05 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 05:47:05 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 05:47:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:47:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 05:47:05 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:47:05 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace third-namespace-test
2022-04-06 05:47:05 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 05:47:05 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 05:47:05 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 05:47:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:47:05 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:47:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:47:05 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:47:05 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace third-namespace-test
2022-04-06 05:47:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:47:05 [main] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 05:47:05 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 05:47:05 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 05:47:05 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:47:05 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 05:47:06 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:47:06 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:47:06 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 05:47:06 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:47:06 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-namespace-test
2022-04-06 05:47:06 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:47:06 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:47:06 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:47:06 [main] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace second-namespace-test
2022-04-06 05:47:06 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 05:47:06 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:47:06 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:47:06 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 05:47:06 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:47:15 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 05:47:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 05:47:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 05:47:16 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:47:16 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 05:47:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:47:36 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 05:47:36 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 05:47:36 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 05:47:36 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:47:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:47:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:47:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 05:47:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 05:47:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 05:47:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 05:47:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 05:47:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 05:47:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 05:47:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 05:47:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:47:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:47:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 05:47:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 05:47:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 05:47:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 05:47:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:47:37 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 05:47:37 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:47:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:47:37 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 05:47:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:47:37 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 05:47:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:47:37 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:47:37 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:47:37 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 05:47:37 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 05:47:37 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 05:47:37 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 05:47:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:47:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 05:47:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:47:37 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 05:47:55 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 05:47:55 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 05:48:05 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 05:48:05 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-06 05:48:05 [main] [32mINFO [m [OauthAbstractST:125] Deploying keycloak...
2022-04-06 05:48:05 [main] [32mINFO [m [KeycloakUtils:35] Prepare Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-06 05:49:43 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/prepare_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-06 05:49:43 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 05:49:43 [main] [32mINFO [m [KeycloakUtils:48] Keycloak in namespace infra-namespace is ready
2022-04-06 05:49:43 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret credential-example-keycloak
2022-04-06 05:49:43 [main] [32mINFO [m [SecretUtils:50] Secret credential-example-keycloak created
2022-04-06 05:49:43 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-producer-secret
2022-04-06 05:49:43 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-consumer-secret
2022-04-06 05:49:43 [main] [32mINFO [m [SecretUtils:70] Creating secret team-a-client-secret
2022-04-06 05:49:43 [main] [32mINFO [m [SecretUtils:70] Creating secret team-b-client-secret
2022-04-06 05:49:43 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-broker-secret
2022-04-06 05:49:43 [main] [32mINFO [m [SecretUtils:70] Creating secret my-connect-oauth
2022-04-06 05:49:43 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-oauth
2022-04-06 05:49:43 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-2-oauth
2022-04-06 05:49:43 [main] [32mINFO [m [SecretUtils:70] Creating secret my-bridge-oauth
2022-04-06 05:49:43 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-audience-secret
2022-04-06 05:49:43 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-client-secret
2022-04-06 05:49:43 [main] [32mINFO [m [KeycloakInstance:50] Replacing validIssuerUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal to pointing to internal realm
2022-04-06 05:49:43 [main] [32mINFO [m [KeycloakInstance:51] Replacing jwksEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/certs to pointing to internal realm
2022-04-06 05:49:43 [main] [32mINFO [m [KeycloakInstance:52] Replacing oauthTokenEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token to pointing to internal realm
2022-04-06 05:49:43 [main] [32mINFO [m [KeycloakInstance:60] Using HTTP endpoints
2022-04-06 05:49:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-plain-name in namespace infra-namespace
2022-04-06 05:49:43 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-plain-name will have desired state: Ready
2022-04-06 05:51:01 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-plain-name is in desired state: Ready
2022-04-06 05:51:01 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:51:01 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testSaslPlainProducerConsumer-STARTED
2022-04-06 05:51:01 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:51:01 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 05:51:01 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 05:51:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Job kafka-audience-producer-my-cluster-0192ad04 in namespace infra-namespace
2022-04-06 05:51:01 [main] [32mINFO [m [JobUtils:81] Waiting for job: kafka-audience-producer-my-cluster-0192ad04 will be in active state
2022-04-06 05:51:02 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:kafka-audience-producer-my-cluster-0192ad04 to finished
2022-04-06 05:51:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Job kafka-audience-consumer-my-cluster-0192ad04 in namespace infra-namespace
2022-04-06 05:51:10 [main] [32mINFO [m [JobUtils:81] Waiting for job: kafka-audience-consumer-my-cluster-0192ad04 will be in active state
2022-04-06 05:51:11 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:kafka-audience-consumer-my-cluster-0192ad04 to finished
2022-04-06 05:51:22 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:51:22 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSaslPlainProducerConsumer
2022-04-06 05:51:22 [main] [32mINFO [m [ResourceManager:241] Delete of Job kafka-audience-consumer-my-cluster-0192ad04 in namespace infra-namespace
2022-04-06 05:51:22 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job kafka-audience-producer-my-cluster-0192ad04 in namespace infra-namespace
2022-04-06 05:51:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:51:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testSaslPlainProducerConsumer-FINISHED
2022-04-06 05:51:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:51:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:51:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testSaslPlainAuthenticationKafkaConnectIsAbleToConnectToKafkaOAuth-STARTED
2022-04-06 05:51:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:51:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-d695f6a9-kafka-clients in namespace infra-namespace
2022-04-06 05:51:22 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d695f6a9-kafka-clients will be ready
2022-04-06 05:51:24 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d695f6a9-kafka-clients is ready
2022-04-06 05:51:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-d695f6a9-scraper in namespace infra-namespace
2022-04-06 05:51:24 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d695f6a9-scraper will be ready
2022-04-06 05:51:26 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d695f6a9-scraper is ready
2022-04-06 05:51:26 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-d695f6a9-scraper to be ready
2022-04-06 05:51:36 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-d695f6a9-scraper is ready
2022-04-06 05:51:36 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-d695f6a9-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 05:51:36 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-d695f6a9-allow in namespace infra-namespace
2022-04-06 05:51:36 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 05:51:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-d695f6a9 in namespace infra-namespace
2022-04-06 05:51:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-d695f6a9 will have desired state: Ready
2022-04-06 05:52:40 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-d695f6a9 is in desired state: Ready
2022-04-06 05:52:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:52:40 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSaslPlainAuthenticationKafkaConnectIsAbleToConnectToKafkaOAuth
2022-04-06 05:52:40 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-d695f6a9-allow in namespace infra-namespace
2022-04-06 05:52:40 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-d695f6a9-scraper in namespace infra-namespace
2022-04-06 05:52:40 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-d695f6a9-kafka-clients in namespace infra-namespace
2022-04-06 05:52:40 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-d695f6a9 in namespace infra-namespace
2022-04-06 05:53:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:53:30 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testSaslPlainAuthenticationKafkaConnectIsAbleToConnectToKafkaOAuth-FINISHED
2022-04-06 05:53:30 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:53:30 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:53:30 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerMirrorMaker-STARTED
2022-04-06 05:53:30 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:53:30 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 05:53:30 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1332105518-330937281 in namespace infra-namespace
2022-04-06 05:53:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1332105518-330937281 will have desired state: Ready
2022-04-06 05:53:31 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1332105518-330937281 is in desired state: Ready
2022-04-06 05:53:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-50f23cc8 in namespace infra-namespace
2022-04-06 05:53:31 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-50f23cc8 will be in active state
2022-04-06 05:53:32 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-50f23cc8 to finished
2022-04-06 05:53:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-50f23cc8 in namespace infra-namespace
2022-04-06 05:53:40 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-50f23cc8 will be in active state
2022-04-06 05:53:41 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-50f23cc8 to finished
2022-04-06 05:53:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-50f23cc8-target in namespace infra-namespace
2022-04-06 05:53:52 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-50f23cc8-target will have desired state: Ready
2022-04-06 05:55:09 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-50f23cc8-target is in desired state: Ready
2022-04-06 05:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker oauth-cluster-plain-name in namespace infra-namespace
2022-04-06 05:55:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: oauth-cluster-plain-name will have desired state: Ready
2022-04-06 05:56:13 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: oauth-cluster-plain-name is in desired state: Ready
2022-04-06 05:56:14 [main] [32mINFO [m [OauthPlainIsolatedST:440] Deleting the Job
2022-04-06 05:56:14 [main] [32mINFO [m [OauthPlainIsolatedST:443] Creating new client with new consumer-group and also to point on my-cluster-50f23cc8-target cluster
2022-04-06 05:56:14 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 05:56:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer in namespace infra-namespace
2022-04-06 05:56:14 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer will be in active state
2022-04-06 05:56:15 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer to finished
2022-04-06 05:56:26 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:56:26 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerMirrorMaker
2022-04-06 05:56:26 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-50f23cc8-target in namespace infra-namespace
2022-04-06 05:56:26 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker oauth-cluster-plain-name in namespace infra-namespace
2022-04-06 05:56:26 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer in namespace infra-namespace
2022-04-06 05:56:26 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-50f23cc8 in namespace infra-namespace
2022-04-06 05:56:26 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-50f23cc8 in namespace infra-namespace
2022-04-06 05:56:26 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1332105518-330937281 in namespace infra-namespace
2022-04-06 05:56:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:56:36 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerMirrorMaker-FINISHED
2022-04-06 05:56:36 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:56:36 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:56:36 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerBridge-STARTED
2022-04-06 05:56:36 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:56:36 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 05:56:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1889954647-62093230 in namespace infra-namespace
2022-04-06 05:56:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1889954647-62093230 will have desired state: Ready
2022-04-06 05:56:37 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1889954647-62093230 is in desired state: Ready
2022-04-06 05:56:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-95d6ceaa in namespace infra-namespace
2022-04-06 05:56:37 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-95d6ceaa will be in active state
2022-04-06 05:56:38 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-95d6ceaa to finished
2022-04-06 05:56:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-95d6ceaa in namespace infra-namespace
2022-04-06 05:56:41 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-95d6ceaa will be in active state
2022-04-06 05:56:42 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-95d6ceaa to finished
2022-04-06 05:56:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-95d6ceaa-kafka-clients in namespace infra-namespace
2022-04-06 05:56:53 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-95d6ceaa-kafka-clients will be ready
2022-04-06 05:56:54 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-95d6ceaa-kafka-clients is ready
2022-04-06 05:56:54 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge oauth-cluster-plain-name in namespace infra-namespace
2022-04-06 05:56:54 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: oauth-cluster-plain-name will have desired state: Ready
2022-04-06 05:57:20 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: oauth-cluster-plain-name is in desired state: Ready
2022-04-06 05:57:20 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 05:57:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Job bridge-producer-my-cluster-95d6ceaa in namespace infra-namespace
2022-04-06 05:57:20 [main] [32mINFO [m [JobUtils:81] Waiting for job: bridge-producer-my-cluster-95d6ceaa will be in active state
2022-04-06 05:57:21 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:bridge-producer-my-cluster-95d6ceaa to finished
2022-04-06 05:59:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:59:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerBridge
2022-04-06 05:59:11 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-95d6ceaa-kafka-clients in namespace infra-namespace
2022-04-06 05:59:11 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job bridge-producer-my-cluster-95d6ceaa in namespace infra-namespace
2022-04-06 05:59:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge oauth-cluster-plain-name in namespace infra-namespace
2022-04-06 05:59:11 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-95d6ceaa in namespace infra-namespace
2022-04-06 05:59:11 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1889954647-62093230 in namespace infra-namespace
2022-04-06 05:59:11 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-95d6ceaa in namespace infra-namespace
2022-04-06 05:59:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:59:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerBridge-FINISHED
2022-04-06 05:59:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:59:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:59:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumer-STARTED
2022-04-06 05:59:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:59:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1066050564-1109777557 in namespace infra-namespace
2022-04-06 05:59:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1066050564-1109777557 will have desired state: Ready
2022-04-06 05:59:52 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1066050564-1109777557 is in desired state: Ready
2022-04-06 05:59:52 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 05:59:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-275f277d in namespace infra-namespace
2022-04-06 05:59:52 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-275f277d will be in active state
2022-04-06 05:59:53 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-275f277d to finished
2022-04-06 06:00:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-275f277d in namespace infra-namespace
2022-04-06 06:00:01 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-275f277d will be in active state
2022-04-06 06:00:02 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-275f277d to finished
2022-04-06 06:00:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:00:13 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumer
2022-04-06 06:00:13 [main] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-275f277d in namespace infra-namespace
2022-04-06 06:00:13 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1066050564-1109777557 in namespace infra-namespace
2022-04-06 06:00:13 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-275f277d in namespace infra-namespace
2022-04-06 06:00:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:00:13 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumer-FINISHED
2022-04-06 06:00:13 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:00:13 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:00:13 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerMirrorMaker2-STARTED
2022-04-06 06:00:13 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:00:13 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 06:00:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-118508077-410671533 in namespace infra-namespace
2022-04-06 06:00:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-118508077-410671533 will have desired state: Ready
2022-04-06 06:00:14 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-118508077-410671533 is in desired state: Ready
2022-04-06 06:00:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-befe7212 in namespace infra-namespace
2022-04-06 06:00:14 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-befe7212 will be in active state
2022-04-06 06:00:15 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-befe7212 to finished
2022-04-06 06:00:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-befe7212 in namespace infra-namespace
2022-04-06 06:00:23 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-befe7212 will be in active state
2022-04-06 06:00:24 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-befe7212 to finished
2022-04-06 06:00:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-befe7212-target in namespace infra-namespace
2022-04-06 06:00:30 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-befe7212-target will have desired state: Ready
2022-04-06 06:01:48 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-befe7212-target is in desired state: Ready
2022-04-06 06:01:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 oauth-cluster-plain-name in namespace infra-namespace
2022-04-06 06:01:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: oauth-cluster-plain-name will have desired state: Ready
2022-04-06 06:03:01 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: oauth-cluster-plain-name is in desired state: Ready
2022-04-06 06:03:02 [main] [32mINFO [m [OauthPlainIsolatedST:590] Deleting the Job oauth-consumer-my-cluster-befe7212
2022-04-06 06:03:02 [main] [32mINFO [m [OauthPlainIsolatedST:593] Creating new client with new consumer-group and also to point on my-cluster-befe7212-target cluster
2022-04-06 06:03:02 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 06:03:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-befe7212 in namespace infra-namespace
2022-04-06 06:03:02 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-befe7212 will be in active state
2022-04-06 06:03:03 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-befe7212 to finished
2022-04-06 06:03:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:03:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerMirrorMaker2
2022-04-06 06:03:14 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-befe7212-target in namespace infra-namespace
2022-04-06 06:03:14 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-befe7212 in namespace infra-namespace
2022-04-06 06:03:14 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-118508077-410671533 in namespace infra-namespace
2022-04-06 06:03:14 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 oauth-cluster-plain-name in namespace infra-namespace
2022-04-06 06:03:14 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-befe7212 in namespace infra-namespace
2022-04-06 06:03:14 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-befe7212 in namespace infra-namespace
2022-04-06 06:03:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:03:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerMirrorMaker2-FINISHED
2022-04-06 06:03:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:03:34 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:03:34 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerAudienceTokenChecks-STARTED
2022-04-06 06:03:34 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:03:34 [main] [32mINFO [m [OauthPlainIsolatedST:161] Setting producer and consumer properties
2022-04-06 06:03:34 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 06:03:34 [main] [32mINFO [m [OauthPlainIsolatedST:174] Use clients without access token containing audience token
2022-04-06 06:03:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-e8004271 in namespace infra-namespace
2022-04-06 06:03:34 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-e8004271 will be in active state
2022-04-06 06:03:35 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:oauth-producer-my-cluster-e8004271 to finish with failure.
2022-04-06 06:07:15 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
io.strimzi.test.WaitException: Timeout after 220000 ms waiting for Job did not finish within time limit (as expected).
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientTimeout(ClientUtils.java:91)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.lambda$testProducerConsumerAudienceTokenChecks$0(OauthPlainIsolatedST.java:176)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:50)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:37)
	at org.junit.jupiter.api.Assertions.assertDoesNotThrow(Assertions.java:3135)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerAudienceTokenChecks(OauthPlainIsolatedST.java:176)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-06 06:07:15 [main] [32mINFO [m [ClientUtils:100] Client job 'oauth-producer-my-cluster-e8004271' finished with expected timeout.
2022-04-06 06:07:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-e8004271 in namespace infra-namespace
2022-04-06 06:07:15 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-e8004271 will be in active state
2022-04-06 06:07:16 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:oauth-consumer-my-cluster-e8004271 to finish with failure.
2022-04-06 06:10:56 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
io.strimzi.test.WaitException: Timeout after 220000 ms waiting for Job did not finish within time limit (as expected).
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientTimeout(ClientUtils.java:91)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.lambda$testProducerConsumerAudienceTokenChecks$1(OauthPlainIsolatedST.java:178)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:50)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:37)
	at org.junit.jupiter.api.Assertions.assertDoesNotThrow(Assertions.java:3135)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerAudienceTokenChecks(OauthPlainIsolatedST.java:178)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-06 06:10:56 [main] [32mINFO [m [ClientUtils:100] Client job 'oauth-consumer-my-cluster-e8004271' finished with expected timeout.
2022-04-06 06:11:06 [main] [32mINFO [m [OauthPlainIsolatedST:183] Use clients with Access token containing audience token
2022-04-06 06:11:06 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 06:11:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Job kafka-audience-producer-my-cluster-e8004271 in namespace infra-namespace
2022-04-06 06:11:06 [main] [32mINFO [m [JobUtils:81] Waiting for job: kafka-audience-producer-my-cluster-e8004271 will be in active state
2022-04-06 06:11:07 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:kafka-audience-producer-my-cluster-e8004271 to finished
2022-04-06 06:11:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Job kafka-audience-consumer-my-cluster-e8004271 in namespace infra-namespace
2022-04-06 06:11:15 [main] [32mINFO [m [JobUtils:81] Waiting for job: kafka-audience-consumer-my-cluster-e8004271 will be in active state
2022-04-06 06:11:16 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:kafka-audience-consumer-my-cluster-e8004271 to finished
2022-04-06 06:11:27 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:11:27 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerAudienceTokenChecks
2022-04-06 06:11:27 [main] [32mINFO [m [ResourceManager:241] Delete of Job kafka-audience-producer-my-cluster-e8004271 in namespace infra-namespace
2022-04-06 06:11:27 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job kafka-audience-consumer-my-cluster-e8004271 in namespace infra-namespace
2022-04-06 06:11:27 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-e8004271 in namespace infra-namespace
2022-04-06 06:11:27 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-e8004271 in namespace infra-namespace
2022-04-06 06:11:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:11:27 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerAudienceTokenChecks-FINISHED
2022-04-06 06:11:27 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:11:27 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:11:27 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect-STARTED
2022-04-06 06:11:27 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:11:27 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 06:11:27 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-516243898-89140188 in namespace infra-namespace
2022-04-06 06:11:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-516243898-89140188 will have desired state: Ready
2022-04-06 06:11:28 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-516243898-89140188 is in desired state: Ready
2022-04-06 06:11:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-a0ac283f in namespace infra-namespace
2022-04-06 06:11:28 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-a0ac283f will be in active state
2022-04-06 06:11:29 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-a0ac283f to finished
2022-04-06 06:11:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-a0ac283f in namespace infra-namespace
2022-04-06 06:11:37 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-a0ac283f will be in active state
2022-04-06 06:11:38 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-a0ac283f to finished
2022-04-06 06:11:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a0ac283f-kafka-clients in namespace infra-namespace
2022-04-06 06:11:49 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a0ac283f-kafka-clients will be ready
2022-04-06 06:11:51 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a0ac283f-kafka-clients is ready
2022-04-06 06:11:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a0ac283f-scraper in namespace infra-namespace
2022-04-06 06:11:51 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a0ac283f-scraper will be ready
2022-04-06 06:11:53 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a0ac283f-scraper is ready
2022-04-06 06:11:53 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-a0ac283f-scraper to be ready
2022-04-06 06:12:03 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-a0ac283f-scraper is ready
2022-04-06 06:12:03 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-a0ac283f-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 06:12:03 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-a0ac283f-allow in namespace infra-namespace
2022-04-06 06:12:03 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 06:12:03 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-a0ac283f in namespace infra-namespace
2022-04-06 06:12:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-a0ac283f will have desired state: Ready
2022-04-06 06:22:03 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for KafkaConnect: my-cluster-a0ac283f will have desired state: Ready, null
2022-04-06 06:22:03 [main] [32mINFO [m [ResourceManager:414] KafkaConnect status:

Conditions:
	Type: NotReady
	Message: Exceeded timeout of 300000ms while waiting for Deployment resource my-cluster-a0ac283f-connect in namespace infra-namespace to be ready

Pods with conditions and messages:

my-cluster-a0ac283f-connect-659f74889b-6l6pg:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: Ready
	Message: containers with unready status: [my-cluster-a0ac283f-connect]

	Type: ContainersReady
	Message: containers with unready status: [my-cluster-a0ac283f-connect]

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-a0ac283f-kafka-clients-5f6f54679b-bpcd5:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-a0ac283f-scraper-6f56b47495-9bxpj:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>
io.strimzi.test.WaitException: Timeout after 600000 ms waiting for KafkaConnect: my-cluster-a0ac283f will have desired state: Ready
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.systemtest.resources.ResourceManager.waitForResourceStatus(ResourceManager.java:435)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils.waitForConnectStatus(KafkaConnectUtils.java:42)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils.waitForConnectReady(KafkaConnectUtils.java:47)
	at io.strimzi.systemtest.resources.crd.KafkaConnectResource.waitForReadiness(KafkaConnectResource.java:42)
	at io.strimzi.systemtest.resources.crd.KafkaConnectResource.waitForReadiness(KafkaConnectResource.java:19)
	at io.strimzi.systemtest.resources.ResourceManager.lambda$waitResourceCondition$2(ResourceManager.java:268)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:142)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.resources.ResourceManager.waitResourceCondition(ResourceManager.java:264)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:226)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:148)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect(OauthPlainIsolatedST.java:287)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
io.strimzi.test.WaitException: Timeout after 600000 ms waiting for Resource condition: readiness is fulfilled for resource KafkaConnect:my-cluster-a0ac283f
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.resources.ResourceManager.waitResourceCondition(ResourceManager.java:264)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:226)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:148)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect(OauthPlainIsolatedST.java:287)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-06 06:22:03 [main] [1;31mERROR[m [TestExecutionWatcher:28] OauthPlainIsolatedST - Exception Timeout after 600000 ms waiting for Resource condition: readiness is fulfilled for resource KafkaConnect:my-cluster-a0ac283f has been thrown in @Test. Going to collect logs from components.
2022-04-06 06:22:03 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-04-06 06:22:03 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-04-06 06:22:03 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-04-06 06:22:03 [main] [33mWARN [m [LogCollector:247] Searching for logs in all pods failed! Some of the logs will not be stored. Exception messagenull
2022-04-06 06:22:03 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-04-06 06:22:03 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-04-06 06:22:04 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-04-06 06:22:04 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-04-06 06:22:04 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-06 06:22:04 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:22:04 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerConnect
2022-04-06 06:22:04 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-516243898-89140188 in namespace infra-namespace
2022-04-06 06:22:04 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a0ac283f-scraper in namespace infra-namespace
2022-04-06 06:22:04 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-a0ac283f in namespace infra-namespace
2022-04-06 06:22:04 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a0ac283f-kafka-clients in namespace infra-namespace
2022-04-06 06:22:04 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-a0ac283f in namespace infra-namespace
2022-04-06 06:22:04 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-a0ac283f in namespace infra-namespace
2022-04-06 06:22:04 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-a0ac283f-allow in namespace infra-namespace
2022-04-06 06:22:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:22:44 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect-FINISHED
2022-04-06 06:22:44 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:22:44 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:22:44 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testAccessTokenClaimCheck-STARTED
2022-04-06 06:22:44 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:22:44 [main] [32mINFO [m [OauthPlainIsolatedST:213] Use clients with clientId not containing 'hello-world' in access token.
2022-04-06 06:22:44 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 06:22:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Job kafka-audience-producer-my-cluster-a0032dc5 in namespace infra-namespace
2022-04-06 06:22:44 [main] [32mINFO [m [JobUtils:81] Waiting for job: kafka-audience-producer-my-cluster-a0032dc5 will be in active state
2022-04-06 06:22:45 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:kafka-audience-producer-my-cluster-a0032dc5 to finish with failure.
2022-04-06 06:26:25 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
io.strimzi.test.WaitException: Timeout after 220000 ms waiting for Job did not finish within time limit (as expected).
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientTimeout(ClientUtils.java:91)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.lambda$testAccessTokenClaimCheck$2(OauthPlainIsolatedST.java:229)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:50)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:37)
	at org.junit.jupiter.api.Assertions.assertDoesNotThrow(Assertions.java:3135)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testAccessTokenClaimCheck(OauthPlainIsolatedST.java:229)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-06 06:26:25 [main] [32mINFO [m [ClientUtils:100] Client job 'kafka-audience-producer-my-cluster-a0032dc5' finished with expected timeout.
2022-04-06 06:26:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Job kafka-audience-consumer-my-cluster-a0032dc5 in namespace infra-namespace
2022-04-06 06:26:25 [main] [32mINFO [m [JobUtils:81] Waiting for job: kafka-audience-consumer-my-cluster-a0032dc5 will be in active state
2022-04-06 06:26:26 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:kafka-audience-consumer-my-cluster-a0032dc5 to finish with failure.
2022-04-06 06:30:06 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
io.strimzi.test.WaitException: Timeout after 220000 ms waiting for Job did not finish within time limit (as expected).
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientTimeout(ClientUtils.java:91)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.lambda$testAccessTokenClaimCheck$3(OauthPlainIsolatedST.java:231)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:50)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:37)
	at org.junit.jupiter.api.Assertions.assertDoesNotThrow(Assertions.java:3135)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testAccessTokenClaimCheck(OauthPlainIsolatedST.java:231)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-06 06:30:06 [main] [32mINFO [m [ClientUtils:100] Client job 'kafka-audience-consumer-my-cluster-a0032dc5' finished with expected timeout.
2022-04-06 06:30:16 [main] [32mINFO [m [OauthPlainIsolatedST:236] Use clients with clientId containing 'hello-world' in access token.
2022-04-06 06:30:16 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 06:30:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-a0032dc5 in namespace infra-namespace
2022-04-06 06:30:16 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-a0032dc5 will be in active state
2022-04-06 06:30:17 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-a0032dc5 to finished
2022-04-06 06:30:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-a0032dc5 in namespace infra-namespace
2022-04-06 06:30:25 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-a0032dc5 will be in active state
2022-04-06 06:30:26 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-a0032dc5 to finished
2022-04-06 06:30:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:30:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAccessTokenClaimCheck
2022-04-06 06:30:37 [main] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-a0032dc5 in namespace infra-namespace
2022-04-06 06:30:37 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-a0032dc5 in namespace infra-namespace
2022-04-06 06:30:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job kafka-audience-producer-my-cluster-a0032dc5 in namespace infra-namespace
2022-04-06 06:30:37 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job kafka-audience-consumer-my-cluster-a0032dc5 in namespace infra-namespace
2022-04-06 06:30:37 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:30:37 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testAccessTokenClaimCheck-FINISHED
2022-04-06 06:30:37 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:30:37 [main] [32mINFO [m [KeycloakUtils:52] Teardown Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-06 06:30:41 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/teardown_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-06 06:30:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 06:30:41 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:30:41 [main] [32mINFO [m [ResourceManager:348] Delete all resources for OauthPlainIsolatedST
2022-04-06 06:30:41 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-plain-name in namespace infra-namespace
2022-04-06 06:30:41 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-06 06:30:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:30:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:30:51 [main] [32mINFO [m [ResourceManager:346] In context OauthPlainIsolatedST is everything deleted.
2022-04-06 06:30:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;31mERROR[m] Tests run: 9, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 2,650.208 s <<< FAILURE! - in io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST
[[1;31mERROR[m] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect(ExtensionContext)  Time elapsed: 677.331 s  <<< ERROR!
io.strimzi.test.WaitException: Timeout after 600000 ms waiting for Resource condition: readiness is fulfilled for resource KafkaConnect:my-cluster-a0ac283f
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.resources.ResourceManager.waitResourceCondition(ResourceManager.java:264)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:226)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:148)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect(OauthPlainIsolatedST.java:287)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)

[[1;34mINFO[m] Running io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST
2022-04-06 06:30:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 06:31:16 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 06:31:16 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 06:31:16 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 06:31:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:31:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 06:31:16 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 06:31:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 06:31:16 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 06:31:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 06:31:16 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 06:31:16 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 06:31:16 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 06:31:16 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 06:31:16 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 06:31:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:31:16 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 06:31:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:31:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 06:31:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 06:31:16 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 06:31:16 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:31:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 06:31:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 06:31:16 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 06:31:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:31:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 06:31:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 06:31:26 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 06:31:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 06:31:26 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 06:31:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:31:42 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 06:31:42 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 06:31:42 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 06:31:42 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 06:31:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:31:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 06:31:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 06:31:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 06:31:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 06:31:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 06:31:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 06:31:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 06:31:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 06:31:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 06:31:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 06:31:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 06:31:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 06:31:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 06:31:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 06:31:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 06:31:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:31:42 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 06:31:42 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 06:31:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 06:31:42 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 06:31:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 06:31:42 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 06:31:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 06:31:42 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 06:31:42 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:31:42 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 06:31:42 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 06:31:42 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 06:31:42 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 06:31:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 06:31:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 06:31:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:31:42 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 06:32:09 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 06:32:09 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 06:32:19 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 06:32:19 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-06 06:32:19 [main] [32mINFO [m [OauthAbstractST:125] Deploying keycloak...
2022-04-06 06:32:19 [main] [32mINFO [m [KeycloakUtils:35] Prepare Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-06 06:33:56 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/prepare_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-06 06:33:56 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 06:33:56 [main] [32mINFO [m [KeycloakUtils:48] Keycloak in namespace infra-namespace is ready
2022-04-06 06:33:56 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret credential-example-keycloak
2022-04-06 06:33:56 [main] [32mINFO [m [SecretUtils:50] Secret credential-example-keycloak created
2022-04-06 06:33:56 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-producer-secret
2022-04-06 06:33:56 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-consumer-secret
2022-04-06 06:33:56 [main] [32mINFO [m [SecretUtils:70] Creating secret team-a-client-secret
2022-04-06 06:33:56 [main] [32mINFO [m [SecretUtils:70] Creating secret team-b-client-secret
2022-04-06 06:33:56 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-broker-secret
2022-04-06 06:33:56 [main] [32mINFO [m [SecretUtils:70] Creating secret my-connect-oauth
2022-04-06 06:33:56 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-oauth
2022-04-06 06:33:56 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-2-oauth
2022-04-06 06:33:56 [main] [32mINFO [m [SecretUtils:70] Creating secret my-bridge-oauth
2022-04-06 06:33:56 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-audience-secret
2022-04-06 06:33:56 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-client-secret
2022-04-06 06:33:56 [main] [32mINFO [m [KeycloakInstance:50] Replacing validIssuerUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal to pointing to kafka-authz realm
2022-04-06 06:33:56 [main] [32mINFO [m [KeycloakInstance:51] Replacing jwksEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/certs to pointing to kafka-authz realm
2022-04-06 06:33:56 [main] [32mINFO [m [KeycloakInstance:52] Replacing oauthTokenEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token to pointing to kafka-authz realm
2022-04-06 06:33:56 [main] [32mINFO [m [KeycloakInstance:55] Using HTTPS endpoints
2022-04-06 06:33:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-authz-name in namespace infra-namespace
2022-04-06 06:33:56 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-authz-name will have desired state: Ready
2022-04-06 06:35:07 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-authz-name is in desired state: Ready
2022-04-06 06:35:07 [main] [32mINFO [m [OauthAuthorizationIsolatedST:680] Setting producer and consumer properties
2022-04-06 06:35:07 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser team-a-client in namespace infra-namespace
2022-04-06 06:35:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: team-a-client will have desired state: Ready
2022-04-06 06:35:08 [main] [32mINFO [m [ResourceManager:444] KafkaUser: team-a-client is in desired state: Ready
2022-04-06 06:35:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser team-b-client in namespace infra-namespace
2022-04-06 06:35:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: team-b-client will have desired state: Ready
2022-04-06 06:35:09 [main] [32mINFO [m [ResourceManager:444] KafkaUser: team-b-client is in desired state: Ready
2022-04-06 06:35:09 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:35:09 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.smokeTestForClients-STARTED
2022-04-06 06:35:09 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:35:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic a-topic-my-topic-658591668-998363980 in namespace infra-namespace
2022-04-06 06:35:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: a-topic-my-topic-658591668-998363980 will have desired state: Ready
2022-04-06 06:35:10 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: a-topic-my-topic-658591668-998363980 is in desired state: Ready
2022-04-06 06:35:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-e5baaec2 in namespace infra-namespace
2022-04-06 06:35:10 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-e5baaec2 will be in active state
2022-04-06 06:35:11 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-e5baaec2 to finished
2022-04-06 06:35:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-consumer-my-cluster-e5baaec2 in namespace infra-namespace
2022-04-06 06:35:20 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-consumer-my-cluster-e5baaec2 will be in active state
2022-04-06 06:35:21 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-consumer-my-cluster-e5baaec2 to finished
2022-04-06 06:35:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:35:32 [main] [32mINFO [m [ResourceManager:348] Delete all resources for smokeTestForClients
2022-04-06 06:35:32 [main] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-e5baaec2 in namespace infra-namespace
2022-04-06 06:35:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic a-topic-my-topic-658591668-998363980 in namespace infra-namespace
2022-04-06 06:35:32 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-consumer-my-cluster-e5baaec2 in namespace infra-namespace
2022-04-06 06:35:42 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:35:42 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.smokeTestForClients-FINISHED
2022-04-06 06:35:42 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:35:42 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:35:42 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamAWriteToTopic-STARTED
2022-04-06 06:35:42 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:35:42 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-559746075-1710317906 in namespace infra-namespace
2022-04-06 06:35:42 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-559746075-1710317906 will have desired state: Ready
2022-04-06 06:35:43 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-559746075-1710317906 is in desired state: Ready
2022-04-06 06:35:43 [main] [32mINFO [m [OauthAuthorizationIsolatedST:146] Sending 100 messages to broker with topic name my-topic-559746075-1710317906
2022-04-06 06:35:43 [main] [32mINFO [m [OauthAuthorizationIsolatedST:147] Producer will not produce messages because authorization topic will failed. Team A can write only to topic starting with 'x-'
2022-04-06 06:35:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-88bc7df3 in namespace infra-namespace
2022-04-06 06:35:43 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-88bc7df3 will be in active state
2022-04-06 06:35:44 [main] [32mINFO [m [JobUtils:70] Waiting for job: team-a-client-producer-my-cluster-88bc7df3 will be in error state
2022-04-06 06:36:02 [main] [32mINFO [m [OauthAuthorizationIsolatedST:154] Sending 100 messages to broker with topic name x-topic-my-cluster-88bc7df3
2022-04-06 06:36:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-88bc7df3 in namespace infra-namespace
2022-04-06 06:36:02 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-88bc7df3 will be in active state
2022-04-06 06:36:03 [main] [32mINFO [m [JobUtils:70] Waiting for job: team-a-client-producer-my-cluster-88bc7df3 will be in error state
2022-04-06 06:36:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic x-topic-my-cluster-88bc7df3 in namespace infra-namespace
2022-04-06 06:36:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: x-topic-my-cluster-88bc7df3 will have desired state: Ready
2022-04-06 06:36:24 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: x-topic-my-cluster-88bc7df3 is in desired state: Ready
2022-04-06 06:36:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-88bc7df3 in namespace infra-namespace
2022-04-06 06:36:24 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-88bc7df3 will be in active state
2022-04-06 06:36:25 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-88bc7df3 to finished
2022-04-06 06:36:34 [main] [32mINFO [m [OauthAuthorizationIsolatedST:172] Sending 100 messages to broker with topic name a-topic-my-cluster-88bc7df3
2022-04-06 06:36:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-88bc7df3 in namespace infra-namespace
2022-04-06 06:36:34 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-88bc7df3 will be in active state
2022-04-06 06:36:35 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-88bc7df3 to finished
2022-04-06 06:36:44 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:36:44 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTeamAWriteToTopic
2022-04-06 06:36:44 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic x-topic-my-cluster-88bc7df3 in namespace infra-namespace
2022-04-06 06:36:44 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-559746075-1710317906 in namespace infra-namespace
2022-04-06 06:36:44 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-88bc7df3 in namespace infra-namespace
2022-04-06 06:36:44 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-88bc7df3 in namespace infra-namespace
2022-04-06 06:36:44 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-88bc7df3 in namespace infra-namespace
2022-04-06 06:36:44 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-88bc7df3 in namespace infra-namespace
2022-04-06 06:36:54 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:36:54 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamAWriteToTopic-FINISHED
2022-04-06 06:36:54 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:36:54 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:36:54 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamAReadFromTopic-STARTED
2022-04-06 06:36:54 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:36:54 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic a-topic-my-topic-2074751957-1154565536 in namespace infra-namespace
2022-04-06 06:36:54 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: a-topic-my-topic-2074751957-1154565536 will have desired state: Ready
2022-04-06 06:36:55 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: a-topic-my-topic-2074751957-1154565536 is in desired state: Ready
2022-04-06 06:36:55 [main] [32mINFO [m [OauthAuthorizationIsolatedST:208] Sending 100 messages to broker with topic name a-topic-my-topic-2074751957-1154565536
2022-04-06 06:36:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-7e0ca8f5 in namespace infra-namespace
2022-04-06 06:36:55 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-7e0ca8f5 will be in active state
2022-04-06 06:36:56 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-7e0ca8f5 to finished
2022-04-06 06:37:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-consumer-my-cluster-7e0ca8f5 in namespace infra-namespace
2022-04-06 06:37:04 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-consumer-my-cluster-7e0ca8f5 will be in active state
2022-04-06 06:37:05 [main] [32mINFO [m [JobUtils:70] Waiting for job: team-a-client-consumer-my-cluster-7e0ca8f5 will be in error state
2022-04-06 06:37:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-7e0ca8f5 in namespace infra-namespace
2022-04-06 06:37:08 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-7e0ca8f5 will be in active state
2022-04-06 06:37:09 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-7e0ca8f5 to finished
2022-04-06 06:37:12 [main] [32mINFO [m [OauthAbstractST:153] Deleting team-a-client-consumer-my-cluster-7e0ca8f5 job
2022-04-06 06:37:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:37:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTeamAReadFromTopic
2022-04-06 06:37:17 [main] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-consumer-my-cluster-7e0ca8f5 in namespace infra-namespace
2022-04-06 06:37:17 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-7e0ca8f5 in namespace infra-namespace
2022-04-06 06:37:17 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic a-topic-my-topic-2074751957-1154565536 in namespace infra-namespace
2022-04-06 06:37:17 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-7e0ca8f5 in namespace infra-namespace
2022-04-06 06:37:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:37:27 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamAReadFromTopic-FINISHED
2022-04-06 06:37:27 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:37:27 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:37:27 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamBWriteToTopic-STARTED
2022-04-06 06:37:27 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:37:27 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1471759285-1214474718 in namespace infra-namespace
2022-04-06 06:37:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1471759285-1214474718 will have desired state: Ready
2022-04-06 06:37:28 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1471759285-1214474718 is in desired state: Ready
2022-04-06 06:37:28 [main] [32mINFO [m [OauthAuthorizationIsolatedST:259] Sending 100 messages to broker with topic name my-topic-57885039-819052364
2022-04-06 06:37:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-b-client-producer-my-cluster-0dfa5f2d in namespace infra-namespace
2022-04-06 06:37:28 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-b-client-producer-my-cluster-0dfa5f2d will be in active state
2022-04-06 06:37:29 [main] [32mINFO [m [JobUtils:70] Waiting for job: team-b-client-producer-my-cluster-0dfa5f2d will be in error state
2022-04-06 06:37:48 [main] [32mINFO [m [OauthAuthorizationIsolatedST:265] Sending 100 messages to broker with topic name b-topic
2022-04-06 06:37:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-b-client-producer-my-cluster-0dfa5f2d in namespace infra-namespace
2022-04-06 06:37:48 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-b-client-producer-my-cluster-0dfa5f2d will be in active state
2022-04-06 06:37:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-b-client-consumer-my-cluster-0dfa5f2d in namespace infra-namespace
2022-04-06 06:37:49 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-b-client-consumer-my-cluster-0dfa5f2d will be in active state
2022-04-06 06:37:50 [main] [32mINFO [m [ClientUtils:61] Waiting till producer team-b-client-producer-my-cluster-0dfa5f2d and consumer team-b-client-consumer-my-cluster-0dfa5f2d finish
2022-04-06 06:38:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:38:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTeamBWriteToTopic
2022-04-06 06:38:02 [main] [32mINFO [m [ResourceManager:241] Delete of Job team-b-client-producer-my-cluster-0dfa5f2d in namespace infra-namespace
2022-04-06 06:38:02 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job team-b-client-consumer-my-cluster-0dfa5f2d in namespace infra-namespace
2022-04-06 06:38:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1471759285-1214474718 in namespace infra-namespace
2022-04-06 06:38:02 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job team-b-client-producer-my-cluster-0dfa5f2d in namespace infra-namespace
2022-04-06 06:38:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:38:12 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamBWriteToTopic-FINISHED
2022-04-06 06:38:12 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:38:12 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:38:12 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamAWriteToTopicStartingWithXAndTeamBReadFromTopicStartingWithX-STARTED
2022-04-06 06:38:12 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:38:12 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic x-topicmy-topic-1777305003-1642744847 in namespace infra-namespace
2022-04-06 06:38:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: x-topicmy-topic-1777305003-1642744847 will have desired state: Ready
2022-04-06 06:38:13 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: x-topicmy-topic-1777305003-1642744847 is in desired state: Ready
2022-04-06 06:38:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-e2926317 in namespace infra-namespace
2022-04-06 06:38:13 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-e2926317 will be in active state
2022-04-06 06:38:14 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-e2926317 to finished
2022-04-06 06:38:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-b-client-consumer-my-cluster-e2926317 in namespace infra-namespace
2022-04-06 06:38:22 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-b-client-consumer-my-cluster-e2926317 will be in active state
2022-04-06 06:38:23 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-b-client-consumer-my-cluster-e2926317 to finished
2022-04-06 06:38:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:38:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTeamAWriteToTopicStartingWithXAndTeamBReadFromTopicStartingWithX
2022-04-06 06:38:34 [main] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-e2926317 in namespace infra-namespace
2022-04-06 06:38:34 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job team-b-client-consumer-my-cluster-e2926317 in namespace infra-namespace
2022-04-06 06:38:34 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic x-topicmy-topic-1777305003-1642744847 in namespace infra-namespace
2022-04-06 06:38:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:38:44 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamAWriteToTopicStartingWithXAndTeamBReadFromTopicStartingWithX-FINISHED
2022-04-06 06:38:44 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:38:44 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:38:44 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testSuperUserWithOauthAuthorization-STARTED
2022-04-06 06:38:44 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:38:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic x-topicmy-topic-355287153-763712625 in namespace infra-namespace
2022-04-06 06:38:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: x-topicmy-topic-355287153-763712625 will have desired state: Ready
2022-04-06 06:38:45 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: x-topicmy-topic-355287153-763712625 is in desired state: Ready
2022-04-06 06:38:45 [main] [32mINFO [m [OauthAuthorizationIsolatedST:347] Verifying that team B is not able write to topic starting with 'x-' because in kafka clusterdoes not have super-users to break authorization rules
2022-04-06 06:38:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-285704538-448271880 in namespace infra-namespace
2022-04-06 06:38:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-285704538-448271880 will have desired state: Ready
2022-04-06 06:38:46 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-285704538-448271880 is in desired state: Ready
2022-04-06 06:38:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-b-client-producer-my-cluster-8c7fa01a in namespace infra-namespace
2022-04-06 06:38:46 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-b-client-producer-my-cluster-8c7fa01a will be in active state
2022-04-06 06:38:47 [main] [32mINFO [m [JobUtils:70] Waiting for job: team-b-client-producer-my-cluster-8c7fa01a will be in error state
2022-04-06 06:38:56 [main] [32mINFO [m [OauthAuthorizationIsolatedST:370] Verifying that team A is not able read to topic starting with 'x-' because in kafka clusterdoes not have super-users to break authorization rules
2022-04-06 06:38:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-consumer-my-cluster-8c7fa01a in namespace infra-namespace
2022-04-06 06:38:56 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-consumer-my-cluster-8c7fa01a will be in active state
2022-04-06 06:38:57 [main] [32mINFO [m [JobUtils:70] Waiting for job: team-a-client-consumer-my-cluster-8c7fa01a will be in error state
2022-04-06 06:39:05 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: oauth-cluster-authz-name-kafka rolling update
2022-04-06 06:39:15 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: oauth-cluster-authz-name-kafka has been successfully rolled
2022-04-06 06:39:15 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 1 Pod(s) of oauth-cluster-authz-name-kafka to be ready
2022-04-06 06:39:41 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-authz-name will have desired state: Ready
2022-04-06 06:39:41 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-authz-name is in desired state: Ready
2022-04-06 06:39:41 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: oauth-cluster-authz-name is ready
2022-04-06 06:39:41 [main] [32mINFO [m [OauthAuthorizationIsolatedST:404] Verifying that team B is able to write to topic starting with 'x-' and break authorization rule
2022-04-06 06:39:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-b-client-producer-my-cluster-8c7fa01a in namespace infra-namespace
2022-04-06 06:39:41 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-b-client-producer-my-cluster-8c7fa01a will be in active state
2022-04-06 06:39:42 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-b-client-producer-my-cluster-8c7fa01a to finished
2022-04-06 06:39:50 [main] [32mINFO [m [OauthAuthorizationIsolatedST:409] Verifying that team A is able to write to topic starting with 'x-' and break authorization rule
2022-04-06 06:39:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-consumer-my-cluster-8c7fa01a in namespace infra-namespace
2022-04-06 06:39:50 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-consumer-my-cluster-8c7fa01a will be in active state
2022-04-06 06:39:51 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-consumer-my-cluster-8c7fa01a to finished
2022-04-06 06:40:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:40:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSuperUserWithOauthAuthorization
2022-04-06 06:40:02 [main] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-consumer-my-cluster-8c7fa01a in namespace infra-namespace
2022-04-06 06:40:02 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-consumer-my-cluster-8c7fa01a in namespace infra-namespace
2022-04-06 06:40:02 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job team-b-client-producer-my-cluster-8c7fa01a in namespace infra-namespace
2022-04-06 06:40:02 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-285704538-448271880 in namespace infra-namespace
2022-04-06 06:40:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job team-b-client-producer-my-cluster-8c7fa01a in namespace infra-namespace
2022-04-06 06:40:02 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic x-topicmy-topic-355287153-763712625 in namespace infra-namespace
2022-04-06 06:40:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:40:12 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testSuperUserWithOauthAuthorization-FINISHED
2022-04-06 06:40:12 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:40:12 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:40:12 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testSessionReAuthentication-STARTED
2022-04-06 06:40:12 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:40:12 [main] [32mINFO [m [OauthAuthorizationIsolatedST:443] Verifying that team A producer is able to send messages to the x-topic-example-topic topic -> the topic starting with 'x'
2022-04-06 06:40:12 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic x-topic-example-topic in namespace infra-namespace
2022-04-06 06:40:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: x-topic-example-topic will have desired state: Ready
2022-04-06 06:40:13 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: x-topic-example-topic is in desired state: Ready
2022-04-06 06:40:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic a-topic-example-topic in namespace infra-namespace
2022-04-06 06:40:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: a-topic-example-topic will have desired state: Ready
2022-04-06 06:40:14 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: a-topic-example-topic is in desired state: Ready
2022-04-06 06:40:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-99e91766 in namespace infra-namespace
2022-04-06 06:40:14 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-99e91766 will be in active state
2022-04-06 06:40:15 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-99e91766 to finished
2022-04-06 06:40:24 [main] [32mINFO [m [OauthAuthorizationIsolatedST:465] Adding the maxSecondsWithoutReauthentication to Kafka listener with OAuth authentication
2022-04-06 06:40:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-authz-name will have desired state: Ready
2022-04-06 06:40:24 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-authz-name is in desired state: Ready
2022-04-06 06:40:24 [main] [32mINFO [m [OauthAuthorizationIsolatedST:493] Setting the master realm token's lifespan to 3600s
2022-04-06 06:40:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-88lkq -- curl -v --insecure -X POST -d client_id=admin-cli&client_secret=aGVsbG8td29ybGQtcHJvZHVjZXItc2VjcmV0&grant_type=password&username=admin&password=6g3DJA6KdCHC_Q== https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/master/protocol/openid-connect/token
2022-04-06 06:40:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 06:40:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-88lkq -- curl -v --insecure -X GET https://keycloak.infra-namespace.svc.cluster.local:8443/auth/admin/realms/master -H Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICI4bFlfczFwQ2ZGS2IzRFNZOGVVOEdQSjRSRnYwRDlNVFZYWmNXTFFIekpnIn0.eyJleHAiOjE2NDkyMjcyODQsImlhdCI6MTY0OTIyNzIyNCwianRpIjoiZjkyY2M0NWQtNmU1MC00MzI3LWEzZWQtMTdlZGQ0NmExOGEyIiwiaXNzIjoiaHR0cHM6Ly9rZXljbG9hay5pbmZyYS1uYW1lc3BhY2Uuc3ZjLmNsdXN0ZXIubG9jYWw6ODQ0My9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJzdWIiOiI2MzcyNzVjNi04MGU1LTRkYTEtYWM2OS1jNjBlODRjMDY1NDAiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhZG1pbi1jbGkiLCJzZXNzaW9uX3N0YXRlIjoiOTIxMmY2MzktNjQ1Yi00ZDgwLWI1YTQtZWIzY2VhY2FhMDU1IiwiYWNyIjoiMSIsInNjb3BlIjoicHJvZmlsZSBlbWFpbCIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4ifQ.HRyUEAz3oh4L6iOzZgg_t_bOZqDOr5bUrH6gVMlhgWVyMP1nyHKUTn7t9BXWfaR0HlnjCP8QFB_Y-PiTVLY7DEZsmnndls_Q9z6HZgP2QWElUg37uMLFKcgKr_urQgpzS9up_AUbZHYadHlm7H1hEgnzB83Bfn7BU0vHWbLkd7ApD8X5FHl1-HEr6K-YFBnqAML9TZBXqeIGcxfyulISuDF110t7ME9VpM7jOMfvOaiMCT_ePQmo-cf5u6tmmHLvtuOMT39vZZsYMsbIP2avmFhb6ShnKukAFKeectWkCsoMF8vfVW8sMJQ1sB0DaUWr7yZI97mcbyEgC97ZfmPUpQ
2022-04-06 06:40:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 06:40:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-88lkq -- curl -v --insecure -X PUT https://keycloak.infra-namespace.svc.cluster.local:8443/auth/admin/realms/master -H Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICI4bFlfczFwQ2ZGS2IzRFNZOGVVOEdQSjRSRnYwRDlNVFZYWmNXTFFIekpnIn0.eyJleHAiOjE2NDkyMjcyODQsImlhdCI6MTY0OTIyNzIyNCwianRpIjoiZjkyY2M0NWQtNmU1MC00MzI3LWEzZWQtMTdlZGQ0NmExOGEyIiwiaXNzIjoiaHR0cHM6Ly9rZXljbG9hay5pbmZyYS1uYW1lc3BhY2Uuc3ZjLmNsdXN0ZXIubG9jYWw6ODQ0My9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJzdWIiOiI2MzcyNzVjNi04MGU1LTRkYTEtYWM2OS1jNjBlODRjMDY1NDAiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhZG1pbi1jbGkiLCJzZXNzaW9uX3N0YXRlIjoiOTIxMmY2MzktNjQ1Yi00ZDgwLWI1YTQtZWIzY2VhY2FhMDU1IiwiYWNyIjoiMSIsInNjb3BlIjoicHJvZmlsZSBlbWFpbCIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4ifQ.HRyUEAz3oh4L6iOzZgg_t_bOZqDOr5bUrH6gVMlhgWVyMP1nyHKUTn7t9BXWfaR0HlnjCP8QFB_Y-PiTVLY7DEZsmnndls_Q9z6HZgP2QWElUg37uMLFKcgKr_urQgpzS9up_AUbZHYadHlm7H1hEgnzB83Bfn7BU0vHWbLkd7ApD8X5FHl1-HEr6K-YFBnqAML9TZBXqeIGcxfyulISuDF110t7ME9VpM7jOMfvOaiMCT_ePQmo-cf5u6tmmHLvtuOMT39vZZsYMsbIP2avmFhb6ShnKukAFKeectWkCsoMF8vfVW8sMJQ1sB0DaUWr7yZI97mcbyEgC97ZfmPUpQ -d {"id":"master","realm":"master","displayName":"Keycloak","displayNameHtml":"<div class=\"kc-logo-text\"><span>Keycloak</span></div>","notBefore":0,"revokeRefreshToken":false,"refreshTokenMaxReuse":0,"accessTokenLifespan":"3600","accessTokenLifespanForImplicitFlow":900,"ssoSessionIdleTimeout":1800,"ssoSessionMaxLifespan":36000,"ssoSessionIdleTimeoutRememberMe":0,"ssoSessionMaxLifespanRememberMe":0,"offlineSessionIdleTimeout":2592000,"offlineSessionMaxLifespanEnabled":false,"offlineSessionMaxLifespan":5184000,"clientSessionIdleTimeout":0,"clientSessionMaxLifespan":0,"clientOfflineSessionIdleTimeout":0,"clientOfflineSessionMaxLifespan":0,"accessCodeLifespan":60,"accessCodeLifespanUserAction":300,"accessCodeLifespanLogin":1800,"actionTokenGeneratedByAdminLifespan":43200,"actionTokenGeneratedByUserLifespan":300,"enabled":true,"sslRequired":"external","registrationAllowed":false,"registrationEmailAsUsername":false,"rememberMe":false,"verifyEmail":false,"loginWithEmailAllowed":true,"duplicateEmailsAllowed":false,"resetPasswordAllowed":false,"editUsernameAllowed":false,"bruteForceProtected":false,"permanentLockout":false,"maxFailureWaitSeconds":900,"minimumQuickLoginWaitSeconds":60,"waitIncrementSeconds":60,"quickLoginCheckMilliSeconds":1000,"maxDeltaTimeSeconds":43200,"failureFactor":30,"defaultRoles":["offline_access","uma_authorization"],"requiredCredentials":["password"],"otpPolicyType":"totp","otpPolicyAlgorithm":"HmacSHA1","otpPolicyInitialCounter":0,"otpPolicyDigits":6,"otpPolicyLookAheadWindow":1,"otpPolicyPeriod":30,"otpSupportedApplications":["FreeOTP","Google Authenticator"],"webAuthnPolicyRpEntityName":"keycloak","webAuthnPolicySignatureAlgorithms":["ES256"],"webAuthnPolicyRpId":"","webAuthnPolicyAttestationConveyancePreference":"not specified","webAuthnPolicyAuthenticatorAttachment":"not specified","webAuthnPolicyRequireResidentKey":"not specified","webAuthnPolicyUserVerificationRequirement":"not specified","webAuthnPolicyCreateTimeout":0,"webAuthnPolicyAvoidSameAuthenticatorRegister":false,"webAuthnPolicyAcceptableAaguids":[],"webAuthnPolicyPasswordlessRpEntityName":"keycloak","webAuthnPolicyPasswordlessSignatureAlgorithms":["ES256"],"webAuthnPolicyPasswordlessRpId":"","webAuthnPolicyPasswordlessAttestationConveyancePreference":"not specified","webAuthnPolicyPasswordlessAuthenticatorAttachment":"not specified","webAuthnPolicyPasswordlessRequireResidentKey":"not specified","webAuthnPolicyPasswordlessUserVerificationRequirement":"not specified","webAuthnPolicyPasswordlessCreateTimeout":0,"webAuthnPolicyPasswordlessAvoidSameAuthenticatorRegister":false,"webAuthnPolicyPasswordlessAcceptableAaguids":[],"browserSecurityHeaders":{"contentSecurityPolicyReportOnly":"","xContentTypeOptions":"nosniff","xRobotsTag":"none","xFrameOptions":"SAMEORIGIN","xXSSProtection":"1; mode=block","contentSecurityPolicy":"frame-src 'self'; frame-ancestors 'self'; object-src 'none';","strictTransportSecurity":"max-age=31536000; includeSubDomains"},"smtpServer":{},"eventsEnabled":false,"eventsListeners":["jboss-logging"],"enabledEventTypes":[],"adminEventsEnabled":false,"adminEventsDetailsEnabled":false,"internationalizationEnabled":false,"supportedLocales":[],"browserFlow":"browser","registrationFlow":"registration","directGrantFlow":"direct grant","resetCredentialsFlow":"reset credentials","clientAuthenticationFlow":"clients","dockerAuthenticationFlow":"docker auth","attributes":{},"userManagedAccessAllowed":false} -H Content-Type: application/json
2022-04-06 06:40:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 06:40:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-88lkq -- curl -v --insecure -X POST -d client_id=admin-cli&client_secret=aGVsbG8td29ybGQtcHJvZHVjZXItc2VjcmV0&grant_type=password&username=admin&password=6g3DJA6KdCHC_Q== https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/master/protocol/openid-connect/token
2022-04-06 06:40:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 06:40:25 [main] [32mINFO [m [OauthAuthorizationIsolatedST:508] Getting the kafka-authz kafka client for obtaining the Dev A Team policy for the x topics
2022-04-06 06:40:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-88lkq -- curl -v --insecure -X GET https://keycloak.infra-namespace.svc.cluster.local:8443/auth/admin/realms/kafka-authz/clients -H Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICI4bFlfczFwQ2ZGS2IzRFNZOGVVOEdQSjRSRnYwRDlNVFZYWmNXTFFIekpnIn0.eyJleHAiOjE2NDkyMzA4MjUsImlhdCI6MTY0OTIyNzIyNSwianRpIjoiYTBmZmFiMDAtZWU4Zi00MDBiLTgwYmUtOTM4YzYxYmNiOTUxIiwiaXNzIjoiaHR0cHM6Ly9rZXljbG9hay5pbmZyYS1uYW1lc3BhY2Uuc3ZjLmNsdXN0ZXIubG9jYWw6ODQ0My9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJzdWIiOiI2MzcyNzVjNi04MGU1LTRkYTEtYWM2OS1jNjBlODRjMDY1NDAiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhZG1pbi1jbGkiLCJzZXNzaW9uX3N0YXRlIjoiYjQ4ZDBmZDUtYjhiZC00NmFiLTliMDktYTcwZWNiZDY3OWEzIiwiYWNyIjoiMSIsInNjb3BlIjoicHJvZmlsZSBlbWFpbCIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4ifQ.U_7uPpiEM9yxC097tJillqGSIFqcdgqZHnsttplYl0oEbdZOjmZ76TBnW66WnxtW4-ND5Shl_eIHOHOqu13b03YBtVupthUzExAZBcz0E58nib7p7U2YLcYZGbXVMtMXRULRxHOBCHTa-_ycIhzA0xsjjS2xNUfFbsOHqsFeQ7j-CD0MHyOb0609T0Ej4ecqYFpdOzq7h3JyDiGd3W2TiX51Ta28aYdcAR8bIujmlBbo1OrMA6_DcICnuDBqmAKh7KeDcjHM6zWVeVg0zEv7Pz7oyfYnM-hbeKgLmEvKkjnEr4BD41CLJricOhYf7tefP03O-LnRvjl1jbkFX7MRqg
2022-04-06 06:40:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 06:40:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-88lkq -- curl -v --insecure -X GET https://keycloak.infra-namespace.svc.cluster.local:8443/auth/admin/realms/kafka-authz/clients/63ce7236-5986-4f29-b625-6f4a1833add7/authz/resource-server/policy -H Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICI4bFlfczFwQ2ZGS2IzRFNZOGVVOEdQSjRSRnYwRDlNVFZYWmNXTFFIekpnIn0.eyJleHAiOjE2NDkyMzA4MjUsImlhdCI6MTY0OTIyNzIyNSwianRpIjoiYTBmZmFiMDAtZWU4Zi00MDBiLTgwYmUtOTM4YzYxYmNiOTUxIiwiaXNzIjoiaHR0cHM6Ly9rZXljbG9hay5pbmZyYS1uYW1lc3BhY2Uuc3ZjLmNsdXN0ZXIubG9jYWw6ODQ0My9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJzdWIiOiI2MzcyNzVjNi04MGU1LTRkYTEtYWM2OS1jNjBlODRjMDY1NDAiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhZG1pbi1jbGkiLCJzZXNzaW9uX3N0YXRlIjoiYjQ4ZDBmZDUtYjhiZC00NmFiLTliMDktYTcwZWNiZDY3OWEzIiwiYWNyIjoiMSIsInNjb3BlIjoicHJvZmlsZSBlbWFpbCIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4ifQ.U_7uPpiEM9yxC097tJillqGSIFqcdgqZHnsttplYl0oEbdZOjmZ76TBnW66WnxtW4-ND5Shl_eIHOHOqu13b03YBtVupthUzExAZBcz0E58nib7p7U2YLcYZGbXVMtMXRULRxHOBCHTa-_ycIhzA0xsjjS2xNUfFbsOHqsFeQ7j-CD0MHyOb0609T0Ej4ecqYFpdOzq7h3JyDiGd3W2TiX51Ta28aYdcAR8bIujmlBbo1OrMA6_DcICnuDBqmAKh7KeDcjHM6zWVeVg0zEv7Pz7oyfYnM-hbeKgLmEvKkjnEr4BD41CLJricOhYf7tefP03O-LnRvjl1jbkFX7MRqg
2022-04-06 06:40:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 06:40:26 [main] [32mINFO [m [OauthAuthorizationIsolatedST:539] Changing the Dev Team A policy for topics starting with x- and checking that job will not be successful
2022-04-06 06:40:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-88lkq -- curl -v --insecure -X PUT https://keycloak.infra-namespace.svc.cluster.local:8443/auth/admin/realms/kafka-authz/clients/63ce7236-5986-4f29-b625-6f4a1833add7/authz/resource-server/policy/ebf0a38b-5ffe-403d-9ee5-004407f69d5a -H Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICI4bFlfczFwQ2ZGS2IzRFNZOGVVOEdQSjRSRnYwRDlNVFZYWmNXTFFIekpnIn0.eyJleHAiOjE2NDkyMzA4MjUsImlhdCI6MTY0OTIyNzIyNSwianRpIjoiYTBmZmFiMDAtZWU4Zi00MDBiLTgwYmUtOTM4YzYxYmNiOTUxIiwiaXNzIjoiaHR0cHM6Ly9rZXljbG9hay5pbmZyYS1uYW1lc3BhY2Uuc3ZjLmNsdXN0ZXIubG9jYWw6ODQ0My9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJzdWIiOiI2MzcyNzVjNi04MGU1LTRkYTEtYWM2OS1jNjBlODRjMDY1NDAiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhZG1pbi1jbGkiLCJzZXNzaW9uX3N0YXRlIjoiYjQ4ZDBmZDUtYjhiZC00NmFiLTliMDktYTcwZWNiZDY3OWEzIiwiYWNyIjoiMSIsInNjb3BlIjoicHJvZmlsZSBlbWFpbCIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4ifQ.U_7uPpiEM9yxC097tJillqGSIFqcdgqZHnsttplYl0oEbdZOjmZ76TBnW66WnxtW4-ND5Shl_eIHOHOqu13b03YBtVupthUzExAZBcz0E58nib7p7U2YLcYZGbXVMtMXRULRxHOBCHTa-_ycIhzA0xsjjS2xNUfFbsOHqsFeQ7j-CD0MHyOb0609T0Ej4ecqYFpdOzq7h3JyDiGd3W2TiX51Ta28aYdcAR8bIujmlBbo1OrMA6_DcICnuDBqmAKh7KeDcjHM6zWVeVg0zEv7Pz7oyfYnM-hbeKgLmEvKkjnEr4BD41CLJricOhYf7tefP03O-LnRvjl1jbkFX7MRqg -d {"id":"ebf0a38b-5ffe-403d-9ee5-004407f69d5a","name":"Dev Team A can write to topics that start with x- on any cluster","type":"scope","logic":"POSITIVE","decisionStrategy":"UNANIMOUS","config":{"resources":"[\"Topic:x-*\"]","scopes":"[\"Describe\"]","applyPolicies":"[\"Dev Team A\"]"}} -H Content-Type: application/json
2022-04-06 06:40:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 06:40:26 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-99e91766 to finished
2022-04-06 06:44:06 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for job finished, null
io.strimzi.test.WaitException: Timeout after 220000 ms waiting for job finished
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientSuccess(ClientUtils.java:77)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientSuccess(ClientUtils.java:72)
	at io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.lambda$testSessionReAuthentication$2(OauthAuthorizationIsolatedST.java:541)
	at org.junit.jupiter.api.AssertThrows.assertThrows(AssertThrows.java:55)
	at org.junit.jupiter.api.AssertThrows.assertThrows(AssertThrows.java:37)
	at org.junit.jupiter.api.Assertions.assertThrows(Assertions.java:3082)
	at io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testSessionReAuthentication(OauthAuthorizationIsolatedST.java:541)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-06 06:44:06 [main] [32mINFO [m [OauthAuthorizationIsolatedST:545] Sending messages to topic starting with a- -> the messages should be successfully sent
2022-04-06 06:44:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-99e91766 in namespace infra-namespace
2022-04-06 06:44:06 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-99e91766 will be in active state
2022-04-06 06:44:07 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-99e91766 to finished
2022-04-06 06:44:15 [main] [32mINFO [m [OauthAuthorizationIsolatedST:554] Changing back to the original settings and checking, if the producer will be successful
2022-04-06 06:44:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-88lkq -- curl -v --insecure -X PUT https://keycloak.infra-namespace.svc.cluster.local:8443/auth/admin/realms/kafka-authz/clients/63ce7236-5986-4f29-b625-6f4a1833add7/authz/resource-server/policy/ebf0a38b-5ffe-403d-9ee5-004407f69d5a -H Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICI4bFlfczFwQ2ZGS2IzRFNZOGVVOEdQSjRSRnYwRDlNVFZYWmNXTFFIekpnIn0.eyJleHAiOjE2NDkyMzA4MjUsImlhdCI6MTY0OTIyNzIyNSwianRpIjoiYTBmZmFiMDAtZWU4Zi00MDBiLTgwYmUtOTM4YzYxYmNiOTUxIiwiaXNzIjoiaHR0cHM6Ly9rZXljbG9hay5pbmZyYS1uYW1lc3BhY2Uuc3ZjLmNsdXN0ZXIubG9jYWw6ODQ0My9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJzdWIiOiI2MzcyNzVjNi04MGU1LTRkYTEtYWM2OS1jNjBlODRjMDY1NDAiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhZG1pbi1jbGkiLCJzZXNzaW9uX3N0YXRlIjoiYjQ4ZDBmZDUtYjhiZC00NmFiLTliMDktYTcwZWNiZDY3OWEzIiwiYWNyIjoiMSIsInNjb3BlIjoicHJvZmlsZSBlbWFpbCIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4ifQ.U_7uPpiEM9yxC097tJillqGSIFqcdgqZHnsttplYl0oEbdZOjmZ76TBnW66WnxtW4-ND5Shl_eIHOHOqu13b03YBtVupthUzExAZBcz0E58nib7p7U2YLcYZGbXVMtMXRULRxHOBCHTa-_ycIhzA0xsjjS2xNUfFbsOHqsFeQ7j-CD0MHyOb0609T0Ej4ecqYFpdOzq7h3JyDiGd3W2TiX51Ta28aYdcAR8bIujmlBbo1OrMA6_DcICnuDBqmAKh7KeDcjHM6zWVeVg0zEv7Pz7oyfYnM-hbeKgLmEvKkjnEr4BD41CLJricOhYf7tefP03O-LnRvjl1jbkFX7MRqg -d {"id":"ebf0a38b-5ffe-403d-9ee5-004407f69d5a","name":"Dev Team A can write to topics that start with x- on any cluster","type":"scope","logic":"POSITIVE","decisionStrategy":"UNANIMOUS","config":{"resources":"[\"Topic:x-*\"]","scopes":"[\"Describe\",\"Write\"]","applyPolicies":"[\"Dev Team A\"]"}} -H Content-Type: application/json
2022-04-06 06:44:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 06:44:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-99e91766 in namespace infra-namespace
2022-04-06 06:44:15 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-99e91766 will be in active state
2022-04-06 06:44:16 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-99e91766 to finished
2022-04-06 06:46:05 [main] [32mINFO [m [OauthAuthorizationIsolatedST:568] Changing configuration of Kafka back to it's original form
2022-04-06 06:46:05 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-authz-name will have desired state: Ready
2022-04-06 06:46:05 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-authz-name is in desired state: Ready
2022-04-06 06:46:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:46:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSessionReAuthentication
2022-04-06 06:46:05 [main] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-99e91766 in namespace infra-namespace
2022-04-06 06:46:05 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-99e91766 in namespace infra-namespace
2022-04-06 06:46:05 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-99e91766 in namespace infra-namespace
2022-04-06 06:46:05 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic x-topic-example-topic in namespace infra-namespace
2022-04-06 06:46:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic a-topic-example-topic in namespace infra-namespace
2022-04-06 06:46:15 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:46:15 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testSessionReAuthentication-FINISHED
2022-04-06 06:46:15 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:46:15 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:46:15 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testKeycloakAuthorizerToDelegateToSimpleAuthorizer-STARTED
2022-04-06 06:46:15 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:46:15 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-97 for test case:testKeycloakAuthorizerToDelegateToSimpleAuthorizer
2022-04-06 06:46:15 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-97
2022-04-06 06:46:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-97
2022-04-06 06:46:15 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-97
2022-04-06 06:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Secret sso-x509-https-secret in namespace infra-namespace
2022-04-06 06:46:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-06 06:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Secret team-a-client-secret in namespace infra-namespace
2022-04-06 06:46:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-06 06:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Secret team-b-client-secret in namespace infra-namespace
2022-04-06 06:46:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-06 06:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-fe27c63d in namespace namespace-97
2022-04-06 06:46:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-06 06:46:15 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-fe27c63d will have desired state: Ready
2022-04-06 06:47:25 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-fe27c63d is in desired state: Ready
2022-04-06 06:47:25 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser team-a-client in namespace namespace-97
2022-04-06 06:47:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-06 06:47:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: team-a-client will have desired state: Ready
2022-04-06 06:47:26 [main] [32mINFO [m [ResourceManager:444] KafkaUser: team-a-client is in desired state: Ready
2022-04-06 06:47:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser team-b-client in namespace namespace-97
2022-04-06 06:47:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-06 06:47:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: team-b-client will have desired state: Ready
2022-04-06 06:47:27 [main] [32mINFO [m [ResourceManager:444] KafkaUser: team-b-client is in desired state: Ready
2022-04-06 06:47:27 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic a-topic-my-topic-474568403-1249915633 in namespace namespace-97
2022-04-06 06:47:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-06 06:47:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: a-topic-my-topic-474568403-1249915633 will have desired state: Ready
2022-04-06 06:47:28 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: a-topic-my-topic-474568403-1249915633 is in desired state: Ready
2022-04-06 06:47:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-fe27c63d in namespace namespace-97
2022-04-06 06:47:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-06 06:47:28 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-fe27c63d will be in active state
2022-04-06 06:47:29 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-fe27c63d to finished
2022-04-06 06:47:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-consumer-my-cluster-fe27c63d in namespace namespace-97
2022-04-06 06:47:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-06 06:47:38 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-consumer-my-cluster-fe27c63d will be in active state
2022-04-06 06:47:39 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-consumer-my-cluster-fe27c63d to finished
2022-04-06 06:47:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:47:51 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKeycloakAuthorizerToDelegateToSimpleAuthorizer
2022-04-06 06:47:51 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser team-b-client in namespace namespace-97
2022-04-06 06:47:51 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic a-topic-my-topic-474568403-1249915633 in namespace namespace-97
2022-04-06 06:47:51 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaUser team-a-client in namespace namespace-97
2022-04-06 06:47:51 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-fe27c63d in namespace namespace-97
2022-04-06 06:47:51 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-consumer-my-cluster-fe27c63d in namespace namespace-97
2022-04-06 06:47:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Secret team-a-client-secret in namespace namespace-97
2022-04-06 06:47:51 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Secret team-b-client-secret in namespace namespace-97
2022-04-06 06:47:51 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Secret sso-x509-https-secret in namespace namespace-97
2022-04-06 06:47:51 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-fe27c63d in namespace namespace-97
2022-04-06 06:48:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:48:01 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-97 for test case:testKeycloakAuthorizerToDelegateToSimpleAuthorizer
2022-04-06 06:48:44 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testKeycloakAuthorizerToDelegateToSimpleAuthorizer-FINISHED
2022-04-06 06:48:44 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:48:44 [main] [32mINFO [m [KeycloakUtils:52] Teardown Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-06 06:48:48 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/teardown_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-06 06:48:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 06:48:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:48:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for OauthAuthorizationIsolatedST
2022-04-06 06:48:48 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser team-a-client in namespace infra-namespace
2022-04-06 06:48:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser team-b-client in namespace infra-namespace
2022-04-06 06:48:48 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-06 06:48:48 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-authz-name in namespace infra-namespace
2022-04-06 06:48:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:48:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:48:58 [main] [32mINFO [m [ResourceManager:346] In context OauthAuthorizationIsolatedST is everything deleted.
2022-04-06 06:48:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;33mWARNING[m] Tests run: 10, Failures: 0, Errors: 0, Skipped: 2, Time elapsed: 1,087.169 s - in io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST
2022-04-06 06:48:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 06:49:23 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 06:49:23 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 06:49:23 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 06:49:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:49:23 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 06:49:23 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 06:49:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 06:49:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 06:49:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 06:49:23 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 06:49:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 06:49:23 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 06:49:23 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 06:49:23 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:49:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 06:49:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:49:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 06:49:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:49:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 06:49:23 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 06:49:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 06:49:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 06:49:23 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 06:49:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 06:49:23 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:49:23 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 06:49:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 06:49:33 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 06:49:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 06:49:33 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 06:49:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:49:49 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 06:49:49 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 06:49:49 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 06:49:49 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 06:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 06:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 06:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 06:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 06:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 06:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 06:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 06:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 06:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 06:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 06:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 06:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 06:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 06:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 06:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 06:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:49:49 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 06:49:49 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 06:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 06:49:49 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 06:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 06:49:49 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 06:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 06:49:49 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 06:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:49:49 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 06:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 06:49:49 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 06:49:49 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 06:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 06:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 06:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:49:49 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 06:50:21 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 06:50:21 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 06:50:31 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 06:50:31 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-06 06:50:31 [main] [32mINFO [m [OauthAbstractST:125] Deploying keycloak...
2022-04-06 06:50:31 [main] [32mINFO [m [KeycloakUtils:35] Prepare Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-06 06:52:08 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/prepare_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-06 06:52:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 06:52:08 [main] [32mINFO [m [KeycloakUtils:48] Keycloak in namespace infra-namespace is ready
2022-04-06 06:52:08 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret credential-example-keycloak
2022-04-06 06:52:08 [main] [32mINFO [m [SecretUtils:50] Secret credential-example-keycloak created
2022-04-06 06:52:08 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-producer-secret
2022-04-06 06:52:08 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-consumer-secret
2022-04-06 06:52:08 [main] [32mINFO [m [SecretUtils:70] Creating secret team-a-client-secret
2022-04-06 06:52:08 [main] [32mINFO [m [SecretUtils:70] Creating secret team-b-client-secret
2022-04-06 06:52:08 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-broker-secret
2022-04-06 06:52:08 [main] [32mINFO [m [SecretUtils:70] Creating secret my-connect-oauth
2022-04-06 06:52:08 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-oauth
2022-04-06 06:52:08 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-2-oauth
2022-04-06 06:52:08 [main] [32mINFO [m [SecretUtils:70] Creating secret my-bridge-oauth
2022-04-06 06:52:08 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-audience-secret
2022-04-06 06:52:08 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-client-secret
2022-04-06 06:52:08 [main] [32mINFO [m [KeycloakInstance:50] Replacing validIssuerUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal to pointing to scope-test realm
2022-04-06 06:52:08 [main] [32mINFO [m [KeycloakInstance:51] Replacing jwksEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/certs to pointing to scope-test realm
2022-04-06 06:52:08 [main] [32mINFO [m [KeycloakInstance:52] Replacing oauthTokenEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token to pointing to scope-test realm
2022-04-06 06:52:08 [main] [32mINFO [m [KeycloakInstance:60] Using HTTP endpoints
2022-04-06 06:52:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-scope-name in namespace infra-namespace
2022-04-06 06:52:08 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-scope-name will have desired state: Ready
2022-04-06 06:53:21 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-scope-name is in desired state: Ready
2022-04-06 06:53:21 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:53:21 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testScopeKafkaConnectSetCorrectly-STARTED
2022-04-06 06:53:21 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:53:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-bddf8cc4-kafka-clients in namespace infra-namespace
2022-04-06 06:53:21 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-bddf8cc4-kafka-clients will be ready
2022-04-06 06:53:23 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-bddf8cc4-kafka-clients is ready
2022-04-06 06:53:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-bddf8cc4-scraper in namespace infra-namespace
2022-04-06 06:53:23 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-bddf8cc4-scraper will be ready
2022-04-06 06:53:24 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-bddf8cc4-scraper is ready
2022-04-06 06:53:24 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-bddf8cc4-scraper to be ready
2022-04-06 06:53:34 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-bddf8cc4-scraper is ready
2022-04-06 06:53:34 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-bddf8cc4-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 06:53:34 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-bddf8cc4-allow in namespace infra-namespace
2022-04-06 06:53:34 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 06:53:34 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-bddf8cc4 in namespace infra-namespace
2022-04-06 06:53:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-bddf8cc4 will have desired state: Ready
2022-04-06 06:54:45 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-bddf8cc4 is in desired state: Ready
2022-04-06 06:54:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:54:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScopeKafkaConnectSetCorrectly
2022-04-06 06:54:45 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-bddf8cc4-allow in namespace infra-namespace
2022-04-06 06:54:45 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-bddf8cc4 in namespace infra-namespace
2022-04-06 06:54:45 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-bddf8cc4-kafka-clients in namespace infra-namespace
2022-04-06 06:54:45 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-bddf8cc4-scraper in namespace infra-namespace
2022-04-06 06:55:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:55:25 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testScopeKafkaConnectSetCorrectly-FINISHED
2022-04-06 06:55:25 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:55:25 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:55:25 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testScopeKafkaConnectSetIncorrectly-STARTED
2022-04-06 06:55:25 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:55:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-fc119aa9-kafka-clients in namespace infra-namespace
2022-04-06 06:55:25 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-fc119aa9-kafka-clients will be ready
2022-04-06 06:55:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-fc119aa9-kafka-clients is ready
2022-04-06 06:55:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-fc119aa9-scraper in namespace infra-namespace
2022-04-06 06:55:27 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-fc119aa9-scraper will be ready
2022-04-06 06:55:29 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-fc119aa9-scraper is ready
2022-04-06 06:55:29 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-fc119aa9-scraper to be ready
2022-04-06 06:55:39 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-fc119aa9-scraper is ready
2022-04-06 06:55:39 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-fc119aa9-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 06:55:39 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-fc119aa9-allow in namespace infra-namespace
2022-04-06 06:55:39 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 06:55:39 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-fc119aa9 in namespace infra-namespace
2022-04-06 06:55:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:55:53 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScopeKafkaConnectSetIncorrectly
2022-04-06 06:55:53 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-fc119aa9-allow in namespace infra-namespace
2022-04-06 06:55:53 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-fc119aa9 in namespace infra-namespace
2022-04-06 06:55:53 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-fc119aa9-scraper in namespace infra-namespace
2022-04-06 06:55:53 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-fc119aa9-kafka-clients in namespace infra-namespace
2022-04-06 06:56:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:56:43 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testScopeKafkaConnectSetIncorrectly-FINISHED
2022-04-06 06:56:43 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:56:43 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:56:43 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testClientScopeKafkaSetCorrectly-STARTED
2022-04-06 06:56:43 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:56:43 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 06:56:43 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-883316535-1910966124 in namespace infra-namespace
2022-04-06 06:56:43 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-883316535-1910966124 will have desired state: Ready
2022-04-06 06:56:44 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-883316535-1910966124 is in desired state: Ready
2022-04-06 06:56:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-bf2d7a64 in namespace infra-namespace
2022-04-06 06:56:44 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-bf2d7a64 will be in active state
2022-04-06 06:56:45 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-bf2d7a64 to finished
2022-04-06 06:56:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:56:53 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testClientScopeKafkaSetCorrectly
2022-04-06 06:56:53 [main] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-bf2d7a64 in namespace infra-namespace
2022-04-06 06:56:53 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-883316535-1910966124 in namespace infra-namespace
2022-04-06 06:57:03 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:57:03 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testClientScopeKafkaSetCorrectly-FINISHED
2022-04-06 06:57:03 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:57:03 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:57:03 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testClientScopeKafkaSetIncorrectly-STARTED
2022-04-06 06:57:03 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:57:03 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 06:57:03 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 1 Pod(s) of oauth-cluster-scope-name-kafka to be ready
2022-04-06 06:57:48 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-scope-name will have desired state: Ready
2022-04-06 06:57:48 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-scope-name is in desired state: Ready
2022-04-06 06:57:48 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: oauth-cluster-scope-name is ready
2022-04-06 06:57:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1377654310-138732411 in namespace infra-namespace
2022-04-06 06:57:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1377654310-138732411 will have desired state: Ready
2022-04-06 06:57:49 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1377654310-138732411 is in desired state: Ready
2022-04-06 06:57:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-344d6ca6 in namespace infra-namespace
2022-04-06 06:57:49 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-344d6ca6 will be in active state
2022-04-06 06:57:50 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:oauth-producer-my-cluster-344d6ca6 to finish with failure.
2022-04-06 07:01:30 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
io.strimzi.test.WaitException: Timeout after 220000 ms waiting for Job did not finish within time limit (as expected).
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientTimeout(ClientUtils.java:91)
	at io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testClientScopeKafkaSetIncorrectly(OauthScopeIsolatedST.java:224)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-06 07:01:30 [main] [32mINFO [m [ClientUtils:100] Client job 'oauth-producer-my-cluster-344d6ca6' finished with expected timeout.
2022-04-06 07:01:35 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 1 Pod(s) of oauth-cluster-scope-name-kafka to be ready
2022-04-06 07:02:17 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-scope-name will have desired state: Ready
2022-04-06 07:02:17 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-scope-name is in desired state: Ready
2022-04-06 07:02:17 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: oauth-cluster-scope-name is ready
2022-04-06 07:02:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 07:02:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testClientScopeKafkaSetIncorrectly
2022-04-06 07:02:17 [main] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-344d6ca6 in namespace infra-namespace
2022-04-06 07:02:17 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1377654310-138732411 in namespace infra-namespace
2022-04-06 07:02:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 07:02:27 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testClientScopeKafkaSetIncorrectly-FINISHED
2022-04-06 07:02:27 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 07:02:27 [main] [32mINFO [m [KeycloakUtils:52] Teardown Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-06 07:02:32 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/teardown_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-06 07:02:32 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 07:02:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 07:02:32 [main] [32mINFO [m [ResourceManager:348] Delete all resources for OauthScopeIsolatedST
2022-04-06 07:02:32 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-scope-name in namespace infra-namespace
2022-04-06 07:02:32 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-06 07:02:42 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 07:02:42 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 07:02:42 [main] [32mINFO [m [ResourceManager:346] In context OauthScopeIsolatedST is everything deleted.
2022-04-06 07:02:42 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 823.902 s - in io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST
2022-04-06 07:02:42 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 07:03:07 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 07:03:07 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 07:03:07 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 07:03:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 07:03:07 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 07:03:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 07:03:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 07:03:07 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 07:03:07 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 07:03:07 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 07:03:07 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 07:03:07 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 07:03:07 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 07:03:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 07:03:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 07:03:07 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 07:03:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 07:03:07 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 07:03:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 07:03:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 07:03:07 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 07:03:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 07:03:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 07:03:07 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 07:03:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 07:03:17 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 07:03:17 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 07:03:17 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 07:03:17 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 07:03:17 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 07:03:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 07:03:32 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 07:03:32 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 07:03:32 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 07:03:32 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 07:03:32 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 07:03:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 07:03:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 07:03:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 07:03:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 07:03:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 07:03:33 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 07:03:33 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 07:03:33 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 07:03:33 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 07:03:33 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 07:03:33 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 07:03:33 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 07:03:33 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 07:03:33 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 07:03:33 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 07:03:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 07:03:33 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 07:03:33 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 07:03:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 07:03:33 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 07:03:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 07:03:33 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 07:03:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 07:03:33 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 07:03:33 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 07:03:33 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 07:03:33 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 07:03:33 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 07:03:33 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 07:03:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 07:03:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 07:03:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 07:03:33 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 07:03:52 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 07:03:52 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 07:04:02 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 07:04:02 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-06 07:04:02 [main] [32mINFO [m [OauthAbstractST:125] Deploying keycloak...
2022-04-06 07:04:02 [main] [32mINFO [m [KeycloakUtils:35] Prepare Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-06 07:05:47 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/prepare_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-06 07:05:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 07:05:47 [main] [32mINFO [m [KeycloakUtils:48] Keycloak in namespace infra-namespace is ready
2022-04-06 07:05:47 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret credential-example-keycloak
2022-04-06 07:05:47 [main] [32mINFO [m [SecretUtils:50] Secret credential-example-keycloak created
2022-04-06 07:05:47 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-producer-secret
2022-04-06 07:05:47 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-consumer-secret
2022-04-06 07:05:47 [main] [32mINFO [m [SecretUtils:70] Creating secret team-a-client-secret
2022-04-06 07:05:47 [main] [32mINFO [m [SecretUtils:70] Creating secret team-b-client-secret
2022-04-06 07:05:47 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-broker-secret
2022-04-06 07:05:47 [main] [32mINFO [m [SecretUtils:70] Creating secret my-connect-oauth
2022-04-06 07:05:47 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-oauth
2022-04-06 07:05:47 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-2-oauth
2022-04-06 07:05:47 [main] [32mINFO [m [SecretUtils:70] Creating secret my-bridge-oauth
2022-04-06 07:05:47 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-audience-secret
2022-04-06 07:05:47 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-client-secret
2022-04-06 07:05:47 [main] [32mINFO [m [KeycloakInstance:50] Replacing validIssuerUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal to pointing to internal realm
2022-04-06 07:05:47 [main] [32mINFO [m [KeycloakInstance:51] Replacing jwksEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/certs to pointing to internal realm
2022-04-06 07:05:47 [main] [32mINFO [m [KeycloakInstance:52] Replacing oauthTokenEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token to pointing to internal realm
2022-04-06 07:05:47 [main] [32mINFO [m [KeycloakInstance:55] Using HTTPS endpoints
2022-04-06 07:05:47 [main] [32mINFO [m [OauthTlsIsolatedST:480] Keycloak settings KeycloakInstance{jwksExpireSeconds=500, jwksRefreshSeconds=400, username='admin', password='luseUWtjLYyxFA==', httpsUri='keycloak.infra-namespace.svc.cluster.local:8443', httpUri='keycloak-discovery.infra-namespace.svc.cluster.local:8080', validIssuerUri='https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal', jwksEndpointUri='https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/certs', oauthTokenEndpointUri='https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token', introspectionEndpointUri='https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token/introspect', userNameClaim='preferred_username', keystorePattern=<tls>\s*<key-stores>\s*<key-store name="kcKeyStore">\s*<credential-reference clear-text=".*"\/>, keystorePasswordPattern=\".*\"}
2022-04-06 07:05:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-tls-name in namespace infra-namespace
2022-04-06 07:05:47 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-tls-name will have desired state: Ready
2022-04-06 07:06:59 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-tls-name is in desired state: Ready
2022-04-06 07:06:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser hello-world-producer in namespace infra-namespace
2022-04-06 07:06:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: hello-world-producer will have desired state: Ready
2022-04-06 07:07:00 [main] [32mINFO [m [ResourceManager:444] KafkaUser: hello-world-producer is in desired state: Ready
2022-04-06 07:07:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 07:07:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testProducerConsumerBridge-STARTED
2022-04-06 07:07:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 07:07:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1648007244-2061981748 in namespace infra-namespace
2022-04-06 07:07:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1648007244-2061981748 will have desired state: Ready
2022-04-06 07:07:01 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1648007244-2061981748 is in desired state: Ready
2022-04-06 07:07:01 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 07:07:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-c9bee9e5 in namespace infra-namespace
2022-04-06 07:07:01 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-c9bee9e5 will be in active state
2022-04-06 07:07:02 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-c9bee9e5 to finished
2022-04-06 07:07:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-c9bee9e5 in namespace infra-namespace
2022-04-06 07:07:10 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-c9bee9e5 will be in active state
2022-04-06 07:07:11 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-c9bee9e5 to finished
2022-04-06 07:07:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-c9bee9e5-kafka-clients in namespace infra-namespace
2022-04-06 07:07:23 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c9bee9e5-kafka-clients will be ready
2022-04-06 07:07:25 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c9bee9e5-kafka-clients is ready
2022-04-06 07:07:25 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge oauth-cluster-tls-name in namespace infra-namespace
2022-04-06 07:07:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: oauth-cluster-tls-name will have desired state: Ready
2022-04-06 07:07:43 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: oauth-cluster-tls-name is in desired state: Ready
2022-04-06 07:07:43 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 07:07:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Job bridge-producer-my-cluster-c9bee9e5 in namespace infra-namespace
2022-04-06 07:07:43 [main] [32mINFO [m [JobUtils:81] Waiting for job: bridge-producer-my-cluster-c9bee9e5 will be in active state
2022-04-06 07:07:44 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:bridge-producer-my-cluster-c9bee9e5 to finished
2022-04-06 07:08:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 07:08:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerBridge
2022-04-06 07:08:02 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-c9bee9e5-kafka-clients in namespace infra-namespace
2022-04-06 07:08:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge oauth-cluster-tls-name in namespace infra-namespace
2022-04-06 07:08:02 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job bridge-producer-my-cluster-c9bee9e5 in namespace infra-namespace
2022-04-06 07:08:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1648007244-2061981748 in namespace infra-namespace
2022-04-06 07:08:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-c9bee9e5 in namespace infra-namespace
2022-04-06 07:08:02 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-c9bee9e5 in namespace infra-namespace
2022-04-06 07:08:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 07:08:52 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testProducerConsumerBridge-FINISHED
2022-04-06 07:08:52 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 07:08:52 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 07:08:52 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testProducerConsumer-STARTED
2022-04-06 07:08:52 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 07:08:52 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1561516293-1639988015 in namespace infra-namespace
2022-04-06 07:08:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1561516293-1639988015 will have desired state: Ready
2022-04-06 07:08:54 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1561516293-1639988015 is in desired state: Ready
2022-04-06 07:08:54 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 07:08:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-5b461113 in namespace infra-namespace
2022-04-06 07:08:54 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-5b461113 will be in active state
2022-04-06 07:08:55 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-5b461113 to finished
2022-04-06 07:09:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-5b461113 in namespace infra-namespace
2022-04-06 07:09:03 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-5b461113 will be in active state
2022-04-06 07:09:04 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-5b461113 to finished
2022-04-06 07:09:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 07:09:15 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumer
2022-04-06 07:09:15 [main] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-5b461113 in namespace infra-namespace
2022-04-06 07:09:15 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1561516293-1639988015 in namespace infra-namespace
2022-04-06 07:09:15 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-5b461113 in namespace infra-namespace
2022-04-06 07:09:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 07:09:25 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testProducerConsumer-FINISHED
2022-04-06 07:09:25 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 07:09:25 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 07:09:25 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testIntrospectionEndpoint-STARTED
2022-04-06 07:09:25 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 07:09:25 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1979933548-25569211 in namespace infra-namespace
2022-04-06 07:09:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1979933548-25569211 will have desired state: Ready
2022-04-06 07:09:26 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1979933548-25569211 is in desired state: Ready
2022-04-06 07:09:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-tls-name-intro in namespace infra-namespace
2022-04-06 07:09:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-tls-name-intro will have desired state: Ready
2022-04-06 07:10:36 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-tls-name-intro is in desired state: Ready
2022-04-06 07:10:36 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 07:10:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-818f613a in namespace infra-namespace
2022-04-06 07:10:36 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-818f613a will be in active state
2022-04-06 07:10:37 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-818f613a to finished
2022-04-06 07:10:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-818f613a in namespace infra-namespace
2022-04-06 07:10:46 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-818f613a will be in active state
2022-04-06 07:10:47 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-818f613a to finished
2022-04-06 07:10:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 07:10:59 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testIntrospectionEndpoint
2022-04-06 07:10:59 [main] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-818f613a in namespace infra-namespace
2022-04-06 07:10:59 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-tls-name-intro in namespace infra-namespace
2022-04-06 07:10:59 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1979933548-25569211 in namespace infra-namespace
2022-04-06 07:10:59 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-818f613a in namespace infra-namespace
2022-04-06 07:11:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 07:11:09 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testIntrospectionEndpoint-FINISHED
2022-04-06 07:11:09 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 07:11:09 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 07:11:09 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testProducerConsumerConnect-STARTED
2022-04-06 07:11:09 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 07:11:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1671537982-163223235 in namespace infra-namespace
2022-04-06 07:11:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1671537982-163223235 will have desired state: Ready
2022-04-06 07:11:10 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1671537982-163223235 is in desired state: Ready
2022-04-06 07:11:10 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 07:11:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-94c77348 in namespace infra-namespace
2022-04-06 07:11:10 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-94c77348 will be in active state
2022-04-06 07:11:11 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-94c77348 to finished
2022-04-06 07:11:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-94c77348 in namespace infra-namespace
2022-04-06 07:11:19 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-94c77348 will be in active state
2022-04-06 07:11:20 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-94c77348 to finished
2022-04-06 07:11:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment oauth-cluster-tls-name-kafka-clients in namespace infra-namespace
2022-04-06 07:11:31 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: oauth-cluster-tls-name-kafka-clients will be ready
2022-04-06 07:11:33 [main] [32mINFO [m [DeploymentUtils:168] Deployment: oauth-cluster-tls-name-kafka-clients is ready
2022-04-06 07:11:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-94c77348-scraper in namespace infra-namespace
2022-04-06 07:11:33 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-94c77348-scraper will be ready
2022-04-06 07:11:35 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-94c77348-scraper is ready
2022-04-06 07:11:35 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-94c77348-scraper to be ready
2022-04-06 07:11:45 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-94c77348-scraper is ready
2022-04-06 07:11:45 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-94c77348-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 07:11:45 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-94c77348-allow in namespace infra-namespace
2022-04-06 07:11:45 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 07:11:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-94c77348 in namespace infra-namespace
2022-04-06 07:11:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-94c77348 will have desired state: Ready
2022-04-06 07:12:56 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-94c77348 is in desired state: Ready
2022-04-06 07:12:56 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-06 07:12:56 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-94c77348-connect-65bcc5bbbf-7b2bl -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-06 07:12:56 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 07:12:56 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-06 07:12:56 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec oauth-cluster-tls-name-kafka-clients-8cb45f87d-b8fjw -- /bin/bash -c curl -X POST -H "Content-Type: application/json" --data '{ "name": "sink-test", "config": { "connector.class": "FileStreamSink", "tasks.max": "1", "topics": "my-topic-1671537982-163223235", "file": "/tmp/test-file-sink.txt" } }' http://my-cluster-94c77348-connect-api.infra-namespace.svc:8083/connectors
2022-04-06 07:12:56 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 07:12:56 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-94c77348-connect-65bcc5bbbf-7b2bl
2022-04-06 07:13:00 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-94c77348-connect-65bcc5bbbf-7b2bl
2022-04-06 07:13:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 07:13:00 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerConnect
2022-04-06 07:13:00 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-94c77348-scraper in namespace infra-namespace
2022-04-06 07:13:00 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment oauth-cluster-tls-name-kafka-clients in namespace infra-namespace
2022-04-06 07:13:00 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-94c77348 in namespace infra-namespace
2022-04-06 07:13:00 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-94c77348 in namespace infra-namespace
2022-04-06 07:13:00 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1671537982-163223235 in namespace infra-namespace
2022-04-06 07:13:00 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-94c77348-allow in namespace infra-namespace
2022-04-06 07:13:00 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-94c77348 in namespace infra-namespace
2022-04-06 07:13:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 07:13:50 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testProducerConsumerConnect-FINISHED
2022-04-06 07:13:50 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 07:13:50 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 07:13:50 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testMirrorMaker-STARTED
2022-04-06 07:13:50 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 07:13:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1642160496-927382271 in namespace infra-namespace
2022-04-06 07:13:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1642160496-927382271 will have desired state: Ready
2022-04-06 07:13:51 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1642160496-927382271 is in desired state: Ready
2022-04-06 07:13:51 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 07:13:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-c6d36de0 in namespace infra-namespace
2022-04-06 07:13:51 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-c6d36de0 will be in active state
2022-04-06 07:13:52 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-c6d36de0 to finished
2022-04-06 07:14:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-c6d36de0 in namespace infra-namespace
2022-04-06 07:14:00 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-c6d36de0 will be in active state
2022-04-06 07:14:01 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-c6d36de0 to finished
2022-04-06 07:14:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-tls-name-target in namespace infra-namespace
2022-04-06 07:14:12 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-tls-name-target will have desired state: Ready
2022-04-06 07:15:27 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-tls-name-target is in desired state: Ready
2022-04-06 07:15:27 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker oauth-cluster-tls-name in namespace infra-namespace
2022-04-06 07:15:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: oauth-cluster-tls-name will have desired state: Ready
2022-04-06 07:16:33 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: oauth-cluster-tls-name is in desired state: Ready
2022-04-06 07:16:33 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-2091517169-1695277953 in namespace infra-namespace
2022-04-06 07:16:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-2091517169-1695277953 will have desired state: Ready
2022-04-06 07:16:34 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-2091517169-1695277953 is in desired state: Ready
2022-04-06 07:16:34 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret my-user-2091517169-1695277953
2022-04-06 07:16:34 [main] [32mINFO [m [SecretUtils:50] Secret my-user-2091517169-1695277953 created
2022-04-06 07:16:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-2091517169-1695277953 will have desired state: Ready
2022-04-06 07:16:34 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-2091517169-1695277953 is in desired state: Ready
2022-04-06 07:16:34 [main] [32mINFO [m [OauthTlsIsolatedST:390] Creating new client with new consumer-group and also to point on oauth-cluster-tls-name-target cluster
2022-04-06 07:16:34 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 07:16:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-c6d36de0 in namespace infra-namespace
2022-04-06 07:16:34 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-c6d36de0 will be in active state
2022-04-06 07:16:35 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-c6d36de0 to finished
2022-04-06 07:16:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 07:16:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker
2022-04-06 07:16:46 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker oauth-cluster-tls-name in namespace infra-namespace
2022-04-06 07:16:46 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1642160496-927382271 in namespace infra-namespace
2022-04-06 07:16:46 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-2091517169-1695277953 in namespace infra-namespace
2022-04-06 07:16:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-c6d36de0 in namespace infra-namespace
2022-04-06 07:16:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-c6d36de0 in namespace infra-namespace
2022-04-06 07:16:46 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-c6d36de0 in namespace infra-namespace
2022-04-06 07:16:46 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-tls-name-target in namespace infra-namespace
2022-04-06 07:16:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 07:16:56 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testMirrorMaker-FINISHED
2022-04-06 07:16:56 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 07:16:56 [main] [32mINFO [m [KeycloakUtils:52] Teardown Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-06 07:17:00 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/teardown_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-06 07:17:00 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 07:17:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 07:17:00 [main] [32mINFO [m [ResourceManager:348] Delete all resources for OauthTlsIsolatedST
2022-04-06 07:17:00 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-tls-name in namespace infra-namespace
2022-04-06 07:17:00 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-06 07:17:00 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaUser hello-world-producer in namespace infra-namespace
2022-04-06 07:17:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 07:17:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 07:17:10 [main] [32mINFO [m [ResourceManager:346] In context OauthTlsIsolatedST is everything deleted.
2022-04-06 07:17:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 868.687 s - in io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST
2022-04-06 07:17:10 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 07:17:35 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 07:17:35 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 07:17:35 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 07:17:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 07:17:35 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 07:17:35 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 07:17:35 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 07:17:35 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 07:17:35 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 07:17:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 07:17:35 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 07:17:35 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 07:17:35 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 07:17:35 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 07:17:35 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 07:17:35 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 07:17:35 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 07:17:35 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 07:17:35 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 07:17:35 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 07:17:35 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 07:17:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 07:17:36 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 07:17:36 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 07:17:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 07:17:36 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 07:17:36 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 07:17:45 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 07:17:45 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 07:17:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 07:17:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 07:18:01 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=120000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 07:18:01 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 07:18:01 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 07:18:01 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 07:18:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 07:18:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 07:18:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 07:18:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 07:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 07:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 07:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 07:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 07:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 07:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 07:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 07:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 07:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 07:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 07:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 07:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 07:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 07:18:02 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 07:18:02 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 07:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 07:18:02 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 07:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 07:18:02 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 07:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 07:18:02 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 07:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 07:18:02 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 07:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 07:18:02 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 07:18:02 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 07:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 07:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 07:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 07:18:02 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 07:18:35 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 07:18:35 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 07:18:45 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 07:18:45 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 07:18:45 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaRollsWhenTopicIsUnderReplicated-STARTED
2022-04-06 07:18:45 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 07:18:45 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-98 for test case:testKafkaRollsWhenTopicIsUnderReplicated
2022-04-06 07:18:45 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-98
2022-04-06 07:18:45 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-98
2022-04-06 07:18:45 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-98
2022-04-06 07:18:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7f4f6266 in namespace namespace-98
2022-04-06 07:18:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-98
2022-04-06 07:18:45 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7f4f6266 will have desired state: Ready
2022-04-06 07:21:13 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7f4f6266 is in desired state: Ready
2022-04-06 07:21:13 [main] [32mINFO [m [KafkaRollerIsolatedST:105] Running kafkaScaleUpScaleDown my-cluster-7f4f6266
2022-04-06 07:21:13 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-7f4f6266-kafka rolling update
2022-04-06 07:22:38 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-7f4f6266-kafka has been successfully rolled
2022-04-06 07:22:38 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 4 Pod(s) of my-cluster-7f4f6266-kafka to be ready
2022-04-06 07:23:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7f4f6266 will have desired state: Ready
2022-04-06 07:23:26 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7f4f6266 is in desired state: Ready
2022-04-06 07:23:26 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-7f4f6266 is ready
2022-04-06 07:23:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1246704211-55172495 in namespace namespace-98
2022-04-06 07:23:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-98
2022-04-06 07:23:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1246704211-55172495 will have desired state: Ready
2022-04-06 07:23:27 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1246704211-55172495 is in desired state: Ready
2022-04-06 07:23:27 [main] [32mINFO [m [KafkaRollerIsolatedST:124] Scaling down to 3
2022-04-06 07:23:27 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-7f4f6266-kafka rolling update
2022-04-06 07:24:57 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-7f4f6266-kafka has been successfully rolled
2022-04-06 07:24:57 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-7f4f6266-kafka to be ready
2022-04-06 07:25:28 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7f4f6266 will have desired state: Ready
2022-04-06 07:25:28 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7f4f6266 is in desired state: Ready
2022-04-06 07:25:28 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-7f4f6266 is ready
2022-04-06 07:25:28 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-7f4f6266 are stable
2022-04-06 07:25:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 07:25:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 07:25:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 07:25:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 07:25:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 07:25:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 07:25:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 07:25:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 07:25:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 07:25:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 07:25:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 07:25:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 07:25:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 07:25:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 07:25:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 07:25:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 07:25:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 07:25:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 07:25:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 07:25:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 07:25:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 07:25:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 07:25:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 07:25:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 07:25:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 07:25:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 07:25:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 07:25:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 07:25:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 07:25:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 07:25:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 07:25:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 07:25:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 07:25:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 07:25:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 07:25:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 07:25:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 07:25:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 07:25:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 07:25:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 07:25:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 07:25:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 07:25:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 07:25:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 07:25:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 07:25:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 07:25:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 07:25:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 07:25:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 07:25:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 07:25:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 07:25:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 07:25:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 07:25:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 07:25:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 07:25:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 07:25:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 07:25:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 07:25:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 07:25:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 07:25:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 07:25:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 07:25:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 07:25:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 07:25:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 07:25:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 07:25:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 07:25:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 07:25:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 07:25:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 07:25:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 07:25:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 07:25:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 07:25:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 07:25:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 07:25:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 07:25:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 07:25:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 07:25:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 07:25:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 07:25:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 07:25:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 07:25:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 07:25:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 07:25:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 07:25:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 07:25:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 07:25:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 07:25:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 07:25:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 07:25:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 07:25:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 07:25:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 07:25:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 07:25:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 07:25:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 07:25:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 07:25:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 07:25:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 07:25:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 07:25:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 07:25:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 07:25:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 07:25:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 07:25:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 07:25:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 07:25:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 07:25:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 07:25:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 07:25:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 07:25:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 07:25:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 07:25:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 07:25:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 07:25:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 07:25:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 07:25:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 07:25:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 07:25:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 07:25:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 07:25:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 07:25:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 07:25:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 07:25:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 07:25:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 07:25:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 07:25:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 07:25:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 07:25:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 07:25:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 07:25:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 07:25:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 07:25:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 07:25:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 07:25:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 07:25:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 07:25:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 07:25:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 07:25:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 07:25:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 07:25:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 07:25:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 07:25:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 07:25:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 07:25:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 07:25:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 07:25:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 07:25:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 07:25:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 07:25:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 07:25:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 07:25:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 07:25:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 07:25:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 07:25:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 07:25:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 07:25:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 07:25:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 07:25:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 07:25:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 07:25:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 07:25:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 07:25:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 07:25:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 07:25:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 07:25:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 07:25:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 07:25:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 07:25:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 07:25:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 07:25:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 07:25:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 07:25:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 07:25:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 07:25:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 07:25:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 07:25:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 07:25:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 07:25:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 07:25:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 07:25:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 07:25:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 07:25:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 07:25:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 07:25:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 07:25:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 07:25:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 07:25:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 07:25:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 07:25:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 07:25:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 07:25:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 07:25:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 07:25:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 07:25:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 07:25:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 07:25:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 07:25:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 07:25:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 07:25:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 07:25:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 07:25:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 07:25:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 07:25:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 07:25:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 07:25:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 07:25:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 07:25:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 07:25:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 07:25:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 07:25:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 07:25:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 07:25:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 07:25:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 07:25:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 07:25:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 07:25:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 07:26:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 07:26:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 07:26:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 07:26:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 07:26:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 07:26:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 07:26:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 07:26:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 07:26:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 07:26:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 07:26:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 07:26:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 07:26:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 07:26:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 07:26:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 07:26:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 07:26:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 07:26:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 07:26:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 07:26:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 07:26:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 07:26:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 07:26:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 07:26:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 07:26:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 07:26:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 07:26:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 07:26:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 07:26:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 07:26:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 07:26:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 07:26:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 07:26:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 07:26:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 07:26:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 07:26:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 07:26:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 07:26:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 07:26:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 07:26:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 07:26:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 07:26:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 07:26:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 07:26:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 07:26:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 07:26:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 07:26:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 07:26:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 07:26:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 07:26:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 07:26:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 07:26:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 07:26:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 07:26:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 07:26:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 07:26:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 07:26:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 07:26:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 07:26:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 07:26:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 07:26:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 07:26:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 07:26:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 07:26:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 07:26:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 07:26:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 07:26:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 07:26:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 07:26:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 07:26:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 07:26:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 07:26:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 07:26:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 07:26:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 07:26:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 07:26:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 07:26:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 07:26:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 07:26:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 07:26:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 07:26:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 07:26:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 07:26:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 07:26:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 07:26:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 07:26:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 07:26:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 07:26:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 07:26:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 07:26:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 07:26:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 07:26:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 07:26:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 07:26:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 07:26:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 07:26:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 07:26:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 07:26:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 07:26:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 07:26:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 07:26:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 07:26:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 07:26:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 07:26:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 07:26:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 07:26:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 07:26:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 07:26:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 07:26:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 07:26:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 07:26:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 07:26:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 07:26:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 07:26:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 07:26:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 07:26:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 07:26:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 07:26:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 07:26:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 07:26:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 07:26:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 07:26:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 07:26:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 07:26:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 07:26:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 07:26:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 07:26:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 07:26:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 07:26:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 07:26:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 07:26:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 07:26:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 07:26:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-7f4f6266-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 07:26:18 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-7f4f6266-entity-operator-5885dd44cd-c6zpj ,my-cluster-7f4f6266-kafka-0 ,my-cluster-7f4f6266-kafka-1 ,my-cluster-7f4f6266-kafka-2 ,my-cluster-7f4f6266-zookeeper-0 ,my-cluster-7f4f6266-zookeeper-1 ,my-cluster-7f4f6266-zookeeper-2
2022-04-06 07:26:18 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-7f4f6266-kafka rolling update
2022-04-06 07:27:58 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-7f4f6266-kafka has been successfully rolled
2022-04-06 07:27:58 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-7f4f6266-kafka to be ready
2022-04-06 07:28:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7f4f6266 will have desired state: Ready
2022-04-06 07:28:24 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7f4f6266 is in desired state: Ready
2022-04-06 07:28:24 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-7f4f6266 is ready
2022-04-06 07:28:24 [main] [32mINFO [m [AbstractST:478] Search in strimzi-cluster-operator log for errors in last 579 seconds
2022-04-06 07:28:25 [main] [32mINFO [m [BaseCmdKubeClient:481] Exception not found
2022-04-06 07:28:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 07:28:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaRollsWhenTopicIsUnderReplicated
2022-04-06 07:28:25 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1246704211-55172495 in namespace namespace-98
2022-04-06 07:28:25 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7f4f6266 in namespace namespace-98
2022-04-06 07:28:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 07:28:35 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-98 for test case:testKafkaRollsWhenTopicIsUnderReplicated
2022-04-06 07:29:02 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaRollsWhenTopicIsUnderReplicated-FINISHED
2022-04-06 07:29:02 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 07:29:02 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 07:29:02 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodPendingDueToRack-STARTED
2022-04-06 07:29:02 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 07:29:02 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-99 for test case:testKafkaPodPendingDueToRack
2022-04-06 07:29:02 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-99
2022-04-06 07:29:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-99
2022-04-06 07:29:02 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-99
2022-04-06 07:29:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-eab8a917 in namespace namespace-99
2022-04-06 07:29:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-99
2022-04-06 07:29:02 [main] [32mINFO [m [PodUtils:209] Wait until Pod my-cluster-eab8a917-kafka will have stable 3 replicas
2022-04-06 07:29:02 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:03 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:04 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:05 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:06 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:07 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:08 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:09 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:10 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:11 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:12 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:13 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:14 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:15 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:16 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:17 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:18 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:19 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:20 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:21 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:22 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:23 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:24 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:25 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:26 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:27 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:28 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:29 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:30 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:31 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:32 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:29:33 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 19 polls
2022-04-06 07:29:34 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 18 polls
2022-04-06 07:29:35 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 17 polls
2022-04-06 07:29:36 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 16 polls
2022-04-06 07:29:37 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 15 polls
2022-04-06 07:29:38 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 14 polls
2022-04-06 07:29:39 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 13 polls
2022-04-06 07:29:40 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 12 polls
2022-04-06 07:29:41 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 11 polls
2022-04-06 07:29:42 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 10 polls
2022-04-06 07:29:43 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 9 polls
2022-04-06 07:29:44 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 8 polls
2022-04-06 07:29:45 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 7 polls
2022-04-06 07:29:46 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 6 polls
2022-04-06 07:29:47 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 5 polls
2022-04-06 07:29:48 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 4 polls
2022-04-06 07:29:49 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 3 polls
2022-04-06 07:29:50 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 2 polls
2022-04-06 07:29:51 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 1 polls
2022-04-06 07:29:52 [main] [32mINFO [m [PodUtils:217] Pod replicas are stable for 20 polls intervals
2022-04-06 07:29:52 [main] [32mINFO [m [PodUtils:228] Pod my-cluster-eab8a917-kafka has 3 replicas
2022-04-06 07:29:52 [main] [32mINFO [m [KafkaRollerIsolatedST:309] Removing requirement for the affinity
2022-04-06 07:29:52 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-eab8a917 will have desired state: Ready
2022-04-06 07:33:35 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-eab8a917 is in desired state: Ready
2022-04-06 07:33:35 [main] [32mINFO [m [KafkaUtils:399] Waiting for deletion of Kafka:my-cluster-eab8a917
2022-04-06 07:33:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 07:33:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaPodPendingDueToRack
2022-04-06 07:33:38 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-eab8a917 in namespace namespace-99
2022-04-06 07:33:38 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 07:33:38 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-99 for test case:testKafkaPodPendingDueToRack
2022-04-06 07:34:21 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodPendingDueToRack-FINISHED
2022-04-06 07:34:21 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 07:34:21 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 07:34:21 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodImagePullBackOff-STARTED
2022-04-06 07:34:21 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 07:34:21 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-100 for test case:testKafkaPodImagePullBackOff
2022-04-06 07:34:21 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-100
2022-04-06 07:34:21 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-100
2022-04-06 07:34:21 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-100
2022-04-06 07:34:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-958f1050 in namespace namespace-100
2022-04-06 07:34:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-100
2022-04-06 07:34:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-958f1050 will have desired state: Ready
2022-04-06 07:35:41 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-958f1050 is in desired state: Ready
2022-04-06 07:35:41 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-958f1050 will have desired state: NotReady
2022-04-06 07:37:51 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-958f1050 is in desired state: NotReady
2022-04-06 07:37:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-958f1050 will have desired state: Ready
2022-04-06 07:42:40 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-958f1050 is in desired state: Ready
2022-04-06 07:42:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 07:42:40 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaPodImagePullBackOff
2022-04-06 07:42:40 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-958f1050 in namespace namespace-100
2022-04-06 07:42:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 07:42:50 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-100 for test case:testKafkaPodImagePullBackOff
2022-04-06 07:43:33 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodImagePullBackOff-FINISHED
2022-04-06 07:43:33 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 07:43:33 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 07:43:33 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodPending-STARTED
2022-04-06 07:43:33 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 07:43:33 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-101 for test case:testKafkaPodPending
2022-04-06 07:43:33 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-101
2022-04-06 07:43:33 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-101
2022-04-06 07:43:33 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-101
2022-04-06 07:43:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e35c0fae in namespace namespace-101
2022-04-06 07:43:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-101
2022-04-06 07:43:33 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e35c0fae will have desired state: Ready
2022-04-06 07:45:18 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e35c0fae is in desired state: Ready
2022-04-06 07:45:18 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e35c0fae will have desired state: NotReady
2022-04-06 07:47:26 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e35c0fae is in desired state: NotReady
2022-04-06 07:47:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e35c0fae will have desired state: Ready
2022-04-06 07:49:26 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e35c0fae is in desired state: Ready
2022-04-06 07:49:26 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 07:49:26 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaPodPending
2022-04-06 07:49:26 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e35c0fae in namespace namespace-101
2022-04-06 07:49:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 07:49:36 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-101 for test case:testKafkaPodPending
2022-04-06 07:50:20 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodPending-FINISHED
2022-04-06 07:50:20 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 07:50:20 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 07:50:20 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaTopicRFLowerThanMinInSyncReplicas-STARTED
2022-04-06 07:50:20 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 07:50:20 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-102 for test case:testKafkaTopicRFLowerThanMinInSyncReplicas
2022-04-06 07:50:20 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-102
2022-04-06 07:50:20 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-102
2022-04-06 07:50:20 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-102
2022-04-06 07:50:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1be69518 in namespace namespace-102
2022-04-06 07:50:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-102
2022-04-06 07:50:20 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1be69518 will have desired state: Ready
2022-04-06 07:51:41 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1be69518 is in desired state: Ready
2022-04-06 07:51:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-413306423-731188856 in namespace namespace-102
2022-04-06 07:51:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-102
2022-04-06 07:51:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-413306423-731188856 will have desired state: Ready
2022-04-06 07:51:42 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-413306423-731188856 is in desired state: Ready
2022-04-06 07:51:42 [main] [32mINFO [m [KafkaRollerIsolatedST:155] Setting KafkaTopic's min.insync.replicas to be higher than replication factor
2022-04-06 07:51:42 [main] [32mINFO [m [KafkaRollerIsolatedST:159] Annotate Kafka StatefulSet my-cluster-1be69518-kafka with manual rolling update annotation
2022-04-06 07:51:42 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-1be69518-kafka rolling update
2022-04-06 07:52:57 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-1be69518-kafka has been successfully rolled
2022-04-06 07:52:57 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-1be69518-kafka to be ready
2022-04-06 07:53:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1be69518 will have desired state: Ready
2022-04-06 07:53:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1be69518 is in desired state: Ready
2022-04-06 07:53:21 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-1be69518 is ready
2022-04-06 07:53:21 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 07:53:21 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaTopicRFLowerThanMinInSyncReplicas
2022-04-06 07:53:21 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-413306423-731188856 in namespace namespace-102
2022-04-06 07:53:21 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1be69518 in namespace namespace-102
2022-04-06 07:53:31 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 07:53:31 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-102 for test case:testKafkaTopicRFLowerThanMinInSyncReplicas
2022-04-06 07:54:14 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaTopicRFLowerThanMinInSyncReplicas-FINISHED
2022-04-06 07:54:14 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 07:54:14 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 07:54:14 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodCrashLooping-STARTED
2022-04-06 07:54:14 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 07:54:14 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-103 for test case:testKafkaPodCrashLooping
2022-04-06 07:54:14 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-103
2022-04-06 07:54:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-103
2022-04-06 07:54:15 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-103
2022-04-06 07:54:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-49acd4c4 in namespace namespace-103
2022-04-06 07:54:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-103
2022-04-06 07:54:15 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-49acd4c4 will have desired state: Ready
2022-04-06 07:56:14 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-49acd4c4 is in desired state: Ready
2022-04-06 07:56:14 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-49acd4c4 will have desired state: NotReady
2022-04-06 07:58:22 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-49acd4c4 is in desired state: NotReady
2022-04-06 07:58:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-49acd4c4 will have desired state: Ready
2022-04-06 08:03:01 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-49acd4c4 is in desired state: Ready
2022-04-06 08:03:01 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:03:01 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaPodCrashLooping
2022-04-06 08:03:01 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-49acd4c4 in namespace namespace-103
2022-04-06 08:03:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:03:11 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-103 for test case:testKafkaPodCrashLooping
2022-04-06 08:03:55 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodCrashLooping-FINISHED
2022-04-06 08:03:55 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 08:03:55 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:03:55 [main] [32mINFO [m [ResourceManager:346] In context KafkaRollerIsolatedST is everything deleted.
2022-04-06 08:03:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2,804.211 s - in io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.connect.ConnectIsolatedST
2022-04-06 08:03:55 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 08:04:20 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 08:04:20 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 08:04:20 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 08:04:20 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:04:20 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 08:04:20 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 08:04:20 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 08:04:20 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 08:04:20 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 08:04:20 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 08:04:20 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 08:04:20 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 08:04:20 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 08:04:20 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 08:04:20 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 08:04:20 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 08:04:20 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 08:04:20 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 08:04:20 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 08:04:20 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 08:04:20 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 08:04:20 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 08:04:20 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 08:04:20 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 08:04:20 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 08:04:20 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 08:04:20 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 08:04:30 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 08:04:30 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 08:04:30 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 08:04:40 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:04:45 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 08:04:45 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 08:04:45 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 08:04:45 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 08:04:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 08:04:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 08:04:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 08:04:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 08:04:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 08:04:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 08:04:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 08:04:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 08:04:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 08:04:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 08:04:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 08:04:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 08:04:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 08:04:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 08:04:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 08:04:46 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 08:04:46 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 08:04:46 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 08:04:46 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 08:04:46 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 08:04:46 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 08:04:46 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 08:04:46 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 08:04:46 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 08:04:46 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 08:04:46 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 08:04:46 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 08:04:46 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 08:04:46 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 08:04:46 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 08:04:46 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 08:04:46 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 08:04:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 08:04:46 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 08:05:32 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 08:05:32 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 08:05:42 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 08:05:42 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 08:05:42 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testMultiNodeKafkaConnectWithConnectorCreation-STARTED
2022-04-06 08:05:42 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 08:05:42 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-104 for test case:testMultiNodeKafkaConnectWithConnectorCreation
2022-04-06 08:05:42 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-104
2022-04-06 08:05:42 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-104
2022-04-06 08:05:42 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-104
2022-04-06 08:05:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5e670092 in namespace namespace-104
2022-04-06 08:05:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-06 08:05:42 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5e670092 will have desired state: Ready
2022-04-06 08:07:07 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5e670092 is in desired state: Ready
2022-04-06 08:07:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-5e670092-scraper in namespace namespace-104
2022-04-06 08:07:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-06 08:07:07 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-5e670092-scraper will be ready
2022-04-06 08:07:09 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-5e670092-scraper is ready
2022-04-06 08:07:09 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-5e670092-scraper to be ready
2022-04-06 08:07:19 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-5e670092-scraper is ready
2022-04-06 08:07:19 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-5e670092-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 08:07:19 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-5e670092-allow in namespace namespace-104
2022-04-06 08:07:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-06 08:07:19 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 08:07:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-5e670092 in namespace namespace-104
2022-04-06 08:07:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-06 08:07:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-5e670092 will have desired state: Ready
2022-04-06 08:08:30 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-5e670092 is in desired state: Ready
2022-04-06 08:08:30 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-5e670092 in namespace namespace-104
2022-04-06 08:08:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-06 08:08:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-5e670092 will have desired state: Ready
2022-04-06 08:08:31 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-5e670092 is in desired state: Ready
2022-04-06 08:08:31 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 08:08:31 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-104 exec my-cluster-5e670092-connect-66bff7587d-d2x7h -- curl -X GET http://localhost:8083/connectors/my-cluster-5e670092/status
2022-04-06 08:08:31 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:08:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-5e670092-hello-world-producer in namespace namespace-104
2022-04-06 08:08:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-06 08:08:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-5e670092-hello-world-consumer in namespace namespace-104
2022-04-06 08:08:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-06 08:08:31 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-5e670092-hello-world-producer will be in active state
2022-04-06 08:08:32 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-5e670092-hello-world-consumer will be in active state
2022-04-06 08:08:32 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-5e670092-hello-world-producer and consumer my-cluster-5e670092-hello-world-consumer finish
2022-04-06 08:08:48 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-5e670092-connect-66bff7587d-jkrj9
2022-04-06 08:08:48 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-5e670092-connect-66bff7587d-jkrj9
2022-04-06 08:08:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:08:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMultiNodeKafkaConnectWithConnectorCreation
2022-04-06 08:08:48 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-5e670092 in namespace namespace-104
2022-04-06 08:08:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5e670092 in namespace namespace-104
2022-04-06 08:08:48 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-5e670092 in namespace namespace-104
2022-04-06 08:08:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-5e670092-allow in namespace namespace-104
2022-04-06 08:08:48 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-5e670092-hello-world-consumer in namespace namespace-104
2022-04-06 08:08:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-5e670092-hello-world-producer in namespace namespace-104
2022-04-06 08:08:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-5e670092-scraper in namespace namespace-104
2022-04-06 08:09:38 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:09:38 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-104 for test case:testMultiNodeKafkaConnectWithConnectorCreation
2022-04-06 08:09:44 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testMultiNodeKafkaConnectWithConnectorCreation-FINISHED
2022-04-06 08:09:44 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 08:09:44 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 08:09:44 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectScaleUpScaleDown-STARTED
2022-04-06 08:09:44 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 08:09:44 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-105 for test case:testKafkaConnectScaleUpScaleDown
2022-04-06 08:09:44 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-105
2022-04-06 08:09:44 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-105
2022-04-06 08:09:44 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-105
2022-04-06 08:09:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-503bfc30 in namespace namespace-105
2022-04-06 08:09:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-105
2022-04-06 08:09:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-503bfc30 will have desired state: Ready
2022-04-06 08:11:00 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-503bfc30 is in desired state: Ready
2022-04-06 08:11:00 [main] [32mINFO [m [ConnectIsolatedST:395] Running kafkaConnectScaleUP namespace-105 in namespace
2022-04-06 08:11:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-503bfc30 in namespace namespace-105
2022-04-06 08:11:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-105
2022-04-06 08:11:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-503bfc30 will have desired state: Ready
2022-04-06 08:12:04 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-503bfc30 is in desired state: Ready
2022-04-06 08:12:04 [main] [32mINFO [m [ConnectIsolatedST:407] Scaling up to 4
2022-04-06 08:12:04 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-503bfc30-connect will be ready
2022-04-06 08:12:04 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-503bfc30-connect is ready
2022-04-06 08:12:04 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 4 Pod(s) of Deployment my-cluster-503bfc30-connect to be ready
2022-04-06 08:13:24 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-503bfc30-connect is ready
2022-04-06 08:13:24 [main] [32mINFO [m [ConnectIsolatedST:414] Scaling down to 1
2022-04-06 08:13:24 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-503bfc30-connect will be ready
2022-04-06 08:13:24 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-503bfc30-connect is ready
2022-04-06 08:13:24 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-503bfc30-connect to be ready
2022-04-06 08:13:38 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-503bfc30-connect is ready
2022-04-06 08:13:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:13:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectScaleUpScaleDown
2022-04-06 08:13:38 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-503bfc30 in namespace namespace-105
2022-04-06 08:13:38 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-503bfc30 in namespace namespace-105
2022-04-06 08:13:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:13:48 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-105 for test case:testKafkaConnectScaleUpScaleDown
2022-04-06 08:14:31 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectScaleUpScaleDown-FINISHED
2022-04-06 08:14:31 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 08:14:31 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 08:14:31 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testScaleConnectAndConnectorSubresource-STARTED
2022-04-06 08:14:31 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 08:14:31 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-106 for test case:testScaleConnectAndConnectorSubresource
2022-04-06 08:14:31 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-106
2022-04-06 08:14:31 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-106
2022-04-06 08:14:31 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-106
2022-04-06 08:14:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b8f28688 in namespace namespace-106
2022-04-06 08:14:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-106
2022-04-06 08:14:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b8f28688 will have desired state: Ready
2022-04-06 08:15:49 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b8f28688 is in desired state: Ready
2022-04-06 08:15:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-b8f28688 in namespace namespace-106
2022-04-06 08:15:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-106
2022-04-06 08:15:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-b8f28688 will have desired state: Ready
2022-04-06 08:16:59 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-b8f28688 is in desired state: Ready
2022-04-06 08:16:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-b8f28688 in namespace namespace-106
2022-04-06 08:16:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-106
2022-04-06 08:16:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-b8f28688 will have desired state: Ready
2022-04-06 08:17:00 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-b8f28688 is in desired state: Ready
2022-04-06 08:17:00 [main] [32mINFO [m [ConnectIsolatedST:979] -------> Scaling KafkaConnect subresource <-------
2022-04-06 08:17:00 [main] [32mINFO [m [ConnectIsolatedST:980] Scaling subresource replicas to 4
2022-04-06 08:17:01 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b8f28688-connect will be ready
2022-04-06 08:17:01 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b8f28688-connect is ready
2022-04-06 08:17:01 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 4 Pod(s) of Deployment my-cluster-b8f28688-connect to be ready
2022-04-06 08:18:22 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-b8f28688-connect is ready
2022-04-06 08:18:22 [main] [32mINFO [m [ConnectIsolatedST:984] Check if replicas is set to 4, observed generation is higher - for spec and status - naming prefix should be same
2022-04-06 08:18:22 [main] [32mINFO [m [ConnectIsolatedST:998] -------> Scaling KafkaConnector subresource <-------
2022-04-06 08:18:22 [main] [32mINFO [m [ConnectIsolatedST:999] Scaling subresource task max to 4
2022-04-06 08:18:23 [main] [32mINFO [m [ConnectIsolatedST:1003] Check if taskMax is set to 4
2022-04-06 08:18:23 [main] [32mINFO [m [ConnectIsolatedST:1007] Check taskMax on Connect pods API
2022-04-06 08:18:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-106 exec my-cluster-b8f28688-connect-7c755b7d8-6zlph -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-b8f28688
2022-04-06 08:18:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:18:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-106 exec my-cluster-b8f28688-connect-7c755b7d8-gw2ck -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-b8f28688
2022-04-06 08:18:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:18:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-106 exec my-cluster-b8f28688-connect-7c755b7d8-tqfdr -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-b8f28688
2022-04-06 08:18:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:18:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-106 exec my-cluster-b8f28688-connect-7c755b7d8-zxqzm -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-b8f28688
2022-04-06 08:18:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:18:24 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:18:24 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleConnectAndConnectorSubresource
2022-04-06 08:18:24 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-b8f28688 in namespace namespace-106
2022-04-06 08:18:24 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-b8f28688 in namespace namespace-106
2022-04-06 08:18:24 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b8f28688 in namespace namespace-106
2022-04-06 08:18:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:18:34 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-106 for test case:testScaleConnectAndConnectorSubresource
2022-04-06 08:19:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testScaleConnectAndConnectorSubresource-FINISHED
2022-04-06 08:19:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 08:19:17 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 08:19:17 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectAndPausedConnectorWithFileSinkPlugin-STARTED
2022-04-06 08:19:17 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 08:19:17 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-107 for test case:testKafkaConnectAndPausedConnectorWithFileSinkPlugin
2022-04-06 08:19:17 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-107
2022-04-06 08:19:17 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-107
2022-04-06 08:19:17 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-107
2022-04-06 08:19:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-def1b718 in namespace namespace-107
2022-04-06 08:19:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-06 08:19:17 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-def1b718 will have desired state: Ready
2022-04-06 08:20:29 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-def1b718 is in desired state: Ready
2022-04-06 08:20:29 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2100716614-45784393 in namespace namespace-107
2022-04-06 08:20:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-06 08:20:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2100716614-45784393 will have desired state: Ready
2022-04-06 08:20:30 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2100716614-45784393 is in desired state: Ready
2022-04-06 08:20:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-def1b718-scraper in namespace namespace-107
2022-04-06 08:20:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-06 08:20:30 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-def1b718-scraper will be ready
2022-04-06 08:20:32 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-def1b718-scraper is ready
2022-04-06 08:20:32 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-def1b718-scraper to be ready
2022-04-06 08:20:42 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-def1b718-scraper is ready
2022-04-06 08:20:42 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-def1b718-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 08:20:42 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-def1b718-allow in namespace namespace-107
2022-04-06 08:20:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-06 08:20:42 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 08:20:42 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-def1b718 in namespace namespace-107
2022-04-06 08:20:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-06 08:20:42 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-def1b718 will have desired state: Ready
2022-04-06 08:21:45 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-def1b718 is in desired state: Ready
2022-04-06 08:21:45 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-06 08:21:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-107 exec my-cluster-def1b718-connect-5b8568db9c-hxxzx -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-06 08:21:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:21:45 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-06 08:21:45 [main] [32mINFO [m [ConnectIsolatedST:181] Creating KafkaConnector with 'pause: true'
2022-04-06 08:21:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-def1b718 in namespace namespace-107
2022-04-06 08:21:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-06 08:21:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-def1b718 will have desired state: Ready
2022-04-06 08:21:46 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-def1b718 is in desired state: Ready
2022-04-06 08:21:46 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 08:21:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-def1b718-hello-world-producer in namespace namespace-107
2022-04-06 08:21:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-06 08:21:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-def1b718-hello-world-consumer in namespace namespace-107
2022-04-06 08:21:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-06 08:21:46 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-def1b718-hello-world-producer will be in active state
2022-04-06 08:21:47 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-def1b718-hello-world-consumer will be in active state
2022-04-06 08:21:47 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-def1b718-hello-world-producer and consumer my-cluster-def1b718-hello-world-consumer finish
2022-04-06 08:22:03 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-def1b718-connect-5b8568db9c-hxxzx
2022-04-06 08:22:03 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-def1b718-connect-5b8568db9c-hxxzx
2022-04-06 08:22:03 [main] [32mINFO [m [ConnectIsolatedST:207] Pausing KafkaConnector: my-cluster-def1b718
2022-04-06 08:22:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-def1b718 will have desired state: Ready
2022-04-06 08:22:03 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-def1b718 is in desired state: Ready
2022-04-06 08:22:03 [main] [32mINFO [m [ConnectIsolatedST:213] Clearing FileSink file to check if KafkaConnector will be really paused
2022-04-06 08:22:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-107 exec my-cluster-def1b718-connect-5b8568db9c-hxxzx -- /bin/bash -c truncate -s 0 /tmp/test-file-sink.txt
2022-04-06 08:22:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:22:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-def1b718-hello-world-producer in namespace namespace-107
2022-04-06 08:22:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-06 08:22:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-def1b718-hello-world-consumer in namespace namespace-107
2022-04-06 08:22:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-06 08:22:03 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-def1b718-hello-world-producer will be in active state
2022-04-06 08:22:04 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-def1b718-hello-world-consumer will be in active state
2022-04-06 08:22:04 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-def1b718-hello-world-producer and consumer my-cluster-def1b718-hello-world-consumer finish
2022-04-06 08:22:48 [main] [32mINFO [m [ConnectIsolatedST:219] Because KafkaConnector is paused, no messages should appear to FileSink file
2022-04-06 08:22:48 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-def1b718-connect-5b8568db9c-hxxzx
io.strimzi.test.WaitException: Timeout after 60000 ms waiting for messages in file sink
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(KafkaConnectUtils.java:75)
	at io.strimzi.systemtest.connect.ConnectIsolatedST.lambda$testKafkaConnectAndPausedConnectorWithFileSinkPlugin$1(ConnectIsolatedST.java:220)
	at org.junit.jupiter.api.AssertThrows.assertThrows(AssertThrows.java:55)
	at org.junit.jupiter.api.AssertThrows.assertThrows(AssertThrows.java:37)
	at org.junit.jupiter.api.Assertions.assertThrows(Assertions.java:3082)
	at io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectAndPausedConnectorWithFileSinkPlugin(ConnectIsolatedST.java:220)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-06 08:23:48 [main] [32mINFO [m [ConnectIsolatedST:222] Unpausing KafkaConnector, messages should again appear to FileSink file
2022-04-06 08:23:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-def1b718 will have desired state: Ready
2022-04-06 08:23:48 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-def1b718 is in desired state: Ready
2022-04-06 08:23:48 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-def1b718-connect-5b8568db9c-hxxzx
2022-04-06 08:23:48 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-def1b718-connect-5b8568db9c-hxxzx
2022-04-06 08:23:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:23:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectAndPausedConnectorWithFileSinkPlugin
2022-04-06 08:23:48 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-def1b718 in namespace namespace-107
2022-04-06 08:23:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2100716614-45784393 in namespace namespace-107
2022-04-06 08:23:48 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-def1b718-hello-world-producer in namespace namespace-107
2022-04-06 08:23:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-def1b718 in namespace namespace-107
2022-04-06 08:23:48 [main] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-def1b718-hello-world-producer in namespace namespace-107
2022-04-06 08:23:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-def1b718-hello-world-consumer in namespace namespace-107
2022-04-06 08:23:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-def1b718-scraper in namespace namespace-107
2022-04-06 08:23:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-def1b718 in namespace namespace-107
2022-04-06 08:23:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-def1b718-hello-world-consumer in namespace namespace-107
2022-04-06 08:23:48 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-def1b718-allow in namespace namespace-107
2022-04-06 08:24:38 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:24:38 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-107 for test case:testKafkaConnectAndPausedConnectorWithFileSinkPlugin
2022-04-06 08:24:44 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectAndPausedConnectorWithFileSinkPlugin-FINISHED
2022-04-06 08:24:44 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 08:24:44 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 08:24:44 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectWithScramShaAuthenticationRolledAfterPasswordChanged-STARTED
2022-04-06 08:24:44 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 08:24:44 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-108 for test case:testKafkaConnectWithScramShaAuthenticationRolledAfterPasswordChanged
2022-04-06 08:24:44 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-108
2022-04-06 08:24:44 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-108
2022-04-06 08:24:44 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-108
2022-04-06 08:24:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b540bdac in namespace namespace-108
2022-04-06 08:24:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-108
2022-04-06 08:24:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b540bdac will have desired state: Ready
2022-04-06 08:26:05 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b540bdac is in desired state: Ready
2022-04-06 08:26:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1826831890-747942060 in namespace namespace-108
2022-04-06 08:26:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-108
2022-04-06 08:26:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1826831890-747942060 will have desired state: Ready
2022-04-06 08:26:06 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1826831890-747942060 is in desired state: Ready
2022-04-06 08:26:06 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1826831890-747942060 in namespace namespace-108
2022-04-06 08:26:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-108
2022-04-06 08:26:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1826831890-747942060 will have desired state: Ready
2022-04-06 08:26:06 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1826831890-747942060 is in desired state: Ready
2022-04-06 08:26:06 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-457762143-1942938815 in namespace namespace-108
2022-04-06 08:26:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-108
2022-04-06 08:26:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-457762143-1942938815 will have desired state: Ready
2022-04-06 08:26:07 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-457762143-1942938815 is in desired state: Ready
2022-04-06 08:26:07 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-b540bdac in namespace namespace-108
2022-04-06 08:26:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-108
2022-04-06 08:26:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-b540bdac will have desired state: Ready
2022-04-06 08:27:15 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-b540bdac is in desired state: Ready
2022-04-06 08:27:15 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-06 08:27:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-108 exec my-cluster-b540bdac-connect-7f7dcb67d6-p946g -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-06 08:27:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:27:15 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-06 08:27:15 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1826831890-747942060 in namespace namespace-108
2022-04-06 08:27:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-108
2022-04-06 08:27:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1826831890-747942060 will have desired state: Ready
2022-04-06 08:27:15 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1826831890-747942060 is in desired state: Ready
2022-04-06 08:27:15 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-b540bdac-connect rolling update
2022-04-06 08:28:41 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b540bdac-connect will be ready
2022-04-06 08:28:41 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b540bdac-connect is ready
2022-04-06 08:28:51 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-b540bdac-connect rolling update finished
2022-04-06 08:28:51 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-06 08:28:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-108 exec my-cluster-b540bdac-connect-5d7d59686c-x67p5 -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-06 08:28:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:28:51 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-06 08:28:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:28:51 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectWithScramShaAuthenticationRolledAfterPasswordChanged
2022-04-06 08:28:51 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-457762143-1942938815 in namespace namespace-108
2022-04-06 08:28:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-b540bdac in namespace namespace-108
2022-04-06 08:28:51 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1826831890-747942060 in namespace namespace-108
2022-04-06 08:28:51 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b540bdac in namespace namespace-108
2022-04-06 08:28:51 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1826831890-747942060 in namespace namespace-108
2022-04-06 08:28:51 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1826831890-747942060 in namespace namespace-108
2022-04-06 08:29:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:29:01 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-108 for test case:testKafkaConnectWithScramShaAuthenticationRolledAfterPasswordChanged
2022-04-06 08:29:44 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectWithScramShaAuthenticationRolledAfterPasswordChanged-FINISHED
2022-04-06 08:29:44 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 08:29:44 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 08:29:44 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testSecretsWithKafkaConnectWithTlsAndScramShaAuthentication-STARTED
2022-04-06 08:29:44 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 08:29:44 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-109 for test case:testSecretsWithKafkaConnectWithTlsAndScramShaAuthentication
2022-04-06 08:29:44 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-109
2022-04-06 08:29:44 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-109
2022-04-06 08:29:44 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-109
2022-04-06 08:29:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-9181d186 in namespace namespace-109
2022-04-06 08:29:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-06 08:29:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-9181d186 will have desired state: Ready
2022-04-06 08:30:52 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-9181d186 is in desired state: Ready
2022-04-06 08:30:52 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-9181d186-user in namespace namespace-109
2022-04-06 08:30:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-06 08:30:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-9181d186-user will have desired state: Ready
2022-04-06 08:30:53 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-9181d186-user is in desired state: Ready
2022-04-06 08:30:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1457934564-289878463 in namespace namespace-109
2022-04-06 08:30:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-06 08:30:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1457934564-289878463 will have desired state: Ready
2022-04-06 08:30:54 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1457934564-289878463 is in desired state: Ready
2022-04-06 08:30:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-9181d186-scraper in namespace namespace-109
2022-04-06 08:30:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-06 08:30:54 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-9181d186-scraper will be ready
2022-04-06 08:30:56 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-9181d186-scraper is ready
2022-04-06 08:30:56 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-9181d186-scraper to be ready
2022-04-06 08:31:06 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-9181d186-scraper is ready
2022-04-06 08:31:06 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-9181d186-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 08:31:06 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-9181d186-allow in namespace namespace-109
2022-04-06 08:31:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-06 08:31:06 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 08:31:06 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-9181d186 in namespace namespace-109
2022-04-06 08:31:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-06 08:31:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-9181d186 will have desired state: Ready
2022-04-06 08:32:16 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-9181d186 is in desired state: Ready
2022-04-06 08:32:16 [main] [32mINFO [m [ConnectIsolatedST:547] Verifying that KafkaConnect pod logs don't contain ERRORs
2022-04-06 08:32:16 [main] [32mINFO [m [ConnectIsolatedST:550] Creating FileStreamSink connector via pod my-cluster-9181d186-scraper-f9bb69788-kzssp with topic my-topic-1457934564-289878463
2022-04-06 08:32:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-109 exec my-cluster-9181d186-scraper-f9bb69788-kzssp -- /bin/bash -c curl -X POST -H "Content-Type: application/json" --data '{ "name": "sink-test", "config": { "connector.class": "FileStreamSink", "tasks.max": "1", "topics": "my-topic-1457934564-289878463", "file": "/tmp/test-file-sink.txt" } }' http://my-cluster-9181d186-connect-api.namespace-109.svc:8083/connectors
2022-04-06 08:32:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:32:16 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 08:32:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-9181d186-hello-world-producer in namespace namespace-109
2022-04-06 08:32:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-06 08:32:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-9181d186-hello-world-consumer in namespace namespace-109
2022-04-06 08:32:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-06 08:32:16 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-9181d186-hello-world-producer will be in active state
2022-04-06 08:32:17 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-9181d186-hello-world-consumer will be in active state
2022-04-06 08:32:17 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-9181d186-hello-world-producer and consumer my-cluster-9181d186-hello-world-consumer finish
2022-04-06 08:32:34 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-9181d186-connect-d8878b966-w76gx
2022-04-06 08:32:35 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-9181d186-connect-d8878b966-w76gx
2022-04-06 08:32:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:32:35 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSecretsWithKafkaConnectWithTlsAndScramShaAuthentication
2022-04-06 08:32:35 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-9181d186 in namespace namespace-109
2022-04-06 08:32:35 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-9181d186-allow in namespace namespace-109
2022-04-06 08:32:35 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-9181d186-hello-world-producer in namespace namespace-109
2022-04-06 08:32:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1457934564-289878463 in namespace namespace-109
2022-04-06 08:32:35 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-9181d186-user in namespace namespace-109
2022-04-06 08:32:35 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-9181d186 in namespace namespace-109
2022-04-06 08:32:35 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-9181d186-hello-world-consumer in namespace namespace-109
2022-04-06 08:32:35 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-9181d186-scraper in namespace namespace-109
2022-04-06 08:33:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:33:25 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-109 for test case:testSecretsWithKafkaConnectWithTlsAndScramShaAuthentication
2022-04-06 08:33:30 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testSecretsWithKafkaConnectWithTlsAndScramShaAuthentication-FINISHED
2022-04-06 08:33:30 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 08:33:30 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 08:33:30 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testConfigureDeploymentStrategy-STARTED
2022-04-06 08:33:30 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 08:33:30 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-110 for test case:testConfigureDeploymentStrategy
2022-04-06 08:33:30 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-110
2022-04-06 08:33:30 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-110
2022-04-06 08:33:30 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-110
2022-04-06 08:33:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ede3eac9 in namespace namespace-110
2022-04-06 08:33:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-110
2022-04-06 08:33:30 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ede3eac9 will have desired state: Ready
2022-04-06 08:34:44 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ede3eac9 is in desired state: Ready
2022-04-06 08:34:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-ede3eac9 in namespace namespace-110
2022-04-06 08:34:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-110
2022-04-06 08:34:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-ede3eac9 will have desired state: Ready
2022-04-06 08:35:47 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-ede3eac9 is in desired state: Ready
2022-04-06 08:35:47 [main] [32mINFO [m [ConnectIsolatedST:1191] Adding label to Connect resource, the CR should be recreated
2022-04-06 08:35:47 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ede3eac9-connect will be ready
2022-04-06 08:35:47 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ede3eac9-connect is ready
2022-04-06 08:35:47 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-ede3eac9-connect to be ready
2022-04-06 08:37:15 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-ede3eac9-connect is ready
2022-04-06 08:37:15 [main] [32mINFO [m [ConnectIsolatedST:1198] Checking that observed gen. is still on 1 (recreation) and new label is present
2022-04-06 08:37:15 [main] [32mINFO [m [ConnectIsolatedST:1203] Changing deployment strategy to ROLLING_UPDATE
2022-04-06 08:37:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-ede3eac9 will have desired state: Ready
2022-04-06 08:37:15 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-ede3eac9 is in desired state: Ready
2022-04-06 08:37:15 [main] [32mINFO [m [ConnectIsolatedST:1208] Adding another label to Connect resource, pods should be rolled
2022-04-06 08:37:15 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ede3eac9-connect will be ready
2022-04-06 08:37:15 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ede3eac9-connect is ready
2022-04-06 08:37:15 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-ede3eac9-connect to be ready
2022-04-06 08:38:29 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-ede3eac9-connect is ready
2022-04-06 08:38:29 [main] [32mINFO [m [ConnectIsolatedST:1212] Checking that observed gen. higher (rolling update) and label is changed
2022-04-06 08:38:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:38:29 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigureDeploymentStrategy
2022-04-06 08:38:29 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-ede3eac9 in namespace namespace-110
2022-04-06 08:38:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ede3eac9 in namespace namespace-110
2022-04-06 08:38:39 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:38:39 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-110 for test case:testConfigureDeploymentStrategy
2022-04-06 08:39:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testConfigureDeploymentStrategy-FINISHED
2022-04-06 08:39:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 08:39:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 08:39:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectAndConnectorFileSinkPlugin-STARTED
2022-04-06 08:39:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 08:39:07 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-111 for test case:testKafkaConnectAndConnectorFileSinkPlugin
2022-04-06 08:39:07 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-111
2022-04-06 08:39:07 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-111
2022-04-06 08:39:07 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-111
2022-04-06 08:39:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-6f372f6e in namespace namespace-111
2022-04-06 08:39:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-111
2022-04-06 08:39:07 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-6f372f6e will have desired state: Ready
2022-04-06 08:40:27 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-6f372f6e is in desired state: Ready
2022-04-06 08:40:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-6f372f6e-scraper in namespace namespace-111
2022-04-06 08:40:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-111
2022-04-06 08:40:27 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-6f372f6e-scraper will be ready
2022-04-06 08:40:29 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-6f372f6e-scraper is ready
2022-04-06 08:40:29 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-6f372f6e-scraper to be ready
2022-04-06 08:40:39 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-6f372f6e-scraper is ready
2022-04-06 08:40:39 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-6f372f6e-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 08:40:39 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-6f372f6e-allow in namespace namespace-111
2022-04-06 08:40:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-111
2022-04-06 08:40:39 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 08:40:39 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-6f372f6e in namespace namespace-111
2022-04-06 08:40:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-111
2022-04-06 08:40:39 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-6f372f6e will have desired state: Ready
2022-04-06 08:41:50 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-6f372f6e is in desired state: Ready
2022-04-06 08:41:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector license-source in namespace namespace-111
2022-04-06 08:41:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-111
2022-04-06 08:41:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: license-source will have desired state: Ready
2022-04-06 08:41:51 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: license-source is in desired state: Ready
2022-04-06 08:41:51 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 08:41:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-6f372f6e-hello-world-consumer in namespace namespace-111
2022-04-06 08:41:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-111
2022-04-06 08:41:51 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-6f372f6e-hello-world-consumer will be in active state
2022-04-06 08:41:52 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:my-cluster-6f372f6e-hello-world-consumer to finished
2022-04-06 08:42:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-111 exec my-cluster-6f372f6e-scraper-865b469567-65dmx -- /bin/bash -c curl http://my-cluster-6f372f6e-connect-api.namespace-111.svc:8083/connectors/license-source
2022-04-06 08:42:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:42:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:42:03 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectAndConnectorFileSinkPlugin
2022-04-06 08:42:03 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-6f372f6e in namespace namespace-111
2022-04-06 08:42:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-6f372f6e in namespace namespace-111
2022-04-06 08:42:03 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-6f372f6e-hello-world-consumer in namespace namespace-111
2022-04-06 08:42:03 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector license-source in namespace namespace-111
2022-04-06 08:42:03 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-6f372f6e-allow in namespace namespace-111
2022-04-06 08:42:03 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-6f372f6e-scraper in namespace namespace-111
2022-04-06 08:42:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:42:53 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-111 for test case:testKafkaConnectAndConnectorFileSinkPlugin
2022-04-06 08:42:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectAndConnectorFileSinkPlugin-FINISHED
2022-04-06 08:42:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 08:42:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 08:42:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testDeployUndeploy-STARTED
2022-04-06 08:42:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 08:42:58 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-112 for test case:testDeployUndeploy
2022-04-06 08:42:58 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-112
2022-04-06 08:42:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-112
2022-04-06 08:42:58 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-112
2022-04-06 08:42:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-683730d5 in namespace namespace-112
2022-04-06 08:42:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-112
2022-04-06 08:42:58 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-683730d5 will have desired state: Ready
2022-04-06 08:44:16 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-683730d5 is in desired state: Ready
2022-04-06 08:44:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-683730d5-scraper in namespace namespace-112
2022-04-06 08:44:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-112
2022-04-06 08:44:16 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-683730d5-scraper will be ready
2022-04-06 08:44:17 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-683730d5-scraper is ready
2022-04-06 08:44:17 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-683730d5-scraper to be ready
2022-04-06 08:44:28 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-683730d5-scraper is ready
2022-04-06 08:44:28 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-683730d5-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 08:44:28 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-683730d5-allow in namespace namespace-112
2022-04-06 08:44:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-112
2022-04-06 08:44:28 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 08:44:28 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-683730d5 in namespace namespace-112
2022-04-06 08:44:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-112
2022-04-06 08:44:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-683730d5 will have desired state: Ready
2022-04-06 08:45:31 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-683730d5 is in desired state: Ready
2022-04-06 08:45:31 [main] [32mINFO [m [ConnectIsolatedST:123] Looks like the connect cluster my-cluster deployed OK
2022-04-06 08:45:31 [main] [32mINFO [m [ConnectIsolatedST:140] Verifying docker image names
2022-04-06 08:45:31 [main] [32mINFO [m [AbstractST:172] strimzi-cluster-operator
2022-04-06 08:45:31 [main] [32mINFO [m [ConnectIsolatedST:152] Docker images verified
2022-04-06 08:45:31 [main] [32mINFO [m [AbstractST:311] Verifying labels on pod type connect
2022-04-06 08:45:31 [main] [32mINFO [m [AbstractST:315] Verifying labels for pod: my-cluster-683730d5-connect-6f5bf77957-5qdpc
2022-04-06 08:45:31 [main] [32mINFO [m [AbstractST:356] Verifying labels for Kafka Connect Services
2022-04-06 08:45:31 [main] [32mINFO [m [AbstractST:362] Verifying labels for service my-cluster-683730d5-connect-api
2022-04-06 08:45:31 [main] [32mINFO [m [AbstractST:384] Verifying labels for Config maps
2022-04-06 08:45:31 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-683730d5-connect-config
2022-04-06 08:45:31 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-683730d5-entity-topic-operator-config
2022-04-06 08:45:31 [main] [32mINFO [m [AbstractST:407] CM my-cluster-683730d5-entity-topic-operator-config is not related to current test
2022-04-06 08:45:31 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-683730d5-entity-user-operator-config
2022-04-06 08:45:31 [main] [32mINFO [m [AbstractST:407] CM my-cluster-683730d5-entity-user-operator-config is not related to current test
2022-04-06 08:45:31 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-683730d5-kafka-config
2022-04-06 08:45:31 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-683730d5-zookeeper-config
2022-04-06 08:45:31 [main] [32mINFO [m [AbstractST:407] CM my-cluster-683730d5-zookeeper-config is not related to current test
2022-04-06 08:45:31 [main] [32mINFO [m [AbstractST:414] Verifying labels for Service Accounts
2022-04-06 08:45:31 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-683730d5-connect
2022-04-06 08:45:31 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-683730d5-entity-operator
2022-04-06 08:45:31 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-683730d5-kafka
2022-04-06 08:45:31 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-683730d5-zookeeper
2022-04-06 08:45:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:45:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeployUndeploy
2022-04-06 08:45:31 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-683730d5-allow in namespace namespace-112
2022-04-06 08:45:31 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-683730d5 in namespace namespace-112
2022-04-06 08:45:31 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-683730d5 in namespace namespace-112
2022-04-06 08:45:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-683730d5-scraper in namespace namespace-112
2022-04-06 08:46:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:46:11 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-112 for test case:testDeployUndeploy
2022-04-06 08:46:16 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testDeployUndeploy-FINISHED
2022-04-06 08:46:16 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 08:46:16 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 08:46:16 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testMountingSecretAndConfigMapAsVolumesAndEnvVars-STARTED
2022-04-06 08:46:16 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 08:46:16 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-113 for test case:testMountingSecretAndConfigMapAsVolumesAndEnvVars
2022-04-06 08:46:16 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-113
2022-04-06 08:46:16 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-113
2022-04-06 08:46:16 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-113
2022-04-06 08:46:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2b073eb8 in namespace namespace-113
2022-04-06 08:46:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-113
2022-04-06 08:46:16 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2b073eb8 will have desired state: Ready
2022-04-06 08:47:32 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2b073eb8 is in desired state: Ready
2022-04-06 08:47:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-2b073eb8 in namespace namespace-113
2022-04-06 08:47:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-113
2022-04-06 08:47:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-2b073eb8 will have desired state: Ready
2022-04-06 08:48:43 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-2b073eb8 is in desired state: Ready
2022-04-06 08:48:43 [main] [32mINFO [m [ConnectIsolatedST:1148] Check if the ENVs contains desired values
2022-04-06 08:48:43 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-2b073eb8-connect-6b66647cc5-qb9q2 -- /bin/bash -c printenv MY_CONNECT_SECRET
2022-04-06 08:48:43 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:48:43 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-2b073eb8-connect-6b66647cc5-qb9q2 -- /bin/bash -c printenv MY_CONNECT_CONFIG_MAP
2022-04-06 08:48:43 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:48:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-2b073eb8-connect-6b66647cc5-qb9q2 -- /bin/bash -c printenv MY_DOTED_CONNECT_SECRET
2022-04-06 08:48:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:48:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-2b073eb8-connect-6b66647cc5-qb9q2 -- /bin/bash -c printenv MY_DOTED_CONNECT_CONFIG_MAP
2022-04-06 08:48:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:48:44 [main] [32mINFO [m [ConnectIsolatedST:1154] Check if volumes contains desired values
2022-04-06 08:48:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-2b073eb8-connect-6b66647cc5-qb9q2 -- /bin/bash -c cat external-configuration/connect-config-map/my-key
2022-04-06 08:48:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:48:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-2b073eb8-connect-6b66647cc5-qb9q2 -- /bin/bash -c cat external-configuration/connect-secret/my-secret-key
2022-04-06 08:48:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:48:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-2b073eb8-connect-6b66647cc5-qb9q2 -- /bin/bash -c cat external-configuration/connect.config.map/my-key
2022-04-06 08:48:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:48:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-2b073eb8-connect-6b66647cc5-qb9q2 -- /bin/bash -c cat external-configuration/connect.secret/my-secret-key
2022-04-06 08:48:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:48:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:48:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMountingSecretAndConfigMapAsVolumesAndEnvVars
2022-04-06 08:48:45 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-2b073eb8 in namespace namespace-113
2022-04-06 08:48:45 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2b073eb8 in namespace namespace-113
2022-04-06 08:48:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:48:55 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-113 for test case:testMountingSecretAndConfigMapAsVolumesAndEnvVars
2022-04-06 08:49:38 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testMountingSecretAndConfigMapAsVolumesAndEnvVars-FINISHED
2022-04-06 08:49:38 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 08:49:38 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 08:49:38 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testJvmAndResources-STARTED
2022-04-06 08:49:38 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 08:49:38 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-114 for test case:testJvmAndResources
2022-04-06 08:49:38 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-114
2022-04-06 08:49:38 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-114
2022-04-06 08:49:38 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-114
2022-04-06 08:49:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d7d24551 in namespace namespace-114
2022-04-06 08:49:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-114
2022-04-06 08:49:38 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d7d24551 will have desired state: Ready
2022-04-06 08:51:02 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d7d24551 is in desired state: Ready
2022-04-06 08:51:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-d7d24551-kafka-clients in namespace namespace-114
2022-04-06 08:51:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-114
2022-04-06 08:51:02 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d7d24551-kafka-clients will be ready
2022-04-06 08:51:04 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d7d24551-kafka-clients is ready
2022-04-06 08:51:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-d7d24551-scraper in namespace namespace-114
2022-04-06 08:51:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-114
2022-04-06 08:51:04 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d7d24551-scraper will be ready
2022-04-06 08:51:06 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d7d24551-scraper is ready
2022-04-06 08:51:06 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-d7d24551-scraper to be ready
2022-04-06 08:51:16 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-d7d24551-scraper is ready
2022-04-06 08:51:16 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-d7d24551-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 08:51:16 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-d7d24551-allow in namespace namespace-114
2022-04-06 08:51:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-114
2022-04-06 08:51:16 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 08:51:16 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-d7d24551 in namespace namespace-114
2022-04-06 08:51:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-114
2022-04-06 08:51:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-d7d24551 will have desired state: Ready
2022-04-06 08:52:24 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-d7d24551 is in desired state: Ready
2022-04-06 08:52:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-114 exec my-cluster-d7d24551-connect-65b855976d-wvm6g -c my-cluster-d7d24551-connect -- /bin/bash -c for proc in $(ls -1 /proc/ | grep [0-9]); do if echo "$(ls -lh /proc/$proc/exe 2>/dev/null || true)" | grep -q java; then cat /proc/$proc/cmdline; fi; done
2022-04-06 08:52:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:52:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:52:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testJvmAndResources
2022-04-06 08:52:25 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-d7d24551-scraper in namespace namespace-114
2022-04-06 08:52:25 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d7d24551 in namespace namespace-114
2022-04-06 08:52:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-d7d24551 in namespace namespace-114
2022-04-06 08:52:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-d7d24551-allow in namespace namespace-114
2022-04-06 08:52:25 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-d7d24551-kafka-clients in namespace namespace-114
2022-04-06 08:53:15 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:53:15 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-114 for test case:testJvmAndResources
2022-04-06 08:53:20 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testJvmAndResources-FINISHED
2022-04-06 08:53:20 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 08:53:20 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 08:53:20 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testSecretsWithKafkaConnectWithTlsAndTlsClientAuthentication-STARTED
2022-04-06 08:53:20 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 08:53:20 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-115 for test case:testSecretsWithKafkaConnectWithTlsAndTlsClientAuthentication
2022-04-06 08:53:20 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-115
2022-04-06 08:53:20 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-115
2022-04-06 08:53:20 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-115
2022-04-06 08:53:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-50f44e84 in namespace namespace-115
2022-04-06 08:53:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-06 08:53:20 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-50f44e84 will have desired state: Ready
2022-04-06 08:54:36 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-50f44e84 is in desired state: Ready
2022-04-06 08:54:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-50f44e84-user in namespace namespace-115
2022-04-06 08:54:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-06 08:54:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-50f44e84-user will have desired state: Ready
2022-04-06 08:54:37 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-50f44e84-user is in desired state: Ready
2022-04-06 08:54:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-444533706-1312454534 in namespace namespace-115
2022-04-06 08:54:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-06 08:54:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-444533706-1312454534 will have desired state: Ready
2022-04-06 08:54:38 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-444533706-1312454534 is in desired state: Ready
2022-04-06 08:54:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-50f44e84-scraper in namespace namespace-115
2022-04-06 08:54:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-06 08:54:38 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-50f44e84-scraper will be ready
2022-04-06 08:54:40 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-50f44e84-scraper is ready
2022-04-06 08:54:40 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-50f44e84-scraper to be ready
2022-04-06 08:54:51 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-50f44e84-scraper is ready
2022-04-06 08:54:51 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-50f44e84-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 08:54:51 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-50f44e84-allow in namespace namespace-115
2022-04-06 08:54:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-06 08:54:51 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 08:54:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-50f44e84 in namespace namespace-115
2022-04-06 08:54:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-06 08:54:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-50f44e84 will have desired state: Ready
2022-04-06 08:55:59 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-50f44e84 is in desired state: Ready
2022-04-06 08:55:59 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-06 08:55:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-115 exec my-cluster-50f44e84-connect-65bf449698-dlgq4 -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-06 08:55:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:55:59 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-06 08:55:59 [main] [32mINFO [m [ConnectIsolatedST:474] Verifying that KafkaConnect pod logs don't contain ERRORs
2022-04-06 08:55:59 [main] [32mINFO [m [ConnectIsolatedST:477] Creating FileStreamSink connector via pod my-cluster-50f44e84-scraper-78b9d4698b-tc7t8 with topic my-topic-444533706-1312454534
2022-04-06 08:56:00 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-115 exec my-cluster-50f44e84-scraper-78b9d4698b-tc7t8 -- /bin/bash -c curl -X POST -H "Content-Type: application/json" --data '{ "name": "sink-test", "config": { "connector.class": "FileStreamSink", "tasks.max": "1", "topics": "my-topic-444533706-1312454534", "file": "/tmp/test-file-sink.txt" } }' http://my-cluster-50f44e84-connect-api.namespace-115.svc:8083/connectors
2022-04-06 08:56:00 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:56:00 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 08:56:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-50f44e84-hello-world-producer in namespace namespace-115
2022-04-06 08:56:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-06 08:56:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-50f44e84-hello-world-consumer in namespace namespace-115
2022-04-06 08:56:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-06 08:56:00 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-50f44e84-hello-world-producer will be in active state
2022-04-06 08:56:00 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-50f44e84-hello-world-consumer will be in active state
2022-04-06 08:56:00 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-50f44e84-hello-world-producer and consumer my-cluster-50f44e84-hello-world-consumer finish
2022-04-06 08:56:17 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-50f44e84-connect-65bf449698-dlgq4
2022-04-06 08:56:17 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-50f44e84-connect-65bf449698-dlgq4
2022-04-06 08:56:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:56:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSecretsWithKafkaConnectWithTlsAndTlsClientAuthentication
2022-04-06 08:56:17 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-50f44e84 in namespace namespace-115
2022-04-06 08:56:17 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-50f44e84-hello-world-producer in namespace namespace-115
2022-04-06 08:56:17 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-50f44e84-user in namespace namespace-115
2022-04-06 08:56:17 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-444533706-1312454534 in namespace namespace-115
2022-04-06 08:56:17 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-50f44e84-scraper in namespace namespace-115
2022-04-06 08:56:17 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-50f44e84-hello-world-consumer in namespace namespace-115
2022-04-06 08:56:17 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-50f44e84-allow in namespace namespace-115
2022-04-06 08:56:17 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-50f44e84 in namespace namespace-115
2022-04-06 08:57:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:57:07 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-115 for test case:testSecretsWithKafkaConnectWithTlsAndTlsClientAuthentication
2022-04-06 08:57:12 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testSecretsWithKafkaConnectWithTlsAndTlsClientAuthentication-FINISHED
2022-04-06 08:57:12 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 08:57:12 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 08:57:12 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testScaleConnectWithoutConnectorToZero-STARTED
2022-04-06 08:57:12 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 08:57:12 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-116 for test case:testScaleConnectWithoutConnectorToZero
2022-04-06 08:57:12 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-116
2022-04-06 08:57:13 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-116
2022-04-06 08:57:13 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-116
2022-04-06 08:57:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-54ef156f in namespace namespace-116
2022-04-06 08:57:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-116
2022-04-06 08:57:13 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-54ef156f will have desired state: Ready
2022-04-06 08:58:32 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-54ef156f is in desired state: Ready
2022-04-06 08:58:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-54ef156f in namespace namespace-116
2022-04-06 08:58:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-116
2022-04-06 08:58:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-54ef156f will have desired state: Ready
2022-04-06 08:59:40 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-54ef156f is in desired state: Ready
2022-04-06 08:59:40 [main] [32mINFO [m [ConnectIsolatedST:891] Scaling KafkaConnect down to zero
2022-04-06 08:59:40 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-54ef156f will have desired state: Ready
2022-04-06 08:59:40 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-54ef156f is in desired state: Ready
2022-04-06 08:59:42 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:59:42 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleConnectWithoutConnectorToZero
2022-04-06 08:59:42 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-54ef156f in namespace namespace-116
2022-04-06 08:59:42 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-54ef156f in namespace namespace-116
2022-04-06 08:59:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:59:52 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-116 for test case:testScaleConnectWithoutConnectorToZero
2022-04-06 09:00:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testScaleConnectWithoutConnectorToZero-FINISHED
2022-04-06 09:00:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 09:00:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 09:00:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testScaleConnectWithConnectorToZero-STARTED
2022-04-06 09:00:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 09:00:35 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-117 for test case:testScaleConnectWithConnectorToZero
2022-04-06 09:00:35 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-117
2022-04-06 09:00:36 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-117
2022-04-06 09:00:36 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-117
2022-04-06 09:00:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-109186b2 in namespace namespace-117
2022-04-06 09:00:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-117
2022-04-06 09:00:36 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-109186b2 will have desired state: Ready
2022-04-06 09:01:53 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-109186b2 is in desired state: Ready
2022-04-06 09:01:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-109186b2 in namespace namespace-117
2022-04-06 09:01:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-117
2022-04-06 09:01:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-109186b2 will have desired state: Ready
2022-04-06 09:03:02 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-109186b2 is in desired state: Ready
2022-04-06 09:03:02 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-109186b2 in namespace namespace-117
2022-04-06 09:03:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-117
2022-04-06 09:03:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-109186b2 will have desired state: Ready
2022-04-06 09:03:03 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-109186b2 is in desired state: Ready
2022-04-06 09:03:03 [main] [32mINFO [m [ConnectIsolatedST:934] Scaling KafkaConnect down to zero
2022-04-06 09:03:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-109186b2 will have desired state: Ready
2022-04-06 09:03:03 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-109186b2 is in desired state: Ready
2022-04-06 09:03:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 09:03:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleConnectWithConnectorToZero
2022-04-06 09:03:11 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-109186b2 in namespace namespace-117
2022-04-06 09:03:11 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-109186b2 in namespace namespace-117
2022-04-06 09:03:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-109186b2 in namespace namespace-117
2022-04-06 09:03:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 09:03:21 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-117 for test case:testScaleConnectWithConnectorToZero
2022-04-06 09:04:04 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testScaleConnectWithConnectorToZero-FINISHED
2022-04-06 09:04:04 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 09:04:04 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 09:04:04 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectWithPlainAndScramShaAuthentication-STARTED
2022-04-06 09:04:04 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 09:04:04 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-118 for test case:testKafkaConnectWithPlainAndScramShaAuthentication
2022-04-06 09:04:04 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-118
2022-04-06 09:04:04 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-118
2022-04-06 09:04:04 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-118
2022-04-06 09:04:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-51b69e04 in namespace namespace-118
2022-04-06 09:04:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-06 09:04:04 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-51b69e04 will have desired state: Ready
2022-04-06 09:05:26 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-51b69e04 is in desired state: Ready
2022-04-06 09:05:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-51b69e04-user in namespace namespace-118
2022-04-06 09:05:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-06 09:05:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-51b69e04-user will have desired state: Ready
2022-04-06 09:05:27 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-51b69e04-user is in desired state: Ready
2022-04-06 09:05:27 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1876698749-1990480106 in namespace namespace-118
2022-04-06 09:05:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-06 09:05:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1876698749-1990480106 will have desired state: Ready
2022-04-06 09:05:28 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1876698749-1990480106 is in desired state: Ready
2022-04-06 09:05:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-51b69e04-scraper in namespace namespace-118
2022-04-06 09:05:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-06 09:05:28 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-51b69e04-scraper will be ready
2022-04-06 09:05:30 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-51b69e04-scraper is ready
2022-04-06 09:05:30 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-51b69e04-scraper to be ready
2022-04-06 09:05:40 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-51b69e04-scraper is ready
2022-04-06 09:05:40 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-51b69e04-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 09:05:40 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-51b69e04-allow in namespace namespace-118
2022-04-06 09:05:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-06 09:05:40 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 09:05:40 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-51b69e04 in namespace namespace-118
2022-04-06 09:05:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-06 09:05:40 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-51b69e04 will have desired state: Ready
2022-04-06 09:06:50 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-51b69e04 is in desired state: Ready
2022-04-06 09:06:50 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-06 09:06:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-118 exec my-cluster-51b69e04-connect-68bb777759-kj65s -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-06 09:06:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 09:06:50 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-06 09:06:50 [main] [32mINFO [m [ConnectIsolatedST:280] Verifying that KafkaConnect pod logs don't contain ERRORs
2022-04-06 09:06:50 [main] [32mINFO [m [ConnectIsolatedST:283] Creating FileStreamSink connector via pod my-cluster-51b69e04-scraper-6cb769669b-nrc4b with topic my-topic-1876698749-1990480106
2022-04-06 09:06:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-118 exec my-cluster-51b69e04-scraper-6cb769669b-nrc4b -- /bin/bash -c curl -X POST -H "Content-Type: application/json" --data '{ "name": "sink-test", "config": { "connector.class": "FileStreamSink", "tasks.max": "1", "topics": "my-topic-1876698749-1990480106", "file": "/tmp/test-file-sink.txt" } }' http://my-cluster-51b69e04-connect-api.namespace-118.svc:8083/connectors
2022-04-06 09:06:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 09:06:50 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 09:06:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-51b69e04-hello-world-producer in namespace namespace-118
2022-04-06 09:06:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-06 09:06:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-51b69e04-hello-world-consumer in namespace namespace-118
2022-04-06 09:06:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-06 09:06:50 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-51b69e04-hello-world-producer will be in active state
2022-04-06 09:06:51 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-51b69e04-hello-world-consumer will be in active state
2022-04-06 09:06:51 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-51b69e04-hello-world-producer and consumer my-cluster-51b69e04-hello-world-consumer finish
2022-04-06 09:07:08 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-51b69e04-connect-68bb777759-kj65s
2022-04-06 09:07:08 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-51b69e04-connect-68bb777759-kj65s
2022-04-06 09:07:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 09:07:08 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectWithPlainAndScramShaAuthentication
2022-04-06 09:07:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-51b69e04-hello-world-consumer in namespace namespace-118
2022-04-06 09:07:08 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-51b69e04 in namespace namespace-118
2022-04-06 09:07:08 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-51b69e04-hello-world-producer in namespace namespace-118
2022-04-06 09:07:08 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-51b69e04 in namespace namespace-118
2022-04-06 09:07:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-51b69e04-user in namespace namespace-118
2022-04-06 09:07:08 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-51b69e04-allow in namespace namespace-118
2022-04-06 09:07:08 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1876698749-1990480106 in namespace namespace-118
2022-04-06 09:07:08 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-51b69e04-scraper in namespace namespace-118
2022-04-06 09:07:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 09:07:58 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-118 for test case:testKafkaConnectWithPlainAndScramShaAuthentication
2022-04-06 09:08:03 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectWithPlainAndScramShaAuthentication-FINISHED
2022-04-06 09:08:03 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 09:08:03 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 09:08:03 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testCustomAndUpdatedValues-STARTED
2022-04-06 09:08:03 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 09:08:03 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-119 for test case:testCustomAndUpdatedValues
2022-04-06 09:08:03 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-119
2022-04-06 09:08:03 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-119
2022-04-06 09:08:03 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-119
2022-04-06 09:08:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0225ac08 in namespace namespace-119
2022-04-06 09:08:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-119
2022-04-06 09:08:03 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0225ac08 will have desired state: Ready
2022-04-06 09:09:16 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0225ac08 is in desired state: Ready
2022-04-06 09:09:16 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-0225ac08 in namespace namespace-119
2022-04-06 09:09:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-119
2022-04-06 09:09:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-0225ac08 will have desired state: Ready
2022-04-06 09:09:58 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-0225ac08 is in desired state: Ready
2022-04-06 09:09:58 [main] [32mINFO [m [ConnectIsolatedST:629] Verify values before update
2022-04-06 09:09:58 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-0225ac08-connect in pod name
2022-04-06 09:09:58 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container my-cluster-0225ac08-connect
2022-04-06 09:09:58 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-0225ac08-connect
2022-04-06 09:09:58 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container my-cluster-0225ac08-connect
2022-04-06 09:09:58 [main] [32mINFO [m [ConnectIsolatedST:634] Check if actual env variable KAFKA_CONNECT_CONFIGURATION has different value than test.value
2022-04-06 09:09:58 [main] [32mINFO [m [ConnectIsolatedST:640] Updating values in MirrorMaker container
2022-04-06 09:09:58 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-0225ac08-connect rolling update
2022-04-06 09:10:48 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-0225ac08-connect will be ready
2022-04-06 09:10:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-0225ac08-connect is ready
2022-04-06 09:10:58 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-0225ac08-connect rolling update finished
2022-04-06 09:10:58 [main] [32mINFO [m [ConnectIsolatedST:657] Verify values after update
2022-04-06 09:10:58 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-0225ac08-connect in pod name
2022-04-06 09:10:58 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container my-cluster-0225ac08-connect
2022-04-06 09:10:58 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-0225ac08-connect
2022-04-06 09:10:58 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container my-cluster-0225ac08-connect
2022-04-06 09:10:58 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-0225ac08-connect
2022-04-06 09:10:58 [main] [32mINFO [m [AbstractST:194] Testing configuration for container my-cluster-0225ac08-connect
2022-04-06 09:10:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 09:10:58 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCustomAndUpdatedValues
2022-04-06 09:10:58 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-0225ac08 in namespace namespace-119
2022-04-06 09:10:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0225ac08 in namespace namespace-119
2022-04-06 09:11:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 09:11:08 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-119 for test case:testCustomAndUpdatedValues
2022-04-06 09:11:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testCustomAndUpdatedValues-FINISHED
2022-04-06 09:11:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 09:11:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 09:11:35 [main] [32mINFO [m [ResourceManager:346] In context ConnectIsolatedST is everything deleted.
2022-04-06 09:11:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4,060.365 s - in io.strimzi.systemtest.connect.ConnectIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.connect.ConnectBuilderIsolatedST
2022-04-06 09:11:35 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 09:12:00 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 09:12:00 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 09:12:00 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 09:12:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 09:12:00 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 09:12:00 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:00 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:00 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:00 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 09:12:00 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 09:12:00 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 09:12:00 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:12:00 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 09:12:00 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 09:12:00 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 09:12:00 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:00 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:12:00 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:12:00 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 09:12:00 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 09:12:00 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 09:12:00 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 09:12:00 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 09:12:00 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:12:00 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:00 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:10 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 09:12:10 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:20 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 09:12:25 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=120000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 09:12:25 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 09:12:25 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 09:12:25 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 09:12:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:12:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 09:12:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 09:12:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 09:12:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 09:12:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 09:12:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:26 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:26 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 09:12:26 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:26 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:26 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:26 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:26 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:26 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:26 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:26 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:12:26 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 09:12:26 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 09:12:26 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 09:12:26 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 09:12:26 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 09:12:26 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 09:12:26 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 09:12:26 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 09:12:26 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:12:26 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 09:12:26 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 09:12:26 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 09:12:26 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 09:12:26 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 09:12:26 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 09:12:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:12:26 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 09:12:45 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 09:12:45 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 09:12:55 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 09:12:55 [main] [33mWARN [m [ConnectBuilderIsolatedST:546] For running these tests on K8s you have to have internal registry deployed using `minikube start --insecure-registry '10.0.0.0/24'` and `minikube addons enable registry`
2022-04-06 09:12:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka infra-namespace in namespace infra-namespace
2022-04-06 09:12:55 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: infra-namespace will have desired state: Ready
2022-04-06 09:14:18 [main] [32mINFO [m [ResourceManager:444] Kafka: infra-namespace is in desired state: Ready
2022-04-06 09:14:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 09:14:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildWithJarTgzAndZip-STARTED
2022-04-06 09:14:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 09:14:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-949713706-1494462985 in namespace infra-namespace
2022-04-06 09:14:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-949713706-1494462985 will have desired state: Ready
2022-04-06 09:14:19 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-949713706-1494462985 is in desired state: Ready
2022-04-06 09:14:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-073db3fe in namespace infra-namespace
2022-04-06 09:14:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-073db3fe will have desired state: Ready
2022-04-06 09:16:04 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-073db3fe is in desired state: Ready
2022-04-06 09:16:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-073db3fe in namespace infra-namespace
2022-04-06 09:16:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-073db3fe will have desired state: Ready
2022-04-06 09:16:05 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-073db3fe is in desired state: Ready
2022-04-06 09:16:05 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 09:16:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-073db3fe-hello-world-producer in namespace infra-namespace
2022-04-06 09:16:05 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-073db3fe-hello-world-producer will be in active state
2022-04-06 09:16:06 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:my-cluster-073db3fe-hello-world-producer to finished
2022-04-06 09:16:14 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-06 09:16:14 [main] [32mINFO [m [PodUtils:189] Message Received message with key 'null' and value '"Hello-world - 99"' found in my-cluster-073db3fe-connect-8bbd94759-xm8kf log
2022-04-06 09:16:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 09:16:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBuildWithJarTgzAndZip
2022-04-06 09:16:14 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-073db3fe in namespace infra-namespace
2022-04-06 09:16:14 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-073db3fe in namespace infra-namespace
2022-04-06 09:16:14 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-949713706-1494462985 in namespace infra-namespace
2022-04-06 09:16:14 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-073db3fe-hello-world-producer in namespace infra-namespace
2022-04-06 09:16:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 09:16:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildWithJarTgzAndZip-FINISHED
2022-04-06 09:16:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 09:16:34 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 09:16:34 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildFailsWithWrongChecksumOfArtifact-STARTED
2022-04-06 09:16:34 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 09:16:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-9ccf7b21-scraper in namespace infra-namespace
2022-04-06 09:16:34 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-9ccf7b21-scraper will be ready
2022-04-06 09:16:36 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-9ccf7b21-scraper is ready
2022-04-06 09:16:36 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-9ccf7b21-scraper to be ready
2022-04-06 09:16:46 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-9ccf7b21-scraper is ready
2022-04-06 09:16:46 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-9ccf7b21-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 09:16:46 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-9ccf7b21-allow in namespace infra-namespace
2022-04-06 09:16:46 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 09:16:46 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-9ccf7b21 in namespace infra-namespace
2022-04-06 09:16:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-9ccf7b21 will have desired state: NotReady
2022-04-06 09:16:47 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-9ccf7b21 is in desired state: NotReady
2022-04-06 09:17:09 [main] [32mINFO [m [ConnectBuilderIsolatedST:186] Checking if KafkaConnect status condition contains message about build failure
2022-04-06 09:17:09 [main] [32mINFO [m [ConnectBuilderIsolatedST:189] Deploying network policies for KafkaConnect
2022-04-06 09:17:09 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-9ccf7b21-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 09:17:09 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-9ccf7b21-allow in namespace infra-namespace
2022-04-06 09:17:09 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 09:17:09 [main] [32mINFO [m [ConnectBuilderIsolatedST:197] Replacing plugin's checksum with right one
2022-04-06 09:17:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-9ccf7b21 will have desired state: Ready
2022-04-06 09:19:37 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-9ccf7b21 is in desired state: Ready
2022-04-06 09:19:37 [main] [32mINFO [m [ConnectBuilderIsolatedST:215] Checking if KafkaConnect API contains EchoSink connector
2022-04-06 09:19:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-9ccf7b21-scraper-67d5dc67bc-lzk5j -- curl -X GET http://my-cluster-9ccf7b21-connect-api:8083/connector-plugins
2022-04-06 09:19:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 09:19:38 [main] [32mINFO [m [ConnectBuilderIsolatedST:220] Checking if KafkaConnect resource contains EchoSink connector in status
2022-04-06 09:19:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 09:19:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBuildFailsWithWrongChecksumOfArtifact
2022-04-06 09:19:38 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-9ccf7b21 in namespace infra-namespace
2022-04-06 09:19:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-9ccf7b21-allow in namespace infra-namespace
2022-04-06 09:19:38 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-9ccf7b21-scraper in namespace infra-namespace
2022-04-06 09:19:38 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-9ccf7b21-allow in namespace infra-namespace
2022-04-06 09:20:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 09:20:18 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildFailsWithWrongChecksumOfArtifact-FINISHED
2022-04-06 09:20:18 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 09:20:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 09:20:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildOtherPluginTypeWithAndWithoutFileName-STARTED
2022-04-06 09:20:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 09:20:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-473951983-246245622 in namespace infra-namespace
2022-04-06 09:20:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-473951983-246245622 will have desired state: Ready
2022-04-06 09:20:19 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-473951983-246245622 is in desired state: Ready
2022-04-06 09:20:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-7244ab73-scraper in namespace infra-namespace
2022-04-06 09:20:19 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7244ab73-scraper will be ready
2022-04-06 09:20:20 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7244ab73-scraper is ready
2022-04-06 09:20:20 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-7244ab73-scraper to be ready
2022-04-06 09:20:30 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-7244ab73-scraper is ready
2022-04-06 09:20:30 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-7244ab73-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 09:20:30 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-7244ab73-allow in namespace infra-namespace
2022-04-06 09:20:30 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 09:20:30 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-7244ab73 in namespace infra-namespace
2022-04-06 09:20:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-7244ab73 will have desired state: Ready
2022-04-06 09:22:11 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-7244ab73 is in desired state: Ready
2022-04-06 09:22:11 [main] [32mINFO [m [ConnectBuilderIsolatedST:448] Checking that plugin has correct file name: echo-sink-test.jar
2022-04-06 09:22:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-7244ab73-connect-6cb689cc87-mjdr7 -- /bin/bash -c ls plugins/plugin-with-other-type/*
2022-04-06 09:22:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 09:22:12 [main] [32mINFO [m [ConnectBuilderIsolatedST:461] Removing file name from the plugin, hash should be used
2022-04-06 09:22:12 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-7244ab73-connect rolling update
2022-04-06 09:23:47 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7244ab73-connect will be ready
2022-04-06 09:23:47 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7244ab73-connect is ready
2022-04-06 09:23:57 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-7244ab73-connect rolling update finished
2022-04-06 09:23:57 [main] [32mINFO [m [ConnectBuilderIsolatedST:468] Checking that plugin has different name than before
2022-04-06 09:23:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-7244ab73-connect-fddf46c49-9q8mt -- /bin/bash -c ls plugins/plugin-with-other-type/*
2022-04-06 09:23:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 09:23:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 09:23:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBuildOtherPluginTypeWithAndWithoutFileName
2022-04-06 09:23:57 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-7244ab73-allow in namespace infra-namespace
2022-04-06 09:23:57 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-7244ab73 in namespace infra-namespace
2022-04-06 09:23:57 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-473951983-246245622 in namespace infra-namespace
2022-04-06 09:23:57 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-7244ab73-scraper in namespace infra-namespace
2022-04-06 09:24:37 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 09:24:37 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildOtherPluginTypeWithAndWithoutFileName-FINISHED
2022-04-06 09:24:37 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 09:24:37 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 09:24:37 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testUpdateConnectWithAnotherPlugin-STARTED
2022-04-06 09:24:37 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 09:24:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-714536427-709196911 in namespace infra-namespace
2022-04-06 09:24:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-714536427-709196911 will have desired state: Ready
2022-04-06 09:24:38 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-714536427-709196911 is in desired state: Ready
2022-04-06 09:24:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-e266c0cf-scraper in namespace infra-namespace
2022-04-06 09:24:38 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-e266c0cf-scraper will be ready
2022-04-06 09:24:40 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-e266c0cf-scraper is ready
2022-04-06 09:24:40 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-e266c0cf-scraper to be ready
2022-04-06 09:24:50 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-e266c0cf-scraper is ready
2022-04-06 09:24:50 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-e266c0cf-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 09:24:50 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-e266c0cf-allow in namespace infra-namespace
2022-04-06 09:24:50 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 09:24:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-e266c0cf in namespace infra-namespace
2022-04-06 09:24:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-e266c0cf will have desired state: Ready
2022-04-06 09:26:28 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-e266c0cf is in desired state: Ready
2022-04-06 09:26:28 [main] [32mINFO [m [ConnectBuilderIsolatedST:370] Creating EchoSink connector
2022-04-06 09:26:28 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector echo-sink-connector in namespace infra-namespace
2022-04-06 09:26:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: echo-sink-connector will have desired state: Ready
2022-04-06 09:26:29 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: echo-sink-connector is in desired state: Ready
2022-04-06 09:26:29 [main] [32mINFO [m [ConnectBuilderIsolatedST:382] Checking that KafkaConnect API contains EchoSink connector and not Camel-Telegram Connector class name
2022-04-06 09:26:30 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-e266c0cf-scraper-585d584778-wl4dk -- curl -X GET http://my-cluster-e266c0cf-connect-api:8083/connector-plugins
2022-04-06 09:26:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 09:26:30 [main] [32mINFO [m [ConnectBuilderIsolatedST:388] Adding one more connector to the KafkaConnect
2022-04-06 09:26:30 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-e266c0cf-connect rolling update
2022-04-06 09:28:10 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-e266c0cf-connect will be ready
2022-04-06 09:28:10 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-e266c0cf-connect is ready
2022-04-06 09:28:20 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-e266c0cf-connect rolling update finished
2022-04-06 09:28:20 [main] [32mINFO [m [ConnectBuilderIsolatedST:399] Creating Camel-HTTP-Sink connector
2022-04-06 09:28:20 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector camel-http-connector in namespace infra-namespace
2022-04-06 09:28:20 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: camel-http-connector will have desired state: Ready
2022-04-06 09:28:21 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: camel-http-connector is in desired state: Ready
2022-04-06 09:28:21 [main] [32mINFO [m [ConnectBuilderIsolatedST:409] Checking if both Connectors were created and Connect contains both plugins
2022-04-06 09:28:21 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 09:28:21 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUpdateConnectWithAnotherPlugin
2022-04-06 09:28:21 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-e266c0cf in namespace infra-namespace
2022-04-06 09:28:21 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-714536427-709196911 in namespace infra-namespace
2022-04-06 09:28:21 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector camel-http-connector in namespace infra-namespace
2022-04-06 09:28:21 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector echo-sink-connector in namespace infra-namespace
2022-04-06 09:28:21 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-e266c0cf-allow in namespace infra-namespace
2022-04-06 09:28:21 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-e266c0cf-scraper in namespace infra-namespace
2022-04-06 09:29:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 09:29:11 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testUpdateConnectWithAnotherPlugin-FINISHED
2022-04-06 09:29:11 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 09:29:11 [main] [32mINFO [m [OpenShiftOnlyCondition:25] testPushIntoImageStream is @OpenShiftOnly, but the running cluster is not OpenShift: Ignoring testPushIntoImageStream
2022-04-06 09:29:11 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 09:29:11 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildPluginUsingMavenCoordinatesArtifacts-STARTED
2022-04-06 09:29:11 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 09:29:11 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1071519118-1690691442 in namespace infra-namespace
2022-04-06 09:29:11 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-20cda32d in namespace infra-namespace
2022-04-06 09:29:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1071519118-1690691442 will have desired state: Ready
2022-04-06 09:29:12 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1071519118-1690691442 is in desired state: Ready
2022-04-06 09:29:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-20cda32d will have desired state: Ready
2022-04-06 09:31:20 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-20cda32d is in desired state: Ready
2022-04-06 09:31:20 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-20cda32d-camel-connector in namespace infra-namespace
2022-04-06 09:31:20 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-20cda32d-camel-connector will have desired state: Ready
2022-04-06 09:31:21 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-20cda32d-camel-connector is in desired state: Ready
2022-04-06 09:31:21 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 09:31:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-20cda32d-hello-world-consumer in namespace infra-namespace
2022-04-06 09:31:21 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-20cda32d-hello-world-consumer will be in active state
2022-04-06 09:31:22 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:my-cluster-20cda32d-hello-world-consumer to finished
2022-04-06 09:32:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 09:32:18 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBuildPluginUsingMavenCoordinatesArtifacts
2022-04-06 09:32:18 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-20cda32d-camel-connector in namespace infra-namespace
2022-04-06 09:32:18 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-20cda32d-hello-world-consumer in namespace infra-namespace
2022-04-06 09:32:18 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-20cda32d in namespace infra-namespace
2022-04-06 09:32:18 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1071519118-1690691442 in namespace infra-namespace
2022-04-06 09:32:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 09:32:28 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildPluginUsingMavenCoordinatesArtifacts-FINISHED
2022-04-06 09:32:28 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 09:32:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 09:32:28 [main] [32mINFO [m [ResourceManager:348] Delete all resources for ConnectBuilderIsolatedST
2022-04-06 09:32:28 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka infra-namespace in namespace infra-namespace
2022-04-06 09:32:38 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;33mWARNING[m] Tests run: 6, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 1,262.731 s - in io.strimzi.systemtest.connect.ConnectBuilderIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST
2022-04-06 09:32:38 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 09:33:03 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 09:33:03 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 09:33:03 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 09:33:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 09:33:03 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 09:33:03 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 09:33:03 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 09:33:03 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 09:33:03 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:33:03 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 09:33:03 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 09:33:03 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 09:33:03 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 09:33:03 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 09:33:03 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 09:33:03 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 09:33:03 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 09:33:03 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:33:03 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 09:33:03 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 09:33:03 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 09:33:03 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:33:03 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 09:33:13 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 09:33:13 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 09:33:13 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 09:33:13 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 09:33:13 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:33:13 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 09:33:13 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 09:33:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 09:33:29 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 09:33:29 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 09:33:29 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 09:33:29 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 09:33:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:33:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 09:33:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 09:33:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 09:33:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 09:33:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 09:33:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 09:33:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 09:33:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 09:33:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 09:33:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 09:33:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 09:33:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 09:33:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 09:33:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 09:33:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 09:33:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:33:29 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 09:33:29 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 09:33:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 09:33:29 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 09:33:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 09:33:29 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 09:33:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 09:33:29 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 09:33:29 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:33:29 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 09:33:29 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 09:33:29 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 09:33:29 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 09:33:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 09:33:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 09:33:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:33:29 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 09:33:56 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 09:33:56 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 09:34:06 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 09:34:06 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 09:34:06 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST.backupAndRestore-STARTED
2022-04-06 09:34:06 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 09:34:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-4c5c64ed in namespace infra-namespace
2022-04-06 09:34:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4c5c64ed will have desired state: Ready
2022-04-06 09:35:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4c5c64ed is in desired state: Ready
2022-04-06 09:35:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-4c5c64ed-producer in namespace infra-namespace
2022-04-06 09:35:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-4c5c64ed-consumer in namespace infra-namespace
2022-04-06 09:35:21 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-4c5c64ed-producer will be in active state
2022-04-06 09:35:21 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-4c5c64ed-consumer will be in active state
2022-04-06 09:35:21 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-4c5c64ed-producer and consumer my-cluster-4c5c64ed-consumer finish
2022-04-06 09:35:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-4c5c64ed-kafka-0 -- /opt/kafka/bin/kafka-consumer-groups.sh --describe --bootstrap-server localhost:9092 --group my-group
2022-04-06 09:35:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 09:35:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-4c5c64ed-producer in namespace infra-namespace
2022-04-06 09:35:35 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-4c5c64ed-producer will be in active state
2022-04-06 09:35:36 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:my-cluster-4c5c64ed-producer to finished
2022-04-06 09:35:39 [main] [32mINFO [m [ColdBackupScriptIsolatedST:95] Running backup procedure for infra-namespace/my-cluster-4c5c64ed
2022-04-06 09:37:48 [main] [32mINFO [m [Exec:417] Command: /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/cold-backup/run.sh backup -n infra-namespace -c my-cluster-4c5c64ed -t /home/ec2-user/strimzi-kafka-operator/systemtest/target/my-cluster-4c5c64ed.tgz -y
2022-04-06 09:37:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 09:37:48 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 09:37:48 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 09:37:48 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 09:37:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 09:37:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 09:37:48 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 09:37:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 09:37:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 09:37:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 09:37:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 09:37:48 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 09:37:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 09:37:48 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 09:37:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 09:37:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 09:37:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 09:37:48 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:37:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 09:37:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 09:37:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:37:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:37:48 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 09:37:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 09:37:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 09:37:48 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 09:37:58 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 09:37:58 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:37:58 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 09:37:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 09:37:58 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 09:38:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 09:38:35 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 09:38:35 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 09:38:35 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 09:38:35 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 09:38:35 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:38:35 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 09:38:35 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 09:38:35 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 09:38:35 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 09:38:35 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 09:38:35 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 09:38:35 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 09:38:35 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 09:38:35 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 09:38:35 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 09:38:35 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 09:38:35 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 09:38:35 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 09:38:35 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 09:38:35 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 09:38:35 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:38:35 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 09:38:35 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 09:38:35 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 09:38:35 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 09:38:35 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 09:38:35 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 09:38:35 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 09:38:35 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 09:38:35 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:38:35 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 09:38:35 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 09:38:35 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 09:38:35 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 09:38:35 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 09:38:35 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 09:38:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:38:35 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 09:39:02 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 09:39:02 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 09:39:12 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 09:39:12 [main] [32mINFO [m [ColdBackupScriptIsolatedST:109] Running restore procedure for infra-namespace/my-cluster-4c5c64ed
2022-04-06 09:40:16 [main] [32mINFO [m [Exec:417] Command: /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/cold-backup/run.sh restore -n infra-namespace -c my-cluster-4c5c64ed -s /home/ec2-user/strimzi-kafka-operator/systemtest/target/my-cluster-4c5c64ed.tgz -y
2022-04-06 09:40:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 09:40:16 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4c5c64ed will have desired state: Ready
2022-04-06 09:41:44 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4c5c64ed is in desired state: Ready
2022-04-06 09:41:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-4c5c64ed-kafka-0 -- /opt/kafka/bin/kafka-consumer-groups.sh --describe --bootstrap-server localhost:9092 --group my-group
2022-04-06 09:41:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 09:41:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-4c5c64ed-consumer in namespace infra-namespace
2022-04-06 09:41:47 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-4c5c64ed-consumer will be in active state
2022-04-06 09:41:48 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:my-cluster-4c5c64ed-consumer to finished
2022-04-06 09:41:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-4c5c64ed-consumer in namespace infra-namespace
2022-04-06 09:41:58 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-4c5c64ed-consumer will be in active state
2022-04-06 09:41:59 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:my-cluster-4c5c64ed-consumer to finished
2022-04-06 09:42:09 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 09:42:09 [main] [32mINFO [m [ResourceManager:348] Delete all resources for backupAndRestore
2022-04-06 09:42:09 [main] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-4c5c64ed-producer in namespace infra-namespace
2022-04-06 09:42:09 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-4c5c64ed in namespace infra-namespace
2022-04-06 09:42:09 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-4c5c64ed-consumer in namespace infra-namespace
2022-04-06 09:42:09 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-4c5c64ed-consumer in namespace infra-namespace
2022-04-06 09:42:09 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-4c5c64ed-producer in namespace infra-namespace
2022-04-06 09:42:09 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-4c5c64ed-consumer in namespace infra-namespace
2022-04-06 09:42:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 09:42:19 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST.backupAndRestore-FINISHED
2022-04-06 09:42:19 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 09:42:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 09:42:19 [main] [32mINFO [m [ResourceManager:346] In context ColdBackupScriptIsolatedST is everything deleted.
2022-04-06 09:42:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 581.32 s - in io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST
2022-04-06 09:42:19 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 09:42:44 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 09:42:44 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 09:42:44 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 09:42:44 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 09:42:44 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 09:42:44 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 09:42:44 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 09:42:44 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 09:42:44 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 09:42:44 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:42:44 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 09:42:44 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 09:42:44 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 09:42:44 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:42:44 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 09:42:44 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 09:42:44 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 09:42:44 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 09:42:44 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:42:44 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 09:42:44 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 09:42:44 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 09:42:44 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 09:42:44 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 09:42:44 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:42:44 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 09:42:44 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 09:42:44 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 09:42:44 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 09:42:54 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 09:43:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 09:43:09 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=30000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 09:43:09 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 09:43:09 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 09:43:10 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 09:43:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:43:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 09:43:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 09:43:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 09:43:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 09:43:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 09:43:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 09:43:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 09:43:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 09:43:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 09:43:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 09:43:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 09:43:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 09:43:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 09:43:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 09:43:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 09:43:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:43:10 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 09:43:10 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 09:43:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 09:43:10 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 09:43:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 09:43:10 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 09:43:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 09:43:10 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 09:43:10 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:43:10 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 09:43:10 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 09:43:10 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 09:43:10 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 09:43:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 09:43:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 09:43:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:43:10 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 09:43:41 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 09:43:41 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 09:43:51 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 09:43:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 09:43:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testRestoreOffsetsInConsumerGroup-STARTED
2022-04-06 09:43:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 09:43:51 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-120 for test case:testRestoreOffsetsInConsumerGroup
2022-04-06 09:43:51 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-120
2022-04-06 09:43:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-120
2022-04-06 09:43:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-120
2022-04-06 09:43:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c4b1f69e-source in namespace namespace-120
2022-04-06 09:43:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-06 09:43:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c4b1f69e-target in namespace namespace-120
2022-04-06 09:43:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-06 09:43:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c4b1f69e-source will have desired state: Ready
2022-04-06 09:45:14 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c4b1f69e-source is in desired state: Ready
2022-04-06 09:45:14 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c4b1f69e-target will have desired state: Ready
2022-04-06 09:45:14 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c4b1f69e-target is in desired state: Ready
2022-04-06 09:45:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-c4b1f69e-trg-src in namespace namespace-120
2022-04-06 09:45:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-06 09:45:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-c4b1f69e-src-trg in namespace namespace-120
2022-04-06 09:45:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-06 09:45:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic test-sync-offset-1061202162 in namespace namespace-120
2022-04-06 09:45:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-06 09:45:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-c4b1f69e-trg-src will have desired state: Ready
2022-04-06 09:46:27 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-c4b1f69e-trg-src is in desired state: Ready
2022-04-06 09:46:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-c4b1f69e-src-trg will have desired state: Ready
2022-04-06 09:46:27 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-c4b1f69e-src-trg is in desired state: Ready
2022-04-06 09:46:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: test-sync-offset-1061202162 will have desired state: Ready
2022-04-06 09:46:27 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: test-sync-offset-1061202162 is in desired state: Ready
2022-04-06 09:46:27 [main] [32mINFO [m [MirrorMaker2IsolatedST:1090] Send & receive 100 messages to/from Source cluster.
2022-04-06 09:46:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-producer-source-my-consumer-group-1981948834 in namespace namespace-120
2022-04-06 09:46:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-06 09:46:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-consumer-source-my-consumer-group-14425072 in namespace namespace-120
2022-04-06 09:46:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-06 09:46:27 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-producer-source-my-consumer-group-1981948834 will be in active state
2022-04-06 09:46:28 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-consumer-source-my-consumer-group-14425072 will be in active state
2022-04-06 09:46:28 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-producer-source-my-consumer-group-1981948834 to finished
2022-04-06 09:46:36 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-consumer-source-my-consumer-group-14425072 to finished
2022-04-06 09:46:41 [main] [32mINFO [m [MirrorMaker2IsolatedST:1098] Send 100 messages to Source cluster.
2022-04-06 09:46:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-producer-source-my-consumer-group-1981948834 in namespace namespace-120
2022-04-06 09:46:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-06 09:46:41 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-producer-source-my-consumer-group-1981948834 will be in active state
2022-04-06 09:46:42 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-producer-source-my-consumer-group-1981948834 to finished
2022-04-06 09:46:45 [main] [32mINFO [m [MirrorMaker2IsolatedST:1105] Wait 1 second as 'sync.group.offsets.interval.seconds=1'. As this is insignificant wait, we're skipping it
2022-04-06 09:46:45 [main] [32mINFO [m [MirrorMaker2IsolatedST:1107] Receive 100 messages from mirrored topic on Target cluster.
2022-04-06 09:46:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-consumer-target-my-consumer-group-495918796 in namespace namespace-120
2022-04-06 09:46:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-06 09:46:45 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-consumer-target-my-consumer-group-495918796 will be in active state
2022-04-06 09:46:46 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-consumer-target-my-consumer-group-495918796 to finished
2022-04-06 09:46:57 [main] [32mINFO [m [MirrorMaker2IsolatedST:1112] Send 50 messages to Source cluster
2022-04-06 09:46:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-producer-source-my-consumer-group-1981948834 in namespace namespace-120
2022-04-06 09:46:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-06 09:46:57 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-producer-source-my-consumer-group-1981948834 will be in active state
2022-04-06 09:46:58 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-producer-source-my-consumer-group-1981948834 to finished
2022-04-06 09:47:05 [main] [32mINFO [m [MirrorMaker2IsolatedST:1118] Wait 1 second as 'sync.group.offsets.interval.seconds=1'. As this is insignificant wait, we're skipping it
2022-04-06 09:47:05 [main] [32mINFO [m [MirrorMaker2IsolatedST:1119] Receive 10 msgs from source cluster
2022-04-06 09:47:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-consumer-source-my-consumer-group-14425072 in namespace namespace-120
2022-04-06 09:47:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-06 09:47:05 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-consumer-source-my-consumer-group-14425072 will be in active state
2022-04-06 09:47:06 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-consumer-source-my-consumer-group-14425072 to finished
2022-04-06 09:47:23 [main] [32mINFO [m [MirrorMaker2IsolatedST:1125] Wait 1 second as 'sync.group.offsets.interval.seconds=1'. As this is insignificant wait, we're skipping it
2022-04-06 09:47:23 [main] [32mINFO [m [MirrorMaker2IsolatedST:1127] Receive 40 msgs from mirrored topic on Target cluster
2022-04-06 09:47:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-consumer-target-my-consumer-group-495918796 in namespace namespace-120
2022-04-06 09:47:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-06 09:47:23 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-consumer-target-my-consumer-group-495918796 will be in active state
2022-04-06 09:47:24 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-consumer-target-my-consumer-group-495918796 to finished
2022-04-06 09:47:37 [main] [32mINFO [m [MirrorMaker2IsolatedST:1133] There should be no more messages to read. Try to consume at least 1 message. This client job should fail on timeout.
2022-04-06 09:47:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-consumer-target-my-consumer-group-495918796 in namespace namespace-120
2022-04-06 09:47:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-06 09:47:37 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-consumer-target-my-consumer-group-495918796 will be in active state
2022-04-06 09:47:38 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:mm2-consumer-target-my-consumer-group-495918796 to finish with failure.
2022-04-06 09:49:39 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
io.strimzi.test.WaitException: Timeout after 121000 ms waiting for Job did not finish within time limit (as expected).
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientTimeout(ClientUtils.java:91)
	at io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.lambda$testRestoreOffsetsInConsumerGroup$13(MirrorMaker2IsolatedST.java:1137)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:50)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:37)
	at org.junit.jupiter.api.Assertions.assertDoesNotThrow(Assertions.java:3135)
	at io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testRestoreOffsetsInConsumerGroup(MirrorMaker2IsolatedST.java:1137)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-06 09:49:39 [main] [32mINFO [m [ClientUtils:100] Client job 'mm2-consumer-target-my-consumer-group-495918796' finished with expected timeout.
2022-04-06 09:49:39 [main] [32mINFO [m [MirrorMaker2IsolatedST:1139] As it's Active-Active MM2 mode, there should be no more messages to read from Source cluster topic. This client job should fail on timeout.
2022-04-06 09:49:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-consumer-source-my-consumer-group-14425072 in namespace namespace-120
2022-04-06 09:49:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-06 09:49:39 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-consumer-source-my-consumer-group-14425072 will be in active state
2022-04-06 09:49:40 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:mm2-consumer-source-my-consumer-group-14425072 to finish with failure.
2022-04-06 09:51:41 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
io.strimzi.test.WaitException: Timeout after 121000 ms waiting for Job did not finish within time limit (as expected).
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientTimeout(ClientUtils.java:91)
	at io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.lambda$testRestoreOffsetsInConsumerGroup$14(MirrorMaker2IsolatedST.java:1143)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:50)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:37)
	at org.junit.jupiter.api.Assertions.assertDoesNotThrow(Assertions.java:3135)
	at io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testRestoreOffsetsInConsumerGroup(MirrorMaker2IsolatedST.java:1143)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-06 09:51:41 [main] [32mINFO [m [ClientUtils:100] Client job 'mm2-consumer-source-my-consumer-group-14425072' finished with expected timeout.
2022-04-06 09:51:41 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 09:51:41 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRestoreOffsetsInConsumerGroup
2022-04-06 09:51:41 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job mm2-consumer-target-my-consumer-group-495918796 in namespace namespace-120
2022-04-06 09:51:41 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job mm2-producer-source-my-consumer-group-1981948834 in namespace namespace-120
2022-04-06 09:51:41 [main] [32mINFO [m [ResourceManager:241] Delete of Job mm2-consumer-target-my-consumer-group-495918796 in namespace namespace-120
2022-04-06 09:51:41 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job mm2-consumer-target-my-consumer-group-495918796 in namespace namespace-120
2022-04-06 09:51:41 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c4b1f69e-target in namespace namespace-120
2022-04-06 09:51:41 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job mm2-consumer-source-my-consumer-group-14425072 in namespace namespace-120
2022-04-06 09:51:41 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic test-sync-offset-1061202162 in namespace namespace-120
2022-04-06 09:51:41 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job mm2-consumer-source-my-consumer-group-14425072 in namespace namespace-120
2022-04-06 09:51:41 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job mm2-producer-source-my-consumer-group-1981948834 in namespace namespace-120
2022-04-06 09:51:41 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job mm2-producer-source-my-consumer-group-1981948834 in namespace namespace-120
2022-04-06 09:51:41 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job mm2-consumer-source-my-consumer-group-14425072 in namespace namespace-120
2022-04-06 09:51:41 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-c4b1f69e-src-trg in namespace namespace-120
2022-04-06 09:51:41 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c4b1f69e-source in namespace namespace-120
2022-04-06 09:51:41 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-c4b1f69e-trg-src in namespace namespace-120
2022-04-06 09:52:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 09:52:01 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-120 for test case:testRestoreOffsetsInConsumerGroup
2022-04-06 09:52:45 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testRestoreOffsetsInConsumerGroup-FINISHED
2022-04-06 09:52:45 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 09:52:45 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 09:52:45 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2-STARTED
2022-04-06 09:52:45 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 09:52:45 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-121 for test case:testMirrorMaker2
2022-04-06 09:52:45 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-121
2022-04-06 09:52:45 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-121
2022-04-06 09:52:45 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-121
2022-04-06 09:52:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-926edd09-source in namespace namespace-121
2022-04-06 09:52:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-121
2022-04-06 09:52:45 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-926edd09-source will have desired state: Ready
2022-04-06 09:53:52 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-926edd09-source is in desired state: Ready
2022-04-06 09:53:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-926edd09-target in namespace namespace-121
2022-04-06 09:53:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-121
2022-04-06 09:53:52 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-926edd09-target will have desired state: Ready
2022-04-06 09:55:08 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-926edd09-target is in desired state: Ready
2022-04-06 09:55:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-1506066930 in namespace namespace-121
2022-04-06 09:55:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-121
2022-04-06 09:55:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-1506066930 will have desired state: Ready
2022-04-06 09:55:09 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-1506066930 is in desired state: Ready
2022-04-06 09:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-926edd09-kafka-clients in namespace namespace-121
2022-04-06 09:55:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-121
2022-04-06 09:55:19 [main] [32mINFO [m [MirrorMaker2IsolatedST:155] Sending messages to - topic availability-topic-source-my-topic-1198226442-216562328, cluster my-cluster-926edd09-source and message count of 100
2022-04-06 09:55:19 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5fbd7c9f, messages=[], arguments=[--max-messages, 100, --topic, availability-topic-source-my-topic-1198226442-216562328, --bootstrap-server, my-cluster-926edd09-source-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-926edd09-kafka-clients-5b99f8dff7-57x7m', podNamespace='namespace-121', bootstrapServer='my-cluster-926edd09-source-kafka-bootstrap.namespace-121.svc:9092', topicName='availability-topic-source-my-topic-1198226442-216562328', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3f1d50a3}
2022-04-06 09:55:19 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-926edd09-source-kafka-bootstrap.namespace-121.svc:9092:availability-topic-source-my-topic-1198226442-216562328 from pod my-cluster-926edd09-kafka-clients-5b99f8dff7-57x7m
2022-04-06 09:55:19 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-926edd09-kafka-clients-5b99f8dff7-57x7m -n namespace-121 -- /opt/kafka/producer.sh --max-messages 100 --topic availability-topic-source-my-topic-1198226442-216562328 --bootstrap-server my-cluster-926edd09-source-kafka-bootstrap.namespace-121.svc:9092
2022-04-06 09:55:22 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 09:55:22 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-06 09:55:22 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@12bc2000, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-500941363, --group-instance-id, instance251354497, --topic, availability-topic-source-my-topic-1198226442-216562328, --bootstrap-server, my-cluster-926edd09-source-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-926edd09-kafka-clients-5b99f8dff7-57x7m', podNamespace='namespace-121', bootstrapServer='my-cluster-926edd09-source-kafka-bootstrap.namespace-121.svc:9092', topicName='availability-topic-source-my-topic-1198226442-216562328', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-500941363', consumerInstanceId='instance251354497', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@47f1e815}
2022-04-06 09:55:22 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-926edd09-source-kafka-bootstrap.namespace-121.svc:9092#availability-topic-source-my-topic-1198226442-216562328 from pod my-cluster-926edd09-kafka-clients-5b99f8dff7-57x7m
2022-04-06 09:55:22 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-926edd09-kafka-clients-5b99f8dff7-57x7m -n namespace-121 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-500941363 --group-instance-id instance251354497 --topic availability-topic-source-my-topic-1198226442-216562328 --bootstrap-server my-cluster-926edd09-source-kafka-bootstrap.namespace-121.svc:9092
2022-04-06 09:55:27 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 09:55:27 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-06 09:55:27 [main] [32mINFO [m [MirrorMaker2IsolatedST:160] Setting topic to availability-topic-target-my-topic-1198226442-216562328, cluster to my-cluster-926edd09-target and changing consumer group
2022-04-06 09:55:27 [main] [32mINFO [m [MirrorMaker2IsolatedST:168] Sending messages to - topic availability-topic-target-my-topic-1198226442-216562328, cluster my-cluster-926edd09-target and message count of 100
2022-04-06 09:55:27 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@852ec45, messages=[], arguments=[--max-messages, 100, --topic, availability-topic-target-my-topic-1198226442-216562328, --bootstrap-server, my-cluster-926edd09-target-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-926edd09-kafka-clients-5b99f8dff7-57x7m', podNamespace='namespace-121', bootstrapServer='my-cluster-926edd09-target-kafka-bootstrap.namespace-121.svc:9092', topicName='availability-topic-target-my-topic-1198226442-216562328', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@26d1ff4c}
2022-04-06 09:55:27 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-926edd09-target-kafka-bootstrap.namespace-121.svc:9092:availability-topic-target-my-topic-1198226442-216562328 from pod my-cluster-926edd09-kafka-clients-5b99f8dff7-57x7m
2022-04-06 09:55:27 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-926edd09-kafka-clients-5b99f8dff7-57x7m -n namespace-121 -- /opt/kafka/producer.sh --max-messages 100 --topic availability-topic-target-my-topic-1198226442-216562328 --bootstrap-server my-cluster-926edd09-target-kafka-bootstrap.namespace-121.svc:9092
2022-04-06 09:55:30 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 09:55:30 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-06 09:55:30 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@33e4882f, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1668496857, --group-instance-id, instance340165060, --topic, availability-topic-target-my-topic-1198226442-216562328, --bootstrap-server, my-cluster-926edd09-target-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-926edd09-kafka-clients-5b99f8dff7-57x7m', podNamespace='namespace-121', bootstrapServer='my-cluster-926edd09-target-kafka-bootstrap.namespace-121.svc:9092', topicName='availability-topic-target-my-topic-1198226442-216562328', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1668496857', consumerInstanceId='instance340165060', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@40ab0c1a}
2022-04-06 09:55:30 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-926edd09-target-kafka-bootstrap.namespace-121.svc:9092#availability-topic-target-my-topic-1198226442-216562328 from pod my-cluster-926edd09-kafka-clients-5b99f8dff7-57x7m
2022-04-06 09:55:30 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-926edd09-kafka-clients-5b99f8dff7-57x7m -n namespace-121 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1668496857 --group-instance-id instance340165060 --topic availability-topic-target-my-topic-1198226442-216562328 --bootstrap-server my-cluster-926edd09-target-kafka-bootstrap.namespace-121.svc:9092
2022-04-06 09:55:36 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 09:55:36 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-06 09:55:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-926edd09 in namespace namespace-121
2022-04-06 09:55:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-121
2022-04-06 09:55:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-926edd09 will have desired state: Ready
2022-04-06 09:56:48 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-926edd09 is in desired state: Ready
2022-04-06 09:56:48 [main] [32mINFO [m [MirrorMaker2IsolatedST:183] Looks like the mirrormaker2 cluster my-cluster deployed OK
2022-04-06 09:56:48 [main] [32mINFO [m [MirrorMaker2IsolatedST:640] Verifying docker image names
2022-04-06 09:56:48 [main] [32mINFO [m [AbstractST:172] strimzi-cluster-operator
2022-04-06 09:56:48 [main] [32mINFO [m [MirrorMaker2IsolatedST:653] Docker images verified
2022-04-06 09:56:48 [main] [32mINFO [m [AbstractST:311] Verifying labels on pod type mirrormaker2
2022-04-06 09:56:48 [main] [32mINFO [m [AbstractST:315] Verifying labels for pod: my-cluster-926edd09-mirrormaker2-77964d685f-tkxdr
2022-04-06 09:56:48 [main] [32mINFO [m [AbstractST:356] Verifying labels for Kafka Connect Services
2022-04-06 09:56:48 [main] [32mINFO [m [AbstractST:362] Verifying labels for service my-cluster-926edd09-mirrormaker2-api
2022-04-06 09:56:48 [main] [32mINFO [m [AbstractST:384] Verifying labels for Config maps
2022-04-06 09:56:48 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-926edd09-mirrormaker2-config
2022-04-06 09:56:48 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-926edd09-source-entity-topic-operator-config
2022-04-06 09:56:48 [main] [32mINFO [m [AbstractST:407] CM my-cluster-926edd09-source-entity-topic-operator-config is not related to current test
2022-04-06 09:56:48 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-926edd09-source-entity-user-operator-config
2022-04-06 09:56:48 [main] [32mINFO [m [AbstractST:407] CM my-cluster-926edd09-source-entity-user-operator-config is not related to current test
2022-04-06 09:56:48 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-926edd09-source-kafka-config
2022-04-06 09:56:48 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-926edd09-source-zookeeper-config
2022-04-06 09:56:48 [main] [32mINFO [m [AbstractST:407] CM my-cluster-926edd09-source-zookeeper-config is not related to current test
2022-04-06 09:56:48 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-926edd09-target-entity-topic-operator-config
2022-04-06 09:56:48 [main] [32mINFO [m [AbstractST:407] CM my-cluster-926edd09-target-entity-topic-operator-config is not related to current test
2022-04-06 09:56:48 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-926edd09-target-entity-user-operator-config
2022-04-06 09:56:48 [main] [32mINFO [m [AbstractST:407] CM my-cluster-926edd09-target-entity-user-operator-config is not related to current test
2022-04-06 09:56:48 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-926edd09-target-kafka-config
2022-04-06 09:56:48 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-926edd09-target-zookeeper-config
2022-04-06 09:56:48 [main] [32mINFO [m [AbstractST:407] CM my-cluster-926edd09-target-zookeeper-config is not related to current test
2022-04-06 09:56:48 [main] [32mINFO [m [AbstractST:414] Verifying labels for Service Accounts
2022-04-06 09:56:48 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-926edd09-source-entity-operator
2022-04-06 09:56:48 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-926edd09-source-kafka
2022-04-06 09:56:48 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-926edd09-source-zookeeper
2022-04-06 09:56:48 [main] [32mINFO [m [MirrorMaker2IsolatedST:198] Setting topic to mirrormaker2-topic-example-1506066930, cluster to my-cluster-926edd09-source and changing consumer group
2022-04-06 09:56:48 [main] [32mINFO [m [MirrorMaker2IsolatedST:206] Sending messages to - topic mirrormaker2-topic-example-1506066930, cluster my-cluster-926edd09-source and message count of 100
2022-04-06 09:56:48 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@44e7068d, messages=[], arguments=[--max-messages, 100, --topic, mirrormaker2-topic-example-1506066930, --bootstrap-server, my-cluster-926edd09-source-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-926edd09-kafka-clients-5b99f8dff7-57x7m', podNamespace='namespace-121', bootstrapServer='my-cluster-926edd09-source-kafka-bootstrap.namespace-121.svc:9092', topicName='mirrormaker2-topic-example-1506066930', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7553fc7}
2022-04-06 09:56:48 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-926edd09-source-kafka-bootstrap.namespace-121.svc:9092:mirrormaker2-topic-example-1506066930 from pod my-cluster-926edd09-kafka-clients-5b99f8dff7-57x7m
2022-04-06 09:56:48 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-926edd09-kafka-clients-5b99f8dff7-57x7m -n namespace-121 -- /opt/kafka/producer.sh --max-messages 100 --topic mirrormaker2-topic-example-1506066930 --bootstrap-server my-cluster-926edd09-source-kafka-bootstrap.namespace-121.svc:9092
2022-04-06 09:56:50 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 09:56:50 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-06 09:56:50 [main] [32mINFO [m [MirrorMaker2IsolatedST:210] Consumer in source cluster and topic should receive 100 messages
2022-04-06 09:56:50 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@39131a54, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1650763647, --group-instance-id, instance797107821, --topic, mirrormaker2-topic-example-1506066930, --bootstrap-server, my-cluster-926edd09-source-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-926edd09-kafka-clients-5b99f8dff7-57x7m', podNamespace='namespace-121', bootstrapServer='my-cluster-926edd09-source-kafka-bootstrap.namespace-121.svc:9092', topicName='mirrormaker2-topic-example-1506066930', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1650763647', consumerInstanceId='instance797107821', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@45bcaf00}
2022-04-06 09:56:50 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-926edd09-source-kafka-bootstrap.namespace-121.svc:9092#mirrormaker2-topic-example-1506066930 from pod my-cluster-926edd09-kafka-clients-5b99f8dff7-57x7m
2022-04-06 09:56:50 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-926edd09-kafka-clients-5b99f8dff7-57x7m -n namespace-121 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1650763647 --group-instance-id instance797107821 --topic mirrormaker2-topic-example-1506066930 --bootstrap-server my-cluster-926edd09-source-kafka-bootstrap.namespace-121.svc:9092
2022-04-06 09:56:56 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 09:56:56 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-06 09:56:56 [main] [32mINFO [m [MirrorMaker2IsolatedST:214] Now setting topic to my-cluster-926edd09-source.mirrormaker2-topic-example-1506066930 and cluster to my-cluster-926edd09-target - the messages should be mirrored
2022-04-06 09:56:56 [main] [32mINFO [m [MirrorMaker2IsolatedST:222] Consumer in target cluster and topic should receive 100 messages
2022-04-06 09:56:56 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1b069719, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-330324817, --group-instance-id, instance377674472, --topic, my-cluster-926edd09-source.mirrormaker2-topic-example-1506066930, --bootstrap-server, my-cluster-926edd09-target-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-926edd09-kafka-clients-5b99f8dff7-57x7m', podNamespace='namespace-121', bootstrapServer='my-cluster-926edd09-target-kafka-bootstrap.namespace-121.svc:9092', topicName='my-cluster-926edd09-source.mirrormaker2-topic-example-1506066930', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-330324817', consumerInstanceId='instance377674472', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@38e9ea95}
2022-04-06 09:56:56 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-926edd09-target-kafka-bootstrap.namespace-121.svc:9092#my-cluster-926edd09-source.mirrormaker2-topic-example-1506066930 from pod my-cluster-926edd09-kafka-clients-5b99f8dff7-57x7m
2022-04-06 09:56:56 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-926edd09-kafka-clients-5b99f8dff7-57x7m -n namespace-121 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-330324817 --group-instance-id instance377674472 --topic my-cluster-926edd09-source.mirrormaker2-topic-example-1506066930 --bootstrap-server my-cluster-926edd09-target-kafka-bootstrap.namespace-121.svc:9092
2022-04-06 09:57:02 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 09:57:02 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-06 09:57:02 [main] [32mINFO [m [MirrorMaker2IsolatedST:227] Changing topic to my-cluster-926edd09-source.availability-topic-source-my-topic-1198226442-216562328
2022-04-06 09:57:02 [main] [32mINFO [m [MirrorMaker2IsolatedST:233] Check if mm2 mirror automatically created topic
2022-04-06 09:57:02 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1a029354, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-465442372, --group-instance-id, instance1020209948, --topic, my-cluster-926edd09-source.availability-topic-source-my-topic-1198226442-216562328, --bootstrap-server, my-cluster-926edd09-target-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-926edd09-kafka-clients-5b99f8dff7-57x7m', podNamespace='namespace-121', bootstrapServer='my-cluster-926edd09-target-kafka-bootstrap.namespace-121.svc:9092', topicName='my-cluster-926edd09-source.availability-topic-source-my-topic-1198226442-216562328', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-465442372', consumerInstanceId='instance1020209948', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3b62efd6}
2022-04-06 09:57:02 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-926edd09-target-kafka-bootstrap.namespace-121.svc:9092#my-cluster-926edd09-source.availability-topic-source-my-topic-1198226442-216562328 from pod my-cluster-926edd09-kafka-clients-5b99f8dff7-57x7m
2022-04-06 09:57:02 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-926edd09-kafka-clients-5b99f8dff7-57x7m -n namespace-121 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-465442372 --group-instance-id instance1020209948 --topic my-cluster-926edd09-source.availability-topic-source-my-topic-1198226442-216562328 --bootstrap-server my-cluster-926edd09-target-kafka-bootstrap.namespace-121.svc:9092
2022-04-06 09:57:07 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 09:57:07 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-06 09:57:07 [main] [32mINFO [m [MirrorMaker2IsolatedST:236] Mirrored successful
2022-04-06 09:57:07 [main] [32mINFO [m [KafkaTopicUtils:124] Waiting for KafkaTopic change my-cluster-926edd09-source.mirrormaker2-topic-example-1506066930
2022-04-06 09:57:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 09:57:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker2
2022-04-06 09:57:48 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-1506066930 in namespace namespace-121
2022-04-06 09:57:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-926edd09 in namespace namespace-121
2022-04-06 09:57:48 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-926edd09-kafka-clients in namespace namespace-121
2022-04-06 09:57:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-926edd09-source in namespace namespace-121
2022-04-06 09:57:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-926edd09-target in namespace namespace-121
2022-04-06 09:58:39 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 09:58:39 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-121 for test case:testMirrorMaker2
2022-04-06 09:58:44 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2-FINISHED
2022-04-06 09:58:44 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 09:58:44 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 09:58:44 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testKafkaMirrorMaker2ReflectsConnectorsState-STARTED
2022-04-06 09:58:44 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 09:58:44 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-122 for test case:testKafkaMirrorMaker2ReflectsConnectorsState
2022-04-06 09:58:44 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-122
2022-04-06 09:58:44 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-122
2022-04-06 09:58:44 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-122
2022-04-06 09:58:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c11fa357-source in namespace namespace-122
2022-04-06 09:58:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-122
2022-04-06 09:58:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c11fa357-target in namespace namespace-122
2022-04-06 09:58:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-122
2022-04-06 09:58:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c11fa357-source will have desired state: Ready
2022-04-06 09:59:48 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c11fa357-source is in desired state: Ready
2022-04-06 09:59:48 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c11fa357-target will have desired state: Ready
2022-04-06 09:59:58 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c11fa357-target is in desired state: Ready
2022-04-06 09:59:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-c11fa357 in namespace namespace-122
2022-04-06 09:59:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-122
2022-04-06 09:59:58 [main] [32mINFO [m [ResourceManager:481] Wait for KafkaMirrorMaker2: my-cluster-c11fa357 will contain desired status message: One or more connectors are in FAILED state
2022-04-06 10:01:18 [main] [32mINFO [m [ResourceManager:492] KafkaMirrorMaker2: my-cluster-c11fa357 contains desired message in status: One or more connectors are in FAILED state
2022-04-06 10:01:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-c11fa357 will have desired state: Ready
2022-04-06 10:01:19 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-c11fa357 is in desired state: Ready
2022-04-06 10:01:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 10:01:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaMirrorMaker2ReflectsConnectorsState
2022-04-06 10:01:19 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c11fa357-target in namespace namespace-122
2022-04-06 10:01:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-c11fa357 in namespace namespace-122
2022-04-06 10:01:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c11fa357-source in namespace namespace-122
2022-04-06 10:01:39 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 10:01:39 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-122 for test case:testKafkaMirrorMaker2ReflectsConnectorsState
2022-04-06 10:02:06 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testKafkaMirrorMaker2ReflectsConnectorsState-FINISHED
2022-04-06 10:02:06 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 10:02:06 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 10:02:06 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testKMM2RollAfterSecretsCertsUpdateTLS-STARTED
2022-04-06 10:02:06 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 10:02:06 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-123 for test case:testKMM2RollAfterSecretsCertsUpdateTLS
2022-04-06 10:02:06 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-123
2022-04-06 10:02:06 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-123
2022-04-06 10:02:06 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-123
2022-04-06 10:02:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-005e2201-source in namespace namespace-123
2022-04-06 10:02:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-06 10:02:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-005e2201-source will have desired state: Ready
2022-04-06 10:03:26 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-005e2201-source is in desired state: Ready
2022-04-06 10:03:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-005e2201-target in namespace namespace-123
2022-04-06 10:03:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-06 10:03:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-005e2201-target will have desired state: Ready
2022-04-06 10:04:44 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-005e2201-target is in desired state: Ready
2022-04-06 10:04:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-a-1730763932 in namespace namespace-123
2022-04-06 10:04:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-06 10:04:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-a-1730763932 will have desired state: Ready
2022-04-06 10:04:45 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-a-1730763932 is in desired state: Ready
2022-04-06 10:04:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-b-1065653241 in namespace namespace-123
2022-04-06 10:04:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-06 10:04:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-b-1065653241 will have desired state: Ready
2022-04-06 10:04:46 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-b-1065653241 is in desired state: Ready
2022-04-06 10:04:46 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-005e2201-my-user-source in namespace namespace-123
2022-04-06 10:04:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-06 10:04:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-005e2201-my-user-source will have desired state: Ready
2022-04-06 10:04:47 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-005e2201-my-user-source is in desired state: Ready
2022-04-06 10:04:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-005e2201-my-user-target in namespace namespace-123
2022-04-06 10:04:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-06 10:04:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-005e2201-my-user-target will have desired state: Ready
2022-04-06 10:04:48 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-005e2201-my-user-target is in desired state: Ready
2022-04-06 10:04:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b6cd335a-kafka-clients in namespace namespace-123
2022-04-06 10:04:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-06 10:04:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-917852214-535892768-test-1 in namespace namespace-123
2022-04-06 10:04:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-06 10:04:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-917852214-535892768-test-1 will have desired state: Ready
2022-04-06 10:05:00 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-917852214-535892768-test-1 is in desired state: Ready
2022-04-06 10:05:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-917852214-535892768-test-2 in namespace namespace-123
2022-04-06 10:05:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-06 10:05:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-917852214-535892768-test-2 will have desired state: Ready
2022-04-06 10:05:01 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-917852214-535892768-test-2 is in desired state: Ready
2022-04-06 10:05:01 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 10:05:01 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@78624986, messages=[], arguments=[--max-messages, 200, --topic, my-topic-917852214-535892768-test-2, --bootstrap-server, my-cluster-005e2201-target-kafka-bootstrap.namespace-123.svc:9093, USER=my_cluster_005e2201_my_user_target], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b6cd335a-kafka-clients-f78884489-qdsdn', podNamespace='namespace-123', bootstrapServer='my-cluster-005e2201-target-kafka-bootstrap.namespace-123.svc:9093', topicName='my-topic-917852214-535892768-test-2', maxMessages=200, kafkaUsername='my-cluster-005e2201-my-user-target', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@550fafc1}
2022-04-06 10:05:01 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-005e2201-target-kafka-bootstrap.namespace-123.svc:9093:my-topic-917852214-535892768-test-2 from pod my-cluster-b6cd335a-kafka-clients-f78884489-qdsdn
2022-04-06 10:05:01 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b6cd335a-kafka-clients-f78884489-qdsdn -n namespace-123 -- /opt/kafka/producer.sh --max-messages 200 --topic my-topic-917852214-535892768-test-2 --bootstrap-server my-cluster-005e2201-target-kafka-bootstrap.namespace-123.svc:9093 USER=my_cluster_005e2201_my_user_target
2022-04-06 10:05:04 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 10:05:04 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 10:05:04 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5d46b9b1, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-463097319, --group-instance-id, instance119152216, --topic, my-topic-917852214-535892768-test-2, --bootstrap-server, my-cluster-005e2201-target-kafka-bootstrap.namespace-123.svc:9093, USER=my_cluster_005e2201_my_user_target], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b6cd335a-kafka-clients-f78884489-qdsdn', podNamespace='namespace-123', bootstrapServer='my-cluster-005e2201-target-kafka-bootstrap.namespace-123.svc:9093', topicName='my-topic-917852214-535892768-test-2', maxMessages=200, kafkaUsername='my-cluster-005e2201-my-user-target', consumerGroupName='my-consumer-group-463097319', consumerInstanceId='instance119152216', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@759f7164}
2022-04-06 10:05:04 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-005e2201-target-kafka-bootstrap.namespace-123.svc:9093:my-topic-917852214-535892768-test-2 from pod my-cluster-b6cd335a-kafka-clients-f78884489-qdsdn
2022-04-06 10:05:04 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b6cd335a-kafka-clients-f78884489-qdsdn -n namespace-123 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-463097319 --group-instance-id instance119152216 --topic my-topic-917852214-535892768-test-2 --bootstrap-server my-cluster-005e2201-target-kafka-bootstrap.namespace-123.svc:9093 USER=my_cluster_005e2201_my_user_target
2022-04-06 10:05:11 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 10:05:11 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 10:05:11 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-005e2201 in namespace namespace-123
2022-04-06 10:05:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-06 10:05:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-005e2201 will have desired state: Ready
2022-04-06 10:06:22 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-005e2201 is in desired state: Ready
2022-04-06 10:06:22 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@572480b0, messages=[], arguments=[--max-messages, 200, --topic, mirrormaker2-topic-example-a-1730763932, --bootstrap-server, my-cluster-005e2201-source-kafka-bootstrap.namespace-123.svc:9093, USER=my_cluster_005e2201_my_user_source], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b6cd335a-kafka-clients-f78884489-qdsdn', podNamespace='namespace-123', bootstrapServer='my-cluster-005e2201-source-kafka-bootstrap.namespace-123.svc:9093', topicName='mirrormaker2-topic-example-a-1730763932', maxMessages=200, kafkaUsername='my-cluster-005e2201-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@790a7e47}
2022-04-06 10:06:22 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-005e2201-source-kafka-bootstrap.namespace-123.svc:9093:mirrormaker2-topic-example-a-1730763932 from pod my-cluster-b6cd335a-kafka-clients-f78884489-qdsdn
2022-04-06 10:06:22 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b6cd335a-kafka-clients-f78884489-qdsdn -n namespace-123 -- /opt/kafka/producer.sh --max-messages 200 --topic mirrormaker2-topic-example-a-1730763932 --bootstrap-server my-cluster-005e2201-source-kafka-bootstrap.namespace-123.svc:9093 USER=my_cluster_005e2201_my_user_source
2022-04-06 10:06:26 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 10:06:26 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 10:06:26 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4e278d0, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-463097319, --group-instance-id, instance1448962180, --topic, mirrormaker2-topic-example-a-1730763932, --bootstrap-server, my-cluster-005e2201-source-kafka-bootstrap.namespace-123.svc:9093, USER=my_cluster_005e2201_my_user_source], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b6cd335a-kafka-clients-f78884489-qdsdn', podNamespace='namespace-123', bootstrapServer='my-cluster-005e2201-source-kafka-bootstrap.namespace-123.svc:9093', topicName='mirrormaker2-topic-example-a-1730763932', maxMessages=200, kafkaUsername='my-cluster-005e2201-my-user-source', consumerGroupName='my-consumer-group-463097319', consumerInstanceId='instance1448962180', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2eb0d307}
2022-04-06 10:06:26 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-005e2201-source-kafka-bootstrap.namespace-123.svc:9093:mirrormaker2-topic-example-a-1730763932 from pod my-cluster-b6cd335a-kafka-clients-f78884489-qdsdn
2022-04-06 10:06:26 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b6cd335a-kafka-clients-f78884489-qdsdn -n namespace-123 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-463097319 --group-instance-id instance1448962180 --topic mirrormaker2-topic-example-a-1730763932 --bootstrap-server my-cluster-005e2201-source-kafka-bootstrap.namespace-123.svc:9093 USER=my_cluster_005e2201_my_user_source
2022-04-06 10:06:33 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 10:06:33 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 10:06:33 [main] [32mINFO [m [MirrorMaker2IsolatedST:1551] Consumer in target cluster and topic should receive 200 messages
2022-04-06 10:06:33 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@680f6ce7, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-463097319, --group-instance-id, instance1911995777, --topic, my-cluster-005e2201-source.mirrormaker2-topic-example-a-1730763932, --bootstrap-server, my-cluster-005e2201-target-kafka-bootstrap.namespace-123.svc:9093, USER=my_cluster_005e2201_my_user_target], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b6cd335a-kafka-clients-f78884489-qdsdn', podNamespace='namespace-123', bootstrapServer='my-cluster-005e2201-target-kafka-bootstrap.namespace-123.svc:9093', topicName='my-cluster-005e2201-source.mirrormaker2-topic-example-a-1730763932', maxMessages=200, kafkaUsername='my-cluster-005e2201-my-user-target', consumerGroupName='my-consumer-group-463097319', consumerInstanceId='instance1911995777', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@773059fc}
2022-04-06 10:06:33 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-005e2201-target-kafka-bootstrap.namespace-123.svc:9093:my-cluster-005e2201-source.mirrormaker2-topic-example-a-1730763932 from pod my-cluster-b6cd335a-kafka-clients-f78884489-qdsdn
2022-04-06 10:06:33 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b6cd335a-kafka-clients-f78884489-qdsdn -n namespace-123 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-463097319 --group-instance-id instance1911995777 --topic my-cluster-005e2201-source.mirrormaker2-topic-example-a-1730763932 --bootstrap-server my-cluster-005e2201-target-kafka-bootstrap.namespace-123.svc:9093 USER=my_cluster_005e2201_my_user_target
2022-04-06 10:06:40 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 10:06:40 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 10:06:40 [main] [32mINFO [m [MirrorMaker2IsolatedST:1553] Messages successfully mirrored
2022-04-06 10:06:40 [main] [32mINFO [m [MirrorMaker2IsolatedST:1567] Renew Clients CA secret for Source cluster via annotation
2022-04-06 10:06:40 [main] [32mINFO [m [SecretUtils:178] Annotating Secret:my-cluster-005e2201-source-clients-ca-cert with annotation strimzi.io/force-renew=true
2022-04-06 10:06:40 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-005e2201-source-kafka rolling update
2022-04-06 10:08:00 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-005e2201-source-kafka has been successfully rolled
2022-04-06 10:08:00 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-005e2201-source-kafka to be ready
2022-04-06 10:08:22 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-005e2201-mirrormaker2 rolling update
2022-04-06 10:08:22 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-005e2201-mirrormaker2 will be ready
2022-04-06 10:08:22 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-005e2201-mirrormaker2 is ready
2022-04-06 10:08:33 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-005e2201-mirrormaker2 rolling update finished
2022-04-06 10:08:33 [main] [32mINFO [m [MirrorMaker2IsolatedST:1573] Renew Clients CA secret for Target cluster via annotation
2022-04-06 10:08:33 [main] [32mINFO [m [SecretUtils:178] Annotating Secret:my-cluster-005e2201-target-clients-ca-cert with annotation strimzi.io/force-renew=true
2022-04-06 10:08:33 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-005e2201-target-kafka rolling update
2022-04-06 10:10:18 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-005e2201-target-kafka has been successfully rolled
2022-04-06 10:10:18 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-005e2201-target-kafka to be ready
2022-04-06 10:10:48 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-005e2201-mirrormaker2 rolling update
2022-04-06 10:12:08 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-005e2201-mirrormaker2 will be ready
2022-04-06 10:12:08 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-005e2201-mirrormaker2 is ready
2022-04-06 10:12:18 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-005e2201-mirrormaker2 rolling update finished
2022-04-06 10:12:18 [main] [32mINFO [m [MirrorMaker2IsolatedST:1579] Send and receive messages after clients certs were removed
2022-04-06 10:12:18 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@6445360b, messages=[], arguments=[--max-messages, 200, --topic, mirrormaker2-topic-example-a-1730763932, --bootstrap-server, my-cluster-005e2201-source-kafka-bootstrap.namespace-123.svc:9093, USER=my_cluster_005e2201_my_user_source], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b6cd335a-kafka-clients-f78884489-qdsdn', podNamespace='namespace-123', bootstrapServer='my-cluster-005e2201-source-kafka-bootstrap.namespace-123.svc:9093', topicName='mirrormaker2-topic-example-a-1730763932', maxMessages=200, kafkaUsername='my-cluster-005e2201-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6459526d}
2022-04-06 10:12:18 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-005e2201-source-kafka-bootstrap.namespace-123.svc:9093:mirrormaker2-topic-example-a-1730763932 from pod my-cluster-b6cd335a-kafka-clients-f78884489-qdsdn
2022-04-06 10:12:18 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b6cd335a-kafka-clients-f78884489-qdsdn -n namespace-123 -- /opt/kafka/producer.sh --max-messages 200 --topic mirrormaker2-topic-example-a-1730763932 --bootstrap-server my-cluster-005e2201-source-kafka-bootstrap.namespace-123.svc:9093 USER=my_cluster_005e2201_my_user_source
2022-04-06 10:12:22 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 10:12:22 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 10:12:22 [main] [32mINFO [m [MirrorMaker2IsolatedST:1595] Consumer in target cluster and topic should receive 200 messages
2022-04-06 10:12:22 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@242158a7, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-1632129353, --group-instance-id, instance1413801349, --topic, my-cluster-005e2201-source.mirrormaker2-topic-example-a-1730763932, --bootstrap-server, my-cluster-005e2201-target-kafka-bootstrap.namespace-123.svc:9093, USER=my_cluster_005e2201_my_user_target], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b6cd335a-kafka-clients-f78884489-qdsdn', podNamespace='namespace-123', bootstrapServer='my-cluster-005e2201-target-kafka-bootstrap.namespace-123.svc:9093', topicName='my-cluster-005e2201-source.mirrormaker2-topic-example-a-1730763932', maxMessages=200, kafkaUsername='my-cluster-005e2201-my-user-target', consumerGroupName='my-consumer-group-1632129353', consumerInstanceId='instance1413801349', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@ac5a9a8}
2022-04-06 10:12:22 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-005e2201-target-kafka-bootstrap.namespace-123.svc:9093:my-cluster-005e2201-source.mirrormaker2-topic-example-a-1730763932 from pod my-cluster-b6cd335a-kafka-clients-f78884489-qdsdn
2022-04-06 10:12:22 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b6cd335a-kafka-clients-f78884489-qdsdn -n namespace-123 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-1632129353 --group-instance-id instance1413801349 --topic my-cluster-005e2201-source.mirrormaker2-topic-example-a-1730763932 --bootstrap-server my-cluster-005e2201-target-kafka-bootstrap.namespace-123.svc:9093 USER=my_cluster_005e2201_my_user_target
2022-04-06 10:12:29 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 10:12:29 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 10:12:29 [main] [32mINFO [m [MirrorMaker2IsolatedST:1597] Messages successfully mirrored
2022-04-06 10:12:29 [main] [32mINFO [m [MirrorMaker2IsolatedST:1599] Renew Cluster CA secret for Source clusters via annotation
2022-04-06 10:12:29 [main] [32mINFO [m [SecretUtils:178] Annotating Secret:my-cluster-005e2201-source-cluster-ca-cert with annotation strimzi.io/force-renew=true
2022-04-06 10:12:29 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-005e2201-source-zookeeper rolling update
2022-04-06 10:13:34 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-005e2201-source-zookeeper has been successfully rolled
2022-04-06 10:13:34 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-005e2201-source-zookeeper to be ready
2022-04-06 10:14:09 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-005e2201-source-kafka rolling update
2022-04-06 10:14:59 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-005e2201-source-kafka has been successfully rolled
2022-04-06 10:14:59 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-005e2201-source-kafka to be ready
2022-04-06 10:15:28 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-005e2201-source-entity-operator rolling update
2022-04-06 10:15:28 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-005e2201-source-entity-operator will be ready
2022-04-06 10:16:15 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-005e2201-source-entity-operator is ready
2022-04-06 10:16:25 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-005e2201-source-entity-operator rolling update finished
2022-04-06 10:16:25 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-005e2201-mirrormaker2 rolling update
2022-04-06 10:16:25 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-005e2201-mirrormaker2 will be ready
2022-04-06 10:16:25 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-005e2201-mirrormaker2 is ready
2022-04-06 10:16:35 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-005e2201-mirrormaker2 rolling update finished
2022-04-06 10:16:35 [main] [32mINFO [m [MirrorMaker2IsolatedST:1607] Renew Cluster CA secret for Target clusters via annotation
2022-04-06 10:16:35 [main] [32mINFO [m [SecretUtils:178] Annotating Secret:my-cluster-005e2201-target-cluster-ca-cert with annotation strimzi.io/force-renew=true
2022-04-06 10:16:35 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-005e2201-target-zookeeper rolling update
2022-04-06 10:17:50 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-005e2201-target-zookeeper has been successfully rolled
2022-04-06 10:17:50 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-005e2201-target-zookeeper to be ready
2022-04-06 10:18:23 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-005e2201-target-kafka rolling update
2022-04-06 10:19:28 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-005e2201-target-kafka has been successfully rolled
2022-04-06 10:19:28 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-005e2201-target-kafka to be ready
2022-04-06 10:19:56 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-005e2201-target-entity-operator rolling update
2022-04-06 10:19:56 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-005e2201-target-entity-operator will be ready
2022-04-06 10:21:20 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-005e2201-target-entity-operator is ready
2022-04-06 10:21:30 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-005e2201-target-entity-operator rolling update finished
2022-04-06 10:21:30 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-005e2201-mirrormaker2 rolling update
2022-04-06 10:21:30 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-005e2201-mirrormaker2 will be ready
2022-04-06 10:21:30 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-005e2201-mirrormaker2 is ready
2022-04-06 10:21:40 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-005e2201-mirrormaker2 rolling update finished
2022-04-06 10:21:40 [main] [32mINFO [m [MirrorMaker2IsolatedST:1615] Send and receive messages after clients certs were removed
2022-04-06 10:21:40 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5025e79f, messages=[], arguments=[--max-messages, 200, --topic, mirrormaker2-topic-example-b-1065653241, --bootstrap-server, my-cluster-005e2201-source-kafka-bootstrap.namespace-123.svc:9093, USER=my_cluster_005e2201_my_user_source], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b6cd335a-kafka-clients-f78884489-qdsdn', podNamespace='namespace-123', bootstrapServer='my-cluster-005e2201-source-kafka-bootstrap.namespace-123.svc:9093', topicName='mirrormaker2-topic-example-b-1065653241', maxMessages=200, kafkaUsername='my-cluster-005e2201-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2f765d5d}
2022-04-06 10:21:40 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-005e2201-source-kafka-bootstrap.namespace-123.svc:9093:mirrormaker2-topic-example-b-1065653241 from pod my-cluster-b6cd335a-kafka-clients-f78884489-qdsdn
2022-04-06 10:21:40 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b6cd335a-kafka-clients-f78884489-qdsdn -n namespace-123 -- /opt/kafka/producer.sh --max-messages 200 --topic mirrormaker2-topic-example-b-1065653241 --bootstrap-server my-cluster-005e2201-source-kafka-bootstrap.namespace-123.svc:9093 USER=my_cluster_005e2201_my_user_source
2022-04-06 10:21:43 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 10:21:43 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 10:21:43 [main] [32mINFO [m [MirrorMaker2IsolatedST:1631] Consumer in target cluster and topic should receive 200 messages
2022-04-06 10:21:43 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2da5b832, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-1411480299, --group-instance-id, instance1280895466, --topic, my-cluster-005e2201-source.mirrormaker2-topic-example-b-1065653241, --bootstrap-server, my-cluster-005e2201-target-kafka-bootstrap.namespace-123.svc:9093, USER=my_cluster_005e2201_my_user_target], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b6cd335a-kafka-clients-f78884489-qdsdn', podNamespace='namespace-123', bootstrapServer='my-cluster-005e2201-target-kafka-bootstrap.namespace-123.svc:9093', topicName='my-cluster-005e2201-source.mirrormaker2-topic-example-b-1065653241', maxMessages=200, kafkaUsername='my-cluster-005e2201-my-user-target', consumerGroupName='my-consumer-group-1411480299', consumerInstanceId='instance1280895466', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@302497de}
2022-04-06 10:21:43 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-005e2201-target-kafka-bootstrap.namespace-123.svc:9093:my-cluster-005e2201-source.mirrormaker2-topic-example-b-1065653241 from pod my-cluster-b6cd335a-kafka-clients-f78884489-qdsdn
2022-04-06 10:21:43 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b6cd335a-kafka-clients-f78884489-qdsdn -n namespace-123 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-1411480299 --group-instance-id instance1280895466 --topic my-cluster-005e2201-source.mirrormaker2-topic-example-b-1065653241 --bootstrap-server my-cluster-005e2201-target-kafka-bootstrap.namespace-123.svc:9093 USER=my_cluster_005e2201_my_user_target
2022-04-06 10:21:51 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 10:21:51 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 10:21:51 [main] [32mINFO [m [MirrorMaker2IsolatedST:1633] Messages successfully mirrored
2022-04-06 10:21:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 10:21:51 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKMM2RollAfterSecretsCertsUpdateTLS
2022-04-06 10:21:51 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-917852214-535892768-test-2 in namespace namespace-123
2022-04-06 10:21:51 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-917852214-535892768-test-1 in namespace namespace-123
2022-04-06 10:21:51 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b6cd335a-kafka-clients in namespace namespace-123
2022-04-06 10:21:51 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-005e2201 in namespace namespace-123
2022-04-06 10:21:51 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-005e2201-target in namespace namespace-123
2022-04-06 10:21:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-005e2201-my-user-target in namespace namespace-123
2022-04-06 10:21:51 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-a-1730763932 in namespace namespace-123
2022-04-06 10:21:51 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-005e2201-my-user-source in namespace namespace-123
2022-04-06 10:22:01 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-005e2201-source in namespace namespace-123
2022-04-06 10:22:01 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-b-1065653241 in namespace namespace-123
2022-04-06 10:22:41 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 10:22:41 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-123 for test case:testKMM2RollAfterSecretsCertsUpdateTLS
2022-04-06 10:22:47 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testKMM2RollAfterSecretsCertsUpdateTLS-FINISHED
2022-04-06 10:22:47 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 10:22:47 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 10:22:47 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testStrimziIdentityReplicationPolicy-STARTED
2022-04-06 10:22:47 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 10:22:47 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-124 for test case:testStrimziIdentityReplicationPolicy
2022-04-06 10:22:47 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-124
2022-04-06 10:22:48 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-124
2022-04-06 10:22:48 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-124
2022-04-06 10:22:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-bdaf0800-source in namespace namespace-124
2022-04-06 10:22:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-124
2022-04-06 10:22:48 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-bdaf0800-source will have desired state: Ready
2022-04-06 10:24:00 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-bdaf0800-source is in desired state: Ready
2022-04-06 10:24:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-bdaf0800-target in namespace namespace-124
2022-04-06 10:24:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-124
2022-04-06 10:24:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-bdaf0800-target will have desired state: Ready
2022-04-06 10:25:05 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-bdaf0800-target is in desired state: Ready
2022-04-06 10:25:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-cluster-bdaf0800 in namespace namespace-124
2022-04-06 10:25:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-124
2022-04-06 10:25:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-cluster-bdaf0800 will have desired state: Ready
2022-04-06 10:25:06 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-cluster-bdaf0800 is in desired state: Ready
2022-04-06 10:25:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-bdaf0800-kafka-clients in namespace namespace-124
2022-04-06 10:25:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-124
2022-04-06 10:25:16 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-bdaf0800 in namespace namespace-124
2022-04-06 10:25:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-124
2022-04-06 10:25:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-bdaf0800 will have desired state: Ready
2022-04-06 10:26:26 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-bdaf0800 is in desired state: Ready
2022-04-06 10:26:26 [main] [32mINFO [m [MirrorMaker2IsolatedST:902] Sending and receiving messages via my-cluster-bdaf0800-source
2022-04-06 10:26:26 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 10:26:26 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1f2650e8, messages=[], arguments=[--max-messages, 100, --topic, my-cluster-bdaf0800, --bootstrap-server, my-cluster-bdaf0800-source-kafka-bootstrap.namespace-124.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-bdaf0800-kafka-clients-865c8b4c5b-2bdw6', podNamespace='namespace-124', bootstrapServer='my-cluster-bdaf0800-source-kafka-bootstrap.namespace-124.svc:9092', topicName='my-cluster-bdaf0800', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7249bb99}
2022-04-06 10:26:26 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-bdaf0800-source-kafka-bootstrap.namespace-124.svc:9092:my-cluster-bdaf0800 from pod my-cluster-bdaf0800-kafka-clients-865c8b4c5b-2bdw6
2022-04-06 10:26:26 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-bdaf0800-kafka-clients-865c8b4c5b-2bdw6 -n namespace-124 -- /opt/kafka/producer.sh --max-messages 100 --topic my-cluster-bdaf0800 --bootstrap-server my-cluster-bdaf0800-source-kafka-bootstrap.namespace-124.svc:9092
2022-04-06 10:26:29 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 10:26:29 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-06 10:26:29 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7acc0f2b, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1935446232, --group-instance-id, instance50394990, --topic, my-cluster-bdaf0800, --bootstrap-server, my-cluster-bdaf0800-source-kafka-bootstrap.namespace-124.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-bdaf0800-kafka-clients-865c8b4c5b-2bdw6', podNamespace='namespace-124', bootstrapServer='my-cluster-bdaf0800-source-kafka-bootstrap.namespace-124.svc:9092', topicName='my-cluster-bdaf0800', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1935446232', consumerInstanceId='instance50394990', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@45e6e17d}
2022-04-06 10:26:29 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-bdaf0800-source-kafka-bootstrap.namespace-124.svc:9092#my-cluster-bdaf0800 from pod my-cluster-bdaf0800-kafka-clients-865c8b4c5b-2bdw6
2022-04-06 10:26:29 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-bdaf0800-kafka-clients-865c8b4c5b-2bdw6 -n namespace-124 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1935446232 --group-instance-id instance50394990 --topic my-cluster-bdaf0800 --bootstrap-server my-cluster-bdaf0800-source-kafka-bootstrap.namespace-124.svc:9092
2022-04-06 10:26:34 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 10:26:34 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-06 10:26:34 [main] [32mINFO [m [MirrorMaker2IsolatedST:917] Changing to my-cluster-bdaf0800-target and will try to receive messages
2022-04-06 10:26:34 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4024116b, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1935446232, --group-instance-id, instance594105488, --topic, my-cluster-bdaf0800, --bootstrap-server, my-cluster-bdaf0800-target-kafka-bootstrap.namespace-124.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-bdaf0800-kafka-clients-865c8b4c5b-2bdw6', podNamespace='namespace-124', bootstrapServer='my-cluster-bdaf0800-target-kafka-bootstrap.namespace-124.svc:9092', topicName='my-cluster-bdaf0800', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1935446232', consumerInstanceId='instance594105488', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5740a18a}
2022-04-06 10:26:34 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-bdaf0800-target-kafka-bootstrap.namespace-124.svc:9092#my-cluster-bdaf0800 from pod my-cluster-bdaf0800-kafka-clients-865c8b4c5b-2bdw6
2022-04-06 10:26:34 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-bdaf0800-kafka-clients-865c8b4c5b-2bdw6 -n namespace-124 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1935446232 --group-instance-id instance594105488 --topic my-cluster-bdaf0800 --bootstrap-server my-cluster-bdaf0800-target-kafka-bootstrap.namespace-124.svc:9092
2022-04-06 10:26:40 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 10:26:40 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-06 10:26:40 [main] [32mINFO [m [MirrorMaker2IsolatedST:925] Checking if the mirrored topic name is same as the original one
2022-04-06 10:26:43 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-124 exec my-cluster-bdaf0800-target-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-06 10:26:43 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 10:26:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-124 exec my-cluster-bdaf0800-target-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic my-cluster-bdaf0800
2022-04-06 10:26:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 10:26:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 10:26:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testStrimziIdentityReplicationPolicy
2022-04-06 10:26:45 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-cluster-bdaf0800 in namespace namespace-124
2022-04-06 10:26:45 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-bdaf0800-kafka-clients in namespace namespace-124
2022-04-06 10:26:45 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-bdaf0800 in namespace namespace-124
2022-04-06 10:26:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-bdaf0800-source in namespace namespace-124
2022-04-06 10:26:45 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-bdaf0800-target in namespace namespace-124
2022-04-06 10:27:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 10:27:35 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-124 for test case:testStrimziIdentityReplicationPolicy
2022-04-06 10:27:41 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testStrimziIdentityReplicationPolicy-FINISHED
2022-04-06 10:27:41 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 10:27:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 10:27:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testScaleMirrorMaker2Subresource-STARTED
2022-04-06 10:27:41 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 10:27:41 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-125 for test case:testScaleMirrorMaker2Subresource
2022-04-06 10:27:41 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-125
2022-04-06 10:27:41 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-125
2022-04-06 10:27:41 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-125
2022-04-06 10:27:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0f2fbf6c-source in namespace namespace-125
2022-04-06 10:27:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-125
2022-04-06 10:27:41 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0f2fbf6c-source will have desired state: Ready
2022-04-06 10:28:49 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0f2fbf6c-source is in desired state: Ready
2022-04-06 10:28:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0f2fbf6c-target in namespace namespace-125
2022-04-06 10:28:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-125
2022-04-06 10:28:49 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0f2fbf6c-target will have desired state: Ready
2022-04-06 10:29:59 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0f2fbf6c-target is in desired state: Ready
2022-04-06 10:29:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-0f2fbf6c in namespace namespace-125
2022-04-06 10:29:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-125
2022-04-06 10:29:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-0f2fbf6c will have desired state: Ready
2022-04-06 10:31:18 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-0f2fbf6c is in desired state: Ready
2022-04-06 10:31:18 [main] [32mINFO [m [MirrorMaker2IsolatedST:675] -------> Scaling KafkaMirrorMaker2 subresource <-------
2022-04-06 10:31:18 [main] [32mINFO [m [MirrorMaker2IsolatedST:676] Scaling subresource replicas to 4
2022-04-06 10:31:18 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-0f2fbf6c-mirrormaker2 will be ready
2022-04-06 10:31:18 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-0f2fbf6c-mirrormaker2 is ready
2022-04-06 10:31:18 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 4 Pod(s) of Deployment my-cluster-0f2fbf6c-mirrormaker2 to be ready
2022-04-06 10:32:35 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-0f2fbf6c-mirrormaker2 is ready
2022-04-06 10:32:35 [main] [32mINFO [m [MirrorMaker2IsolatedST:680] Check if replicas is set to 4, naming prefix should be same and observed generation higher
2022-04-06 10:32:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 10:32:35 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleMirrorMaker2Subresource
2022-04-06 10:32:35 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0f2fbf6c-target in namespace namespace-125
2022-04-06 10:32:35 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-0f2fbf6c in namespace namespace-125
2022-04-06 10:32:35 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0f2fbf6c-source in namespace namespace-125
2022-04-06 10:32:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 10:32:55 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-125 for test case:testScaleMirrorMaker2Subresource
2022-04-06 10:33:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testScaleMirrorMaker2Subresource-FINISHED
2022-04-06 10:33:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 10:33:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 10:33:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testIdentityReplicationPolicy-STARTED
2022-04-06 10:33:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 10:33:22 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-126 for test case:testIdentityReplicationPolicy
2022-04-06 10:33:22 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-126
2022-04-06 10:33:22 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-126
2022-04-06 10:33:22 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-126
2022-04-06 10:33:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1aaebf57-source in namespace namespace-126
2022-04-06 10:33:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-126
2022-04-06 10:33:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1aaebf57-source will have desired state: Ready
2022-04-06 10:34:36 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1aaebf57-source is in desired state: Ready
2022-04-06 10:34:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1aaebf57-target in namespace namespace-126
2022-04-06 10:34:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-126
2022-04-06 10:34:36 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1aaebf57-target will have desired state: Ready
2022-04-06 10:35:46 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1aaebf57-target is in desired state: Ready
2022-04-06 10:35:46 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-cluster-1aaebf57 in namespace namespace-126
2022-04-06 10:35:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-126
2022-04-06 10:35:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-cluster-1aaebf57 will have desired state: Ready
2022-04-06 10:35:47 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-cluster-1aaebf57 is in desired state: Ready
2022-04-06 10:35:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-1aaebf57-kafka-clients in namespace namespace-126
2022-04-06 10:35:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-126
2022-04-06 10:35:57 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-1aaebf57 in namespace namespace-126
2022-04-06 10:35:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-126
2022-04-06 10:35:57 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-1aaebf57 will have desired state: Ready
2022-04-06 10:37:18 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-1aaebf57 is in desired state: Ready
2022-04-06 10:37:18 [main] [32mINFO [m [MirrorMaker2IsolatedST:833] Sending and receiving messages via my-cluster-1aaebf57-source
2022-04-06 10:37:18 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 10:37:18 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@539b166, messages=[], arguments=[--max-messages, 100, --topic, my-cluster-1aaebf57, --bootstrap-server, my-cluster-1aaebf57-source-kafka-bootstrap.namespace-126.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-1aaebf57-kafka-clients-648cc95758-wnt68', podNamespace='namespace-126', bootstrapServer='my-cluster-1aaebf57-source-kafka-bootstrap.namespace-126.svc:9092', topicName='my-cluster-1aaebf57', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@51f19268}
2022-04-06 10:37:18 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-1aaebf57-source-kafka-bootstrap.namespace-126.svc:9092:my-cluster-1aaebf57 from pod my-cluster-1aaebf57-kafka-clients-648cc95758-wnt68
2022-04-06 10:37:18 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1aaebf57-kafka-clients-648cc95758-wnt68 -n namespace-126 -- /opt/kafka/producer.sh --max-messages 100 --topic my-cluster-1aaebf57 --bootstrap-server my-cluster-1aaebf57-source-kafka-bootstrap.namespace-126.svc:9092
2022-04-06 10:37:21 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 10:37:21 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-06 10:37:21 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1b4ab2ff, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-2008753600, --group-instance-id, instance1587016339, --topic, my-cluster-1aaebf57, --bootstrap-server, my-cluster-1aaebf57-source-kafka-bootstrap.namespace-126.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-1aaebf57-kafka-clients-648cc95758-wnt68', podNamespace='namespace-126', bootstrapServer='my-cluster-1aaebf57-source-kafka-bootstrap.namespace-126.svc:9092', topicName='my-cluster-1aaebf57', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-2008753600', consumerInstanceId='instance1587016339', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@46f50a9b}
2022-04-06 10:37:21 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-1aaebf57-source-kafka-bootstrap.namespace-126.svc:9092#my-cluster-1aaebf57 from pod my-cluster-1aaebf57-kafka-clients-648cc95758-wnt68
2022-04-06 10:37:21 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1aaebf57-kafka-clients-648cc95758-wnt68 -n namespace-126 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-2008753600 --group-instance-id instance1587016339 --topic my-cluster-1aaebf57 --bootstrap-server my-cluster-1aaebf57-source-kafka-bootstrap.namespace-126.svc:9092
2022-04-06 10:37:26 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 10:37:26 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-06 10:37:26 [main] [32mINFO [m [MirrorMaker2IsolatedST:848] Changing to my-cluster-1aaebf57-target and will try to receive messages
2022-04-06 10:37:26 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1cedc483, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-2008753600, --group-instance-id, instance1873363782, --topic, my-cluster-1aaebf57, --bootstrap-server, my-cluster-1aaebf57-target-kafka-bootstrap.namespace-126.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-1aaebf57-kafka-clients-648cc95758-wnt68', podNamespace='namespace-126', bootstrapServer='my-cluster-1aaebf57-target-kafka-bootstrap.namespace-126.svc:9092', topicName='my-cluster-1aaebf57', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-2008753600', consumerInstanceId='instance1873363782', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@53309271}
2022-04-06 10:37:26 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-1aaebf57-target-kafka-bootstrap.namespace-126.svc:9092#my-cluster-1aaebf57 from pod my-cluster-1aaebf57-kafka-clients-648cc95758-wnt68
2022-04-06 10:37:26 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1aaebf57-kafka-clients-648cc95758-wnt68 -n namespace-126 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-2008753600 --group-instance-id instance1873363782 --topic my-cluster-1aaebf57 --bootstrap-server my-cluster-1aaebf57-target-kafka-bootstrap.namespace-126.svc:9092
2022-04-06 10:37:32 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 10:37:32 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-06 10:37:32 [main] [32mINFO [m [MirrorMaker2IsolatedST:856] Checking if the mirrored topic name is same as the original one
2022-04-06 10:37:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-126 exec my-cluster-1aaebf57-target-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-06 10:37:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 10:37:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-126 exec my-cluster-1aaebf57-target-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic my-cluster-1aaebf57
2022-04-06 10:37:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 10:37:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 10:37:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testIdentityReplicationPolicy
2022-04-06 10:37:37 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-cluster-1aaebf57 in namespace namespace-126
2022-04-06 10:37:37 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1aaebf57-source in namespace namespace-126
2022-04-06 10:37:37 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-1aaebf57 in namespace namespace-126
2022-04-06 10:37:37 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-1aaebf57-kafka-clients in namespace namespace-126
2022-04-06 10:37:37 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1aaebf57-target in namespace namespace-126
2022-04-06 10:38:37 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 10:38:37 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-126 for test case:testIdentityReplicationPolicy
2022-04-06 10:38:43 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testIdentityReplicationPolicy-FINISHED
2022-04-06 10:38:43 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 10:38:43 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 10:38:43 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testKMM2RollAfterSecretsCertsUpdateScramsha-STARTED
2022-04-06 10:38:43 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 10:38:43 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-127 for test case:testKMM2RollAfterSecretsCertsUpdateScramsha
2022-04-06 10:38:43 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-127
2022-04-06 10:38:43 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-127
2022-04-06 10:38:43 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-127
2022-04-06 10:38:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7f0ba685-source in namespace namespace-127
2022-04-06 10:38:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-06 10:38:43 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7f0ba685-source will have desired state: Ready
2022-04-06 10:39:51 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7f0ba685-source is in desired state: Ready
2022-04-06 10:39:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7f0ba685-target in namespace namespace-127
2022-04-06 10:39:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-06 10:39:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7f0ba685-target will have desired state: Ready
2022-04-06 10:41:03 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7f0ba685-target is in desired state: Ready
2022-04-06 10:41:03 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-a-1457881823 in namespace namespace-127
2022-04-06 10:41:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-06 10:41:03 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-b-2116282178 in namespace namespace-127
2022-04-06 10:41:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-06 10:41:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-a-1457881823 will have desired state: Ready
2022-04-06 10:41:04 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-a-1457881823 is in desired state: Ready
2022-04-06 10:41:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-b-2116282178 will have desired state: Ready
2022-04-06 10:41:04 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-b-2116282178 is in desired state: Ready
2022-04-06 10:41:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-7f0ba685-my-user-source in namespace namespace-127
2022-04-06 10:41:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-06 10:41:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-7f0ba685-my-user-target in namespace namespace-127
2022-04-06 10:41:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-06 10:41:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-7f0ba685-my-user-source will have desired state: Ready
2022-04-06 10:41:05 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-7f0ba685-my-user-source is in desired state: Ready
2022-04-06 10:41:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-7f0ba685-my-user-target will have desired state: Ready
2022-04-06 10:41:05 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-7f0ba685-my-user-target is in desired state: Ready
2022-04-06 10:41:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-7f0ba685-kafka-clients in namespace namespace-127
2022-04-06 10:41:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-06 10:41:06 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7f0ba685-kafka-clients will be ready
2022-04-06 10:41:08 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7f0ba685-kafka-clients is ready
2022-04-06 10:41:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-7f0ba685 in namespace namespace-127
2022-04-06 10:41:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-06 10:41:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-7f0ba685 will have desired state: Ready
2022-04-06 10:42:20 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-7f0ba685 is in desired state: Ready
2022-04-06 10:42:20 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 10:42:20 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@18c89493, messages=[], arguments=[--max-messages, 200, --topic, mirrormaker2-topic-example-a-1457881823, --bootstrap-server, my-cluster-7f0ba685-source-kafka-bootstrap.namespace-127.svc:9093, USER=my_cluster_7f0ba685_my_user_source], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-7f0ba685-kafka-clients-7665ffdbd6-kxghd', podNamespace='namespace-127', bootstrapServer='my-cluster-7f0ba685-source-kafka-bootstrap.namespace-127.svc:9093', topicName='mirrormaker2-topic-example-a-1457881823', maxMessages=200, kafkaUsername='my-cluster-7f0ba685-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7f6fc566}
2022-04-06 10:42:20 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-7f0ba685-source-kafka-bootstrap.namespace-127.svc:9093:mirrormaker2-topic-example-a-1457881823 from pod my-cluster-7f0ba685-kafka-clients-7665ffdbd6-kxghd
2022-04-06 10:42:20 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7f0ba685-kafka-clients-7665ffdbd6-kxghd -n namespace-127 -- /opt/kafka/producer.sh --max-messages 200 --topic mirrormaker2-topic-example-a-1457881823 --bootstrap-server my-cluster-7f0ba685-source-kafka-bootstrap.namespace-127.svc:9093 USER=my_cluster_7f0ba685_my_user_source
2022-04-06 10:42:23 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 10:42:23 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 10:42:23 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@26c67da7, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-545551126, --group-instance-id, instance1279759004, --topic, mirrormaker2-topic-example-a-1457881823, --bootstrap-server, my-cluster-7f0ba685-source-kafka-bootstrap.namespace-127.svc:9093, USER=my_cluster_7f0ba685_my_user_source], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-7f0ba685-kafka-clients-7665ffdbd6-kxghd', podNamespace='namespace-127', bootstrapServer='my-cluster-7f0ba685-source-kafka-bootstrap.namespace-127.svc:9093', topicName='mirrormaker2-topic-example-a-1457881823', maxMessages=200, kafkaUsername='my-cluster-7f0ba685-my-user-source', consumerGroupName='my-consumer-group-545551126', consumerInstanceId='instance1279759004', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2783c8c4}
2022-04-06 10:42:23 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-7f0ba685-source-kafka-bootstrap.namespace-127.svc:9093:mirrormaker2-topic-example-a-1457881823 from pod my-cluster-7f0ba685-kafka-clients-7665ffdbd6-kxghd
2022-04-06 10:42:23 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7f0ba685-kafka-clients-7665ffdbd6-kxghd -n namespace-127 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-545551126 --group-instance-id instance1279759004 --topic mirrormaker2-topic-example-a-1457881823 --bootstrap-server my-cluster-7f0ba685-source-kafka-bootstrap.namespace-127.svc:9093 USER=my_cluster_7f0ba685_my_user_source
2022-04-06 10:42:30 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 10:42:30 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 10:42:30 [main] [32mINFO [m [MirrorMaker2IsolatedST:1338] Now messages should be mirrored to target topic and cluster
2022-04-06 10:42:30 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@a055261, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-1218846084, --group-instance-id, instance16199619, --topic, my-cluster-7f0ba685-source.mirrormaker2-topic-example-a-1457881823, --bootstrap-server, my-cluster-7f0ba685-target-kafka-bootstrap.namespace-127.svc:9093, USER=my_cluster_7f0ba685_my_user_target], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-7f0ba685-kafka-clients-7665ffdbd6-kxghd', podNamespace='namespace-127', bootstrapServer='my-cluster-7f0ba685-target-kafka-bootstrap.namespace-127.svc:9093', topicName='my-cluster-7f0ba685-source.mirrormaker2-topic-example-a-1457881823', maxMessages=200, kafkaUsername='my-cluster-7f0ba685-my-user-target', consumerGroupName='my-consumer-group-1218846084', consumerInstanceId='instance16199619', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7af619e0}
2022-04-06 10:42:30 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-7f0ba685-target-kafka-bootstrap.namespace-127.svc:9093:my-cluster-7f0ba685-source.mirrormaker2-topic-example-a-1457881823 from pod my-cluster-7f0ba685-kafka-clients-7665ffdbd6-kxghd
2022-04-06 10:42:30 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7f0ba685-kafka-clients-7665ffdbd6-kxghd -n namespace-127 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-1218846084 --group-instance-id instance16199619 --topic my-cluster-7f0ba685-source.mirrormaker2-topic-example-a-1457881823 --bootstrap-server my-cluster-7f0ba685-target-kafka-bootstrap.namespace-127.svc:9093 USER=my_cluster_7f0ba685_my_user_target
2022-04-06 10:42:37 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 10:42:37 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 10:42:37 [main] [32mINFO [m [MirrorMaker2IsolatedST:1340] Messages successfully mirrored
2022-04-06 10:42:37 [main] [32mINFO [m [MirrorMaker2IsolatedST:1344] Changing KafkaUser sha-password on KMM2 Source and make sure it rolled
2022-04-06 10:42:37 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-7f0ba685-mirrormaker2 rolling update
2022-04-06 10:44:08 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7f0ba685-mirrormaker2 will be ready
2022-04-06 10:44:08 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7f0ba685-mirrormaker2 is ready
2022-04-06 10:44:18 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-7f0ba685-mirrormaker2 rolling update finished
2022-04-06 10:44:18 [main] [32mINFO [m [MirrorMaker2IsolatedST:1354] Changing KafkaUser sha-password on KMM2 Target
2022-04-06 10:44:18 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-7f0ba685-mirrormaker2 rolling update
2022-04-06 10:45:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7f0ba685-mirrormaker2 will be ready
2022-04-06 10:45:58 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7f0ba685-mirrormaker2 is ready
2022-04-06 10:46:08 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-7f0ba685-mirrormaker2 rolling update finished
2022-04-06 10:46:08 [main] [32mINFO [m [MirrorMaker2IsolatedST:1364] Recreate kafkaClients pod with new passwords.
2022-04-06 10:46:08 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-7f0ba685-kafka-clients in namespace namespace-127
2022-04-06 10:46:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-7f0ba685-kafka-clients in namespace namespace-127
2022-04-06 10:46:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-06 10:46:48 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7f0ba685-kafka-clients will be ready
2022-04-06 10:46:50 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7f0ba685-kafka-clients is ready
2022-04-06 10:46:50 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@ff9f451, messages=[], arguments=[--max-messages, 200, --topic, mirrormaker2-topic-example-b-2116282178, --bootstrap-server, my-cluster-7f0ba685-source-kafka-bootstrap.namespace-127.svc:9093, USER=my_cluster_7f0ba685_my_user_source], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-7f0ba685-kafka-clients-669c64c5c8-dlnxx', podNamespace='namespace-127', bootstrapServer='my-cluster-7f0ba685-source-kafka-bootstrap.namespace-127.svc:9093', topicName='mirrormaker2-topic-example-b-2116282178', maxMessages=200, kafkaUsername='my-cluster-7f0ba685-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@336e18f2}
2022-04-06 10:46:50 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-7f0ba685-source-kafka-bootstrap.namespace-127.svc:9093:mirrormaker2-topic-example-b-2116282178 from pod my-cluster-7f0ba685-kafka-clients-669c64c5c8-dlnxx
2022-04-06 10:46:50 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7f0ba685-kafka-clients-669c64c5c8-dlnxx -n namespace-127 -- /opt/kafka/producer.sh --max-messages 200 --topic mirrormaker2-topic-example-b-2116282178 --bootstrap-server my-cluster-7f0ba685-source-kafka-bootstrap.namespace-127.svc:9093 USER=my_cluster_7f0ba685_my_user_source
2022-04-06 10:46:54 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 10:46:54 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 10:46:54 [main] [32mINFO [m [MirrorMaker2IsolatedST:1385] Now messages should be mirrored to target topic and cluster
2022-04-06 10:46:54 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6733deac, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-863284245, --group-instance-id, instance55390077, --topic, my-cluster-7f0ba685-source.mirrormaker2-topic-example-b-2116282178, --bootstrap-server, my-cluster-7f0ba685-target-kafka-bootstrap.namespace-127.svc:9093, USER=my_cluster_7f0ba685_my_user_target], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-7f0ba685-kafka-clients-669c64c5c8-dlnxx', podNamespace='namespace-127', bootstrapServer='my-cluster-7f0ba685-target-kafka-bootstrap.namespace-127.svc:9093', topicName='my-cluster-7f0ba685-source.mirrormaker2-topic-example-b-2116282178', maxMessages=200, kafkaUsername='my-cluster-7f0ba685-my-user-target', consumerGroupName='my-consumer-group-863284245', consumerInstanceId='instance55390077', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2459fb5d}
2022-04-06 10:46:54 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-7f0ba685-target-kafka-bootstrap.namespace-127.svc:9093:my-cluster-7f0ba685-source.mirrormaker2-topic-example-b-2116282178 from pod my-cluster-7f0ba685-kafka-clients-669c64c5c8-dlnxx
2022-04-06 10:46:54 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7f0ba685-kafka-clients-669c64c5c8-dlnxx -n namespace-127 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-863284245 --group-instance-id instance55390077 --topic my-cluster-7f0ba685-source.mirrormaker2-topic-example-b-2116282178 --bootstrap-server my-cluster-7f0ba685-target-kafka-bootstrap.namespace-127.svc:9093 USER=my_cluster_7f0ba685_my_user_target
2022-04-06 10:47:01 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 10:47:01 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 10:47:01 [main] [32mINFO [m [MirrorMaker2IsolatedST:1387] Messages successfully mirrored
2022-04-06 10:47:01 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 10:47:01 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKMM2RollAfterSecretsCertsUpdateScramsha
2022-04-06 10:47:01 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-7f0ba685-my-user-source in namespace namespace-127
2022-04-06 10:47:01 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-7f0ba685-my-user-target in namespace namespace-127
2022-04-06 10:47:01 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7f0ba685-target in namespace namespace-127
2022-04-06 10:47:01 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-7f0ba685-kafka-clients in namespace namespace-127
2022-04-06 10:47:01 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-7f0ba685 in namespace namespace-127
2022-04-06 10:47:01 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-7f0ba685-kafka-clients in namespace namespace-127
2022-04-06 10:47:01 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-a-1457881823 in namespace namespace-127
2022-04-06 10:47:01 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7f0ba685-source in namespace namespace-127
2022-04-06 10:47:11 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-b-2116282178 in namespace namespace-127
2022-04-06 10:48:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 10:48:01 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-127 for test case:testKMM2RollAfterSecretsCertsUpdateScramsha
2022-04-06 10:48:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testKMM2RollAfterSecretsCertsUpdateScramsha-FINISHED
2022-04-06 10:48:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 10:48:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 10:48:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2TlsAndTlsClientAuth-STARTED
2022-04-06 10:48:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 10:48:07 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-128 for test case:testMirrorMaker2TlsAndTlsClientAuth
2022-04-06 10:48:07 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-128
2022-04-06 10:48:08 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-128
2022-04-06 10:48:08 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-128
2022-04-06 10:48:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-6ae9fcd4-source in namespace namespace-128
2022-04-06 10:48:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-06 10:48:08 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-6ae9fcd4-source will have desired state: Ready
2022-04-06 10:49:10 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-6ae9fcd4-source is in desired state: Ready
2022-04-06 10:49:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-6ae9fcd4-target in namespace namespace-128
2022-04-06 10:49:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-06 10:49:10 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-6ae9fcd4-target will have desired state: Ready
2022-04-06 10:50:18 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-6ae9fcd4-target is in desired state: Ready
2022-04-06 10:50:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-868980171 in namespace namespace-128
2022-04-06 10:50:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-06 10:50:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-868980171 will have desired state: Ready
2022-04-06 10:50:19 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-868980171 is in desired state: Ready
2022-04-06 10:50:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-6ae9fcd4-my-user-source in namespace namespace-128
2022-04-06 10:50:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-06 10:50:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-6ae9fcd4-my-user-source will have desired state: Ready
2022-04-06 10:50:20 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-6ae9fcd4-my-user-source is in desired state: Ready
2022-04-06 10:50:20 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-6ae9fcd4-my-user-target in namespace namespace-128
2022-04-06 10:50:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-06 10:50:20 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-6ae9fcd4-my-user-target will have desired state: Ready
2022-04-06 10:50:21 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-6ae9fcd4-my-user-target is in desired state: Ready
2022-04-06 10:50:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-6ae9fcd4-kafka-clients in namespace namespace-128
2022-04-06 10:50:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-06 10:50:31 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1451737534-748298160-test-1 in namespace namespace-128
2022-04-06 10:50:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-06 10:50:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1451737534-748298160-test-1 will have desired state: Ready
2022-04-06 10:50:32 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1451737534-748298160-test-1 is in desired state: Ready
2022-04-06 10:50:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1451737534-748298160-test-2 in namespace namespace-128
2022-04-06 10:50:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-06 10:50:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1451737534-748298160-test-2 will have desired state: Ready
2022-04-06 10:50:33 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1451737534-748298160-test-2 is in desired state: Ready
2022-04-06 10:50:33 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 10:50:33 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1307696930-2127659835 in namespace namespace-128
2022-04-06 10:50:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-06 10:50:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1307696930-2127659835 will have desired state: Ready
2022-04-06 10:50:34 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1307696930-2127659835 is in desired state: Ready
2022-04-06 10:50:34 [main] [32mINFO [m [ClientUtils:127] Sending messages to - topic my-topic-1451737534-748298160-test-1, cluster my-cluster-6ae9fcd4-source and message count of 200
2022-04-06 10:50:34 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@4f1eef9d, messages=[], arguments=[--max-messages, 200, --topic, my-topic-1307696930-2127659835, --bootstrap-server, my-cluster-6ae9fcd4-source-kafka-bootstrap.namespace-128.svc:9093, USER=my_cluster_6ae9fcd4_my_user_source], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-6ae9fcd4-kafka-clients-669457ff54-5tph6', podNamespace='namespace-128', bootstrapServer='my-cluster-6ae9fcd4-source-kafka-bootstrap.namespace-128.svc:9093', topicName='my-topic-1307696930-2127659835', maxMessages=200, kafkaUsername='my-cluster-6ae9fcd4-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5e61f739}
2022-04-06 10:50:34 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-6ae9fcd4-source-kafka-bootstrap.namespace-128.svc:9093:my-topic-1307696930-2127659835 from pod my-cluster-6ae9fcd4-kafka-clients-669457ff54-5tph6
2022-04-06 10:50:34 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-6ae9fcd4-kafka-clients-669457ff54-5tph6 -n namespace-128 -- /opt/kafka/producer.sh --max-messages 200 --topic my-topic-1307696930-2127659835 --bootstrap-server my-cluster-6ae9fcd4-source-kafka-bootstrap.namespace-128.svc:9093 USER=my_cluster_6ae9fcd4_my_user_source
2022-04-06 10:50:38 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 10:50:38 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 10:50:38 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2b3f0c83, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-528189661, --group-instance-id, instance1322288798, --topic, my-topic-1307696930-2127659835, --bootstrap-server, my-cluster-6ae9fcd4-source-kafka-bootstrap.namespace-128.svc:9093, USER=my_cluster_6ae9fcd4_my_user_source], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-6ae9fcd4-kafka-clients-669457ff54-5tph6', podNamespace='namespace-128', bootstrapServer='my-cluster-6ae9fcd4-source-kafka-bootstrap.namespace-128.svc:9093', topicName='my-topic-1307696930-2127659835', maxMessages=200, kafkaUsername='my-cluster-6ae9fcd4-my-user-source', consumerGroupName='my-consumer-group-528189661', consumerInstanceId='instance1322288798', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7ab6e4d3}
2022-04-06 10:50:38 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-6ae9fcd4-source-kafka-bootstrap.namespace-128.svc:9093:my-topic-1307696930-2127659835 from pod my-cluster-6ae9fcd4-kafka-clients-669457ff54-5tph6
2022-04-06 10:50:38 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-6ae9fcd4-kafka-clients-669457ff54-5tph6 -n namespace-128 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-528189661 --group-instance-id instance1322288798 --topic my-topic-1307696930-2127659835 --bootstrap-server my-cluster-6ae9fcd4-source-kafka-bootstrap.namespace-128.svc:9093 USER=my_cluster_6ae9fcd4_my_user_source
2022-04-06 10:50:45 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 10:50:45 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 10:50:45 [main] [32mINFO [m [ClientUtils:133] Sent 200 and received 200
2022-04-06 10:50:45 [main] [32mINFO [m [MirrorMaker2IsolatedST:328] Setting topic to my-topic-1451737534-748298160-test-2, cluster to my-cluster-6ae9fcd4-target and changing user to my-cluster-6ae9fcd4-my-user-target
2022-04-06 10:50:45 [main] [32mINFO [m [MirrorMaker2IsolatedST:337] Sending messages to - topic my-topic-1451737534-748298160-test-2, cluster my-cluster-6ae9fcd4-target and message count of 200
2022-04-06 10:50:45 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5df17908, messages=[], arguments=[--max-messages, 200, --topic, my-topic-1451737534-748298160-test-2, --bootstrap-server, my-cluster-6ae9fcd4-target-kafka-bootstrap.namespace-128.svc:9093, USER=my_cluster_6ae9fcd4_my_user_target], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-6ae9fcd4-kafka-clients-669457ff54-5tph6', podNamespace='namespace-128', bootstrapServer='my-cluster-6ae9fcd4-target-kafka-bootstrap.namespace-128.svc:9093', topicName='my-topic-1451737534-748298160-test-2', maxMessages=200, kafkaUsername='my-cluster-6ae9fcd4-my-user-target', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@13656c7e}
2022-04-06 10:50:45 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-6ae9fcd4-target-kafka-bootstrap.namespace-128.svc:9093:my-topic-1451737534-748298160-test-2 from pod my-cluster-6ae9fcd4-kafka-clients-669457ff54-5tph6
2022-04-06 10:50:45 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-6ae9fcd4-kafka-clients-669457ff54-5tph6 -n namespace-128 -- /opt/kafka/producer.sh --max-messages 200 --topic my-topic-1451737534-748298160-test-2 --bootstrap-server my-cluster-6ae9fcd4-target-kafka-bootstrap.namespace-128.svc:9093 USER=my_cluster_6ae9fcd4_my_user_target
2022-04-06 10:50:48 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 10:50:48 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 10:50:48 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4324c39b, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-1413186882, --group-instance-id, instance1363333613, --topic, my-topic-1451737534-748298160-test-2, --bootstrap-server, my-cluster-6ae9fcd4-target-kafka-bootstrap.namespace-128.svc:9093, USER=my_cluster_6ae9fcd4_my_user_target], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-6ae9fcd4-kafka-clients-669457ff54-5tph6', podNamespace='namespace-128', bootstrapServer='my-cluster-6ae9fcd4-target-kafka-bootstrap.namespace-128.svc:9093', topicName='my-topic-1451737534-748298160-test-2', maxMessages=200, kafkaUsername='my-cluster-6ae9fcd4-my-user-target', consumerGroupName='my-consumer-group-1413186882', consumerInstanceId='instance1363333613', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@10ac9e19}
2022-04-06 10:50:48 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-6ae9fcd4-target-kafka-bootstrap.namespace-128.svc:9093:my-topic-1451737534-748298160-test-2 from pod my-cluster-6ae9fcd4-kafka-clients-669457ff54-5tph6
2022-04-06 10:50:48 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-6ae9fcd4-kafka-clients-669457ff54-5tph6 -n namespace-128 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-1413186882 --group-instance-id instance1363333613 --topic my-topic-1451737534-748298160-test-2 --bootstrap-server my-cluster-6ae9fcd4-target-kafka-bootstrap.namespace-128.svc:9093 USER=my_cluster_6ae9fcd4_my_user_target
2022-04-06 10:50:55 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 10:50:55 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 10:50:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-6ae9fcd4 in namespace namespace-128
2022-04-06 10:50:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-06 10:50:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-6ae9fcd4 will have desired state: Ready
2022-04-06 10:52:07 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-6ae9fcd4 is in desired state: Ready
2022-04-06 10:52:07 [main] [32mINFO [m [MirrorMaker2IsolatedST:397] Setting topic to mirrormaker2-topic-example-868980171, cluster to my-cluster-6ae9fcd4-source and changing user to my-cluster-6ae9fcd4-my-user-source
2022-04-06 10:52:07 [main] [32mINFO [m [MirrorMaker2IsolatedST:407] Sending messages to - topic mirrormaker2-topic-example-868980171, cluster my-cluster-6ae9fcd4-source and message count of 200
2022-04-06 10:52:07 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@428fd7e5, messages=[], arguments=[--max-messages, 200, --topic, mirrormaker2-topic-example-868980171, --bootstrap-server, my-cluster-6ae9fcd4-source-kafka-bootstrap.namespace-128.svc:9093, USER=my_cluster_6ae9fcd4_my_user_source], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-6ae9fcd4-kafka-clients-669457ff54-5tph6', podNamespace='namespace-128', bootstrapServer='my-cluster-6ae9fcd4-source-kafka-bootstrap.namespace-128.svc:9093', topicName='mirrormaker2-topic-example-868980171', maxMessages=200, kafkaUsername='my-cluster-6ae9fcd4-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@278fe790}
2022-04-06 10:52:07 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-6ae9fcd4-source-kafka-bootstrap.namespace-128.svc:9093:mirrormaker2-topic-example-868980171 from pod my-cluster-6ae9fcd4-kafka-clients-669457ff54-5tph6
2022-04-06 10:52:07 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-6ae9fcd4-kafka-clients-669457ff54-5tph6 -n namespace-128 -- /opt/kafka/producer.sh --max-messages 200 --topic mirrormaker2-topic-example-868980171 --bootstrap-server my-cluster-6ae9fcd4-source-kafka-bootstrap.namespace-128.svc:9093 USER=my_cluster_6ae9fcd4_my_user_source
2022-04-06 10:52:11 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 10:52:11 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 10:52:11 [main] [32mINFO [m [MirrorMaker2IsolatedST:411] Receiving messages from - topic mirrormaker2-topic-example-868980171, cluster my-cluster-6ae9fcd4-source and message count of 200
2022-04-06 10:52:11 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@68d5be65, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-1413186882, --group-instance-id, instance1951715355, --topic, mirrormaker2-topic-example-868980171, --bootstrap-server, my-cluster-6ae9fcd4-source-kafka-bootstrap.namespace-128.svc:9093, USER=my_cluster_6ae9fcd4_my_user_source], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-6ae9fcd4-kafka-clients-669457ff54-5tph6', podNamespace='namespace-128', bootstrapServer='my-cluster-6ae9fcd4-source-kafka-bootstrap.namespace-128.svc:9093', topicName='mirrormaker2-topic-example-868980171', maxMessages=200, kafkaUsername='my-cluster-6ae9fcd4-my-user-source', consumerGroupName='my-consumer-group-1413186882', consumerInstanceId='instance1951715355', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@30be6c85}
2022-04-06 10:52:11 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-6ae9fcd4-source-kafka-bootstrap.namespace-128.svc:9093:mirrormaker2-topic-example-868980171 from pod my-cluster-6ae9fcd4-kafka-clients-669457ff54-5tph6
2022-04-06 10:52:11 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-6ae9fcd4-kafka-clients-669457ff54-5tph6 -n namespace-128 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-1413186882 --group-instance-id instance1951715355 --topic mirrormaker2-topic-example-868980171 --bootstrap-server my-cluster-6ae9fcd4-source-kafka-bootstrap.namespace-128.svc:9093 USER=my_cluster_6ae9fcd4_my_user_source
2022-04-06 10:52:17 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 10:52:17 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 10:52:17 [main] [32mINFO [m [MirrorMaker2IsolatedST:418] Now setting topic to my-cluster-6ae9fcd4-source.mirrormaker2-topic-example-868980171, cluster to my-cluster-6ae9fcd4-target and user to my-cluster-6ae9fcd4-my-user-target - the messages should be mirrored
2022-04-06 10:52:17 [main] [32mINFO [m [MirrorMaker2IsolatedST:427] Consumer in target cluster and topic should receive 200 messages
2022-04-06 10:52:17 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@60d26ce5, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-1413186882, --group-instance-id, instance1576498568, --topic, my-cluster-6ae9fcd4-source.mirrormaker2-topic-example-868980171, --bootstrap-server, my-cluster-6ae9fcd4-target-kafka-bootstrap.namespace-128.svc:9093, USER=my_cluster_6ae9fcd4_my_user_target], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-6ae9fcd4-kafka-clients-669457ff54-5tph6', podNamespace='namespace-128', bootstrapServer='my-cluster-6ae9fcd4-target-kafka-bootstrap.namespace-128.svc:9093', topicName='my-cluster-6ae9fcd4-source.mirrormaker2-topic-example-868980171', maxMessages=200, kafkaUsername='my-cluster-6ae9fcd4-my-user-target', consumerGroupName='my-consumer-group-1413186882', consumerInstanceId='instance1576498568', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@54d96c65}
2022-04-06 10:52:17 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-6ae9fcd4-target-kafka-bootstrap.namespace-128.svc:9093:my-cluster-6ae9fcd4-source.mirrormaker2-topic-example-868980171 from pod my-cluster-6ae9fcd4-kafka-clients-669457ff54-5tph6
2022-04-06 10:52:17 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-6ae9fcd4-kafka-clients-669457ff54-5tph6 -n namespace-128 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-1413186882 --group-instance-id instance1576498568 --topic my-cluster-6ae9fcd4-source.mirrormaker2-topic-example-868980171 --bootstrap-server my-cluster-6ae9fcd4-target-kafka-bootstrap.namespace-128.svc:9093 USER=my_cluster_6ae9fcd4_my_user_target
2022-04-06 10:52:24 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 10:52:24 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 10:52:24 [main] [32mINFO [m [MirrorMaker2IsolatedST:432] Messages successfully mirrored
2022-04-06 10:52:24 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 10:52:24 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker2TlsAndTlsClientAuth
2022-04-06 10:52:24 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1451737534-748298160-test-1 in namespace namespace-128
2022-04-06 10:52:24 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-6ae9fcd4-my-user-target in namespace namespace-128
2022-04-06 10:52:24 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1307696930-2127659835 in namespace namespace-128
2022-04-06 10:52:24 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1451737534-748298160-test-2 in namespace namespace-128
2022-04-06 10:52:24 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-6ae9fcd4-target in namespace namespace-128
2022-04-06 10:52:24 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-868980171 in namespace namespace-128
2022-04-06 10:52:24 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-6ae9fcd4 in namespace namespace-128
2022-04-06 10:52:24 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-6ae9fcd4-kafka-clients in namespace namespace-128
2022-04-06 10:52:34 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-6ae9fcd4-source in namespace namespace-128
2022-04-06 10:52:34 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-6ae9fcd4-my-user-source in namespace namespace-128
2022-04-06 10:53:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 10:53:04 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-128 for test case:testMirrorMaker2TlsAndTlsClientAuth
2022-04-06 10:53:10 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2TlsAndTlsClientAuth-FINISHED
2022-04-06 10:53:10 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 10:53:10 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 10:53:10 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testConfigureDeploymentStrategy-STARTED
2022-04-06 10:53:10 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 10:53:10 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-129 for test case:testConfigureDeploymentStrategy
2022-04-06 10:53:10 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-129
2022-04-06 10:53:10 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-129
2022-04-06 10:53:10 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-129
2022-04-06 10:53:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ad76f4ba-source in namespace namespace-129
2022-04-06 10:53:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-129
2022-04-06 10:53:10 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ad76f4ba-source will have desired state: Ready
2022-04-06 10:54:18 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ad76f4ba-source is in desired state: Ready
2022-04-06 10:54:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ad76f4ba-target in namespace namespace-129
2022-04-06 10:54:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-129
2022-04-06 10:54:18 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ad76f4ba-target will have desired state: Ready
2022-04-06 10:55:29 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ad76f4ba-target is in desired state: Ready
2022-04-06 10:55:29 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-ad76f4ba in namespace namespace-129
2022-04-06 10:55:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-129
2022-04-06 10:55:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-ad76f4ba will have desired state: Ready
2022-04-06 10:56:48 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-ad76f4ba is in desired state: Ready
2022-04-06 10:56:48 [main] [32mINFO [m [MirrorMaker2IsolatedST:959] Adding label to MirrorMaker2 resource, the CR should be recreated
2022-04-06 10:56:48 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ad76f4ba-mirrormaker2 will be ready
2022-04-06 10:56:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ad76f4ba-mirrormaker2 is ready
2022-04-06 10:56:48 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-ad76f4ba-mirrormaker2 to be ready
2022-04-06 10:58:08 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-ad76f4ba-mirrormaker2 is ready
2022-04-06 10:58:08 [main] [32mINFO [m [MirrorMaker2IsolatedST:966] Checking that observed gen. is still on 1 (recreation) and new label is present
2022-04-06 10:58:08 [main] [32mINFO [m [MirrorMaker2IsolatedST:971] Changing deployment strategy to ROLLING_UPDATE
2022-04-06 10:58:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-ad76f4ba will have desired state: Ready
2022-04-06 10:58:08 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-ad76f4ba is in desired state: Ready
2022-04-06 10:58:08 [main] [32mINFO [m [MirrorMaker2IsolatedST:976] Adding another label to MirrorMaker2 resource, pods should be rolled
2022-04-06 10:58:08 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ad76f4ba-mirrormaker2 will be ready
2022-04-06 10:58:08 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ad76f4ba-mirrormaker2 is ready
2022-04-06 10:58:08 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-ad76f4ba-mirrormaker2 to be ready
2022-04-06 10:59:23 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-ad76f4ba-mirrormaker2 is ready
2022-04-06 10:59:23 [main] [32mINFO [m [MirrorMaker2IsolatedST:980] Checking that observed gen. higher (rolling update) and label is changed
2022-04-06 10:59:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 10:59:23 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigureDeploymentStrategy
2022-04-06 10:59:23 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ad76f4ba-target in namespace namespace-129
2022-04-06 10:59:23 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-ad76f4ba in namespace namespace-129
2022-04-06 10:59:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ad76f4ba-source in namespace namespace-129
2022-04-06 10:59:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 10:59:43 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-129 for test case:testConfigureDeploymentStrategy
2022-04-06 11:00:11 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testConfigureDeploymentStrategy-FINISHED
2022-04-06 11:00:11 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:00:11 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:00:11 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2CorrectlyMirrorsHeaders-STARTED
2022-04-06 11:00:11 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:00:11 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-130 for test case:testMirrorMaker2CorrectlyMirrorsHeaders
2022-04-06 11:00:11 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-130
2022-04-06 11:00:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-130
2022-04-06 11:00:11 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-130
2022-04-06 11:00:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d7603cda-source in namespace namespace-130
2022-04-06 11:00:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-130
2022-04-06 11:00:11 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d7603cda-source will have desired state: Ready
2022-04-06 11:01:25 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d7603cda-source is in desired state: Ready
2022-04-06 11:01:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d7603cda-target in namespace namespace-130
2022-04-06 11:01:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-130
2022-04-06 11:01:25 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d7603cda-target will have desired state: Ready
2022-04-06 11:02:36 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d7603cda-target is in desired state: Ready
2022-04-06 11:02:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-cluster-d7603cda-source-example-topic in namespace namespace-130
2022-04-06 11:02:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-130
2022-04-06 11:02:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-cluster-d7603cda-source-example-topic will have desired state: Ready
2022-04-06 11:02:37 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-cluster-d7603cda-source-example-topic is in desired state: Ready
2022-04-06 11:02:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-d7603cda in namespace namespace-130
2022-04-06 11:02:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-130
2022-04-06 11:02:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-d7603cda will have desired state: Ready
2022-04-06 11:03:47 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-d7603cda is in desired state: Ready
2022-04-06 11:03:47 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 11:03:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-d7603cda-target-consumer in namespace namespace-130
2022-04-06 11:03:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-130
2022-04-06 11:03:47 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-d7603cda-target-consumer will be in active state
2022-04-06 11:03:48 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 11:03:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-d7603cda-source-producer in namespace namespace-130
2022-04-06 11:03:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-130
2022-04-06 11:03:48 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-d7603cda-source-producer will be in active state
2022-04-06 11:03:49 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-d7603cda-source-producer and consumer my-cluster-d7603cda-target-consumer finish
2022-04-06 11:05:33 [main] [32mINFO [m [MirrorMaker2IsolatedST:753] Checking log of my-cluster-d7603cda-target-consumer job if the headers are correct
2022-04-06 11:05:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:05:33 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker2CorrectlyMirrorsHeaders
2022-04-06 11:05:33 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-d7603cda in namespace namespace-130
2022-04-06 11:05:33 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-d7603cda-target-consumer in namespace namespace-130
2022-04-06 11:05:33 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-d7603cda-source-producer in namespace namespace-130
2022-04-06 11:05:33 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d7603cda-source in namespace namespace-130
2022-04-06 11:05:33 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d7603cda-target in namespace namespace-130
2022-04-06 11:05:33 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-cluster-d7603cda-source-example-topic in namespace namespace-130
2022-04-06 11:05:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:05:53 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-130 for test case:testMirrorMaker2CorrectlyMirrorsHeaders
2022-04-06 11:06:20 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2CorrectlyMirrorsHeaders-FINISHED
2022-04-06 11:06:20 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:06:20 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:06:20 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2TlsAndScramSha512Auth-STARTED
2022-04-06 11:06:20 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:06:20 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-131 for test case:testMirrorMaker2TlsAndScramSha512Auth
2022-04-06 11:06:20 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-131
2022-04-06 11:06:20 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-131
2022-04-06 11:06:20 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-131
2022-04-06 11:06:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a3aeaa2f-source in namespace namespace-131
2022-04-06 11:06:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-06 11:06:20 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a3aeaa2f-source will have desired state: Ready
2022-04-06 11:07:28 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a3aeaa2f-source is in desired state: Ready
2022-04-06 11:07:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a3aeaa2f-target in namespace namespace-131
2022-04-06 11:07:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-06 11:07:28 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a3aeaa2f-target will have desired state: Ready
2022-04-06 11:08:38 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a3aeaa2f-target is in desired state: Ready
2022-04-06 11:08:38 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-128683713 in namespace namespace-131
2022-04-06 11:08:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-06 11:08:38 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-128683713 will have desired state: Ready
2022-04-06 11:08:39 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-128683713 is in desired state: Ready
2022-04-06 11:08:39 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-a3aeaa2f-my-user-source in namespace namespace-131
2022-04-06 11:08:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-06 11:08:40 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-a3aeaa2f-my-user-source will have desired state: Ready
2022-04-06 11:08:41 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-a3aeaa2f-my-user-source is in desired state: Ready
2022-04-06 11:08:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-a3aeaa2f-my-user-target in namespace namespace-131
2022-04-06 11:08:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-06 11:08:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-a3aeaa2f-my-user-target will have desired state: Ready
2022-04-06 11:08:42 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-a3aeaa2f-my-user-target is in desired state: Ready
2022-04-06 11:08:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a3aeaa2f-kafka-clients in namespace namespace-131
2022-04-06 11:08:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-06 11:08:42 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a3aeaa2f-kafka-clients will be ready
2022-04-06 11:08:44 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a3aeaa2f-kafka-clients is ready
2022-04-06 11:08:44 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 11:08:44 [main] [32mINFO [m [MirrorMaker2IsolatedST:536] Sending messages to - topic availability-topic-source-my-topic-89493584-1330648268, cluster my-cluster-a3aeaa2f-source and message count of 200
2022-04-06 11:08:44 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@445b815c, messages=[], arguments=[--max-messages, 200, --topic, availability-topic-source-my-topic-89493584-1330648268, --bootstrap-server, my-cluster-a3aeaa2f-source-kafka-bootstrap.namespace-131.svc:9093, USER=my_cluster_a3aeaa2f_my_user_source], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-a3aeaa2f-kafka-clients-656cf5c556-4dxj7', podNamespace='namespace-131', bootstrapServer='my-cluster-a3aeaa2f-source-kafka-bootstrap.namespace-131.svc:9093', topicName='availability-topic-source-my-topic-89493584-1330648268', maxMessages=200, kafkaUsername='my-cluster-a3aeaa2f-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@446aa68f}
2022-04-06 11:08:44 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-a3aeaa2f-source-kafka-bootstrap.namespace-131.svc:9093:availability-topic-source-my-topic-89493584-1330648268 from pod my-cluster-a3aeaa2f-kafka-clients-656cf5c556-4dxj7
2022-04-06 11:08:44 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a3aeaa2f-kafka-clients-656cf5c556-4dxj7 -n namespace-131 -- /opt/kafka/producer.sh --max-messages 200 --topic availability-topic-source-my-topic-89493584-1330648268 --bootstrap-server my-cluster-a3aeaa2f-source-kafka-bootstrap.namespace-131.svc:9093 USER=my_cluster_a3aeaa2f_my_user_source
2022-04-06 11:08:47 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 11:08:47 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 11:08:47 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@669c4e81, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-927724905, --group-instance-id, instance1571780947, --topic, availability-topic-source-my-topic-89493584-1330648268, --bootstrap-server, my-cluster-a3aeaa2f-source-kafka-bootstrap.namespace-131.svc:9093, USER=my_cluster_a3aeaa2f_my_user_source], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a3aeaa2f-kafka-clients-656cf5c556-4dxj7', podNamespace='namespace-131', bootstrapServer='my-cluster-a3aeaa2f-source-kafka-bootstrap.namespace-131.svc:9093', topicName='availability-topic-source-my-topic-89493584-1330648268', maxMessages=200, kafkaUsername='my-cluster-a3aeaa2f-my-user-source', consumerGroupName='my-consumer-group-927724905', consumerInstanceId='instance1571780947', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@77d3d02a}
2022-04-06 11:08:47 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-a3aeaa2f-source-kafka-bootstrap.namespace-131.svc:9093:availability-topic-source-my-topic-89493584-1330648268 from pod my-cluster-a3aeaa2f-kafka-clients-656cf5c556-4dxj7
2022-04-06 11:08:47 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a3aeaa2f-kafka-clients-656cf5c556-4dxj7 -n namespace-131 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-927724905 --group-instance-id instance1571780947 --topic availability-topic-source-my-topic-89493584-1330648268 --bootstrap-server my-cluster-a3aeaa2f-source-kafka-bootstrap.namespace-131.svc:9093 USER=my_cluster_a3aeaa2f_my_user_source
2022-04-06 11:08:54 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 11:08:54 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 11:08:54 [main] [32mINFO [m [MirrorMaker2IsolatedST:544] Setting topic to availability-topic-target-my-topic-89493584-1330648268, cluster to my-cluster-a3aeaa2f-target and changing user to my-cluster-a3aeaa2f-my-user-target
2022-04-06 11:08:54 [main] [32mINFO [m [MirrorMaker2IsolatedST:553] Sending messages to - topic availability-topic-target-my-topic-89493584-1330648268, cluster my-cluster-a3aeaa2f-target and message count of 200
2022-04-06 11:08:54 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@687dc3a5, messages=[], arguments=[--max-messages, 200, --topic, availability-topic-target-my-topic-89493584-1330648268, --bootstrap-server, my-cluster-a3aeaa2f-target-kafka-bootstrap.namespace-131.svc:9093, USER=my_cluster_a3aeaa2f_my_user_target], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-a3aeaa2f-kafka-clients-656cf5c556-4dxj7', podNamespace='namespace-131', bootstrapServer='my-cluster-a3aeaa2f-target-kafka-bootstrap.namespace-131.svc:9093', topicName='availability-topic-target-my-topic-89493584-1330648268', maxMessages=200, kafkaUsername='my-cluster-a3aeaa2f-my-user-target', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7e55626f}
2022-04-06 11:08:54 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-a3aeaa2f-target-kafka-bootstrap.namespace-131.svc:9093:availability-topic-target-my-topic-89493584-1330648268 from pod my-cluster-a3aeaa2f-kafka-clients-656cf5c556-4dxj7
2022-04-06 11:08:54 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a3aeaa2f-kafka-clients-656cf5c556-4dxj7 -n namespace-131 -- /opt/kafka/producer.sh --max-messages 200 --topic availability-topic-target-my-topic-89493584-1330648268 --bootstrap-server my-cluster-a3aeaa2f-target-kafka-bootstrap.namespace-131.svc:9093 USER=my_cluster_a3aeaa2f_my_user_target
2022-04-06 11:08:58 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 11:08:58 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 11:08:58 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5aab2ef, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-927724905, --group-instance-id, instance2126857913, --topic, availability-topic-target-my-topic-89493584-1330648268, --bootstrap-server, my-cluster-a3aeaa2f-target-kafka-bootstrap.namespace-131.svc:9093, USER=my_cluster_a3aeaa2f_my_user_target], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a3aeaa2f-kafka-clients-656cf5c556-4dxj7', podNamespace='namespace-131', bootstrapServer='my-cluster-a3aeaa2f-target-kafka-bootstrap.namespace-131.svc:9093', topicName='availability-topic-target-my-topic-89493584-1330648268', maxMessages=200, kafkaUsername='my-cluster-a3aeaa2f-my-user-target', consumerGroupName='my-consumer-group-927724905', consumerInstanceId='instance2126857913', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1461c00}
2022-04-06 11:08:58 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-a3aeaa2f-target-kafka-bootstrap.namespace-131.svc:9093:availability-topic-target-my-topic-89493584-1330648268 from pod my-cluster-a3aeaa2f-kafka-clients-656cf5c556-4dxj7
2022-04-06 11:08:58 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a3aeaa2f-kafka-clients-656cf5c556-4dxj7 -n namespace-131 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-927724905 --group-instance-id instance2126857913 --topic availability-topic-target-my-topic-89493584-1330648268 --bootstrap-server my-cluster-a3aeaa2f-target-kafka-bootstrap.namespace-131.svc:9093 USER=my_cluster_a3aeaa2f_my_user_target
2022-04-06 11:09:05 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 11:09:05 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 11:09:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-a3aeaa2f in namespace namespace-131
2022-04-06 11:09:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-06 11:09:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-a3aeaa2f will have desired state: Ready
2022-04-06 11:10:18 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-a3aeaa2f is in desired state: Ready
2022-04-06 11:10:18 [main] [32mINFO [m [MirrorMaker2IsolatedST:597] Setting topic to mirrormaker2-topic-example-128683713, cluster to my-cluster-a3aeaa2f-source and changing user to my-cluster-a3aeaa2f-my-user-source
2022-04-06 11:10:18 [main] [32mINFO [m [MirrorMaker2IsolatedST:606] Sending messages to - topic mirrormaker2-topic-example-128683713, cluster my-cluster-a3aeaa2f-source and message count of 200
2022-04-06 11:10:18 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@4bad0b93, messages=[], arguments=[--max-messages, 200, --topic, mirrormaker2-topic-example-128683713, --bootstrap-server, my-cluster-a3aeaa2f-source-kafka-bootstrap.namespace-131.svc:9093, USER=my_cluster_a3aeaa2f_my_user_source], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-a3aeaa2f-kafka-clients-656cf5c556-4dxj7', podNamespace='namespace-131', bootstrapServer='my-cluster-a3aeaa2f-source-kafka-bootstrap.namespace-131.svc:9093', topicName='mirrormaker2-topic-example-128683713', maxMessages=200, kafkaUsername='my-cluster-a3aeaa2f-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5f6ff1bf}
2022-04-06 11:10:18 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-a3aeaa2f-source-kafka-bootstrap.namespace-131.svc:9093:mirrormaker2-topic-example-128683713 from pod my-cluster-a3aeaa2f-kafka-clients-656cf5c556-4dxj7
2022-04-06 11:10:18 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a3aeaa2f-kafka-clients-656cf5c556-4dxj7 -n namespace-131 -- /opt/kafka/producer.sh --max-messages 200 --topic mirrormaker2-topic-example-128683713 --bootstrap-server my-cluster-a3aeaa2f-source-kafka-bootstrap.namespace-131.svc:9093 USER=my_cluster_a3aeaa2f_my_user_source
2022-04-06 11:10:22 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 11:10:22 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 11:10:22 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7123a13d, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-927724905, --group-instance-id, instance760005069, --topic, mirrormaker2-topic-example-128683713, --bootstrap-server, my-cluster-a3aeaa2f-source-kafka-bootstrap.namespace-131.svc:9093, USER=my_cluster_a3aeaa2f_my_user_source], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a3aeaa2f-kafka-clients-656cf5c556-4dxj7', podNamespace='namespace-131', bootstrapServer='my-cluster-a3aeaa2f-source-kafka-bootstrap.namespace-131.svc:9093', topicName='mirrormaker2-topic-example-128683713', maxMessages=200, kafkaUsername='my-cluster-a3aeaa2f-my-user-source', consumerGroupName='my-consumer-group-927724905', consumerInstanceId='instance760005069', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@51e140b7}
2022-04-06 11:10:22 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-a3aeaa2f-source-kafka-bootstrap.namespace-131.svc:9093:mirrormaker2-topic-example-128683713 from pod my-cluster-a3aeaa2f-kafka-clients-656cf5c556-4dxj7
2022-04-06 11:10:22 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a3aeaa2f-kafka-clients-656cf5c556-4dxj7 -n namespace-131 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-927724905 --group-instance-id instance760005069 --topic mirrormaker2-topic-example-128683713 --bootstrap-server my-cluster-a3aeaa2f-source-kafka-bootstrap.namespace-131.svc:9093 USER=my_cluster_a3aeaa2f_my_user_source
2022-04-06 11:10:29 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 11:10:29 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 11:10:29 [main] [32mINFO [m [MirrorMaker2IsolatedST:615] Changing to target - topic my-cluster-a3aeaa2f-source.mirrormaker2-topic-example-128683713, cluster my-cluster-a3aeaa2f-target, user my-cluster-a3aeaa2f-my-user-target
2022-04-06 11:10:29 [main] [32mINFO [m [MirrorMaker2IsolatedST:623] Now messages should be mirrored to target topic and cluster
2022-04-06 11:10:29 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7c944194, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-927724905, --group-instance-id, instance706377690, --topic, my-cluster-a3aeaa2f-source.mirrormaker2-topic-example-128683713, --bootstrap-server, my-cluster-a3aeaa2f-target-kafka-bootstrap.namespace-131.svc:9093, USER=my_cluster_a3aeaa2f_my_user_target], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a3aeaa2f-kafka-clients-656cf5c556-4dxj7', podNamespace='namespace-131', bootstrapServer='my-cluster-a3aeaa2f-target-kafka-bootstrap.namespace-131.svc:9093', topicName='my-cluster-a3aeaa2f-source.mirrormaker2-topic-example-128683713', maxMessages=200, kafkaUsername='my-cluster-a3aeaa2f-my-user-target', consumerGroupName='my-consumer-group-927724905', consumerInstanceId='instance706377690', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@52f1cd19}
2022-04-06 11:10:29 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-a3aeaa2f-target-kafka-bootstrap.namespace-131.svc:9093:my-cluster-a3aeaa2f-source.mirrormaker2-topic-example-128683713 from pod my-cluster-a3aeaa2f-kafka-clients-656cf5c556-4dxj7
2022-04-06 11:10:29 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a3aeaa2f-kafka-clients-656cf5c556-4dxj7 -n namespace-131 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-927724905 --group-instance-id instance706377690 --topic my-cluster-a3aeaa2f-source.mirrormaker2-topic-example-128683713 --bootstrap-server my-cluster-a3aeaa2f-target-kafka-bootstrap.namespace-131.svc:9093 USER=my_cluster_a3aeaa2f_my_user_target
2022-04-06 11:10:36 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 11:10:36 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 11:10:36 [main] [32mINFO [m [MirrorMaker2IsolatedST:628] Messages successfully mirrored
2022-04-06 11:10:36 [main] [32mINFO [m [KafkaTopicUtils:78] Waiting for KafkaTopic my-cluster-a3aeaa2f-source.mirrormaker2-topic-example-128683713 creation 
2022-04-06 11:10:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:10:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker2TlsAndScramSha512Auth
2022-04-06 11:10:36 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-a3aeaa2f-my-user-target in namespace namespace-131
2022-04-06 11:10:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-a3aeaa2f-my-user-source in namespace namespace-131
2022-04-06 11:10:36 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a3aeaa2f-source in namespace namespace-131
2022-04-06 11:10:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-128683713 in namespace namespace-131
2022-04-06 11:10:36 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-a3aeaa2f in namespace namespace-131
2022-04-06 11:10:36 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a3aeaa2f-target in namespace namespace-131
2022-04-06 11:10:36 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a3aeaa2f-kafka-clients in namespace namespace-131
2022-04-06 11:11:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:11:26 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-131 for test case:testMirrorMaker2TlsAndScramSha512Auth
2022-04-06 11:11:32 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2TlsAndScramSha512Auth-FINISHED
2022-04-06 11:11:32 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:11:32 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:11:32 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testScaleMirrorMaker2ToZero-STARTED
2022-04-06 11:11:32 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:11:32 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-132 for test case:testScaleMirrorMaker2ToZero
2022-04-06 11:11:32 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-132
2022-04-06 11:11:32 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-132
2022-04-06 11:11:32 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-132
2022-04-06 11:11:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-764c3e0e-source in namespace namespace-132
2022-04-06 11:11:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-132
2022-04-06 11:11:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-764c3e0e-source will have desired state: Ready
2022-04-06 11:12:41 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-764c3e0e-source is in desired state: Ready
2022-04-06 11:12:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-764c3e0e-target in namespace namespace-132
2022-04-06 11:12:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-132
2022-04-06 11:12:41 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-764c3e0e-target will have desired state: Ready
2022-04-06 11:13:54 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-764c3e0e-target is in desired state: Ready
2022-04-06 11:13:54 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-764c3e0e in namespace namespace-132
2022-04-06 11:13:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-132
2022-04-06 11:13:54 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-764c3e0e will have desired state: Ready
2022-04-06 11:15:07 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-764c3e0e is in desired state: Ready
2022-04-06 11:15:07 [main] [32mINFO [m [MirrorMaker2IsolatedST:781] Scaling MirrorMaker2 to zero
2022-04-06 11:15:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:15:15 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleMirrorMaker2ToZero
2022-04-06 11:15:15 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-764c3e0e-target in namespace namespace-132
2022-04-06 11:15:15 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-764c3e0e-source in namespace namespace-132
2022-04-06 11:15:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-764c3e0e in namespace namespace-132
2022-04-06 11:15:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:15:35 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-132 for test case:testScaleMirrorMaker2ToZero
2022-04-06 11:16:02 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testScaleMirrorMaker2ToZero-FINISHED
2022-04-06 11:16:02 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:16:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:16:02 [main] [32mINFO [m [ResourceManager:346] In context MirrorMaker2IsolatedST is everything deleted.
2022-04-06 11:16:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5,622.455 s - in io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST
2022-04-06 11:16:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 11:16:27 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 11:16:27 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 11:16:27 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 11:16:27 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:16:27 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 11:16:27 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 11:16:27 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 11:16:27 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 11:16:27 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 11:16:27 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 11:16:27 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:16:27 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 11:16:27 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 11:16:27 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 11:16:27 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:16:27 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 11:16:27 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:16:27 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 11:16:27 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 11:16:27 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 11:16:27 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 11:16:27 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 11:16:27 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 11:16:27 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:16:27 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 11:16:27 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 11:16:27 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 11:16:37 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 11:16:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 11:16:37 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 11:16:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:16:52 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=120000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 11:16:52 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 11:16:52 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 11:16:52 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 11:16:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:16:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 11:16:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 11:16:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 11:16:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 11:16:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 11:16:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 11:16:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 11:16:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 11:16:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 11:16:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 11:16:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 11:16:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 11:16:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 11:16:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 11:16:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 11:16:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:16:52 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 11:16:52 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 11:16:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 11:16:52 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 11:16:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 11:16:52 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 11:16:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 11:16:52 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 11:16:52 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:16:52 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 11:16:52 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 11:16:52 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 11:16:52 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 11:16:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 11:16:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 11:16:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:16:52 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 11:17:32 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 11:17:32 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 11:17:43 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 11:17:43 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:17:43 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMakerTlsAuthenticated-STARTED
2022-04-06 11:17:43 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:17:43 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-133 for test case:testMirrorMakerTlsAuthenticated
2022-04-06 11:17:43 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-133
2022-04-06 11:17:43 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-133
2022-04-06 11:17:43 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-133
2022-04-06 11:17:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b053c097-source in namespace namespace-133
2022-04-06 11:17:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-06 11:17:43 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b053c097-source will have desired state: Ready
2022-04-06 11:19:03 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b053c097-source is in desired state: Ready
2022-04-06 11:19:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b053c097-target in namespace namespace-133
2022-04-06 11:19:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-06 11:19:03 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b053c097-target will have desired state: Ready
2022-04-06 11:20:11 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b053c097-target is in desired state: Ready
2022-04-06 11:20:11 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-57885039-819052364-source-1947248355 in namespace namespace-133
2022-04-06 11:20:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-06 11:20:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-57885039-819052364-source-1947248355 will have desired state: Ready
2022-04-06 11:20:12 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-57885039-819052364-source-1947248355 is in desired state: Ready
2022-04-06 11:20:12 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-b053c097-my-user-source in namespace namespace-133
2022-04-06 11:20:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-06 11:20:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-b053c097-my-user-source will have desired state: Ready
2022-04-06 11:20:13 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-b053c097-my-user-source is in desired state: Ready
2022-04-06 11:20:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-b053c097-my-user-target in namespace namespace-133
2022-04-06 11:20:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-06 11:20:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-b053c097-my-user-target will have desired state: Ready
2022-04-06 11:20:14 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-b053c097-my-user-target is in desired state: Ready
2022-04-06 11:20:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b053c097-kafka-clients in namespace namespace-133
2022-04-06 11:20:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-06 11:20:14 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b053c097-kafka-clients will be ready
2022-04-06 11:20:16 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b053c097-kafka-clients is ready
2022-04-06 11:20:16 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1754517248-1509225797-test-1 in namespace namespace-133
2022-04-06 11:20:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-06 11:20:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1754517248-1509225797-test-1 will have desired state: Ready
2022-04-06 11:20:17 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1754517248-1509225797-test-1 is in desired state: Ready
2022-04-06 11:20:17 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1754517248-1509225797-test-2 in namespace namespace-133
2022-04-06 11:20:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-06 11:20:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1754517248-1509225797-test-2 will have desired state: Ready
2022-04-06 11:20:18 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1754517248-1509225797-test-2 is in desired state: Ready
2022-04-06 11:20:18 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 11:20:18 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5bc8dd6d, messages=[], arguments=[--max-messages, 200, --topic, my-topic-1754517248-1509225797-test-1, --bootstrap-server, my-cluster-b053c097-source-kafka-bootstrap.namespace-133.svc:9093, USER=my_cluster_b053c097_my_user_source], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b053c097-kafka-clients-765fdf7f4-fjvmv', podNamespace='namespace-133', bootstrapServer='my-cluster-b053c097-source-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-1754517248-1509225797-test-1', maxMessages=200, kafkaUsername='my-cluster-b053c097-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@621e6f5f}
2022-04-06 11:20:18 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-b053c097-source-kafka-bootstrap.namespace-133.svc:9093:my-topic-1754517248-1509225797-test-1 from pod my-cluster-b053c097-kafka-clients-765fdf7f4-fjvmv
2022-04-06 11:20:18 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b053c097-kafka-clients-765fdf7f4-fjvmv -n namespace-133 -- /opt/kafka/producer.sh --max-messages 200 --topic my-topic-1754517248-1509225797-test-1 --bootstrap-server my-cluster-b053c097-source-kafka-bootstrap.namespace-133.svc:9093 USER=my_cluster_b053c097_my_user_source
2022-04-06 11:20:22 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 11:20:22 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 11:20:22 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@427eeb1f, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-1231650104, --group-instance-id, instance1119709282, --topic, my-topic-1754517248-1509225797-test-1, --bootstrap-server, my-cluster-b053c097-source-kafka-bootstrap.namespace-133.svc:9093, USER=my_cluster_b053c097_my_user_source], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b053c097-kafka-clients-765fdf7f4-fjvmv', podNamespace='namespace-133', bootstrapServer='my-cluster-b053c097-source-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-1754517248-1509225797-test-1', maxMessages=200, kafkaUsername='my-cluster-b053c097-my-user-source', consumerGroupName='my-consumer-group-1231650104', consumerInstanceId='instance1119709282', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@530b12b6}
2022-04-06 11:20:22 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-b053c097-source-kafka-bootstrap.namespace-133.svc:9093:my-topic-1754517248-1509225797-test-1 from pod my-cluster-b053c097-kafka-clients-765fdf7f4-fjvmv
2022-04-06 11:20:22 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b053c097-kafka-clients-765fdf7f4-fjvmv -n namespace-133 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-1231650104 --group-instance-id instance1119709282 --topic my-topic-1754517248-1509225797-test-1 --bootstrap-server my-cluster-b053c097-source-kafka-bootstrap.namespace-133.svc:9093 USER=my_cluster_b053c097_my_user_source
2022-04-06 11:20:29 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 11:20:29 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 11:20:29 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@772ee621, messages=[], arguments=[--max-messages, 200, --topic, my-topic-1754517248-1509225797-test-2, --bootstrap-server, my-cluster-b053c097-target-kafka-bootstrap.namespace-133.svc:9093, USER=my_cluster_b053c097_my_user_target], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b053c097-kafka-clients-765fdf7f4-fjvmv', podNamespace='namespace-133', bootstrapServer='my-cluster-b053c097-target-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-1754517248-1509225797-test-2', maxMessages=200, kafkaUsername='my-cluster-b053c097-my-user-target', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5fc07588}
2022-04-06 11:20:29 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-b053c097-target-kafka-bootstrap.namespace-133.svc:9093:my-topic-1754517248-1509225797-test-2 from pod my-cluster-b053c097-kafka-clients-765fdf7f4-fjvmv
2022-04-06 11:20:29 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b053c097-kafka-clients-765fdf7f4-fjvmv -n namespace-133 -- /opt/kafka/producer.sh --max-messages 200 --topic my-topic-1754517248-1509225797-test-2 --bootstrap-server my-cluster-b053c097-target-kafka-bootstrap.namespace-133.svc:9093 USER=my_cluster_b053c097_my_user_target
2022-04-06 11:20:33 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 11:20:33 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 11:20:33 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4928ee4b, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-2105721545, --group-instance-id, instance1121561322, --topic, my-topic-1754517248-1509225797-test-2, --bootstrap-server, my-cluster-b053c097-target-kafka-bootstrap.namespace-133.svc:9093, USER=my_cluster_b053c097_my_user_target], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b053c097-kafka-clients-765fdf7f4-fjvmv', podNamespace='namespace-133', bootstrapServer='my-cluster-b053c097-target-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-1754517248-1509225797-test-2', maxMessages=200, kafkaUsername='my-cluster-b053c097-my-user-target', consumerGroupName='my-consumer-group-2105721545', consumerInstanceId='instance1121561322', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7cbbd4d0}
2022-04-06 11:20:33 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-b053c097-target-kafka-bootstrap.namespace-133.svc:9093:my-topic-1754517248-1509225797-test-2 from pod my-cluster-b053c097-kafka-clients-765fdf7f4-fjvmv
2022-04-06 11:20:33 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b053c097-kafka-clients-765fdf7f4-fjvmv -n namespace-133 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-2105721545 --group-instance-id instance1121561322 --topic my-topic-1754517248-1509225797-test-2 --bootstrap-server my-cluster-b053c097-target-kafka-bootstrap.namespace-133.svc:9093 USER=my_cluster_b053c097_my_user_target
2022-04-06 11:20:39 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 11:20:39 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 11:20:39 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-b053c097 in namespace namespace-133
2022-04-06 11:20:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-06 11:20:39 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-b053c097 will have desired state: Ready
2022-04-06 11:21:43 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-b053c097 is in desired state: Ready
2022-04-06 11:21:43 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@786683c, messages=[], arguments=[--max-messages, 200, --topic, my-topic-57885039-819052364-source-1947248355, --bootstrap-server, my-cluster-b053c097-source-kafka-bootstrap.namespace-133.svc:9093, USER=my_cluster_b053c097_my_user_source], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b053c097-kafka-clients-765fdf7f4-fjvmv', podNamespace='namespace-133', bootstrapServer='my-cluster-b053c097-source-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-57885039-819052364-source-1947248355', maxMessages=200, kafkaUsername='my-cluster-b053c097-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3a08ad2a}
2022-04-06 11:21:43 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-b053c097-source-kafka-bootstrap.namespace-133.svc:9093:my-topic-57885039-819052364-source-1947248355 from pod my-cluster-b053c097-kafka-clients-765fdf7f4-fjvmv
2022-04-06 11:21:43 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b053c097-kafka-clients-765fdf7f4-fjvmv -n namespace-133 -- /opt/kafka/producer.sh --max-messages 200 --topic my-topic-57885039-819052364-source-1947248355 --bootstrap-server my-cluster-b053c097-source-kafka-bootstrap.namespace-133.svc:9093 USER=my_cluster_b053c097_my_user_source
2022-04-06 11:21:46 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 11:21:46 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 11:21:46 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@28343112, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-541456189, --group-instance-id, instance254753209, --topic, my-topic-57885039-819052364-source-1947248355, --bootstrap-server, my-cluster-b053c097-source-kafka-bootstrap.namespace-133.svc:9093, USER=my_cluster_b053c097_my_user_source], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b053c097-kafka-clients-765fdf7f4-fjvmv', podNamespace='namespace-133', bootstrapServer='my-cluster-b053c097-source-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-57885039-819052364-source-1947248355', maxMessages=200, kafkaUsername='my-cluster-b053c097-my-user-source', consumerGroupName='my-consumer-group-541456189', consumerInstanceId='instance254753209', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@572aa720}
2022-04-06 11:21:46 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-b053c097-source-kafka-bootstrap.namespace-133.svc:9093:my-topic-57885039-819052364-source-1947248355 from pod my-cluster-b053c097-kafka-clients-765fdf7f4-fjvmv
2022-04-06 11:21:46 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b053c097-kafka-clients-765fdf7f4-fjvmv -n namespace-133 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-541456189 --group-instance-id instance254753209 --topic my-topic-57885039-819052364-source-1947248355 --bootstrap-server my-cluster-b053c097-source-kafka-bootstrap.namespace-133.svc:9093 USER=my_cluster_b053c097_my_user_source
2022-04-06 11:21:53 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 11:21:53 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 11:21:53 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@647e175e, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-1165144375, --group-instance-id, instance463760494, --topic, my-topic-57885039-819052364-source-1947248355, --bootstrap-server, my-cluster-b053c097-target-kafka-bootstrap.namespace-133.svc:9093, USER=my_cluster_b053c097_my_user_target], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b053c097-kafka-clients-765fdf7f4-fjvmv', podNamespace='namespace-133', bootstrapServer='my-cluster-b053c097-target-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-57885039-819052364-source-1947248355', maxMessages=200, kafkaUsername='my-cluster-b053c097-my-user-target', consumerGroupName='my-consumer-group-1165144375', consumerInstanceId='instance463760494', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1cc77ba0}
2022-04-06 11:21:53 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-b053c097-target-kafka-bootstrap.namespace-133.svc:9093:my-topic-57885039-819052364-source-1947248355 from pod my-cluster-b053c097-kafka-clients-765fdf7f4-fjvmv
2022-04-06 11:21:53 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b053c097-kafka-clients-765fdf7f4-fjvmv -n namespace-133 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-1165144375 --group-instance-id instance463760494 --topic my-topic-57885039-819052364-source-1947248355 --bootstrap-server my-cluster-b053c097-target-kafka-bootstrap.namespace-133.svc:9093 USER=my_cluster_b053c097_my_user_target
2022-04-06 11:22:00 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 11:22:00 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 11:22:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:22:00 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMakerTlsAuthenticated
2022-04-06 11:22:00 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b053c097-kafka-clients in namespace namespace-133
2022-04-06 11:22:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1754517248-1509225797-test-1 in namespace namespace-133
2022-04-06 11:22:00 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b053c097-target in namespace namespace-133
2022-04-06 11:22:00 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b053c097-source in namespace namespace-133
2022-04-06 11:22:00 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-57885039-819052364-source-1947248355 in namespace namespace-133
2022-04-06 11:22:00 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-b053c097-my-user-target in namespace namespace-133
2022-04-06 11:22:00 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1754517248-1509225797-test-2 in namespace namespace-133
2022-04-06 11:22:00 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-b053c097-my-user-source in namespace namespace-133
2022-04-06 11:22:10 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-b053c097 in namespace namespace-133
2022-04-06 11:22:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:22:50 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-133 for test case:testMirrorMakerTlsAuthenticated
2022-04-06 11:22:55 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMakerTlsAuthenticated-FINISHED
2022-04-06 11:22:55 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:22:55 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:22:55 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMakerTlsScramSha-STARTED
2022-04-06 11:22:55 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:22:55 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-134 for test case:testMirrorMakerTlsScramSha
2022-04-06 11:22:55 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-134
2022-04-06 11:22:56 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-134
2022-04-06 11:22:56 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-134
2022-04-06 11:22:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-73d04aca-source in namespace namespace-134
2022-04-06 11:22:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-06 11:22:56 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-73d04aca-source will have desired state: Ready
2022-04-06 11:24:15 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-73d04aca-source is in desired state: Ready
2022-04-06 11:24:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-73d04aca-target in namespace namespace-134
2022-04-06 11:24:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-06 11:24:15 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-73d04aca-target will have desired state: Ready
2022-04-06 11:25:26 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-73d04aca-target is in desired state: Ready
2022-04-06 11:25:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1760950256-1057060912 in namespace namespace-134
2022-04-06 11:25:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-06 11:25:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1760950256-1057060912 will have desired state: Ready
2022-04-06 11:25:27 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1760950256-1057060912 is in desired state: Ready
2022-04-06 11:25:27 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-73d04aca-my-user-source in namespace namespace-134
2022-04-06 11:25:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-06 11:25:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-73d04aca-my-user-source will have desired state: Ready
2022-04-06 11:25:28 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-73d04aca-my-user-source is in desired state: Ready
2022-04-06 11:25:28 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-73d04aca-my-user-target in namespace namespace-134
2022-04-06 11:25:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-06 11:25:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-73d04aca-my-user-target will have desired state: Ready
2022-04-06 11:25:29 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-73d04aca-my-user-target is in desired state: Ready
2022-04-06 11:25:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-73d04aca-kafka-clients in namespace namespace-134
2022-04-06 11:25:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-06 11:25:29 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-73d04aca-kafka-clients will be ready
2022-04-06 11:25:31 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-73d04aca-kafka-clients is ready
2022-04-06 11:25:31 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1760950256-1057060912-test-1 in namespace namespace-134
2022-04-06 11:25:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-06 11:25:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1760950256-1057060912-test-1 will have desired state: Ready
2022-04-06 11:25:32 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1760950256-1057060912-test-1 is in desired state: Ready
2022-04-06 11:25:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1760950256-1057060912-test-2 in namespace namespace-134
2022-04-06 11:25:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-06 11:25:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1760950256-1057060912-test-2 will have desired state: Ready
2022-04-06 11:25:33 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1760950256-1057060912-test-2 is in desired state: Ready
2022-04-06 11:25:33 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 11:25:33 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3cabebef, messages=[], arguments=[--max-messages, 200, --topic, my-topic-1760950256-1057060912-test-1, --bootstrap-server, my-cluster-73d04aca-source-kafka-bootstrap.namespace-134.svc:9093, USER=my_cluster_73d04aca_my_user_source], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-73d04aca-kafka-clients-5996f9cb6c-62pms', podNamespace='namespace-134', bootstrapServer='my-cluster-73d04aca-source-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-1760950256-1057060912-test-1', maxMessages=200, kafkaUsername='my-cluster-73d04aca-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@341de77b}
2022-04-06 11:25:33 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-73d04aca-source-kafka-bootstrap.namespace-134.svc:9093:my-topic-1760950256-1057060912-test-1 from pod my-cluster-73d04aca-kafka-clients-5996f9cb6c-62pms
2022-04-06 11:25:33 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-73d04aca-kafka-clients-5996f9cb6c-62pms -n namespace-134 -- /opt/kafka/producer.sh --max-messages 200 --topic my-topic-1760950256-1057060912-test-1 --bootstrap-server my-cluster-73d04aca-source-kafka-bootstrap.namespace-134.svc:9093 USER=my_cluster_73d04aca_my_user_source
2022-04-06 11:25:37 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 11:25:37 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 11:25:37 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1e4a3475, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-1980376873, --group-instance-id, instance1807123310, --topic, my-topic-1760950256-1057060912-test-1, --bootstrap-server, my-cluster-73d04aca-source-kafka-bootstrap.namespace-134.svc:9093, USER=my_cluster_73d04aca_my_user_source], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-73d04aca-kafka-clients-5996f9cb6c-62pms', podNamespace='namespace-134', bootstrapServer='my-cluster-73d04aca-source-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-1760950256-1057060912-test-1', maxMessages=200, kafkaUsername='my-cluster-73d04aca-my-user-source', consumerGroupName='my-consumer-group-1980376873', consumerInstanceId='instance1807123310', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@45372597}
2022-04-06 11:25:37 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-73d04aca-source-kafka-bootstrap.namespace-134.svc:9093:my-topic-1760950256-1057060912-test-1 from pod my-cluster-73d04aca-kafka-clients-5996f9cb6c-62pms
2022-04-06 11:25:37 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-73d04aca-kafka-clients-5996f9cb6c-62pms -n namespace-134 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-1980376873 --group-instance-id instance1807123310 --topic my-topic-1760950256-1057060912-test-1 --bootstrap-server my-cluster-73d04aca-source-kafka-bootstrap.namespace-134.svc:9093 USER=my_cluster_73d04aca_my_user_source
2022-04-06 11:25:44 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 11:25:44 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 11:25:44 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@20a823ef, messages=[], arguments=[--max-messages, 200, --topic, my-topic-1760950256-1057060912-test-2, --bootstrap-server, my-cluster-73d04aca-target-kafka-bootstrap.namespace-134.svc:9093, USER=my_cluster_73d04aca_my_user_target], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-73d04aca-kafka-clients-5996f9cb6c-62pms', podNamespace='namespace-134', bootstrapServer='my-cluster-73d04aca-target-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-1760950256-1057060912-test-2', maxMessages=200, kafkaUsername='my-cluster-73d04aca-my-user-target', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7ddd50c0}
2022-04-06 11:25:44 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-73d04aca-target-kafka-bootstrap.namespace-134.svc:9093:my-topic-1760950256-1057060912-test-2 from pod my-cluster-73d04aca-kafka-clients-5996f9cb6c-62pms
2022-04-06 11:25:44 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-73d04aca-kafka-clients-5996f9cb6c-62pms -n namespace-134 -- /opt/kafka/producer.sh --max-messages 200 --topic my-topic-1760950256-1057060912-test-2 --bootstrap-server my-cluster-73d04aca-target-kafka-bootstrap.namespace-134.svc:9093 USER=my_cluster_73d04aca_my_user_target
2022-04-06 11:25:48 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 11:25:48 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 11:25:48 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@13e9cf90, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-769318387, --group-instance-id, instance436379716, --topic, my-topic-1760950256-1057060912-test-2, --bootstrap-server, my-cluster-73d04aca-target-kafka-bootstrap.namespace-134.svc:9093, USER=my_cluster_73d04aca_my_user_target], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-73d04aca-kafka-clients-5996f9cb6c-62pms', podNamespace='namespace-134', bootstrapServer='my-cluster-73d04aca-target-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-1760950256-1057060912-test-2', maxMessages=200, kafkaUsername='my-cluster-73d04aca-my-user-target', consumerGroupName='my-consumer-group-769318387', consumerInstanceId='instance436379716', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5c4fb1f0}
2022-04-06 11:25:48 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-73d04aca-target-kafka-bootstrap.namespace-134.svc:9093:my-topic-1760950256-1057060912-test-2 from pod my-cluster-73d04aca-kafka-clients-5996f9cb6c-62pms
2022-04-06 11:25:48 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-73d04aca-kafka-clients-5996f9cb6c-62pms -n namespace-134 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-769318387 --group-instance-id instance436379716 --topic my-topic-1760950256-1057060912-test-2 --bootstrap-server my-cluster-73d04aca-target-kafka-bootstrap.namespace-134.svc:9093 USER=my_cluster_73d04aca_my_user_target
2022-04-06 11:25:55 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 11:25:55 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 11:25:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-73d04aca in namespace namespace-134
2022-04-06 11:25:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-06 11:25:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-73d04aca will have desired state: Ready
2022-04-06 11:27:02 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-73d04aca is in desired state: Ready
2022-04-06 11:27:02 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@4fbbcb74, messages=[], arguments=[--max-messages, 200, --topic, my-topic-1760950256-1057060912, --bootstrap-server, my-cluster-73d04aca-source-kafka-bootstrap.namespace-134.svc:9093, USER=my_cluster_73d04aca_my_user_source], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-73d04aca-kafka-clients-5996f9cb6c-62pms', podNamespace='namespace-134', bootstrapServer='my-cluster-73d04aca-source-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-1760950256-1057060912', maxMessages=200, kafkaUsername='my-cluster-73d04aca-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@33e62e17}
2022-04-06 11:27:02 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-73d04aca-source-kafka-bootstrap.namespace-134.svc:9093:my-topic-1760950256-1057060912 from pod my-cluster-73d04aca-kafka-clients-5996f9cb6c-62pms
2022-04-06 11:27:02 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-73d04aca-kafka-clients-5996f9cb6c-62pms -n namespace-134 -- /opt/kafka/producer.sh --max-messages 200 --topic my-topic-1760950256-1057060912 --bootstrap-server my-cluster-73d04aca-source-kafka-bootstrap.namespace-134.svc:9093 USER=my_cluster_73d04aca_my_user_source
2022-04-06 11:27:05 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 11:27:05 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 11:27:05 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@56ee3bd2, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-1825710303, --group-instance-id, instance665047172, --topic, my-topic-1760950256-1057060912, --bootstrap-server, my-cluster-73d04aca-source-kafka-bootstrap.namespace-134.svc:9093, USER=my_cluster_73d04aca_my_user_source], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-73d04aca-kafka-clients-5996f9cb6c-62pms', podNamespace='namespace-134', bootstrapServer='my-cluster-73d04aca-source-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-1760950256-1057060912', maxMessages=200, kafkaUsername='my-cluster-73d04aca-my-user-source', consumerGroupName='my-consumer-group-1825710303', consumerInstanceId='instance665047172', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@54fa31cc}
2022-04-06 11:27:05 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-73d04aca-source-kafka-bootstrap.namespace-134.svc:9093:my-topic-1760950256-1057060912 from pod my-cluster-73d04aca-kafka-clients-5996f9cb6c-62pms
2022-04-06 11:27:05 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-73d04aca-kafka-clients-5996f9cb6c-62pms -n namespace-134 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-1825710303 --group-instance-id instance665047172 --topic my-topic-1760950256-1057060912 --bootstrap-server my-cluster-73d04aca-source-kafka-bootstrap.namespace-134.svc:9093 USER=my_cluster_73d04aca_my_user_source
2022-04-06 11:27:12 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 11:27:12 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 11:27:12 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4f269d9b, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-784459875, --group-instance-id, instance1816924705, --topic, my-topic-1760950256-1057060912, --bootstrap-server, my-cluster-73d04aca-target-kafka-bootstrap.namespace-134.svc:9093, USER=my_cluster_73d04aca_my_user_target], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-73d04aca-kafka-clients-5996f9cb6c-62pms', podNamespace='namespace-134', bootstrapServer='my-cluster-73d04aca-target-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-1760950256-1057060912', maxMessages=200, kafkaUsername='my-cluster-73d04aca-my-user-target', consumerGroupName='my-consumer-group-784459875', consumerInstanceId='instance1816924705', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@479faa10}
2022-04-06 11:27:12 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-73d04aca-target-kafka-bootstrap.namespace-134.svc:9093:my-topic-1760950256-1057060912 from pod my-cluster-73d04aca-kafka-clients-5996f9cb6c-62pms
2022-04-06 11:27:12 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-73d04aca-kafka-clients-5996f9cb6c-62pms -n namespace-134 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-784459875 --group-instance-id instance1816924705 --topic my-topic-1760950256-1057060912 --bootstrap-server my-cluster-73d04aca-target-kafka-bootstrap.namespace-134.svc:9093 USER=my_cluster_73d04aca_my_user_target
2022-04-06 11:27:19 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 11:27:19 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 11:27:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:27:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMakerTlsScramSha
2022-04-06 11:27:19 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-73d04aca-kafka-clients in namespace namespace-134
2022-04-06 11:27:19 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-73d04aca-target in namespace namespace-134
2022-04-06 11:27:19 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-73d04aca-my-user-source in namespace namespace-134
2022-04-06 11:27:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-73d04aca-source in namespace namespace-134
2022-04-06 11:27:19 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1760950256-1057060912-test-2 in namespace namespace-134
2022-04-06 11:27:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-73d04aca-my-user-target in namespace namespace-134
2022-04-06 11:27:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1760950256-1057060912 in namespace namespace-134
2022-04-06 11:27:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1760950256-1057060912-test-1 in namespace namespace-134
2022-04-06 11:27:29 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-73d04aca in namespace namespace-134
2022-04-06 11:28:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:28:09 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-134 for test case:testMirrorMakerTlsScramSha
2022-04-06 11:28:15 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMakerTlsScramSha-FINISHED
2022-04-06 11:28:15 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:28:15 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:28:15 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testIncludeList-STARTED
2022-04-06 11:28:15 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:28:15 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-135 for test case:testIncludeList
2022-04-06 11:28:15 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-135
2022-04-06 11:28:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-135
2022-04-06 11:28:15 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-135
2022-04-06 11:28:15 [main] [32mINFO [m [MirrorMakerIsolatedST:471] Creating kafka source cluster my-cluster-880206dd-source
2022-04-06 11:28:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-880206dd-source in namespace namespace-135
2022-04-06 11:28:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-135
2022-04-06 11:28:15 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-880206dd-source will have desired state: Ready
2022-04-06 11:29:25 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-880206dd-source is in desired state: Ready
2022-04-06 11:29:25 [main] [32mINFO [m [MirrorMakerIsolatedST:473] Creating kafka target cluster my-cluster-880206dd-target
2022-04-06 11:29:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-880206dd-target in namespace namespace-135
2022-04-06 11:29:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-135
2022-04-06 11:29:25 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-880206dd-target will have desired state: Ready
2022-04-06 11:30:31 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-880206dd-target is in desired state: Ready
2022-04-06 11:30:31 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic included-topic in namespace namespace-135
2022-04-06 11:30:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-135
2022-04-06 11:30:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: included-topic will have desired state: Ready
2022-04-06 11:30:32 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: included-topic is in desired state: Ready
2022-04-06 11:30:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic not-included-topic in namespace namespace-135
2022-04-06 11:30:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-135
2022-04-06 11:30:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: not-included-topic will have desired state: Ready
2022-04-06 11:30:33 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: not-included-topic is in desired state: Ready
2022-04-06 11:30:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-880206dd-kafka-clients in namespace namespace-135
2022-04-06 11:30:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-135
2022-04-06 11:30:33 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-880206dd-kafka-clients will be ready
2022-04-06 11:30:35 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-880206dd-kafka-clients is ready
2022-04-06 11:30:35 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@11c95acb, messages=[], arguments=[--max-messages, 200, --topic, topic-example-10, --bootstrap-server, my-cluster-880206dd-source-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-880206dd-kafka-clients-7cc6588944-fp2s8', podNamespace='namespace-135', bootstrapServer='my-cluster-880206dd-source-kafka-bootstrap.namespace-135.svc:9092', topicName='topic-example-10', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5ad98910}
2022-04-06 11:30:35 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-880206dd-source-kafka-bootstrap.namespace-135.svc:9092:topic-example-10 from pod my-cluster-880206dd-kafka-clients-7cc6588944-fp2s8
2022-04-06 11:30:35 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-880206dd-kafka-clients-7cc6588944-fp2s8 -n namespace-135 -- /opt/kafka/producer.sh --max-messages 200 --topic topic-example-10 --bootstrap-server my-cluster-880206dd-source-kafka-bootstrap.namespace-135.svc:9092
2022-04-06 11:30:38 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 11:30:38 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-06 11:30:38 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@129adc6f, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-564353443, --group-instance-id, instance1823514213, --topic, topic-example-10, --bootstrap-server, my-cluster-880206dd-source-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-880206dd-kafka-clients-7cc6588944-fp2s8', podNamespace='namespace-135', bootstrapServer='my-cluster-880206dd-source-kafka-bootstrap.namespace-135.svc:9092', topicName='topic-example-10', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-564353443', consumerInstanceId='instance1823514213', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@49d54e5}
2022-04-06 11:30:38 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-880206dd-source-kafka-bootstrap.namespace-135.svc:9092#topic-example-10 from pod my-cluster-880206dd-kafka-clients-7cc6588944-fp2s8
2022-04-06 11:30:38 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-880206dd-kafka-clients-7cc6588944-fp2s8 -n namespace-135 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-564353443 --group-instance-id instance1823514213 --topic topic-example-10 --bootstrap-server my-cluster-880206dd-source-kafka-bootstrap.namespace-135.svc:9092
2022-04-06 11:30:44 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 11:30:44 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-06 11:30:44 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@70a86be4, messages=[], arguments=[--max-messages, 200, --topic, topic-example-11, --bootstrap-server, my-cluster-880206dd-target-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-880206dd-kafka-clients-7cc6588944-fp2s8', podNamespace='namespace-135', bootstrapServer='my-cluster-880206dd-target-kafka-bootstrap.namespace-135.svc:9092', topicName='topic-example-11', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@49dec3f5}
2022-04-06 11:30:44 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-880206dd-target-kafka-bootstrap.namespace-135.svc:9092:topic-example-11 from pod my-cluster-880206dd-kafka-clients-7cc6588944-fp2s8
2022-04-06 11:30:44 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-880206dd-kafka-clients-7cc6588944-fp2s8 -n namespace-135 -- /opt/kafka/producer.sh --max-messages 200 --topic topic-example-11 --bootstrap-server my-cluster-880206dd-target-kafka-bootstrap.namespace-135.svc:9092
2022-04-06 11:30:46 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 11:30:46 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-06 11:30:46 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5a41fd7c, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-1134793780, --group-instance-id, instance633856453, --topic, topic-example-11, --bootstrap-server, my-cluster-880206dd-target-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-880206dd-kafka-clients-7cc6588944-fp2s8', podNamespace='namespace-135', bootstrapServer='my-cluster-880206dd-target-kafka-bootstrap.namespace-135.svc:9092', topicName='topic-example-11', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-1134793780', consumerInstanceId='instance633856453', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1efc3368}
2022-04-06 11:30:46 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-880206dd-target-kafka-bootstrap.namespace-135.svc:9092#topic-example-11 from pod my-cluster-880206dd-kafka-clients-7cc6588944-fp2s8
2022-04-06 11:30:46 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-880206dd-kafka-clients-7cc6588944-fp2s8 -n namespace-135 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-1134793780 --group-instance-id instance633856453 --topic topic-example-11 --bootstrap-server my-cluster-880206dd-target-kafka-bootstrap.namespace-135.svc:9092
2022-04-06 11:30:52 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 11:30:52 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-06 11:30:52 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-880206dd in namespace namespace-135
2022-04-06 11:30:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-135
2022-04-06 11:30:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-880206dd will have desired state: Ready
2022-04-06 11:32:03 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-880206dd is in desired state: Ready
2022-04-06 11:32:03 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@567bfca2, messages=[], arguments=[--max-messages, 200, --topic, included-topic, --bootstrap-server, my-cluster-880206dd-source-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-880206dd-kafka-clients-7cc6588944-fp2s8', podNamespace='namespace-135', bootstrapServer='my-cluster-880206dd-source-kafka-bootstrap.namespace-135.svc:9092', topicName='included-topic', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@653f5caa}
2022-04-06 11:32:03 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-880206dd-source-kafka-bootstrap.namespace-135.svc:9092:included-topic from pod my-cluster-880206dd-kafka-clients-7cc6588944-fp2s8
2022-04-06 11:32:03 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-880206dd-kafka-clients-7cc6588944-fp2s8 -n namespace-135 -- /opt/kafka/producer.sh --max-messages 200 --topic included-topic --bootstrap-server my-cluster-880206dd-source-kafka-bootstrap.namespace-135.svc:9092
2022-04-06 11:32:06 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 11:32:06 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-06 11:32:06 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6359890e, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-116297043, --group-instance-id, instance628987220, --topic, included-topic, --bootstrap-server, my-cluster-880206dd-source-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-880206dd-kafka-clients-7cc6588944-fp2s8', podNamespace='namespace-135', bootstrapServer='my-cluster-880206dd-source-kafka-bootstrap.namespace-135.svc:9092', topicName='included-topic', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-116297043', consumerInstanceId='instance628987220', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7c9c503b}
2022-04-06 11:32:06 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-880206dd-source-kafka-bootstrap.namespace-135.svc:9092#included-topic from pod my-cluster-880206dd-kafka-clients-7cc6588944-fp2s8
2022-04-06 11:32:06 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-880206dd-kafka-clients-7cc6588944-fp2s8 -n namespace-135 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-116297043 --group-instance-id instance628987220 --topic included-topic --bootstrap-server my-cluster-880206dd-source-kafka-bootstrap.namespace-135.svc:9092
2022-04-06 11:32:11 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 11:32:11 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-06 11:32:11 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5c08c846, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-1972724048, --group-instance-id, instance203933161, --topic, included-topic, --bootstrap-server, my-cluster-880206dd-target-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-880206dd-kafka-clients-7cc6588944-fp2s8', podNamespace='namespace-135', bootstrapServer='my-cluster-880206dd-target-kafka-bootstrap.namespace-135.svc:9092', topicName='included-topic', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-1972724048', consumerInstanceId='instance203933161', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6a4ef72b}
2022-04-06 11:32:11 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-880206dd-target-kafka-bootstrap.namespace-135.svc:9092#included-topic from pod my-cluster-880206dd-kafka-clients-7cc6588944-fp2s8
2022-04-06 11:32:11 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-880206dd-kafka-clients-7cc6588944-fp2s8 -n namespace-135 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-1972724048 --group-instance-id instance203933161 --topic included-topic --bootstrap-server my-cluster-880206dd-target-kafka-bootstrap.namespace-135.svc:9092
2022-04-06 11:32:17 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 11:32:17 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-06 11:32:17 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@6d35a6d2, messages=[], arguments=[--max-messages, 200, --topic, not-included-topic, --bootstrap-server, my-cluster-880206dd-source-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-880206dd-kafka-clients-7cc6588944-fp2s8', podNamespace='namespace-135', bootstrapServer='my-cluster-880206dd-source-kafka-bootstrap.namespace-135.svc:9092', topicName='not-included-topic', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@428b4674}
2022-04-06 11:32:17 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-880206dd-source-kafka-bootstrap.namespace-135.svc:9092:not-included-topic from pod my-cluster-880206dd-kafka-clients-7cc6588944-fp2s8
2022-04-06 11:32:17 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-880206dd-kafka-clients-7cc6588944-fp2s8 -n namespace-135 -- /opt/kafka/producer.sh --max-messages 200 --topic not-included-topic --bootstrap-server my-cluster-880206dd-source-kafka-bootstrap.namespace-135.svc:9092
2022-04-06 11:32:19 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 11:32:19 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-06 11:32:19 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6a8f5f45, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-2132367402, --group-instance-id, instance1402086354, --topic, not-included-topic, --bootstrap-server, my-cluster-880206dd-source-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-880206dd-kafka-clients-7cc6588944-fp2s8', podNamespace='namespace-135', bootstrapServer='my-cluster-880206dd-source-kafka-bootstrap.namespace-135.svc:9092', topicName='not-included-topic', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-2132367402', consumerInstanceId='instance1402086354', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@705fe3f0}
2022-04-06 11:32:19 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-880206dd-source-kafka-bootstrap.namespace-135.svc:9092#not-included-topic from pod my-cluster-880206dd-kafka-clients-7cc6588944-fp2s8
2022-04-06 11:32:19 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-880206dd-kafka-clients-7cc6588944-fp2s8 -n namespace-135 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-2132367402 --group-instance-id instance1402086354 --topic not-included-topic --bootstrap-server my-cluster-880206dd-source-kafka-bootstrap.namespace-135.svc:9092
2022-04-06 11:32:25 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 11:32:25 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-06 11:32:25 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@326c3727, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-2132367402, --group-instance-id, instance474081574, --topic, not-included-topic, --bootstrap-server, my-cluster-880206dd-target-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-880206dd-kafka-clients-7cc6588944-fp2s8', podNamespace='namespace-135', bootstrapServer='my-cluster-880206dd-target-kafka-bootstrap.namespace-135.svc:9092', topicName='not-included-topic', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-2132367402', consumerInstanceId='instance474081574', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@722f1c86}
2022-04-06 11:32:25 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-880206dd-target-kafka-bootstrap.namespace-135.svc:9092#not-included-topic from pod my-cluster-880206dd-kafka-clients-7cc6588944-fp2s8
2022-04-06 11:32:25 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-880206dd-kafka-clients-7cc6588944-fp2s8 -n namespace-135 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-2132367402 --group-instance-id instance474081574 --topic not-included-topic --bootstrap-server my-cluster-880206dd-target-kafka-bootstrap.namespace-135.svc:9092
2022-04-06 11:34:25 [main] [32mINFO [m [VerifiableClient:199] CLI_KAFKA_VERIFIABLE_CONSUMER RETURN code: 1
2022-04-06 11:34:25 [main] [32mINFO [m [VerifiableClient:201] ======STDOUT START=======
2022-04-06 11:34:25 [main] [33mWARN [m [Exec:358] Executor log is too long. Going to strip it and print only first 20000 characters
2022-04-06 11:34:25 [main] [32mINFO [m [VerifiableClient:202] /tmp/.properties
Starting Consumer with configuration:

[2022-04-06 11:32:26,795] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [my-cluster-880206dd-target-kafka-bootstrap.namespace-135.svc:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-2132367402-instance474081574
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group-2132367402
	group.instance.id = instance474081574
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (ConsumerConfig:376)
[2022-04-06 11:32:26,800] DEBUG [Consumer instanceId=instance474081574, clientId=consumer-my-consumer-group-2132367402-instance474081574, groupId=my-consumer-group-2132367402] Initializing the Kafka consumer (KafkaConsumer:695)
[2022-04-06 11:32:26,926] INFO Kafka version: 3.1.0 (AppInfoParser:119)
[2022-04-06 11:32:26,927] INFO Kafka commitId: 37edeed0777bacb3 (AppInfoParser:120)
[2022-04-06 11:32:26,927] INFO Kafka startTimeMs: 1649244746923 (AppInfoParser:121)
[2022-04-06 11:32:26,929] DEBUG [Consumer instanceId=instance474081574, clientId=consumer-my-consumer-group-2132367402-instance474081574, groupId=my-consumer-group-2132367402] Kafka consumer initialized (KafkaConsumer:815)
{"timestamp":1649244747068,"name":"startup_complete"}
[2022-04-06 11:32:27,109] INFO [Consumer instanceId=instance474081574, clientId=consumer-my-consumer-group-2132367402-instance474081574, groupId=my-consumer-group-2132367402] Subscribed to topic(s): not-included-topic (KafkaConsumer:966)
[2022-04-06 11:32:27,110] DEBUG [Consumer instanceId=instance474081574, clientId=consumer-my-consumer-group-2132367402-instance474081574, groupId=my-consumer-group-2132367402] Sending FindCoordinator request to broker my-cluster-880206dd-target-kafka-bootstrap.namespace-135.svc:9092 (id: -1 rack: null) (ConsumerCoordinator:821)
[2022-04-06 11:32:27,347] DEBUG Resolved host my-cluster-880206dd-target-kafka-bootstrap.namespace-135.svc as 10.103.124.106 (ClientUtils:113)
[2022-04-06 11:32:27,348] DEBUG [Consumer instanceId=instance474081574, clientId=consumer-my-consumer-group-2132367402-instance474081574, groupId=my-consumer-group-2132367402] Initiating connection to node my-cluster-880206dd-target-kafka-bootstrap.namespace-135.svc:9092 (id: -1 rack: null) using address my-cluster-880206dd-target-kafka-bootstrap.namespace-135.svc/10.103.124.106 (NetworkClient:985)
[2022-04-06 11:32:27,360] DEBUG [Consumer instanceId=instance474081574, clientId=consumer-my-consumer-group-2132367402-instance474081574, groupId=my-consumer-group-2132367402] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1 (Selector:531)
[2022-04-06 11:32:27,362] DEBUG [Consumer instanceId=instance474081574, clientId=consumer-my-consumer-group-2132367402-instance474081574, groupId=my-consumer-group-2132367402] Completed connection to node -1. Fetching API versions. (NetworkClient:952)
[2022-04-06 11:32:27,362] DEBUG [Consumer instanceId=instance474081574, clientId=consumer-my-consumer-group-2132367402-instance474081574, groupId=my-consumer-group-2132367402] Initiating API versions fetch from node -1. (NetworkClient:966)
[2022-04-06 11:32:27,364] DEBUG [Consumer instanceId=instance474081574, clientId=consumer-my-consumer-group-2132367402-instance474081574, groupId=my-consumer-group-2132367402] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-my-consumer-group-2132367402-instance474081574, correlationId=1) and timeout 30000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.1.0') (NetworkClient:521)
[2022-04-06 11:32:27,404] DEBUG [Consumer instanceId=instance474081574, clientId=consumer-my-consumer-group-2132367402-instance474081574, groupId=my-consumer-group-2132367402] Received API_VERSIONS response from node -1 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-my-consumer-group-2132367402-instance474081574, correlationId=1): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=9), ApiVersion(apiKey=1, minVersion=0, maxVersion=13), ApiVersion(apiKey=2, minVersion=0, maxVersion=7), ApiVersion(apiKey=3, minVersion=0, maxVersion=12), ApiVersion(apiKey=4, minVersion=0, maxVersion=5), ApiVersion(apiKey=5, minVersion=0, maxVersion=3), ApiVersion(apiKey=6, minVersion=0, maxVersion=7), ApiVersion(apiKey=7, minVersion=0, maxVersion=3), ApiVersion(apiKey=8, minVersion=0, maxVersion=8), ApiVersion(apiKey=9, minVersion=0, maxVersion=8), ApiVersion(apiKey=10, minVersion=0, maxVersion=4), ApiVersion(apiKey=11, minVersion=0, maxVersion=7), ApiVersion(apiKey=12, minVersion=0, maxVersion=4), ApiVersion(apiKey=13, minVersion=0, maxVersion=4), ApiVersion(apiKey=14, minVersion=0, maxVersion=5), ApiVersion(apiKey=15, minVersion=0, maxVersion=5), ApiVersion(apiKey=16, minVersion=0, maxVersion=4), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=3), ApiVersion(apiKey=19, minVersion=0, maxVersion=7), ApiVersion(apiKey=20, minVersion=0, maxVersion=6), ApiVersion(apiKey=21, minVersion=0, maxVersion=2), ApiVersion(apiKey=22, minVersion=0, maxVersion=4), ApiVersion(apiKey=23, minVersion=0, maxVersion=4), ApiVersion(apiKey=24, minVersion=0, maxVersion=3), ApiVersion(apiKey=25, minVersion=0, maxVersion=3), ApiVersion(apiKey=26, minVersion=0, maxVersion=3), ApiVersion(apiKey=27, minVersion=0, maxVersion=1), ApiVersion(apiKey=28, minVersion=0, maxVersion=3), ApiVersion(apiKey=29, minVersion=0, maxVersion=2), ApiVersion(apiKey=30, minVersion=0, maxVersion=2), ApiVersion(apiKey=31, minVersion=0, maxVersion=2), ApiVersion(apiKey=32, minVersion=0, maxVersion=4), ApiVersion(apiKey=33, minVersion=0, maxVersion=2), ApiVersion(apiKey=34, minVersion=0, maxVersion=2), ApiVersion(apiKey=35, minVersion=0, maxVersion=2), ApiVersion(apiKey=36, minVersion=0, maxVersion=2), ApiVersion(apiKey=37, minVersion=0, maxVersion=3), ApiVersion(apiKey=38, minVersion=0, maxVersion=2), ApiVersion(apiKey=39, minVersion=0, maxVersion=2), ApiVersion(apiKey=40, minVersion=0, maxVersion=2), ApiVersion(apiKey=41, minVersion=0, maxVersion=2), ApiVersion(apiKey=42, minVersion=0, maxVersion=2), ApiVersion(apiKey=43, minVersion=0, maxVersion=2), ApiVersion(apiKey=44, minVersion=0, maxVersion=1), ApiVersion(apiKey=45, minVersion=0, maxVersion=0), ApiVersion(apiKey=46, minVersion=0, maxVersion=0), ApiVersion(apiKey=47, minVersion=0, maxVersion=0), ApiVersion(apiKey=48, minVersion=0, maxVersion=1), ApiVersion(apiKey=49, minVersion=0, maxVersion=1), ApiVersion(apiKey=50, minVersion=0, maxVersion=0), ApiVersion(apiKey=51, minVersion=0, maxVersion=0), ApiVersion(apiKey=56, minVersion=0, maxVersion=0), ApiVersion(apiKey=57, minVersion=0, maxVersion=0), ApiVersion(apiKey=60, minVersion=0, maxVersion=0), ApiVersion(apiKey=61, minVersion=0, maxVersion=0), ApiVersion(apiKey=65, minVersion=0, maxVersion=0), ApiVersion(apiKey=66, minVersion=0, maxVersion=0), ApiVersion(apiKey=67, minVersion=0, maxVersion=0)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=0, finalizedFeatures=[]) (NetworkClient:879)
[2022-04-06 11:32:27,462] DEBUG [Consumer instanceId=instance474081574, clientId=consumer-my-consumer-group-2132367402-instance474081574, groupId=my-consumer-group-2132367402] Node -1 has finalized features epoch: 0, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 9 [usable: 9], Fetch(1): 0 to 13 [usable: 13], ListOffsets(2): 0 to 7 [usable: 7], Metadata(3): 0 to 12 [usable: 12], LeaderAndIsr(4): 0 to 5 [usable: 5], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 7 [usable: 7], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 8 [usable: 8], FindCoordinator(10): 0 to 4 [usable: 4], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 7 [usable: 7], DeleteTopics(20): 0 to 6 [usable: 6], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 4 [usable: 4], AddPartitionsToTxn(24): 0 to 3 [usable: 3], AddOffsetsToTxn(25): 0 to 3 [usable: 3], EndTxn(26): 0 to 3 [usable: 3], WriteTxnMarkers(27): 0 to 1 [usable: 1], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 4 [usable: 4], AlterConfigs(33): 0 to 2 [usable: 2], AlterReplicaLogDirs(34): 0 to 2 [usable: 2], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 to 1 [usable: 1], AlterClientQuotas(49): 0 to 1 [usable: 1], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0], DescribeCluster(60): 0 [usable: 0], DescribeProducers(61): 0 [usable: 0], DescribeTransactions(65): 0 [usable: 0], ListTransactions(66): 0 [usable: 0], AllocateProducerIds(67): 0 [usable: 0]). (NetworkClient:921)
[2022-04-06 11:32:27,465] DEBUG [Consumer instanceId=instance474081574, clientId=consumer-my-consumer-group-2132367402-instance474081574, groupId=my-consumer-group-2132367402] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='not-included-topic')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node my-cluster-880206dd-target-kafka-bootstrap.namespace-135.svc:9092 (id: -1 rack: null) (NetworkClient:1139)
[2022-04-06 11:32:27,466] DEBUG [Consumer instanceId=instance474081574, clientId=consumer-my-consumer-group-2132367402-instance474081574, groupId=my-consumer-group-2132367402] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=12, clientId=consumer-my-consumer-group-2132367402-instance474081574, correlationId=2) and timeout 30000 to node -1: MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='not-included-topic')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) (NetworkClient:521)
[2022-04-06 11:32:27,467] DEBUG [Consumer instanceId=instance474081574, clientId=consumer-my-consumer-group-2132367402-instance474081574, groupId=my-consumer-group-2132367402] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=4, clientId=consumer-my-consumer-group-2132367402-instance474081574, correlationId=0) and timeout 30000 to node -1: FindCoordinatorRequestData(key='', keyType=0, coordinatorKeys=[my-consumer-group-2132367402]) (NetworkClient:521)
[2022-04-06 11:32:27,485] DEBUG [Consumer instanceId=instance474081574, clientId=consumer-my-consumer-group-2132367402-instance474081574, groupId=my-consumer-group-2132367402] Received METADATA response from node -1 for request with header RequestHeader(apiKey=METADATA, apiVersion=12, clientId=consumer-my-consumer-group-2132367402-instance474081574, correlationId=2): MetadataResponseData(throttleTimeMs=0, brokers=[MetadataResponseBroker(nodeId=0, host='my-cluster-880206dd-target-kafka-0.my-cluster-880206dd-target-kafka-brokers.namespace-135.svc', port=9092, rack=null)], clusterId='OLdbpVW4QmOoRtp_BF2cVw', controllerId=0, topics=[MetadataResponseTopic(errorCode=5, name='not-included-topic', topicId=AAAAAAAAAAAAAAAAAAAAAA, isInternal=false, partitions=[], topicAuthorizedOperations=-2147483648)], clusterAuthorizedOperations=-2147483648) (NetworkClient:879)
[2022-04-06 11:32:27,489] WARN [Consumer instanceId=instance474081574, clientId=consumer-my-consumer-group-2132367402-instance474081574, groupId=my-consumer-group-2132367402] Error while fetching metadata with correlation id 2 : {not-included-topic=LEADER_NOT_AVAILABLE} (NetworkClient:1099)
[2022-04-06 11:32:27,489] DEBUG [Consumer instanceId=instance474081574, clientId=consumer-my-consumer-group-2132367402-instance474081574, groupId=my-consumer-group-2132367402] Requesting metadata update for topic not-included-topic due to error LEADER_NOT_AVAILABLE (Metadata:363)
[2022-04-06 11:32:27,490] INFO [Consumer instanceId=instance474081574, clientId=consumer-my-consumer-group-2132367402-instance474081574, groupId=my-consumer-group-2132367402] Cluster ID: OLdbpVW4QmOoRtp_BF2cVw (Metadata:287)
[2022-04-06 11:32:27,490] DEBUG [Consumer instanceId=instance474081574, clientId=consumer-my-consumer-group-2132367402-instance474081574, groupId=my-consumer-group-2132367402] Updated cluster metadata updateVersion 2 to MetadataCache{clusterId='OLdbpVW4QmOoRtp_BF2cVw', nodes={0=my-cluster-880206dd-target-kafka-0.my-cluster-880206dd-target-kafka-brokers.namespace-135.svc:9092 (id: 0 rack: null)}, partitions=[], controller=my-cluster-880206dd-target-kafka-0.my-cluster-880206dd-target-kafka-brokers.namespace-135.svc:9092 (id: 0 rack: null)} (Metadata:291)
[2022-04-06 11:32:27,491] DEBUG [Consumer instanceId=instance474081574, clientId=consumer-my-consumer-group-2132367402-instance474081574, groupId=my-consumer-group-2132367402] Received FIND_COORDINATOR response from node -1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=4, clientId=consumer-my-consumer-group-2132367402-instance474081574, correlationId=0): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='', nodeId=0, host='', port=0, coordinators=[Coordinator(key='my-consumer-group-2132367402', nodeId=0, host='my-cluster-880206dd-target-kafka-0.my-cluster-880206dd-target-kafka-brokers.namespace-135.svc', port=9092, errorCode=0, errorMessage='')]) (NetworkClient:879)
[2022-04-06 11:32:27,492] DEBUG [Consumer instanceId=instance474081574, clientId=consumer-my-consumer-group-2132367402-instance474081574, groupId=my-consumer-group-2132367402] Received FindCoordinator response ClientResponse(receivedTimeMs=1649244747491, latencyMs=151, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=4, clientId=consumer-my-consumer-group-2132367402-instance474081574, correlationId=0), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='', nodeId=0, host='', port=0, coordinators=[Coordinator(key='my-consumer-group-2132367402', nodeId=0, host='my-cluster-880206dd-target-kafka-0.my-cluster-880206dd-target-kafka-brokers.namespace-135.svc', port=9092, errorCode=0, errorMessage='')])) (ConsumerCoordinator:834)
[2022-04-06 11:32:27,492] INFO [Consumer instanceId=instance474081574, clientId=consumer-my-consumer-group-2132367402-instance474081574, groupId=my-consumer-group-2132367402] Discovered group coordinator my-cluster-880206dd-target-kafka-0.my-cluster-880206dd-target-kafka-brokers.namespace-135.svc:9092 (id: 2147483647 rack: null) (ConsumerCoordinator:853)
[2022-04-06 11:32:27,494] DEBUG Resolved host my-cluster-880206dd-target-kafka-0.my-cluster-880206dd-target-kafka-brokers.namespace-135.svc as 172.17.0.11 (ClientUtils:113)
[2022-04-06 11:32:27,494] DEBUG [Consumer instanceId=instance474081574, clientId=consumer-my-consumer-group-2132367402-instance474081574, groupId=my-consumer-group-2132367402] Initiating connection to node my-cluster-880206dd-target-kafka-0.my-cluster-880206dd-target-kafka-brokers.namespace-135.svc:9092 (id: 2147483647 rack: null) using address my-cluster-880206dd-target-kafka-0.my-cluster-880206dd-target-kafka-brokers.namespace-135.svc/172.17.0.11 (NetworkClient:985)
[2022-04-06 11:32:27,496] DEBUG [Consumer instanceId=instance474081574, clientId=consumer-my-consumer-group-2132367402-instance474081574, groupId=my-consumer-group-2132367402] Executing onJoinPrepare with generation -1 and memberId  (ConsumerCoordinator:700)
[2022-04-06 11:32:27,496] DEBUG [Consumer instanceId=instance474081574, clientId=consumer-my-consumer-group-2132367402-instance474081574, groupId=my-consumer-group-2132367402] Heartbeat thread started (ConsumerCoordinator:1367)
[2022-04-06 11:32:27,497] INFO [Consumer instanceId=instance474081574, clientId=consumer-my-consumer-group-2132367402-instance474081574, groupId=my-consumer-group-2132367402] (Re-)joining group (ConsumerCoordinator:535)
[2022-04-06 11:32:27,499] DEBUG [Consumer instanceId=instance474081574, clie
2022-04-06 11:34:25 [main] [32mINFO [m [VerifiableClient:203] ======STDOUT END======
2022-04-06 11:34:25 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: false
2022-04-06 11:34:25 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 0 messages
2022-04-06 11:34:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:34:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testIncludeList
2022-04-06 11:34:25 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic not-included-topic in namespace namespace-135
2022-04-06 11:34:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-880206dd-source in namespace namespace-135
2022-04-06 11:34:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-880206dd in namespace namespace-135
2022-04-06 11:34:25 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-880206dd-kafka-clients in namespace namespace-135
2022-04-06 11:34:25 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic included-topic in namespace namespace-135
2022-04-06 11:34:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-880206dd-target in namespace namespace-135
2022-04-06 11:35:15 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:35:15 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-135 for test case:testIncludeList
2022-04-06 11:35:20 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testIncludeList-FINISHED
2022-04-06 11:35:20 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:35:20 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:35:20 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testConfigureDeploymentStrategy-STARTED
2022-04-06 11:35:20 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:35:20 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-136 for test case:testConfigureDeploymentStrategy
2022-04-06 11:35:20 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-136
2022-04-06 11:35:20 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-136
2022-04-06 11:35:20 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-136
2022-04-06 11:35:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c1bd79e8-source in namespace namespace-136
2022-04-06 11:35:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-136
2022-04-06 11:35:20 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c1bd79e8-source will have desired state: Ready
2022-04-06 11:36:30 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c1bd79e8-source is in desired state: Ready
2022-04-06 11:36:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c1bd79e8-target in namespace namespace-136
2022-04-06 11:36:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-136
2022-04-06 11:36:30 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c1bd79e8-target will have desired state: Ready
2022-04-06 11:37:37 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c1bd79e8-target is in desired state: Ready
2022-04-06 11:37:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-c1bd79e8 in namespace namespace-136
2022-04-06 11:37:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-136
2022-04-06 11:37:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-c1bd79e8 will have desired state: Ready
2022-04-06 11:38:42 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-c1bd79e8 is in desired state: Ready
2022-04-06 11:38:42 [main] [32mINFO [m [MirrorMakerIsolatedST:763] Adding label to MirrorMaker resource, the CR should be recreateAndWaitForReadinessd
2022-04-06 11:38:42 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c1bd79e8-mirror-maker will be ready
2022-04-06 11:38:42 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c1bd79e8-mirror-maker is ready
2022-04-06 11:38:42 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-c1bd79e8-mirror-maker to be ready
2022-04-06 11:40:03 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-c1bd79e8-mirror-maker is ready
2022-04-06 11:40:03 [main] [32mINFO [m [MirrorMakerIsolatedST:770] Checking that observed gen. is still on 1 (recreation) and new label is present
2022-04-06 11:40:03 [main] [32mINFO [m [MirrorMakerIsolatedST:775] Changing deployment strategy to ROLLING_UPDATE
2022-04-06 11:40:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-c1bd79e8 will have desired state: Ready
2022-04-06 11:40:03 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-c1bd79e8 is in desired state: Ready
2022-04-06 11:40:03 [main] [32mINFO [m [MirrorMakerIsolatedST:780] Adding another label to MirrorMaker resource, pods should be rolled
2022-04-06 11:40:03 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c1bd79e8-mirror-maker will be ready
2022-04-06 11:40:04 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c1bd79e8-mirror-maker is ready
2022-04-06 11:40:04 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-c1bd79e8-mirror-maker to be ready
2022-04-06 11:41:33 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-c1bd79e8-mirror-maker is ready
2022-04-06 11:41:33 [main] [32mINFO [m [MirrorMakerIsolatedST:784] Checking that observed gen. higher (rolling update) and label is changed
2022-04-06 11:41:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:41:33 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigureDeploymentStrategy
2022-04-06 11:41:33 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c1bd79e8-target in namespace namespace-136
2022-04-06 11:41:33 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-c1bd79e8 in namespace namespace-136
2022-04-06 11:41:33 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c1bd79e8-source in namespace namespace-136
2022-04-06 11:41:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:41:53 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-136 for test case:testConfigureDeploymentStrategy
2022-04-06 11:42:20 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testConfigureDeploymentStrategy-FINISHED
2022-04-06 11:42:20 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:42:20 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:42:20 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testScaleMirrorMakerToZero-STARTED
2022-04-06 11:42:20 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:42:20 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-137 for test case:testScaleMirrorMakerToZero
2022-04-06 11:42:20 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-137
2022-04-06 11:42:20 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-137
2022-04-06 11:42:20 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-137
2022-04-06 11:42:20 [main] [32mINFO [m [MirrorMakerIsolatedST:713] Creating kafka source cluster my-cluster-6f0d5c47-source
2022-04-06 11:42:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-6f0d5c47-source in namespace namespace-137
2022-04-06 11:42:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-137
2022-04-06 11:42:20 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-6f0d5c47-source will have desired state: Ready
2022-04-06 11:43:28 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-6f0d5c47-source is in desired state: Ready
2022-04-06 11:43:28 [main] [32mINFO [m [MirrorMakerIsolatedST:715] Creating kafka target cluster my-cluster-6f0d5c47-target
2022-04-06 11:43:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-6f0d5c47-target in namespace namespace-137
2022-04-06 11:43:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-137
2022-04-06 11:43:28 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-6f0d5c47-target will have desired state: Ready
2022-04-06 11:44:40 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-6f0d5c47-target is in desired state: Ready
2022-04-06 11:44:40 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-6f0d5c47 in namespace namespace-137
2022-04-06 11:44:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-137
2022-04-06 11:44:40 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-6f0d5c47 will have desired state: Ready
2022-04-06 11:45:51 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-6f0d5c47 is in desired state: Ready
2022-04-06 11:45:51 [main] [32mINFO [m [MirrorMakerIsolatedST:725] Scaling MirrorMaker to zero
2022-04-06 11:46:04 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:46:04 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleMirrorMakerToZero
2022-04-06 11:46:04 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-6f0d5c47-target in namespace namespace-137
2022-04-06 11:46:04 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-6f0d5c47 in namespace namespace-137
2022-04-06 11:46:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-6f0d5c47-source in namespace namespace-137
2022-04-06 11:46:24 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:46:24 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-137 for test case:testScaleMirrorMakerToZero
2022-04-06 11:47:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testScaleMirrorMakerToZero-FINISHED
2022-04-06 11:47:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:47:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:47:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testScaleMirrorMakerSubresource-STARTED
2022-04-06 11:47:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:47:07 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-138 for test case:testScaleMirrorMakerSubresource
2022-04-06 11:47:07 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-138
2022-04-06 11:47:07 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-138
2022-04-06 11:47:07 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-138
2022-04-06 11:47:07 [main] [32mINFO [m [MirrorMakerIsolatedST:674] Creating kafka source cluster my-cluster-f2806107-source
2022-04-06 11:47:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-f2806107-source in namespace namespace-138
2022-04-06 11:47:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-138
2022-04-06 11:47:07 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f2806107-source will have desired state: Ready
2022-04-06 11:48:18 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f2806107-source is in desired state: Ready
2022-04-06 11:48:18 [main] [32mINFO [m [MirrorMakerIsolatedST:676] Creating kafka target cluster my-cluster-f2806107-target
2022-04-06 11:48:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-f2806107-target in namespace namespace-138
2022-04-06 11:48:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-138
2022-04-06 11:48:18 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f2806107-target will have desired state: Ready
2022-04-06 11:49:23 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f2806107-target is in desired state: Ready
2022-04-06 11:49:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-f2806107 in namespace namespace-138
2022-04-06 11:49:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-138
2022-04-06 11:49:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-f2806107 will have desired state: Ready
2022-04-06 11:50:34 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-f2806107 is in desired state: Ready
2022-04-06 11:50:34 [main] [32mINFO [m [MirrorMakerIsolatedST:685] -------> Scaling KafkaMirrorMaker subresource <-------
2022-04-06 11:50:34 [main] [32mINFO [m [MirrorMakerIsolatedST:686] Scaling subresource replicas to 4
2022-04-06 11:50:34 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f2806107-mirror-maker will be ready
2022-04-06 11:50:34 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f2806107-mirror-maker is ready
2022-04-06 11:50:34 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 4 Pod(s) of Deployment my-cluster-f2806107-mirror-maker to be ready
2022-04-06 11:51:54 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-f2806107-mirror-maker is ready
2022-04-06 11:51:54 [main] [32mINFO [m [MirrorMakerIsolatedST:690] Check if replicas is set to 4, naming prefix should be same and observed generation higher
2022-04-06 11:51:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:51:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleMirrorMakerSubresource
2022-04-06 11:51:54 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-f2806107-target in namespace namespace-138
2022-04-06 11:51:54 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-f2806107 in namespace namespace-138
2022-04-06 11:51:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-f2806107-source in namespace namespace-138
2022-04-06 11:52:14 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:52:14 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-138 for test case:testScaleMirrorMakerSubresource
2022-04-06 11:52:20 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testScaleMirrorMakerSubresource-FINISHED
2022-04-06 11:52:20 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:52:20 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:52:20 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testCustomAndUpdatedValues-STARTED
2022-04-06 11:52:20 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:52:20 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-139 for test case:testCustomAndUpdatedValues
2022-04-06 11:52:20 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-139
2022-04-06 11:52:20 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-139
2022-04-06 11:52:20 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-139
2022-04-06 11:52:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-cd05f8e9 in namespace namespace-139
2022-04-06 11:52:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-139
2022-04-06 11:52:20 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-cd05f8e9 will have desired state: Ready
2022-04-06 11:53:06 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-cd05f8e9 is in desired state: Ready
2022-04-06 11:53:06 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-cd05f8e9 in namespace namespace-139
2022-04-06 11:53:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-139
2022-04-06 11:53:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-cd05f8e9 will have desired state: Ready
2022-04-06 11:53:41 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-cd05f8e9 is in desired state: Ready
2022-04-06 11:53:41 [main] [32mINFO [m [MirrorMakerIsolatedST:622] Verify values before update
2022-04-06 11:53:41 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-cd05f8e9-mirror-maker in pod name
2022-04-06 11:53:41 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container my-cluster-cd05f8e9-mirror-maker
2022-04-06 11:53:41 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-cd05f8e9-mirror-maker
2022-04-06 11:53:41 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container my-cluster-cd05f8e9-mirror-maker
2022-04-06 11:53:41 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-cd05f8e9-mirror-maker
2022-04-06 11:53:41 [main] [32mINFO [m [AbstractST:194] Testing configuration for container my-cluster-cd05f8e9-mirror-maker
2022-04-06 11:53:41 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-cd05f8e9-mirror-maker
2022-04-06 11:53:41 [main] [32mINFO [m [AbstractST:194] Testing configuration for container my-cluster-cd05f8e9-mirror-maker
2022-04-06 11:53:41 [main] [32mINFO [m [MirrorMakerIsolatedST:633] Check if actual env variable KAFKA_MIRRORMAKER_CONFIGURATION_PRODUCER has different value than test.value
2022-04-06 11:53:41 [main] [32mINFO [m [MirrorMakerIsolatedST:637] Updating values in MirrorMaker container
2022-04-06 11:53:41 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-cd05f8e9-mirror-maker rolling update
2022-04-06 11:54:21 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-cd05f8e9-mirror-maker will be ready
2022-04-06 11:54:21 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-cd05f8e9-mirror-maker is ready
2022-04-06 11:54:31 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-cd05f8e9-mirror-maker rolling update finished
2022-04-06 11:54:31 [main] [32mINFO [m [MirrorMakerIsolatedST:654] Verify values after update
2022-04-06 11:54:31 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-cd05f8e9-mirror-maker in pod name
2022-04-06 11:54:31 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container my-cluster-cd05f8e9-mirror-maker
2022-04-06 11:54:31 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-cd05f8e9-mirror-maker
2022-04-06 11:54:31 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container my-cluster-cd05f8e9-mirror-maker
2022-04-06 11:54:31 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-cd05f8e9-mirror-maker
2022-04-06 11:54:31 [main] [32mINFO [m [AbstractST:194] Testing configuration for container my-cluster-cd05f8e9-mirror-maker
2022-04-06 11:54:31 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-cd05f8e9-mirror-maker
2022-04-06 11:54:31 [main] [32mINFO [m [AbstractST:194] Testing configuration for container my-cluster-cd05f8e9-mirror-maker
2022-04-06 11:54:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:54:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCustomAndUpdatedValues
2022-04-06 11:54:31 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-cd05f8e9 in namespace namespace-139
2022-04-06 11:54:31 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-cd05f8e9 in namespace namespace-139
2022-04-06 11:54:42 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:54:42 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-139 for test case:testCustomAndUpdatedValues
2022-04-06 11:55:08 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testCustomAndUpdatedValues-FINISHED
2022-04-06 11:55:08 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:55:08 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:55:08 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMaker-STARTED
2022-04-06 11:55:08 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:55:08 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-140 for test case:testMirrorMaker
2022-04-06 11:55:09 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-140
2022-04-06 11:55:09 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-140
2022-04-06 11:55:09 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-140
2022-04-06 11:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e7942704-source in namespace namespace-140
2022-04-06 11:55:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-140
2022-04-06 11:55:09 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e7942704-source will have desired state: Ready
2022-04-06 11:56:13 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e7942704-source is in desired state: Ready
2022-04-06 11:56:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e7942704-target in namespace namespace-140
2022-04-06 11:56:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-140
2022-04-06 11:56:13 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e7942704-target will have desired state: Ready
2022-04-06 11:57:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e7942704-target is in desired state: Ready
2022-04-06 11:57:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-57885039-819052364-source-506971212 in namespace namespace-140
2022-04-06 11:57:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-140
2022-04-06 11:57:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-57885039-819052364-source-506971212 will have desired state: Ready
2022-04-06 11:57:22 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-57885039-819052364-source-506971212 is in desired state: Ready
2022-04-06 11:57:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-e7942704-kafka-clients in namespace namespace-140
2022-04-06 11:57:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-140
2022-04-06 11:57:22 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-e7942704-kafka-clients will be ready
2022-04-06 11:57:24 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-e7942704-kafka-clients is ready
2022-04-06 11:57:24 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 11:57:24 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@11d50f53, messages=[], arguments=[--max-messages, 200, --topic, topic-for-test-broker-1, --bootstrap-server, my-cluster-e7942704-source-kafka-bootstrap.namespace-140.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-e7942704-kafka-clients-5fdf466d79-vgnxj', podNamespace='namespace-140', bootstrapServer='my-cluster-e7942704-source-kafka-bootstrap.namespace-140.svc:9092', topicName='topic-for-test-broker-1', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3965a184}
2022-04-06 11:57:24 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-e7942704-source-kafka-bootstrap.namespace-140.svc:9092:topic-for-test-broker-1 from pod my-cluster-e7942704-kafka-clients-5fdf466d79-vgnxj
2022-04-06 11:57:24 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-e7942704-kafka-clients-5fdf466d79-vgnxj -n namespace-140 -- /opt/kafka/producer.sh --max-messages 200 --topic topic-for-test-broker-1 --bootstrap-server my-cluster-e7942704-source-kafka-bootstrap.namespace-140.svc:9092
2022-04-06 11:57:27 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 11:57:27 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-06 11:57:27 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2657894d, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-1861232282, --group-instance-id, instance498815527, --topic, topic-for-test-broker-1, --bootstrap-server, my-cluster-e7942704-source-kafka-bootstrap.namespace-140.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-e7942704-kafka-clients-5fdf466d79-vgnxj', podNamespace='namespace-140', bootstrapServer='my-cluster-e7942704-source-kafka-bootstrap.namespace-140.svc:9092', topicName='topic-for-test-broker-1', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-1861232282', consumerInstanceId='instance498815527', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@322a770d}
2022-04-06 11:57:27 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-e7942704-source-kafka-bootstrap.namespace-140.svc:9092#topic-for-test-broker-1 from pod my-cluster-e7942704-kafka-clients-5fdf466d79-vgnxj
2022-04-06 11:57:27 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-e7942704-kafka-clients-5fdf466d79-vgnxj -n namespace-140 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-1861232282 --group-instance-id instance498815527 --topic topic-for-test-broker-1 --bootstrap-server my-cluster-e7942704-source-kafka-bootstrap.namespace-140.svc:9092
2022-04-06 11:57:32 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 11:57:32 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-06 11:57:32 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@36bb6cb2, messages=[], arguments=[--max-messages, 200, --topic, topic-for-test-broker-2, --bootstrap-server, my-cluster-e7942704-target-kafka-bootstrap.namespace-140.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-e7942704-kafka-clients-5fdf466d79-vgnxj', podNamespace='namespace-140', bootstrapServer='my-cluster-e7942704-target-kafka-bootstrap.namespace-140.svc:9092', topicName='topic-for-test-broker-2', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1fc1a543}
2022-04-06 11:57:32 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-e7942704-target-kafka-bootstrap.namespace-140.svc:9092:topic-for-test-broker-2 from pod my-cluster-e7942704-kafka-clients-5fdf466d79-vgnxj
2022-04-06 11:57:32 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-e7942704-kafka-clients-5fdf466d79-vgnxj -n namespace-140 -- /opt/kafka/producer.sh --max-messages 200 --topic topic-for-test-broker-2 --bootstrap-server my-cluster-e7942704-target-kafka-bootstrap.namespace-140.svc:9092
2022-04-06 11:57:35 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 11:57:35 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-06 11:57:35 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4dcf0122, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-1119070212, --group-instance-id, instance1328249125, --topic, topic-for-test-broker-2, --bootstrap-server, my-cluster-e7942704-target-kafka-bootstrap.namespace-140.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-e7942704-kafka-clients-5fdf466d79-vgnxj', podNamespace='namespace-140', bootstrapServer='my-cluster-e7942704-target-kafka-bootstrap.namespace-140.svc:9092', topicName='topic-for-test-broker-2', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-1119070212', consumerInstanceId='instance1328249125', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@57c8e777}
2022-04-06 11:57:35 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-e7942704-target-kafka-bootstrap.namespace-140.svc:9092#topic-for-test-broker-2 from pod my-cluster-e7942704-kafka-clients-5fdf466d79-vgnxj
2022-04-06 11:57:35 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-e7942704-kafka-clients-5fdf466d79-vgnxj -n namespace-140 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-1119070212 --group-instance-id instance1328249125 --topic topic-for-test-broker-2 --bootstrap-server my-cluster-e7942704-target-kafka-bootstrap.namespace-140.svc:9092
2022-04-06 11:57:40 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 11:57:40 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-06 11:57:40 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-e7942704 in namespace namespace-140
2022-04-06 11:57:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-140
2022-04-06 11:57:40 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-e7942704 will have desired state: Ready
2022-04-06 11:58:51 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-e7942704 is in desired state: Ready
2022-04-06 11:58:51 [main] [32mINFO [m [AbstractST:311] Verifying labels on pod type mirror-maker
2022-04-06 11:58:51 [main] [32mINFO [m [AbstractST:315] Verifying labels for pod: my-cluster-e7942704-mirror-maker-869d5c45cf-qtqd2
2022-04-06 11:58:51 [main] [32mINFO [m [AbstractST:356] Verifying labels for Kafka Connect Services
2022-04-06 11:58:51 [main] [32mINFO [m [AbstractST:384] Verifying labels for Config maps
2022-04-06 11:58:51 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-e7942704-mirror-maker-config
2022-04-06 11:58:51 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-e7942704-source-entity-topic-operator-config
2022-04-06 11:58:51 [main] [32mINFO [m [AbstractST:407] CM my-cluster-e7942704-source-entity-topic-operator-config is not related to current test
2022-04-06 11:58:51 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-e7942704-source-entity-user-operator-config
2022-04-06 11:58:51 [main] [32mINFO [m [AbstractST:407] CM my-cluster-e7942704-source-entity-user-operator-config is not related to current test
2022-04-06 11:58:51 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-e7942704-source-kafka-config
2022-04-06 11:58:51 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-e7942704-source-zookeeper-config
2022-04-06 11:58:51 [main] [32mINFO [m [AbstractST:407] CM my-cluster-e7942704-source-zookeeper-config is not related to current test
2022-04-06 11:58:51 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-e7942704-target-entity-topic-operator-config
2022-04-06 11:58:51 [main] [32mINFO [m [AbstractST:407] CM my-cluster-e7942704-target-entity-topic-operator-config is not related to current test
2022-04-06 11:58:51 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-e7942704-target-entity-user-operator-config
2022-04-06 11:58:51 [main] [32mINFO [m [AbstractST:407] CM my-cluster-e7942704-target-entity-user-operator-config is not related to current test
2022-04-06 11:58:51 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-e7942704-target-kafka-config
2022-04-06 11:58:51 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-e7942704-target-zookeeper-config
2022-04-06 11:58:51 [main] [32mINFO [m [AbstractST:407] CM my-cluster-e7942704-target-zookeeper-config is not related to current test
2022-04-06 11:58:51 [main] [32mINFO [m [AbstractST:414] Verifying labels for Service Accounts
2022-04-06 11:58:51 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-e7942704-source-entity-operator
2022-04-06 11:58:51 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-e7942704-source-kafka
2022-04-06 11:58:51 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-e7942704-source-zookeeper
2022-04-06 11:58:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-140 exec my-cluster-e7942704-mirror-maker-869d5c45cf-qtqd2 -c my-cluster-e7942704-mirror-maker -- /bin/bash -c for proc in $(ls -1 /proc/ | grep [0-9]); do if echo "$(ls -lh /proc/$proc/exe 2>/dev/null || true)" | grep -q java; then cat /proc/$proc/cmdline; fi; done
2022-04-06 11:58:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 11:58:51 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@7abdbf3b, messages=[], arguments=[--max-messages, 200, --topic, my-topic-57885039-819052364-source-506971212, --bootstrap-server, my-cluster-e7942704-source-kafka-bootstrap.namespace-140.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-e7942704-kafka-clients-5fdf466d79-vgnxj', podNamespace='namespace-140', bootstrapServer='my-cluster-e7942704-source-kafka-bootstrap.namespace-140.svc:9092', topicName='my-topic-57885039-819052364-source-506971212', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@17950eca}
2022-04-06 11:58:51 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-e7942704-source-kafka-bootstrap.namespace-140.svc:9092:my-topic-57885039-819052364-source-506971212 from pod my-cluster-e7942704-kafka-clients-5fdf466d79-vgnxj
2022-04-06 11:58:51 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-e7942704-kafka-clients-5fdf466d79-vgnxj -n namespace-140 -- /opt/kafka/producer.sh --max-messages 200 --topic my-topic-57885039-819052364-source-506971212 --bootstrap-server my-cluster-e7942704-source-kafka-bootstrap.namespace-140.svc:9092
2022-04-06 11:58:53 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 11:58:53 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-06 11:58:53 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7780661d, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-1054057144, --group-instance-id, instance1637458367, --topic, my-topic-57885039-819052364-source-506971212, --bootstrap-server, my-cluster-e7942704-source-kafka-bootstrap.namespace-140.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-e7942704-kafka-clients-5fdf466d79-vgnxj', podNamespace='namespace-140', bootstrapServer='my-cluster-e7942704-source-kafka-bootstrap.namespace-140.svc:9092', topicName='my-topic-57885039-819052364-source-506971212', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-1054057144', consumerInstanceId='instance1637458367', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@639f843e}
2022-04-06 11:58:53 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-e7942704-source-kafka-bootstrap.namespace-140.svc:9092#my-topic-57885039-819052364-source-506971212 from pod my-cluster-e7942704-kafka-clients-5fdf466d79-vgnxj
2022-04-06 11:58:53 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-e7942704-kafka-clients-5fdf466d79-vgnxj -n namespace-140 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-1054057144 --group-instance-id instance1637458367 --topic my-topic-57885039-819052364-source-506971212 --bootstrap-server my-cluster-e7942704-source-kafka-bootstrap.namespace-140.svc:9092
2022-04-06 11:58:59 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 11:58:59 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-06 11:58:59 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5f8fff2e, messages=[], arguments=[--max-messages, 200, --group-id, my-consumer-group-534704408, --group-instance-id, instance1663249026, --topic, my-topic-57885039-819052364-source-506971212, --bootstrap-server, my-cluster-e7942704-target-kafka-bootstrap.namespace-140.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-e7942704-kafka-clients-5fdf466d79-vgnxj', podNamespace='namespace-140', bootstrapServer='my-cluster-e7942704-target-kafka-bootstrap.namespace-140.svc:9092', topicName='my-topic-57885039-819052364-source-506971212', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-534704408', consumerInstanceId='instance1663249026', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@485cc579}
2022-04-06 11:58:59 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-e7942704-target-kafka-bootstrap.namespace-140.svc:9092#my-topic-57885039-819052364-source-506971212 from pod my-cluster-e7942704-kafka-clients-5fdf466d79-vgnxj
2022-04-06 11:58:59 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-e7942704-kafka-clients-5fdf466d79-vgnxj -n namespace-140 -- /opt/kafka/consumer.sh --max-messages 200 --group-id my-consumer-group-534704408 --group-instance-id instance1663249026 --topic my-topic-57885039-819052364-source-506971212 --bootstrap-server my-cluster-e7942704-target-kafka-bootstrap.namespace-140.svc:9092
2022-04-06 11:59:05 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 11:59:05 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-06 11:59:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:59:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker
2022-04-06 11:59:05 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-57885039-819052364-source-506971212 in namespace namespace-140
2022-04-06 11:59:05 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-e7942704 in namespace namespace-140
2022-04-06 11:59:05 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-e7942704-kafka-clients in namespace namespace-140
2022-04-06 11:59:05 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e7942704-source in namespace namespace-140
2022-04-06 11:59:05 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e7942704-target in namespace namespace-140
2022-04-06 11:59:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:59:55 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-140 for test case:testMirrorMaker
2022-04-06 12:00:00 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMaker-FINISHED
2022-04-06 12:00:00 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 12:00:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:00:00 [main] [32mINFO [m [ResourceManager:346] In context MirrorMakerIsolatedST is everything deleted.
2022-04-06 12:00:00 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2,638.502 s - in io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.metrics.MetricsIsolatedST
2022-04-06 12:00:00 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 12:00:25 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 12:00:25 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 12:00:25 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 12:00:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:00:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 12:00:25 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:25 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 12:00:25 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 12:00:25 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:25 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 12:00:25 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 12:00:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:25 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:00:25 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 12:00:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:00:25 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 12:00:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 12:00:25 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:00:25 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 12:00:25 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 12:00:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:25 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 12:00:25 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:25 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 12:00:25 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:00:25 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:35 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:35 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:35 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 12:00:45 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:00:50 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace,second-metrics-cluster-test
bindingsNamespaces=[infra-namespace, second-metrics-cluster-test]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 12:00:50 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 12:00:50 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 12:00:50 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: second-metrics-cluster-test
2022-04-06 12:00:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 12:00:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:00:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 12:00:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 12:00:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 12:00:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 12:00:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 12:00:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 12:00:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:00:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 12:00:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: second-metrics-cluster-test
2022-04-06 12:00:51 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 12:00:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 12:00:51 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 12:00:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 12:00:51 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 12:00:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 12:00:51 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 12:00:51 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:00:51 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 12:00:51 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 12:00:51 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 12:00:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 12:00:51 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 12:00:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 12:00:51 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 12:00:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 12:00:51 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 12:00:51 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace second-metrics-cluster-test
2022-04-06 12:00:51 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 12:00:51 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-metrics-cluster-test
2022-04-06 12:00:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:00:51 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 12:01:25 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 12:01:25 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 12:01:35 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 12:01:35 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 12:01:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka metrics-cluster-name in namespace infra-namespace
2022-04-06 12:01:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka second-kafka-cluster in namespace second-metrics-cluster-test
2022-04-06 12:01:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment infra-namespace-kafka-clients in namespace infra-namespace
2022-04-06 12:01:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment second-metrics-cluster-test-kafka-clients in namespace second-metrics-cluster-test
2022-04-06 12:01:35 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: metrics-cluster-name will have desired state: Ready
2022-04-06 12:04:36 [main] [32mINFO [m [ResourceManager:444] Kafka: metrics-cluster-name is in desired state: Ready
2022-04-06 12:04:36 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: second-kafka-cluster will have desired state: Ready
2022-04-06 12:04:36 [main] [32mINFO [m [ResourceManager:444] Kafka: second-kafka-cluster is in desired state: Ready
2022-04-06 12:04:36 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: infra-namespace-kafka-clients will be ready
2022-04-06 12:04:36 [main] [32mINFO [m [DeploymentUtils:168] Deployment: infra-namespace-kafka-clients is ready
2022-04-06 12:04:36 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: second-metrics-cluster-test-kafka-clients will be ready
2022-04-06 12:04:36 [main] [32mINFO [m [DeploymentUtils:168] Deployment: second-metrics-cluster-test-kafka-clients is ready
2022-04-06 12:04:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge my-bridge in namespace infra-namespace
2022-04-06 12:04:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: my-bridge will have desired state: Ready
2022-04-06 12:05:02 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: my-bridge is in desired state: Ready
2022-04-06 12:05:02 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 mm2-cluster in namespace infra-namespace
2022-04-06 12:05:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: mm2-cluster will have desired state: Ready
2022-04-06 12:06:05 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: mm2-cluster is in desired state: Ready
2022-04-06 12:06:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2071265083-1486485415 in namespace infra-namespace
2022-04-06 12:06:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2071265083-1486485415 will have desired state: Ready
2022-04-06 12:06:06 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2071265083-1486485415 is in desired state: Ready
2022-04-06 12:06:06 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1677921817-183331475 in namespace infra-namespace
2022-04-06 12:06:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1677921817-183331475 will have desired state: Ready
2022-04-06 12:06:07 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1677921817-183331475 is in desired state: Ready
2022-04-06 12:06:07 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-789290823-2114898132 in namespace infra-namespace
2022-04-06 12:06:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-789290823-2114898132 will have desired state: Ready
2022-04-06 12:06:08 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-789290823-2114898132 is in desired state: Ready
2022-04-06 12:06:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-278375114-1283247985 in namespace infra-namespace
2022-04-06 12:06:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-278375114-1283247985 will have desired state: Ready
2022-04-06 12:06:09 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-278375114-1283247985 is in desired state: Ready
2022-04-06 12:06:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-879461624-1882311746 in namespace infra-namespace
2022-04-06 12:06:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-879461624-1882311746 will have desired state: Ready
2022-04-06 12:06:10 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-879461624-1882311746 is in desired state: Ready
2022-04-06 12:06:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect metrics-cluster-name in namespace infra-namespace
2022-04-06 12:06:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: metrics-cluster-name will have desired state: Ready
2022-04-06 12:07:14 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: metrics-cluster-name is in desired state: Ready
2022-04-06 12:07:14 [main] [32mINFO [m [NetworkPolicyResource:72] Apply NetworkPolicy access to cluster-operator from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-04-06 12:07:14 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy cluster-operator-allow in namespace infra-namespace
2022-04-06 12:07:14 [main] [32mINFO [m [NetworkPolicyResource:90] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-04-06 12:07:14 [main] [32mINFO [m [NetworkPolicyResource:104] Apply NetworkPolicy access to metrics-cluster-name-entity-operator from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-04-06 12:07:14 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy metrics-cluster-name-entity-operator-allow in namespace infra-namespace
2022-04-06 12:07:14 [main] [32mINFO [m [NetworkPolicyResource:128] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-04-06 12:07:14 [main] [32mINFO [m [NetworkPolicyResource:104] Apply NetworkPolicy access to second-kafka-cluster-entity-operator from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-04-06 12:07:14 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy second-kafka-cluster-entity-operator-allow in namespace second-metrics-cluster-test
2022-04-06 12:07:14 [main] [32mINFO [m [NetworkPolicyResource:128] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-04-06 12:07:14 [main] [32mINFO [m [NetworkPolicyResource:141] Apply NetworkPolicy access to metrics-cluster-name-kafka-exporter from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-04-06 12:07:14 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy metrics-cluster-name-kafka-exporter-allow in namespace infra-namespace
2022-04-06 12:07:14 [main] [32mINFO [m [NetworkPolicyResource:161] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-04-06 12:07:14 [main] [32mINFO [m [NetworkPolicyResource:141] Apply NetworkPolicy access to second-kafka-cluster-kafka-exporter from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-04-06 12:07:14 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy second-kafka-cluster-kafka-exporter-allow in namespace second-metrics-cluster-test
2022-04-06 12:07:14 [main] [32mINFO [m [NetworkPolicyResource:161] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-04-06 12:08:36 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.17 from Pod infra-namespace-kafka-clients-748578f786-d7tjw finished with return code: 0
2022-04-06 12:08:38 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.16 from Pod infra-namespace-kafka-clients-748578f786-d7tjw finished with return code: 0
2022-04-06 12:08:39 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.15 from Pod infra-namespace-kafka-clients-748578f786-d7tjw finished with return code: 0
2022-04-06 12:08:40 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.10 from Pod infra-namespace-kafka-clients-748578f786-d7tjw finished with return code: 0
2022-04-06 12:08:40 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.11 from Pod infra-namespace-kafka-clients-748578f786-d7tjw finished with return code: 0
2022-04-06 12:08:41 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.12 from Pod infra-namespace-kafka-clients-748578f786-d7tjw finished with return code: 0
2022-04-06 12:08:42 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.24 from Pod infra-namespace-kafka-clients-748578f786-d7tjw finished with return code: 0
2022-04-06 12:08:42 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.21 from Pod infra-namespace-kafka-clients-748578f786-d7tjw finished with return code: 0
2022-04-06 12:08:42 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 12:08:42 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testUserOperatorMetrics-STARTED
2022-04-06 12:08:42 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 12:08:42 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.19 from Pod infra-namespace-kafka-clients-748578f786-d7tjw finished with return code: 0
2022-04-06 12:08:42 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:08:42 [main] [32mINFO [m [ResourceManager:346] In context testUserOperatorMetrics is everything deleted.
2022-04-06 12:08:42 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:08:42 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testUserOperatorMetrics-FINISHED
2022-04-06 12:08:42 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 12:08:42 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 12:08:42 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperWatchersCount-STARTED
2022-04-06 12:08:42 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 12:08:42 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:08:42 [main] [32mINFO [m [ResourceManager:346] In context testZookeeperWatchersCount is everything deleted.
2022-04-06 12:08:42 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:08:42 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperWatchersCount-FINISHED
2022-04-06 12:08:42 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 12:08:42 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 12:08:42 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectIoNetwork-STARTED
2022-04-06 12:08:42 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 12:08:43 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.24 from Pod infra-namespace-kafka-clients-748578f786-d7tjw finished with return code: 0
2022-04-06 12:08:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:08:43 [main] [32mINFO [m [ResourceManager:346] In context testKafkaConnectIoNetwork is everything deleted.
2022-04-06 12:08:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:08:43 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectIoNetwork-FINISHED
2022-04-06 12:08:43 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 12:08:43 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 12:08:43 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaBrokersCount-STARTED
2022-04-06 12:08:43 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 12:08:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:08:43 [main] [32mINFO [m [ResourceManager:346] In context testKafkaBrokersCount is everything deleted.
2022-04-06 12:08:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:08:43 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaBrokersCount-FINISHED
2022-04-06 12:08:43 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 12:08:43 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 12:08:43 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaActiveControllers-STARTED
2022-04-06 12:08:43 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 12:08:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:08:43 [main] [32mINFO [m [ResourceManager:346] In context testKafkaActiveControllers is everything deleted.
2022-04-06 12:08:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:08:43 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaActiveControllers-FINISHED
2022-04-06 12:08:43 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 12:08:43 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 12:08:43 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaTopicUnderReplicatedPartitions-STARTED
2022-04-06 12:08:43 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 12:08:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:08:43 [main] [32mINFO [m [ResourceManager:346] In context testKafkaTopicUnderReplicatedPartitions is everything deleted.
2022-04-06 12:08:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:08:43 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaTopicUnderReplicatedPartitions-FINISHED
2022-04-06 12:08:43 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 12:08:43 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 12:08:43 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperQuorumSize-STARTED
2022-04-06 12:08:43 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 12:08:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:08:43 [main] [32mINFO [m [ResourceManager:346] In context testZookeeperQuorumSize is everything deleted.
2022-04-06 12:08:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:08:43 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperQuorumSize-FINISHED
2022-04-06 12:08:43 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 12:08:43 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 12:08:43 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperAliveConnections-STARTED
2022-04-06 12:08:43 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 12:08:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:08:43 [main] [32mINFO [m [ResourceManager:346] In context testZookeeperAliveConnections is everything deleted.
2022-04-06 12:08:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:08:43 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperAliveConnections-FINISHED
2022-04-06 12:08:43 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 12:08:43 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 12:08:43 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaTopicPartitions-STARTED
2022-04-06 12:08:43 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 12:08:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:08:43 [main] [32mINFO [m [ResourceManager:346] In context testKafkaTopicPartitions is everything deleted.
2022-04-06 12:08:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:08:43 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaTopicPartitions-FINISHED
2022-04-06 12:08:43 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 12:08:43 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 12:08:43 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testReconcileStateMetricInTopicOperator-STARTED
2022-04-06 12:08:43 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 12:08:43 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-metrics-cluster-test
2022-04-06 12:08:43 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1351646989-2038194476 in namespace second-metrics-cluster-test
2022-04-06 12:08:43 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1351646989-2038194476 will have desired state: Ready
2022-04-06 12:08:44 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1351646989-2038194476 is in desired state: Ready
2022-04-06 12:08:44 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.14 from Pod second-metrics-cluster-test-kafka-clients-6c57d6898-xsbvm finished with return code: 0
2022-04-06 12:08:44 [main] [32mINFO [m [MetricsIsolatedST:555] Checking if resource state metric reason message is "none" and KafkaTopic is ready
2022-04-06 12:08:44 [main] [32mINFO [m [MetricsIsolatedST:558] Changing topic name in spec.topicName
2022-04-06 12:08:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1351646989-2038194476 will have desired state: NotReady
2022-04-06 12:08:45 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1351646989-2038194476 is in desired state: NotReady
2022-04-06 12:08:45 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.14 from Pod second-metrics-cluster-test-kafka-clients-6c57d6898-xsbvm finished with return code: 0
2022-04-06 12:08:45 [main] [32mINFO [m [MetricsIsolatedST:566] Changing back to it's original name and scaling replicas to be higher number
2022-04-06 12:08:45 [main] [32mINFO [m [KafkaTopicUtils:132] Waiting for KafkaTopic change my-topic-1351646989-2038194476
2022-04-06 12:08:46 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.14 from Pod second-metrics-cluster-test-kafka-clients-6c57d6898-xsbvm finished with return code: 0
2022-04-06 12:08:46 [main] [32mINFO [m [MetricsIsolatedST:578] Scaling replicas to be higher than before
2022-04-06 12:08:46 [main] [32mINFO [m [KafkaTopicUtils:132] Waiting for KafkaTopic change my-topic-1351646989-2038194476
2022-04-06 12:08:46 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.14 from Pod second-metrics-cluster-test-kafka-clients-6c57d6898-xsbvm finished with return code: 0
2022-04-06 12:08:46 [main] [32mINFO [m [MetricsIsolatedST:586] Changing KafkaTopic's spec to correct state
2022-04-06 12:08:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1351646989-2038194476 will have desired state: Ready
2022-04-06 12:08:47 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1351646989-2038194476 is in desired state: Ready
2022-04-06 12:08:47 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.14 from Pod second-metrics-cluster-test-kafka-clients-6c57d6898-xsbvm finished with return code: 0
2022-04-06 12:08:47 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 12:08:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:08:47 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testReconcileStateMetricInTopicOperator
2022-04-06 12:08:47 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1351646989-2038194476 in namespace second-metrics-cluster-test
2022-04-06 12:08:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:08:57 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testReconcileStateMetricInTopicOperator-FINISHED
2022-04-06 12:08:57 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 12:08:57 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 12:08:57 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testMirrorMaker2Metrics-STARTED
2022-04-06 12:08:57 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 12:08:58 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.23 from Pod infra-namespace-kafka-clients-748578f786-d7tjw finished with return code: 0
2022-04-06 12:08:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:08:58 [main] [32mINFO [m [ResourceManager:346] In context testMirrorMaker2Metrics is everything deleted.
2022-04-06 12:08:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:08:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testMirrorMaker2Metrics-FINISHED
2022-04-06 12:08:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 12:08:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 12:08:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaBridgeMetrics-STARTED
2022-04-06 12:08:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 12:08:58 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 12:08:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Job bridge-producer in namespace infra-namespace
2022-04-06 12:08:58 [main] [32mINFO [m [JobUtils:81] Waiting for job: bridge-producer will be in active state
2022-04-06 12:08:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Job bridge-consumer in namespace infra-namespace
2022-04-06 12:08:59 [main] [32mINFO [m [JobUtils:81] Waiting for job: bridge-consumer will be in active state
2022-04-06 12:09:00 [main] [32mINFO [m [MetricsIsolatedST:422] Looking for 'strimzi_bridge_kafka_producer_count' in bridge metrics
2022-04-06 12:09:01 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.22 from Pod infra-namespace-kafka-clients-748578f786-d7tjw finished with return code: 0
2022-04-06 12:09:02 [main] [32mINFO [m [MetricsIsolatedST:422] Looking for 'strimzi_bridge_kafka_producer_count' in bridge metrics
2022-04-06 12:09:02 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.22 from Pod infra-namespace-kafka-clients-748578f786-d7tjw finished with return code: 0
2022-04-06 12:09:02 [main] [32mINFO [m [MetricsIsolatedST:430] Looking for 'strimzi_bridge_kafka_consumer_connection_count' in bridge metrics
2022-04-06 12:09:02 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.22 from Pod infra-namespace-kafka-clients-748578f786-d7tjw finished with return code: 0
2022-04-06 12:09:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:09:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaBridgeMetrics
2022-04-06 12:09:02 [main] [32mINFO [m [ResourceManager:241] Delete of Job bridge-consumer in namespace infra-namespace
2022-04-06 12:09:02 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job bridge-producer in namespace infra-namespace
2022-04-06 12:09:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:09:02 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaBridgeMetrics-FINISHED
2022-04-06 12:09:02 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 12:09:02 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 12:09:02 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaMetricsSettings-STARTED
2022-04-06 12:09:02 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 12:09:02 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: second-kafka-cluster are stable
2022-04-06 12:09:02 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 12:09:02 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 12:09:02 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 12:09:02 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 12:09:03 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 12:09:03 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 12:09:03 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 12:09:03 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 12:09:04 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 12:09:04 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 12:09:04 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 12:09:04 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 12:09:05 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 12:09:05 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 12:09:05 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 12:09:05 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 12:09:06 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 12:09:06 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 12:09:06 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 12:09:06 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 12:09:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 12:09:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 12:09:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 12:09:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 12:09:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 12:09:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 12:09:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 12:09:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 12:09:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 12:09:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 12:09:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 12:09:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 12:09:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 12:09:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 12:09:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 12:09:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 12:09:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 12:09:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 12:09:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 12:09:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 12:09:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 12:09:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 12:09:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 12:09:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 12:09:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 12:09:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 12:09:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 12:09:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 12:09:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 12:09:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 12:09:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 12:09:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 12:09:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 12:09:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 12:09:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 12:09:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 12:09:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 12:09:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 12:09:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 12:09:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 12:09:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 12:09:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 12:09:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 12:09:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 12:09:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 12:09:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 12:09:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 12:09:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 12:09:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 12:09:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 12:09:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 12:09:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 12:09:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 12:09:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 12:09:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 12:09:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 12:09:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 12:09:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 12:09:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 12:09:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 12:09:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 12:09:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 12:09:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 12:09:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 12:09:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 12:09:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 12:09:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 12:09:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 12:09:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 12:09:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 12:09:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 12:09:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 12:09:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 12:09:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 12:09:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 12:09:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 12:09:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 12:09:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 12:09:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 12:09:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 12:09:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 12:09:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 12:09:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 12:09:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 12:09:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 12:09:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 12:09:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 12:09:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 12:09:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 12:09:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 12:09:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 12:09:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 12:09:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 12:09:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 12:09:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 12:09:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 12:09:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 12:09:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 12:09:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 12:09:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 12:09:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 12:09:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 12:09:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 12:09:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 12:09:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 12:09:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 12:09:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 12:09:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 12:09:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 12:09:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 12:09:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 12:09:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 12:09:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 12:09:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 12:09:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 12:09:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 12:09:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 12:09:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 12:09:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 12:09:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 12:09:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 12:09:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 12:09:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 12:09:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 12:09:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 12:09:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 12:09:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 12:09:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 12:09:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 12:09:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 12:09:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 12:09:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 12:09:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 12:09:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 12:09:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 12:09:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 12:09:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 12:09:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 12:09:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 12:09:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 12:09:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 12:09:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 12:09:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 12:09:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 12:09:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 12:09:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 12:09:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 12:09:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 12:09:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 12:09:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 12:09:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 12:09:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 12:09:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 12:09:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 12:09:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 12:09:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 12:09:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 12:09:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 12:09:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 12:09:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 12:09:48 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 12:09:48 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 12:09:48 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 12:09:48 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 12:09:49 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 12:09:49 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 12:09:49 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 12:09:49 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 12:09:50 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 12:09:50 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 12:09:50 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 12:09:50 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 12:09:51 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 12:09:51 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 12:09:51 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 12:09:51 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 12:09:52 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 12:09:52 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 12:09:52 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 12:09:52 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 12:09:52 [main] [32mINFO [m [PodUtils:335] All pods are stable second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 ,second-kafka-cluster-kafka-0 ,second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd ,second-kafka-cluster-zookeeper-0
2022-04-06 12:09:52 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: second-kafka-cluster are stable
2022-04-06 12:09:52 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 12:09:52 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 12:09:52 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 12:09:52 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 12:09:53 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 12:09:53 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 12:09:53 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 12:09:53 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 12:09:54 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 12:09:54 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 12:09:54 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 12:09:54 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 12:09:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 12:09:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 12:09:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 12:09:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 12:09:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 12:09:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 12:09:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 12:09:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 12:09:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 12:09:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 12:09:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 12:09:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 12:09:58 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 12:09:58 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 12:09:58 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 12:09:58 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 12:09:59 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 12:09:59 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 12:09:59 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 12:09:59 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 12:10:00 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 12:10:00 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 12:10:00 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 12:10:00 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 12:10:01 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 12:10:01 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 12:10:01 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 12:10:01 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 12:10:02 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 12:10:02 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 12:10:02 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 12:10:02 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 12:10:03 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 12:10:03 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 12:10:03 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 12:10:03 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 12:10:04 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 12:10:04 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 12:10:04 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 12:10:04 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 12:10:05 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 12:10:05 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 12:10:05 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 12:10:05 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 12:10:06 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 12:10:06 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 12:10:06 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 12:10:06 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 12:10:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 12:10:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 12:10:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 12:10:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 12:10:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 12:10:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 12:10:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 12:10:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 12:10:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 12:10:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 12:10:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 12:10:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 12:10:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 12:10:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 12:10:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 12:10:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 12:10:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 12:10:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 12:10:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 12:10:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 12:10:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 12:10:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 12:10:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 12:10:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 12:10:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 12:10:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 12:10:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 12:10:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 12:10:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 12:10:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 12:10:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 12:10:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 12:10:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 12:10:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 12:10:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 12:10:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 12:10:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 12:10:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 12:10:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 12:10:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 12:10:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 12:10:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 12:10:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 12:10:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 12:10:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 12:10:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 12:10:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 12:10:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 12:10:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 12:10:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 12:10:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 12:10:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 12:10:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 12:10:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 12:10:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 12:10:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 12:10:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 12:10:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 12:10:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 12:10:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 12:10:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 12:10:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 12:10:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 12:10:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 12:10:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 12:10:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 12:10:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 12:10:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 12:10:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 12:10:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 12:10:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 12:10:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 12:10:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 12:10:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 12:10:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 12:10:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 12:10:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 12:10:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 12:10:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 12:10:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 12:10:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 12:10:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 12:10:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 12:10:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 12:10:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 12:10:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 12:10:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 12:10:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 12:10:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 12:10:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 12:10:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 12:10:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 12:10:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 12:10:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 12:10:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 12:10:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 12:10:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 12:10:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 12:10:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 12:10:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 12:10:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 12:10:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 12:10:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 12:10:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 12:10:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 12:10:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 12:10:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 12:10:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 12:10:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 12:10:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 12:10:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 12:10:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 12:10:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 12:10:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 12:10:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 12:10:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 12:10:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 12:10:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 12:10:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 12:10:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 12:10:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 12:10:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 12:10:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 12:10:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 12:10:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 12:10:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 12:10:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 12:10:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 12:10:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 12:10:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 12:10:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 12:10:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 12:10:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 12:10:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 12:10:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 12:10:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 12:10:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 12:10:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 12:10:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 12:10:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 12:10:41 [main] [32mINFO [m [PodUtils:335] All pods are stable second-kafka-cluster-entity-operator-5f8949dc9c-blrs5 ,second-kafka-cluster-kafka-0 ,second-kafka-cluster-kafka-exporter-6dfb7ccc69-hqzjd ,second-kafka-cluster-zookeeper-0
2022-04-06 12:10:41 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:10:41 [main] [32mINFO [m [ResourceManager:346] In context testKafkaMetricsSettings is everything deleted.
2022-04-06 12:10:41 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:10:41 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaMetricsSettings-FINISHED
2022-04-06 12:10:41 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 12:10:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 12:10:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testClusterOperatorMetrics-STARTED
2022-04-06 12:10:41 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 12:10:41 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.6 from Pod infra-namespace-kafka-clients-748578f786-d7tjw finished with return code: 0
2022-04-06 12:10:41 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:10:41 [main] [32mINFO [m [ResourceManager:346] In context testClusterOperatorMetrics is everything deleted.
2022-04-06 12:10:41 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:10:41 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testClusterOperatorMetrics-FINISHED
2022-04-06 12:10:41 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 12:10:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 12:10:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testCruiseControlMetrics-STARTED
2022-04-06 12:10:42 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 12:10:42 [main] [32mINFO [m [MetricsIsolatedST:452] Verifying that we have more than 0 groups
2022-04-06 12:10:42 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:10:42 [main] [32mINFO [m [ResourceManager:346] In context testCruiseControlMetrics is everything deleted.
2022-04-06 12:10:42 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:10:42 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testCruiseControlMetrics-FINISHED
2022-04-06 12:10:42 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 12:10:42 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 12:10:42 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaExporterDataAfterExchange-STARTED
2022-04-06 12:10:42 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 12:10:42 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 12:10:42 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@49aba06b, messages=[], arguments=[--max-messages, 5000, --topic, my-topic-1677921817-183331475, --bootstrap-server, metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='infra-namespace-kafka-clients-748578f786-d7tjw', podNamespace='infra-namespace', bootstrapServer='metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092', topicName='my-topic-1677921817-183331475', maxMessages=5000, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6dc4901}
2022-04-06 12:10:42 [main] [32mINFO [m [InternalKafkaClient:94] Producing 5000 messages to metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092:my-topic-1677921817-183331475 from pod infra-namespace-kafka-clients-748578f786-d7tjw
2022-04-06 12:10:42 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec infra-namespace-kafka-clients-748578f786-d7tjw -n infra-namespace -- /opt/kafka/producer.sh --max-messages 5000 --topic my-topic-1677921817-183331475 --bootstrap-server metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092
2022-04-06 12:10:45 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 12:10:45 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 5000 messages
2022-04-06 12:10:45 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5b9f76c, messages=[], arguments=[--max-messages, 5000, --group-id, my-consumer-group-609393413, --group-instance-id, instance1331788752, --topic, my-topic-1677921817-183331475, --bootstrap-server, metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='infra-namespace-kafka-clients-748578f786-d7tjw', podNamespace='infra-namespace', bootstrapServer='metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092', topicName='my-topic-1677921817-183331475', maxMessages=5000, kafkaUsername='null', consumerGroupName='my-consumer-group-609393413', consumerInstanceId='instance1331788752', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@416de43d}
2022-04-06 12:10:45 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 5000 messages from metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092#my-topic-1677921817-183331475 from pod infra-namespace-kafka-clients-748578f786-d7tjw
2022-04-06 12:10:45 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec infra-namespace-kafka-clients-748578f786-d7tjw -n infra-namespace -- /opt/kafka/consumer.sh --max-messages 5000 --group-id my-consumer-group-609393413 --group-instance-id instance1331788752 --topic my-topic-1677921817-183331475 --bootstrap-server metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092
2022-04-06 12:10:50 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 12:10:50 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 5000 messages
2022-04-06 12:10:51 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.21 from Pod infra-namespace-kafka-clients-748578f786-d7tjw finished with return code: 0
2022-04-06 12:10:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:10:51 [main] [32mINFO [m [ResourceManager:346] In context testKafkaExporterDataAfterExchange is everything deleted.
2022-04-06 12:10:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:10:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaExporterDataAfterExchange-FINISHED
2022-04-06 12:10:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 12:10:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 12:10:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testTopicOperatorMetrics-STARTED
2022-04-06 12:10:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 12:10:51 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.19 from Pod infra-namespace-kafka-clients-748578f786-d7tjw finished with return code: 0
2022-04-06 12:10:51 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: consumer-offsets---84e7a678d08f4bd226872e5cdd4eb527fadc1c6a
2022-04-06 12:10:51 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: heartbeats
2022-04-06 12:10:51 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: metrics-cluster-name-connect-config
2022-04-06 12:10:51 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: metrics-cluster-name-connect-offsets
2022-04-06 12:10:51 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: metrics-cluster-name-connect-status
2022-04-06 12:10:51 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: mirrormaker2-cluster-configs
2022-04-06 12:10:51 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: mirrormaker2-cluster-offsets
2022-04-06 12:10:51 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: mirrormaker2-cluster-status
2022-04-06 12:10:51 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: my-topic-1677921817-183331475
2022-04-06 12:10:51 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: my-topic-2071265083-1486485415
2022-04-06 12:10:51 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: my-topic-789290823-2114898132
2022-04-06 12:10:51 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: second-kafka-cluster.checkpoints.internal
2022-04-06 12:10:51 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: strimzi-store-topic---effb8e3e057afce1ecf67c3f5d8e4e3ff177fc55
2022-04-06 12:10:51 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: strimzi-topic-operator-kstreams-topic-store-changelog---b75e702040b99be8a9263134de3507fc0cc4017b
2022-04-06 12:10:51 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: strimzi.cruisecontrol.metrics
2022-04-06 12:10:51 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: strimzi.cruisecontrol.modeltrainingsamples
2022-04-06 12:10:51 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: strimzi.cruisecontrol.partitionmetricsamples
2022-04-06 12:10:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:10:51 [main] [32mINFO [m [ResourceManager:346] In context testTopicOperatorMetrics is everything deleted.
2022-04-06 12:10:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:10:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testTopicOperatorMetrics-FINISHED
2022-04-06 12:10:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 12:10:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 12:10:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectRequests-STARTED
2022-04-06 12:10:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 12:10:52 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.24 from Pod infra-namespace-kafka-clients-748578f786-d7tjw finished with return code: 0
2022-04-06 12:10:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:10:52 [main] [32mINFO [m [ResourceManager:346] In context testKafkaConnectRequests is everything deleted.
2022-04-06 12:10:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:10:52 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectRequests-FINISHED
2022-04-06 12:10:52 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 12:10:52 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 12:10:52 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectResponse-STARTED
2022-04-06 12:10:52 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 12:10:52 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.24 from Pod infra-namespace-kafka-clients-748578f786-d7tjw finished with return code: 0
2022-04-06 12:10:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:10:52 [main] [32mINFO [m [ResourceManager:346] In context testKafkaConnectResponse is everything deleted.
2022-04-06 12:10:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:10:52 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectResponse-FINISHED
2022-04-06 12:10:52 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 12:10:52 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 12:10:52 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaExporterDifferentSetting-STARTED
2022-04-06 12:10:52 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 12:10:52 [main] [32mINFO [m [MetricsIsolatedST:610] Metrics collection for pod metrics-cluster-name-kafka-exporter-8454677f49-vbgcv return code - 0
2022-04-06 12:10:52 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment metrics-cluster-name-kafka-exporter rolling update
2022-04-06 12:11:27 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: metrics-cluster-name-kafka-exporter will be ready
2022-04-06 12:11:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: metrics-cluster-name-kafka-exporter is ready
2022-04-06 12:11:38 [main] [32mINFO [m [DeploymentUtils:141] Deployment metrics-cluster-name-kafka-exporter rolling update finished
2022-04-06 12:11:38 [main] [32mINFO [m [MetricsIsolatedST:610] Metrics collection for pod metrics-cluster-name-kafka-exporter-547b5bf757-l4g6v return code - 0
2022-04-06 12:11:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:11:38 [main] [32mINFO [m [ResourceManager:346] In context testKafkaExporterDifferentSetting is everything deleted.
2022-04-06 12:11:38 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:11:38 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaExporterDifferentSetting-FINISHED
2022-04-06 12:11:38 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 12:11:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:11:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for MetricsIsolatedST
2022-04-06 12:11:38 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 mm2-cluster in namespace infra-namespace
2022-04-06 12:11:38 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-278375114-1283247985 in namespace infra-namespace
2022-04-06 12:11:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect metrics-cluster-name in namespace infra-namespace
2022-04-06 12:11:38 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-879461624-1882311746 in namespace infra-namespace
2022-04-06 12:11:38 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-789290823-2114898132 in namespace infra-namespace
2022-04-06 12:11:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy second-kafka-cluster-entity-operator-allow in namespace second-metrics-cluster-test
2022-04-06 12:11:38 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment infra-namespace-kafka-clients in namespace infra-namespace
2022-04-06 12:11:38 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy metrics-cluster-name-entity-operator-allow in namespace infra-namespace
2022-04-06 12:11:38 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy cluster-operator-allow in namespace infra-namespace
2022-04-06 12:11:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy second-kafka-cluster-kafka-exporter-allow in namespace second-metrics-cluster-test
2022-04-06 12:11:38 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy metrics-cluster-name-kafka-exporter-allow in namespace infra-namespace
2022-04-06 12:11:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka second-kafka-cluster in namespace second-metrics-cluster-test
2022-04-06 12:11:38 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka metrics-cluster-name in namespace infra-namespace
2022-04-06 12:11:38 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace infra-namespace, for cruise control Kafka cluster metrics-cluster-name
2022-04-06 12:11:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment second-metrics-cluster-test-kafka-clients in namespace second-metrics-cluster-test
2022-04-06 12:11:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1677921817-183331475 in namespace infra-namespace
2022-04-06 12:11:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2071265083-1486485415 in namespace infra-namespace
2022-04-06 12:11:48 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge my-bridge in namespace infra-namespace
2022-04-06 12:12:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 20, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 767.764 s - in io.strimzi.systemtest.metrics.MetricsIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.metrics.JmxIsolatedST
2022-04-06 12:12:48 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 12:13:13 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 12:13:13 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 12:13:13 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 12:13:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:13:13 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 12:13:13 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 12:13:13 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 12:13:13 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 12:13:13 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 12:13:13 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace second-metrics-cluster-test
2022-04-06 12:13:13 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:13:13 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 12:13:13 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 12:13:13 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:13:13 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 12:13:13 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 12:13:13 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 12:13:13 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 12:13:13 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:13:13 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 12:13:13 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 12:13:13 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 12:13:13 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 12:13:13 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 12:13:13 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:13:13 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 12:13:13 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-metrics-cluster-test
2022-04-06 12:13:13 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 12:13:13 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:13:23 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 12:13:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 12:13:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 12:13:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:13:33 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:13:54 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=30000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 12:13:54 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 12:13:54 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 12:13:54 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 12:13:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:13:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 12:13:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 12:13:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 12:13:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 12:13:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 12:13:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 12:13:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 12:13:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 12:13:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 12:13:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:13:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:13:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 12:13:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 12:13:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 12:13:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 12:13:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:13:55 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 12:13:55 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 12:13:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 12:13:55 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 12:13:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 12:13:55 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 12:13:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 12:13:55 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 12:13:55 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:13:55 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 12:13:55 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 12:13:55 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 12:13:55 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 12:13:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 12:13:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 12:13:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:13:55 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 12:14:08 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 12:14:08 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 12:14:18 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 12:14:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:14:18 [main] [32mINFO [m [ResourceManager:346] In context JmxIsolatedST is everything deleted.
2022-04-06 12:14:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;33mWARNING[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 89.94 s - in io.strimzi.systemtest.metrics.JmxIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.dump.LogDumpScriptIsolatedST
2022-04-06 12:14:18 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 12:14:43 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 12:14:43 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 12:14:43 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 12:14:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:14:43 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 12:14:43 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 12:14:43 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 12:14:43 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 12:14:43 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:14:43 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 12:14:43 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 12:14:43 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 12:14:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 12:14:43 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 12:14:43 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 12:14:43 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 12:14:43 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:14:43 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 12:14:43 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 12:14:43 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:14:43 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 12:14:53 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 12:14:53 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:14:53 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:14:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 12:14:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:14:53 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 12:14:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 12:14:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 12:14:53 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 12:15:03 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:15:08 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@7d696d9e
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 12:15:08 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 12:15:08 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 12:15:08 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 12:15:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:15:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 12:15:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 12:15:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 12:15:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 12:15:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 12:15:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 12:15:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 12:15:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 12:15:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 12:15:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:15:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:15:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 12:15:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 12:15:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 12:15:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 12:15:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:15:09 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 12:15:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 12:15:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 12:15:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 12:15:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 12:15:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 12:15:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 12:15:09 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 12:15:09 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:15:09 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 12:15:09 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 12:15:09 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 12:15:09 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 12:15:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 12:15:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 12:15:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:15:09 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 12:15:28 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 12:15:28 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 12:15:38 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 12:15:38 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 12:15:38 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.dump.LogDumpScriptIsolatedST.dumpPartitions-STARTED
2022-04-06 12:15:38 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 12:15:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-4f170079 in namespace infra-namespace
2022-04-06 12:15:38 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4f170079 will have desired state: Ready
2022-04-06 12:16:56 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4f170079 is in desired state: Ready
2022-04-06 12:16:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-4f170079-hello-world-producer in namespace infra-namespace
2022-04-06 12:16:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-4f170079-hello-world-consumer in namespace infra-namespace
2022-04-06 12:16:56 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-4f170079-hello-world-producer will be in active state
2022-04-06 12:16:56 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-4f170079-hello-world-consumer will be in active state
2022-04-06 12:16:56 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-4f170079-hello-world-producer and consumer my-cluster-4f170079-hello-world-consumer finish
2022-04-06 12:17:12 [main] [32mINFO [m [LogDumpScriptIsolatedST:78] Print partition segments from cluster infra-namespace/my-cluster-4f170079
2022-04-06 12:17:12 [main] [32mINFO [m [Exec:417] Command: /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/log-dump/run.sh partition --namespace infra-namespace --cluster my-cluster-4f170079 --topic my-topic-620428445-414549393 --partition 0 --dry-run
2022-04-06 12:17:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 12:17:12 [main] [32mINFO [m [LogDumpScriptIsolatedST:87] Dump topic partition from cluster infra-namespace/my-cluster-4f170079
2022-04-06 12:17:15 [main] [32mINFO [m [Exec:417] Command: /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/log-dump/run.sh partition --namespace infra-namespace --cluster my-cluster-4f170079 --topic my-topic-620428445-414549393 --partition 0 --out-path /home/ec2-user/strimzi-kafka-operator/systemtest/target/my-cluster-4f170079
2022-04-06 12:17:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 12:17:15 [main] [32mINFO [m [LogDumpScriptIsolatedST:99] Dump consumer offsets partition from cluster infra-namespace/my-cluster-4f170079
2022-04-06 12:17:19 [main] [32mINFO [m [Exec:417] Command: /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/log-dump/run.sh cg_offsets --namespace infra-namespace --cluster my-cluster-4f170079 --group-id my-group --out-path /home/ec2-user/strimzi-kafka-operator/systemtest/target/my-cluster-4f170079
2022-04-06 12:17:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 12:17:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:17:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for dumpPartitions
2022-04-06 12:17:19 [main] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-4f170079-hello-world-producer in namespace infra-namespace
2022-04-06 12:17:19 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-4f170079-hello-world-consumer in namespace infra-namespace
2022-04-06 12:17:19 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-4f170079 in namespace infra-namespace
2022-04-06 12:17:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:17:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.dump.LogDumpScriptIsolatedST.dumpPartitions-FINISHED
2022-04-06 12:17:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 12:17:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:17:29 [main] [32mINFO [m [ResourceManager:346] In context LogDumpScriptIsolatedST is everything deleted.
2022-04-06 12:17:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 191.695 s - in io.strimzi.systemtest.dump.LogDumpScriptIsolatedST
2022-04-06 12:17:29 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 12:17:29 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 12:17:29 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 12:17:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:17:29 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 12:17:29 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 12:17:29 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 12:17:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 12:17:29 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 12:17:29 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 12:17:29 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 12:17:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 12:17:29 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 12:17:29 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:17:29 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 12:17:30 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 12:17:30 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:17:30 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 12:17:30 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 12:17:30 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 12:17:30 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 12:17:30 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 12:17:30 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 12:17:30 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:17:30 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:17:30 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:17:30 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 12:17:40 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:17:40 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 12:17:40 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 12:17:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:17:55 [main] [32mINFO [m [TestExecutionListener:40] =======================================================================
2022-04-06 12:17:55 [main] [32mINFO [m [TestExecutionListener:41] =======================================================================
2022-04-06 12:17:55 [main] [32mINFO [m [TestExecutionListener:42]                         Test run finished
2022-04-06 12:17:55 [main] [32mINFO [m [TestExecutionListener:43] =======================================================================
2022-04-06 12:17:55 [main] [32mINFO [m [TestExecutionListener:44] =======================================================================
2022-04-06 12:17:55 [main] [32mINFO [m [TestExecutionListener:29] =======================================================================
2022-04-06 12:17:55 [main] [32mINFO [m [TestExecutionListener:30] =======================================================================
2022-04-06 12:17:55 [main] [32mINFO [m [TestExecutionListener:31]                         Test run started
2022-04-06 12:17:55 [main] [32mINFO [m [TestExecutionListener:32] =======================================================================
2022-04-06 12:17:55 [main] [32mINFO [m [TestExecutionListener:33] =======================================================================
2022-04-06 12:17:55 [main] [32mINFO [m [TestExecutionListener:48] Following testclasses are selected for run:
2022-04-06 12:17:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.KafkaST
2022-04-06 12:17:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST
2022-04-06 12:17:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.SecurityST
2022-04-06 12:17:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST
2022-04-06 12:17:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST
2022-04-06 12:17:55 [main] [32mINFO [m [TestExecutionListener:52] =======================================================================
2022-04-06 12:17:55 [main] [32mINFO [m [TestExecutionListener:53] =======================================================================
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.KafkaST
2022-04-06 12:17:55 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@228dce95
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 12:17:55 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 12:17:55 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 12:17:55 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 12:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 12:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 12:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 12:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 12:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 12:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 12:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 12:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 12:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 12:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 12:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 12:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 12:17:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 12:17:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:17:56 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 12:17:56 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 12:17:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 12:17:56 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 12:17:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 12:17:56 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 12:17:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 12:17:56 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 12:17:56 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:17:56 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 12:17:56 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 12:17:56 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 12:17:56 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 12:17:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 12:17:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 12:17:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:17:56 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 12:18:23 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 12:18:23 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 12:18:33 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 12:18:33 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: kafka-st
2022-04-06 12:18:33 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: kafka-st
2022-04-06 12:18:33 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: kafka-st
2022-04-06 12:18:33 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 12:18:33 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testLabelModificationDoesNotBreakCluster-STARTED
2022-04-06 12:18:33 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 12:18:33 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-141 for test case:testLabelModificationDoesNotBreakCluster
2022-04-06 12:18:33 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-141
2022-04-06 12:18:33 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-141
2022-04-06 12:18:33 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-141
2022-04-06 12:18:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-eaa0365d in namespace namespace-141
2022-04-06 12:18:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-141
2022-04-06 12:18:33 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-eaa0365d will have desired state: Ready
2022-04-06 12:19:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-eaa0365d is in desired state: Ready
2022-04-06 12:19:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1999240660-1204707500 in namespace namespace-141
2022-04-06 12:19:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-141
2022-04-06 12:19:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1999240660-1204707500 will have desired state: Ready
2022-04-06 12:19:46 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1999240660-1204707500 is in desired state: Ready
2022-04-06 12:19:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-eaa0365d-kafka-clients in namespace namespace-141
2022-04-06 12:19:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-141
2022-04-06 12:19:46 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-eaa0365d-kafka-clients will be ready
2022-04-06 12:19:47 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-eaa0365d-kafka-clients is ready
2022-04-06 12:19:47 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 12:19:47 [main] [32mINFO [m [KafkaST:1078] Waiting for kafka stateful set labels changed {label-name-1=name-of-the-label-1, label-name-2=name-of-the-label-2}
2022-04-06 12:19:47 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-1 -> name-of-the-label-1
2022-04-06 12:19:47 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-2 -> name-of-the-label-2
2022-04-06 12:19:47 [main] [32mINFO [m [KafkaST:1081] Getting labels from stateful set resource
2022-04-06 12:19:47 [main] [32mINFO [m [KafkaST:1084] Verifying default labels in the Kafka CR
2022-04-06 12:19:47 [main] [32mINFO [m [KafkaST:1095] Setting new values of labels from name-of-the-label-1 to new-name-of-the-label-1 | from name-of-the-label-2 to new-name-of-the-label-2 and adding one label-name-3 with value name-of-the-label-3
2022-04-06 12:19:47 [main] [32mINFO [m [KafkaST:1098] Edit kafka labels in Kafka CR
2022-04-06 12:19:47 [main] [32mINFO [m [KafkaST:1109] Waiting for kafka service labels changed {label-name-1=new-name-of-the-label-1, label-name-2=new-name-of-the-label-2, label-name-3=name-of-the-label-3}
2022-04-06 12:19:47 [main] [32mINFO [m [ServiceUtils:33] Waiting for Service label change label-name-1 -> new-name-of-the-label-1
2022-04-06 12:20:14 [main] [32mINFO [m [ServiceUtils:33] Waiting for Service label change label-name-2 -> new-name-of-the-label-2
2022-04-06 12:20:14 [main] [32mINFO [m [ServiceUtils:33] Waiting for Service label change label-name-3 -> name-of-the-label-3
2022-04-06 12:20:14 [main] [32mINFO [m [KafkaST:1112] Verifying kafka labels via services
2022-04-06 12:20:14 [main] [32mINFO [m [KafkaST:1118] Waiting for Kafka ConfigMap my-cluster-eaa0365d-kafka-config in namespace namespace-141 to have new labels: {label-name-1=new-name-of-the-label-1, label-name-2=new-name-of-the-label-2, label-name-3=name-of-the-label-3}
2022-04-06 12:20:14 [main] [32mINFO [m [ConfigMapUtils:42] Waiting for ConfigMap my-cluster-eaa0365d-kafka-config label change label-name-1 -> new-name-of-the-label-1
2022-04-06 12:20:14 [main] [32mINFO [m [ConfigMapUtils:42] Waiting for ConfigMap my-cluster-eaa0365d-kafka-config label change label-name-2 -> new-name-of-the-label-2
2022-04-06 12:20:14 [main] [32mINFO [m [ConfigMapUtils:42] Waiting for ConfigMap my-cluster-eaa0365d-kafka-config label change label-name-3 -> name-of-the-label-3
2022-04-06 12:20:14 [main] [32mINFO [m [KafkaST:1121] Verifying Kafka labels on ConfigMap my-cluster-eaa0365d-kafka-config in namespace namespace-141
2022-04-06 12:20:14 [main] [32mINFO [m [KafkaST:1127] Waiting for kafka stateful set labels changed {label-name-1=new-name-of-the-label-1, label-name-2=new-name-of-the-label-2, label-name-3=name-of-the-label-3}
2022-04-06 12:20:14 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-1 -> new-name-of-the-label-1
2022-04-06 12:20:14 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-2 -> new-name-of-the-label-2
2022-04-06 12:20:14 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-3 -> name-of-the-label-3
2022-04-06 12:20:14 [main] [32mINFO [m [KafkaST:1130] Verifying kafka labels via stateful set
2022-04-06 12:20:14 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-eaa0365d-kafka rolling update
2022-04-06 12:21:04 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-eaa0365d-kafka has been successfully rolled
2022-04-06 12:21:04 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-eaa0365d-kafka to be ready
2022-04-06 12:21:36 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-eaa0365d will have desired state: Ready
2022-04-06 12:21:36 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-eaa0365d is in desired state: Ready
2022-04-06 12:21:36 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-eaa0365d is ready
2022-04-06 12:21:36 [main] [32mINFO [m [KafkaST:1136] Verifying via kafka pods
2022-04-06 12:21:36 [main] [32mINFO [m [KafkaST:1143] Removing labels: label-name-1 -> new-name-of-the-label-1, label-name-2 -> new-name-of-the-label-2, label-name-3 -> name-of-the-label-3
2022-04-06 12:21:36 [main] [32mINFO [m [KafkaST:1155] Waiting for kafka service labels deletion {app.kubernetes.io/instance=my-cluster-eaa0365d, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-eaa0365d, controller-revision-hash=my-cluster-eaa0365d-kafka-7bbfc9b7c8, statefulset.kubernetes.io/pod-name=my-cluster-eaa0365d-kafka-0, strimzi.io/cluster=my-cluster-eaa0365d, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-eaa0365d-kafka, test.case=testLabelModificationDoesNotBreakCluster}
2022-04-06 12:21:36 [main] [32mINFO [m [ServiceUtils:44] Service label label-name-1 change to null
io.strimzi.test.WaitException: Timeout after 180000 ms waiting for Service labellabel-name-1 change to null
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.kubeUtils.objects.ServiceUtils.waitForServiceLabelsDeletion(ServiceUtils.java:45)
	at io.strimzi.systemtest.kafka.KafkaST.testLabelModificationDoesNotBreakCluster(KafkaST.java:1156)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:165)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-06 12:24:36 [main] [1;31mERROR[m [TestExecutionWatcher:28] KafkaST - Exception Timeout after 180000 ms waiting for Service labellabel-name-1 change to null has been thrown in @Test. Going to collect logs from components.
2022-04-06 12:24:36 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-04-06 12:24:36 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-04-06 12:24:36 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-04-06 12:24:36 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-04-06 12:24:36 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-04-06 12:24:36 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-04-06 12:24:36 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-04-06 12:24:37 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-06 12:24:37 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace kafka-st
2022-04-06 12:24:37 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace kafka-st
2022-04-06 12:24:37 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace kafka-st
2022-04-06 12:24:37 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace kafka-st
2022-04-06 12:24:37 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace kafka-st
2022-04-06 12:24:37 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace kafka-st
2022-04-06 12:24:37 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace kafka-st
2022-04-06 12:24:37 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-06 12:24:37 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace namespace-141
2022-04-06 12:24:37 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace namespace-141
2022-04-06 12:24:37 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace namespace-141
2022-04-06 12:24:39 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace namespace-141
2022-04-06 12:24:39 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace namespace-141
2022-04-06 12:24:39 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace namespace-141
2022-04-06 12:24:39 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace namespace-141
2022-04-06 12:24:39 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-06 12:24:39 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:24:39 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testLabelModificationDoesNotBreakCluster
2022-04-06 12:24:39 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1999240660-1204707500 in namespace namespace-141
2022-04-06 12:24:39 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-eaa0365d in namespace namespace-141
2022-04-06 12:24:39 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-eaa0365d-kafka-clients in namespace namespace-141
2022-04-06 12:25:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:25:30 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-141 for test case:testLabelModificationDoesNotBreakCluster
2022-04-06 12:25:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testLabelModificationDoesNotBreakCluster-FINISHED
2022-04-06 12:25:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 12:25:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:25:35 [main] [32mINFO [m [ResourceManager:346] In context KafkaST is everything deleted.
2022-04-06 12:25:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;31mERROR[m] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 465.362 s <<< FAILURE! - in io.strimzi.systemtest.kafka.KafkaST
[[1;31mERROR[m] io.strimzi.systemtest.kafka.KafkaST.testLabelModificationDoesNotBreakCluster(ExtensionContext)  Time elapsed: 422.06 s  <<< ERROR!
io.strimzi.test.WaitException: Timeout after 180000 ms waiting for Service labellabel-name-1 change to null
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.kubeUtils.objects.ServiceUtils.waitForServiceLabelsDeletion(ServiceUtils.java:45)
	at io.strimzi.systemtest.kafka.KafkaST.testLabelModificationDoesNotBreakCluster(KafkaST.java:1156)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:165)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)

[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST
2022-04-06 12:25:40 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: dynamic-conf-shared-st
2022-04-06 12:25:40 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: dynamic-conf-shared-st
2022-04-06 12:25:40 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: dynamic-conf-shared-st
2022-04-06 12:25:40 [main] [32mINFO [m [DynamicConfSharedST:218] Deploying shared Kafka across all test cases!
2022-04-06 12:25:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka dynamic-configuration-shared-cluster-name in namespace dynamic-conf-shared-st
2022-04-06 12:25:41 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: dynamic-configuration-shared-cluster-name will have desired state: Ready
2022-04-06 12:27:02 [main] [32mINFO [m [ResourceManager:444] Kafka: dynamic-configuration-shared-cluster-name is in desired state: Ready
2022-04-06 12:27:02 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 12:27:02 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.testDynConfiguration-STARTED
2022-04-06 12:27:02 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:334] Kafka config {advertised.listeners=io.strimzi.kafka.config.model.ConfigModel@23cc4fd4, alter.config.policy.class.name=io.strimzi.kafka.config.model.ConfigModel@7464f4b8, alter.log.dirs.replication.quota.window.num=io.strimzi.kafka.config.model.ConfigModel@118243ee, alter.log.dirs.replication.quota.window.size.seconds=io.strimzi.kafka.config.model.ConfigModel@6522ea21, authorizer.class.name=io.strimzi.kafka.config.model.ConfigModel@24d1abbe, auto.create.topics.enable=io.strimzi.kafka.config.model.ConfigModel@77434aa8, auto.leader.rebalance.enable=io.strimzi.kafka.config.model.ConfigModel@74ddfa9d, background.threads=io.strimzi.kafka.config.model.ConfigModel@65c75c5, broker.heartbeat.interval.ms=io.strimzi.kafka.config.model.ConfigModel@2ff9a2eb, broker.id=io.strimzi.kafka.config.model.ConfigModel@4202bbb6, broker.id.generation.enable=io.strimzi.kafka.config.model.ConfigModel@5910b879, broker.rack=io.strimzi.kafka.config.model.ConfigModel@3c070cc3, broker.session.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@5e0b1f52, client.quota.callback.class=io.strimzi.kafka.config.model.ConfigModel@903d02e, compression.type=io.strimzi.kafka.config.model.ConfigModel@558c7207, connection.failed.authentication.delay.ms=io.strimzi.kafka.config.model.ConfigModel@51e90d61, connections.max.idle.ms=io.strimzi.kafka.config.model.ConfigModel@579e7981, connections.max.reauth.ms=io.strimzi.kafka.config.model.ConfigModel@400b41fc, control.plane.listener.name=io.strimzi.kafka.config.model.ConfigModel@76210fb0, controlled.shutdown.enable=io.strimzi.kafka.config.model.ConfigModel@6fba9610, controlled.shutdown.max.retries=io.strimzi.kafka.config.model.ConfigModel@4bcca817, controlled.shutdown.retry.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@51521433, controller.listener.names=io.strimzi.kafka.config.model.ConfigModel@2ff0cd26, controller.quorum.append.linger.ms=io.strimzi.kafka.config.model.ConfigModel@14c1c4de, controller.quorum.election.backoff.max.ms=io.strimzi.kafka.config.model.ConfigModel@3ae34a41, controller.quorum.election.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@7bd132a2, controller.quorum.fetch.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@52614903, controller.quorum.request.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@481c80a5, controller.quorum.retry.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@688d7aa5, controller.quota.window.num=io.strimzi.kafka.config.model.ConfigModel@1abb1134, controller.quota.window.size.seconds=io.strimzi.kafka.config.model.ConfigModel@424a6a31, controller.socket.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@6effc375, create.topic.policy.class.name=io.strimzi.kafka.config.model.ConfigModel@6da4c45d, default.replication.factor=io.strimzi.kafka.config.model.ConfigModel@2f544a6c, delegation.token.expiry.check.interval.ms=io.strimzi.kafka.config.model.ConfigModel@3edea655, delegation.token.expiry.time.ms=io.strimzi.kafka.config.model.ConfigModel@2eaa2e90, delegation.token.master.key=io.strimzi.kafka.config.model.ConfigModel@65679134, delegation.token.max.lifetime.ms=io.strimzi.kafka.config.model.ConfigModel@686da0de, delegation.token.secret.key=io.strimzi.kafka.config.model.ConfigModel@234a5f88, delete.records.purgatory.purge.interval.requests=io.strimzi.kafka.config.model.ConfigModel@5c6b2bdf, delete.topic.enable=io.strimzi.kafka.config.model.ConfigModel@55cef57, fetch.max.bytes=io.strimzi.kafka.config.model.ConfigModel@b2d472, fetch.purgatory.purge.interval.requests=io.strimzi.kafka.config.model.ConfigModel@71756df3, group.initial.rebalance.delay.ms=io.strimzi.kafka.config.model.ConfigModel@74c595d1, group.max.session.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@1601ea49, group.max.size=io.strimzi.kafka.config.model.ConfigModel@6adbf, group.min.session.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@5a4652b9, initial.broker.registration.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@2753f3d, inter.broker.listener.name=io.strimzi.kafka.config.model.ConfigModel@1bbfde98, inter.broker.protocol.version=io.strimzi.kafka.config.model.ConfigModel@2e61e305, kafka.metrics.polling.interval.secs=io.strimzi.kafka.config.model.ConfigModel@465abfea, kafka.metrics.reporters=io.strimzi.kafka.config.model.ConfigModel@6dfdeccb, leader.imbalance.check.interval.seconds=io.strimzi.kafka.config.model.ConfigModel@853b4f2, leader.imbalance.per.broker.percentage=io.strimzi.kafka.config.model.ConfigModel@298b1736, listener.security.protocol.map=io.strimzi.kafka.config.model.ConfigModel@3abd5802, listeners=io.strimzi.kafka.config.model.ConfigModel@38a4602a, log.cleaner.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@2d45b7e8, log.cleaner.dedupe.buffer.size=io.strimzi.kafka.config.model.ConfigModel@5c0627d1, log.cleaner.delete.retention.ms=io.strimzi.kafka.config.model.ConfigModel@c2b191b, log.cleaner.enable=io.strimzi.kafka.config.model.ConfigModel@17958d84, log.cleaner.io.buffer.load.factor=io.strimzi.kafka.config.model.ConfigModel@176f8269, log.cleaner.io.buffer.size=io.strimzi.kafka.config.model.ConfigModel@7a3a17fa, log.cleaner.io.max.bytes.per.second=io.strimzi.kafka.config.model.ConfigModel@2e8d3a67, log.cleaner.max.compaction.lag.ms=io.strimzi.kafka.config.model.ConfigModel@15cf6b9f, log.cleaner.min.cleanable.ratio=io.strimzi.kafka.config.model.ConfigModel@7ed8cf85, log.cleaner.min.compaction.lag.ms=io.strimzi.kafka.config.model.ConfigModel@54f79263, log.cleaner.threads=io.strimzi.kafka.config.model.ConfigModel@13eec498, log.cleanup.policy=io.strimzi.kafka.config.model.ConfigModel@7d93c6e9, log.dir=io.strimzi.kafka.config.model.ConfigModel@450f9a39, log.dirs=io.strimzi.kafka.config.model.ConfigModel@2d836c71, log.flush.interval.messages=io.strimzi.kafka.config.model.ConfigModel@482ca75d, log.flush.interval.ms=io.strimzi.kafka.config.model.ConfigModel@2beb843f, log.flush.offset.checkpoint.interval.ms=io.strimzi.kafka.config.model.ConfigModel@128c0d29, log.flush.scheduler.interval.ms=io.strimzi.kafka.config.model.ConfigModel@245a1bed, log.flush.start.offset.checkpoint.interval.ms=io.strimzi.kafka.config.model.ConfigModel@9615674, log.index.interval.bytes=io.strimzi.kafka.config.model.ConfigModel@7edcf11b, log.index.size.max.bytes=io.strimzi.kafka.config.model.ConfigModel@ccb4eac, log.message.downconversion.enable=io.strimzi.kafka.config.model.ConfigModel@783ab9ab, log.message.format.version=io.strimzi.kafka.config.model.ConfigModel@7b6b922e, log.message.timestamp.difference.max.ms=io.strimzi.kafka.config.model.ConfigModel@6226f071, log.message.timestamp.type=io.strimzi.kafka.config.model.ConfigModel@34ce7cb7, log.preallocate=io.strimzi.kafka.config.model.ConfigModel@19947c64, log.retention.bytes=io.strimzi.kafka.config.model.ConfigModel@3ec9679a, log.retention.check.interval.ms=io.strimzi.kafka.config.model.ConfigModel@6bb9ad4a, log.retention.hours=io.strimzi.kafka.config.model.ConfigModel@2c554f4e, log.retention.minutes=io.strimzi.kafka.config.model.ConfigModel@169871fc, log.retention.ms=io.strimzi.kafka.config.model.ConfigModel@63983102, log.roll.hours=io.strimzi.kafka.config.model.ConfigModel@45ed03c6, log.roll.jitter.hours=io.strimzi.kafka.config.model.ConfigModel@43c41b0a, log.roll.jitter.ms=io.strimzi.kafka.config.model.ConfigModel@1606951f, log.roll.ms=io.strimzi.kafka.config.model.ConfigModel@3434b6fc, log.segment.bytes=io.strimzi.kafka.config.model.ConfigModel@19ea608f, log.segment.delete.delay.ms=io.strimzi.kafka.config.model.ConfigModel@7a9524f3, max.connection.creation.rate=io.strimzi.kafka.config.model.ConfigModel@5899f8d3, max.connections=io.strimzi.kafka.config.model.ConfigModel@490b266a, max.connections.per.ip=io.strimzi.kafka.config.model.ConfigModel@32fd9dc, max.connections.per.ip.overrides=io.strimzi.kafka.config.model.ConfigModel@50cec7f6, max.incremental.fetch.session.cache.slots=io.strimzi.kafka.config.model.ConfigModel@4706e25c, message.max.bytes=io.strimzi.kafka.config.model.ConfigModel@572ea4a0, metadata.log.dir=io.strimzi.kafka.config.model.ConfigModel@2a3276a0, metadata.log.max.record.bytes.between.snapshots=io.strimzi.kafka.config.model.ConfigModel@c65e567, metadata.log.segment.bytes=io.strimzi.kafka.config.model.ConfigModel@7c01f2b5, metadata.log.segment.min.bytes=io.strimzi.kafka.config.model.ConfigModel@5e285231, metadata.log.segment.ms=io.strimzi.kafka.config.model.ConfigModel@6796a822, metadata.max.retention.bytes=io.strimzi.kafka.config.model.ConfigModel@44fb376a, metadata.max.retention.ms=io.strimzi.kafka.config.model.ConfigModel@371cf11a, metric.reporters=io.strimzi.kafka.config.model.ConfigModel@2bb99412, metrics.num.samples=io.strimzi.kafka.config.model.ConfigModel@79bcfeff, metrics.recording.level=io.strimzi.kafka.config.model.ConfigModel@6461c6c5, metrics.sample.window.ms=io.strimzi.kafka.config.model.ConfigModel@34257f72, min.insync.replicas=io.strimzi.kafka.config.model.ConfigModel@53db74e0, node.id=io.strimzi.kafka.config.model.ConfigModel@4d8e3362, num.io.threads=io.strimzi.kafka.config.model.ConfigModel@27b383f8, num.network.threads=io.strimzi.kafka.config.model.ConfigModel@38f2b693, num.partitions=io.strimzi.kafka.config.model.ConfigModel@3006a919, num.recovery.threads.per.data.dir=io.strimzi.kafka.config.model.ConfigModel@c2f9958, num.replica.alter.log.dirs.threads=io.strimzi.kafka.config.model.ConfigModel@37387766, num.replica.fetchers=io.strimzi.kafka.config.model.ConfigModel@1a53093c, offset.metadata.max.bytes=io.strimzi.kafka.config.model.ConfigModel@1f18350e, offsets.commit.required.acks=io.strimzi.kafka.config.model.ConfigModel@6f8d9aec, offsets.commit.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@1b7a433c, offsets.load.buffer.size=io.strimzi.kafka.config.model.ConfigModel@1962a386, offsets.retention.check.interval.ms=io.strimzi.kafka.config.model.ConfigModel@478c45e1, offsets.retention.minutes=io.strimzi.kafka.config.model.ConfigModel@4455fd06, offsets.topic.compression.codec=io.strimzi.kafka.config.model.ConfigModel@d7f3513, offsets.topic.num.partitions=io.strimzi.kafka.config.model.ConfigModel@18dd9a9, offsets.topic.replication.factor=io.strimzi.kafka.config.model.ConfigModel@248b2734, offsets.topic.segment.bytes=io.strimzi.kafka.config.model.ConfigModel@4fdd536e, password.encoder.cipher.algorithm=io.strimzi.kafka.config.model.ConfigModel@3bfe302b, password.encoder.iterations=io.strimzi.kafka.config.model.ConfigModel@5451e66c, password.encoder.key.length=io.strimzi.kafka.config.model.ConfigModel@299ec955, password.encoder.keyfactory.algorithm=io.strimzi.kafka.config.model.ConfigModel@cfdb92b, password.encoder.old.secret=io.strimzi.kafka.config.model.ConfigModel@4648bff7, password.encoder.secret=io.strimzi.kafka.config.model.ConfigModel@1d7153d4, principal.builder.class=io.strimzi.kafka.config.model.ConfigModel@42fae54e, process.roles=io.strimzi.kafka.config.model.ConfigModel@23af38db, producer.purgatory.purge.interval.requests=io.strimzi.kafka.config.model.ConfigModel@201b8c5e, queued.max.request.bytes=io.strimzi.kafka.config.model.ConfigModel@3763947a, queued.max.requests=io.strimzi.kafka.config.model.ConfigModel@2226c74d, quota.window.num=io.strimzi.kafka.config.model.ConfigModel@78154a32, quota.window.size.seconds=io.strimzi.kafka.config.model.ConfigModel@4904012, remote.log.index.file.cache.total.size.bytes=io.strimzi.kafka.config.model.ConfigModel@2ffbd4be, remote.log.manager.task.interval.ms=io.strimzi.kafka.config.model.ConfigModel@3bf362a3, remote.log.manager.task.retry.backoff.max.ms=io.strimzi.kafka.config.model.ConfigModel@6965fb35, remote.log.manager.task.retry.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@6ff3a6db, remote.log.manager.task.retry.jitter=io.strimzi.kafka.config.model.ConfigModel@1e5cc1bf, remote.log.manager.thread.pool.size=io.strimzi.kafka.config.model.ConfigModel@3e1a5ead, remote.log.metadata.manager.class.name=io.strimzi.kafka.config.model.ConfigModel@7860a608, remote.log.metadata.manager.class.path=io.strimzi.kafka.config.model.ConfigModel@ad712a1, remote.log.metadata.manager.impl.prefix=io.strimzi.kafka.config.model.ConfigModel@727e7b7d, remote.log.metadata.manager.listener.name=io.strimzi.kafka.config.model.ConfigModel@1efdbca9, remote.log.reader.max.pending.tasks=io.strimzi.kafka.config.model.ConfigModel@63d01998, remote.log.reader.threads=io.strimzi.kafka.config.model.ConfigModel@51205d59, remote.log.storage.manager.class.name=io.strimzi.kafka.config.model.ConfigModel@50846193, remote.log.storage.manager.class.path=io.strimzi.kafka.config.model.ConfigModel@23ef87de, remote.log.storage.manager.impl.prefix=io.strimzi.kafka.config.model.ConfigModel@409046e2, remote.log.storage.system.enable=io.strimzi.kafka.config.model.ConfigModel@1309113c, replica.fetch.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@60f26237, replica.fetch.max.bytes=io.strimzi.kafka.config.model.ConfigModel@3f7cc880, replica.fetch.min.bytes=io.strimzi.kafka.config.model.ConfigModel@7d193edb, replica.fetch.response.max.bytes=io.strimzi.kafka.config.model.ConfigModel@26c250b5, replica.fetch.wait.max.ms=io.strimzi.kafka.config.model.ConfigModel@55d27d80, replica.high.watermark.checkpoint.interval.ms=io.strimzi.kafka.config.model.ConfigModel@c338772, replica.lag.time.max.ms=io.strimzi.kafka.config.model.ConfigModel@38e89fc9, replica.selector.class=io.strimzi.kafka.config.model.ConfigModel@c1b3799, replica.socket.receive.buffer.bytes=io.strimzi.kafka.config.model.ConfigModel@4ae375e7, replica.socket.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@5afb73de, replication.quota.window.num=io.strimzi.kafka.config.model.ConfigModel@2611a99f, replication.quota.window.size.seconds=io.strimzi.kafka.config.model.ConfigModel@7363f53b, request.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@22feeafd, reserved.broker.max.id=io.strimzi.kafka.config.model.ConfigModel@239a08ff, sasl.client.callback.handler.class=io.strimzi.kafka.config.model.ConfigModel@86c0042, sasl.enabled.mechanisms=io.strimzi.kafka.config.model.ConfigModel@644af659, sasl.jaas.config=io.strimzi.kafka.config.model.ConfigModel@3136512f, sasl.kerberos.kinit.cmd=io.strimzi.kafka.config.model.ConfigModel@42186a06, sasl.kerberos.min.time.before.relogin=io.strimzi.kafka.config.model.ConfigModel@2a9e1c17, sasl.kerberos.principal.to.local.rules=io.strimzi.kafka.config.model.ConfigModel@1955cf23, sasl.kerberos.service.name=io.strimzi.kafka.config.model.ConfigModel@1ae94a0f, sasl.kerberos.ticket.renew.jitter=io.strimzi.kafka.config.model.ConfigModel@1b204b0e, sasl.kerberos.ticket.renew.window.factor=io.strimzi.kafka.config.model.ConfigModel@410492d9, sasl.login.callback.handler.class=io.strimzi.kafka.config.model.ConfigModel@761f610d, sasl.login.class=io.strimzi.kafka.config.model.ConfigModel@2676e4f3, sasl.login.connect.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@3f17b308, sasl.login.read.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@5ae06c69, sasl.login.refresh.buffer.seconds=io.strimzi.kafka.config.model.ConfigModel@577a6931, sasl.login.refresh.min.period.seconds=io.strimzi.kafka.config.model.ConfigModel@463a4e51, sasl.login.refresh.window.factor=io.strimzi.kafka.config.model.ConfigModel@44b73a6d, sasl.login.refresh.window.jitter=io.strimzi.kafka.config.model.ConfigModel@1ded95b6, sasl.login.retry.backoff.max.ms=io.strimzi.kafka.config.model.ConfigModel@195a54db, sasl.login.retry.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@d86d967, sasl.mechanism.controller.protocol=io.strimzi.kafka.config.model.ConfigModel@701ffee8, sasl.mechanism.inter.broker.protocol=io.strimzi.kafka.config.model.ConfigModel@1ae9578, sasl.oauthbearer.clock.skew.seconds=io.strimzi.kafka.config.model.ConfigModel@4a99f51a, sasl.oauthbearer.expected.audience=io.strimzi.kafka.config.model.ConfigModel@716f50cf, sasl.oauthbearer.expected.issuer=io.strimzi.kafka.config.model.ConfigModel@7e0818b4, sasl.oauthbearer.jwks.endpoint.refresh.ms=io.strimzi.kafka.config.model.ConfigModel@bf84758, sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms=io.strimzi.kafka.config.model.ConfigModel@e4c4218, sasl.oauthbearer.jwks.endpoint.retry.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@52e8236, sasl.oauthbearer.jwks.endpoint.url=io.strimzi.kafka.config.model.ConfigModel@3bdde79f, sasl.oauthbearer.scope.claim.name=io.strimzi.kafka.config.model.ConfigModel@7256b53b, sasl.oauthbearer.sub.claim.name=io.strimzi.kafka.config.model.ConfigModel@1e6675eb, sasl.oauthbearer.token.endpoint.url=io.strimzi.kafka.config.model.ConfigModel@6fa86b23, sasl.server.callback.handler.class=io.strimzi.kafka.config.model.ConfigModel@3b1d9856, security.inter.broker.protocol=io.strimzi.kafka.config.model.ConfigModel@7ca50d63, security.providers=io.strimzi.kafka.config.model.ConfigModel@51c1e631, socket.connection.setup.timeout.max.ms=io.strimzi.kafka.config.model.ConfigModel@7d1c7e59, socket.connection.setup.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@2a149684, socket.receive.buffer.bytes=io.strimzi.kafka.config.model.ConfigModel@7e8e48b0, socket.request.max.bytes=io.strimzi.kafka.config.model.ConfigModel@20a0d93e, socket.send.buffer.bytes=io.strimzi.kafka.config.model.ConfigModel@3e5095c5, ssl.cipher.suites=io.strimzi.kafka.config.model.ConfigModel@307e943d, ssl.client.auth=io.strimzi.kafka.config.model.ConfigModel@3cb9914a, ssl.enabled.protocols=io.strimzi.kafka.config.model.ConfigModel@1a76d6ca, ssl.endpoint.identification.algorithm=io.strimzi.kafka.config.model.ConfigModel@20b286fc, ssl.engine.factory.class=io.strimzi.kafka.config.model.ConfigModel@64a931ab, ssl.key.password=io.strimzi.kafka.config.model.ConfigModel@146acfb5, ssl.keymanager.algorithm=io.strimzi.kafka.config.model.ConfigModel@38869b74, ssl.keystore.certificate.chain=io.strimzi.kafka.config.model.ConfigModel@c376ffe, ssl.keystore.key=io.strimzi.kafka.config.model.ConfigModel@213e33ba, ssl.keystore.location=io.strimzi.kafka.config.model.ConfigModel@63eb574f, ssl.keystore.password=io.strimzi.kafka.config.model.ConfigModel@6f3a3d7d, ssl.keystore.type=io.strimzi.kafka.config.model.ConfigModel@5845f7fb, ssl.principal.mapping.rules=io.strimzi.kafka.config.model.ConfigModel@8b6acaa, ssl.protocol=io.strimzi.kafka.config.model.ConfigModel@31dec3dc, ssl.provider=io.strimzi.kafka.config.model.ConfigModel@f31d14f, ssl.secure.random.implementation=io.strimzi.kafka.config.model.ConfigModel@783c157d, ssl.trustmanager.algorithm=io.strimzi.kafka.config.model.ConfigModel@45d2352c, ssl.truststore.certificates=io.strimzi.kafka.config.model.ConfigModel@255de69, ssl.truststore.location=io.strimzi.kafka.config.model.ConfigModel@3efccc5, ssl.truststore.password=io.strimzi.kafka.config.model.ConfigModel@1be0a638, ssl.truststore.type=io.strimzi.kafka.config.model.ConfigModel@4f4f9b3d, transaction.abort.timed.out.transaction.cleanup.interval.ms=io.strimzi.kafka.config.model.ConfigModel@6345a22b, transaction.max.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@1eb1d362, transaction.remove.expired.transaction.cleanup.interval.ms=io.strimzi.kafka.config.model.ConfigModel@fe77ea, transaction.state.log.load.buffer.size=io.strimzi.kafka.config.model.ConfigModel@335b92bb, transaction.state.log.min.isr=io.strimzi.kafka.config.model.ConfigModel@7dc13a01, transaction.state.log.num.partitions=io.strimzi.kafka.config.model.ConfigModel@6dfbcc18, transaction.state.log.replication.factor=io.strimzi.kafka.config.model.ConfigModel@1e49b76a, transaction.state.log.segment.bytes=io.strimzi.kafka.config.model.ConfigModel@71683052, transactional.id.expiration.ms=io.strimzi.kafka.config.model.ConfigModel@58d0d4c, unclean.leader.election.enable=io.strimzi.kafka.config.model.ConfigModel@36259ae9, zookeeper.clientCnxnSocket=io.strimzi.kafka.config.model.ConfigModel@658489a0, zookeeper.connect=io.strimzi.kafka.config.model.ConfigModel@55decfe2, zookeeper.connection.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@38545f78, zookeeper.max.in.flight.requests=io.strimzi.kafka.config.model.ConfigModel@22bc6849, zookeeper.session.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@63343c37, zookeeper.set.acl=io.strimzi.kafka.config.model.ConfigModel@40b65e6c, zookeeper.ssl.cipher.suites=io.strimzi.kafka.config.model.ConfigModel@5a03769d, zookeeper.ssl.client.enable=io.strimzi.kafka.config.model.ConfigModel@1bbcb3b4, zookeeper.ssl.crl.enable=io.strimzi.kafka.config.model.ConfigModel@592bf170, zookeeper.ssl.enabled.protocols=io.strimzi.kafka.config.model.ConfigModel@2b1c9107, zookeeper.ssl.endpoint.identification.algorithm=io.strimzi.kafka.config.model.ConfigModel@6a6aad67, zookeeper.ssl.keystore.location=io.strimzi.kafka.config.model.ConfigModel@1435928d, zookeeper.ssl.keystore.password=io.strimzi.kafka.config.model.ConfigModel@1213410a, zookeeper.ssl.keystore.type=io.strimzi.kafka.config.model.ConfigModel@5dc86ee6, zookeeper.ssl.ocsp.enable=io.strimzi.kafka.config.model.ConfigModel@62f6e1ad, zookeeper.ssl.protocol=io.strimzi.kafka.config.model.ConfigModel@5aefa684, zookeeper.ssl.truststore.location=io.strimzi.kafka.config.model.ConfigModel@52fca7c2, zookeeper.ssl.truststore.password=io.strimzi.kafka.config.model.ConfigModel@4cdd4c25, zookeeper.ssl.truststore.type=io.strimzi.kafka.config.model.ConfigModel@1973279a, zookeeper.sync.time.ms=io.strimzi.kafka.config.model.ConfigModel@3e8f69b6}
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:336] Number of all kafka configs 261
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:356] Number of dynamic-configs 40
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:364] Number of forbidden-exception-configs 7
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:371] Size of dynamic-configs with forbidden-exception-configs 46
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] compression.type -> CLUSTER_WIDE:STRING
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.min.compaction.lag.ms -> CLUSTER_WIDE:LONG
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] log.retention.ms -> CLUSTER_WIDE:LONG
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] max.connections.per.ip.overrides -> CLUSTER_WIDE:STRING
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] metric.reporters -> CLUSTER_WIDE:LIST
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] log.flush.interval.messages -> CLUSTER_WIDE:LONG
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] log.message.timestamp.difference.max.ms -> CLUSTER_WIDE:LONG
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] log.flush.interval.ms -> CLUSTER_WIDE:LONG
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] principal.builder.class -> PER_BROKER:CLASS
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.delete.retention.ms -> CLUSTER_WIDE:LONG
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.io.buffer.size -> CLUSTER_WIDE:INT
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] min.insync.replicas -> CLUSTER_WIDE:INT
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] zookeeper.connection.timeout.ms -> READ_ONLY:INT
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.threads -> CLUSTER_WIDE:INT
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.io.max.bytes.per.second -> CLUSTER_WIDE:DOUBLE
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.min.cleanable.ratio -> CLUSTER_WIDE:DOUBLE
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] num.recovery.threads.per.data.dir -> CLUSTER_WIDE:INT
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] log.retention.bytes -> CLUSTER_WIDE:LONG
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] num.network.threads -> CLUSTER_WIDE:INT
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] log.cleanup.policy -> CLUSTER_WIDE:LIST
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] log.message.timestamp.type -> CLUSTER_WIDE:STRING
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] log.preallocate -> CLUSTER_WIDE:BOOLEAN
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] log.roll.jitter.ms -> CLUSTER_WIDE:LONG
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] max.connections -> CLUSTER_WIDE:INT
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] max.connections.per.ip -> CLUSTER_WIDE:INT
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] background.threads -> CLUSTER_WIDE:INT
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] log.message.downconversion.enable -> CLUSTER_WIDE:BOOLEAN
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] message.max.bytes -> CLUSTER_WIDE:INT
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] ssl.protocol -> PER_BROKER:STRING
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] num.partitions -> READ_ONLY:INT
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] num.io.threads -> CLUSTER_WIDE:INT
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] ssl.enabled.protocols -> PER_BROKER:LIST
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] max.connection.creation.rate -> CLUSTER_WIDE:INT
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] log.roll.ms -> CLUSTER_WIDE:LONG
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] ssl.cipher.suites -> PER_BROKER:LIST
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] unclean.leader.election.enable -> CLUSTER_WIDE:BOOLEAN
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] log.index.interval.bytes -> CLUSTER_WIDE:INT
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.backoff.ms -> CLUSTER_WIDE:LONG
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] log.segment.bytes -> CLUSTER_WIDE:INT
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.io.buffer.load.factor -> CLUSTER_WIDE:DOUBLE
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] log.index.size.max.bytes -> CLUSTER_WIDE:INT
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] zookeeper.connect -> READ_ONLY:STRING
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] log.segment.delete.delay.ms -> CLUSTER_WIDE:LONG
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.max.compaction.lag.ms -> CLUSTER_WIDE:LONG
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] num.replica.fetchers -> CLUSTER_WIDE:INT
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.dedupe.buffer.size -> CLUSTER_WIDE:LONG
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:234] Kafka config before updating '{default.replication.factor=3, inter.broker.protocol.version=3.1, log.message.format.version=3.1, min.insync.replicas=2, offsets.topic.replication.factor=3, transaction.state.log.min.isr=2, transaction.state.log.replication.factor=3}'
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:238] Kafka config after updating '{default.replication.factor=3, inter.broker.protocol.version=3.1, log.message.format.version=3.1, min.insync.replicas=2, offsets.topic.replication.factor=3, transaction.state.log.min.isr=2, transaction.state.log.replication.factor=3, ssl.protocol=TLSv1.1}'
2022-04-06 12:27:02 [main] [32mINFO [m [KafkaUtils:180] Waiting for cluster stability
2022-04-06 12:28:04 [main] [32mINFO [m [KafkaUtils:208] Kafka cluster is stable after 61 polls.
2022-04-06 12:28:04 [main] [32mINFO [m [KafkaUtils:262] Dynamic Configuration in Kafka CR is ssl.protocol=TLSv1.1 and expected is ssl.protocol=TLSv1.1
2022-04-06 12:28:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-06 12:28:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 12:28:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-1 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-06 12:28:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 12:28:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-2 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-06 12:28:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 12:28:12 [main] [32mINFO [m [KafkaUtils:234] Kafka config before updating '{default.replication.factor=3, inter.broker.protocol.version=3.1, log.message.format.version=3.1, min.insync.replicas=2, offsets.topic.replication.factor=3, ssl.protocol=TLSv1.1, transaction.state.log.min.isr=2, transaction.state.log.replication.factor=3}'
2022-04-06 12:28:12 [main] [32mINFO [m [KafkaUtils:238] Kafka config after updating '{default.replication.factor=3, inter.broker.protocol.version=3.1, log.message.format.version=3.1, min.insync.replicas=2, offsets.topic.replication.factor=3, ssl.protocol=TLSv1.1, transaction.state.log.min.isr=2, transaction.state.log.replication.factor=3, log.message.timestamp.type=LogAppendTime}'
2022-04-06 12:28:12 [main] [32mINFO [m [KafkaUtils:180] Waiting for cluster stability
2022-04-06 12:29:14 [main] [32mINFO [m [KafkaUtils:208] Kafka cluster is stable after 61 polls.
2022-04-06 12:29:14 [main] [32mINFO [m [KafkaUtils:262] Dynamic Configuration in Kafka CR is log.message.timestamp.type=LogAppendTime and expected is log.message.timestamp.type=LogAppendTime
2022-04-06 12:29:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-06 12:29:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 12:29:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-1 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-06 12:29:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 12:29:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-2 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-06 12:29:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 12:29:22 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:29:22 [main] [32mINFO [m [ResourceManager:346] In context testDynConfiguration is everything deleted.
2022-04-06 12:29:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:29:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.testDynConfiguration-FINISHED
2022-04-06 12:29:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 12:29:22 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:29:22 [main] [32mINFO [m [ResourceManager:348] Delete all resources for DynamicConfSharedST
2022-04-06 12:29:22 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka dynamic-configuration-shared-cluster-name in namespace dynamic-conf-shared-st
2022-04-06 12:29:32 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 258.445 s - in io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.SecurityST
2022-04-06 12:29:59 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: security-st
2022-04-06 12:29:59 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: security-st
2022-04-06 12:29:59 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: security-st
2022-04-06 12:29:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 12:29:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno-STARTED
2022-04-06 12:29:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 12:29:59 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-142 for test case:testAutoReplaceClusterCaKeysTriggeredByAnno
2022-04-06 12:29:59 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-142
2022-04-06 12:29:59 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-142
2022-04-06 12:29:59 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-142
2022-04-06 12:29:59 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-06 12:29:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-f58c54e6 in namespace namespace-142
2022-04-06 12:29:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-142
2022-04-06 12:29:59 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f58c54e6 will have desired state: Ready
2022-04-06 12:33:14 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f58c54e6 is in desired state: Ready
2022-04-06 12:33:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-777619998-1100517471 in namespace namespace-142
2022-04-06 12:33:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-142
2022-04-06 12:33:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-777619998-1100517471 will have desired state: Ready
2022-04-06 12:33:15 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-777619998-1100517471 is in desired state: Ready
2022-04-06 12:33:15 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1995313158-212572073 in namespace namespace-142
2022-04-06 12:33:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-142
2022-04-06 12:33:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1995313158-212572073 will have desired state: Ready
2022-04-06 12:33:16 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1995313158-212572073 is in desired state: Ready
2022-04-06 12:33:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-f58c54e6-kafka-clients in namespace namespace-142
2022-04-06 12:33:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-142
2022-04-06 12:33:16 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f58c54e6-kafka-clients will be ready
2022-04-06 12:33:18 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f58c54e6-kafka-clients is ready
2022-04-06 12:33:18 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 12:33:18 [main] [32mINFO [m [SecurityST:453] Checking produced and consumed messages to pod:my-cluster-f58c54e6-kafka-clients-57469fbffc-2w5gh
2022-04-06 12:33:18 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@459e3a24, messages=[], arguments=[--max-messages, 100, --topic, my-topic-1995313158-212572073, --bootstrap-server, my-cluster-f58c54e6-kafka-bootstrap.namespace-142.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-f58c54e6-kafka-clients-57469fbffc-2w5gh', podNamespace='namespace-142', bootstrapServer='my-cluster-f58c54e6-kafka-bootstrap.namespace-142.svc:9092', topicName='my-topic-1995313158-212572073', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@b4d92dd}
2022-04-06 12:33:18 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-f58c54e6-kafka-bootstrap.namespace-142.svc:9092:my-topic-1995313158-212572073 from pod my-cluster-f58c54e6-kafka-clients-57469fbffc-2w5gh
2022-04-06 12:33:18 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f58c54e6-kafka-clients-57469fbffc-2w5gh -n namespace-142 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-1995313158-212572073 --bootstrap-server my-cluster-f58c54e6-kafka-bootstrap.namespace-142.svc:9092
2022-04-06 12:33:20 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 12:33:20 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-06 12:33:20 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5d919ea5, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1523392843, --group-instance-id, instance621181710, --topic, my-topic-1995313158-212572073, --bootstrap-server, my-cluster-f58c54e6-kafka-bootstrap.namespace-142.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-f58c54e6-kafka-clients-57469fbffc-2w5gh', podNamespace='namespace-142', bootstrapServer='my-cluster-f58c54e6-kafka-bootstrap.namespace-142.svc:9092', topicName='my-topic-1995313158-212572073', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1523392843', consumerInstanceId='instance621181710', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3aad3857}
2022-04-06 12:33:20 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-f58c54e6-kafka-bootstrap.namespace-142.svc:9092#my-topic-1995313158-212572073 from pod my-cluster-f58c54e6-kafka-clients-57469fbffc-2w5gh
2022-04-06 12:33:20 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f58c54e6-kafka-clients-57469fbffc-2w5gh -n namespace-142 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1523392843 --group-instance-id instance621181710 --topic my-topic-1995313158-212572073 --bootstrap-server my-cluster-f58c54e6-kafka-bootstrap.namespace-142.svc:9092
2022-04-06 12:33:26 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 12:33:26 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-06 12:33:26 [main] [32mINFO [m [SecurityST:467] Triggering CA cert renewal by adding the annotation
2022-04-06 12:33:26 [main] [32mINFO [m [SecurityST:479] Patching secret my-cluster-f58c54e6-cluster-ca with strimzi.io/force-replace
2022-04-06 12:33:26 [main] [32mINFO [m [SecurityST:484] Wait for zk to rolling restart (1)...
2022-04-06 12:33:26 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-f58c54e6-zookeeper rolling update
2022-04-06 12:34:46 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-f58c54e6-zookeeper has been successfully rolled
2022-04-06 12:34:46 [main] [32mINFO [m [SecurityST:489] Wait for kafka to rolling restart (1)...
2022-04-06 12:34:46 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-f58c54e6-kafka rolling update
2022-04-06 12:36:16 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-f58c54e6-kafka has been successfully rolled
2022-04-06 12:36:16 [main] [32mINFO [m [SecurityST:494] Wait for EO to rolling restart (1)...
2022-04-06 12:36:16 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-f58c54e6-entity-operator rolling update
2022-04-06 12:36:41 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f58c54e6-entity-operator will be ready
2022-04-06 12:37:31 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f58c54e6-entity-operator is ready
2022-04-06 12:37:41 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-f58c54e6-entity-operator rolling update finished
2022-04-06 12:37:41 [main] [32mINFO [m [SecurityST:499] Wait for KafkaExporter and CruiseControl to rolling restart (1)...
2022-04-06 12:37:41 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-f58c54e6-kafka-exporter rolling update
2022-04-06 12:37:46 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f58c54e6-kafka-exporter will be ready
2022-04-06 12:38:17 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f58c54e6-kafka-exporter is ready
2022-04-06 12:38:27 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-f58c54e6-kafka-exporter rolling update finished
2022-04-06 12:38:27 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-f58c54e6-cruise-control rolling update
2022-04-06 12:38:38 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f58c54e6-cruise-control will be ready
2022-04-06 12:38:44 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f58c54e6-cruise-control is ready
2022-04-06 12:38:54 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-f58c54e6-cruise-control rolling update finished
2022-04-06 12:38:54 [main] [32mINFO [m [SecurityST:505] Wait for zk to rolling restart (2)...
2022-04-06 12:38:54 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-f58c54e6-zookeeper rolling update
2022-04-06 12:39:49 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-f58c54e6-zookeeper has been successfully rolled
2022-04-06 12:39:49 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-f58c54e6-zookeeper to be ready
2022-04-06 12:40:13 [main] [32mINFO [m [SecurityST:510] Wait for kafka to rolling restart (2)...
2022-04-06 12:40:13 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-f58c54e6-kafka rolling update
2022-04-06 12:41:18 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-f58c54e6-kafka has been successfully rolled
2022-04-06 12:41:18 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-f58c54e6-kafka to be ready
2022-04-06 12:41:45 [main] [32mINFO [m [SecurityST:515] Wait for EO to rolling restart (2)...
2022-04-06 12:41:45 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-f58c54e6-entity-operator rolling update
2022-04-06 12:41:45 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f58c54e6-entity-operator will be ready
2022-04-06 12:44:14 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f58c54e6-entity-operator is ready
2022-04-06 12:44:24 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-f58c54e6-entity-operator rolling update finished
2022-04-06 12:44:24 [main] [32mINFO [m [SecurityST:520] Wait for KafkaExporter and CruiseControl to rolling restart (2)...
2022-04-06 12:44:24 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-f58c54e6-kafka-exporter rolling update
2022-04-06 12:45:25 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f58c54e6-kafka-exporter will be ready
2022-04-06 12:45:25 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f58c54e6-kafka-exporter is ready
2022-04-06 12:45:35 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-f58c54e6-kafka-exporter rolling update finished
2022-04-06 12:45:35 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-f58c54e6-cruise-control rolling update
2022-04-06 12:45:35 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f58c54e6-cruise-control will be ready
2022-04-06 12:45:35 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f58c54e6-cruise-control is ready
2022-04-06 12:45:45 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-f58c54e6-cruise-control rolling update finished
2022-04-06 12:45:45 [main] [32mINFO [m [SecurityST:525] Checking the certificates have been replaced
2022-04-06 12:45:45 [main] [32mINFO [m [SecurityST:536] Checking consumed messages to pod:my-cluster-f58c54e6-kafka-clients-57469fbffc-2w5gh
2022-04-06 12:45:45 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4ffd3c07, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1193921568, --group-instance-id, instance685833029, --topic, my-topic-1995313158-212572073, --bootstrap-server, my-cluster-f58c54e6-kafka-bootstrap.namespace-142.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-f58c54e6-kafka-clients-57469fbffc-2w5gh', podNamespace='namespace-142', bootstrapServer='my-cluster-f58c54e6-kafka-bootstrap.namespace-142.svc:9092', topicName='my-topic-1995313158-212572073', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1193921568', consumerInstanceId='instance685833029', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@44990f2e}
2022-04-06 12:45:45 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-f58c54e6-kafka-bootstrap.namespace-142.svc:9092#my-topic-1995313158-212572073 from pod my-cluster-f58c54e6-kafka-clients-57469fbffc-2w5gh
2022-04-06 12:45:45 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f58c54e6-kafka-clients-57469fbffc-2w5gh -n namespace-142 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1193921568 --group-instance-id instance685833029 --topic my-topic-1995313158-212572073 --bootstrap-server my-cluster-f58c54e6-kafka-bootstrap.namespace-142.svc:9092
2022-04-06 12:45:51 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 12:45:51 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-06 12:45:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-352730928-1882119961 in namespace namespace-142
2022-04-06 12:45:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-142
2022-04-06 12:45:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-352730928-1882119961 will have desired state: Ready
2022-04-06 12:45:52 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-352730928-1882119961 is in desired state: Ready
2022-04-06 12:45:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-f58c54e6-kafka-clients-tls in namespace namespace-142
2022-04-06 12:45:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-142
2022-04-06 12:45:52 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f58c54e6-kafka-clients-tls will be ready
2022-04-06 12:45:54 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f58c54e6-kafka-clients-tls is ready
2022-04-06 12:45:54 [main] [32mINFO [m [SecurityST:561] Checking consumed messages to pod:my-cluster-f58c54e6-kafka-clients-tls-67f4bdb779-pwf42
2022-04-06 12:45:54 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@107141bd, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-1774073902, --group-instance-id, instance1447962638, --topic, my-topic-1995313158-212572073, --bootstrap-server, my-cluster-f58c54e6-kafka-bootstrap.namespace-142.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-f58c54e6-kafka-clients-tls-67f4bdb779-pwf42', podNamespace='namespace-142', bootstrapServer='my-cluster-f58c54e6-kafka-bootstrap.namespace-142.svc:9092', topicName='my-topic-1995313158-212572073', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1774073902', consumerInstanceId='instance1447962638', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1c9ddd7f}
2022-04-06 12:45:54 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-f58c54e6-kafka-bootstrap.namespace-142.svc:9092#my-topic-1995313158-212572073 from pod my-cluster-f58c54e6-kafka-clients-tls-67f4bdb779-pwf42
2022-04-06 12:45:54 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f58c54e6-kafka-clients-tls-67f4bdb779-pwf42 -n namespace-142 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-1774073902 --group-instance-id instance1447962638 --topic my-topic-1995313158-212572073 --bootstrap-server my-cluster-f58c54e6-kafka-bootstrap.namespace-142.svc:9092
2022-04-06 12:45:59 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 12:45:59 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-06 12:45:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:45:59 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoReplaceClusterCaKeysTriggeredByAnno
2022-04-06 12:45:59 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-f58c54e6-kafka-clients in namespace namespace-142
2022-04-06 12:45:59 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-352730928-1882119961 in namespace namespace-142
2022-04-06 12:45:59 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-f58c54e6-kafka-clients-tls in namespace namespace-142
2022-04-06 12:45:59 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-f58c54e6 in namespace namespace-142
2022-04-06 12:45:59 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-142, for cruise control Kafka cluster my-cluster-f58c54e6
2022-04-06 12:45:59 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1995313158-212572073 in namespace namespace-142
2022-04-06 12:45:59 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-777619998-1100517471 in namespace namespace-142
2022-04-06 12:46:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:46:50 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-142 for test case:testAutoReplaceClusterCaKeysTriggeredByAnno
2022-04-06 12:46:56 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno-FINISHED
2022-04-06 12:46:56 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 12:46:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:46:56 [main] [32mINFO [m [ResourceManager:346] In context SecurityST is everything deleted.
2022-04-06 12:46:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,022.656 s - in io.strimzi.systemtest.security.SecurityST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST
2022-04-06 12:47:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 12:47:27 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 12:47:27 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 12:47:27 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 12:47:27 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:47:27 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 12:47:27 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 12:47:27 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 12:47:27 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 12:47:27 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 12:47:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 12:47:27 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 12:47:27 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 12:47:27 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 12:47:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 12:47:27 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 12:47:27 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:47:27 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:47:27 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 12:47:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 12:47:27 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 12:47:27 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:47:27 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:47:27 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:47:27 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 12:47:27 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 12:47:37 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 12:47:37 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 12:47:37 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:47:37 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 12:47:37 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 12:47:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:47:52 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 12:47:52 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testKafkaCCAndRebalanceWithMultipleCOs-STARTED
2022-04-06 12:47:52 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 12:47:52 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:230] Creating first-strimzi-cluster-operator in multiple-co-cluster-test namespace
2022-04-06 12:47:52 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@51a38e96, extensionContext=org.junit.jupiter.engine.descriptor.MethodExtensionContext@204ef2c9, clusterOperatorName='first-strimzi-cluster-operator', namespaceInstallTo='multiple-co-cluster-test', namespaceToWatch='multiple-co-cluster-test', bindingsNamespaces=[multiple-co-cluster-test], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[EnvVar(name=STRIMZI_CUSTOM_RESOURCE_SELECTOR, value=app.kubernetes.io/operator=first-strimzi-cluster-operator, valueFrom=null, additionalProperties={})], extraLabels={app.kubernetes.io/operator=first-strimzi-cluster-operator}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-06 12:47:52 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 12:47:52 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: multiple-co-cluster-test
2022-04-06 12:47:52 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: multiple-co-cluster-test
2022-04-06 12:47:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 12:47:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 12:47:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 12:47:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 12:47:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 12:47:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 12:47:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 12:47:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 12:47:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 12:47:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 12:47:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:47:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:47:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 12:47:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 12:47:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 12:47:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 12:47:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 12:47:53 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: multiple-co-cluster-test
2022-04-06 12:47:53 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace multiple-co-cluster-test
2022-04-06 12:47:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 12:47:53 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace multiple-co-cluster-test
2022-04-06 12:47:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 12:47:53 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace multiple-co-cluster-test
2022-04-06 12:47:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 12:47:53 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace multiple-co-cluster-test
2022-04-06 12:47:53 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 12:47:53 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace multiple-co-cluster-test
2022-04-06 12:47:53 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace multiple-co-cluster-test
2022-04-06 12:47:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment first-strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 12:47:53 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: first-strimzi-cluster-operator will be ready
2022-04-06 12:48:12 [main] [32mINFO [m [DeploymentUtils:168] Deployment: first-strimzi-cluster-operator is ready
2022-04-06 12:48:12 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment first-strimzi-cluster-operator to be ready
2022-04-06 12:48:22 [main] [32mINFO [m [DeploymentUtils:197] Deployment first-strimzi-cluster-operator is ready
2022-04-06 12:48:22 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:230] Creating second-strimzi-cluster-operator in multiple-co-cluster-test namespace
2022-04-06 12:48:22 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@51a38e96, extensionContext=org.junit.jupiter.engine.descriptor.MethodExtensionContext@204ef2c9, clusterOperatorName='second-strimzi-cluster-operator', namespaceInstallTo='multiple-co-cluster-test', namespaceToWatch='multiple-co-cluster-test', bindingsNamespaces=[multiple-co-cluster-test], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[EnvVar(name=STRIMZI_CUSTOM_RESOURCE_SELECTOR, value=app.kubernetes.io/operator=second-strimzi-cluster-operator, valueFrom=null, additionalProperties={})], extraLabels={app.kubernetes.io/operator=second-strimzi-cluster-operator}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-06 12:48:22 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 12:48:22 [main] [32mINFO [m [SetupClusterOperator:254] Environment for ClusterOperator was already prepared! Going to install it now.
2022-04-06 12:48:22 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 12:48:22 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 12:48:22 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 12:48:22 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 12:48:22 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 12:48:22 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 12:48:22 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 12:48:22 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 12:48:22 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 12:48:22 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 12:48:22 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:48:22 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:48:22 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 12:48:22 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 12:48:22 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 12:48:22 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 12:48:22 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 12:48:22 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: multiple-co-cluster-test
2022-04-06 12:48:22 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace multiple-co-cluster-test
2022-04-06 12:48:22 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 12:48:22 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace multiple-co-cluster-test
2022-04-06 12:48:22 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 12:48:23 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace multiple-co-cluster-test
2022-04-06 12:48:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 12:48:23 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace multiple-co-cluster-test
2022-04-06 12:48:23 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 12:48:23 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace multiple-co-cluster-test
2022-04-06 12:48:23 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace multiple-co-cluster-test
2022-04-06 12:48:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment second-strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 12:48:23 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: second-strimzi-cluster-operator will be ready
2022-04-06 12:48:45 [main] [32mINFO [m [DeploymentUtils:168] Deployment: second-strimzi-cluster-operator is ready
2022-04-06 12:48:45 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment second-strimzi-cluster-operator to be ready
2022-04-06 12:48:55 [main] [32mINFO [m [DeploymentUtils:197] Deployment second-strimzi-cluster-operator is ready
2022-04-06 12:48:55 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:171] Deploying Kafka with {app.kubernetes.io/operator=first-strimzi-cluster-operator} selector of first-strimzi-cluster-operator
2022-04-06 12:48:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a5a27d40 in namespace multiple-co-cluster-test
2022-04-06 12:48:55 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a5a27d40 will have desired state: Ready
2022-04-06 12:50:39 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a5a27d40 is in desired state: Ready
2022-04-06 12:50:39 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:180] Removing CR selector from Kafka and increasing number of replicas to 4, new pod should not appear
2022-04-06 12:50:39 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:188] Creating KafkaRebalance when CC doesn't have label for CO, the KR should be ignored
2022-04-06 12:50:39 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-a5a27d40 in namespace multiple-co-cluster-test
2022-04-06 12:50:39 [main] [32mINFO [m [KafkaUtils:180] Waiting for cluster stability
2022-04-06 12:51:41 [main] [32mINFO [m [KafkaUtils:208] Kafka cluster is stable after 61 polls.
2022-04-06 12:51:41 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:204] Checking if KafkaRebalance is still ignored, after the cluster stability wait
2022-04-06 12:51:41 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:209] Adding {app.kubernetes.io/operator=second-strimzi-cluster-operator} selector of second-strimzi-cluster-operator to Kafka
2022-04-06 12:51:41 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:212] Waiting for Kafka to scales pods to 4
2022-04-06 12:51:41 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 4 Pod(s) of my-cluster-a5a27d40-kafka to be ready
2022-04-06 12:55:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a5a27d40 will have desired state: Ready
2022-04-06 12:55:06 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a5a27d40 is in desired state: Ready
2022-04-06 12:55:06 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-a5a27d40 is ready
2022-04-06 12:55:06 [main] [32mINFO [m [KafkaRebalanceUtils:75] Reconciliation #9(test) KafkaRebalance(second-co-namespace/my-cluster-a5a27d40): ============================================================================
2022-04-06 12:55:06 [main] [32mINFO [m [KafkaRebalanceUtils:76] Reconciliation #9(test) KafkaRebalance(second-co-namespace/my-cluster-a5a27d40): PendingProposal
2022-04-06 12:55:06 [main] [32mINFO [m [KafkaRebalanceUtils:77] Reconciliation #9(test) KafkaRebalance(second-co-namespace/my-cluster-a5a27d40): ============================================================================
2022-04-06 12:55:06 [main] [32mINFO [m [KafkaRebalanceUtils:81] Reconciliation #9(test) KafkaRebalance(second-co-namespace/my-cluster-a5a27d40): Verifying that KafkaRebalance resource is in PendingProposal state
2022-04-06 12:55:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-a5a27d40 will have desired state: PendingProposal
2022-04-06 12:55:06 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-a5a27d40 is in desired state: PendingProposal
2022-04-06 12:55:06 [main] [32mINFO [m [KafkaRebalanceUtils:85] Reconciliation #9(test) KafkaRebalance(second-co-namespace/my-cluster-a5a27d40): Verifying that KafkaRebalance resource is in ProposalReady state
2022-04-06 12:55:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-a5a27d40 will have desired state: ProposalReady
2022-04-06 12:55:30 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-a5a27d40 is in desired state: ProposalReady
2022-04-06 12:55:30 [main] [32mINFO [m [KafkaRebalanceUtils:90] Reconciliation #9(test) KafkaRebalance(second-co-namespace/my-cluster-a5a27d40): ============================================================================
2022-04-06 12:55:30 [main] [32mINFO [m [KafkaRebalanceUtils:91] Reconciliation #9(test) KafkaRebalance(second-co-namespace/my-cluster-a5a27d40): ProposalReady
2022-04-06 12:55:30 [main] [32mINFO [m [KafkaRebalanceUtils:92] Reconciliation #9(test) KafkaRebalance(second-co-namespace/my-cluster-a5a27d40): ============================================================================
2022-04-06 12:55:30 [main] [32mINFO [m [KafkaRebalanceUtils:94] Reconciliation #9(test) KafkaRebalance(second-co-namespace/my-cluster-a5a27d40): Triggering the rebalance with annotation strimzi.io/rebalance=approve of KafkaRebalance resource
2022-04-06 12:55:30 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #9(test) KafkaRebalance(second-co-namespace/my-cluster-a5a27d40): Annotating KafkaRebalance:my-cluster-a5a27d40 with annotation approve
2022-04-06 12:55:30 [main] [32mINFO [m [KafkaRebalanceUtils:98] Reconciliation #9(test) KafkaRebalance(second-co-namespace/my-cluster-a5a27d40): Response from the annotation process kafkarebalance.kafka.strimzi.io/my-cluster-a5a27d40 annotated
2022-04-06 12:55:30 [main] [32mINFO [m [KafkaRebalanceUtils:100] Reconciliation #9(test) KafkaRebalance(second-co-namespace/my-cluster-a5a27d40): Verifying that annotation triggers the Rebalancing state
2022-04-06 12:55:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-a5a27d40 will have desired state: Rebalancing
2022-04-06 12:55:31 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-a5a27d40 is in desired state: Rebalancing
2022-04-06 12:55:31 [main] [32mINFO [m [KafkaRebalanceUtils:104] Reconciliation #9(test) KafkaRebalance(second-co-namespace/my-cluster-a5a27d40): Verifying that KafkaRebalance is in the Ready state
2022-04-06 12:55:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-a5a27d40 will have desired state: Ready
2022-04-06 12:55:36 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-a5a27d40 is in desired state: Ready
2022-04-06 12:55:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:55:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaCCAndRebalanceWithMultipleCOs
2022-04-06 12:55:36 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 12:55:36 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 12:55:36 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 12:55:36 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 12:55:36 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 12:55:36 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 12:55:36 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 12:55:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:55:36 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 12:55:36 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace multiple-co-cluster-test
2022-04-06 12:55:36 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 12:55:36 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 12:55:36 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 12:55:36 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a5a27d40 in namespace multiple-co-cluster-test
2022-04-06 12:55:36 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace multiple-co-cluster-test, for cruise control Kafka cluster my-cluster-a5a27d40
2022-04-06 12:55:36 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment second-strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 12:55:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 12:55:46 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 12:55:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 12:55:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 12:55:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 12:55:46 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 12:55:46 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 12:55:46 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 12:55:46 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 12:55:46 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-a5a27d40 in namespace multiple-co-cluster-test
2022-04-06 12:55:46 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 12:55:46 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:55:47 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 12:55:47 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 12:55:47 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 12:55:47 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 12:55:47 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 12:55:47 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 12:55:47 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:55:47 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:55:47 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 12:55:47 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 12:55:47 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 12:55:47 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 12:55:47 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 12:55:47 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace multiple-co-cluster-test
2022-04-06 12:55:47 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 12:55:47 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment first-strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 12:55:56 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 12:55:56 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 12:55:56 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 12:55:56 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 12:55:56 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 12:55:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:55:57 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testKafkaCCAndRebalanceWithMultipleCOs-FINISHED
2022-04-06 12:55:57 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 12:55:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:55:57 [main] [32mINFO [m [ResourceManager:346] In context MultipleClusterOperatorsIsolatedST is everything deleted.
2022-04-06 12:55:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 535.166 s - in io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST
2022-04-06 12:55:57 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 12:56:22 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 12:56:22 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 12:56:22 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 12:56:22 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:56:22 [main] [32mINFO [m [ResourceManager:346] In context JUnit Jupiter is everything deleted.
2022-04-06 12:56:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:56:27 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@228dce95
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 12:56:27 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 12:56:27 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 12:56:27 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 12:56:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:56:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 12:56:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 12:56:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 12:56:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 12:56:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 12:56:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 12:56:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 12:56:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 12:56:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 12:56:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:56:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:56:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 12:56:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 12:56:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 12:56:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 12:56:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:56:28 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 12:56:28 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 12:56:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 12:56:28 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 12:56:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 12:56:28 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 12:56:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 12:56:28 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 12:56:28 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:56:28 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 12:56:28 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 12:56:28 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 12:56:28 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 12:56:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 12:56:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 12:56:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:56:28 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 12:56:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 12:56:48 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 12:56:58 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 12:56:58 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-06 12:56:58 [main] [32mINFO [m [OauthAbstractST:125] Deploying keycloak...
2022-04-06 12:56:58 [main] [32mINFO [m [KeycloakUtils:35] Prepare Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-06 12:58:35 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/prepare_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-06 12:58:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 12:58:35 [main] [32mINFO [m [KeycloakUtils:48] Keycloak in namespace infra-namespace is ready
2022-04-06 12:58:35 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret credential-example-keycloak
2022-04-06 12:58:35 [main] [32mINFO [m [SecretUtils:50] Secret credential-example-keycloak created
2022-04-06 12:58:35 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-producer-secret
2022-04-06 12:58:35 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-consumer-secret
2022-04-06 12:58:35 [main] [32mINFO [m [SecretUtils:70] Creating secret team-a-client-secret
2022-04-06 12:58:35 [main] [32mINFO [m [SecretUtils:70] Creating secret team-b-client-secret
2022-04-06 12:58:35 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-broker-secret
2022-04-06 12:58:35 [main] [32mINFO [m [SecretUtils:70] Creating secret my-connect-oauth
2022-04-06 12:58:35 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-oauth
2022-04-06 12:58:35 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-2-oauth
2022-04-06 12:58:35 [main] [32mINFO [m [SecretUtils:70] Creating secret my-bridge-oauth
2022-04-06 12:58:35 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-audience-secret
2022-04-06 12:58:35 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-client-secret
2022-04-06 12:58:35 [main] [32mINFO [m [KeycloakInstance:50] Replacing validIssuerUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal to pointing to internal realm
2022-04-06 12:58:35 [main] [32mINFO [m [KeycloakInstance:51] Replacing jwksEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/certs to pointing to internal realm
2022-04-06 12:58:35 [main] [32mINFO [m [KeycloakInstance:52] Replacing oauthTokenEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token to pointing to internal realm
2022-04-06 12:58:35 [main] [32mINFO [m [KeycloakInstance:60] Using HTTP endpoints
2022-04-06 12:58:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-plain-name in namespace infra-namespace
2022-04-06 12:58:35 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-plain-name will have desired state: Ready
2022-04-06 12:59:53 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-plain-name is in desired state: Ready
2022-04-06 12:59:53 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 12:59:53 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect-STARTED
2022-04-06 12:59:53 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 12:59:53 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 12:59:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1353531840-261575815 in namespace infra-namespace
2022-04-06 12:59:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1353531840-261575815 will have desired state: Ready
2022-04-06 12:59:54 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1353531840-261575815 is in desired state: Ready
2022-04-06 12:59:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-ff80a9ab in namespace infra-namespace
2022-04-06 12:59:54 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-ff80a9ab will be in active state
2022-04-06 12:59:55 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-ff80a9ab to finished
2022-04-06 13:00:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-ff80a9ab in namespace infra-namespace
2022-04-06 13:00:04 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-ff80a9ab will be in active state
2022-04-06 13:00:05 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-ff80a9ab to finished
2022-04-06 13:00:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-ff80a9ab-kafka-clients in namespace infra-namespace
2022-04-06 13:00:16 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ff80a9ab-kafka-clients will be ready
2022-04-06 13:00:18 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ff80a9ab-kafka-clients is ready
2022-04-06 13:00:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-ff80a9ab-scraper in namespace infra-namespace
2022-04-06 13:00:18 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ff80a9ab-scraper will be ready
2022-04-06 13:00:19 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ff80a9ab-scraper is ready
2022-04-06 13:00:19 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-ff80a9ab-scraper to be ready
2022-04-06 13:00:29 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-ff80a9ab-scraper is ready
2022-04-06 13:00:29 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-ff80a9ab-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 13:00:29 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-ff80a9ab-allow in namespace infra-namespace
2022-04-06 13:00:29 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 13:00:29 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-ff80a9ab in namespace infra-namespace
2022-04-06 13:00:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-ff80a9ab will have desired state: Ready
2022-04-06 13:01:33 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-ff80a9ab is in desired state: Ready
2022-04-06 13:01:33 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-06 13:01:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-ff80a9ab-connect-57f58f8cf6-7hlf4 -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-06 13:01:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 13:01:33 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-06 13:01:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-ff80a9ab-connect-57f58f8cf6-7hlf4 -- /bin/bash -c curl -X POST -H "Content-Type: application/json" --data '{ "name": "sink-test", "config": { "connector.class": "FileStreamSink", "tasks.max": "1", "topics": "my-topic-1353531840-261575815", "file": "/tmp/test-file-sink.txt" } }' http://localhost:8083/connectors
2022-04-06 13:01:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 13:01:33 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-ff80a9ab-connect-57f58f8cf6-7hlf4
2022-04-06 13:01:37 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-ff80a9ab-connect-57f58f8cf6-7hlf4
2022-04-06 13:01:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 13:01:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerConnect
2022-04-06 13:01:38 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-ff80a9ab-scraper in namespace infra-namespace
2022-04-06 13:01:38 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-ff80a9ab-allow in namespace infra-namespace
2022-04-06 13:01:38 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-ff80a9ab in namespace infra-namespace
2022-04-06 13:01:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1353531840-261575815 in namespace infra-namespace
2022-04-06 13:01:38 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-ff80a9ab-kafka-clients in namespace infra-namespace
2022-04-06 13:01:38 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-ff80a9ab in namespace infra-namespace
2022-04-06 13:01:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-ff80a9ab in namespace infra-namespace
2022-04-06 13:02:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 13:02:18 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect-FINISHED
2022-04-06 13:02:18 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 13:02:18 [main] [32mINFO [m [KeycloakUtils:52] Teardown Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-06 13:02:22 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/teardown_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-06 13:02:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 13:02:22 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 13:02:22 [main] [32mINFO [m [ResourceManager:348] Delete all resources for OauthPlainIsolatedST
2022-04-06 13:02:22 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-plain-name in namespace infra-namespace
2022-04-06 13:02:22 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-06 13:02:32 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 13:02:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 13:02:32 [main] [32mINFO [m [ResourceManager:346] In context OauthPlainIsolatedST is everything deleted.
2022-04-06 13:02:32 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 395.299 s - in io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST
2022-04-06 13:02:32 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 13:02:32 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 13:02:32 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 13:02:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 13:02:32 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 13:02:32 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 13:02:32 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 13:02:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 13:02:32 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 13:02:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 13:02:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 13:02:32 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 13:02:32 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 13:02:32 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 13:02:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 13:02:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 13:02:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 13:02:32 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 13:02:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 13:02:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 13:02:32 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 13:02:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 13:02:32 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 13:02:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 13:02:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 13:02:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 13:02:32 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 13:02:42 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 13:02:42 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 13:02:42 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 13:02:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 13:02:58 [main] [32mINFO [m [TestExecutionListener:40] =======================================================================
2022-04-06 13:02:58 [main] [32mINFO [m [TestExecutionListener:41] =======================================================================
2022-04-06 13:02:58 [main] [32mINFO [m [TestExecutionListener:42]                         Test run finished
2022-04-06 13:02:58 [main] [32mINFO [m [TestExecutionListener:43] =======================================================================
2022-04-06 13:02:58 [main] [32mINFO [m [TestExecutionListener:44] =======================================================================
2022-04-06 13:02:58 [main] [32mINFO [m [TestExecutionListener:29] =======================================================================
2022-04-06 13:02:58 [main] [32mINFO [m [TestExecutionListener:30] =======================================================================
2022-04-06 13:02:58 [main] [32mINFO [m [TestExecutionListener:31]                         Test run started
2022-04-06 13:02:58 [main] [32mINFO [m [TestExecutionListener:32] =======================================================================
2022-04-06 13:02:58 [main] [32mINFO [m [TestExecutionListener:33] =======================================================================
2022-04-06 13:02:58 [main] [32mINFO [m [TestExecutionListener:48] Following testclasses are selected for run:
2022-04-06 13:02:58 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.KafkaST
2022-04-06 13:02:58 [main] [32mINFO [m [TestExecutionListener:52] =======================================================================
2022-04-06 13:02:58 [main] [32mINFO [m [TestExecutionListener:53] =======================================================================
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.KafkaST
2022-04-06 13:02:58 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@58f22a09
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 13:02:58 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 13:02:58 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 13:02:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 13:02:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 13:02:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 13:02:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 13:02:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 13:02:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 13:02:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 13:02:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 13:02:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 13:02:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 13:02:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 13:02:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 13:02:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 13:02:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 13:02:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 13:02:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 13:02:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 13:02:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 13:02:58 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 13:02:58 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 13:02:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 13:02:58 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 13:02:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 13:02:58 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 13:02:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 13:02:58 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 13:02:58 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 13:02:58 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 13:02:58 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 13:02:58 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 13:02:58 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 13:02:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 13:02:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 13:02:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 13:02:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 13:03:10 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 13:03:10 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 13:03:20 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 13:03:20 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: kafka-st
2022-04-06 13:03:20 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: kafka-st
2022-04-06 13:03:20 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: kafka-st
2022-04-06 13:03:20 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 13:03:20 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testLabelModificationDoesNotBreakCluster-STARTED
2022-04-06 13:03:20 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 13:03:20 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-143 for test case:testLabelModificationDoesNotBreakCluster
2022-04-06 13:03:20 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-143
2022-04-06 13:03:20 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-143
2022-04-06 13:03:20 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-143
2022-04-06 13:03:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-86c60164 in namespace namespace-143
2022-04-06 13:03:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-143
2022-04-06 13:03:20 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-86c60164 will have desired state: Ready
2022-04-06 13:04:31 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-86c60164 is in desired state: Ready
2022-04-06 13:04:31 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-17470907-1202013256 in namespace namespace-143
2022-04-06 13:04:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-143
2022-04-06 13:04:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-17470907-1202013256 will have desired state: Ready
2022-04-06 13:04:32 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-17470907-1202013256 is in desired state: Ready
2022-04-06 13:04:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-86c60164-kafka-clients in namespace namespace-143
2022-04-06 13:04:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-143
2022-04-06 13:04:32 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-86c60164-kafka-clients will be ready
2022-04-06 13:04:34 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-86c60164-kafka-clients is ready
2022-04-06 13:04:34 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 13:04:34 [main] [32mINFO [m [KafkaST:1078] Waiting for kafka stateful set labels changed {label-name-1=name-of-the-label-1, label-name-2=name-of-the-label-2}
2022-04-06 13:04:34 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-1 -> name-of-the-label-1
2022-04-06 13:04:34 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-2 -> name-of-the-label-2
2022-04-06 13:04:34 [main] [32mINFO [m [KafkaST:1081] Getting labels from stateful set resource
2022-04-06 13:04:34 [main] [32mINFO [m [KafkaST:1084] Verifying default labels in the Kafka CR
2022-04-06 13:04:34 [main] [32mINFO [m [KafkaST:1095] Setting new values of labels from name-of-the-label-1 to new-name-of-the-label-1 | from name-of-the-label-2 to new-name-of-the-label-2 and adding one label-name-3 with value name-of-the-label-3
2022-04-06 13:04:34 [main] [32mINFO [m [KafkaST:1098] Edit kafka labels in Kafka CR
2022-04-06 13:04:34 [main] [32mINFO [m [KafkaST:1109] Waiting for kafka service labels changed {label-name-1=new-name-of-the-label-1, label-name-2=new-name-of-the-label-2, label-name-3=name-of-the-label-3}
2022-04-06 13:04:34 [main] [32mINFO [m [ServiceUtils:33] Waiting for Service label change label-name-1 -> new-name-of-the-label-1
2022-04-06 13:04:59 [main] [32mINFO [m [ServiceUtils:33] Waiting for Service label change label-name-2 -> new-name-of-the-label-2
2022-04-06 13:04:59 [main] [32mINFO [m [ServiceUtils:33] Waiting for Service label change label-name-3 -> name-of-the-label-3
2022-04-06 13:04:59 [main] [32mINFO [m [KafkaST:1112] Verifying kafka labels via services
2022-04-06 13:04:59 [main] [32mINFO [m [KafkaST:1118] Waiting for Kafka ConfigMap my-cluster-86c60164-kafka-config in namespace namespace-143 to have new labels: {label-name-1=new-name-of-the-label-1, label-name-2=new-name-of-the-label-2, label-name-3=name-of-the-label-3}
2022-04-06 13:04:59 [main] [32mINFO [m [ConfigMapUtils:42] Waiting for ConfigMap my-cluster-86c60164-kafka-config label change label-name-1 -> new-name-of-the-label-1
2022-04-06 13:04:59 [main] [32mINFO [m [ConfigMapUtils:42] Waiting for ConfigMap my-cluster-86c60164-kafka-config label change label-name-2 -> new-name-of-the-label-2
2022-04-06 13:04:59 [main] [32mINFO [m [ConfigMapUtils:42] Waiting for ConfigMap my-cluster-86c60164-kafka-config label change label-name-3 -> name-of-the-label-3
2022-04-06 13:04:59 [main] [32mINFO [m [KafkaST:1121] Verifying Kafka labels on ConfigMap my-cluster-86c60164-kafka-config in namespace namespace-143
2022-04-06 13:04:59 [main] [32mINFO [m [KafkaST:1127] Waiting for kafka stateful set labels changed {label-name-1=new-name-of-the-label-1, label-name-2=new-name-of-the-label-2, label-name-3=name-of-the-label-3}
2022-04-06 13:04:59 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-1 -> new-name-of-the-label-1
2022-04-06 13:04:59 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-2 -> new-name-of-the-label-2
2022-04-06 13:04:59 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-3 -> name-of-the-label-3
2022-04-06 13:04:59 [main] [32mINFO [m [KafkaST:1130] Verifying kafka labels via stateful set
2022-04-06 13:04:59 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-86c60164-kafka rolling update
2022-04-06 13:06:04 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-86c60164-kafka has been successfully rolled
2022-04-06 13:06:04 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-86c60164-kafka to be ready
2022-04-06 13:06:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-86c60164 will have desired state: Ready
2022-04-06 13:06:26 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-86c60164 is in desired state: Ready
2022-04-06 13:06:26 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-86c60164 is ready
2022-04-06 13:06:26 [main] [32mINFO [m [KafkaST:1136] Verifying via kafka pods
2022-04-06 13:06:26 [main] [32mINFO [m [KafkaST:1143] Removing labels: label-name-1 -> new-name-of-the-label-1, label-name-2 -> new-name-of-the-label-2, label-name-3 -> name-of-the-label-3
2022-04-06 13:06:26 [main] [32mINFO [m [KafkaST:1155] Waiting for kafka service labels deletion {app.kubernetes.io/instance=my-cluster-86c60164, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-86c60164, controller-revision-hash=my-cluster-86c60164-kafka-58f4b7964b, statefulset.kubernetes.io/pod-name=my-cluster-86c60164-kafka-0, strimzi.io/cluster=my-cluster-86c60164, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-86c60164-kafka, test.case=testLabelModificationDoesNotBreakCluster}
2022-04-06 13:06:26 [main] [32mINFO [m [ServiceUtils:44] Service label label-name-1 change to null
2022-04-06 13:07:37 [main] [32mINFO [m [ServiceUtils:44] Service label label-name-2 change to null
2022-04-06 13:07:37 [main] [32mINFO [m [ServiceUtils:44] Service label label-name-3 change to null
2022-04-06 13:07:37 [main] [32mINFO [m [KafkaST:1158] Verifying kafka labels via services
2022-04-06 13:07:37 [main] [32mINFO [m [KafkaST:1164] Waiting for Kafka ConfigMap my-cluster-86c60164-kafka-config in namespace namespace-143 to have labels removed: [label-name-1, label-name-2, label-name-3]
2022-04-06 13:07:37 [main] [32mINFO [m [ConfigMapUtils:53] Waiting for ConfigMap my-cluster-86c60164-kafka-config label label-name-1 change to null
2022-04-06 13:07:37 [main] [32mINFO [m [ConfigMapUtils:60] ConfigMap my-cluster-86c60164-kafka-config label label-name-1 change to null
2022-04-06 13:07:37 [main] [32mINFO [m [ConfigMapUtils:53] Waiting for ConfigMap my-cluster-86c60164-kafka-config label label-name-2 change to null
2022-04-06 13:07:37 [main] [32mINFO [m [ConfigMapUtils:60] ConfigMap my-cluster-86c60164-kafka-config label label-name-2 change to null
2022-04-06 13:07:37 [main] [32mINFO [m [ConfigMapUtils:53] Waiting for ConfigMap my-cluster-86c60164-kafka-config label label-name-3 change to null
2022-04-06 13:07:37 [main] [32mINFO [m [ConfigMapUtils:60] ConfigMap my-cluster-86c60164-kafka-config label label-name-3 change to null
2022-04-06 13:07:37 [main] [32mINFO [m [KafkaST:1167] Verifying Kafka labels on ConfigMap my-cluster-86c60164-kafka-config in namespace namespace-143
2022-04-06 13:07:37 [main] [32mINFO [m [KafkaST:1173] Waiting for kafka stateful set labels changed {app.kubernetes.io/instance=my-cluster-86c60164, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-86c60164, controller-revision-hash=my-cluster-86c60164-kafka-58f4b7964b, statefulset.kubernetes.io/pod-name=my-cluster-86c60164-kafka-0, strimzi.io/cluster=my-cluster-86c60164, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-86c60164-kafka, test.case=testLabelModificationDoesNotBreakCluster}
2022-04-06 13:07:37 [main] [32mINFO [m [StatefulSetUtils:96] Waiting for StatefulSet label label-name-1 change to null
2022-04-06 13:07:37 [main] [32mINFO [m [StatefulSetUtils:101] StatefulSet label label-name-1 change to null
2022-04-06 13:07:37 [main] [32mINFO [m [StatefulSetUtils:96] Waiting for StatefulSet label label-name-2 change to null
2022-04-06 13:07:37 [main] [32mINFO [m [StatefulSetUtils:101] StatefulSet label label-name-2 change to null
2022-04-06 13:07:37 [main] [32mINFO [m [StatefulSetUtils:96] Waiting for StatefulSet label label-name-3 change to null
2022-04-06 13:07:37 [main] [32mINFO [m [StatefulSetUtils:101] StatefulSet label label-name-3 change to null
2022-04-06 13:07:37 [main] [32mINFO [m [KafkaST:1176] Verifying kafka labels via stateful set
2022-04-06 13:07:37 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-86c60164-kafka rolling update
2022-04-06 13:07:37 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-86c60164-kafka has been successfully rolled
2022-04-06 13:07:37 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-86c60164-kafka to be ready
2022-04-06 13:09:02 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-86c60164 will have desired state: Ready
2022-04-06 13:09:02 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-86c60164 is in desired state: Ready
2022-04-06 13:09:02 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-86c60164 is ready
2022-04-06 13:09:02 [main] [32mINFO [m [KafkaST:1181] Waiting for kafka pod labels deletion {app.kubernetes.io/instance=my-cluster-86c60164, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-86c60164, controller-revision-hash=my-cluster-86c60164-kafka-58f4b7964b, statefulset.kubernetes.io/pod-name=my-cluster-86c60164-kafka-0, strimzi.io/cluster=my-cluster-86c60164, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-86c60164-kafka, test.case=testLabelModificationDoesNotBreakCluster}
2022-04-06 13:09:02 [main] [32mINFO [m [PodUtils:262] Waiting for Pod label label-name-1 change to null
2022-04-06 13:09:02 [main] [32mINFO [m [PodUtils:267] Pod label label-name-1 changed to null
2022-04-06 13:09:02 [main] [32mINFO [m [PodUtils:262] Waiting for Pod label label-name-2 change to null
2022-04-06 13:09:02 [main] [32mINFO [m [PodUtils:267] Pod label label-name-2 changed to null
2022-04-06 13:09:02 [main] [32mINFO [m [PodUtils:262] Waiting for Pod label label-name-3 change to null
2022-04-06 13:09:02 [main] [32mINFO [m [PodUtils:267] Pod label label-name-3 changed to null
2022-04-06 13:09:02 [main] [32mINFO [m [KafkaST:1186] Verifying via kafka pods
2022-04-06 13:09:02 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@197d3045, messages=[], arguments=[--max-messages, 100, --topic, my-topic-17470907-1202013256, --bootstrap-server, my-cluster-86c60164-kafka-bootstrap.namespace-143.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-86c60164-kafka-clients-5756649c57-84xq6', podNamespace='namespace-143', bootstrapServer='my-cluster-86c60164-kafka-bootstrap.namespace-143.svc:9092', topicName='my-topic-17470907-1202013256', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@178da4d3}
2022-04-06 13:09:02 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-86c60164-kafka-bootstrap.namespace-143.svc:9092:my-topic-17470907-1202013256 from pod my-cluster-86c60164-kafka-clients-5756649c57-84xq6
2022-04-06 13:09:02 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-86c60164-kafka-clients-5756649c57-84xq6 -n namespace-143 -- /opt/kafka/producer.sh --max-messages 100 --topic my-topic-17470907-1202013256 --bootstrap-server my-cluster-86c60164-kafka-bootstrap.namespace-143.svc:9092
2022-04-06 13:09:04 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 13:09:04 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-06 13:09:04 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7b922f1f, messages=[], arguments=[--max-messages, 100, --group-id, my-consumer-group-436125604, --group-instance-id, instance2046355344, --topic, my-topic-17470907-1202013256, --bootstrap-server, my-cluster-86c60164-kafka-bootstrap.namespace-143.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-86c60164-kafka-clients-5756649c57-84xq6', podNamespace='namespace-143', bootstrapServer='my-cluster-86c60164-kafka-bootstrap.namespace-143.svc:9092', topicName='my-topic-17470907-1202013256', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-436125604', consumerInstanceId='instance2046355344', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@143a8d8}
2022-04-06 13:09:04 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-86c60164-kafka-bootstrap.namespace-143.svc:9092#my-topic-17470907-1202013256 from pod my-cluster-86c60164-kafka-clients-5756649c57-84xq6
2022-04-06 13:09:04 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-86c60164-kafka-clients-5756649c57-84xq6 -n namespace-143 -- /opt/kafka/consumer.sh --max-messages 100 --group-id my-consumer-group-436125604 --group-instance-id instance2046355344 --topic my-topic-17470907-1202013256 --bootstrap-server my-cluster-86c60164-kafka-bootstrap.namespace-143.svc:9092
2022-04-06 13:09:10 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 13:09:10 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-06 13:09:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 13:09:10 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testLabelModificationDoesNotBreakCluster
2022-04-06 13:09:10 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-17470907-1202013256 in namespace namespace-143
2022-04-06 13:09:10 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-86c60164-kafka-clients in namespace namespace-143
2022-04-06 13:09:10 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-86c60164 in namespace namespace-143
2022-04-06 13:09:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 13:09:50 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-143 for test case:testLabelModificationDoesNotBreakCluster
2022-04-06 13:09:57 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testLabelModificationDoesNotBreakCluster-FINISHED
2022-04-06 13:09:57 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 13:09:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 13:09:57 [main] [32mINFO [m [ResourceManager:346] In context KafkaST is everything deleted.
2022-04-06 13:09:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 424.806 s - in io.strimzi.systemtest.kafka.KafkaST
2022-04-06 13:10:02 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 13:10:02 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 13:10:02 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 13:10:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 13:10:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 13:10:02 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 13:10:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 13:10:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 13:10:02 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 13:10:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 13:10:02 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 13:10:02 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 13:10:02 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 13:10:02 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 13:10:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 13:10:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 13:10:02 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 13:10:02 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 13:10:02 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 13:10:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 13:10:02 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 13:10:03 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 13:10:03 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 13:10:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 13:10:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 13:10:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 13:10:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 13:10:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 13:10:12 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 13:10:13 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 13:10:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 13:10:49 [main] [32mINFO [m [TestExecutionListener:40] =======================================================================
2022-04-06 13:10:49 [main] [32mINFO [m [TestExecutionListener:41] =======================================================================
2022-04-06 13:10:49 [main] [32mINFO [m [TestExecutionListener:42]                         Test run finished
2022-04-06 13:10:49 [main] [32mINFO [m [TestExecutionListener:43] =======================================================================
2022-04-06 13:10:49 [main] [32mINFO [m [TestExecutionListener:44] =======================================================================
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;33mWARNING[m] Flakes: 
[[1;33mWARNING[m] io.strimzi.systemtest.kafka.KafkaST.testLabelModificationDoesNotBreakCluster(ExtensionContext)
[[1;31mERROR[m]   Run 1: KafkaST.testLabelModificationDoesNotBreakCluster:1156 ? Wait Timeout after 180...
[[1;31mERROR[m]   Run 2: KafkaST.testLabelModificationDoesNotBreakCluster:1156 ? Wait Timeout after 180...
[[1;34mINFO[m]   Run 3: PASS
[[1;34mINFO[m] 
[[1;33mWARNING[m] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.testDynConfiguration
[[1;34mINFO[m]   Run 1: PASS
[[1;31mERROR[m]   Run 2: DynamicConfSharedST.lambda$testDynConfiguration$0:69 ? Wait Timeout after 4000...
[[1;31mERROR[m]   Run 3: DynamicConfSharedST.lambda$testDynConfiguration$0:69 ? Wait Timeout after 4000...
[[1;34mINFO[m]   Run 4: PASS
[[1;34mINFO[m]   Run 5: PASS
[[1;34mINFO[m] 
[[1;33mWARNING[m] io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testKafkaCCAndRebalanceWithMultipleCOs(ExtensionContext)
[[1;31mERROR[m]   Run 1: MultipleClusterOperatorsIsolatedST.testKafkaCCAndRebalanceWithMultipleCOs:217 ? Wait
[[1;34mINFO[m]   Run 2: PASS
[[1;34mINFO[m] 
[[1;33mWARNING[m] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno(ExtensionContext)
[[1;31mERROR[m]   Run 1: SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno:373->autoReplaceSomeKeysTriggeredByAnno:500 ? Wait
[[1;34mINFO[m]   Run 2: PASS
[[1;34mINFO[m] 
[[1;33mWARNING[m] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect(ExtensionContext)
[[1;31mERROR[m]   Run 1: OauthPlainIsolatedST.testProducerConsumerConnect:287 ? Wait Timeout after 6000...
[[1;34mINFO[m]   Run 2: PASS
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;33mWARNING[m] Tests run: 302, Failures: 0, Errors: 0, Skipped: 13, Flakes: 5
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] [1mReactor Summary for Strimzi - Apache Kafka on Kubernetes and OpenShift 0.29.0-SNAPSHOT:[m
[[1;34mINFO[m] 
[[1;34mINFO[m] Strimzi - Apache Kafka on Kubernetes and OpenShift . [1;32mSUCCESS[m [  2.602 s]
[[1;34mINFO[m] test ............................................... [1;32mSUCCESS[m [  0.987 s]
[[1;34mINFO[m] crd-annotations .................................... [1;32mSUCCESS[m [  0.989 s]
[[1;34mINFO[m] crd-generator ...................................... [1;32mSUCCESS[m [  2.530 s]
[[1;34mINFO[m] api ................................................ [1;32mSUCCESS[m [  6.797 s]
[[1;34mINFO[m] mockkube ........................................... [1;32mSUCCESS[m [  0.883 s]
[[1;34mINFO[m] config-model ....................................... [1;32mSUCCESS[m [  0.693 s]
[[1;34mINFO[m] certificate-manager ................................ [1;32mSUCCESS[m [  0.759 s]
[[1;34mINFO[m] operator-common .................................... [1;32mSUCCESS[m [  1.840 s]
[[1;34mINFO[m] systemtest ......................................... [1;32mSUCCESS[m [  21:36 h]
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] [1;32mBUILD SUCCESS[m
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] Total time:  21:37 h
[[1;34mINFO[m] Finished at: 2022-04-06T13:10:49Z
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
