[[1;34mINFO[m] Scanning for projects...
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] [1mReactor Build Order:[m
[[1;34mINFO[m] 
[[1;34mINFO[m] Strimzi - Apache Kafka on Kubernetes and OpenShift                 [pom]
[[1;34mINFO[m] test                                                               [jar]
[[1;34mINFO[m] crd-annotations                                                    [jar]
[[1;34mINFO[m] crd-generator                                                      [jar]
[[1;34mINFO[m] api                                                                [jar]
[[1;34mINFO[m] mockkube                                                           [jar]
[[1;34mINFO[m] config-model                                                       [jar]
[[1;34mINFO[m] certificate-manager                                                [jar]
[[1;34mINFO[m] operator-common                                                    [jar]
[[1;34mINFO[m] systemtest                                                         [jar]
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m-------------------------< [0;36mio.strimzi:strimzi[0;1m >-------------------------[m
[[1;34mINFO[m] [1mBuilding Strimzi - Apache Kafka on Kubernetes and OpenShift 0.29.0-SNAPSHOT [1/10][m
[[1;34mINFO[m] [1m--------------------------------[ pom ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mstrimzi[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mstrimzi[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] No tests to run.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Skipping pom project
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--------------------------< [0;36mio.strimzi:test[0;1m >---------------------------[m
[[1;34mINFO[m] [1mBuilding test 0.29.0-SNAPSHOT                                     [2/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/test/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/test/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/test/src/test/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] No sources to compile
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] No tests to run.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mtest[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/test/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mtest[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/test/target/test-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] No tests to run.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m---------------------< [0;36mio.strimzi:crd-annotations[0;1m >---------------------[m
[[1;34mINFO[m] [1mBuilding crd-annotations 0.29.0-SNAPSHOT                          [3/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/crd-annotations/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/crd-annotations/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/crd-annotations/src/test/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mcrd-annotations[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/crd-annotations/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mcrd-annotations[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/crd-annotations/target/crd-annotations-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mcrd-annotations[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m----------------------< [0;36mio.strimzi:crd-generator[0;1m >----------------------[m
[[1;34mINFO[m] [1mBuilding crd-generator 0.29.0-SNAPSHOT                            [4/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/crd-generator/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/crd-generator/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 7 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mcrd-generator[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/crd-generator/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mcrd-generator[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/crd-generator/target/crd-generator-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-shade-plugin:3.1.0:shade[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Including io.strimzi:crd-annotations:jar:0.29.0-SNAPSHOT in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.core:jackson-core:jar:2.12.6 in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.core:jackson-databind:jar:2.12.6.1 in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.dataformat:jackson-dataformat-yaml:jar:2.12.6 in the shaded jar.
[[1;34mINFO[m] Including org.yaml:snakeyaml:jar:1.27 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-client:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-rbac:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-admissionregistration:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-apps:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-autoscaling:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-apiextensions:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-batch:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-certificates:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-coordination:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-discovery:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-events:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-extensions:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-flowcontrol:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-networking:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-metrics:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-policy:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-scheduling:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-storageclass:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-node:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including com.squareup.okhttp3:okhttp:jar:3.12.12 in the shaded jar.
[[1;34mINFO[m] Including com.squareup.okio:okio:jar:1.15.0 in the shaded jar.
[[1;34mINFO[m] Including com.squareup.okhttp3:logging-interceptor:jar:3.12.12 in the shaded jar.
[[1;34mINFO[m] Including org.slf4j:slf4j-api:jar:1.7.36 in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.datatype:jackson-datatype-jsr310:jar:2.13.1 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:zjsonpatch:jar:0.3.0 in the shaded jar.
[[1;34mINFO[m] Including com.github.mifmif:generex:jar:1.0.2 in the shaded jar.
[[1;34mINFO[m] Including dk.brics.automaton:automaton:jar:1.11-8 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-core:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-common:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.core:jackson-annotations:jar:2.12.6 in the shaded jar.
[[1;33mWARNING[m] Discovered module-info.class. Shading will break its strong encapsulation.
[[1;33mWARNING[m] Discovered module-info.class. Shading will break its strong encapsulation.
[[1;33mWARNING[m] Discovered module-info.class. Shading will break its strong encapsulation.
[[1;33mWARNING[m] Discovered module-info.class. Shading will break its strong encapsulation.
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, generex-1.0.2.jar define 7 overlapping classes: 
[[1;33mWARNING[m]   - com.mifmif.common.regex.GenerexIterator
[[1;33mWARNING[m]   - com.mifmif.common.regex.Generex
[[1;33mWARNING[m]   - com.mifmif.common.regex.GenerexIterator$Step
[[1;33mWARNING[m]   - com.mifmif.common.regex.Node
[[1;33mWARNING[m]   - com.mifmif.common.regex.Main
[[1;33mWARNING[m]   - com.mifmif.common.regex.util.Iterable
[[1;33mWARNING[m]   - com.mifmif.common.regex.util.Iterator
[[1;33mWARNING[m] kubernetes-model-rbac-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 80 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.SubjectBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.ClusterRoleBindingFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.RoleListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.ClusterRoleBindingFluent$MetadataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.RoleBindingBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.ClusterRoleBindingBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.AggregationRuleFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.SubjectFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.ClusterRoleListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.PolicyRuleFluent
[[1;33mWARNING[m]   - 70 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, jackson-annotations-2.12.6.jar define 71 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonAutoDetect
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonInclude
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.ObjectIdGenerators
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonFormat$Features
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonFormat$Feature
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonIgnore
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonSetter
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonTypeInfo$None
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonFormat$Shape
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonSubTypes
[[1;33mWARNING[m]   - 61 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-extensions-5.12.0.jar define 264 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.DaemonSetConditionBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.NetworkPolicyListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.DeploymentStrategyFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.IngressListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.NetworkPolicySpecFluent$IngressNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.IngressStatus
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.DaemonSetFluentImpl$SpecNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.IngressSpecFluent$RulesNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.DaemonSetSpecFluent$UpdateStrategyNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.NetworkPolicyPeerBuilder
[[1;33mWARNING[m]   - 254 more...
[[1;33mWARNING[m] kubernetes-model-autoscaling-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 350 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.MetricSpecFluentImpl$ObjectNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta2.HorizontalPodAutoscalerSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.CrossVersionObjectReferenceBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.HorizontalPodAutoscalerStatusFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta2.HorizontalPodAutoscalerFluent$SpecNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta2.ContainerResourceMetricStatusFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.HorizontalPodAutoscalerStatus
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.MetricStatusFluent$ObjectNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta2.HorizontalPodAutoscalerSpecFluent$ScaleTargetRefNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.HorizontalPodAutoscalerFluent$SpecNested
[[1;33mWARNING[m]   - 340 more...
[[1;33mWARNING[m] kubernetes-model-storageclass-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 172 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.v1beta1.CSIStorageCapacityListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.CSINodeFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.CSINodeDriverFluentImpl$AllocatableNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.StorageClass
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.VolumeAttachmentSourceBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.VolumeAttachmentSourceFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.TokenRequestFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.v1beta1.CSINodeDriverFluent$AllocatableNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.v1beta1.CSIDriverSpecBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.VolumeAttachmentSpecFluent
[[1;33mWARNING[m]   - 162 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-batch-5.12.0.jar define 112 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.JobFluentImpl$StatusNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.CronJobStatusFluentImpl$ActiveNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.JobSpecFluent$TemplateNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1beta1.CronJobListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1beta1.CronJobSpecFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.JobSpecFluentImpl$TemplateNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.Job
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1beta1.CronJobFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1beta1.CronJobListFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.CronJobListFluent
[[1;33mWARNING[m]   - 102 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-apiextensions-5.12.0.jar define 350 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceDefinitionVersionBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.JSONSchemaPropsOrBoolBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceDefinitionSpecFluent$ValidationNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceDefinitionVersionFluentImpl$SchemaNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.JSONSchemaPropsOrStringArraySerDe$Deserializer$1
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceValidationFluentImpl$OpenAPIV3SchemaNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.JSONSchemaPropsFluentImpl$NotNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.WebhookClientConfigFluentImpl$ServiceNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.JSONSchemaPropsOrArrayFluent$SchemaNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1.JSONSchemaPropsOrBoolSerDe
[[1;33mWARNING[m]   - 340 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-discovery-5.12.0.jar define 88 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointSliceFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1.EndpointSliceBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointPort
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.ForZoneBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1.EndpointFluent$TargetRefNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointFluentImpl$ConditionsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1.EndpointSliceListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointConditionsFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointSliceListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - 78 more...
[[1;33mWARNING[m] okhttp-3.12.12.jar, crd-generator-0.29.0-SNAPSHOT.jar define 208 overlapping classes: 
[[1;33mWARNING[m]   - okhttp3.WebSocket
[[1;33mWARNING[m]   - okhttp3.Cookie$Builder
[[1;33mWARNING[m]   - okhttp3.internal.http.HttpHeaders
[[1;33mWARNING[m]   - okhttp3.internal.http2.Http2Connection$ReaderRunnable
[[1;33mWARNING[m]   - okhttp3.internal.http2.Http2Reader$ContinuationSource
[[1;33mWARNING[m]   - okhttp3.internal.tls.OkHostnameVerifier
[[1;33mWARNING[m]   - okhttp3.Cache$Entry
[[1;33mWARNING[m]   - okhttp3.internal.http2.Http2Connection$3
[[1;33mWARNING[m]   - okhttp3.internal.ws.RealWebSocket$Streams
[[1;33mWARNING[m]   - okhttp3.CacheControl$Builder
[[1;33mWARNING[m]   - 198 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-metrics-5.12.0.jar define 30 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.PodMetricsFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetricsListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.ContainerMetricsFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetrics
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetricsListFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetricsListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetricsFluent$MetadataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.PodMetricsFluentImpl$ContainersNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.PodMetricsListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.PodMetricsListBuilder
[[1;33mWARNING[m]   - 20 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-flowcontrol-5.12.0.jar define 132 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfigurationFluentImpl$SpecNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.FlowSchemaConditionFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.FlowDistinguisherMethodBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfigurationReferenceBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.QueuingConfiguration
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.QueuingConfigurationFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfiguration
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfigurationReference
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PolicyRulesWithSubjects
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfigurationListFluent$ItemsNested
[[1;33mWARNING[m]   - 122 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-events-5.12.0.jar define 44 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventFluent$MetadataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventFluent$SeriesNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1.EventList
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1.EventListBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventFluent$RegardingNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1.EventSeriesFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - 34 more...
[[1;33mWARNING[m] automaton-1.11-8.jar, crd-generator-0.29.0-SNAPSHOT.jar define 25 overlapping classes: 
[[1;33mWARNING[m]   - dk.brics.automaton.AutomatonMatcher
[[1;33mWARNING[m]   - dk.brics.automaton.ShuffleOperations$ShuffleConfiguration
[[1;33mWARNING[m]   - dk.brics.automaton.RegExp$Kind
[[1;33mWARNING[m]   - dk.brics.automaton.RunAutomaton
[[1;33mWARNING[m]   - dk.brics.automaton.Automaton
[[1;33mWARNING[m]   - dk.brics.automaton.RegExp
[[1;33mWARNING[m]   - dk.brics.automaton.AutomatonProvider
[[1;33mWARNING[m]   - dk.brics.automaton.RegExp$1
[[1;33mWARNING[m]   - dk.brics.automaton.MinimizationOperations$StateListNode
[[1;33mWARNING[m]   - dk.brics.automaton.State
[[1;33mWARNING[m]   - 15 more...
[[1;33mWARNING[m] jackson-core-2.12.6.jar, crd-generator-0.29.0-SNAPSHOT.jar define 124 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.JsonGenerator$Feature
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.json.JsonReadFeature
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.util.ThreadLocalBufferManager$ThreadLocalBufferManagerHolder
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.util.Separators
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.io.SegmentedStringWriter
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.TreeNode
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.sym.Name
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.util.RequestPayload
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.util.JsonGeneratorDelegate
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.async.NonBlockingInputFeeder
[[1;33mWARNING[m]   - 114 more...
[[1;33mWARNING[m] kubernetes-model-networking-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 234 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1beta1.IngressClassListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1beta1.IngressClassListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.IngressServiceBackend
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyPort
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1beta1.IngressFluentImpl$StatusNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1beta1.IngressClassSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.IngressStatus
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.IngressClassFluent$SpecNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.IngressRuleFluentImpl$HttpNestedImpl
[[1;33mWARNING[m]   - 224 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-coordination-5.12.0.jar define 18 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseFluentImpl$SpecNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseFluent$SpecNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseSpecBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseSpecFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseFluentImpl$MetadataNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseListFluent
[[1;33mWARNING[m]   - 8 more...
[[1;33mWARNING[m] zjsonpatch-0.3.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 24 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.sequence.InsertCommand
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.Operation
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.sequence.CommandVisitor
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.guava.Strings
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.sequence.EditCommand
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.JsonDiff$EncodePathFunction
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.sequence.SequencesComparator
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.Diff
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.ListUtils
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.JsonPatch
[[1;33mWARNING[m]   - 14 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-common-5.12.0.jar define 16 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.Plural
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.Group
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.jackson.JsonUnwrappedDeserializer$CancelUnwrapped
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.jackson.JsonUnwrappedDeserializer
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.PrinterColumn
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.jackson.UnwrappedTypeResolverBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.Singular
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.StatusReplicas
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.SpecReplicas
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.Version
[[1;33mWARNING[m]   - 6 more...
[[1;33mWARNING[m] kubernetes-model-admissionregistration-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 362 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1beta1.MutatingWebhookFluent$ObjectSelectorNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authorization.v1.SubjectAccessReviewSpecFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authorization.v1beta1.SubjectRulesReviewStatusBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1.ValidatingWebhookConfigurationBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authentication.TokenReviewFluentImpl$MetadataNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authorization.v1beta1.SelfSubjectRulesReviewSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1beta1.MutatingWebhookFluentImpl$NamespaceSelectorNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1beta1.MutatingWebhookConfigurationFluentImpl$WebhooksNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authorization.v1beta1.SelfSubjectAccessReviewFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1.MutatingWebhookFluent$ClientConfigNested
[[1;33mWARNING[m]   - 352 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, okio-1.15.0.jar define 44 overlapping classes: 
[[1;33mWARNING[m]   - okio.ByteString
[[1;33mWARNING[m]   - okio.Source
[[1;33mWARNING[m]   - okio.ForwardingSink
[[1;33mWARNING[m]   - okio.BufferedSource
[[1;33mWARNING[m]   - okio.Util
[[1;33mWARNING[m]   - okio.AsyncTimeout$1
[[1;33mWARNING[m]   - okio.HashingSource
[[1;33mWARNING[m]   - okio.GzipSink
[[1;33mWARNING[m]   - okio.Okio$1
[[1;33mWARNING[m]   - okio.Pipe$PipeSink
[[1;33mWARNING[m]   - 34 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-certificates-5.12.0.jar define 60 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestStatusFluent$ConditionsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestFluent$SpecNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestFluentImpl$StatusNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestStatusFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestFluent$MetadataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestConditionFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestStatusBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestStatusFluent$ConditionsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestFluentImpl
[[1;33mWARNING[m]   - 50 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, jackson-datatype-jsr310-2.13.1.jar define 59 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.deser.LocalDateDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.deser.key.Jsr310KeyDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.PackageVersion
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.deser.YearDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.ser.key.Jsr310NullKeySerializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.deser.key.LocalDateTimeKeyDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.util.DurationUnitConverter
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.ser.InstantSerializerBase
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.ser.LocalDateTimeSerializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.ser.OffsetDateTimeSerializer
[[1;33mWARNING[m]   - 49 more...
[[1;33mWARNING[m] crd-annotations-0.29.0-SNAPSHOT.jar, crd-generator-0.29.0-SNAPSHOT.jar define 8 overlapping classes: 
[[1;33mWARNING[m]   - io.strimzi.api.annotations.VersionRange
[[1;33mWARNING[m]   - io.strimzi.api.annotations.ApiVersion
[[1;33mWARNING[m]   - io.strimzi.api.annotations.ApiVersion$Stability
[[1;33mWARNING[m]   - io.strimzi.api.annotations.ApiVersion$1
[[1;33mWARNING[m]   - io.strimzi.api.annotations.DeprecatedType
[[1;33mWARNING[m]   - io.strimzi.api.annotations.DeprecatedProperty
[[1;33mWARNING[m]   - io.strimzi.api.annotations.VersionRange$VersionParser
[[1;33mWARNING[m]   - io.strimzi.api.annotations.KubeVersion
[[1;33mWARNING[m] kubernetes-model-apps-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 212 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ReplicaSetSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.StatefulSetConditionFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.DeploymentStrategyFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ControllerRevisionFluent$DeploymentDataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ReplicaSetSpecFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.DeploymentFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ReplicaSetStatusFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ControllerRevisionFluentImpl$PersistentVolumeClaimDataNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ReplicaSetCondition
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.StatefulSetSpecFluent$UpdateStrategyNested
[[1;33mWARNING[m]   - 202 more...
[[1;33mWARNING[m] logging-interceptor-3.12.12.jar, crd-generator-0.29.0-SNAPSHOT.jar define 8 overlapping classes: 
[[1;33mWARNING[m]   - okhttp3.logging.HttpLoggingInterceptor$Logger$1
[[1;33mWARNING[m]   - okhttp3.logging.LoggingEventListener$Factory
[[1;33mWARNING[m]   - okhttp3.logging.HttpLoggingInterceptor$Level
[[1;33mWARNING[m]   - okhttp3.logging.HttpLoggingInterceptor
[[1;33mWARNING[m]   - okhttp3.logging.package-info
[[1;33mWARNING[m]   - okhttp3.logging.LoggingEventListener
[[1;33mWARNING[m]   - okhttp3.logging.LoggingEventListener$1
[[1;33mWARNING[m]   - okhttp3.logging.HttpLoggingInterceptor$Logger
[[1;33mWARNING[m] jackson-dataformat-yaml-2.12.6.jar, crd-generator-0.29.0-SNAPSHOT.jar define 17 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLMapper$Builder
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.snakeyaml.error.Mark
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLGenerator
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.UTF8Reader
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLParser
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.util.StringQuotingChecker
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLGenerator$Feature
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.JacksonYAMLParseException
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLParser$Feature
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.util.StringQuotingChecker$Default
[[1;33mWARNING[m]   - 7 more...
[[1;33mWARNING[m] kubernetes-model-core-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 2394 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.BaseKubernetesListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.StatusBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.KubeSchemaFluentImpl$APIResourceNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.NodeListBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.ResourceQuotaListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.WatchEventFluentImpl$APIServiceStatusObjectNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.WatchEventFluent$VsphereVirtualDiskVolumeSourceObjectNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.ProbeFluentImpl$HttpGetNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.PatchOptionsFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.ServerAddressByClientCIDRFluentImpl
[[1;33mWARNING[m]   - 2384 more...
[[1;33mWARNING[m] slf4j-api-1.7.36.jar, crd-generator-0.29.0-SNAPSHOT.jar define 34 overlapping classes: 
[[1;33mWARNING[m]   - org.slf4j.helpers.SubstituteLogger
[[1;33mWARNING[m]   - org.slf4j.helpers.NamedLoggerBase
[[1;33mWARNING[m]   - org.slf4j.helpers.NOPMDCAdapter
[[1;33mWARNING[m]   - org.slf4j.MarkerFactory
[[1;33mWARNING[m]   - org.slf4j.helpers.BasicMarker
[[1;33mWARNING[m]   - org.slf4j.spi.LoggerFactoryBinder
[[1;33mWARNING[m]   - org.slf4j.MDC$MDCCloseable
[[1;33mWARNING[m]   - org.slf4j.spi.LocationAwareLogger
[[1;33mWARNING[m]   - org.slf4j.helpers.MessageFormatter
[[1;33mWARNING[m]   - org.slf4j.helpers.Util$ClassContextSecurityManager
[[1;33mWARNING[m]   - 24 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-node-5.12.0.jar define 78 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1beta1.OverheadBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1.RuntimeClassListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1alpha1.Scheduling
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1beta1.RuntimeClassFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1beta1.RuntimeClassListBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1.RuntimeClassFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1alpha1.SchedulingFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1alpha1.RuntimeClassSpecFluent$OverheadNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1.RuntimeClassBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1.RuntimeClassFluentImpl
[[1;33mWARNING[m]   - 68 more...
[[1;33mWARNING[m] jackson-databind-2.12.6.1.jar, crd-generator-0.29.0-SNAPSHOT.jar define 700 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.introspect.AnnotationCollector$NoAnnotations
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.jsontype.BasicPolymorphicTypeValidator$Builder
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.BeanDescription
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.deser.impl.BeanAsArrayBuilderDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.introspect.AnnotatedMethodMap
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.SerializerProvider
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.introspect.AnnotationCollector$OneAnnotation
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.ser.std.StaticListSerializerBase
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.ser.std.NumberSerializers$ShortSerializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.ser.BeanSerializerFactory
[[1;33mWARNING[m]   - 690 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, snakeyaml-1.27.jar define 216 overlapping classes: 
[[1;33mWARNING[m]   - org.yaml.snakeyaml.emitter.Emitter$ExpectBlockMappingValue
[[1;33mWARNING[m]   - org.yaml.snakeyaml.parser.ParserImpl$ParseBlockNode
[[1;33mWARNING[m]   - org.yaml.snakeyaml.emitter.Emitter$ExpectBlockMappingSimpleValue
[[1;33mWARNING[m]   - org.yaml.snakeyaml.emitter.Emitter$ExpectDocumentEnd
[[1;33mWARNING[m]   - org.yaml.snakeyaml.Yaml$3
[[1;33mWARNING[m]   - org.yaml.snakeyaml.emitter.Emitter$ExpectBlockSequenceItem
[[1;33mWARNING[m]   - org.yaml.snakeyaml.parser.ParserImpl$ParseBlockSequenceEntry
[[1;33mWARNING[m]   - org.yaml.snakeyaml.util.ArrayUtils
[[1;33mWARNING[m]   - org.yaml.snakeyaml.tokens.Token$ID
[[1;33mWARNING[m]   - org.yaml.snakeyaml.reader.StreamReader
[[1;33mWARNING[m]   - 206 more...
[[1;33mWARNING[m] kubernetes-client-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 536 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.internal.CertUtils
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.CustomResource
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.osgi.ManagedKubernetesClient
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.V1beta1ApiextensionAPIGroupDSL
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.internal.PatchUtils$SingletonHolder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.VersionInfo$1
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.utils.ReplaceValueStream
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.dsl.CreateFromServerGettable
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.dsl.ApiextensionsAPIGroupDSL
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.dsl.Containerable
[[1;33mWARNING[m]   - 526 more...
[[1;33mWARNING[m] kubernetes-model-scheduling-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 24 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassFluentImpl$MetadataNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassList
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1beta1.PriorityClassListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassListFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClass
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1beta1.PriorityClassBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1beta1.PriorityClassFluent$MetadataNested
[[1;33mWARNING[m]   - 14 more...
[[1;33mWARNING[m] kubernetes-model-policy-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 162 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1.PodDisruptionBudgetList
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.HostPortRangeBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.EvictionFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.PodSecurityPolicyFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.PodSecurityPolicySpecFluentImpl$AllowedCSIDriversNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.PodSecurityPolicyListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.AllowedFlexVolumeBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.IDRangeFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.SELinuxStrategyOptionsFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.PodSecurityPolicySpecFluentImpl$FsGroupNestedImpl
[[1;33mWARNING[m]   - 152 more...
[[1;33mWARNING[m] maven-shade-plugin has detected that some class files are
[[1;33mWARNING[m] present in two or more JARs. When this happens, only one
[[1;33mWARNING[m] single version of the class is copied to the uber jar.
[[1;33mWARNING[m] Usually this is not harmful and you can skip these warnings,
[[1;33mWARNING[m] otherwise try to manually exclude artifacts based on
[[1;33mWARNING[m] mvn dependency:tree -Ddetail=true and the above output.
[[1;33mWARNING[m] See http://maven.apache.org/plugins/maven-shade-plugin/
[[1;34mINFO[m] Replacing original artifact with shaded artifact.
[[1;34mINFO[m] Replacing /home/ec2-user/strimzi-kafka-operator/crd-generator/target/crd-generator-0.29.0-SNAPSHOT.jar with /home/ec2-user/strimzi-kafka-operator/crd-generator/target/crd-generator-0.29.0-SNAPSHOT-shaded.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m---------------------------< [0;36mio.strimzi:api[0;1m >---------------------------[m
[[1;34mINFO[m] [1mBuilding api 0.29.0-SNAPSHOT                                      [5/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/api/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/api/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mexec-maven-plugin:1.6.0:exec[m [1m(generate-crd-co-install-v1)[m @ [36mapi[0;1m ---[m
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mexec-maven-plugin:1.6.0:exec[m [1m(generate-crd-co-install-v1-eo)[m @ [36mapi[0;1m ---[m
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mexec-maven-plugin:1.6.0:exec[m [1m(generate-doc)[m @ [36mapi[0;1m ---[m
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 99 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-test-compile)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mapi[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/api/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mapi[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:test-jar[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m------------------------< [0;36mio.strimzi:mockkube[0;1m >-------------------------[m
[[1;34mINFO[m] [1mBuilding mockkube 0.29.0-SNAPSHOT                                 [6/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/mockkube/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/mockkube/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 1 resource
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mmockkube[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/mockkube/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mmockkube[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/mockkube/target/mockkube-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mmockkube[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m----------------------< [0;36mio.strimzi:config-model[0;1m >-----------------------[m
[[1;34mINFO[m] [1mBuilding config-model 0.29.0-SNAPSHOT                             [7/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/config-model/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/config-model/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/config-model/src/test/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mconfig-model[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/config-model/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mconfig-model[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/config-model/target/config-model-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mconfig-model[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m-------------------< [0;36mio.strimzi:certificate-manager[0;1m >-------------------[m
[[1;34mINFO[m] [1mBuilding certificate-manager 0.29.0-SNAPSHOT                      [8/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/certificate-manager/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 1 resource
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 1 resource
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mcertificate-manager[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/certificate-manager/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mcertificate-manager[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/certificate-manager/target/certificate-manager-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mcertificate-manager[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m---------------------< [0;36mio.strimzi:operator-common[0;1m >---------------------[m
[[1;34mINFO[m] [1mBuilding operator-common 0.29.0-SNAPSHOT                          [9/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/operator-common/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/operator-common/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 9 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36moperator-common[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/operator-common/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36moperator-common[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/operator-common/target/operator-common-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:test-jar[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m-----------------------< [0;36mio.strimzi:systemtest[0;1m >------------------------[m
[[1;34mINFO[m] [1mBuilding systemtest 0.29.0-SNAPSHOT                              [10/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/systemtest/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 3 resources
[[1;34mINFO[m] Copying 2 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 32 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;33mWARNING[m] Corrupted STDOUT by directly writing to native stream in forked JVM 1. See FAQ web page and the dump file /home/ec2-user/strimzi-kafka-operator/systemtest/target/surefire-reports/2022-04-04T06-55-24_143-jvmRun1.dumpstream
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36msystemtest[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/systemtest/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36msystemtest[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36msystemtest[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:29] =======================================================================
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:30] =======================================================================
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:31]                         Test run started
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:32] =======================================================================
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:33] =======================================================================
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:48] Following testclasses are selected for run:
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.user.UserST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.topic.ThrottlingQuotaST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.topic.TopicST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.ReconciliationST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.bridge.HttpBridgeScramShaST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.bridge.HttpBridgeTlsST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.tracing.TracingST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.cruisecontrol.CruiseControlApiST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.cruisecontrol.CruiseControlST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.KafkaST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.listeners.ListenersST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.listeners.MultipleListenersST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.ConfigProviderST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.OpaIntegrationST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.SecurityST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.custom.CustomAuthorizerST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.rollingupdate.RollingUpdateST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.log.LoggingChangeST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.log.LogSettingST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.FeatureGatesIsolatedST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.NamespaceRbacScopeOperatorIsolatedST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.RecoveryIsolatedST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.bridge.HttpBridgeIsolatedST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.specific.HelmChartIsolatedST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.specific.SpecificIsolatedST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.specific.DrainCleanerIsolatedST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.watcher.AllNamespaceIsolatedST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.connect.ConnectIsolatedST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.connect.ConnectBuilderIsolatedST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.metrics.MetricsIsolatedST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.metrics.JmxIsolatedST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.dump.LogDumpScriptIsolatedST
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:52] =======================================================================
2022-04-04 06:55:40 [main] [32mINFO [m [TestExecutionListener:53] =======================================================================
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.user.UserST
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:219] Used environment variables:
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:220] CONFIG: /home/ec2-user/strimzi-kafka-operator/systemtest/config.json
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] STRIMZI_RBAC_SCOPE: CLUSTER
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] OLM_APP_BUNDLE_PREFIX: strimzi-cluster-operator
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] TEST_CLIENTS_VERSION: 0.2.0
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] OLM_SOURCE_NAMESPACE: openshift-marketplace
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] CLUSTER_OPERATOR_INSTALL_TYPE: BUNDLE
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] STRIMZI_COMPONENTS_LOG_LEVEL: INFO
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] SKIP_TEARDOWN: false
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] LB_FINALIZERS: false
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] OLM_OPERATOR_DEPLOYMENT_NAME: strimzi-cluster-operator
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] DOCKER_ORG: strimzi
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] TEST_LOG_DIR: /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/target/logs/
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] COMPONENTS_IMAGE_PULL_POLICY: IfNotPresent
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] DOCKER_REGISTRY: quay.io
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] TEST_CLIENT_IMAGE: quay.io/strimzi/test-client:latest-kafka-3.1.0
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] SYSTEM_TEST_STRIMZI_IMAGE_PULL_SECRET: 
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] TEST_ADMIN_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-admin:0.2.0-kafka-3.1.0
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] TEST_HTTP_PRODUCER_IMAGE: quay.io/strimzi-test-clients/test-client-http-producer:0.2.0
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] OLM_OPERATOR_NAME: strimzi-kafka-operator
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] DOCKER_TAG: latest
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] OLM_SOURCE_NAME: community-operators
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] STRIMZI_FEATURE_GATES: 
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] CLIENTS_KAFKA_VERSION: 3.1.0
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] TEST_HTTP_CONSUMER_IMAGE: quay.io/strimzi-test-clients/test-client-http-consumer:0.2.0
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] STRIMZI_LOG_LEVEL: DEBUG
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] ST_KAFKA_VERSION: 3.1.0
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] OPERATOR_IMAGE_PULL_POLICY: Always
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] DEFAULT_TO_DENY_NETWORK_POLICIES: true
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] TEST_PRODUCER_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-producer:0.2.0-kafka-3.1.0
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] BRIDGE_IMAGE: latest-released
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] TEST_STREAMS_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-streams:0.2.0-kafka-3.1.0
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] TEST_CONSUMER_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-consumer:0.2.0-kafka-3.1.0
2022-04-04 06:55:40 [main] [32mINFO [m [Environment:221] OLM_OPERATOR_VERSION: 
2022-04-04 06:55:41 [main] [32mINFO [m [KubeCluster:87] Using cluster: minikube
2022-04-04 06:55:41 [main] [32mINFO [m [KubeClusterResource:60] Cluster default namespace is 'default'
2022-04-04 06:55:41 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 06:55:41 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 06:55:42 [main] [33mWARN [m [KubeClusterResource:151] Namespace infra-namespace is already created, going to delete it
2022-04-04 06:55:53 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 06:55:53 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 06:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 06:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 06:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 06:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 06:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 06:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 06:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 06:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 06:55:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 06:55:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 06:55:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 06:55:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 06:55:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 06:55:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 06:55:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 06:55:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 06:55:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 06:55:54 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 06:55:54 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 06:55:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 06:55:54 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 06:55:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 06:55:54 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 06:55:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 06:55:54 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 06:55:54 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 06:55:54 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 06:55:54 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 06:55:54 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 06:55:54 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 06:55:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 06:55:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 06:55:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 06:55:54 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 06:56:12 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 06:56:12 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 06:56:22 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 06:56:22 [main] [33mWARN [m [KubeClusterResource:151] Namespace user-st is already created, going to delete it
2022-04-04 06:56:48 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: user-st
2022-04-04 06:56:48 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: user-st
2022-04-04 06:56:48 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: user-st
2022-04-04 06:56:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka user-cluster-name in namespace user-st
2022-04-04 06:56:49 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkas' with unstable version 'v1beta2'
2022-04-04 06:56:49 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: user-cluster-name will have desired state: Ready
2022-04-04 06:57:54 [main] [32mINFO [m [ResourceManager:444] Kafka: user-cluster-name is in desired state: Ready
2022-04-04 06:57:54 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 06:57:54 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testTlsExternalUserWithQuotas-STARTED
2022-04-04 06:57:54 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 06:57:54 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1501367867-582575768 in namespace user-st
2022-04-04 06:57:54 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkausers' with unstable version 'v1beta2'
2022-04-04 06:57:54 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1501367867-582575768 will have desired state: Ready
2022-04-04 06:57:55 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1501367867-582575768 is in desired state: Ready
2022-04-04 06:57:58 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace user-st exec user-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user CN=my-user-1501367867-582575768
2022-04-04 06:57:58 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 06:57:58 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion my-user-1501367867-582575768
2022-04-04 06:57:58 [main] [33mWARN [m [KafkaUserUtils:68] KafkaUser my-user-1501367867-582575768 is not deleted yet! Triggering force delete by cmd client!
2022-04-04 06:57:59 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser my-user-1501367867-582575768 deleted
2022-04-04 06:58:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace user-st exec user-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user CN=my-user-1501367867-582575768
2022-04-04 06:58:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 06:58:01 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 06:58:01 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTlsExternalUserWithQuotas
2022-04-04 06:58:01 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1501367867-582575768 in namespace user-st
2022-04-04 06:58:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 06:58:01 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testTlsExternalUserWithQuotas-FINISHED
2022-04-04 06:58:01 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 06:58:01 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 06:58:01 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testUserTemplate-STARTED
2022-04-04 06:58:01 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 06:58:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-576148773-830573933 in namespace user-st
2022-04-04 06:58:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-576148773-830573933 will have desired state: Ready
2022-04-04 06:58:02 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-576148773-830573933 is in desired state: Ready
2022-04-04 06:58:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 06:58:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUserTemplate
2022-04-04 06:58:02 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-576148773-830573933 in namespace user-st
2022-04-04 06:58:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 06:58:12 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testUserTemplate-FINISHED
2022-04-04 06:58:12 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 06:58:12 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 06:58:12 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testUpdateUser-STARTED
2022-04-04 06:58:12 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 06:58:12 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-2144694349-32552726 in namespace user-st
2022-04-04 06:58:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-2144694349-32552726 will have desired state: Ready
2022-04-04 06:58:13 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-2144694349-32552726 is in desired state: Ready
2022-04-04 06:58:14 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret my-user-2144694349-32552726
2022-04-04 06:58:14 [main] [32mINFO [m [SecretUtils:50] Secret my-user-2144694349-32552726 created
2022-04-04 06:58:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-2144694349-32552726 will have desired state: Ready
2022-04-04 06:58:14 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-2144694349-32552726 is in desired state: Ready
2022-04-04 06:58:14 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion my-user-2144694349-32552726
2022-04-04 06:58:14 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser my-user-2144694349-32552726 deleted
2022-04-04 06:58:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 06:58:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUpdateUser
2022-04-04 06:58:14 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-2144694349-32552726 in namespace user-st
2022-04-04 06:58:14 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 06:58:14 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testUpdateUser-FINISHED
2022-04-04 06:58:14 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 06:58:14 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 06:58:14 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testTlsExternalUser-STARTED
2022-04-04 06:58:14 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 06:58:14 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-0 for test case:testTlsExternalUser
2022-04-04 06:58:14 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-0
2022-04-04 06:58:14 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-0
2022-04-04 06:58:14 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-0
2022-04-04 06:58:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-17939cf8 in namespace namespace-0
2022-04-04 06:58:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-0
2022-04-04 06:58:14 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-17939cf8 will have desired state: Ready
2022-04-04 06:59:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-17939cf8 is in desired state: Ready
2022-04-04 06:59:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1309342165-1020139123 in namespace namespace-0
2022-04-04 06:59:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-0
2022-04-04 06:59:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1309342165-1020139123 will have desired state: Ready
2022-04-04 06:59:22 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1309342165-1020139123 is in desired state: Ready
2022-04-04 06:59:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1309342165-1020139123 will have desired state: Ready
2022-04-04 06:59:22 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1309342165-1020139123 is in desired state: Ready
2022-04-04 06:59:22 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 06:59:22 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTlsExternalUser
2022-04-04 06:59:22 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1309342165-1020139123 in namespace namespace-0
2022-04-04 06:59:22 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-17939cf8 in namespace namespace-0
2022-04-04 06:59:32 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 06:59:32 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-0 for test case:testTlsExternalUser
2022-04-04 06:59:59 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testTlsExternalUser-FINISHED
2022-04-04 06:59:59 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 06:59:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 06:59:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testUserWithNameMoreThan64Chars-STARTED
2022-04-04 06:59:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 06:59:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser user-with-correct-nameabcdefghijklmnopqrstuvxyzabcdefghijklmnopq in namespace user-st
2022-04-04 06:59:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: user-with-correct-nameabcdefghijklmnopqrstuvxyzabcdefghijklmnopq will have desired state: Ready
2022-04-04 07:00:00 [main] [32mINFO [m [ResourceManager:444] KafkaUser: user-with-correct-nameabcdefghijklmnopqrstuvxyzabcdefghijklmnopq is in desired state: Ready
2022-04-04 07:00:00 [main] [32mINFO [m [KafkaUserUtils:90] Wait until KafkaUser user-with-correct-nameabcdefghijklmnopqrstuvxyzabcdefghijklmnopq status is available
2022-04-04 07:00:00 [main] [32mINFO [m [KafkaUserUtils:95] KafkaUser user-with-correct-nameabcdefghijklmnopqrstuvxyzabcdefghijklmnopq status is available
2022-04-04 07:00:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser sasl-userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef in namespace user-st
2022-04-04 07:00:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: sasl-userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef will have desired state: Ready
2022-04-04 07:00:01 [main] [32mINFO [m [ResourceManager:444] KafkaUser: sasl-userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef is in desired state: Ready
2022-04-04 07:00:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdefghijk in namespace user-st
2022-04-04 07:00:01 [main] [32mINFO [m [KafkaUserUtils:90] Wait until KafkaUser userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdefghijk status is available
2022-04-04 07:00:02 [main] [32mINFO [m [KafkaUserUtils:95] KafkaUser userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdefghijk status is available
2022-04-04 07:00:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:00:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUserWithNameMoreThan64Chars
2022-04-04 07:00:02 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser sasl-userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef in namespace user-st
2022-04-04 07:00:02 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser user-with-correct-nameabcdefghijklmnopqrstuvxyzabcdefghijklmnopq in namespace user-st
2022-04-04 07:00:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdefghijk in namespace user-st
2022-04-04 07:00:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 07:00:12 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testUserWithNameMoreThan64Chars-FINISHED
2022-04-04 07:00:12 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 07:00:12 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 07:00:12 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testTlsUserWithQuotas-STARTED
2022-04-04 07:00:12 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 07:00:12 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser encrypted-arnost in namespace user-st
2022-04-04 07:00:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: encrypted-arnost will have desired state: Ready
2022-04-04 07:00:13 [main] [32mINFO [m [ResourceManager:444] KafkaUser: encrypted-arnost is in desired state: Ready
2022-04-04 07:00:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace user-st exec user-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user CN=encrypted-arnost
2022-04-04 07:00:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:00:15 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion encrypted-arnost
2022-04-04 07:00:15 [main] [33mWARN [m [KafkaUserUtils:68] KafkaUser encrypted-arnost is not deleted yet! Triggering force delete by cmd client!
2022-04-04 07:00:16 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser encrypted-arnost deleted
2022-04-04 07:00:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace user-st exec user-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user CN=encrypted-arnost
2022-04-04 07:00:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:00:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:00:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTlsUserWithQuotas
2022-04-04 07:00:19 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser encrypted-arnost in namespace user-st
2022-04-04 07:00:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 07:00:19 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testTlsUserWithQuotas-FINISHED
2022-04-04 07:00:19 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 07:00:19 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 07:00:19 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testScramUserWithQuotas-STARTED
2022-04-04 07:00:19 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 07:00:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser scramed-arnost in namespace user-st
2022-04-04 07:00:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: scramed-arnost will have desired state: Ready
2022-04-04 07:00:20 [main] [32mINFO [m [ResourceManager:444] KafkaUser: scramed-arnost is in desired state: Ready
2022-04-04 07:00:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace user-st exec user-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user scramed-arnost
2022-04-04 07:00:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:00:22 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion scramed-arnost
2022-04-04 07:00:22 [main] [33mWARN [m [KafkaUserUtils:68] KafkaUser scramed-arnost is not deleted yet! Triggering force delete by cmd client!
2022-04-04 07:00:23 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser scramed-arnost deleted
2022-04-04 07:00:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace user-st exec user-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user scramed-arnost
2022-04-04 07:00:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:00:26 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:00:26 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScramUserWithQuotas
2022-04-04 07:00:26 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser scramed-arnost in namespace user-st
2022-04-04 07:00:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 07:00:26 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testScramUserWithQuotas-FINISHED
2022-04-04 07:00:26 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 07:00:26 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 07:00:26 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testCreatingUsersWithSecretPrefix-STARTED
2022-04-04 07:00:26 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 07:00:26 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-1 for test case:testCreatingUsersWithSecretPrefix
2022-04-04 07:00:26 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-1
2022-04-04 07:00:26 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-1
2022-04-04 07:00:26 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-1
2022-04-04 07:00:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d9f03760 in namespace namespace-1
2022-04-04 07:00:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-04-04 07:00:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d9f03760 will have desired state: Ready
2022-04-04 07:01:43 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d9f03760 is in desired state: Ready
2022-04-04 07:01:43 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-175628898-877437865 in namespace namespace-1
2022-04-04 07:01:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-04-04 07:01:43 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkatopics' with unstable version 'v1beta2'
2022-04-04 07:01:43 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-175628898-877437865 will have desired state: Ready
2022-04-04 07:01:44 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-175628898-877437865 is in desired state: Ready
2022-04-04 07:01:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser encrypted-leopold in namespace namespace-1
2022-04-04 07:01:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-04-04 07:01:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: encrypted-leopold will have desired state: Ready
2022-04-04 07:01:45 [main] [32mINFO [m [ResourceManager:444] KafkaUser: encrypted-leopold is in desired state: Ready
2022-04-04 07:01:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser scramed-leopold in namespace namespace-1
2022-04-04 07:01:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-04-04 07:01:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: scramed-leopold will have desired state: Ready
2022-04-04 07:01:46 [main] [32mINFO [m [ResourceManager:444] KafkaUser: scramed-leopold is in desired state: Ready
2022-04-04 07:01:46 [main] [32mINFO [m [UserST:346] Deploying KafkaClients pod for TLS listener
2022-04-04 07:01:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-d9f03760-tls-kafka-clients in namespace namespace-1
2022-04-04 07:01:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-04-04 07:01:46 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d9f03760-tls-kafka-clients will be ready
2022-04-04 07:01:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d9f03760-tls-kafka-clients is ready
2022-04-04 07:01:48 [main] [32mINFO [m [UserST:350] Deploying KafkaClients pod for PLAIN listener
2022-04-04 07:01:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-d9f03760-plain-kafka-clients in namespace namespace-1
2022-04-04 07:01:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-04-04 07:01:48 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d9f03760-plain-kafka-clients will be ready
2022-04-04 07:01:49 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d9f03760-plain-kafka-clients is ready
2022-04-04 07:01:49 [main] [32mINFO [m [UserST:357] Checking if user secrets with secret prefixes exists
2022-04-04 07:01:49 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 07:01:49 [main] [32mINFO [m [UserST:373] Checking if TLS user is able to send messages
2022-04-04 07:01:49 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@48b6b6b8, messages=[], arguments=[--topic, my-topic-335653399-1112350690, --max-messages, 100, USER=top_secret_encrypted_leopold, --bootstrap-server, my-cluster-d9f03760-kafka-bootstrap.namespace-1.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-d9f03760-tls-kafka-clients-558966fcdb-lr7wp', podNamespace='namespace-1', bootstrapServer='my-cluster-d9f03760-kafka-bootstrap.namespace-1.svc:9093', topicName='my-topic-335653399-1112350690', maxMessages=100, kafkaUsername='top-secret-encrypted-leopold', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2bbbea37}
2022-04-04 07:01:49 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-d9f03760-kafka-bootstrap.namespace-1.svc:9093:my-topic-335653399-1112350690 from pod my-cluster-d9f03760-tls-kafka-clients-558966fcdb-lr7wp
2022-04-04 07:01:49 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d9f03760-tls-kafka-clients-558966fcdb-lr7wp -n namespace-1 -- /opt/kafka/producer.sh --topic my-topic-335653399-1112350690 --max-messages 100 USER=top_secret_encrypted_leopold --bootstrap-server my-cluster-d9f03760-kafka-bootstrap.namespace-1.svc:9093
2022-04-04 07:01:53 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 07:01:53 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 07:01:53 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@75292204, messages=[], arguments=[--topic, my-topic-335653399-1112350690, --max-messages, 100, --group-instance-id, instance1183315014, USER=top_secret_encrypted_leopold, --group-id, my-consumer-group-881241411, --bootstrap-server, my-cluster-d9f03760-kafka-bootstrap.namespace-1.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d9f03760-tls-kafka-clients-558966fcdb-lr7wp', podNamespace='namespace-1', bootstrapServer='my-cluster-d9f03760-kafka-bootstrap.namespace-1.svc:9093', topicName='my-topic-335653399-1112350690', maxMessages=100, kafkaUsername='top-secret-encrypted-leopold', consumerGroupName='my-consumer-group-881241411', consumerInstanceId='instance1183315014', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@57e929c0}
2022-04-04 07:01:53 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-d9f03760-kafka-bootstrap.namespace-1.svc:9093:my-topic-335653399-1112350690 from pod my-cluster-d9f03760-tls-kafka-clients-558966fcdb-lr7wp
2022-04-04 07:01:53 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d9f03760-tls-kafka-clients-558966fcdb-lr7wp -n namespace-1 -- /opt/kafka/consumer.sh --topic my-topic-335653399-1112350690 --max-messages 100 --group-instance-id instance1183315014 USER=top_secret_encrypted_leopold --group-id my-consumer-group-881241411 --bootstrap-server my-cluster-d9f03760-kafka-bootstrap.namespace-1.svc:9093
2022-04-04 07:02:00 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 07:02:00 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 07:02:00 [main] [32mINFO [m [UserST:386] Checking if SCRAM-SHA user is able to send messages
2022-04-04 07:02:00 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3b896555, messages=[], arguments=[--topic, my-topic-335653399-1112350690, --max-messages, 100, USER=top_secret_scramed_leopold, --bootstrap-server, my-cluster-d9f03760-kafka-bootstrap.namespace-1.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-d9f03760-plain-kafka-clients-55fdd66fcb-kh2pv', podNamespace='namespace-1', bootstrapServer='my-cluster-d9f03760-kafka-bootstrap.namespace-1.svc:9092', topicName='my-topic-335653399-1112350690', maxMessages=100, kafkaUsername='top-secret-scramed-leopold', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7b824ddc}
2022-04-04 07:02:00 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-d9f03760-kafka-bootstrap.namespace-1.svc:9092:my-topic-335653399-1112350690 from pod my-cluster-d9f03760-plain-kafka-clients-55fdd66fcb-kh2pv
2022-04-04 07:02:00 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d9f03760-plain-kafka-clients-55fdd66fcb-kh2pv -n namespace-1 -- /opt/kafka/producer.sh --topic my-topic-335653399-1112350690 --max-messages 100 USER=top_secret_scramed_leopold --bootstrap-server my-cluster-d9f03760-kafka-bootstrap.namespace-1.svc:9092
2022-04-04 07:02:02 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 07:02:02 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 07:02:02 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1935c37d, messages=[], arguments=[--topic, my-topic-335653399-1112350690, --max-messages, 100, --group-instance-id, instance1085058922, USER=top_secret_scramed_leopold, --group-id, my-consumer-group-881241411, --bootstrap-server, my-cluster-d9f03760-kafka-bootstrap.namespace-1.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d9f03760-plain-kafka-clients-55fdd66fcb-kh2pv', podNamespace='namespace-1', bootstrapServer='my-cluster-d9f03760-kafka-bootstrap.namespace-1.svc:9092', topicName='my-topic-335653399-1112350690', maxMessages=100, kafkaUsername='top-secret-scramed-leopold', consumerGroupName='my-consumer-group-881241411', consumerInstanceId='instance1085058922', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@25b0eccd}
2022-04-04 07:02:02 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-d9f03760-kafka-bootstrap.namespace-1.svc:9092#my-topic-335653399-1112350690 from pod my-cluster-d9f03760-plain-kafka-clients-55fdd66fcb-kh2pv
2022-04-04 07:02:02 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d9f03760-plain-kafka-clients-55fdd66fcb-kh2pv -n namespace-1 -- /opt/kafka/consumer.sh --topic my-topic-335653399-1112350690 --max-messages 100 --group-instance-id instance1085058922 USER=top_secret_scramed_leopold --group-id my-consumer-group-881241411 --bootstrap-server my-cluster-d9f03760-kafka-bootstrap.namespace-1.svc:9092
2022-04-04 07:02:30 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 07:02:30 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 07:02:30 [main] [32mINFO [m [UserST:392] Checking owner reference - if the secret will be deleted when we delete KafkaUser
2022-04-04 07:02:30 [main] [32mINFO [m [UserST:394] Deleting KafkaUser:encrypted-leopold
2022-04-04 07:02:30 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion encrypted-leopold
2022-04-04 07:02:30 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser encrypted-leopold deleted
2022-04-04 07:02:30 [main] [32mINFO [m [UserST:398] Deleting KafkaUser:scramed-leopold
2022-04-04 07:02:30 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion scramed-leopold
2022-04-04 07:02:30 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser scramed-leopold deleted
2022-04-04 07:02:30 [main] [32mINFO [m [UserST:402] Checking if secrets are deleted
2022-04-04 07:02:30 [main] [32mINFO [m [SecretUtils:54] Waiting for Secret deletion top-secret-encrypted-leopold
2022-04-04 07:02:31 [main] [32mINFO [m [SecretUtils:58] Secret top-secret-encrypted-leopold deleted
2022-04-04 07:02:31 [main] [32mINFO [m [SecretUtils:54] Waiting for Secret deletion top-secret-scramed-leopold
2022-04-04 07:02:31 [main] [32mINFO [m [SecretUtils:58] Secret top-secret-scramed-leopold deleted
2022-04-04 07:02:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:02:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCreatingUsersWithSecretPrefix
2022-04-04 07:02:31 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser scramed-leopold in namespace namespace-1
2022-04-04 07:02:31 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d9f03760 in namespace namespace-1
2022-04-04 07:02:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-175628898-877437865 in namespace namespace-1
2022-04-04 07:02:31 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-d9f03760-plain-kafka-clients in namespace namespace-1
2022-04-04 07:02:31 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaUser encrypted-leopold in namespace namespace-1
2022-04-04 07:02:31 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-d9f03760-tls-kafka-clients in namespace namespace-1
2022-04-04 07:03:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 07:03:11 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-1 for test case:testCreatingUsersWithSecretPrefix
2022-04-04 07:03:16 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testCreatingUsersWithSecretPrefix-FINISHED
2022-04-04 07:03:16 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 07:03:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:03:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for UserST
2022-04-04 07:03:16 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka user-cluster-name in namespace user-st
2022-04-04 07:03:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;33mWARNING[m] Tests run: 12, Failures: 0, Errors: 0, Skipped: 4, Time elapsed: 493.018 s - in io.strimzi.systemtest.operators.user.UserST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.topic.ThrottlingQuotaST
2022-04-04 07:03:53 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: throttling-quota-st
2022-04-04 07:03:53 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: throttling-quota-st
2022-04-04 07:03:53 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: throttling-quota-st
2022-04-04 07:03:53 [main] [32mINFO [m [ThrottlingQuotaST:304] Deploying shared Kafka across all test cases in throttling-quota-st namespace
2022-04-04 07:03:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka quota-cluster in namespace throttling-quota-st
2022-04-04 07:03:53 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: quota-cluster will have desired state: Ready
2022-04-04 07:05:05 [main] [32mINFO [m [ResourceManager:444] Kafka: quota-cluster is in desired state: Ready
2022-04-04 07:05:05 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 07:05:05 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testThrottlingQuotasCreateAlterPartitions-STARTED
2022-04-04 07:05:05 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 07:05:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-894281801-1597690488 in namespace throttling-quota-st
2022-04-04 07:05:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-894281801-1597690488 will have desired state: Ready
2022-04-04 07:05:06 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-894281801-1597690488 is in desired state: Ready
2022-04-04 07:05:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-8e724d2d-kafka-clients in namespace throttling-quota-st
2022-04-04 07:05:07 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-8e724d2d-kafka-clients will be in active state
2022-04-04 07:05:07 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-04 07:09:19 [main] [32mINFO [m [PodUtils:189] Message org.apache.kafka.common.errors.ThrottlingQuotaExceededException: The throttling quota has been exceeded. found in create-admin-my-cluster-8e724d2d-kafka-clients-64r5n log
2022-04-04 07:09:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-8e724d2d-kafka-clients in namespace throttling-quota-st
2022-04-04 07:09:24 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-8e724d2d-kafka-clients will be in active state
2022-04-04 07:09:25 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-04 07:10:27 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-8e724d2d-kafka-clients-mvlph log
2022-04-04 07:10:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Job alter-admin-my-cluster-8e724d2d-kafka-clients in namespace throttling-quota-st
2022-04-04 07:10:37 [main] [32mINFO [m [JobUtils:81] Waiting for job: alter-admin-my-cluster-8e724d2d-kafka-clients will be in active state
2022-04-04 07:10:38 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-04 07:14:39 [main] [32mINFO [m [PodUtils:189] Message org.apache.kafka.common.errors.ThrottlingQuotaExceededException: The throttling quota has been exceeded. found in alter-admin-my-cluster-8e724d2d-kafka-clients-5vtzr log
2022-04-04 07:14:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Job teardown-delete in namespace throttling-quota-st
2022-04-04 07:14:44 [main] [32mINFO [m [JobUtils:81] Waiting for job: teardown-delete will be in active state
2022-04-04 07:14:45 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:teardown-delete to finished
2022-04-04 07:15:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:15:51 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testThrottlingQuotasCreateAlterPartitions
2022-04-04 07:15:51 [main] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-8e724d2d-kafka-clients in namespace throttling-quota-st
2022-04-04 07:15:51 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-8e724d2d-kafka-clients in namespace throttling-quota-st
2022-04-04 07:15:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-894281801-1597690488 in namespace throttling-quota-st
2022-04-04 07:15:51 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job alter-admin-my-cluster-8e724d2d-kafka-clients in namespace throttling-quota-st
2022-04-04 07:15:51 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job teardown-delete in namespace throttling-quota-st
2022-04-04 07:16:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 07:16:01 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testThrottlingQuotasCreateAlterPartitions-FINISHED
2022-04-04 07:16:01 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 07:16:01 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 07:16:01 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testKafkaAdminTopicOperations-STARTED
2022-04-04 07:16:01 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 07:16:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1575231263-240316008 in namespace throttling-quota-st
2022-04-04 07:16:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1575231263-240316008 will have desired state: Ready
2022-04-04 07:16:02 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1575231263-240316008 is in desired state: Ready
2022-04-04 07:16:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-b319232b-kafka-clients in namespace throttling-quota-st
2022-04-04 07:16:02 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-b319232b-kafka-clients will be in active state
2022-04-04 07:16:03 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-04 07:17:33 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-b319232b-kafka-clients-kkkvj log
2022-04-04 07:17:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Job list-admin-my-cluster-b319232b-kafka-clients in namespace throttling-quota-st
2022-04-04 07:17:38 [main] [32mINFO [m [JobUtils:81] Waiting for job: list-admin-my-cluster-b319232b-kafka-clients will be in active state
2022-04-04 07:17:39 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-04 07:17:41 [main] [32mINFO [m [PodUtils:189] Message quota-topic-test-simple-99 found in list-admin-my-cluster-b319232b-kafka-clients-nbstg log
2022-04-04 07:17:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-b319232b-kafka-clients in namespace throttling-quota-st
2022-04-04 07:17:46 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-b319232b-kafka-clients will be in active state
2022-04-04 07:17:47 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-04 07:19:17 [main] [32mINFO [m [PodUtils:189] Message Successfully removed all 100 found in delete-admin-my-cluster-b319232b-kafka-clients-r4thd log
2022-04-04 07:19:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Job list-admin-my-cluster-b319232b-kafka-clients in namespace throttling-quota-st
2022-04-04 07:19:27 [main] [32mINFO [m [JobUtils:81] Waiting for job: list-admin-my-cluster-b319232b-kafka-clients will be in active state
2022-04-04 07:19:28 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:list-admin-my-cluster-b319232b-kafka-clients to finished
2022-04-04 07:19:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:19:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaAdminTopicOperations
2022-04-04 07:19:31 [main] [32mINFO [m [ResourceManager:241] Delete of Job list-admin-my-cluster-b319232b-kafka-clients in namespace throttling-quota-st
2022-04-04 07:19:31 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-b319232b-kafka-clients in namespace throttling-quota-st
2022-04-04 07:19:31 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job list-admin-my-cluster-b319232b-kafka-clients in namespace throttling-quota-st
2022-04-04 07:19:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1575231263-240316008 in namespace throttling-quota-st
2022-04-04 07:19:31 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-b319232b-kafka-clients in namespace throttling-quota-st
2022-04-04 07:19:41 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 07:19:41 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testKafkaAdminTopicOperations-FINISHED
2022-04-04 07:19:41 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 07:19:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 07:19:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testThrottlingQuotasDeleteTopic-STARTED
2022-04-04 07:19:41 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 07:19:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-2033529116-321841710 in namespace throttling-quota-st
2022-04-04 07:19:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-2033529116-321841710 will have desired state: Ready
2022-04-04 07:19:42 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-2033529116-321841710 is in desired state: Ready
2022-04-04 07:19:42 [main] [32mINFO [m [ThrottlingQuotaST:112] Executing 1/5 iteration.
2022-04-04 07:19:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-98a3c54d-kafka-clients in namespace throttling-quota-st
2022-04-04 07:19:42 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-98a3c54d-kafka-clients will be in active state
2022-04-04 07:19:43 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:create-admin-my-cluster-98a3c54d-kafka-clients to finished
2022-04-04 07:21:14 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-04 07:21:14 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-98a3c54d-kafka-clients-xvrpc log
2022-04-04 07:21:19 [main] [32mINFO [m [ThrottlingQuotaST:112] Executing 2/5 iteration.
2022-04-04 07:21:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-98a3c54d-kafka-clients in namespace throttling-quota-st
2022-04-04 07:21:19 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-98a3c54d-kafka-clients will be in active state
2022-04-04 07:21:20 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:create-admin-my-cluster-98a3c54d-kafka-clients to finished
2022-04-04 07:22:54 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-04 07:22:54 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-98a3c54d-kafka-clients-tr8mz log
2022-04-04 07:22:59 [main] [32mINFO [m [ThrottlingQuotaST:112] Executing 3/5 iteration.
2022-04-04 07:22:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-98a3c54d-kafka-clients in namespace throttling-quota-st
2022-04-04 07:22:59 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-98a3c54d-kafka-clients will be in active state
2022-04-04 07:23:00 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:create-admin-my-cluster-98a3c54d-kafka-clients to finished
2022-04-04 07:24:35 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-04 07:24:35 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-98a3c54d-kafka-clients-hd8rv log
2022-04-04 07:24:40 [main] [32mINFO [m [ThrottlingQuotaST:112] Executing 4/5 iteration.
2022-04-04 07:24:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-98a3c54d-kafka-clients in namespace throttling-quota-st
2022-04-04 07:24:40 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-98a3c54d-kafka-clients will be in active state
2022-04-04 07:24:41 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:create-admin-my-cluster-98a3c54d-kafka-clients to finished
2022-04-04 07:26:14 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-04 07:26:14 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-98a3c54d-kafka-clients-6kr98 log
2022-04-04 07:26:19 [main] [32mINFO [m [ThrottlingQuotaST:112] Executing 5/5 iteration.
2022-04-04 07:26:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-98a3c54d-kafka-clients in namespace throttling-quota-st
2022-04-04 07:26:19 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-98a3c54d-kafka-clients will be in active state
2022-04-04 07:26:20 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:create-admin-my-cluster-98a3c54d-kafka-clients to finished
2022-04-04 07:27:55 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-04 07:27:55 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-98a3c54d-kafka-clients-wl8z4 log
2022-04-04 07:28:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-98a3c54d-kafka-clients in namespace throttling-quota-st
2022-04-04 07:28:00 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-98a3c54d-kafka-clients will be in active state
2022-04-04 07:28:01 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-04 07:32:02 [main] [32mINFO [m [PodUtils:189] Message org.apache.kafka.common.errors.ThrottlingQuotaExceededException: The throttling quota has been exceeded. found in delete-admin-my-cluster-98a3c54d-kafka-clients-v7nw7 log
2022-04-04 07:32:17 [main] [32mINFO [m [ThrottlingQuotaST:144] Executing 1/5 iteration for delete-admin-my-cluster-98a3c54d-kafka-clients.
2022-04-04 07:32:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-98a3c54d-kafka-clients in namespace throttling-quota-st
2022-04-04 07:32:17 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-98a3c54d-kafka-clients will be in active state
2022-04-04 07:32:18 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:delete-admin-my-cluster-98a3c54d-kafka-clients to finished
2022-04-04 07:33:26 [main] [32mINFO [m [ThrottlingQuotaST:144] Executing 2/5 iteration for delete-admin-my-cluster-98a3c54d-kafka-clients.
2022-04-04 07:33:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-98a3c54d-kafka-clients in namespace throttling-quota-st
2022-04-04 07:33:26 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-98a3c54d-kafka-clients will be in active state
2022-04-04 07:33:27 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:delete-admin-my-cluster-98a3c54d-kafka-clients to finished
2022-04-04 07:34:34 [main] [32mINFO [m [ThrottlingQuotaST:144] Executing 3/5 iteration for delete-admin-my-cluster-98a3c54d-kafka-clients.
2022-04-04 07:34:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-98a3c54d-kafka-clients in namespace throttling-quota-st
2022-04-04 07:34:34 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-98a3c54d-kafka-clients will be in active state
2022-04-04 07:34:35 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:delete-admin-my-cluster-98a3c54d-kafka-clients to finished
2022-04-04 07:35:42 [main] [32mINFO [m [ThrottlingQuotaST:144] Executing 4/5 iteration for delete-admin-my-cluster-98a3c54d-kafka-clients.
2022-04-04 07:35:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-98a3c54d-kafka-clients in namespace throttling-quota-st
2022-04-04 07:35:42 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-98a3c54d-kafka-clients will be in active state
2022-04-04 07:35:43 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:delete-admin-my-cluster-98a3c54d-kafka-clients to finished
2022-04-04 07:36:50 [main] [32mINFO [m [ThrottlingQuotaST:144] Executing 5/5 iteration for delete-admin-my-cluster-98a3c54d-kafka-clients.
2022-04-04 07:36:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-98a3c54d-kafka-clients in namespace throttling-quota-st
2022-04-04 07:36:50 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-98a3c54d-kafka-clients will be in active state
2022-04-04 07:36:51 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:delete-admin-my-cluster-98a3c54d-kafka-clients to finished
2022-04-04 07:37:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:37:59 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testThrottlingQuotasDeleteTopic
2022-04-04 07:37:59 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-98a3c54d-kafka-clients in namespace throttling-quota-st
2022-04-04 07:37:59 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-98a3c54d-kafka-clients in namespace throttling-quota-st
2022-04-04 07:37:59 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-98a3c54d-kafka-clients in namespace throttling-quota-st
2022-04-04 07:37:59 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-98a3c54d-kafka-clients in namespace throttling-quota-st
2022-04-04 07:37:59 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-98a3c54d-kafka-clients in namespace throttling-quota-st
2022-04-04 07:37:59 [main] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-98a3c54d-kafka-clients in namespace throttling-quota-st
2022-04-04 07:37:59 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-98a3c54d-kafka-clients in namespace throttling-quota-st
2022-04-04 07:37:59 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-98a3c54d-kafka-clients in namespace throttling-quota-st
2022-04-04 07:37:59 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-98a3c54d-kafka-clients in namespace throttling-quota-st
2022-04-04 07:37:59 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-98a3c54d-kafka-clients in namespace throttling-quota-st
2022-04-04 07:37:59 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-2033529116-321841710 in namespace throttling-quota-st
2022-04-04 07:37:59 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-98a3c54d-kafka-clients in namespace throttling-quota-st
2022-04-04 07:38:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 07:38:09 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testThrottlingQuotasDeleteTopic-FINISHED
2022-04-04 07:38:09 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 07:38:09 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 07:38:09 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testThrottlingQuotasCreateTopic-STARTED
2022-04-04 07:38:09 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 07:38:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-284434301-384338225 in namespace throttling-quota-st
2022-04-04 07:38:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-284434301-384338225 will have desired state: Ready
2022-04-04 07:38:10 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-284434301-384338225 is in desired state: Ready
2022-04-04 07:38:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-ce121634-kafka-clients in namespace throttling-quota-st
2022-04-04 07:38:10 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-ce121634-kafka-clients will be in active state
2022-04-04 07:38:11 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-04 07:42:12 [main] [32mINFO [m [PodUtils:189] Message org.apache.kafka.common.errors.ThrottlingQuotaExceededException: The throttling quota has been exceeded. found in create-admin-my-cluster-ce121634-kafka-clients-sskbn log
2022-04-04 07:42:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:42:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testThrottlingQuotasCreateTopic
2022-04-04 07:42:45 [main] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-ce121634-kafka-clients in namespace throttling-quota-st
2022-04-04 07:42:45 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-284434301-384338225 in namespace throttling-quota-st
2022-04-04 07:42:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 07:42:55 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testThrottlingQuotasCreateTopic-FINISHED
2022-04-04 07:42:55 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 07:42:55 [main] [32mINFO [m [ThrottlingQuotaST:353] Tearing down resources after all test
2022-04-04 07:43:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:43:15 [main] [32mINFO [m [ResourceManager:348] Delete all resources for ThrottlingQuotaST
2022-04-04 07:43:15 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka quota-cluster in namespace throttling-quota-st
2022-04-04 07:43:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2,414.804 s - in io.strimzi.systemtest.operators.topic.ThrottlingQuotaST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.topic.TopicST
2022-04-04 07:44:08 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: topic-st
2022-04-04 07:44:08 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: topic-st
2022-04-04 07:44:08 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: topic-st
2022-04-04 07:44:08 [main] [32mINFO [m [TopicST:491] Deploying shared Kafka across all test cases in topic-st namespace
2022-04-04 07:44:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka topic-cluster-name in namespace topic-st
2022-04-04 07:44:08 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: topic-cluster-name will have desired state: Ready
2022-04-04 07:45:24 [main] [32mINFO [m [ResourceManager:444] Kafka: topic-cluster-name is in desired state: Ready
2022-04-04 07:45:24 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 07:45:24 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testCreateTopicViaAdminClient-STARTED
2022-04-04 07:45:24 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 07:45:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-17078d4c in namespace topic-st
2022-04-04 07:45:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-17078d4c will have desired state: Ready
2022-04-04 07:46:49 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-17078d4c is in desired state: Ready
2022-04-04 07:46:49 [main] [32mINFO [m [AdminClientConfig:376] AdminClientConfig values: 
	bootstrap.servers = [192.168.49.2:32489]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-04-04 07:46:49 [main] [32mINFO [m [AppInfoParser:119] Kafka version: 3.1.0
2022-04-04 07:46:49 [main] [32mINFO [m [AppInfoParser:120] Kafka commitId: 37edeed0777bacb3
2022-04-04 07:46:49 [main] [32mINFO [m [AppInfoParser:121] Kafka startTimeMs: 1649058409097
2022-04-04 07:46:49 [main] [32mINFO [m [TopicST:166] Creating async topic my-topic-353343093-313323920 via Admin client
2022-04-04 07:46:49 [main] [32mINFO [m [TopicST:172] Verify that in Kafka cluster contains 3 topics
2022-04-04 07:46:49 [main] [32mINFO [m [KafkaTopicUtils:78] Waiting for KafkaTopic my-topic-353343093-313323920 creation 
2022-04-04 07:46:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-353343093-313323920 will have desired state: Ready
2022-04-04 07:46:50 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-353343093-313323920 is in desired state: Ready
2022-04-04 07:46:50 [kafka-admin-client-thread | adminclient-1] [32mINFO [m [AppInfoParser:83] App info kafka.admin.client for adminclient-1 unregistered
2022-04-04 07:46:50 [kafka-admin-client-thread | adminclient-1] [32mINFO [m [Metrics:659] Metrics scheduler closed
2022-04-04 07:46:50 [kafka-admin-client-thread | adminclient-1] [32mINFO [m [Metrics:663] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-04-04 07:46:50 [kafka-admin-client-thread | adminclient-1] [32mINFO [m [Metrics:669] Metrics reporters closed
2022-04-04 07:46:50 [main] [32mINFO [m [TopicST:182] Verify that corresponding 1 KafkaTopic custom resources were created and topic is in Ready state
2022-04-04 07:46:50 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:46:50 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCreateTopicViaAdminClient
2022-04-04 07:46:50 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-17078d4c in namespace topic-st
2022-04-04 07:47:00 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 07:47:00 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testCreateTopicViaAdminClient-FINISHED
2022-04-04 07:47:00 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 07:47:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 07:47:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testCreateDeleteCreate-STARTED
2022-04-04 07:47:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 07:47:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-9af80bf0 in namespace topic-st
2022-04-04 07:47:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-9af80bf0 will have desired state: Ready
2022-04-04 07:48:22 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-9af80bf0 is in desired state: Ready
2022-04-04 07:48:22 [main] [32mINFO [m [AdminClientConfig:376] AdminClientConfig values: 
	bootstrap.servers = [192.168.49.2:30577]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-04-04 07:48:22 [main] [32mINFO [m [AppInfoParser:119] Kafka version: 3.1.0
2022-04-04 07:48:22 [main] [32mINFO [m [AppInfoParser:120] Kafka commitId: 37edeed0777bacb3
2022-04-04 07:48:22 [main] [32mINFO [m [AppInfoParser:121] Kafka startTimeMs: 1649058502799
2022-04-04 07:48:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1516886274-1475890816 in namespace topic-st
2022-04-04 07:48:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1516886274-1475890816 will have desired state: Ready
2022-04-04 07:48:23 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1516886274-1475890816 is in desired state: Ready
2022-04-04 07:48:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1516886274-1475890816 will have desired state: Ready
2022-04-04 07:48:23 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1516886274-1475890816 is in desired state: Ready
2022-04-04 07:48:25 [main] [32mINFO [m [TopicST:238] Iteration 0: Deleting my-topic-1516886274-1475890816
2022-04-04 07:48:25 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-1516886274-1475890816 deletion
2022-04-04 07:48:28 [main] [32mINFO [m [TopicST:250] Iteration 0: Recreating my-topic-1516886274-1475890816
2022-04-04 07:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1516886274-1475890816 in namespace topic-st
2022-04-04 07:48:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1516886274-1475890816 will have desired state: Ready
2022-04-04 07:48:29 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1516886274-1475890816 is in desired state: Ready
2022-04-04 07:48:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1516886274-1475890816 will have desired state: Ready
2022-04-04 07:48:29 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1516886274-1475890816 is in desired state: Ready
2022-04-04 07:48:31 [main] [32mINFO [m [TopicST:238] Iteration 1: Deleting my-topic-1516886274-1475890816
2022-04-04 07:48:32 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-1516886274-1475890816 deletion
2022-04-04 07:48:35 [main] [32mINFO [m [TopicST:250] Iteration 1: Recreating my-topic-1516886274-1475890816
2022-04-04 07:48:35 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1516886274-1475890816 in namespace topic-st
2022-04-04 07:48:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1516886274-1475890816 will have desired state: Ready
2022-04-04 07:48:36 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1516886274-1475890816 is in desired state: Ready
2022-04-04 07:48:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1516886274-1475890816 will have desired state: Ready
2022-04-04 07:48:36 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1516886274-1475890816 is in desired state: Ready
2022-04-04 07:48:38 [main] [32mINFO [m [TopicST:238] Iteration 2: Deleting my-topic-1516886274-1475890816
2022-04-04 07:48:38 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-1516886274-1475890816 deletion
2022-04-04 07:48:41 [main] [32mINFO [m [TopicST:250] Iteration 2: Recreating my-topic-1516886274-1475890816
2022-04-04 07:48:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1516886274-1475890816 in namespace topic-st
2022-04-04 07:48:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1516886274-1475890816 will have desired state: Ready
2022-04-04 07:48:42 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1516886274-1475890816 is in desired state: Ready
2022-04-04 07:48:42 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1516886274-1475890816 will have desired state: Ready
2022-04-04 07:48:42 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1516886274-1475890816 is in desired state: Ready
2022-04-04 07:48:44 [main] [32mINFO [m [TopicST:238] Iteration 3: Deleting my-topic-1516886274-1475890816
2022-04-04 07:48:44 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-1516886274-1475890816 deletion
2022-04-04 07:48:47 [main] [32mINFO [m [TopicST:250] Iteration 3: Recreating my-topic-1516886274-1475890816
2022-04-04 07:48:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1516886274-1475890816 in namespace topic-st
2022-04-04 07:48:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1516886274-1475890816 will have desired state: Ready
2022-04-04 07:48:48 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1516886274-1475890816 is in desired state: Ready
2022-04-04 07:48:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1516886274-1475890816 will have desired state: Ready
2022-04-04 07:48:48 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1516886274-1475890816 is in desired state: Ready
2022-04-04 07:48:50 [main] [32mINFO [m [TopicST:238] Iteration 4: Deleting my-topic-1516886274-1475890816
2022-04-04 07:48:50 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-1516886274-1475890816 deletion
2022-04-04 07:48:53 [main] [32mINFO [m [TopicST:250] Iteration 4: Recreating my-topic-1516886274-1475890816
2022-04-04 07:48:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1516886274-1475890816 in namespace topic-st
2022-04-04 07:48:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1516886274-1475890816 will have desired state: Ready
2022-04-04 07:48:54 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1516886274-1475890816 is in desired state: Ready
2022-04-04 07:48:54 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1516886274-1475890816 will have desired state: Ready
2022-04-04 07:48:54 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1516886274-1475890816 is in desired state: Ready
2022-04-04 07:48:56 [main] [32mINFO [m [TopicST:238] Iteration 5: Deleting my-topic-1516886274-1475890816
2022-04-04 07:48:56 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-1516886274-1475890816 deletion
2022-04-04 07:48:59 [main] [32mINFO [m [TopicST:250] Iteration 5: Recreating my-topic-1516886274-1475890816
2022-04-04 07:48:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1516886274-1475890816 in namespace topic-st
2022-04-04 07:48:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1516886274-1475890816 will have desired state: Ready
2022-04-04 07:49:00 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1516886274-1475890816 is in desired state: Ready
2022-04-04 07:49:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1516886274-1475890816 will have desired state: Ready
2022-04-04 07:49:00 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1516886274-1475890816 is in desired state: Ready
2022-04-04 07:49:02 [main] [32mINFO [m [TopicST:238] Iteration 6: Deleting my-topic-1516886274-1475890816
2022-04-04 07:49:02 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-1516886274-1475890816 deletion
2022-04-04 07:49:05 [main] [32mINFO [m [TopicST:250] Iteration 6: Recreating my-topic-1516886274-1475890816
2022-04-04 07:49:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1516886274-1475890816 in namespace topic-st
2022-04-04 07:49:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1516886274-1475890816 will have desired state: Ready
2022-04-04 07:49:06 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1516886274-1475890816 is in desired state: Ready
2022-04-04 07:49:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1516886274-1475890816 will have desired state: Ready
2022-04-04 07:49:06 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1516886274-1475890816 is in desired state: Ready
2022-04-04 07:49:08 [main] [32mINFO [m [TopicST:238] Iteration 7: Deleting my-topic-1516886274-1475890816
2022-04-04 07:49:08 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-1516886274-1475890816 deletion
2022-04-04 07:49:11 [main] [32mINFO [m [TopicST:250] Iteration 7: Recreating my-topic-1516886274-1475890816
2022-04-04 07:49:11 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1516886274-1475890816 in namespace topic-st
2022-04-04 07:49:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1516886274-1475890816 will have desired state: Ready
2022-04-04 07:49:12 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1516886274-1475890816 is in desired state: Ready
2022-04-04 07:49:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1516886274-1475890816 will have desired state: Ready
2022-04-04 07:49:12 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1516886274-1475890816 is in desired state: Ready
2022-04-04 07:49:14 [main] [32mINFO [m [TopicST:238] Iteration 8: Deleting my-topic-1516886274-1475890816
2022-04-04 07:49:14 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-1516886274-1475890816 deletion
2022-04-04 07:49:17 [main] [32mINFO [m [TopicST:250] Iteration 8: Recreating my-topic-1516886274-1475890816
2022-04-04 07:49:17 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1516886274-1475890816 in namespace topic-st
2022-04-04 07:49:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1516886274-1475890816 will have desired state: Ready
2022-04-04 07:49:18 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1516886274-1475890816 is in desired state: Ready
2022-04-04 07:49:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1516886274-1475890816 will have desired state: Ready
2022-04-04 07:49:18 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1516886274-1475890816 is in desired state: Ready
2022-04-04 07:49:20 [main] [32mINFO [m [TopicST:238] Iteration 9: Deleting my-topic-1516886274-1475890816
2022-04-04 07:49:20 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-1516886274-1475890816 deletion
2022-04-04 07:49:23 [main] [32mINFO [m [TopicST:250] Iteration 9: Recreating my-topic-1516886274-1475890816
2022-04-04 07:49:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1516886274-1475890816 in namespace topic-st
2022-04-04 07:49:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1516886274-1475890816 will have desired state: Ready
2022-04-04 07:49:24 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1516886274-1475890816 is in desired state: Ready
2022-04-04 07:49:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1516886274-1475890816 will have desired state: Ready
2022-04-04 07:49:24 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1516886274-1475890816 is in desired state: Ready
2022-04-04 07:49:24 [kafka-admin-client-thread | adminclient-2] [32mINFO [m [AppInfoParser:83] App info kafka.admin.client for adminclient-2 unregistered
2022-04-04 07:49:24 [kafka-admin-client-thread | adminclient-2] [32mINFO [m [Metrics:659] Metrics scheduler closed
2022-04-04 07:49:24 [kafka-admin-client-thread | adminclient-2] [32mINFO [m [Metrics:663] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-04-04 07:49:24 [kafka-admin-client-thread | adminclient-2] [32mINFO [m [Metrics:669] Metrics reporters closed
2022-04-04 07:49:24 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:49:24 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCreateDeleteCreate
2022-04-04 07:49:24 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1516886274-1475890816 in namespace topic-st
2022-04-04 07:49:24 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1516886274-1475890816 in namespace topic-st
2022-04-04 07:49:24 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1516886274-1475890816 in namespace topic-st
2022-04-04 07:49:24 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1516886274-1475890816 in namespace topic-st
2022-04-04 07:49:24 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1516886274-1475890816 in namespace topic-st
2022-04-04 07:49:24 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1516886274-1475890816 in namespace topic-st
2022-04-04 07:49:24 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-9af80bf0 in namespace topic-st
2022-04-04 07:49:24 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1516886274-1475890816 in namespace topic-st
2022-04-04 07:49:34 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1516886274-1475890816 in namespace topic-st
2022-04-04 07:49:34 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1516886274-1475890816 in namespace topic-st
2022-04-04 07:49:34 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1516886274-1475890816 in namespace topic-st
2022-04-04 07:49:34 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1516886274-1475890816 in namespace topic-st
2022-04-04 07:49:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 07:49:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testCreateDeleteCreate-FINISHED
2022-04-04 07:49:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 07:49:34 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 07:49:34 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testTopicModificationOfReplicationFactor-STARTED
2022-04-04 07:49:34 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 07:49:34 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-450889097-1331096595 in namespace topic-st
2022-04-04 07:49:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-450889097-1331096595 will have desired state: Ready
2022-04-04 07:49:35 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-450889097-1331096595 is in desired state: Ready
2022-04-04 07:49:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-450889097-1331096595 will have desired state: NotReady
2022-04-04 07:49:36 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-450889097-1331096595 is in desired state: NotReady
2022-04-04 07:49:37 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-450889097-1331096595 deletion
2022-04-04 07:49:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:49:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTopicModificationOfReplicationFactor
2022-04-04 07:49:37 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-450889097-1331096595 in namespace topic-st
2022-04-04 07:49:37 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 07:49:37 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testTopicModificationOfReplicationFactor-FINISHED
2022-04-04 07:49:37 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 07:49:37 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 07:49:37 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testDeleteTopicEnableFalse-STARTED
2022-04-04 07:49:37 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 07:49:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c37ac2ec-isolated in namespace topic-st
2022-04-04 07:49:37 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c37ac2ec-isolated will have desired state: Ready
2022-04-04 07:50:47 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c37ac2ec-isolated is in desired state: Ready
2022-04-04 07:50:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-c37ac2ec-isolated-kafka-clients in namespace topic-st
2022-04-04 07:50:47 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c37ac2ec-isolated-kafka-clients will be ready
2022-04-04 07:50:49 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c37ac2ec-isolated-kafka-clients is ready
2022-04-04 07:50:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1357584804-1429337312 in namespace topic-st
2022-04-04 07:50:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1357584804-1429337312 will have desired state: Ready
2022-04-04 07:50:50 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1357584804-1429337312 is in desired state: Ready
2022-04-04 07:50:50 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 07:50:50 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@36b1b27c, messages=[], arguments=[--topic, my-topic-1357584804-1429337312, --max-messages, 100, --bootstrap-server, my-cluster-c37ac2ec-isolated-kafka-bootstrap.topic-st.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-c37ac2ec-isolated-kafka-clients-77589856c4-64gcd', podNamespace='topic-st', bootstrapServer='my-cluster-c37ac2ec-isolated-kafka-bootstrap.topic-st.svc:9092', topicName='my-topic-1357584804-1429337312', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@33765af2}
2022-04-04 07:50:50 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-c37ac2ec-isolated-kafka-bootstrap.topic-st.svc:9092:my-topic-1357584804-1429337312 from pod my-cluster-c37ac2ec-isolated-kafka-clients-77589856c4-64gcd
2022-04-04 07:50:50 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c37ac2ec-isolated-kafka-clients-77589856c4-64gcd -n topic-st -- /opt/kafka/producer.sh --topic my-topic-1357584804-1429337312 --max-messages 100 --bootstrap-server my-cluster-c37ac2ec-isolated-kafka-bootstrap.topic-st.svc:9092
2022-04-04 07:50:52 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 07:50:52 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 07:50:52 [main] [32mINFO [m [TopicST:395] Deleting KafkaTopic: my-topic-1357584804-1429337312
2022-04-04 07:50:52 [main] [32mINFO [m [TopicST:397] KafkaTopic my-topic-1357584804-1429337312 deleted
2022-04-04 07:52:32 [main] [32mINFO [m [TopicST:401] Wait KafkaTopic my-topic-1357584804-1429337312 recreation
2022-04-04 07:52:32 [main] [32mINFO [m [KafkaTopicUtils:78] Waiting for KafkaTopic my-topic-1357584804-1429337312 creation 
2022-04-04 07:52:32 [main] [32mINFO [m [TopicST:403] KafkaTopic my-topic-1357584804-1429337312 recreated
2022-04-04 07:52:32 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1d562f2b, messages=[], arguments=[--topic, my-topic-1357584804-1429337312, --max-messages, 100, --group-instance-id, instance362498574, --group-id, my-consumer-group-1806507876, --bootstrap-server, my-cluster-c37ac2ec-isolated-kafka-bootstrap.topic-st.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-c37ac2ec-isolated-kafka-clients-77589856c4-64gcd', podNamespace='topic-st', bootstrapServer='my-cluster-c37ac2ec-isolated-kafka-bootstrap.topic-st.svc:9092', topicName='my-topic-1357584804-1429337312', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1806507876', consumerInstanceId='instance362498574', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@26cf5bdc}
2022-04-04 07:52:32 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-c37ac2ec-isolated-kafka-bootstrap.topic-st.svc:9092#my-topic-1357584804-1429337312 from pod my-cluster-c37ac2ec-isolated-kafka-clients-77589856c4-64gcd
2022-04-04 07:52:32 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c37ac2ec-isolated-kafka-clients-77589856c4-64gcd -n topic-st -- /opt/kafka/consumer.sh --topic my-topic-1357584804-1429337312 --max-messages 100 --group-instance-id instance362498574 --group-id my-consumer-group-1806507876 --bootstrap-server my-cluster-c37ac2ec-isolated-kafka-bootstrap.topic-st.svc:9092
2022-04-04 07:52:38 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 07:52:38 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 07:52:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:52:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeleteTopicEnableFalse
2022-04-04 07:52:38 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-c37ac2ec-isolated-kafka-clients in namespace topic-st
2022-04-04 07:52:38 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c37ac2ec-isolated in namespace topic-st
2022-04-04 07:52:38 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1357584804-1429337312 in namespace topic-st
2022-04-04 07:53:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 07:53:18 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testDeleteTopicEnableFalse-FINISHED
2022-04-04 07:53:18 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 07:53:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 07:53:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testSendingMessagesToNonExistingTopic-STARTED
2022-04-04 07:53:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 07:53:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment topic-cluster-name-kafka-clients in namespace topic-st
2022-04-04 07:53:18 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: topic-cluster-name-kafka-clients will be ready
2022-04-04 07:53:20 [main] [32mINFO [m [DeploymentUtils:168] Deployment: topic-cluster-name-kafka-clients is ready
2022-04-04 07:53:20 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 07:53:20 [main] [32mINFO [m [TopicST:320] Checking if my-topic-1281447881-1606247594 is on topic list
2022-04-04 07:53:20 [main] [32mINFO [m [TopicST:456] Checking topic my-topic-1281447881-1606247594 in Kafka
2022-04-04 07:53:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-04 07:53:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:53:22 [main] [32mINFO [m [TopicST:323] Topic with name my-topic-1281447881-1606247594 is not created yet
2022-04-04 07:53:22 [main] [32mINFO [m [TopicST:325] Trying to send messages to non-existing topic my-topic-1281447881-1606247594
2022-04-04 07:53:22 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@7354a1d8, messages=[], arguments=[--topic, my-topic-1281447881-1606247594, --max-messages, 100, --bootstrap-server, topic-cluster-name-kafka-bootstrap.topic-st.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='topic-cluster-name-kafka-clients-7dd7cb68d4-wjcbf', podNamespace='topic-st', bootstrapServer='topic-cluster-name-kafka-bootstrap.topic-st.svc:9092', topicName='my-topic-1281447881-1606247594', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5bf51627}
2022-04-04 07:53:22 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to topic-cluster-name-kafka-bootstrap.topic-st.svc:9092:my-topic-1281447881-1606247594 from pod topic-cluster-name-kafka-clients-7dd7cb68d4-wjcbf
2022-04-04 07:53:22 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec topic-cluster-name-kafka-clients-7dd7cb68d4-wjcbf -n topic-st -- /opt/kafka/producer.sh --topic my-topic-1281447881-1606247594 --max-messages 100 --bootstrap-server topic-cluster-name-kafka-bootstrap.topic-st.svc:9092
2022-04-04 07:53:24 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 07:53:24 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 07:53:24 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3ccc2fe, messages=[], arguments=[--topic, my-topic-1281447881-1606247594, --max-messages, 100, --group-instance-id, instance792227680, --group-id, my-consumer-group-1625536042, --bootstrap-server, topic-cluster-name-kafka-bootstrap.topic-st.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='topic-cluster-name-kafka-clients-7dd7cb68d4-wjcbf', podNamespace='topic-st', bootstrapServer='topic-cluster-name-kafka-bootstrap.topic-st.svc:9092', topicName='my-topic-1281447881-1606247594', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1625536042', consumerInstanceId='instance792227680', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4683a7a3}
2022-04-04 07:53:24 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from topic-cluster-name-kafka-bootstrap.topic-st.svc:9092#my-topic-1281447881-1606247594 from pod topic-cluster-name-kafka-clients-7dd7cb68d4-wjcbf
2022-04-04 07:53:24 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec topic-cluster-name-kafka-clients-7dd7cb68d4-wjcbf -n topic-st -- /opt/kafka/consumer.sh --topic my-topic-1281447881-1606247594 --max-messages 100 --group-instance-id instance792227680 --group-id my-consumer-group-1625536042 --bootstrap-server topic-cluster-name-kafka-bootstrap.topic-st.svc:9092
2022-04-04 07:53:30 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 07:53:30 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 07:53:30 [main] [32mINFO [m [TopicST:341] Checking if my-topic-1281447881-1606247594 is on topic list
2022-04-04 07:53:30 [main] [32mINFO [m [TopicST:456] Checking topic my-topic-1281447881-1606247594 in Kafka
2022-04-04 07:53:32 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-04 07:53:32 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:53:32 [main] [32mINFO [m [KafkaTopicUtils:78] Waiting for KafkaTopic my-topic-1281447881-1606247594 creation 
2022-04-04 07:53:32 [main] [32mINFO [m [TopicST:353] Topic successfully created
2022-04-04 07:53:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:53:32 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendingMessagesToNonExistingTopic
2022-04-04 07:53:32 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment topic-cluster-name-kafka-clients in namespace topic-st
2022-04-04 07:54:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 07:54:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testSendingMessagesToNonExistingTopic-FINISHED
2022-04-04 07:54:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 07:54:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 07:54:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testMoreReplicasThanAvailableBrokers-STARTED
2022-04-04 07:54:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 07:54:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1973605016-1282861593 in namespace topic-st
2022-04-04 07:54:22 [main] [32mINFO [m [TopicST:461] Checking in KafkaTopic CR that topic my-topic-1973605016-1282861593 exists
2022-04-04 07:54:22 [main] [32mINFO [m [TopicST:456] Checking topic my-topic-1973605016-1282861593 in Kafka
2022-04-04 07:54:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-04 07:54:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:54:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1973605016-1282861593 will have desired state: NotReady
2022-04-04 07:54:25 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1973605016-1282861593 is in desired state: NotReady
2022-04-04 07:54:25 [main] [32mINFO [m [TopicST:90] Delete topic my-topic-1973605016-1282861593
2022-04-04 07:54:25 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-1973605016-1282861593 deletion
2022-04-04 07:54:25 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic topic-example-new in namespace topic-st
2022-04-04 07:54:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: topic-example-new will have desired state: Ready
2022-04-04 07:54:26 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: topic-example-new is in desired state: Ready
2022-04-04 07:54:26 [main] [32mINFO [m [TopicST:456] Checking topic topic-example-new in Kafka
2022-04-04 07:54:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-04 07:54:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:54:28 [main] [32mINFO [m [TopicST:461] Checking in KafkaTopic CR that topic topic-example-new exists
2022-04-04 07:54:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:54:28 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMoreReplicasThanAvailableBrokers
2022-04-04 07:54:28 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic topic-example-new in namespace topic-st
2022-04-04 07:54:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1973605016-1282861593 in namespace topic-st
2022-04-04 07:54:38 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 07:54:38 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testMoreReplicasThanAvailableBrokers-FINISHED
2022-04-04 07:54:38 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 07:54:38 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 07:54:38 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testCreateTopicViaKafka-STARTED
2022-04-04 07:54:38 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 07:54:40 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --create  --topic my-topic-326003318-1147363045 --replication-factor 3 --partitions 3
2022-04-04 07:54:40 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:54:40 [main] [32mINFO [m [KafkaTopicUtils:78] Waiting for KafkaTopic my-topic-326003318-1147363045 creation 
2022-04-04 07:54:41 [main] [32mINFO [m [TopicST:482] Checking in KafkaTopic CR that topic my-topic-326003318-1147363045 was created with expected settings
2022-04-04 07:54:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-04 07:54:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:54:44 [main] [32mINFO [m [TopicST:121] Editing topic via Kafka, settings to partitions 5
2022-04-04 07:54:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic my-topic-326003318-1147363045 --partitions 5
2022-04-04 07:54:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:54:46 [main] [32mINFO [m [KafkaTopicUtils:124] Waiting for KafkaTopic change my-topic-326003318-1147363045
2022-04-04 07:54:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic my-topic-326003318-1147363045
2022-04-04 07:54:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:54:49 [main] [32mINFO [m [TopicST:470] Checking topic my-topic-326003318-1147363045 in Kafka topic-cluster-name
2022-04-04 07:54:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:54:49 [main] [32mINFO [m [ResourceManager:346] In context testCreateTopicViaKafka is everything deleted.
2022-04-04 07:54:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 07:54:49 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testCreateTopicViaKafka-FINISHED
2022-04-04 07:54:49 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 07:54:49 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 07:54:49 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testCreateTopicAfterUnsupportedOperation-STARTED
2022-04-04 07:54:49 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 07:54:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic topic-with-replication-to-change in namespace topic-st
2022-04-04 07:54:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: topic-with-replication-to-change will have desired state: Ready
2022-04-04 07:54:50 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: topic-with-replication-to-change is in desired state: Ready
2022-04-04 07:54:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: topic-with-replication-to-change will have desired state: NotReady
2022-04-04 07:54:51 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: topic-with-replication-to-change is in desired state: NotReady
2022-04-04 07:54:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic another-topic in namespace topic-st
2022-04-04 07:54:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: another-topic will have desired state: Ready
2022-04-04 07:54:52 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: another-topic is in desired state: Ready
2022-04-04 07:54:52 [main] [32mINFO [m [TopicST:456] Checking topic topic-with-replication-to-change in Kafka
2022-04-04 07:54:54 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-04 07:54:54 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:54:54 [main] [32mINFO [m [TopicST:461] Checking in KafkaTopic CR that topic topic-with-replication-to-change exists
2022-04-04 07:54:54 [main] [32mINFO [m [TopicST:456] Checking topic another-topic in Kafka
2022-04-04 07:54:56 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-04 07:54:56 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:54:56 [main] [32mINFO [m [TopicST:461] Checking in KafkaTopic CR that topic another-topic exists
2022-04-04 07:54:56 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic topic-with-replication-to-change deletion
2022-04-04 07:54:57 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic another-topic deletion
2022-04-04 07:54:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:54:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCreateTopicAfterUnsupportedOperation
2022-04-04 07:54:57 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic another-topic in namespace topic-st
2022-04-04 07:54:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic topic-with-replication-to-change in namespace topic-st
2022-04-04 07:54:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 07:54:57 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testCreateTopicAfterUnsupportedOperation-FINISHED
2022-04-04 07:54:57 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 07:54:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:54:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for TopicST
2022-04-04 07:54:57 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka topic-cluster-name in namespace topic-st
2022-04-04 07:55:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 686.507 s - in io.strimzi.systemtest.operators.topic.TopicST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.ReconciliationST
2022-04-04 07:55:34 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: reconciliation-st
2022-04-04 07:55:35 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: reconciliation-st
2022-04-04 07:55:35 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: reconciliation-st
2022-04-04 07:55:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 07:55:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.ReconciliationST.testPauseReconciliationInKafkaAndKafkaConnectWithConnector-STARTED
2022-04-04 07:55:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 07:55:35 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-2 for test case:testPauseReconciliationInKafkaAndKafkaConnectWithConnector
2022-04-04 07:55:35 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-2
2022-04-04 07:55:35 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-2
2022-04-04 07:55:35 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-2
2022-04-04 07:55:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-58074930 in namespace namespace-2
2022-04-04 07:55:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-04-04 07:55:35 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-58074930 will have desired state: Ready
2022-04-04 07:57:37 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-58074930 is in desired state: Ready
2022-04-04 07:57:37 [main] [32mINFO [m [ReconciliationST:80] Adding pause annotation into Kafka resource and also scaling replicas to 4, new pod should not appear
2022-04-04 07:57:37 [main] [32mINFO [m [ReconciliationST:86] Kafka should contain status with ReconciliationPaused
2022-04-04 07:57:37 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-58074930 will have desired state: ReconciliationPaused
2022-04-04 07:57:39 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-58074930 is in desired state: ReconciliationPaused
2022-04-04 07:57:39 [main] [32mINFO [m [PodUtils:209] Wait until Pod my-cluster-58074930-kafka will have stable 3 replicas
2022-04-04 07:57:39 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 19 polls
2022-04-04 07:57:40 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 18 polls
2022-04-04 07:57:41 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 17 polls
2022-04-04 07:57:42 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 16 polls
2022-04-04 07:57:43 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 15 polls
2022-04-04 07:57:44 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 14 polls
2022-04-04 07:57:45 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 13 polls
2022-04-04 07:57:46 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 12 polls
2022-04-04 07:57:47 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 11 polls
2022-04-04 07:57:48 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 10 polls
2022-04-04 07:57:49 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 9 polls
2022-04-04 07:57:50 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 8 polls
2022-04-04 07:57:51 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 7 polls
2022-04-04 07:57:52 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 6 polls
2022-04-04 07:57:53 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 5 polls
2022-04-04 07:57:54 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 4 polls
2022-04-04 07:57:55 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 3 polls
2022-04-04 07:57:56 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 2 polls
2022-04-04 07:57:57 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 1 polls
2022-04-04 07:57:58 [main] [32mINFO [m [PodUtils:217] Pod replicas are stable for 20 polls intervals
2022-04-04 07:57:58 [main] [32mINFO [m [PodUtils:228] Pod my-cluster-58074930-kafka has 3 replicas
2022-04-04 07:57:58 [main] [32mINFO [m [ReconciliationST:90] Setting annotation to "false", Kafka should be scaled to 4
2022-04-04 07:57:58 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 4 Pod(s) of my-cluster-58074930-kafka to be ready
2022-04-04 08:00:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-58074930 will have desired state: Ready
2022-04-04 08:00:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-58074930 is in desired state: Ready
2022-04-04 08:00:21 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-58074930 is ready
2022-04-04 08:00:21 [main] [32mINFO [m [ReconciliationST:94] Deploying KafkaConnect with pause annotation from the start, no pods should appear
2022-04-04 08:00:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-58074930-kafka-clients in namespace namespace-2
2022-04-04 08:00:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-04-04 08:00:21 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-58074930-kafka-clients will be ready
2022-04-04 08:00:22 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-58074930-kafka-clients is ready
2022-04-04 08:00:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-58074930-scraper in namespace namespace-2
2022-04-04 08:00:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-04-04 08:00:22 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-58074930-scraper will be ready
2022-04-04 08:00:29 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-58074930-scraper is ready
2022-04-04 08:00:29 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-58074930-scraper to be ready
2022-04-04 08:00:39 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-58074930-scraper is ready
2022-04-04 08:00:39 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-58074930-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 08:00:39 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-58074930-allow in namespace namespace-2
2022-04-04 08:00:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-04-04 08:00:39 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 08:00:39 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-58074930 in namespace namespace-2
2022-04-04 08:00:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-04-04 08:00:39 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkaconnects' with unstable version 'v1beta2'
2022-04-04 08:00:39 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-58074930 will have desired state: ReconciliationPaused
2022-04-04 08:00:40 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-58074930 is in desired state: ReconciliationPaused
2022-04-04 08:00:40 [main] [32mINFO [m [PodUtils:209] Wait until Pod my-cluster-58074930-connect will have stable 0 replicas
2022-04-04 08:00:40 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 19 polls
2022-04-04 08:00:41 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 18 polls
2022-04-04 08:00:42 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 17 polls
2022-04-04 08:00:43 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 16 polls
2022-04-04 08:00:44 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 15 polls
2022-04-04 08:00:45 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 14 polls
2022-04-04 08:00:46 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 13 polls
2022-04-04 08:00:47 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 12 polls
2022-04-04 08:00:48 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 11 polls
2022-04-04 08:00:49 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 10 polls
2022-04-04 08:00:50 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 9 polls
2022-04-04 08:00:51 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 8 polls
2022-04-04 08:00:52 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 7 polls
2022-04-04 08:00:53 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 6 polls
2022-04-04 08:00:54 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 5 polls
2022-04-04 08:00:55 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 4 polls
2022-04-04 08:00:56 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 3 polls
2022-04-04 08:00:57 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 2 polls
2022-04-04 08:00:58 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 1 polls
2022-04-04 08:00:59 [main] [32mINFO [m [PodUtils:217] Pod replicas are stable for 20 polls intervals
2022-04-04 08:00:59 [main] [32mINFO [m [PodUtils:228] Pod my-cluster-58074930-connect has 0 replicas
2022-04-04 08:00:59 [main] [32mINFO [m [ReconciliationST:108] Setting annotation to "false" and creating KafkaConnector
2022-04-04 08:00:59 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-58074930-connect will be ready
2022-04-04 08:02:03 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-58074930-connect is ready
2022-04-04 08:02:03 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-58074930-connect to be ready
2022-04-04 08:02:13 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-58074930-connect is ready
2022-04-04 08:02:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-58074930 in namespace namespace-2
2022-04-04 08:02:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-04-04 08:02:13 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkaconnectors' with unstable version 'v1beta2'
2022-04-04 08:02:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-58074930 will have desired state: Ready
2022-04-04 08:02:14 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-58074930 is in desired state: Ready
2022-04-04 08:02:14 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-58074930-connect-5544c7bf9f-jn5gs -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-58074930
2022-04-04 08:02:14 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:14 [main] [32mINFO [m [ReconciliationST:118] Adding pause annotation into the KafkaConnector and scaling taskMax to 4
2022-04-04 08:02:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-58074930 will have desired state: ReconciliationPaused
2022-04-04 08:02:15 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-58074930 is in desired state: ReconciliationPaused
2022-04-04 08:02:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-58074930-connect-5544c7bf9f-jn5gs -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-58074930
2022-04-04 08:02:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:16 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 19 polls
2022-04-04 08:02:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-58074930-connect-5544c7bf9f-jn5gs -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-58074930
2022-04-04 08:02:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:17 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 18 polls
2022-04-04 08:02:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-58074930-connect-5544c7bf9f-jn5gs -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-58074930
2022-04-04 08:02:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:18 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 17 polls
2022-04-04 08:02:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-58074930-connect-5544c7bf9f-jn5gs -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-58074930
2022-04-04 08:02:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:19 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 16 polls
2022-04-04 08:02:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-58074930-connect-5544c7bf9f-jn5gs -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-58074930
2022-04-04 08:02:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:20 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 15 polls
2022-04-04 08:02:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-58074930-connect-5544c7bf9f-jn5gs -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-58074930
2022-04-04 08:02:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:22 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 14 polls
2022-04-04 08:02:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-58074930-connect-5544c7bf9f-jn5gs -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-58074930
2022-04-04 08:02:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:23 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 13 polls
2022-04-04 08:02:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-58074930-connect-5544c7bf9f-jn5gs -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-58074930
2022-04-04 08:02:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:24 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 12 polls
2022-04-04 08:02:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-58074930-connect-5544c7bf9f-jn5gs -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-58074930
2022-04-04 08:02:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:25 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 11 polls
2022-04-04 08:02:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-58074930-connect-5544c7bf9f-jn5gs -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-58074930
2022-04-04 08:02:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:26 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 10 polls
2022-04-04 08:02:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-58074930-connect-5544c7bf9f-jn5gs -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-58074930
2022-04-04 08:02:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:27 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 9 polls
2022-04-04 08:02:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-58074930-connect-5544c7bf9f-jn5gs -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-58074930
2022-04-04 08:02:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:29 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 8 polls
2022-04-04 08:02:30 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-58074930-connect-5544c7bf9f-jn5gs -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-58074930
2022-04-04 08:02:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:30 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 7 polls
2022-04-04 08:02:31 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-58074930-connect-5544c7bf9f-jn5gs -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-58074930
2022-04-04 08:02:31 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:31 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 6 polls
2022-04-04 08:02:32 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-58074930-connect-5544c7bf9f-jn5gs -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-58074930
2022-04-04 08:02:32 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:32 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 5 polls
2022-04-04 08:02:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-58074930-connect-5544c7bf9f-jn5gs -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-58074930
2022-04-04 08:02:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:33 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 4 polls
2022-04-04 08:02:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-58074930-connect-5544c7bf9f-jn5gs -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-58074930
2022-04-04 08:02:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:35 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 3 polls
2022-04-04 08:02:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-58074930-connect-5544c7bf9f-jn5gs -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-58074930
2022-04-04 08:02:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:36 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 2 polls
2022-04-04 08:02:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-58074930-connect-5544c7bf9f-jn5gs -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-58074930
2022-04-04 08:02:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:37 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 1 polls
2022-04-04 08:02:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-58074930-connect-5544c7bf9f-jn5gs -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-58074930
2022-04-04 08:02:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:38 [main] [32mINFO [m [KafkaConnectorUtils:154] Connector's spec is stable for 20 polls intervals
2022-04-04 08:02:38 [main] [32mINFO [m [ReconciliationST:127] Setting annotation to "false", taskMax should be increased to 4
2022-04-04 08:02:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-58074930-connect-5544c7bf9f-jn5gs -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-58074930/config
2022-04-04 08:02:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-58074930-connect-5544c7bf9f-jn5gs -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-58074930/config
2022-04-04 08:02:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:39 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:02:39 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testPauseReconciliationInKafkaAndKafkaConnectWithConnector
2022-04-04 08:02:39 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-58074930-allow in namespace namespace-2
2022-04-04 08:02:39 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-58074930 in namespace namespace-2
2022-04-04 08:02:39 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-58074930 in namespace namespace-2
2022-04-04 08:02:39 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-58074930 in namespace namespace-2
2022-04-04 08:02:39 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-58074930-scraper in namespace namespace-2
2022-04-04 08:02:39 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-58074930-kafka-clients in namespace namespace-2
2022-04-04 08:03:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 08:03:29 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-2 for test case:testPauseReconciliationInKafkaAndKafkaConnectWithConnector
2022-04-04 08:03:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.ReconciliationST.testPauseReconciliationInKafkaAndKafkaConnectWithConnector-FINISHED
2022-04-04 08:03:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 08:03:34 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 08:03:34 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.ReconciliationST.testPauseReconciliationInKafkaRebalanceAndTopic-STARTED
2022-04-04 08:03:34 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 08:03:34 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-3 for test case:testPauseReconciliationInKafkaRebalanceAndTopic
2022-04-04 08:03:34 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-3
2022-04-04 08:03:34 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-3
2022-04-04 08:03:34 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-3
2022-04-04 08:03:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ad23e180 in namespace namespace-3
2022-04-04 08:03:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-3
2022-04-04 08:03:34 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ad23e180 will have desired state: Ready
2022-04-04 08:05:16 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ad23e180 is in desired state: Ready
2022-04-04 08:05:16 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2091166361-207586637 in namespace namespace-3
2022-04-04 08:05:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-3
2022-04-04 08:05:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2091166361-207586637 will have desired state: Ready
2022-04-04 08:05:17 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2091166361-207586637 is in desired state: Ready
2022-04-04 08:05:17 [main] [32mINFO [m [ReconciliationST:147] Adding pause annotation into KafkaTopic resource and changing replication factor
2022-04-04 08:05:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2091166361-207586637 will have desired state: ReconciliationPaused
2022-04-04 08:05:18 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2091166361-207586637 is in desired state: ReconciliationPaused
2022-04-04 08:05:21 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-ad23e180-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-2091166361-207586637 --describe --bootstrap-server my-cluster-ad23e180-kafka-bootstrap:9092
2022-04-04 08:05:21 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:05:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-ad23e180-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-2091166361-207586637 --describe --bootstrap-server my-cluster-ad23e180-kafka-bootstrap:9092
2022-04-04 08:05:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:05:23 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 19 polls
2022-04-04 08:05:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-ad23e180-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-2091166361-207586637 --describe --bootstrap-server my-cluster-ad23e180-kafka-bootstrap:9092
2022-04-04 08:05:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:05:27 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 18 polls
2022-04-04 08:05:30 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-ad23e180-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-2091166361-207586637 --describe --bootstrap-server my-cluster-ad23e180-kafka-bootstrap:9092
2022-04-04 08:05:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:05:30 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 17 polls
2022-04-04 08:05:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-ad23e180-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-2091166361-207586637 --describe --bootstrap-server my-cluster-ad23e180-kafka-bootstrap:9092
2022-04-04 08:05:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:05:34 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 16 polls
2022-04-04 08:05:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-ad23e180-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-2091166361-207586637 --describe --bootstrap-server my-cluster-ad23e180-kafka-bootstrap:9092
2022-04-04 08:05:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:05:37 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 15 polls
2022-04-04 08:05:40 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-ad23e180-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-2091166361-207586637 --describe --bootstrap-server my-cluster-ad23e180-kafka-bootstrap:9092
2022-04-04 08:05:40 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:05:40 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 14 polls
2022-04-04 08:05:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-ad23e180-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-2091166361-207586637 --describe --bootstrap-server my-cluster-ad23e180-kafka-bootstrap:9092
2022-04-04 08:05:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:05:44 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 13 polls
2022-04-04 08:05:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-ad23e180-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-2091166361-207586637 --describe --bootstrap-server my-cluster-ad23e180-kafka-bootstrap:9092
2022-04-04 08:05:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:05:47 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 12 polls
2022-04-04 08:05:54 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-ad23e180-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-2091166361-207586637 --describe --bootstrap-server my-cluster-ad23e180-kafka-bootstrap:9092
2022-04-04 08:05:54 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:05:54 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 11 polls
2022-04-04 08:06:04 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-ad23e180-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-2091166361-207586637 --describe --bootstrap-server my-cluster-ad23e180-kafka-bootstrap:9092
2022-04-04 08:06:04 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:06:04 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 10 polls
2022-04-04 08:06:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-ad23e180-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-2091166361-207586637 --describe --bootstrap-server my-cluster-ad23e180-kafka-bootstrap:9092
2022-04-04 08:06:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:06:09 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 9 polls
2022-04-04 08:06:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-ad23e180-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-2091166361-207586637 --describe --bootstrap-server my-cluster-ad23e180-kafka-bootstrap:9092
2022-04-04 08:06:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:06:12 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 8 polls
2022-04-04 08:06:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-ad23e180-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-2091166361-207586637 --describe --bootstrap-server my-cluster-ad23e180-kafka-bootstrap:9092
2022-04-04 08:06:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:06:16 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 7 polls
2022-04-04 08:06:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-ad23e180-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-2091166361-207586637 --describe --bootstrap-server my-cluster-ad23e180-kafka-bootstrap:9092
2022-04-04 08:06:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:06:19 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 6 polls
2022-04-04 08:06:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-ad23e180-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-2091166361-207586637 --describe --bootstrap-server my-cluster-ad23e180-kafka-bootstrap:9092
2022-04-04 08:06:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:06:23 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 5 polls
2022-04-04 08:06:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-ad23e180-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-2091166361-207586637 --describe --bootstrap-server my-cluster-ad23e180-kafka-bootstrap:9092
2022-04-04 08:06:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:06:26 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 4 polls
2022-04-04 08:06:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-ad23e180-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-2091166361-207586637 --describe --bootstrap-server my-cluster-ad23e180-kafka-bootstrap:9092
2022-04-04 08:06:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:06:29 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 3 polls
2022-04-04 08:06:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-ad23e180-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-2091166361-207586637 --describe --bootstrap-server my-cluster-ad23e180-kafka-bootstrap:9092
2022-04-04 08:06:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:06:33 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 2 polls
2022-04-04 08:06:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-ad23e180-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-2091166361-207586637 --describe --bootstrap-server my-cluster-ad23e180-kafka-bootstrap:9092
2022-04-04 08:06:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:06:36 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 1 polls
2022-04-04 08:06:40 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-ad23e180-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-2091166361-207586637 --describe --bootstrap-server my-cluster-ad23e180-kafka-bootstrap:9092
2022-04-04 08:06:40 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:06:40 [main] [32mINFO [m [KafkaTopicUtils:197] KafkaTopic's spec is stable for 20 polls intervals
2022-04-04 08:06:40 [main] [32mINFO [m [ReconciliationST:156] Setting annotation to "false", partitions should be scaled to 4
2022-04-04 08:06:40 [main] [32mINFO [m [KafkaTopicUtils:124] Waiting for KafkaTopic change my-topic-2091166361-207586637
2022-04-04 08:06:40 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-ad23e180 in namespace namespace-3
2022-04-04 08:06:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-3
2022-04-04 08:06:40 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkarebalances' with unstable version 'v1beta2'
2022-04-04 08:06:40 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-ad23e180 will have desired state: PendingProposal
2022-04-04 08:06:41 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-ad23e180 is in desired state: PendingProposal
2022-04-04 08:06:41 [main] [32mINFO [m [ReconciliationST:164] Waiting for ProposalReady, then add pause and rebalance annotation, rebalancing should not be triggered
2022-04-04 08:06:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-ad23e180 will have desired state: ProposalReady
2022-04-04 08:11:10 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-ad23e180 is in desired state: ProposalReady
2022-04-04 08:11:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-ad23e180 will have desired state: ReconciliationPaused
2022-04-04 08:11:11 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-ad23e180 is in desired state: ReconciliationPaused
2022-04-04 08:11:11 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #1(test) KafkaRebalance(namespace-3/my-cluster-ad23e180): Annotating KafkaRebalance:my-cluster-ad23e180 with annotation approve
2022-04-04 08:11:12 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-ad23e180): KafkaRebalance status gonna be stable in 19 polls
2022-04-04 08:11:13 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-ad23e180): KafkaRebalance status gonna be stable in 18 polls
2022-04-04 08:11:14 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-ad23e180): KafkaRebalance status gonna be stable in 17 polls
2022-04-04 08:11:15 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-ad23e180): KafkaRebalance status gonna be stable in 16 polls
2022-04-04 08:11:16 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-ad23e180): KafkaRebalance status gonna be stable in 15 polls
2022-04-04 08:11:17 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-ad23e180): KafkaRebalance status gonna be stable in 14 polls
2022-04-04 08:11:18 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-ad23e180): KafkaRebalance status gonna be stable in 13 polls
2022-04-04 08:11:19 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-ad23e180): KafkaRebalance status gonna be stable in 12 polls
2022-04-04 08:11:20 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-ad23e180): KafkaRebalance status gonna be stable in 11 polls
2022-04-04 08:11:21 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-ad23e180): KafkaRebalance status gonna be stable in 10 polls
2022-04-04 08:11:22 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-ad23e180): KafkaRebalance status gonna be stable in 9 polls
2022-04-04 08:11:23 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-ad23e180): KafkaRebalance status gonna be stable in 8 polls
2022-04-04 08:11:24 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-ad23e180): KafkaRebalance status gonna be stable in 7 polls
2022-04-04 08:11:25 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-ad23e180): KafkaRebalance status gonna be stable in 6 polls
2022-04-04 08:11:26 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-ad23e180): KafkaRebalance status gonna be stable in 5 polls
2022-04-04 08:11:27 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-ad23e180): KafkaRebalance status gonna be stable in 4 polls
2022-04-04 08:11:28 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-ad23e180): KafkaRebalance status gonna be stable in 3 polls
2022-04-04 08:11:29 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-ad23e180): KafkaRebalance status gonna be stable in 2 polls
2022-04-04 08:11:30 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-ad23e180): KafkaRebalance status gonna be stable in 1 polls
2022-04-04 08:11:31 [main] [32mINFO [m [KafkaRebalanceUtils:118] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-ad23e180): KafkaRebalance status is stable for 20 polls intervals
2022-04-04 08:11:31 [main] [32mINFO [m [ReconciliationST:178] Setting annotation to "false" and waiting for KafkaRebalance to be in Ready state
2022-04-04 08:11:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-ad23e180 will have desired state: ProposalReady
2022-04-04 08:11:32 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-ad23e180 is in desired state: ProposalReady
2022-04-04 08:11:32 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #3(test) KafkaRebalance(namespace-3/my-cluster-ad23e180): Annotating KafkaRebalance:my-cluster-ad23e180 with annotation approve
2022-04-04 08:11:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-ad23e180 will have desired state: Ready
2022-04-04 08:12:48 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-ad23e180 is in desired state: Ready
2022-04-04 08:12:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:12:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testPauseReconciliationInKafkaRebalanceAndTopic
2022-04-04 08:12:48 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2091166361-207586637 in namespace namespace-3
2022-04-04 08:12:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-ad23e180 in namespace namespace-3
2022-04-04 08:12:48 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ad23e180 in namespace namespace-3
2022-04-04 08:12:48 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-3, for cruise control Kafka cluster my-cluster-ad23e180
2022-04-04 08:12:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 08:12:58 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-3 for test case:testPauseReconciliationInKafkaRebalanceAndTopic
2022-04-04 08:13:41 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.ReconciliationST.testPauseReconciliationInKafkaRebalanceAndTopic-FINISHED
2022-04-04 08:13:41 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 08:13:41 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:13:41 [main] [32mINFO [m [ResourceManager:346] In context ReconciliationST is everything deleted.
2022-04-04 08:13:41 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,091.77 s - in io.strimzi.systemtest.operators.ReconciliationST
[[1;34mINFO[m] Running io.strimzi.systemtest.bridge.HttpBridgeScramShaST
2022-04-04 08:13:46 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: http-bridge-scram-sha-st
2022-04-04 08:13:46 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: http-bridge-scram-sha-st
2022-04-04 08:13:46 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: http-bridge-scram-sha-st
2022-04-04 08:13:46 [main] [32mINFO [m [HttpBridgeScramShaST:123] Deploy Kafka and KafkaBridge before tests
2022-04-04 08:13:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka http-bridge-scram-sha-cluster-name in namespace http-bridge-scram-sha-st
2022-04-04 08:13:46 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: http-bridge-scram-sha-cluster-name will have desired state: Ready
2022-04-04 08:14:46 [main] [32mINFO [m [ResourceManager:444] Kafka: http-bridge-scram-sha-cluster-name is in desired state: Ready
2022-04-04 08:14:46 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1370630507-669433604 in namespace http-bridge-scram-sha-st
2022-04-04 08:14:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1370630507-669433604 will have desired state: Ready
2022-04-04 08:14:48 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1370630507-669433604 is in desired state: Ready
2022-04-04 08:14:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment http-bridge-scram-sha-st-shared-kafka-clients in namespace http-bridge-scram-sha-st
2022-04-04 08:14:48 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: http-bridge-scram-sha-st-shared-kafka-clients will be ready
2022-04-04 08:14:50 [main] [32mINFO [m [DeploymentUtils:168] Deployment: http-bridge-scram-sha-st-shared-kafka-clients is ready
2022-04-04 08:14:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge http-bridge-scram-sha-cluster-name in namespace http-bridge-scram-sha-st
2022-04-04 08:14:50 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkabridges' with unstable version 'v1beta2'
2022-04-04 08:14:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: http-bridge-scram-sha-cluster-name will have desired state: Ready
2022-04-04 08:15:20 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: http-bridge-scram-sha-cluster-name is in desired state: Ready
2022-04-04 08:15:20 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 08:15:20 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 08:15:20 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeScramShaST.testSendSimpleMessageTlsScramSha-STARTED
2022-04-04 08:15:20 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 08:15:20 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1253655872-985258869 in namespace http-bridge-scram-sha-st
2022-04-04 08:15:20 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1253655872-985258869 will have desired state: Ready
2022-04-04 08:15:21 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1253655872-985258869 is in desired state: Ready
2022-04-04 08:15:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-1531071038 in namespace http-bridge-scram-sha-st
2022-04-04 08:15:21 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-1531071038 will be in active state
2022-04-04 08:15:22 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:producer-1531071038 to finished
2022-04-04 08:15:34 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 08:15:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-1981649358 in namespace http-bridge-scram-sha-st
2022-04-04 08:15:34 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-1981649358 will be in active state
2022-04-04 08:15:35 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:consumer-1981649358 to finished
2022-04-04 08:15:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:15:49 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendSimpleMessageTlsScramSha
2022-04-04 08:15:49 [main] [32mINFO [m [ResourceManager:241] Delete of Job producer-1531071038 in namespace http-bridge-scram-sha-st
2022-04-04 08:15:49 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job consumer-1981649358 in namespace http-bridge-scram-sha-st
2022-04-04 08:15:49 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1253655872-985258869 in namespace http-bridge-scram-sha-st
2022-04-04 08:15:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 08:15:59 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeScramShaST.testSendSimpleMessageTlsScramSha-FINISHED
2022-04-04 08:15:59 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 08:15:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 08:15:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeScramShaST.testReceiveSimpleMessageTlsScramSha-STARTED
2022-04-04 08:15:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 08:15:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-335653399-1112350690 in namespace http-bridge-scram-sha-st
2022-04-04 08:15:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-335653399-1112350690 will have desired state: Ready
2022-04-04 08:16:00 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-335653399-1112350690 is in desired state: Ready
2022-04-04 08:16:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-1648864426 in namespace http-bridge-scram-sha-st
2022-04-04 08:16:00 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-1648864426 will be in active state
2022-04-04 08:16:01 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 08:16:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-901173955 in namespace http-bridge-scram-sha-st
2022-04-04 08:16:01 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-901173955 will be in active state
2022-04-04 08:16:02 [main] [32mINFO [m [ClientUtils:61] Waiting till producer producer-901173955 and consumer consumer-1648864426 finish
2022-04-04 08:16:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:16:23 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testReceiveSimpleMessageTlsScramSha
2022-04-04 08:16:23 [main] [32mINFO [m [ResourceManager:241] Delete of Job consumer-1648864426 in namespace http-bridge-scram-sha-st
2022-04-04 08:16:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job producer-901173955 in namespace http-bridge-scram-sha-st
2022-04-04 08:16:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-335653399-1112350690 in namespace http-bridge-scram-sha-st
2022-04-04 08:16:33 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 08:16:33 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeScramShaST.testReceiveSimpleMessageTlsScramSha-FINISHED
2022-04-04 08:16:33 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 08:16:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:16:33 [main] [32mINFO [m [ResourceManager:348] Delete all resources for HttpBridgeScramShaST
2022-04-04 08:16:33 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment http-bridge-scram-sha-st-shared-kafka-clients in namespace http-bridge-scram-sha-st
2022-04-04 08:16:33 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge http-bridge-scram-sha-cluster-name in namespace http-bridge-scram-sha-st
2022-04-04 08:16:33 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1370630507-669433604 in namespace http-bridge-scram-sha-st
2022-04-04 08:16:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka http-bridge-scram-sha-cluster-name in namespace http-bridge-scram-sha-st
2022-04-04 08:17:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 222.139 s - in io.strimzi.systemtest.bridge.HttpBridgeScramShaST
[[1;34mINFO[m] Running io.strimzi.systemtest.bridge.HttpBridgeTlsST
2022-04-04 08:17:28 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: http-bridge-tls-st
2022-04-04 08:17:28 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: http-bridge-tls-st
2022-04-04 08:17:28 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: http-bridge-tls-st
2022-04-04 08:17:28 [main] [32mINFO [m [HttpBridgeTlsST:129] Deploy Kafka and KafkaBridge before tests
2022-04-04 08:17:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka http-bridge-tls-cluster-name in namespace http-bridge-tls-st
2022-04-04 08:17:28 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: http-bridge-tls-cluster-name will have desired state: Ready
2022-04-04 08:18:31 [main] [32mINFO [m [ResourceManager:444] Kafka: http-bridge-tls-cluster-name is in desired state: Ready
2022-04-04 08:18:31 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-388246880-1392694604 in namespace http-bridge-tls-st
2022-04-04 08:18:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-388246880-1392694604 will have desired state: Ready
2022-04-04 08:18:32 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-388246880-1392694604 is in desired state: Ready
2022-04-04 08:18:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment http-bridge-tls-st-kafka-clients in namespace http-bridge-tls-st
2022-04-04 08:18:32 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: http-bridge-tls-st-kafka-clients will be ready
2022-04-04 08:18:34 [main] [32mINFO [m [DeploymentUtils:168] Deployment: http-bridge-tls-st-kafka-clients is ready
2022-04-04 08:18:34 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge http-bridge-tls-cluster-name in namespace http-bridge-tls-st
2022-04-04 08:18:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: http-bridge-tls-cluster-name will have desired state: Ready
2022-04-04 08:18:59 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: http-bridge-tls-cluster-name is in desired state: Ready
2022-04-04 08:18:59 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 08:18:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 08:18:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeTlsST.testReceiveSimpleMessageTls-STARTED
2022-04-04 08:18:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 08:18:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-320683541-704055247 in namespace http-bridge-tls-st
2022-04-04 08:18:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-320683541-704055247 will have desired state: Ready
2022-04-04 08:19:00 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-320683541-704055247 is in desired state: Ready
2022-04-04 08:19:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-1937012268 in namespace http-bridge-tls-st
2022-04-04 08:19:00 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-1937012268 will be in active state
2022-04-04 08:19:01 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 08:19:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-215114758 in namespace http-bridge-tls-st
2022-04-04 08:19:01 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-215114758 will be in active state
2022-04-04 08:19:02 [main] [32mINFO [m [ClientUtils:61] Waiting till producer producer-215114758 and consumer consumer-1937012268 finish
2022-04-04 08:19:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:19:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testReceiveSimpleMessageTls
2022-04-04 08:19:16 [main] [32mINFO [m [ResourceManager:241] Delete of Job consumer-1937012268 in namespace http-bridge-tls-st
2022-04-04 08:19:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-320683541-704055247 in namespace http-bridge-tls-st
2022-04-04 08:19:16 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job producer-215114758 in namespace http-bridge-tls-st
2022-04-04 08:19:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 08:19:26 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeTlsST.testReceiveSimpleMessageTls-FINISHED
2022-04-04 08:19:26 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 08:19:26 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 08:19:26 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeTlsST.testSendSimpleMessageTls-STARTED
2022-04-04 08:19:26 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 08:19:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1579960319-451180703 in namespace http-bridge-tls-st
2022-04-04 08:19:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1579960319-451180703 will have desired state: Ready
2022-04-04 08:19:27 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1579960319-451180703 is in desired state: Ready
2022-04-04 08:19:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-504767305 in namespace http-bridge-tls-st
2022-04-04 08:19:27 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-504767305 will be in active state
2022-04-04 08:19:28 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:producer-504767305 to finished
2022-04-04 08:19:36 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 08:19:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-1005752520 in namespace http-bridge-tls-st
2022-04-04 08:19:36 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-1005752520 will be in active state
2022-04-04 08:19:37 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:consumer-1005752520 to finished
2022-04-04 08:19:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:19:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendSimpleMessageTls
2022-04-04 08:19:48 [main] [32mINFO [m [ResourceManager:241] Delete of Job producer-504767305 in namespace http-bridge-tls-st
2022-04-04 08:19:48 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job consumer-1005752520 in namespace http-bridge-tls-st
2022-04-04 08:19:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1579960319-451180703 in namespace http-bridge-tls-st
2022-04-04 08:19:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 08:19:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeTlsST.testSendSimpleMessageTls-FINISHED
2022-04-04 08:19:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 08:19:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:19:58 [main] [32mINFO [m [ResourceManager:348] Delete all resources for HttpBridgeTlsST
2022-04-04 08:19:58 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment http-bridge-tls-st-kafka-clients in namespace http-bridge-tls-st
2022-04-04 08:19:58 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka http-bridge-tls-cluster-name in namespace http-bridge-tls-st
2022-04-04 08:19:58 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge http-bridge-tls-cluster-name in namespace http-bridge-tls-st
2022-04-04 08:19:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-388246880-1392694604 in namespace http-bridge-tls-st
2022-04-04 08:20:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 205.046 s - in io.strimzi.systemtest.bridge.HttpBridgeTlsST
[[1;34mINFO[m] Running io.strimzi.systemtest.tracing.TracingST
2022-04-04 08:20:54 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: tracing-st
2022-04-04 08:20:54 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: tracing-st
2022-04-04 08:20:54 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: tracing-st
2022-04-04 08:20:54 [main] [32mINFO [m [TracingST:497] === Applying jaeger operator install files ===
2022-04-04 08:20:54 [main] [32mINFO [m [TracingST:488] Creating jaeger-cluster-role-binding.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-cluster-role-binding.yaml
2022-04-04 08:20:54 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-04 08:20:54 [main] [32mINFO [m [Exec:417] Input: ---
kind: "ClusterRoleBinding"
apiVersion: "rbac.authorization.k8s.io/v1"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
subjects:
- kind: "ServiceAccount"
  name: "jaeger-operator"
  namespace: "tracing-st"
roleRef:
  kind: "ClusterRole"
  name: "jaeger-operator"
  apiGroup: "rbac.authorization.k8s.io"
2022-04-04 08:20:54 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:20:54 [main] [32mINFO [m [TracingST:488] Creating jaeger-cluster-role.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-cluster-role.yaml
2022-04-04 08:20:54 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-04 08:20:54 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "rbac.authorization.k8s.io/v1"
kind: "ClusterRole"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
rules:
- apiGroups:
  - "jaegertracing.io"
  resources:
  - "*"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resourceNames:
  - "jaeger-operator"
  resources:
  - "deployments/finalizers"
  verbs:
  - "update"
- apiGroups:
  - ""
  resources:
  - "configmaps"
  - "persistentvolumeclaims"
  - "pods"
  - "secrets"
  - "serviceaccounts"
  - "services"
  - "services/finalizers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  - "daemonsets"
  - "replicasets"
  - "statefulsets"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "extensions"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "networking.k8s.io"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "batch"
  resources:
  - "jobs"
  - "cronjobs"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "route.openshift.io"
  resources:
  - "routes"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "console.openshift.io"
  resources:
  - "consolelinks"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "autoscaling"
  resources:
  - "horizontalpodautoscalers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "monitoring.coreos.com"
  resources:
  - "servicemonitors"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "logging.openshift.io"
  resources:
  - "elasticsearches"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "kafka.strimzi.io"
  resources:
  - "kafkas"
  - "kafkausers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - ""
  resources:
  - "namespaces"
  verbs:
  - "get"
  - "list"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  verbs:
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "rbac.authorization.k8s.io"
  resources:
  - "clusterrolebindings"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
2022-04-04 08:20:54 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:20:54 [main] [32mINFO [m [TracingST:488] Creating jaeger-crd.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-crd.yaml
2022-04-04 08:20:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-04 08:20:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:20:55 [main] [32mINFO [m [TracingST:488] Creating jaeger-operator.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-operator.yaml
2022-04-04 08:20:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-04 08:20:55 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "apps/v1"
kind: "Deployment"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
spec:
  replicas: 1
  selector:
    matchLabels:
      name: "jaeger-operator"
  template:
    metadata:
      labels:
        name: "jaeger-operator"
    spec:
      serviceAccountName: "jaeger-operator"
      containers:
      - name: "jaeger-operator"
        image: "jaegertracing/jaeger-operator:1.20.0"
        ports:
        - containerPort: 8383
          name: "http-metrics"
        - containerPort: 8686
          name: "cr-metrics"
        args:
        - "start"
        - "--kafka-provision=no"
        imagePullPolicy: "Always"
        env:
        - name: "WATCH_NAMESPACE"
          value: ""
        - name: "POD_NAME"
          valueFrom:
            fieldRef:
              fieldPath: "metadata.name"
        - name: "POD_NAMESPACE"
          valueFrom:
            fieldRef:
              fieldPath: "metadata.namespace"
        - name: "OPERATOR_NAME"
          value: "jaeger-operator"
2022-04-04 08:20:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:20:55 [main] [32mINFO [m [TracingST:488] Creating jaeger-role-binding.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-role-binding.yaml
2022-04-04 08:20:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-04 08:20:55 [main] [32mINFO [m [Exec:417] Input: ---
kind: "RoleBinding"
apiVersion: "rbac.authorization.k8s.io/v1"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
subjects:
- kind: "ServiceAccount"
  name: "jaeger-operator"
roleRef:
  kind: "Role"
  name: "jaeger-operator"
  apiGroup: "rbac.authorization.k8s.io"
2022-04-04 08:20:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:20:55 [main] [32mINFO [m [TracingST:488] Creating jaeger-role.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-role.yaml
2022-04-04 08:20:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-04 08:20:55 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "rbac.authorization.k8s.io/v1"
kind: "Role"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
rules:
- apiGroups:
  - "jaegertracing.io"
  resources:
  - "*"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resourceNames:
  - "jaeger-operator"
  resources:
  - "deployments/finalizers"
  verbs:
  - "update"
- apiGroups:
  - ""
  resources:
  - "configmaps"
  - "persistentvolumeclaims"
  - "pods"
  - "secrets"
  - "serviceaccounts"
  - "services"
  - "services/finalizers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  - "daemonsets"
  - "replicasets"
  - "statefulsets"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "extensions"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "networking.k8s.io"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "batch"
  resources:
  - "jobs"
  - "cronjobs"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "route.openshift.io"
  resources:
  - "routes"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "image.openshift.io"
  resources:
  - "imagestreams"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "autoscaling"
  resources:
  - "horizontalpodautoscalers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "monitoring.coreos.com"
  resources:
  - "servicemonitors"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "logging.openshift.io"
  resources:
  - "elasticsearches"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "kafka.strimzi.io"
  resources:
  - "kafkas"
  - "kafkausers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
2022-04-04 08:20:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:20:55 [main] [32mINFO [m [TracingST:488] Creating jaeger-service-account.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-service-account.yaml
2022-04-04 08:20:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-04 08:20:55 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "v1"
kind: "ServiceAccount"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
2022-04-04 08:20:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:20:55 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: jaeger-operator will be ready
2022-04-04 08:21:03 [main] [32mINFO [m [DeploymentUtils:168] Deployment: jaeger-operator is ready
2022-04-04 08:21:03 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment jaeger-operator to be ready
2022-04-04 08:21:13 [main] [32mINFO [m [DeploymentUtils:197] Deployment jaeger-operator is ready
2022-04-04 08:21:13 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy jaeger-allow in namespace tracing-st
2022-04-04 08:21:13 [main] [32mINFO [m [TracingST:524] Network policy for jaeger successfully created
2022-04-04 08:21:13 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 08:21:13 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerStreamsConnectService-STARTED
2022-04-04 08:21:13 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 08:21:13 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-4 for test case:testProducerConsumerStreamsConnectService
2022-04-04 08:21:13 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-4
2022-04-04 08:21:13 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-4
2022-04-04 08:21:13 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-4
2022-04-04 08:21:13 [main] [32mINFO [m [TracingST:531] === Applying jaeger instance install file ===
2022-04-04 08:21:14 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 apply -f -
2022-04-04 08:21:14 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-04 08:21:14 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:21:14 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-jaeger will be ready
2022-04-04 08:21:20 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-jaeger is ready
2022-04-04 08:21:20 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-jaeger to be ready
2022-04-04 08:21:30 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-jaeger is ready
2022-04-04 08:21:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-1914f4dc-kafka-clients in namespace namespace-4
2022-04-04 08:21:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-04 08:21:30 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1914f4dc-kafka-clients will be ready
2022-04-04 08:21:32 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1914f4dc-kafka-clients is ready
2022-04-04 08:21:32 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 08:21:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1914f4dc in namespace namespace-4
2022-04-04 08:21:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-04 08:21:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1914f4dc will have desired state: Ready
2022-04-04 08:22:44 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1914f4dc is in desired state: Ready
2022-04-04 08:22:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-769040894-583979443 in namespace namespace-4
2022-04-04 08:22:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-04 08:22:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-769040894-583979443 will have desired state: Ready
2022-04-04 08:22:45 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-769040894-583979443 is in desired state: Ready
2022-04-04 08:22:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1158999450-1506370105 in namespace namespace-4
2022-04-04 08:22:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-04 08:22:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1158999450-1506370105 will have desired state: Ready
2022-04-04 08:22:46 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1158999450-1506370105 is in desired state: Ready
2022-04-04 08:22:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-1914f4dc-scraper in namespace namespace-4
2022-04-04 08:22:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-04 08:22:46 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1914f4dc-scraper will be ready
2022-04-04 08:22:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1914f4dc-scraper is ready
2022-04-04 08:22:48 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-1914f4dc-scraper to be ready
2022-04-04 08:22:58 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-1914f4dc-scraper is ready
2022-04-04 08:22:58 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-1914f4dc-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 08:22:58 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-1914f4dc-allow in namespace namespace-4
2022-04-04 08:22:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-04 08:22:58 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 08:22:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-1914f4dc in namespace namespace-4
2022-04-04 08:22:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-04 08:22:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-1914f4dc will have desired state: Ready
2022-04-04 08:24:00 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-1914f4dc is in desired state: Ready
2022-04-04 08:24:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-1914f4dc in namespace namespace-4
2022-04-04 08:24:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-04 08:24:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-1914f4dc will have desired state: Ready
2022-04-04 08:24:01 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-1914f4dc is in desired state: Ready
2022-04-04 08:24:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-1914f4dc-hello-world-producer in namespace namespace-4
2022-04-04 08:24:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-04 08:24:01 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-1914f4dc-hello-world-producer will be in active state
2022-04-04 08:24:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-1914f4dc-hello-world-consumer in namespace namespace-4
2022-04-04 08:24:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-04 08:24:02 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-1914f4dc-hello-world-consumer will be in active state
2022-04-04 08:24:03 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-1914f4dc-hello-world-producer and consumer my-cluster-1914f4dc-hello-world-consumer finish
2022-04-04 08:24:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-1914f4dc-kafka-clients-6b685dbdfd-xfqs8 -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:24:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:24:19 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-producer is present
2022-04-04 08:24:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-1914f4dc-kafka-clients-6b685dbdfd-xfqs8 -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-producer&operation=To_my-topic-769040894-583979443
2022-04-04 08:24:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:24:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-1914f4dc-kafka-clients-6b685dbdfd-xfqs8 -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:24:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:24:19 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-consumer is present
2022-04-04 08:24:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-1914f4dc-kafka-clients-6b685dbdfd-xfqs8 -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-consumer&operation=From_my-topic-769040894-583979443
2022-04-04 08:24:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:24:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-1914f4dc-kafka-clients-6b685dbdfd-xfqs8 -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:24:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:24:20 [main] [32mINFO [m [TracingUtils:47] Jaeger service my-connect is present
2022-04-04 08:24:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-1914f4dc-kafka-clients-6b685dbdfd-xfqs8 -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=my-connect&operation=From_my-topic-769040894-583979443
2022-04-04 08:24:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:24:20 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:24:20 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerStreamsConnectService
2022-04-04 08:24:20 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-1914f4dc-scraper in namespace namespace-4
2022-04-04 08:24:20 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-1914f4dc-allow in namespace namespace-4
2022-04-04 08:24:20 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-1914f4dc-kafka-clients in namespace namespace-4
2022-04-04 08:24:20 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-1914f4dc in namespace namespace-4
2022-04-04 08:24:20 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-1914f4dc-hello-world-producer in namespace namespace-4
2022-04-04 08:24:20 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1914f4dc in namespace namespace-4
2022-04-04 08:24:20 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-1914f4dc in namespace namespace-4
2022-04-04 08:24:20 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1158999450-1506370105 in namespace namespace-4
2022-04-04 08:24:20 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-1914f4dc-hello-world-consumer in namespace namespace-4
2022-04-04 08:24:20 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-769040894-583979443 in namespace namespace-4
2022-04-04 08:24:30 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 delete -f -
2022-04-04 08:24:30 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-04 08:24:30 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:25:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 08:25:10 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-4 for test case:testProducerConsumerStreamsConnectService
2022-04-04 08:25:15 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerStreamsConnectService-FINISHED
2022-04-04 08:25:15 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 08:25:15 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 08:25:15 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.tracing.TracingST.testKafkaBridgeService-STARTED
2022-04-04 08:25:15 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 08:25:15 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-5 for test case:testKafkaBridgeService
2022-04-04 08:25:15 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-5
2022-04-04 08:25:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-5
2022-04-04 08:25:15 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-5
2022-04-04 08:25:15 [main] [32mINFO [m [TracingST:531] === Applying jaeger instance install file ===
2022-04-04 08:25:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-5 apply -f -
2022-04-04 08:25:16 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-04 08:25:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:25:16 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-jaeger will be ready
2022-04-04 08:25:20 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-jaeger is ready
2022-04-04 08:25:20 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-jaeger to be ready
2022-04-04 08:25:30 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-jaeger is ready
2022-04-04 08:25:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-bdbbff18-kafka-clients in namespace namespace-5
2022-04-04 08:25:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-04-04 08:25:30 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-bdbbff18-kafka-clients will be ready
2022-04-04 08:25:32 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-bdbbff18-kafka-clients is ready
2022-04-04 08:25:32 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 08:25:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-bdbbff18 in namespace namespace-5
2022-04-04 08:25:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-04-04 08:25:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-bdbbff18 will have desired state: Ready
2022-04-04 08:26:53 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-bdbbff18 is in desired state: Ready
2022-04-04 08:26:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge my-cluster-bdbbff18 in namespace namespace-5
2022-04-04 08:26:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-04-04 08:26:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: my-cluster-bdbbff18 will have desired state: Ready
2022-04-04 08:27:14 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: my-cluster-bdbbff18 is in desired state: Ready
2022-04-04 08:27:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2093051876-497387409 in namespace namespace-5
2022-04-04 08:27:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-04-04 08:27:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2093051876-497387409 will have desired state: Ready
2022-04-04 08:27:15 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2093051876-497387409 is in desired state: Ready
2022-04-04 08:27:15 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 08:27:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Job bridge-producer in namespace namespace-5
2022-04-04 08:27:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-04-04 08:27:15 [main] [32mINFO [m [JobUtils:81] Waiting for job: bridge-producer will be in active state
2022-04-04 08:27:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-bdbbff18-hello-world-consumer in namespace namespace-5
2022-04-04 08:27:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-04-04 08:27:16 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-bdbbff18-hello-world-consumer will be in active state
2022-04-04 08:27:17 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:bridge-producer to finished
2022-04-04 08:29:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-5 exec my-cluster-bdbbff18-kafka-clients-59b78547d4-r5cj9 -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:29:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:29:05 [main] [32mINFO [m [TracingUtils:47] Jaeger service my-kafka-bridge is present
2022-04-04 08:29:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-5 exec my-cluster-bdbbff18-kafka-clients-59b78547d4-r5cj9 -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=my-kafka-bridge
2022-04-04 08:29:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:29:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:29:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaBridgeService
2022-04-04 08:29:05 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2093051876-497387409 in namespace namespace-5
2022-04-04 08:29:05 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge my-cluster-bdbbff18 in namespace namespace-5
2022-04-04 08:29:05 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-bdbbff18 in namespace namespace-5
2022-04-04 08:29:05 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-bdbbff18-kafka-clients in namespace namespace-5
2022-04-04 08:29:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-bdbbff18-hello-world-consumer in namespace namespace-5
2022-04-04 08:29:05 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job bridge-producer in namespace namespace-5
2022-04-04 08:29:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-5 delete -f -
2022-04-04 08:29:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-04 08:29:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:29:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 08:29:55 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-5 for test case:testKafkaBridgeService
2022-04-04 08:30:00 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.tracing.TracingST.testKafkaBridgeService-FINISHED
2022-04-04 08:30:00 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 08:30:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 08:30:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerStreamsService-STARTED
2022-04-04 08:30:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 08:30:00 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-6 for test case:testProducerConsumerStreamsService
2022-04-04 08:30:00 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-6
2022-04-04 08:30:00 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-6
2022-04-04 08:30:00 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-6
2022-04-04 08:30:00 [main] [32mINFO [m [TracingST:531] === Applying jaeger instance install file ===
2022-04-04 08:30:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 apply -f -
2022-04-04 08:30:01 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-04 08:30:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:30:01 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-jaeger will be ready
2022-04-04 08:30:11 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-jaeger is ready
2022-04-04 08:30:11 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-jaeger to be ready
2022-04-04 08:30:21 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-jaeger is ready
2022-04-04 08:30:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-2bdb7489-kafka-clients in namespace namespace-6
2022-04-04 08:30:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-04 08:30:21 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-2bdb7489-kafka-clients will be ready
2022-04-04 08:30:23 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-2bdb7489-kafka-clients is ready
2022-04-04 08:30:23 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 08:30:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2bdb7489 in namespace namespace-6
2022-04-04 08:30:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-04 08:30:23 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2bdb7489 will have desired state: Ready
2022-04-04 08:31:41 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2bdb7489 is in desired state: Ready
2022-04-04 08:31:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1208510827-1583963013 in namespace namespace-6
2022-04-04 08:31:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-04 08:31:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1208510827-1583963013 will have desired state: Ready
2022-04-04 08:31:42 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1208510827-1583963013 is in desired state: Ready
2022-04-04 08:31:42 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1867883512-756319293 in namespace namespace-6
2022-04-04 08:31:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-04 08:31:42 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1867883512-756319293 will have desired state: Ready
2022-04-04 08:31:43 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1867883512-756319293 is in desired state: Ready
2022-04-04 08:31:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-2bdb7489-hello-world-producer in namespace namespace-6
2022-04-04 08:31:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-04 08:31:43 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-2bdb7489-hello-world-producer will be in active state
2022-04-04 08:31:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-2bdb7489-kafka-clients-6458d9b586-fmb2f -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:31:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:31:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-2bdb7489-kafka-clients-6458d9b586-fmb2f -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:31:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:31:46 [main] [32mINFO [m [TracingUtils:50] Jaeger service hello-world-producer is not present. Present services are ["jaeger-query"].
2022-04-04 08:31:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-2bdb7489-kafka-clients-6458d9b586-fmb2f -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:31:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:31:47 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-producer is present
2022-04-04 08:31:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-2bdb7489-kafka-clients-6458d9b586-fmb2f -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-producer
2022-04-04 08:31:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:31:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-2bdb7489-hello-world-consumer in namespace namespace-6
2022-04-04 08:31:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-04 08:31:47 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-2bdb7489-hello-world-consumer will be in active state
2022-04-04 08:31:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-2bdb7489-kafka-clients-6458d9b586-fmb2f -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:31:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:31:48 [main] [32mINFO [m [TracingUtils:50] Jaeger service hello-world-consumer is not present. Present services are ["jaeger-query","hello-world-producer"].
2022-04-04 08:31:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-2bdb7489-kafka-clients-6458d9b586-fmb2f -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:31:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:31:49 [main] [32mINFO [m [TracingUtils:50] Jaeger service hello-world-consumer is not present. Present services are ["hello-world-producer","jaeger-query"].
2022-04-04 08:31:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-2bdb7489-kafka-clients-6458d9b586-fmb2f -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:31:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:31:50 [main] [32mINFO [m [TracingUtils:50] Jaeger service hello-world-consumer is not present. Present services are ["jaeger-query","hello-world-producer"].
2022-04-04 08:31:52 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-2bdb7489-kafka-clients-6458d9b586-fmb2f -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:31:52 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:31:52 [main] [32mINFO [m [TracingUtils:50] Jaeger service hello-world-consumer is not present. Present services are ["jaeger-query","hello-world-producer"].
2022-04-04 08:31:53 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-2bdb7489-kafka-clients-6458d9b586-fmb2f -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:31:53 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:31:53 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-consumer is present
2022-04-04 08:31:53 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-2bdb7489-kafka-clients-6458d9b586-fmb2f -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-consumer
2022-04-04 08:31:53 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:31:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-streams in namespace namespace-6
2022-04-04 08:31:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-04 08:31:53 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-streams will be in active state
2022-04-04 08:31:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:31:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerStreamsService
2022-04-04 08:31:54 [main] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-2bdb7489-hello-world-producer in namespace namespace-6
2022-04-04 08:31:54 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1867883512-756319293 in namespace namespace-6
2022-04-04 08:31:54 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-streams in namespace namespace-6
2022-04-04 08:31:54 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2bdb7489 in namespace namespace-6
2022-04-04 08:31:54 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-2bdb7489-hello-world-consumer in namespace namespace-6
2022-04-04 08:31:54 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1208510827-1583963013 in namespace namespace-6
2022-04-04 08:31:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-2bdb7489-kafka-clients in namespace namespace-6
2022-04-04 08:31:54 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 delete -f -
2022-04-04 08:31:54 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-04 08:31:54 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:32:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 08:32:44 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-6 for test case:testProducerConsumerStreamsService
2022-04-04 08:32:50 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerStreamsService-FINISHED
2022-04-04 08:32:50 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 08:32:50 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 08:32:50 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerMirrorMakerService-STARTED
2022-04-04 08:32:50 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 08:32:50 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-7 for test case:testProducerConsumerMirrorMakerService
2022-04-04 08:32:50 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-7
2022-04-04 08:32:50 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-7
2022-04-04 08:32:50 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-7
2022-04-04 08:32:50 [main] [32mINFO [m [TracingST:531] === Applying jaeger instance install file ===
2022-04-04 08:32:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 apply -f -
2022-04-04 08:32:50 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-04 08:32:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:32:50 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-jaeger will be ready
2022-04-04 08:32:58 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-jaeger is ready
2022-04-04 08:32:58 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-jaeger to be ready
2022-04-04 08:33:08 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-jaeger is ready
2022-04-04 08:33:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-c85fdc54-kafka-clients in namespace namespace-7
2022-04-04 08:33:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-04 08:33:08 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c85fdc54-kafka-clients will be ready
2022-04-04 08:33:10 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c85fdc54-kafka-clients is ready
2022-04-04 08:33:10 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 08:33:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c85fdc54 in namespace namespace-7
2022-04-04 08:33:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-04 08:33:10 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c85fdc54 will have desired state: Ready
2022-04-04 08:34:22 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c85fdc54 is in desired state: Ready
2022-04-04 08:34:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c85fdc54-target in namespace namespace-7
2022-04-04 08:34:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-04 08:34:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c85fdc54-target will have desired state: Ready
2022-04-04 08:35:32 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c85fdc54-target is in desired state: Ready
2022-04-04 08:35:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-903877305-224506240 in namespace namespace-7
2022-04-04 08:35:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-04 08:35:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-903877305-224506240 will have desired state: Ready
2022-04-04 08:35:33 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-903877305-224506240 is in desired state: Ready
2022-04-04 08:35:33 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-903877305-224506240-target in namespace namespace-7
2022-04-04 08:35:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-04 08:35:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-903877305-224506240-target will have desired state: Ready
2022-04-04 08:35:34 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-903877305-224506240-target is in desired state: Ready
2022-04-04 08:35:34 [main] [32mINFO [m [TracingST:267] Setting for kafka source plain bootstrap:my-cluster-c85fdc54-kafka-bootstrap:9092
2022-04-04 08:35:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-c85fdc54-hello-world-producer in namespace namespace-7
2022-04-04 08:35:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-04 08:35:34 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-c85fdc54-hello-world-producer will be in active state
2022-04-04 08:35:35 [main] [32mINFO [m [TracingST:276] Setting for kafka target plain bootstrap:my-cluster-c85fdc54-target-kafka-bootstrap:9092
2022-04-04 08:35:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-c85fdc54-hello-world-consumer in namespace namespace-7
2022-04-04 08:35:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-04 08:35:35 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-c85fdc54-hello-world-consumer will be in active state
2022-04-04 08:35:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-c85fdc54 in namespace namespace-7
2022-04-04 08:35:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-04 08:35:36 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkamirrormakers' with unstable version 'v1beta2'
2022-04-04 08:35:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-c85fdc54 will have desired state: Ready
2022-04-04 08:36:48 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-c85fdc54 is in desired state: Ready
2022-04-04 08:36:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-c85fdc54-kafka-clients-86c6946798-qm9fl -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:36:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:36:48 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-producer is present
2022-04-04 08:36:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-c85fdc54-kafka-clients-86c6946798-qm9fl -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-producer&operation=To_my-topic-903877305-224506240
2022-04-04 08:36:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:36:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-c85fdc54-kafka-clients-86c6946798-qm9fl -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:36:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:36:48 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-consumer is present
2022-04-04 08:36:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-c85fdc54-kafka-clients-86c6946798-qm9fl -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-consumer&operation=From_my-topic-903877305-224506240
2022-04-04 08:36:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:36:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-c85fdc54-kafka-clients-86c6946798-qm9fl -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:36:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:36:49 [main] [32mINFO [m [TracingUtils:47] Jaeger service my-mirror-maker is present
2022-04-04 08:36:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-c85fdc54-kafka-clients-86c6946798-qm9fl -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=my-mirror-maker&operation=From_my-topic-903877305-224506240
2022-04-04 08:36:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:36:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-c85fdc54-kafka-clients-86c6946798-qm9fl -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:36:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:36:49 [main] [32mINFO [m [TracingUtils:47] Jaeger service my-mirror-maker is present
2022-04-04 08:36:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-c85fdc54-kafka-clients-86c6946798-qm9fl -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=my-mirror-maker&operation=To_my-topic-903877305-224506240
2022-04-04 08:36:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:36:50 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:36:50 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerMirrorMakerService
2022-04-04 08:36:50 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-903877305-224506240-target in namespace namespace-7
2022-04-04 08:36:50 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-903877305-224506240 in namespace namespace-7
2022-04-04 08:36:50 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-c85fdc54-hello-world-consumer in namespace namespace-7
2022-04-04 08:36:50 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-c85fdc54-kafka-clients in namespace namespace-7
2022-04-04 08:36:50 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c85fdc54-target in namespace namespace-7
2022-04-04 08:36:50 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c85fdc54 in namespace namespace-7
2022-04-04 08:36:50 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-c85fdc54-hello-world-producer in namespace namespace-7
2022-04-04 08:36:50 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-c85fdc54 in namespace namespace-7
2022-04-04 08:36:50 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 delete -f -
2022-04-04 08:36:50 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-04 08:36:50 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:37:40 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 08:37:40 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-7 for test case:testProducerConsumerMirrorMakerService
2022-04-04 08:37:46 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerMirrorMakerService-FINISHED
2022-04-04 08:37:46 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 08:37:46 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 08:37:46 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerMirrorMaker2Service-STARTED
2022-04-04 08:37:46 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 08:37:46 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-8 for test case:testProducerConsumerMirrorMaker2Service
2022-04-04 08:37:46 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-8
2022-04-04 08:37:46 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-8
2022-04-04 08:37:46 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-8
2022-04-04 08:37:46 [main] [32mINFO [m [TracingST:531] === Applying jaeger instance install file ===
2022-04-04 08:37:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 apply -f -
2022-04-04 08:37:46 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-04 08:37:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:37:46 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-jaeger will be ready
2022-04-04 08:37:55 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-jaeger is ready
2022-04-04 08:37:55 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-jaeger to be ready
2022-04-04 08:38:05 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-jaeger is ready
2022-04-04 08:38:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-76e70ba0-kafka-clients in namespace namespace-8
2022-04-04 08:38:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-04 08:38:05 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-76e70ba0-kafka-clients will be ready
2022-04-04 08:38:06 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-76e70ba0-kafka-clients is ready
2022-04-04 08:38:06 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 08:38:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-76e70ba0 in namespace namespace-8
2022-04-04 08:38:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-04 08:38:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-76e70ba0 will have desired state: Ready
2022-04-04 08:39:22 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-76e70ba0 is in desired state: Ready
2022-04-04 08:39:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-76e70ba0-target in namespace namespace-8
2022-04-04 08:39:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-04 08:39:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-76e70ba0-target will have desired state: Ready
2022-04-04 08:40:32 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-76e70ba0-target is in desired state: Ready
2022-04-04 08:40:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1797916493-1803567858 in namespace namespace-8
2022-04-04 08:40:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-04 08:40:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1797916493-1803567858 will have desired state: Ready
2022-04-04 08:40:33 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1797916493-1803567858 is in desired state: Ready
2022-04-04 08:40:33 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-cluster-76e70ba0.my-topic-1797916493-1803567858 in namespace namespace-8
2022-04-04 08:40:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-04 08:40:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-cluster-76e70ba0.my-topic-1797916493-1803567858 will have desired state: Ready
2022-04-04 08:40:34 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-cluster-76e70ba0.my-topic-1797916493-1803567858 is in desired state: Ready
2022-04-04 08:40:34 [main] [32mINFO [m [TracingST:177] Setting for kafka source plain bootstrap:my-cluster-76e70ba0-kafka-bootstrap:9092
2022-04-04 08:40:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-76e70ba0-hello-world-producer in namespace namespace-8
2022-04-04 08:40:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-04 08:40:34 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-76e70ba0-hello-world-producer will be in active state
2022-04-04 08:40:35 [main] [32mINFO [m [TracingST:186] Setting for kafka target plain bootstrap:my-cluster-76e70ba0-target-kafka-bootstrap:9092
2022-04-04 08:40:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-76e70ba0-hello-world-consumer in namespace namespace-8
2022-04-04 08:40:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-04 08:40:35 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-76e70ba0-hello-world-consumer will be in active state
2022-04-04 08:40:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-76e70ba0 in namespace namespace-8
2022-04-04 08:40:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-04 08:40:36 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkamirrormaker2s' with unstable version 'v1beta2'
2022-04-04 08:40:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-76e70ba0 will have desired state: Ready
2022-04-04 08:41:45 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-76e70ba0 is in desired state: Ready
2022-04-04 08:41:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-76e70ba0-kafka-clients-7984f7cd58-d4zcf -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:41:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:41:45 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-producer is present
2022-04-04 08:41:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-76e70ba0-kafka-clients-7984f7cd58-d4zcf -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-producer&operation=To_my-topic-1797916493-1803567858
2022-04-04 08:41:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:41:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-76e70ba0-kafka-clients-7984f7cd58-d4zcf -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:41:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:41:46 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-consumer is present
2022-04-04 08:41:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-76e70ba0-kafka-clients-7984f7cd58-d4zcf -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-consumer&operation=From_my-cluster-76e70ba0.my-topic-1797916493-1803567858
2022-04-04 08:41:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:41:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-76e70ba0-kafka-clients-7984f7cd58-d4zcf -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:41:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:41:46 [main] [32mINFO [m [TracingUtils:47] Jaeger service my-mirror-maker2 is present
2022-04-04 08:41:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-76e70ba0-kafka-clients-7984f7cd58-d4zcf -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=my-mirror-maker2&operation=From_my-topic-1797916493-1803567858
2022-04-04 08:41:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:41:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-76e70ba0-kafka-clients-7984f7cd58-d4zcf -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:41:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:41:47 [main] [32mINFO [m [TracingUtils:47] Jaeger service my-mirror-maker2 is present
2022-04-04 08:41:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-76e70ba0-kafka-clients-7984f7cd58-d4zcf -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=my-mirror-maker2&operation=To_my-cluster-76e70ba0.my-topic-1797916493-1803567858
2022-04-04 08:41:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:41:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:41:47 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerMirrorMaker2Service
2022-04-04 08:41:47 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-cluster-76e70ba0.my-topic-1797916493-1803567858 in namespace namespace-8
2022-04-04 08:41:47 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1797916493-1803567858 in namespace namespace-8
2022-04-04 08:41:47 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-76e70ba0-hello-world-producer in namespace namespace-8
2022-04-04 08:41:47 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-76e70ba0 in namespace namespace-8
2022-04-04 08:41:47 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-76e70ba0-hello-world-consumer in namespace namespace-8
2022-04-04 08:41:47 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-76e70ba0-kafka-clients in namespace namespace-8
2022-04-04 08:41:47 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-76e70ba0-target in namespace namespace-8
2022-04-04 08:41:47 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-76e70ba0 in namespace namespace-8
2022-04-04 08:41:47 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 delete -f -
2022-04-04 08:41:47 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-04 08:41:47 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:42:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 08:42:47 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-8 for test case:testProducerConsumerMirrorMaker2Service
2022-04-04 08:42:54 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerMirrorMaker2Service-FINISHED
2022-04-04 08:42:54 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 08:42:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:42:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for TracingST
2022-04-04 08:42:54 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy jaeger-allow in namespace tracing-st
2022-04-04 08:42:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-04 08:42:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [Exec:417] Input: ---
apiVersion: "v1"
kind: "ServiceAccount"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
2022-04-04 08:42:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:42:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-04 08:42:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [Exec:417] Input: ---
apiVersion: "rbac.authorization.k8s.io/v1"
kind: "Role"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
rules:
- apiGroups:
  - "jaegertracing.io"
  resources:
  - "*"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resourceNames:
  - "jaeger-operator"
  resources:
  - "deployments/finalizers"
  verbs:
  - "update"
- apiGroups:
  - ""
  resources:
  - "configmaps"
  - "persistentvolumeclaims"
  - "pods"
  - "secrets"
  - "serviceaccounts"
  - "services"
  - "services/finalizers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  - "daemonsets"
  - "replicasets"
  - "statefulsets"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "extensions"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "networking.k8s.io"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "batch"
  resources:
  - "jobs"
  - "cronjobs"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "route.openshift.io"
  resources:
  - "routes"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "image.openshift.io"
  resources:
  - "imagestreams"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "autoscaling"
  resources:
  - "horizontalpodautoscalers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "monitoring.coreos.com"
  resources:
  - "servicemonitors"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "logging.openshift.io"
  resources:
  - "elasticsearches"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "kafka.strimzi.io"
  resources:
  - "kafkas"
  - "kafkausers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
2022-04-04 08:42:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:42:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-04 08:42:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [Exec:417] Input: ---
kind: "RoleBinding"
apiVersion: "rbac.authorization.k8s.io/v1"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
subjects:
- kind: "ServiceAccount"
  name: "jaeger-operator"
roleRef:
  kind: "Role"
  name: "jaeger-operator"
  apiGroup: "rbac.authorization.k8s.io"
2022-04-04 08:42:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:42:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-04 08:42:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [Exec:417] Input: ---
apiVersion: "apps/v1"
kind: "Deployment"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
spec:
  replicas: 1
  selector:
    matchLabels:
      name: "jaeger-operator"
  template:
    metadata:
      labels:
        name: "jaeger-operator"
    spec:
      serviceAccountName: "jaeger-operator"
      containers:
      - name: "jaeger-operator"
        image: "jaegertracing/jaeger-operator:1.20.0"
        ports:
        - containerPort: 8383
          name: "http-metrics"
        - containerPort: 8686
          name: "cr-metrics"
        args:
        - "start"
        - "--kafka-provision=no"
        imagePullPolicy: "Always"
        env:
        - name: "WATCH_NAMESPACE"
          value: ""
        - name: "POD_NAME"
          valueFrom:
            fieldRef:
              fieldPath: "metadata.name"
        - name: "POD_NAMESPACE"
          valueFrom:
            fieldRef:
              fieldPath: "metadata.namespace"
        - name: "OPERATOR_NAME"
          value: "jaeger-operator"
2022-04-04 08:42:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:42:55 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-04 08:42:55 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:42:55 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-04 08:42:55 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [Exec:417] Input: ---
apiVersion: "rbac.authorization.k8s.io/v1"
kind: "ClusterRole"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
rules:
- apiGroups:
  - "jaegertracing.io"
  resources:
  - "*"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resourceNames:
  - "jaeger-operator"
  resources:
  - "deployments/finalizers"
  verbs:
  - "update"
- apiGroups:
  - ""
  resources:
  - "configmaps"
  - "persistentvolumeclaims"
  - "pods"
  - "secrets"
  - "serviceaccounts"
  - "services"
  - "services/finalizers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  - "daemonsets"
  - "replicasets"
  - "statefulsets"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "extensions"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "networking.k8s.io"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "batch"
  resources:
  - "jobs"
  - "cronjobs"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "route.openshift.io"
  resources:
  - "routes"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "console.openshift.io"
  resources:
  - "consolelinks"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "autoscaling"
  resources:
  - "horizontalpodautoscalers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "monitoring.coreos.com"
  resources:
  - "servicemonitors"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "logging.openshift.io"
  resources:
  - "elasticsearches"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "kafka.strimzi.io"
  resources:
  - "kafkas"
  - "kafkausers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - ""
  resources:
  - "namespaces"
  verbs:
  - "get"
  - "list"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  verbs:
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "rbac.authorization.k8s.io"
  resources:
  - "clusterrolebindings"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
2022-04-04 08:42:55 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:42:55 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-04 08:42:55 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [Exec:417] Input: ---
kind: "ClusterRoleBinding"
apiVersion: "rbac.authorization.k8s.io/v1"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
subjects:
- kind: "ServiceAccount"
  name: "jaeger-operator"
  namespace: "tracing-st"
roleRef:
  kind: "ClusterRole"
  name: "jaeger-operator"
  apiGroup: "rbac.authorization.k8s.io"
2022-04-04 08:42:55 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:42:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,326.836 s - in io.strimzi.systemtest.tracing.TracingST
[[1;34mINFO[m] Running io.strimzi.systemtest.cruisecontrol.CruiseControlApiST
2022-04-04 08:43:00 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: cruise-control-api-st
2022-04-04 08:43:00 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: cruise-control-api-st
2022-04-04 08:43:00 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: cruise-control-api-st
2022-04-04 08:43:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 08:43:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlApiST.testCruiseControlBasicAPIRequests-STARTED
2022-04-04 08:43:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 08:43:00 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-9 for test case:testCruiseControlBasicAPIRequests
2022-04-04 08:43:00 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-9
2022-04-04 08:43:00 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-9
2022-04-04 08:43:00 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-9
2022-04-04 08:43:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d4874fb5 in namespace namespace-9
2022-04-04 08:43:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-9
2022-04-04 08:43:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d4874fb5 will have desired state: Ready
2022-04-04 08:44:38 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d4874fb5 is in desired state: Ready
2022-04-04 08:44:38 [main] [32mINFO [m [CruiseControlApiST:48] ----> CRUISE CONTROL DEPLOYMENT STATE ENDPOINT <----
2022-04-04 08:44:38 [main] [32mINFO [m [CruiseControlApiST:58] Verifying that Cruise Control REST API is available
2022-04-04 08:46:11 [main] [32mINFO [m [CruiseControlApiST:66] ----> KAFKA REBALANCE <----
2022-04-04 08:46:11 [main] [32mINFO [m [CruiseControlApiST:73] Waiting for CC will have for enough metrics to be recorded to make a proposal 
2022-04-04 08:46:32 [main] [32mINFO [m [CruiseControlApiST:97] ----> EXECUTION OF STOP PROPOSAL <----
2022-04-04 08:46:33 [main] [32mINFO [m [CruiseControlApiST:108] ----> USER TASKS <----
2022-04-04 08:46:33 [main] [32mINFO [m [CruiseControlApiST:126] Verifying that Cruise Control REST API doesn't allow HTTP requests
2022-04-04 08:46:33 [main] [32mINFO [m [CruiseControlApiST:132] Verifying that Cruise Control REST API doesn't allow unauthenticated requests
2022-04-04 08:46:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:46:33 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlBasicAPIRequests
2022-04-04 08:46:33 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d4874fb5 in namespace namespace-9
2022-04-04 08:46:33 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-9, for cruise control Kafka cluster my-cluster-d4874fb5
2022-04-04 08:46:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 08:46:43 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-9 for test case:testCruiseControlBasicAPIRequests
2022-04-04 08:47:26 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlApiST.testCruiseControlBasicAPIRequests-FINISHED
2022-04-04 08:47:26 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 08:47:26 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 08:47:26 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlApiST.testCruiseControlBasicAPIRequestsWithSecurityDisabled-STARTED
2022-04-04 08:47:26 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 08:47:26 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-10 for test case:testCruiseControlBasicAPIRequestsWithSecurityDisabled
2022-04-04 08:47:26 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-10
2022-04-04 08:47:26 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-10
2022-04-04 08:47:26 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-10
2022-04-04 08:47:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka cruise-control-api-cluster-name in namespace namespace-10
2022-04-04 08:47:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-10
2022-04-04 08:47:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: cruise-control-api-cluster-name will have desired state: Ready
2022-04-04 08:49:04 [main] [32mINFO [m [ResourceManager:444] Kafka: cruise-control-api-cluster-name is in desired state: Ready
2022-04-04 08:49:04 [main] [32mINFO [m [CruiseControlApiST:153] ----> CRUISE CONTROL DEPLOYMENT STATE ENDPOINT <----
2022-04-04 08:49:04 [main] [32mINFO [m [CruiseControlApiST:157] Verifying that Cruise Control REST API is available using HTTP request without credentials
2022-04-04 08:49:04 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:49:04 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlBasicAPIRequestsWithSecurityDisabled
2022-04-04 08:49:04 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka cruise-control-api-cluster-name in namespace namespace-10
2022-04-04 08:49:04 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-10, for cruise control Kafka cluster cruise-control-api-cluster-name
2022-04-04 08:49:14 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 08:49:14 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-10 for test case:testCruiseControlBasicAPIRequestsWithSecurityDisabled
2022-04-04 08:49:57 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlApiST.testCruiseControlBasicAPIRequestsWithSecurityDisabled-FINISHED
2022-04-04 08:49:57 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 08:49:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:49:57 [main] [32mINFO [m [ResourceManager:346] In context CruiseControlApiST is everything deleted.
2022-04-04 08:49:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 421.846 s - in io.strimzi.systemtest.cruisecontrol.CruiseControlApiST
[[1;34mINFO[m] Running io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST
2022-04-04 08:50:02 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: cruise-control-configuration-st
2022-04-04 08:50:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: cruise-control-configuration-st
2022-04-04 08:50:02 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: cruise-control-configuration-st
2022-04-04 08:50:02 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 08:50:02 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationFileIsCreated-STARTED
2022-04-04 08:50:02 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 08:50:02 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-11 for test case:testConfigurationFileIsCreated
2022-04-04 08:50:02 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-11
2022-04-04 08:50:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-11
2022-04-04 08:50:02 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-11
2022-04-04 08:50:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-67d8f1cf in namespace namespace-11
2022-04-04 08:50:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-11
2022-04-04 08:50:02 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-67d8f1cf will have desired state: Ready
2022-04-04 08:51:47 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-67d8f1cf is in desired state: Ready
2022-04-04 08:51:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-11 exec my-cluster-67d8f1cf-cruise-control-65d844f98f-cc4cs -- /bin/bash -c cat /tmp/cruisecontrol.properties
2022-04-04 08:51:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:51:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:51:47 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigurationFileIsCreated
2022-04-04 08:51:47 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-67d8f1cf in namespace namespace-11
2022-04-04 08:51:47 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-11, for cruise control Kafka cluster my-cluster-67d8f1cf
2022-04-04 08:51:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 08:51:57 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-11 for test case:testConfigurationFileIsCreated
2022-04-04 08:52:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationFileIsCreated-FINISHED
2022-04-04 08:52:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 08:52:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 08:52:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testDeployAndUnDeployCruiseControl-STARTED
2022-04-04 08:52:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 08:52:35 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-12 for test case:testDeployAndUnDeployCruiseControl
2022-04-04 08:52:35 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-12
2022-04-04 08:52:36 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-12
2022-04-04 08:52:36 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-12
2022-04-04 08:52:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-4dabb7d5 in namespace namespace-12
2022-04-04 08:52:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-12
2022-04-04 08:52:36 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4dabb7d5 will have desired state: Ready
2022-04-04 08:54:14 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4dabb7d5 is in desired state: Ready
2022-04-04 08:54:14 [main] [32mINFO [m [CruiseControlConfigurationST:111] Removing Cruise Control to the classic Kafka.
2022-04-04 08:54:14 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-4dabb7d5-kafka rolling update
2022-04-04 08:55:29 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-4dabb7d5-kafka has been successfully rolled
2022-04-04 08:55:29 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-4dabb7d5-kafka to be ready
2022-04-04 08:55:54 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4dabb7d5 will have desired state: Ready
2022-04-04 08:55:54 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4dabb7d5 is in desired state: Ready
2022-04-04 08:55:54 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-4dabb7d5 is ready
2022-04-04 08:55:54 [main] [32mINFO [m [CruiseControlConfigurationST:117] Verifying that in Cruise Control is not present in the Kafka cluster
2022-04-04 08:55:54 [main] [32mINFO [m [CruiseControlConfigurationST:120] Verifying that my-cluster-4dabb7d5-cruise-control- pod is not present
2022-04-04 08:55:54 [main] [32mINFO [m [PodUtils:209] Wait until Pod my-cluster-4dabb7d5-cruise-control- will have stable 0 replicas
2022-04-04 08:55:54 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 19 polls
2022-04-04 08:55:55 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 18 polls
2022-04-04 08:55:56 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 17 polls
2022-04-04 08:55:57 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 16 polls
2022-04-04 08:55:58 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 15 polls
2022-04-04 08:55:59 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 14 polls
2022-04-04 08:56:00 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 13 polls
2022-04-04 08:56:01 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 12 polls
2022-04-04 08:56:02 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 11 polls
2022-04-04 08:56:03 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 10 polls
2022-04-04 08:56:04 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 9 polls
2022-04-04 08:56:05 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 8 polls
2022-04-04 08:56:06 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 7 polls
2022-04-04 08:56:07 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 6 polls
2022-04-04 08:56:08 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 5 polls
2022-04-04 08:56:09 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 4 polls
2022-04-04 08:56:10 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 3 polls
2022-04-04 08:56:11 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 2 polls
2022-04-04 08:56:12 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 1 polls
2022-04-04 08:56:13 [main] [32mINFO [m [PodUtils:217] Pod replicas are stable for 20 polls intervals
2022-04-04 08:56:13 [main] [32mINFO [m [PodUtils:228] Pod my-cluster-4dabb7d5-cruise-control- has 0 replicas
2022-04-04 08:56:13 [main] [32mINFO [m [CruiseControlConfigurationST:123] Verifying that in Kafka config map there is no configuration to cruise control metric reporter
2022-04-04 08:58:13 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Verify that kafka configuration {cluster-name=my-cluster-4dabb7d5} has correct cruise control metric reporter properties, null
io.strimzi.test.WaitException: Timeout after 120000 ms waiting for Verify that kafka configuration {cluster-name=my-cluster-4dabb7d5} has correct cruise control metric reporter properties
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.specific.CruiseControlUtils.verifyCruiseControlMetricReporterConfigurationInKafkaConfigMapIsPresent(CruiseControlUtils.java:83)
	at io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.lambda$testDeployAndUnDeployCruiseControl$1(CruiseControlConfigurationST.java:124)
	at org.junit.jupiter.api.AssertThrows.assertThrows(AssertThrows.java:55)
	at org.junit.jupiter.api.AssertThrows.assertThrows(AssertThrows.java:37)
	at org.junit.jupiter.api.Assertions.assertThrows(Assertions.java:3082)
	at io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testDeployAndUnDeployCruiseControl(CruiseControlConfigurationST.java:124)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-04 08:58:13 [main] [32mINFO [m [CruiseControlConfigurationST:126] Cruise Control topics will not be deleted and will stay in the Kafka cluster
2022-04-04 08:58:13 [main] [32mINFO [m [CruiseControlConfigurationST:130] Adding Cruise Control to the classic Kafka.
2022-04-04 08:58:13 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-4dabb7d5-kafka rolling update
2022-04-04 08:59:28 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-4dabb7d5-kafka has been successfully rolled
2022-04-04 08:59:28 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-4dabb7d5-kafka to be ready
2022-04-04 08:59:50 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4dabb7d5 will have desired state: Ready
2022-04-04 08:59:50 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4dabb7d5 is in desired state: Ready
2022-04-04 08:59:50 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-4dabb7d5 is ready
2022-04-04 08:59:50 [main] [32mINFO [m [CruiseControlConfigurationST:136] Verifying that in Kafka config map there is configuration to cruise control metric reporter
2022-04-04 08:59:50 [main] [32mINFO [m [CruiseControlConfigurationST:139] Verifying that Cruise Control topics are created after CC is instantiated.
2022-04-04 08:59:50 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:59:50 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeployAndUnDeployCruiseControl
2022-04-04 08:59:50 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-4dabb7d5 in namespace namespace-12
2022-04-04 08:59:50 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-12, for cruise control Kafka cluster my-cluster-4dabb7d5
2022-04-04 09:00:00 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:00:00 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-12 for test case:testDeployAndUnDeployCruiseControl
2022-04-04 09:00:43 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testDeployAndUnDeployCruiseControl-FINISHED
2022-04-04 09:00:43 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:00:43 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:00:43 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationPerformanceOptions-STARTED
2022-04-04 09:00:43 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:00:43 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-13 for test case:testConfigurationPerformanceOptions
2022-04-04 09:00:43 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-13
2022-04-04 09:00:43 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-13
2022-04-04 09:00:43 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-13
2022-04-04 09:00:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d91ef45c in namespace namespace-13
2022-04-04 09:00:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-13
2022-04-04 09:00:43 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d91ef45c will have desired state: Ready
2022-04-04 09:02:24 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d91ef45c is in desired state: Ready
2022-04-04 09:02:24 [main] [32mINFO [m [CruiseControlConfigurationST:271] Changing cruise control performance tuning options
2022-04-04 09:02:24 [main] [32mINFO [m [CruiseControlConfigurationST:277] Verifying that CC pod is rolling, after changing options
2022-04-04 09:02:24 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-d91ef45c-cruise-control rolling update
2022-04-04 09:02:59 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d91ef45c-cruise-control will be ready
2022-04-04 09:02:59 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d91ef45c-cruise-control is ready
2022-04-04 09:03:09 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-d91ef45c-cruise-control rolling update finished
2022-04-04 09:03:09 [main] [32mINFO [m [CruiseControlConfigurationST:280] Verifying that Kafka pods did not roll
2022-04-04 09:03:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 50
2022-04-04 09:03:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 49
2022-04-04 09:03:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 48
2022-04-04 09:03:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 47
2022-04-04 09:03:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 46
2022-04-04 09:03:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 45
2022-04-04 09:03:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 44
2022-04-04 09:03:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 43
2022-04-04 09:03:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 42
2022-04-04 09:03:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 41
2022-04-04 09:03:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 40
2022-04-04 09:03:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 39
2022-04-04 09:03:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 38
2022-04-04 09:03:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 37
2022-04-04 09:03:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 36
2022-04-04 09:03:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 35
2022-04-04 09:03:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 34
2022-04-04 09:03:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 33
2022-04-04 09:03:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 32
2022-04-04 09:03:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 31
2022-04-04 09:03:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 30
2022-04-04 09:03:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 29
2022-04-04 09:03:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 28
2022-04-04 09:03:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 27
2022-04-04 09:03:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 26
2022-04-04 09:03:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 25
2022-04-04 09:03:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 24
2022-04-04 09:03:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 23
2022-04-04 09:03:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 22
2022-04-04 09:03:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 21
2022-04-04 09:03:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 20
2022-04-04 09:03:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 19
2022-04-04 09:03:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 18
2022-04-04 09:03:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 17
2022-04-04 09:03:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 16
2022-04-04 09:03:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 15
2022-04-04 09:03:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 14
2022-04-04 09:03:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 13
2022-04-04 09:03:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 12
2022-04-04 09:03:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 11
2022-04-04 09:03:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 10
2022-04-04 09:03:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 9
2022-04-04 09:03:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 8
2022-04-04 09:03:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 7
2022-04-04 09:03:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 6
2022-04-04 09:03:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 5
2022-04-04 09:03:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 4
2022-04-04 09:03:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 3
2022-04-04 09:03:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 2
2022-04-04 09:03:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 1
2022-04-04 09:03:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d91ef45c-kafka-0=b3ef5168-e1fe-4fea-94df-7f03cce92901, my-cluster-d91ef45c-kafka-2=06c0b33d-1362-4803-abc9-f75c7155c7d7, my-cluster-d91ef45c-kafka-1=d47c17e5-b4e4-4a8d-90f4-b1589502b8fc} pods didn't roll. Remaining seconds for stability: 0
2022-04-04 09:03:59 [main] [32mINFO [m [CruiseControlConfigurationST:283] Verifying new configuration in the Kafka CR
2022-04-04 09:03:59 [main] [32mINFO [m [CruiseControlConfigurationST:300] Verifying Cruise control performance options are set in Kafka CR
2022-04-04 09:03:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:03:59 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigurationPerformanceOptions
2022-04-04 09:03:59 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d91ef45c in namespace namespace-13
2022-04-04 09:03:59 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-13, for cruise control Kafka cluster my-cluster-d91ef45c
2022-04-04 09:04:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:04:09 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-13 for test case:testConfigurationPerformanceOptions
2022-04-04 09:04:52 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationPerformanceOptions-FINISHED
2022-04-04 09:04:52 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:04:52 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:04:52 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationReflection-STARTED
2022-04-04 09:04:52 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:04:52 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-14 for test case:testConfigurationReflection
2022-04-04 09:04:52 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-14
2022-04-04 09:04:52 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-14
2022-04-04 09:04:52 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-14
2022-04-04 09:04:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-120353ea in namespace namespace-14
2022-04-04 09:04:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-14
2022-04-04 09:04:52 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-120353ea will have desired state: Ready
2022-04-04 09:06:33 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-120353ea is in desired state: Ready
2022-04-04 09:06:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-14 exec my-cluster-120353ea-cruise-control-8558b8899b-w5ljr -- /bin/bash -c cat /tmp/cruisecontrol.properties
2022-04-04 09:06:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 09:06:34 [main] [32mINFO [m [CruiseControlConfigurationST:221] Verifying that all configuration in the cruise control container matching the cruise control file /tmp/cruisecontrol.properties properties
2022-04-04 09:06:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:06:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigurationReflection
2022-04-04 09:06:34 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-120353ea in namespace namespace-14
2022-04-04 09:06:34 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-14, for cruise control Kafka cluster my-cluster-120353ea
2022-04-04 09:06:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:06:44 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-14 for test case:testConfigurationReflection
2022-04-04 09:07:26 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationReflection-FINISHED
2022-04-04 09:07:26 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:07:26 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:07:26 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationDiskChangeDoNotTriggersRollingUpdateOfKafkaPods-STARTED
2022-04-04 09:07:26 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:07:26 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-15 for test case:testConfigurationDiskChangeDoNotTriggersRollingUpdateOfKafkaPods
2022-04-04 09:07:26 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-15
2022-04-04 09:07:26 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-15
2022-04-04 09:07:26 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-15
2022-04-04 09:07:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-46976150 in namespace namespace-15
2022-04-04 09:07:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-15
2022-04-04 09:07:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-46976150 will have desired state: Ready
2022-04-04 09:08:58 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-46976150 is in desired state: Ready
2022-04-04 09:08:58 [main] [32mINFO [m [CruiseControlConfigurationST:157] Changing the broker capacity of the cruise control
2022-04-04 09:08:58 [main] [32mINFO [m [CruiseControlConfigurationST:168] Verifying that CC pod is rolling, because of change size of disk
2022-04-04 09:08:58 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-46976150-cruise-control rolling update
2022-04-04 09:09:28 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-46976150-cruise-control will be ready
2022-04-04 09:09:28 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-46976150-cruise-control is ready
2022-04-04 09:09:38 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-46976150-cruise-control rolling update finished
2022-04-04 09:09:38 [main] [32mINFO [m [CruiseControlConfigurationST:171] Verifying that Kafka pods did not roll
2022-04-04 09:09:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 50
2022-04-04 09:09:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 49
2022-04-04 09:09:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 48
2022-04-04 09:09:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 47
2022-04-04 09:09:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 46
2022-04-04 09:09:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 45
2022-04-04 09:09:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 44
2022-04-04 09:09:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 43
2022-04-04 09:09:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 42
2022-04-04 09:09:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 41
2022-04-04 09:09:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 40
2022-04-04 09:09:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 39
2022-04-04 09:09:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 38
2022-04-04 09:09:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 37
2022-04-04 09:09:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 36
2022-04-04 09:09:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 35
2022-04-04 09:09:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 34
2022-04-04 09:09:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 33
2022-04-04 09:09:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 32
2022-04-04 09:09:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 31
2022-04-04 09:09:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 30
2022-04-04 09:09:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 29
2022-04-04 09:10:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 28
2022-04-04 09:10:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 27
2022-04-04 09:10:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 26
2022-04-04 09:10:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 25
2022-04-04 09:10:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 24
2022-04-04 09:10:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 23
2022-04-04 09:10:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 22
2022-04-04 09:10:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 21
2022-04-04 09:10:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 20
2022-04-04 09:10:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 19
2022-04-04 09:10:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 18
2022-04-04 09:10:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 17
2022-04-04 09:10:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 16
2022-04-04 09:10:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 15
2022-04-04 09:10:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 14
2022-04-04 09:10:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 13
2022-04-04 09:10:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 12
2022-04-04 09:10:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 11
2022-04-04 09:10:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 10
2022-04-04 09:10:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 9
2022-04-04 09:10:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 8
2022-04-04 09:10:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 7
2022-04-04 09:10:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 6
2022-04-04 09:10:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 5
2022-04-04 09:10:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 4
2022-04-04 09:10:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 3
2022-04-04 09:10:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 2
2022-04-04 09:10:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 1
2022-04-04 09:10:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-46976150-kafka-1=bb52fa16-4a86-4ff7-ac20-e4c235686682, my-cluster-46976150-kafka-0=711732ba-4e62-4ebe-b597-b53f547d7d79, my-cluster-46976150-kafka-2=70ca2c9e-fdc5-43b6-bf8f-4ac5a17db5d6} pods didn't roll. Remaining seconds for stability: 0
2022-04-04 09:10:28 [main] [32mINFO [m [CruiseControlConfigurationST:174] Verifying new configuration in the Kafka CR
2022-04-04 09:10:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:10:28 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigurationDiskChangeDoNotTriggersRollingUpdateOfKafkaPods
2022-04-04 09:10:28 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-46976150 in namespace namespace-15
2022-04-04 09:10:28 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-15, for cruise control Kafka cluster my-cluster-46976150
2022-04-04 09:10:38 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:10:38 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-15 for test case:testConfigurationDiskChangeDoNotTriggersRollingUpdateOfKafkaPods
2022-04-04 09:11:21 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationDiskChangeDoNotTriggersRollingUpdateOfKafkaPods-FINISHED
2022-04-04 09:11:21 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:11:21 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:11:21 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testCapacityFile-STARTED
2022-04-04 09:11:21 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:11:21 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-16 for test case:testCapacityFile
2022-04-04 09:11:21 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-16
2022-04-04 09:11:21 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-16
2022-04-04 09:11:21 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-16
2022-04-04 09:11:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5d4074dc in namespace namespace-16
2022-04-04 09:11:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-16
2022-04-04 09:11:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5d4074dc will have desired state: Ready
2022-04-04 09:13:00 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5d4074dc is in desired state: Ready
2022-04-04 09:13:00 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-16 exec my-cluster-5d4074dc-cruise-control-df45fdfff-wzz2n -- /bin/bash -c cat /tmp/capacity.json
2022-04-04 09:13:00 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 09:13:00 [main] [32mINFO [m [CruiseControlConfigurationST:80] We got only one configuration of broker-capacities
2022-04-04 09:13:00 [main] [32mINFO [m [CruiseControlConfigurationST:83] Verifying cruise control configuration.
2022-04-04 09:13:00 [main] [32mINFO [m [CruiseControlConfigurationST:92] Verifying default cruise control capacities
2022-04-04 09:13:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:13:00 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCapacityFile
2022-04-04 09:13:00 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5d4074dc in namespace namespace-16
2022-04-04 09:13:00 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-16, for cruise control Kafka cluster my-cluster-5d4074dc
2022-04-04 09:13:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:13:10 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-16 for test case:testCapacityFile
2022-04-04 09:13:53 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testCapacityFile-FINISHED
2022-04-04 09:13:53 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:13:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:13:53 [main] [32mINFO [m [ResourceManager:346] In context CruiseControlConfigurationST is everything deleted.
2022-04-04 09:13:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,436.521 s - in io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST
[[1;34mINFO[m] Running io.strimzi.systemtest.cruisecontrol.CruiseControlST
2022-04-04 09:13:59 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: cruise-control-st
2022-04-04 09:13:59 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: cruise-control-st
2022-04-04 09:13:59 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: cruise-control-st
2022-04-04 09:13:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:13:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlTopicExclusion-STARTED
2022-04-04 09:13:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:13:59 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-17 for test case:testCruiseControlTopicExclusion
2022-04-04 09:13:59 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-17
2022-04-04 09:13:59 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-17
2022-04-04 09:13:59 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-17
2022-04-04 09:13:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ec109b82 in namespace namespace-17
2022-04-04 09:13:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-17
2022-04-04 09:13:59 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ec109b82 will have desired state: Ready
2022-04-04 09:15:35 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ec109b82 is in desired state: Ready
2022-04-04 09:15:35 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic excluded-topic-1 in namespace namespace-17
2022-04-04 09:15:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-17
2022-04-04 09:15:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: excluded-topic-1 will have desired state: Ready
2022-04-04 09:15:36 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: excluded-topic-1 is in desired state: Ready
2022-04-04 09:15:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic excluded-topic-2 in namespace namespace-17
2022-04-04 09:15:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-17
2022-04-04 09:15:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: excluded-topic-2 will have desired state: Ready
2022-04-04 09:15:37 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: excluded-topic-2 is in desired state: Ready
2022-04-04 09:15:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic included-topic in namespace namespace-17
2022-04-04 09:15:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-17
2022-04-04 09:15:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: included-topic will have desired state: Ready
2022-04-04 09:15:38 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: included-topic is in desired state: Ready
2022-04-04 09:15:38 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-ec109b82 in namespace namespace-17
2022-04-04 09:15:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-17
2022-04-04 09:15:38 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-ec109b82 will have desired state: PendingProposal
2022-04-04 09:15:39 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-ec109b82 is in desired state: PendingProposal
2022-04-04 09:15:39 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-ec109b82 will have desired state: ProposalReady
2022-04-04 09:21:24 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-ec109b82 is in desired state: ProposalReady
2022-04-04 09:21:24 [main] [32mINFO [m [CruiseControlST:208] Checking status of KafkaRebalance
2022-04-04 09:21:24 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #4(test) KafkaRebalance(cruise-control-st/my-cluster-ec109b82): Annotating KafkaRebalance:my-cluster-ec109b82 with annotation approve
2022-04-04 09:21:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-ec109b82 will have desired state: Ready
2022-04-04 09:22:49 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-ec109b82 is in desired state: Ready
2022-04-04 09:22:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:22:49 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlTopicExclusion
2022-04-04 09:22:49 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic excluded-topic-2 in namespace namespace-17
2022-04-04 09:22:49 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic excluded-topic-1 in namespace namespace-17
2022-04-04 09:22:49 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic included-topic in namespace namespace-17
2022-04-04 09:22:49 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ec109b82 in namespace namespace-17
2022-04-04 09:22:49 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-ec109b82 in namespace namespace-17
2022-04-04 09:22:49 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-17, for cruise control Kafka cluster my-cluster-ec109b82
2022-04-04 09:22:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:22:59 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-17 for test case:testCruiseControlTopicExclusion
2022-04-04 09:23:42 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlTopicExclusion-FINISHED
2022-04-04 09:23:42 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:23:42 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:23:42 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlIntraBrokerBalancingWithoutSpecifyingJBODStorage-STARTED
2022-04-04 09:23:42 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:23:42 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-18 for test case:testCruiseControlIntraBrokerBalancingWithoutSpecifyingJBODStorage
2022-04-04 09:23:42 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-18
2022-04-04 09:23:42 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-18
2022-04-04 09:23:42 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-18
2022-04-04 09:23:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3e4dd25e in namespace namespace-18
2022-04-04 09:23:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-18
2022-04-04 09:23:42 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3e4dd25e will have desired state: Ready
2022-04-04 09:25:20 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3e4dd25e is in desired state: Ready
2022-04-04 09:25:20 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-3e4dd25e in namespace namespace-18
2022-04-04 09:25:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-18
2022-04-04 09:25:20 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-3e4dd25e will have desired state: NotReady
2022-04-04 09:25:21 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-3e4dd25e is in desired state: NotReady
2022-04-04 09:25:21 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:25:21 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlIntraBrokerBalancingWithoutSpecifyingJBODStorage
2022-04-04 09:25:21 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-3e4dd25e in namespace namespace-18
2022-04-04 09:25:21 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3e4dd25e in namespace namespace-18
2022-04-04 09:25:21 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-18, for cruise control Kafka cluster my-cluster-3e4dd25e
2022-04-04 09:25:31 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:25:31 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-18 for test case:testCruiseControlIntraBrokerBalancingWithoutSpecifyingJBODStorage
2022-04-04 09:26:15 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlIntraBrokerBalancingWithoutSpecifyingJBODStorage-FINISHED
2022-04-04 09:26:15 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:26:15 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:26:15 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testAutoCreationOfCruiseControlTopics-STARTED
2022-04-04 09:26:15 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:26:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b8bb08a8 in namespace cruise-control-st
2022-04-04 09:26:15 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b8bb08a8 will have desired state: Ready
2022-04-04 09:27:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b8bb08a8 is in desired state: Ready
2022-04-04 09:27:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: strimzi.cruisecontrol.metrics will have desired state: Ready
2022-04-04 09:27:45 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: strimzi.cruisecontrol.metrics is in desired state: Ready
2022-04-04 09:27:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: strimzi.cruisecontrol.modeltrainingsamples will have desired state: Ready
2022-04-04 09:27:45 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: strimzi.cruisecontrol.modeltrainingsamples is in desired state: Ready
2022-04-04 09:27:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: strimzi.cruisecontrol.partitionmetricsamples will have desired state: Ready
2022-04-04 09:27:45 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: strimzi.cruisecontrol.partitionmetricsamples is in desired state: Ready
2022-04-04 09:27:45 [main] [32mINFO [m [CruiseControlST:96] Checking partitions and replicas for strimzi.cruisecontrol.metrics
2022-04-04 09:27:45 [main] [32mINFO [m [CruiseControlST:100] Checking partitions and replicas for strimzi.cruisecontrol.modeltrainingsamples
2022-04-04 09:27:45 [main] [32mINFO [m [CruiseControlST:104] Checking partitions and replicas for strimzi.cruisecontrol.partitionmetricsamples
2022-04-04 09:27:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:27:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoCreationOfCruiseControlTopics
2022-04-04 09:27:45 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b8bb08a8 in namespace cruise-control-st
2022-04-04 09:27:45 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace cruise-control-st, for cruise control Kafka cluster my-cluster-b8bb08a8
2022-04-04 09:27:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:27:55 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testAutoCreationOfCruiseControlTopics-FINISHED
2022-04-04 09:27:55 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:27:55 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:27:55 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlReplicaMovementStrategy-STARTED
2022-04-04 09:27:55 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:27:55 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-19 for test case:testCruiseControlReplicaMovementStrategy
2022-04-04 09:27:55 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-19
2022-04-04 09:27:55 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-19
2022-04-04 09:27:55 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-19
2022-04-04 09:27:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a54ed558 in namespace namespace-19
2022-04-04 09:27:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-19
2022-04-04 09:27:55 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a54ed558 will have desired state: Ready
2022-04-04 09:29:39 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a54ed558 is in desired state: Ready
2022-04-04 09:29:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a54ed558-kafka-clients in namespace namespace-19
2022-04-04 09:29:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-19
2022-04-04 09:29:39 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a54ed558-kafka-clients will be ready
2022-04-04 09:29:41 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a54ed558-kafka-clients is ready
2022-04-04 09:29:41 [main] [32mINFO [m [CruiseControlST:234] Check for default CruiseControl replicaMovementStrategy in pod configuration file.
2022-04-04 09:29:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-19 exec my-cluster-a54ed558-cruise-control-75c7df5f85-94crh -c cruise-control -- cat /tmp/cruisecontrol.properties
2022-04-04 09:29:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 09:29:41 [main] [32mINFO [m [CruiseControlST:248] Set non-default CruiseControl replicaMovementStrategies to KafkaRebalance resource.
2022-04-04 09:29:41 [main] [32mINFO [m [CruiseControlST:252] Verifying that CC pod is rolling, because of change size of disk
2022-04-04 09:29:41 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-a54ed558-cruise-control rolling update
2022-04-04 09:30:16 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a54ed558-cruise-control will be ready
2022-04-04 09:30:16 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a54ed558-cruise-control is ready
2022-04-04 09:30:27 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-a54ed558-cruise-control rolling update finished
2022-04-04 09:30:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-19 exec my-cluster-a54ed558-cruise-control-5b954fd965-qjlc4 -c cruise-control -- cat /tmp/cruisecontrol.properties
2022-04-04 09:30:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 09:30:27 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:30:27 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlReplicaMovementStrategy
2022-04-04 09:30:27 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a54ed558-kafka-clients in namespace namespace-19
2022-04-04 09:30:27 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a54ed558 in namespace namespace-19
2022-04-04 09:30:27 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-19, for cruise control Kafka cluster my-cluster-a54ed558
2022-04-04 09:31:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:31:17 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-19 for test case:testCruiseControlReplicaMovementStrategy
2022-04-04 09:31:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlReplicaMovementStrategy-FINISHED
2022-04-04 09:31:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:31:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:31:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithSingleNodeKafka-STARTED
2022-04-04 09:31:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:31:22 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-20 for test case:testCruiseControlWithSingleNodeKafka
2022-04-04 09:31:22 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-20
2022-04-04 09:31:22 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-20
2022-04-04 09:31:22 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-20
2022-04-04 09:31:22 [main] [32mINFO [m [CruiseControlST:169] Deploying single node Kafka with CruiseControl
2022-04-04 09:31:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7abcd5c6 in namespace namespace-20
2022-04-04 09:31:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-20
2022-04-04 09:31:24 [main] [32mINFO [m [CruiseControlST:178] Increasing Kafka nodes to 3
2022-04-04 09:31:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7abcd5c6 will have desired state: Ready
2022-04-04 09:32:51 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7abcd5c6 is in desired state: Ready
2022-04-04 09:32:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:32:51 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlWithSingleNodeKafka
2022-04-04 09:32:51 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7abcd5c6 in namespace namespace-20
2022-04-04 09:32:51 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-20, for cruise control Kafka cluster my-cluster-7abcd5c6
2022-04-04 09:33:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:33:01 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-20 for test case:testCruiseControlWithSingleNodeKafka
2022-04-04 09:33:44 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithSingleNodeKafka-FINISHED
2022-04-04 09:33:44 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:33:44 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:33:44 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithRebalanceResourceAndRefreshAnnotation-STARTED
2022-04-04 09:33:44 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:33:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-24b8508d in namespace cruise-control-st
2022-04-04 09:33:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-24b8508d will have desired state: Ready
2022-04-04 09:35:22 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-24b8508d is in desired state: Ready
2022-04-04 09:35:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-24b8508d in namespace cruise-control-st
2022-04-04 09:35:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-24b8508d will have desired state: PendingProposal
2022-04-04 09:35:23 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-24b8508d is in desired state: PendingProposal
2022-04-04 09:35:23 [main] [32mINFO [m [KafkaRebalanceUtils:75] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-24b8508d): ============================================================================
2022-04-04 09:35:23 [main] [32mINFO [m [KafkaRebalanceUtils:76] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-24b8508d): PendingProposal
2022-04-04 09:35:23 [main] [32mINFO [m [KafkaRebalanceUtils:77] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-24b8508d): ============================================================================
2022-04-04 09:35:23 [main] [32mINFO [m [KafkaRebalanceUtils:81] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-24b8508d): Verifying that KafkaRebalance resource is in PendingProposal state
2022-04-04 09:35:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-24b8508d will have desired state: PendingProposal
2022-04-04 09:35:23 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-24b8508d is in desired state: PendingProposal
2022-04-04 09:35:23 [main] [32mINFO [m [KafkaRebalanceUtils:85] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-24b8508d): Verifying that KafkaRebalance resource is in ProposalReady state
2022-04-04 09:35:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-24b8508d will have desired state: ProposalReady
2022-04-04 09:41:13 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-24b8508d is in desired state: ProposalReady
2022-04-04 09:41:13 [main] [32mINFO [m [KafkaRebalanceUtils:90] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-24b8508d): ============================================================================
2022-04-04 09:41:13 [main] [32mINFO [m [KafkaRebalanceUtils:91] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-24b8508d): ProposalReady
2022-04-04 09:41:13 [main] [32mINFO [m [KafkaRebalanceUtils:92] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-24b8508d): ============================================================================
2022-04-04 09:41:13 [main] [32mINFO [m [KafkaRebalanceUtils:94] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-24b8508d): Triggering the rebalance with annotation strimzi.io/rebalance=approve of KafkaRebalance resource
2022-04-04 09:41:13 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-24b8508d): Annotating KafkaRebalance:my-cluster-24b8508d with annotation approve
2022-04-04 09:41:13 [main] [32mINFO [m [KafkaRebalanceUtils:98] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-24b8508d): Response from the annotation process kafkarebalance.kafka.strimzi.io/my-cluster-24b8508d annotated
2022-04-04 09:41:13 [main] [32mINFO [m [KafkaRebalanceUtils:100] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-24b8508d): Verifying that annotation triggers the Rebalancing state
2022-04-04 09:41:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-24b8508d will have desired state: Rebalancing
2022-04-04 09:41:14 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-24b8508d is in desired state: Rebalancing
2022-04-04 09:41:14 [main] [32mINFO [m [KafkaRebalanceUtils:104] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-24b8508d): Verifying that KafkaRebalance is in the Ready state
2022-04-04 09:41:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-24b8508d will have desired state: Ready
2022-04-04 09:43:08 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-24b8508d is in desired state: Ready
2022-04-04 09:43:08 [main] [32mINFO [m [CruiseControlST:152] Annotating KafkaRebalance: my-cluster-24b8508d with 'refresh' anno
2022-04-04 09:43:08 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #6(test) KafkaRebalance(cruise-control-st/my-cluster-24b8508d): Annotating KafkaRebalance:my-cluster-24b8508d with annotation refresh
2022-04-04 09:43:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-24b8508d will have desired state: ProposalReady
2022-04-04 09:43:09 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-24b8508d is in desired state: ProposalReady
2022-04-04 09:43:09 [main] [32mINFO [m [CruiseControlST:156] Trying rebalancing process again
2022-04-04 09:43:09 [main] [32mINFO [m [KafkaRebalanceUtils:75] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-24b8508d): ============================================================================
2022-04-04 09:43:09 [main] [32mINFO [m [KafkaRebalanceUtils:76] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-24b8508d): ProposalReady
2022-04-04 09:43:09 [main] [32mINFO [m [KafkaRebalanceUtils:77] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-24b8508d): ============================================================================
2022-04-04 09:43:09 [main] [32mINFO [m [KafkaRebalanceUtils:90] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-24b8508d): ============================================================================
2022-04-04 09:43:09 [main] [32mINFO [m [KafkaRebalanceUtils:91] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-24b8508d): ProposalReady
2022-04-04 09:43:09 [main] [32mINFO [m [KafkaRebalanceUtils:92] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-24b8508d): ============================================================================
2022-04-04 09:43:09 [main] [32mINFO [m [KafkaRebalanceUtils:94] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-24b8508d): Triggering the rebalance with annotation strimzi.io/rebalance=approve of KafkaRebalance resource
2022-04-04 09:43:09 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-24b8508d): Annotating KafkaRebalance:my-cluster-24b8508d with annotation approve
2022-04-04 09:43:09 [main] [32mINFO [m [KafkaRebalanceUtils:98] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-24b8508d): Response from the annotation process kafkarebalance.kafka.strimzi.io/my-cluster-24b8508d annotated
2022-04-04 09:43:09 [main] [32mINFO [m [KafkaRebalanceUtils:100] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-24b8508d): Verifying that annotation triggers the Rebalancing state
2022-04-04 09:43:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-24b8508d will have desired state: Rebalancing
2022-04-04 09:43:10 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-24b8508d is in desired state: Rebalancing
2022-04-04 09:43:10 [main] [32mINFO [m [KafkaRebalanceUtils:104] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-24b8508d): Verifying that KafkaRebalance is in the Ready state
2022-04-04 09:43:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-24b8508d will have desired state: Ready
2022-04-04 09:43:15 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-24b8508d is in desired state: Ready
2022-04-04 09:43:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:43:15 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlWithRebalanceResourceAndRefreshAnnotation
2022-04-04 09:43:15 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-24b8508d in namespace cruise-control-st
2022-04-04 09:43:15 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-24b8508d in namespace cruise-control-st
2022-04-04 09:43:15 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace cruise-control-st, for cruise control Kafka cluster my-cluster-24b8508d
2022-04-04 09:43:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:43:25 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithRebalanceResourceAndRefreshAnnotation-FINISHED
2022-04-04 09:43:25 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:43:25 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:43:25 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithApiSecurityDisabled-STARTED
2022-04-04 09:43:25 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:43:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c265d356 in namespace cruise-control-st
2022-04-04 09:43:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c265d356 will have desired state: Ready
2022-04-04 09:45:11 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c265d356 is in desired state: Ready
2022-04-04 09:45:11 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-c265d356 in namespace cruise-control-st
2022-04-04 09:45:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-c265d356 will have desired state: PendingProposal
2022-04-04 09:45:12 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-c265d356 is in desired state: PendingProposal
2022-04-04 09:45:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-c265d356 will have desired state: ProposalReady
2022-04-04 09:51:02 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-c265d356 is in desired state: ProposalReady
2022-04-04 09:51:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:51:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlWithApiSecurityDisabled
2022-04-04 09:51:02 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-c265d356 in namespace cruise-control-st
2022-04-04 09:51:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c265d356 in namespace cruise-control-st
2022-04-04 09:51:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace cruise-control-st, for cruise control Kafka cluster my-cluster-c265d356
2022-04-04 09:51:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:51:12 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithApiSecurityDisabled-FINISHED
2022-04-04 09:51:12 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:51:12 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:51:12 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlIntraBrokerBalancing-STARTED
2022-04-04 09:51:12 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:51:12 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-21 for test case:testCruiseControlIntraBrokerBalancing
2022-04-04 09:51:12 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-21
2022-04-04 09:51:12 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-21
2022-04-04 09:51:12 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-21
2022-04-04 09:51:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-027cdf06 in namespace namespace-21
2022-04-04 09:51:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-21
2022-04-04 09:51:12 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-027cdf06 will have desired state: Ready
2022-04-04 09:54:00 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-027cdf06 is in desired state: Ready
2022-04-04 09:54:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-027cdf06 in namespace namespace-21
2022-04-04 09:54:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-21
2022-04-04 09:54:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-027cdf06 will have desired state: PendingProposal
2022-04-04 09:54:01 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-027cdf06 is in desired state: PendingProposal
2022-04-04 09:54:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-027cdf06 will have desired state: ProposalReady
2022-04-04 09:55:50 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-027cdf06 is in desired state: ProposalReady
2022-04-04 09:55:50 [main] [32mINFO [m [CruiseControlST:292] Checking status of KafkaRebalance
2022-04-04 09:55:50 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:55:50 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlIntraBrokerBalancing
2022-04-04 09:55:50 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-027cdf06 in namespace namespace-21
2022-04-04 09:55:50 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-027cdf06 in namespace namespace-21
2022-04-04 09:55:50 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-21, for cruise control Kafka cluster my-cluster-027cdf06
2022-04-04 09:56:00 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:56:00 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-21 for test case:testCruiseControlIntraBrokerBalancing
2022-04-04 09:56:43 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlIntraBrokerBalancing-FINISHED
2022-04-04 09:56:43 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:56:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:56:43 [main] [32mINFO [m [ResourceManager:346] In context CruiseControlST is everything deleted.
2022-04-04 09:56:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2,571.018 s - in io.strimzi.systemtest.cruisecontrol.CruiseControlST
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.KafkaST
2022-04-04 09:56:50 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: kafka-st
2022-04-04 09:56:50 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: kafka-st
2022-04-04 09:56:50 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: kafka-st
2022-04-04 09:56:50 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:56:50 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testKafkaOffsetsReplicationFactorHigherThanReplicas-STARTED
2022-04-04 09:56:50 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:56:50 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-22 for test case:testKafkaOffsetsReplicationFactorHigherThanReplicas
2022-04-04 09:56:50 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-22
2022-04-04 09:56:50 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-22
2022-04-04 09:56:50 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-22
2022-04-04 09:56:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-8f668ff5 in namespace namespace-22
2022-04-04 09:56:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-22
2022-04-04 09:56:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:56:52 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaOffsetsReplicationFactorHigherThanReplicas
2022-04-04 09:56:52 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-8f668ff5 in namespace namespace-22
2022-04-04 09:57:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:57:02 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-22 for test case:testKafkaOffsetsReplicationFactorHigherThanReplicas
2022-04-04 09:57:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testKafkaOffsetsReplicationFactorHigherThanReplicas-FINISHED
2022-04-04 09:57:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:57:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:57:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testEntityOperatorWithoutUserOperator-STARTED
2022-04-04 09:57:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:57:07 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-23 for test case:testEntityOperatorWithoutUserOperator
2022-04-04 09:57:07 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-23
2022-04-04 09:57:07 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-23
2022-04-04 09:57:07 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-23
2022-04-04 09:57:07 [main] [32mINFO [m [KafkaST:787] Deploying Kafka cluster without UO in EO
2022-04-04 09:57:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-847aa74d in namespace namespace-23
2022-04-04 09:57:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-23
2022-04-04 09:57:07 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-847aa74d will have desired state: Ready
2022-04-04 09:58:19 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-847aa74d is in desired state: Ready
2022-04-04 09:58:19 [main] [32mINFO [m [AbstractST:478] Search in strimzi-cluster-operator log for errors in last 71 seconds
2022-04-04 09:58:19 [main] [32mINFO [m [BaseCmdKubeClient:481] Exception not found
2022-04-04 09:58:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:58:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testEntityOperatorWithoutUserOperator
2022-04-04 09:58:19 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-847aa74d in namespace namespace-23
2022-04-04 09:58:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:58:29 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-23 for test case:testEntityOperatorWithoutUserOperator
2022-04-04 09:59:12 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testEntityOperatorWithoutUserOperator-FINISHED
2022-04-04 09:59:12 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:59:12 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:59:12 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testEntityOperatorWithoutTopicOperator-STARTED
2022-04-04 09:59:12 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:59:12 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-24 for test case:testEntityOperatorWithoutTopicOperator
2022-04-04 09:59:12 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-24
2022-04-04 09:59:12 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-24
2022-04-04 09:59:12 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-24
2022-04-04 09:59:12 [main] [32mINFO [m [KafkaST:757] Deploying Kafka cluster without TO in EO
2022-04-04 09:59:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d9703187 in namespace namespace-24
2022-04-04 09:59:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-24
2022-04-04 09:59:12 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d9703187 will have desired state: Ready
2022-04-04 10:00:18 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d9703187 is in desired state: Ready
2022-04-04 10:00:18 [main] [32mINFO [m [AbstractST:478] Search in strimzi-cluster-operator log for errors in last 66 seconds
2022-04-04 10:00:18 [main] [32mINFO [m [BaseCmdKubeClient:481] Exception not found
2022-04-04 10:00:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:00:18 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testEntityOperatorWithoutTopicOperator
2022-04-04 10:00:18 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d9703187 in namespace namespace-24
2022-04-04 10:00:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:00:28 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-24 for test case:testEntityOperatorWithoutTopicOperator
2022-04-04 10:00:55 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testEntityOperatorWithoutTopicOperator-FINISHED
2022-04-04 10:00:55 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:00:55 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:00:55 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testTopicWithoutLabels-STARTED
2022-04-04 10:00:55 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:00:55 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-25 for test case:testTopicWithoutLabels
2022-04-04 10:00:55 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-25
2022-04-04 10:00:55 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-25
2022-04-04 10:00:55 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-25
2022-04-04 10:00:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-6579da54 in namespace namespace-25
2022-04-04 10:00:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-25
2022-04-04 10:00:55 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-6579da54 will have desired state: Ready
2022-04-04 10:02:05 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-6579da54 is in desired state: Ready
2022-04-04 10:02:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic topic-without-labels in namespace namespace-25
2022-04-04 10:02:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-25
2022-04-04 10:02:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-25 exec my-cluster-6579da54-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-04 10:02:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:02:07 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic topic-without-labels deletion
2022-04-04 10:02:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-25 exec my-cluster-6579da54-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-04 10:02:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:02:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:02:10 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTopicWithoutLabels
2022-04-04 10:02:10 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic topic-without-labels in namespace namespace-25
2022-04-04 10:02:10 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-6579da54 in namespace namespace-25
2022-04-04 10:02:20 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:02:20 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-25 for test case:testTopicWithoutLabels
2022-04-04 10:03:03 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testTopicWithoutLabels-FINISHED
2022-04-04 10:03:03 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:03:03 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:03:03 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testRemoveTopicOperatorFromEntityOperator-STARTED
2022-04-04 10:03:03 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:03:03 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-26 for test case:testRemoveTopicOperatorFromEntityOperator
2022-04-04 10:03:03 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-26
2022-04-04 10:03:03 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-26
2022-04-04 10:03:03 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-26
2022-04-04 10:03:03 [main] [32mINFO [m [KafkaST:623] Deploying Kafka cluster my-cluster-0ad08b50
2022-04-04 10:03:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0ad08b50 in namespace namespace-26
2022-04-04 10:03:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-26
2022-04-04 10:03:03 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0ad08b50 will have desired state: Ready
2022-04-04 10:04:22 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0ad08b50 is in desired state: Ready
2022-04-04 10:04:22 [main] [32mINFO [m [PodUtils:154] Waiting when Pod my-cluster-0ad08b50-entity-operator-6d7cf7479c-c9dxf will be deleted
2022-04-04 10:04:32 [main] [32mINFO [m [PodUtils:171] Pod my-cluster-0ad08b50-entity-operator-6d7cf7479c-c9dxf deleted
2022-04-04 10:04:32 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-0ad08b50-entity-operator will be ready
2022-04-04 10:04:49 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-0ad08b50-entity-operator is ready
2022-04-04 10:04:49 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-0ad08b50-entity-operator to be ready
2022-04-04 10:04:59 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-0ad08b50-entity-operator is ready
2022-04-04 10:04:59 [main] [32mINFO [m [PodUtils:201] Wait until Pod my-cluster-0ad08b50-entity-operator will have 1 containers
2022-04-04 10:04:59 [main] [32mINFO [m [PodUtils:205] Pod my-cluster-0ad08b50-entity-operator has 1 containers
2022-04-04 10:04:59 [main] [32mINFO [m [PodUtils:154] Waiting when Pod my-cluster-0ad08b50-entity-operator-56b85c45fd-8th6g will be deleted
2022-04-04 10:05:04 [main] [32mINFO [m [PodUtils:171] Pod my-cluster-0ad08b50-entity-operator-56b85c45fd-8th6g deleted
2022-04-04 10:05:04 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-0ad08b50-entity-operator will be ready
2022-04-04 10:05:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-0ad08b50-entity-operator is ready
2022-04-04 10:05:27 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-0ad08b50-entity-operator to be ready
2022-04-04 10:05:37 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-0ad08b50-entity-operator is ready
2022-04-04 10:05:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:05:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRemoveTopicOperatorFromEntityOperator
2022-04-04 10:05:37 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0ad08b50 in namespace namespace-26
2022-04-04 10:05:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:05:47 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-26 for test case:testRemoveTopicOperatorFromEntityOperator
2022-04-04 10:06:30 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testRemoveTopicOperatorFromEntityOperator-FINISHED
2022-04-04 10:06:30 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:06:30 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:06:30 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testEntityOperatorWithoutUserAndTopicOperators-STARTED
2022-04-04 10:06:30 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:06:30 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-27 for test case:testEntityOperatorWithoutUserAndTopicOperators
2022-04-04 10:06:30 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-27
2022-04-04 10:06:30 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-27
2022-04-04 10:06:30 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-27
2022-04-04 10:06:30 [main] [32mINFO [m [KafkaST:814] Deploying Kafka cluster without UO and TO in EO
2022-04-04 10:06:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-36d66f2a in namespace namespace-27
2022-04-04 10:06:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-27
2022-04-04 10:06:30 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-36d66f2a will have desired state: Ready
2022-04-04 10:07:26 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-36d66f2a is in desired state: Ready
2022-04-04 10:07:26 [main] [32mINFO [m [AbstractST:478] Search in strimzi-cluster-operator log for errors in last 56 seconds
2022-04-04 10:07:26 [main] [32mINFO [m [BaseCmdKubeClient:481] Exception not found
2022-04-04 10:07:26 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:07:26 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testEntityOperatorWithoutUserAndTopicOperators
2022-04-04 10:07:26 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-36d66f2a in namespace namespace-27
2022-04-04 10:07:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:07:36 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-27 for test case:testEntityOperatorWithoutUserAndTopicOperators
2022-04-04 10:08:19 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testEntityOperatorWithoutUserAndTopicOperators-FINISHED
2022-04-04 10:08:19 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:08:19 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:08:19 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testRemoveUserAndTopicOperatorsFromEntityOperator-STARTED
2022-04-04 10:08:19 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:08:19 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-28 for test case:testRemoveUserAndTopicOperatorsFromEntityOperator
2022-04-04 10:08:19 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-28
2022-04-04 10:08:20 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-28
2022-04-04 10:08:20 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-28
2022-04-04 10:08:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-72d6a523 in namespace namespace-28
2022-04-04 10:08:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-28
2022-04-04 10:08:20 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-72d6a523 will have desired state: Ready
2022-04-04 10:09:37 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-72d6a523 is in desired state: Ready
2022-04-04 10:09:37 [main] [32mINFO [m [PodUtils:209] Wait until Pod my-cluster-72d6a523-entity-operator will have stable 0 replicas
2022-04-04 10:09:37 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 10:09:38 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 10:09:39 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 10:09:40 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 10:09:41 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 10:09:42 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 10:09:43 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 10:09:44 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 10:09:45 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 10:09:46 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 10:09:47 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 10:09:48 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 10:09:49 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 10:09:50 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 10:09:51 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 10:09:52 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 10:09:53 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 10:09:54 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 19 polls
2022-04-04 10:09:55 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 18 polls
2022-04-04 10:09:56 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 17 polls
2022-04-04 10:09:57 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 16 polls
2022-04-04 10:09:58 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 15 polls
2022-04-04 10:09:59 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 14 polls
2022-04-04 10:10:00 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 13 polls
2022-04-04 10:10:01 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 12 polls
2022-04-04 10:10:02 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 11 polls
2022-04-04 10:10:03 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 10 polls
2022-04-04 10:10:04 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 9 polls
2022-04-04 10:10:05 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 8 polls
2022-04-04 10:10:06 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 7 polls
2022-04-04 10:10:07 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 6 polls
2022-04-04 10:10:08 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 5 polls
2022-04-04 10:10:09 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 4 polls
2022-04-04 10:10:10 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 3 polls
2022-04-04 10:10:11 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 2 polls
2022-04-04 10:10:12 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 1 polls
2022-04-04 10:10:13 [main] [32mINFO [m [PodUtils:217] Pod replicas are stable for 20 polls intervals
2022-04-04 10:10:13 [main] [32mINFO [m [PodUtils:228] Pod my-cluster-72d6a523-entity-operator has 0 replicas
2022-04-04 10:10:13 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-72d6a523-entity-operator will be ready
2022-04-04 10:10:36 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-72d6a523-entity-operator is ready
2022-04-04 10:10:36 [main] [32mINFO [m [AbstractST:478] Search in strimzi-cluster-operator log for errors in last 136 seconds
2022-04-04 10:10:36 [main] [32mINFO [m [BaseCmdKubeClient:481] Exception not found
2022-04-04 10:10:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:10:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRemoveUserAndTopicOperatorsFromEntityOperator
2022-04-04 10:10:36 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-72d6a523 in namespace namespace-28
2022-04-04 10:10:46 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:10:46 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-28 for test case:testRemoveUserAndTopicOperatorsFromEntityOperator
2022-04-04 10:11:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testRemoveUserAndTopicOperatorsFromEntityOperator-FINISHED
2022-04-04 10:11:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:11:29 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:11:29 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testConsumerOffsetFiles-STARTED
2022-04-04 10:11:29 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:11:29 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-29 for test case:testConsumerOffsetFiles
2022-04-04 10:11:29 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-29
2022-04-04 10:11:30 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-29
2022-04-04 10:11:30 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-29
2022-04-04 10:11:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-424aaee0 in namespace namespace-29
2022-04-04 10:11:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-29
2022-04-04 10:11:30 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-424aaee0 will have desired state: Ready
2022-04-04 10:12:36 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-424aaee0 is in desired state: Ready
2022-04-04 10:12:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-742811948-1781901717 in namespace namespace-29
2022-04-04 10:12:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-29
2022-04-04 10:12:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-742811948-1781901717 will have desired state: Ready
2022-04-04 10:12:37 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-742811948-1781901717 is in desired state: Ready
2022-04-04 10:12:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-424aaee0-kafka-clients in namespace namespace-29
2022-04-04 10:12:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-29
2022-04-04 10:12:37 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-424aaee0-kafka-clients will be ready
2022-04-04 10:12:39 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-424aaee0-kafka-clients is ready
2022-04-04 10:12:39 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 10:12:39 [main] [32mINFO [m [KafkaST:1415] Executing command cd /var/lib/kafka/data/kafka-log0/;ls -1 | sed -n "s#__consumer_offsets-\([0-9]*\)#\1#p" | sort -V in my-cluster-424aaee0-kafka-0
2022-04-04 10:12:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-29 exec my-cluster-424aaee0-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0/;ls -1 | sed -n "s#__consumer_offsets-\([0-9]*\)#\1#p" | sort -V
2022-04-04 10:12:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:12:39 [main] [32mINFO [m [KafkaST:1422] Result: 
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99

2022-04-04 10:12:39 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3513d9be, messages=[], arguments=[--topic, my-topic-742811948-1781901717, --max-messages, 100, --bootstrap-server, my-cluster-424aaee0-kafka-bootstrap.namespace-29.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-424aaee0-kafka-clients-559f97ffd-hvtvj', podNamespace='namespace-29', bootstrapServer='my-cluster-424aaee0-kafka-bootstrap.namespace-29.svc:9092', topicName='my-topic-742811948-1781901717', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@19a0dd25}
2022-04-04 10:12:39 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-424aaee0-kafka-bootstrap.namespace-29.svc:9092:my-topic-742811948-1781901717 from pod my-cluster-424aaee0-kafka-clients-559f97ffd-hvtvj
2022-04-04 10:12:39 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-424aaee0-kafka-clients-559f97ffd-hvtvj -n namespace-29 -- /opt/kafka/producer.sh --topic my-topic-742811948-1781901717 --max-messages 100 --bootstrap-server my-cluster-424aaee0-kafka-bootstrap.namespace-29.svc:9092
2022-04-04 10:12:41 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 10:12:41 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 10:12:41 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2fd2bbb1, messages=[], arguments=[--topic, my-topic-742811948-1781901717, --max-messages, 100, --group-instance-id, instance286971721, --group-id, my-consumer-group-1227024628, --bootstrap-server, my-cluster-424aaee0-kafka-bootstrap.namespace-29.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-424aaee0-kafka-clients-559f97ffd-hvtvj', podNamespace='namespace-29', bootstrapServer='my-cluster-424aaee0-kafka-bootstrap.namespace-29.svc:9092', topicName='my-topic-742811948-1781901717', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1227024628', consumerInstanceId='instance286971721', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@26f16479}
2022-04-04 10:12:41 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-424aaee0-kafka-bootstrap.namespace-29.svc:9092#my-topic-742811948-1781901717 from pod my-cluster-424aaee0-kafka-clients-559f97ffd-hvtvj
2022-04-04 10:12:41 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-424aaee0-kafka-clients-559f97ffd-hvtvj -n namespace-29 -- /opt/kafka/consumer.sh --topic my-topic-742811948-1781901717 --max-messages 100 --group-instance-id instance286971721 --group-id my-consumer-group-1227024628 --bootstrap-server my-cluster-424aaee0-kafka-bootstrap.namespace-29.svc:9092
2022-04-04 10:12:47 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 10:12:47 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 10:12:47 [main] [32mINFO [m [KafkaST:1429] Executing command cd /var/lib/kafka/data/kafka-log0/;ls -1 | sed -n "s#__consumer_offsets-\([0-9]*\)#\1#p" | sort -V in my-cluster-424aaee0-kafka-0
2022-04-04 10:12:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-29 exec my-cluster-424aaee0-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0/;ls -1 | sed -n "s#__consumer_offsets-\([0-9]*\)#\1#p" | sort -V
2022-04-04 10:12:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:12:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:12:47 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConsumerOffsetFiles
2022-04-04 10:12:47 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-742811948-1781901717 in namespace namespace-29
2022-04-04 10:12:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-424aaee0-kafka-clients in namespace namespace-29
2022-04-04 10:12:47 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-424aaee0 in namespace namespace-29
2022-04-04 10:13:37 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:13:37 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-29 for test case:testConsumerOffsetFiles
2022-04-04 10:13:43 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testConsumerOffsetFiles-FINISHED
2022-04-04 10:13:43 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:13:43 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:13:43 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testAppDomainLabels-STARTED
2022-04-04 10:13:43 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:13:43 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-30 for test case:testAppDomainLabels
2022-04-04 10:13:43 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-30
2022-04-04 10:13:43 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-30
2022-04-04 10:13:43 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-30
2022-04-04 10:13:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b824d574 in namespace namespace-30
2022-04-04 10:13:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-30
2022-04-04 10:13:43 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b824d574 will have desired state: Ready
2022-04-04 10:14:56 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b824d574 is in desired state: Ready
2022-04-04 10:14:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1423146857-761920094 in namespace namespace-30
2022-04-04 10:14:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-30
2022-04-04 10:14:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1423146857-761920094 will have desired state: Ready
2022-04-04 10:14:57 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1423146857-761920094 is in desired state: Ready
2022-04-04 10:14:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b824d574-kafka-clients in namespace namespace-30
2022-04-04 10:14:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-30
2022-04-04 10:14:57 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b824d574-kafka-clients will be ready
2022-04-04 10:14:59 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b824d574-kafka-clients is ready
2022-04-04 10:14:59 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1220] ---> PODS <---
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1232] ---> STATEFUL SETS <---
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1236] Getting labels from stateful set of kafka resource
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1765] Verifying labels {app.kubernetes.io/instance=my-cluster-b824d574, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-b824d574, strimzi.io/cluster=my-cluster-b824d574, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-b824d574-kafka, test.case=testAppDomainLabels}
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1241] Getting labels from stateful set of zookeeper resource
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1765] Verifying labels {app.kubernetes.io/instance=my-cluster-b824d574, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=zookeeper, app.kubernetes.io/part-of=strimzi-my-cluster-b824d574, strimzi.io/cluster=my-cluster-b824d574, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-b824d574-zookeeper, test.case=testAppDomainLabels}
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1244] ---> SERVICES <---
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1251] Getting labels from my-cluster-b824d574-kafka-bootstrap service
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1765] Verifying labels {app.kubernetes.io/instance=my-cluster-b824d574, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-b824d574, strimzi.io/cluster=my-cluster-b824d574, strimzi.io/discovery=true, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-b824d574-kafka, test.case=testAppDomainLabels}
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1251] Getting labels from my-cluster-b824d574-kafka-brokers service
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1765] Verifying labels {app.kubernetes.io/instance=my-cluster-b824d574, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-b824d574, strimzi.io/cluster=my-cluster-b824d574, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-b824d574-kafka, test.case=testAppDomainLabels}
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1251] Getting labels from my-cluster-b824d574-zookeeper-client service
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1765] Verifying labels {app.kubernetes.io/instance=my-cluster-b824d574, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=zookeeper, app.kubernetes.io/part-of=strimzi-my-cluster-b824d574, strimzi.io/cluster=my-cluster-b824d574, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-b824d574-zookeeper-client, test.case=testAppDomainLabels}
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1251] Getting labels from my-cluster-b824d574-zookeeper-nodes service
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1765] Verifying labels {app.kubernetes.io/instance=my-cluster-b824d574, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=zookeeper, app.kubernetes.io/part-of=strimzi-my-cluster-b824d574, strimzi.io/cluster=my-cluster-b824d574, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-b824d574-zookeeper, test.case=testAppDomainLabels}
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1255] ---> SECRETS <---
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-b824d574-clients-ca secret
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-b824d574, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-b824d574, strimzi.io/cluster=my-cluster-b824d574, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-b824d574-clients-ca-cert secret
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-b824d574, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-b824d574, strimzi.io/cluster=my-cluster-b824d574, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-b824d574-cluster-ca secret
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-b824d574, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-b824d574, strimzi.io/cluster=my-cluster-b824d574, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-b824d574-cluster-ca-cert secret
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-b824d574, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-b824d574, strimzi.io/cluster=my-cluster-b824d574, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-b824d574-cluster-operator-certs secret
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-b824d574, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-b824d574, strimzi.io/cluster=my-cluster-b824d574, strimzi.io/kind=Kafka, test.case=testAppDomainLabels}
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-b824d574-entity-topic-operator-certs secret
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-b824d574, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=entity-topic-operator, app.kubernetes.io/part-of=strimzi-my-cluster-b824d574, strimzi.io/cluster=my-cluster-b824d574, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-b824d574-entity-user-operator-certs secret
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-b824d574, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=entity-user-operator, app.kubernetes.io/part-of=strimzi-my-cluster-b824d574, strimzi.io/cluster=my-cluster-b824d574, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-b824d574-kafka-brokers secret
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-b824d574, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-b824d574, strimzi.io/cluster=my-cluster-b824d574, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-b824d574-zookeeper-nodes secret
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-b824d574, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=zookeeper, app.kubernetes.io/part-of=strimzi-my-cluster-b824d574, strimzi.io/cluster=my-cluster-b824d574, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1266] ---> CONFIG MAPS <---
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1271] Getting labels from my-cluster-b824d574-entity-topic-operator-config config map
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-b824d574, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=entity-topic-operator, app.kubernetes.io/part-of=strimzi-my-cluster-b824d574, strimzi.io/cluster=my-cluster-b824d574, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1271] Getting labels from my-cluster-b824d574-entity-user-operator-config config map
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-b824d574, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=entity-user-operator, app.kubernetes.io/part-of=strimzi-my-cluster-b824d574, strimzi.io/cluster=my-cluster-b824d574, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1271] Getting labels from my-cluster-b824d574-kafka-config config map
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-b824d574, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-b824d574, strimzi.io/cluster=my-cluster-b824d574, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-b824d574-kafka, test.case=testAppDomainLabels}
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1271] Getting labels from my-cluster-b824d574-zookeeper-config config map
2022-04-04 10:14:59 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-b824d574, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=zookeeper, app.kubernetes.io/part-of=strimzi-my-cluster-b824d574, strimzi.io/cluster=my-cluster-b824d574, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-04 10:14:59 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@7bd471d9, messages=[], arguments=[--topic, my-topic-1423146857-761920094, --max-messages, 100, --bootstrap-server, my-cluster-b824d574-kafka-bootstrap.namespace-30.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b824d574-kafka-clients-6d84687bb4-m69zp', podNamespace='namespace-30', bootstrapServer='my-cluster-b824d574-kafka-bootstrap.namespace-30.svc:9092', topicName='my-topic-1423146857-761920094', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6c275adf}
2022-04-04 10:14:59 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-b824d574-kafka-bootstrap.namespace-30.svc:9092:my-topic-1423146857-761920094 from pod my-cluster-b824d574-kafka-clients-6d84687bb4-m69zp
2022-04-04 10:14:59 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b824d574-kafka-clients-6d84687bb4-m69zp -n namespace-30 -- /opt/kafka/producer.sh --topic my-topic-1423146857-761920094 --max-messages 100 --bootstrap-server my-cluster-b824d574-kafka-bootstrap.namespace-30.svc:9092
2022-04-04 10:15:01 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 10:15:01 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 10:15:01 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@55036033, messages=[], arguments=[--topic, my-topic-1423146857-761920094, --max-messages, 100, --group-instance-id, instance804597497, --group-id, my-consumer-group-1760843201, --bootstrap-server, my-cluster-b824d574-kafka-bootstrap.namespace-30.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b824d574-kafka-clients-6d84687bb4-m69zp', podNamespace='namespace-30', bootstrapServer='my-cluster-b824d574-kafka-bootstrap.namespace-30.svc:9092', topicName='my-topic-1423146857-761920094', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1760843201', consumerInstanceId='instance804597497', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@324332a}
2022-04-04 10:15:01 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-b824d574-kafka-bootstrap.namespace-30.svc:9092#my-topic-1423146857-761920094 from pod my-cluster-b824d574-kafka-clients-6d84687bb4-m69zp
2022-04-04 10:15:01 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b824d574-kafka-clients-6d84687bb4-m69zp -n namespace-30 -- /opt/kafka/consumer.sh --topic my-topic-1423146857-761920094 --max-messages 100 --group-instance-id instance804597497 --group-id my-consumer-group-1760843201 --bootstrap-server my-cluster-b824d574-kafka-bootstrap.namespace-30.svc:9092
2022-04-04 10:15:07 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 10:15:07 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 10:15:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:15:07 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAppDomainLabels
2022-04-04 10:15:07 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1423146857-761920094 in namespace namespace-30
2022-04-04 10:15:07 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b824d574 in namespace namespace-30
2022-04-04 10:15:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b824d574-kafka-clients in namespace namespace-30
2022-04-04 10:15:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:15:57 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-30 for test case:testAppDomainLabels
2022-04-04 10:16:03 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testAppDomainLabels-FINISHED
2022-04-04 10:16:03 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:16:03 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:16:03 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testRemoveUserOperatorFromEntityOperator-STARTED
2022-04-04 10:16:03 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:16:03 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-31 for test case:testRemoveUserOperatorFromEntityOperator
2022-04-04 10:16:03 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-31
2022-04-04 10:16:03 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-31
2022-04-04 10:16:03 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-31
2022-04-04 10:16:03 [main] [32mINFO [m [KafkaST:669] Deploying Kafka cluster my-cluster-79f9b38f
2022-04-04 10:16:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-79f9b38f in namespace namespace-31
2022-04-04 10:16:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-31
2022-04-04 10:16:03 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-79f9b38f will have desired state: Ready
2022-04-04 10:17:22 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-79f9b38f is in desired state: Ready
2022-04-04 10:17:22 [main] [32mINFO [m [PodUtils:154] Waiting when Pod my-cluster-79f9b38f-entity-operator-594946655f-8l58q will be deleted
2022-04-04 10:17:32 [main] [32mINFO [m [PodUtils:171] Pod my-cluster-79f9b38f-entity-operator-594946655f-8l58q deleted
2022-04-04 10:17:32 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-79f9b38f-entity-operator will be ready
2022-04-04 10:19:41 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-79f9b38f-entity-operator is ready
2022-04-04 10:19:41 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-79f9b38f-entity-operator to be ready
2022-04-04 10:19:51 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-79f9b38f-entity-operator is ready
2022-04-04 10:19:51 [main] [32mINFO [m [PodUtils:201] Wait until Pod my-cluster-79f9b38f-entity-operator will have 2 containers
2022-04-04 10:19:51 [main] [32mINFO [m [PodUtils:205] Pod my-cluster-79f9b38f-entity-operator has 2 containers
2022-04-04 10:19:51 [main] [32mINFO [m [PodUtils:154] Waiting when Pod my-cluster-79f9b38f-entity-operator-6b8d7dffd8-42h77 will be deleted
2022-04-04 10:19:56 [main] [32mINFO [m [PodUtils:171] Pod my-cluster-79f9b38f-entity-operator-6b8d7dffd8-42h77 deleted
2022-04-04 10:19:56 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-79f9b38f-entity-operator will be ready
2022-04-04 10:23:41 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-79f9b38f-entity-operator is ready
2022-04-04 10:23:41 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-79f9b38f-entity-operator to be ready
2022-04-04 10:23:51 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-79f9b38f-entity-operator is ready
2022-04-04 10:23:51 [main] [32mINFO [m [AbstractST:478] Search in strimzi-cluster-operator log for errors in last 468 seconds
2022-04-04 10:23:51 [main] [32mINFO [m [BaseCmdKubeClient:481] Exception not found
2022-04-04 10:23:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:23:51 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRemoveUserOperatorFromEntityOperator
2022-04-04 10:23:51 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-79f9b38f in namespace namespace-31
2022-04-04 10:24:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:24:01 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-31 for test case:testRemoveUserOperatorFromEntityOperator
2022-04-04 10:24:44 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testRemoveUserOperatorFromEntityOperator-FINISHED
2022-04-04 10:24:44 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:24:44 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:24:44 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testUOListeningOnlyUsersInSameCluster-STARTED
2022-04-04 10:24:44 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:24:44 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-32 for test case:testUOListeningOnlyUsersInSameCluster
2022-04-04 10:24:44 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-32
2022-04-04 10:24:44 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-32
2022-04-04 10:24:44 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-32
2022-04-04 10:24:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1 in namespace namespace-32
2022-04-04 10:24:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-32
2022-04-04 10:24:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1 will have desired state: Ready
2022-04-04 10:26:03 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1 is in desired state: Ready
2022-04-04 10:26:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2 in namespace namespace-32
2022-04-04 10:26:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-32
2022-04-04 10:26:03 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2 will have desired state: Ready
2022-04-04 10:27:12 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2 is in desired state: Ready
2022-04-04 10:27:12 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-664278664-431762836 in namespace namespace-32
2022-04-04 10:27:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-32
2022-04-04 10:27:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-664278664-431762836 will have desired state: Ready
2022-04-04 10:27:13 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-664278664-431762836 is in desired state: Ready
2022-04-04 10:27:13 [main] [32mINFO [m [KafkaST:1292] Verifying that user my-user-664278664-431762836 in cluster my-cluster-1 is created
2022-04-04 10:27:13 [main] [32mINFO [m [KafkaST:1297] Verifying that user my-user-664278664-431762836 in cluster my-cluster-2 is not created
2022-04-04 10:27:13 [main] [32mINFO [m [KafkaST:1302] Verifying that user belongs to my-cluster-1 cluster
2022-04-04 10:27:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:27:13 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUOListeningOnlyUsersInSameCluster
2022-04-04 10:27:13 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2 in namespace namespace-32
2022-04-04 10:27:13 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1 in namespace namespace-32
2022-04-04 10:27:13 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-664278664-431762836 in namespace namespace-32
2022-04-04 10:27:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:27:23 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-32 for test case:testUOListeningOnlyUsersInSameCluster
2022-04-04 10:28:06 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testUOListeningOnlyUsersInSameCluster-FINISHED
2022-04-04 10:28:06 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:28:06 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:28:06 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testKafkaJBODDeleteClaimsTrueFalse-STARTED
2022-04-04 10:28:06 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:28:06 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-33 for test case:testKafkaJBODDeleteClaimsTrueFalse
2022-04-04 10:28:06 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-33
2022-04-04 10:28:06 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-33
2022-04-04 10:28:06 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-33
2022-04-04 10:28:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-eabe6206 in namespace namespace-33
2022-04-04 10:28:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-33
2022-04-04 10:28:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-eabe6206 will have desired state: Ready
2022-04-04 10:29:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-eabe6206 is in desired state: Ready
2022-04-04 10:29:21 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-0-my-cluster-eabe6206-kafka-0
2022-04-04 10:29:21 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-0-my-cluster-eabe6206-kafka-1
2022-04-04 10:29:21 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-1-my-cluster-eabe6206-kafka-0
2022-04-04 10:29:21 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-1-my-cluster-eabe6206-kafka-1
2022-04-04 10:29:21 [main] [32mINFO [m [KafkaST:1717] Checking PVC names included in JBOD array
2022-04-04 10:29:21 [main] [32mINFO [m [KafkaST:1724] Checking PVC on Kafka pods
2022-04-04 10:29:21 [main] [32mINFO [m [KafkaST:1729] Getting list of mounted data sources and PVCs on Kafka pod 0
2022-04-04 10:29:21 [main] [32mINFO [m [KafkaST:1737] Verifying mounted data sources and PVCs on Kafka pod 0
2022-04-04 10:29:21 [main] [32mINFO [m [KafkaST:1729] Getting list of mounted data sources and PVCs on Kafka pod 1
2022-04-04 10:29:21 [main] [32mINFO [m [KafkaST:1737] Verifying mounted data sources and PVCs on Kafka pod 1
2022-04-04 10:29:21 [main] [32mINFO [m [KafkaST:882] Deleting cluster
2022-04-04 10:29:21 [main] [32mINFO [m [KafkaST:885] Waiting for PVC deletion
2022-04-04 10:29:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:29:51 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaJBODDeleteClaimsTrueFalse
2022-04-04 10:29:51 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-eabe6206 in namespace namespace-33
2022-04-04 10:29:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:29:51 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-33 for test case:testKafkaJBODDeleteClaimsTrueFalse
2022-04-04 10:30:18 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testKafkaJBODDeleteClaimsTrueFalse-FINISHED
2022-04-04 10:30:18 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:30:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:30:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testLabelsAndAnnotationForPVC-STARTED
2022-04-04 10:30:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:30:18 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-34 for test case:testLabelsAndAnnotationForPVC
2022-04-04 10:30:18 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-34
2022-04-04 10:30:18 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-34
2022-04-04 10:30:18 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-34
2022-04-04 10:30:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-90991665 in namespace namespace-34
2022-04-04 10:30:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-34
2022-04-04 10:30:18 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-90991665 will have desired state: Ready
2022-04-04 10:31:37 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-90991665 is in desired state: Ready
2022-04-04 10:31:37 [main] [32mINFO [m [KafkaST:1510] Check if Kubernetes labels are applied
2022-04-04 10:31:37 [main] [32mINFO [m [KafkaST:1517] Kubernetes labels are correctly set and present
2022-04-04 10:31:37 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-0-my-cluster-90991665-kafka-0 - testValue = testValue
2022-04-04 10:31:37 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-0-my-cluster-90991665-kafka-1 - testValue = testValue
2022-04-04 10:31:37 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-0-my-cluster-90991665-kafka-2 - testValue = testValue
2022-04-04 10:31:37 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-1-my-cluster-90991665-kafka-0 - testValue = testValue
2022-04-04 10:31:37 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-1-my-cluster-90991665-kafka-1 - testValue = testValue
2022-04-04 10:31:37 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-1-my-cluster-90991665-kafka-2 - testValue = testValue
2022-04-04 10:31:37 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-my-cluster-90991665-zookeeper-0 - testValue = testValue
2022-04-04 10:31:37 [main] [32mINFO [m [KafkaST:1535] Replacing kafka && zookeeper labels and annotations from testKey to editedTestValue
2022-04-04 10:31:37 [main] [32mINFO [m [PersistentVolumeClaimUtils:30] Wait until PVC labels will change {testKey=editedTestValue}
2022-04-04 10:31:40 [main] [32mINFO [m [PersistentVolumeClaimUtils:46] PVC labels has changed {testKey=editedTestValue}
2022-04-04 10:31:40 [main] [32mINFO [m [PersistentVolumeClaimUtils:50] Wait until PVC annotation will change {testKey=editedTestValue}
2022-04-04 10:31:40 [main] [32mINFO [m [PersistentVolumeClaimUtils:66] PVC annotation has changed {testKey=editedTestValue}
2022-04-04 10:31:40 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-90991665 will have desired state: Ready
2022-04-04 10:31:40 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-90991665 is in desired state: Ready
2022-04-04 10:31:40 [main] [32mINFO [m [KafkaST:1549] [PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=false, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-04T10:30:42Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-90991665, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-90991665, strimzi.io/cluster=my-cluster-90991665, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-90991665-kafka, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-0-my-cluster-90991665-kafka-0, namespace=namespace-34, ownerReferences=[], resourceVersion=36951, selfLink=/api/v1/namespaces/namespace-34/persistentvolumeclaims/data-0-my-cluster-90991665-kafka-0, uid=7a84a641-6a7d-4f93-96c7-3a90586a82d1, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=20Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-7a84a641-6a7d-4f93-96c7-3a90586a82d1, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=20Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={}), PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=false, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-04T10:30:42Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-90991665, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-90991665, strimzi.io/cluster=my-cluster-90991665, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-90991665-kafka, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-0-my-cluster-90991665-kafka-1, namespace=namespace-34, ownerReferences=[], resourceVersion=36952, selfLink=/api/v1/namespaces/namespace-34/persistentvolumeclaims/data-0-my-cluster-90991665-kafka-1, uid=a0177d59-5229-484d-a2b7-8323f158b8d4, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=20Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-a0177d59-5229-484d-a2b7-8323f158b8d4, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=20Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={}), PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=false, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-04T10:30:42Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-90991665, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-90991665, strimzi.io/cluster=my-cluster-90991665, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-90991665-kafka, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-0-my-cluster-90991665-kafka-2, namespace=namespace-34, ownerReferences=[], resourceVersion=36957, selfLink=/api/v1/namespaces/namespace-34/persistentvolumeclaims/data-0-my-cluster-90991665-kafka-2, uid=d2b3dd2e-173e-4edd-b9da-464774a8cfc2, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=20Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-d2b3dd2e-173e-4edd-b9da-464774a8cfc2, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=20Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={}), PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=true, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-04T10:30:42Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-90991665, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-90991665, strimzi.io/cluster=my-cluster-90991665, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-90991665-kafka, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-1-my-cluster-90991665-kafka-0, namespace=namespace-34, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=Kafka, name=my-cluster-90991665, uid=0fe84c58-1808-4df6-9556-740fbc0bbfdf, additionalProperties={})], resourceVersion=36959, selfLink=/api/v1/namespaces/namespace-34/persistentvolumeclaims/data-1-my-cluster-90991665-kafka-0, uid=31e4ff0d-2080-4ce8-859d-d756187126b7, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=10Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-31e4ff0d-2080-4ce8-859d-d756187126b7, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=10Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={}), PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=true, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-04T10:30:42Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-90991665, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-90991665, strimzi.io/cluster=my-cluster-90991665, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-90991665-kafka, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-1-my-cluster-90991665-kafka-1, namespace=namespace-34, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=Kafka, name=my-cluster-90991665, uid=0fe84c58-1808-4df6-9556-740fbc0bbfdf, additionalProperties={})], resourceVersion=36960, selfLink=/api/v1/namespaces/namespace-34/persistentvolumeclaims/data-1-my-cluster-90991665-kafka-1, uid=cd74bf67-d633-42fa-bc48-6d6ad29a39e5, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=10Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-cd74bf67-d633-42fa-bc48-6d6ad29a39e5, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=10Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={}), PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=true, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-04T10:30:42Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-90991665, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-90991665, strimzi.io/cluster=my-cluster-90991665, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-90991665-kafka, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-1-my-cluster-90991665-kafka-2, namespace=namespace-34, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=Kafka, name=my-cluster-90991665, uid=0fe84c58-1808-4df6-9556-740fbc0bbfdf, additionalProperties={})], resourceVersion=36958, selfLink=/api/v1/namespaces/namespace-34/persistentvolumeclaims/data-1-my-cluster-90991665-kafka-2, uid=4a28a252-e6aa-451b-bdd6-3ef97d24a452, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=10Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-4a28a252-e6aa-451b-bdd6-3ef97d24a452, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=10Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={}), PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=false, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-04T10:30:21Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-90991665, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=zookeeper, app.kubernetes.io/part-of=strimzi-my-cluster-90991665, strimzi.io/cluster=my-cluster-90991665, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-90991665-zookeeper, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-my-cluster-90991665-zookeeper-0, namespace=namespace-34, ownerReferences=[], resourceVersion=36942, selfLink=/api/v1/namespaces/namespace-34/persistentvolumeclaims/data-my-cluster-90991665-zookeeper-0, uid=c2b11d80-6ad4-40ce-8441-1b04251a7e13, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=3Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-c2b11d80-6ad4-40ce-8441-1b04251a7e13, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=3Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={})]
2022-04-04 10:31:40 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-0-my-cluster-90991665-kafka-0 - testValue = editedTestValue
2022-04-04 10:31:40 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-0-my-cluster-90991665-kafka-1 - testValue = editedTestValue
2022-04-04 10:31:40 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-0-my-cluster-90991665-kafka-2 - testValue = editedTestValue
2022-04-04 10:31:40 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-1-my-cluster-90991665-kafka-0 - testValue = editedTestValue
2022-04-04 10:31:40 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-1-my-cluster-90991665-kafka-1 - testValue = editedTestValue
2022-04-04 10:31:40 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-1-my-cluster-90991665-kafka-2 - testValue = editedTestValue
2022-04-04 10:31:40 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-my-cluster-90991665-zookeeper-0 - testValue = editedTestValue
2022-04-04 10:31:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:31:40 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testLabelsAndAnnotationForPVC
2022-04-04 10:31:40 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-90991665 in namespace namespace-34
2022-04-04 10:31:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:31:50 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-34 for test case:testLabelsAndAnnotationForPVC
2022-04-04 10:32:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testLabelsAndAnnotationForPVC-FINISHED
2022-04-04 10:32:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:32:34 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:32:34 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testMessagesAreStoredInDisk-STARTED
2022-04-04 10:32:34 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:32:34 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-35 for test case:testMessagesAreStoredInDisk
2022-04-04 10:32:34 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-35
2022-04-04 10:32:34 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-35
2022-04-04 10:32:34 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-35
2022-04-04 10:32:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c4192b30 in namespace namespace-35
2022-04-04 10:32:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-35
2022-04-04 10:32:34 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c4192b30 will have desired state: Ready
2022-04-04 10:33:43 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c4192b30 is in desired state: Ready
2022-04-04 10:33:43 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-633994849-97445922 in namespace namespace-35
2022-04-04 10:33:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-35
2022-04-04 10:33:43 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-633994849-97445922 will have desired state: Ready
2022-04-04 10:33:44 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-633994849-97445922 is in desired state: Ready
2022-04-04 10:33:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-c4192b30-kafka-clients in namespace namespace-35
2022-04-04 10:33:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-35
2022-04-04 10:33:44 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c4192b30-kafka-clients will be ready
2022-04-04 10:33:46 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c4192b30-kafka-clients is ready
2022-04-04 10:33:46 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 10:33:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-35 exec my-cluster-c4192b30-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0; ls -1
2022-04-04 10:33:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:33:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-35 exec my-cluster-c4192b30-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0; ls -1 | sed -n '/my-topic-633994849-97445922/p'
2022-04-04 10:33:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:33:46 [main] [32mINFO [m [KafkaST:1344] Executing command cd /var/lib/kafka/data/kafka-log0/my-topic-633994849-97445922-0
/;cat 00000000000000000000.log in my-cluster-c4192b30-kafka-0
2022-04-04 10:33:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-35 exec my-cluster-c4192b30-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0/my-topic-633994849-97445922-0
/;cat 00000000000000000000.log
2022-04-04 10:33:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:33:46 [main] [32mINFO [m [KafkaST:1348] Topic my-topic-633994849-97445922 is present in kafka broker my-cluster-c4192b30-kafka-0 with no data
2022-04-04 10:33:46 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5474d672, messages=[], arguments=[--topic, my-topic-633994849-97445922, --max-messages, 100, --bootstrap-server, my-cluster-c4192b30-kafka-bootstrap.namespace-35.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-c4192b30-kafka-clients-989c5cf4f-hj7zz', podNamespace='namespace-35', bootstrapServer='my-cluster-c4192b30-kafka-bootstrap.namespace-35.svc:9092', topicName='my-topic-633994849-97445922', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@54d5b3e8}
2022-04-04 10:33:46 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-c4192b30-kafka-bootstrap.namespace-35.svc:9092:my-topic-633994849-97445922 from pod my-cluster-c4192b30-kafka-clients-989c5cf4f-hj7zz
2022-04-04 10:33:46 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c4192b30-kafka-clients-989c5cf4f-hj7zz -n namespace-35 -- /opt/kafka/producer.sh --topic my-topic-633994849-97445922 --max-messages 100 --bootstrap-server my-cluster-c4192b30-kafka-bootstrap.namespace-35.svc:9092
2022-04-04 10:33:49 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 10:33:49 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 10:33:49 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6a2369c, messages=[], arguments=[--topic, my-topic-633994849-97445922, --max-messages, 100, --group-instance-id, instance1294255976, --group-id, my-consumer-group-595195166, --bootstrap-server, my-cluster-c4192b30-kafka-bootstrap.namespace-35.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-c4192b30-kafka-clients-989c5cf4f-hj7zz', podNamespace='namespace-35', bootstrapServer='my-cluster-c4192b30-kafka-bootstrap.namespace-35.svc:9092', topicName='my-topic-633994849-97445922', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-595195166', consumerInstanceId='instance1294255976', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5b7452a9}
2022-04-04 10:33:49 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-c4192b30-kafka-bootstrap.namespace-35.svc:9092#my-topic-633994849-97445922 from pod my-cluster-c4192b30-kafka-clients-989c5cf4f-hj7zz
2022-04-04 10:33:49 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c4192b30-kafka-clients-989c5cf4f-hj7zz -n namespace-35 -- /opt/kafka/consumer.sh --topic my-topic-633994849-97445922 --max-messages 100 --group-instance-id instance1294255976 --group-id my-consumer-group-595195166 --bootstrap-server my-cluster-c4192b30-kafka-bootstrap.namespace-35.svc:9092
2022-04-04 10:33:54 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 10:33:54 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 10:33:54 [main] [32mINFO [m [KafkaST:1355] Executing command cd /var/lib/kafka/data/kafka-log0/my-topic-633994849-97445922-0
/;cat 00000000000000000000.log in my-cluster-c4192b30-kafka-0
2022-04-04 10:33:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-35 exec my-cluster-c4192b30-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0/my-topic-633994849-97445922-0
/;cat 00000000000000000000.log
2022-04-04 10:33:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:33:55 [main] [32mINFO [m [KafkaST:1364] Deleting kafka pod my-cluster-c4192b30-kafka-0
2022-04-04 10:33:55 [main] [32mINFO [m [KafkaST:1364] Deleting kafka pod my-cluster-c4192b30-kafka-clients-989c5cf4f-hj7zz
2022-04-04 10:33:55 [main] [32mINFO [m [KafkaST:1368] Wait for kafka to rolling restart ...
2022-04-04 10:33:55 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-c4192b30-kafka rolling update
2022-04-04 10:34:05 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-c4192b30-kafka has been successfully rolled
2022-04-04 10:34:05 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 1 Pod(s) of my-cluster-c4192b30-kafka to be ready
2022-04-04 10:34:35 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c4192b30 will have desired state: Ready
2022-04-04 10:34:35 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c4192b30 is in desired state: Ready
2022-04-04 10:34:35 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-c4192b30 is ready
2022-04-04 10:34:35 [main] [32mINFO [m [KafkaST:1371] Executing command cd /var/lib/kafka/data/kafka-log0/my-topic-633994849-97445922-0
/;cat 00000000000000000000.log in my-cluster-c4192b30-kafka-0
2022-04-04 10:34:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-35 exec my-cluster-c4192b30-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0/my-topic-633994849-97445922-0
/;cat 00000000000000000000.log
2022-04-04 10:34:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:34:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:34:35 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMessagesAreStoredInDisk
2022-04-04 10:34:35 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-633994849-97445922 in namespace namespace-35
2022-04-04 10:34:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c4192b30 in namespace namespace-35
2022-04-04 10:34:35 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-c4192b30-kafka-clients in namespace namespace-35
2022-04-04 10:35:15 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:35:15 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-35 for test case:testMessagesAreStoredInDisk
2022-04-04 10:35:20 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testMessagesAreStoredInDisk-FINISHED
2022-04-04 10:35:20 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:35:20 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:35:20 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testLabelModificationDoesNotBreakCluster-STARTED
2022-04-04 10:35:20 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:35:20 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-36 for test case:testLabelModificationDoesNotBreakCluster
2022-04-04 10:35:20 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-36
2022-04-04 10:35:20 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-36
2022-04-04 10:35:20 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-36
2022-04-04 10:35:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-df34923b in namespace namespace-36
2022-04-04 10:35:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-36
2022-04-04 10:35:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-df34923b will have desired state: Ready
2022-04-04 10:36:37 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-df34923b is in desired state: Ready
2022-04-04 10:36:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-791111557-646272320 in namespace namespace-36
2022-04-04 10:36:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-36
2022-04-04 10:36:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-791111557-646272320 will have desired state: Ready
2022-04-04 10:36:38 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-791111557-646272320 is in desired state: Ready
2022-04-04 10:36:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-df34923b-kafka-clients in namespace namespace-36
2022-04-04 10:36:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-36
2022-04-04 10:36:38 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-df34923b-kafka-clients will be ready
2022-04-04 10:36:40 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-df34923b-kafka-clients is ready
2022-04-04 10:36:40 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 10:36:40 [main] [32mINFO [m [KafkaST:1078] Waiting for kafka stateful set labels changed {label-name-1=name-of-the-label-1, label-name-2=name-of-the-label-2}
2022-04-04 10:36:40 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-1 -> name-of-the-label-1
2022-04-04 10:36:40 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-2 -> name-of-the-label-2
2022-04-04 10:36:40 [main] [32mINFO [m [KafkaST:1081] Getting labels from stateful set resource
2022-04-04 10:36:40 [main] [32mINFO [m [KafkaST:1084] Verifying default labels in the Kafka CR
2022-04-04 10:36:40 [main] [32mINFO [m [KafkaST:1095] Setting new values of labels from name-of-the-label-1 to new-name-of-the-label-1 | from name-of-the-label-2 to new-name-of-the-label-2 and adding one label-name-3 with value name-of-the-label-3
2022-04-04 10:36:40 [main] [32mINFO [m [KafkaST:1098] Edit kafka labels in Kafka CR
2022-04-04 10:36:40 [main] [32mINFO [m [KafkaST:1109] Waiting for kafka service labels changed {label-name-1=new-name-of-the-label-1, label-name-2=new-name-of-the-label-2, label-name-3=name-of-the-label-3}
2022-04-04 10:36:40 [main] [32mINFO [m [ServiceUtils:33] Waiting for Service label change label-name-1 -> new-name-of-the-label-1
2022-04-04 10:37:20 [main] [32mINFO [m [ServiceUtils:33] Waiting for Service label change label-name-2 -> new-name-of-the-label-2
2022-04-04 10:37:20 [main] [32mINFO [m [ServiceUtils:33] Waiting for Service label change label-name-3 -> name-of-the-label-3
2022-04-04 10:37:20 [main] [32mINFO [m [KafkaST:1112] Verifying kafka labels via services
2022-04-04 10:37:20 [main] [32mINFO [m [KafkaST:1118] Waiting for Kafka ConfigMap my-cluster-df34923b-kafka-config in namespace namespace-36 to have new labels: {label-name-1=new-name-of-the-label-1, label-name-2=new-name-of-the-label-2, label-name-3=name-of-the-label-3}
2022-04-04 10:37:20 [main] [32mINFO [m [ConfigMapUtils:42] Waiting for ConfigMap my-cluster-df34923b-kafka-config label change label-name-1 -> new-name-of-the-label-1
2022-04-04 10:37:20 [main] [32mINFO [m [ConfigMapUtils:42] Waiting for ConfigMap my-cluster-df34923b-kafka-config label change label-name-2 -> new-name-of-the-label-2
2022-04-04 10:37:20 [main] [32mINFO [m [ConfigMapUtils:42] Waiting for ConfigMap my-cluster-df34923b-kafka-config label change label-name-3 -> name-of-the-label-3
2022-04-04 10:37:20 [main] [32mINFO [m [KafkaST:1121] Verifying Kafka labels on ConfigMap my-cluster-df34923b-kafka-config in namespace namespace-36
2022-04-04 10:37:20 [main] [32mINFO [m [KafkaST:1127] Waiting for kafka stateful set labels changed {label-name-1=new-name-of-the-label-1, label-name-2=new-name-of-the-label-2, label-name-3=name-of-the-label-3}
2022-04-04 10:37:20 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-1 -> new-name-of-the-label-1
2022-04-04 10:37:20 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-2 -> new-name-of-the-label-2
2022-04-04 10:37:20 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-3 -> name-of-the-label-3
2022-04-04 10:37:20 [main] [32mINFO [m [KafkaST:1130] Verifying kafka labels via stateful set
2022-04-04 10:37:20 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-df34923b-kafka rolling update
2022-04-04 10:38:45 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-df34923b-kafka has been successfully rolled
2022-04-04 10:38:45 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-df34923b-kafka to be ready
2022-04-04 10:39:12 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-df34923b will have desired state: Ready
2022-04-04 10:39:12 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-df34923b is in desired state: Ready
2022-04-04 10:39:12 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-df34923b is ready
2022-04-04 10:39:12 [main] [32mINFO [m [KafkaST:1136] Verifying via kafka pods
2022-04-04 10:39:12 [main] [32mINFO [m [KafkaST:1143] Removing labels: label-name-1 -> new-name-of-the-label-1, label-name-2 -> new-name-of-the-label-2, label-name-3 -> name-of-the-label-3
2022-04-04 10:39:12 [main] [32mINFO [m [KafkaST:1155] Waiting for kafka service labels deletion {app.kubernetes.io/instance=my-cluster-df34923b, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-df34923b, controller-revision-hash=my-cluster-df34923b-kafka-dc465f77, statefulset.kubernetes.io/pod-name=my-cluster-df34923b-kafka-0, strimzi.io/cluster=my-cluster-df34923b, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-df34923b-kafka, test.case=testLabelModificationDoesNotBreakCluster}
2022-04-04 10:39:12 [main] [32mINFO [m [ServiceUtils:44] Service label label-name-1 change to null
2022-04-04 10:40:58 [main] [32mINFO [m [ServiceUtils:44] Service label label-name-2 change to null
2022-04-04 10:40:58 [main] [32mINFO [m [ServiceUtils:44] Service label label-name-3 change to null
2022-04-04 10:40:58 [main] [32mINFO [m [KafkaST:1158] Verifying kafka labels via services
2022-04-04 10:40:58 [main] [32mINFO [m [KafkaST:1164] Waiting for Kafka ConfigMap my-cluster-df34923b-kafka-config in namespace namespace-36 to have labels removed: [label-name-1, label-name-2, label-name-3]
2022-04-04 10:40:58 [main] [32mINFO [m [ConfigMapUtils:53] Waiting for ConfigMap my-cluster-df34923b-kafka-config label label-name-1 change to null
2022-04-04 10:40:58 [main] [32mINFO [m [ConfigMapUtils:60] ConfigMap my-cluster-df34923b-kafka-config label label-name-1 change to null
2022-04-04 10:40:58 [main] [32mINFO [m [ConfigMapUtils:53] Waiting for ConfigMap my-cluster-df34923b-kafka-config label label-name-2 change to null
2022-04-04 10:40:58 [main] [32mINFO [m [ConfigMapUtils:60] ConfigMap my-cluster-df34923b-kafka-config label label-name-2 change to null
2022-04-04 10:40:58 [main] [32mINFO [m [ConfigMapUtils:53] Waiting for ConfigMap my-cluster-df34923b-kafka-config label label-name-3 change to null
2022-04-04 10:40:58 [main] [32mINFO [m [ConfigMapUtils:60] ConfigMap my-cluster-df34923b-kafka-config label label-name-3 change to null
2022-04-04 10:40:58 [main] [32mINFO [m [KafkaST:1167] Verifying Kafka labels on ConfigMap my-cluster-df34923b-kafka-config in namespace namespace-36
2022-04-04 10:40:58 [main] [32mINFO [m [KafkaST:1173] Waiting for kafka stateful set labels changed {app.kubernetes.io/instance=my-cluster-df34923b, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-df34923b, controller-revision-hash=my-cluster-df34923b-kafka-dc465f77, statefulset.kubernetes.io/pod-name=my-cluster-df34923b-kafka-0, strimzi.io/cluster=my-cluster-df34923b, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-df34923b-kafka, test.case=testLabelModificationDoesNotBreakCluster}
2022-04-04 10:40:58 [main] [32mINFO [m [StatefulSetUtils:96] Waiting for StatefulSet label label-name-1 change to null
2022-04-04 10:40:59 [main] [32mINFO [m [StatefulSetUtils:101] StatefulSet label label-name-1 change to null
2022-04-04 10:40:59 [main] [32mINFO [m [StatefulSetUtils:96] Waiting for StatefulSet label label-name-2 change to null
2022-04-04 10:40:59 [main] [32mINFO [m [StatefulSetUtils:101] StatefulSet label label-name-2 change to null
2022-04-04 10:40:59 [main] [32mINFO [m [StatefulSetUtils:96] Waiting for StatefulSet label label-name-3 change to null
2022-04-04 10:40:59 [main] [32mINFO [m [StatefulSetUtils:101] StatefulSet label label-name-3 change to null
2022-04-04 10:40:59 [main] [32mINFO [m [KafkaST:1176] Verifying kafka labels via stateful set
2022-04-04 10:40:59 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-df34923b-kafka rolling update
2022-04-04 10:40:59 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-df34923b-kafka has been successfully rolled
2022-04-04 10:40:59 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-df34923b-kafka to be ready
2022-04-04 10:42:41 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-df34923b will have desired state: Ready
2022-04-04 10:42:41 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-df34923b is in desired state: Ready
2022-04-04 10:42:41 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-df34923b is ready
2022-04-04 10:42:41 [main] [32mINFO [m [KafkaST:1181] Waiting for kafka pod labels deletion {app.kubernetes.io/instance=my-cluster-df34923b, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-df34923b, controller-revision-hash=my-cluster-df34923b-kafka-dc465f77, statefulset.kubernetes.io/pod-name=my-cluster-df34923b-kafka-0, strimzi.io/cluster=my-cluster-df34923b, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-df34923b-kafka, test.case=testLabelModificationDoesNotBreakCluster}
2022-04-04 10:42:41 [main] [32mINFO [m [PodUtils:262] Waiting for Pod label label-name-1 change to null
2022-04-04 10:42:41 [main] [32mINFO [m [PodUtils:267] Pod label label-name-1 changed to null
2022-04-04 10:42:41 [main] [32mINFO [m [PodUtils:262] Waiting for Pod label label-name-2 change to null
2022-04-04 10:42:41 [main] [32mINFO [m [PodUtils:267] Pod label label-name-2 changed to null
2022-04-04 10:42:41 [main] [32mINFO [m [PodUtils:262] Waiting for Pod label label-name-3 change to null
2022-04-04 10:42:41 [main] [32mINFO [m [PodUtils:267] Pod label label-name-3 changed to null
2022-04-04 10:42:41 [main] [32mINFO [m [KafkaST:1186] Verifying via kafka pods
2022-04-04 10:42:41 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@76c21f07, messages=[], arguments=[--topic, my-topic-791111557-646272320, --max-messages, 100, --bootstrap-server, my-cluster-df34923b-kafka-bootstrap.namespace-36.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-df34923b-kafka-clients-bcbd757f-zgcnf', podNamespace='namespace-36', bootstrapServer='my-cluster-df34923b-kafka-bootstrap.namespace-36.svc:9092', topicName='my-topic-791111557-646272320', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7631a675}
2022-04-04 10:42:41 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-df34923b-kafka-bootstrap.namespace-36.svc:9092:my-topic-791111557-646272320 from pod my-cluster-df34923b-kafka-clients-bcbd757f-zgcnf
2022-04-04 10:42:41 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-df34923b-kafka-clients-bcbd757f-zgcnf -n namespace-36 -- /opt/kafka/producer.sh --topic my-topic-791111557-646272320 --max-messages 100 --bootstrap-server my-cluster-df34923b-kafka-bootstrap.namespace-36.svc:9092
2022-04-04 10:42:43 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 10:42:43 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 10:42:43 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@151fc7c3, messages=[], arguments=[--topic, my-topic-791111557-646272320, --max-messages, 100, --group-instance-id, instance1580493271, --group-id, my-consumer-group-1708988612, --bootstrap-server, my-cluster-df34923b-kafka-bootstrap.namespace-36.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-df34923b-kafka-clients-bcbd757f-zgcnf', podNamespace='namespace-36', bootstrapServer='my-cluster-df34923b-kafka-bootstrap.namespace-36.svc:9092', topicName='my-topic-791111557-646272320', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1708988612', consumerInstanceId='instance1580493271', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6e66c674}
2022-04-04 10:42:43 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-df34923b-kafka-bootstrap.namespace-36.svc:9092#my-topic-791111557-646272320 from pod my-cluster-df34923b-kafka-clients-bcbd757f-zgcnf
2022-04-04 10:42:43 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-df34923b-kafka-clients-bcbd757f-zgcnf -n namespace-36 -- /opt/kafka/consumer.sh --topic my-topic-791111557-646272320 --max-messages 100 --group-instance-id instance1580493271 --group-id my-consumer-group-1708988612 --bootstrap-server my-cluster-df34923b-kafka-bootstrap.namespace-36.svc:9092
2022-04-04 10:42:49 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 10:42:49 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 10:42:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:42:49 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testLabelModificationDoesNotBreakCluster
2022-04-04 10:42:49 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-791111557-646272320 in namespace namespace-36
2022-04-04 10:42:49 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-df34923b in namespace namespace-36
2022-04-04 10:42:49 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-df34923b-kafka-clients in namespace namespace-36
2022-04-04 10:43:39 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:43:39 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-36 for test case:testLabelModificationDoesNotBreakCluster
2022-04-04 10:43:46 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testLabelModificationDoesNotBreakCluster-FINISHED
2022-04-04 10:43:46 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:43:46 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:43:46 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testEODeletion-STARTED
2022-04-04 10:43:46 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:43:46 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-37 for test case:testEODeletion
2022-04-04 10:43:46 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-37
2022-04-04 10:43:46 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-37
2022-04-04 10:43:46 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-37
2022-04-04 10:43:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2c3491e9 in namespace namespace-37
2022-04-04 10:43:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-37
2022-04-04 10:43:46 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2c3491e9 will have desired state: Ready
2022-04-04 10:45:05 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2c3491e9 is in desired state: Ready
2022-04-04 10:45:05 [main] [32mINFO [m [KafkaST:122] Setting entity operator to null
2022-04-04 10:45:05 [main] [33mWARN [m [DeploymentUtils:213] Deployment my-cluster-2c3491e9-entity-operator is not deleted yet! Triggering force delete by cmd client!
2022-04-04 10:45:10 [main] [33mWARN [m [DeploymentUtils:213] Deployment my-cluster-2c3491e9-entity-operator is not deleted yet! Triggering force delete by cmd client!
2022-04-04 10:45:15 [main] [32mINFO [m [PodUtils:154] Waiting when Pod my-cluster-2c3491e9-entity-operator-86c457ff5f-rnsfs will be deleted
2022-04-04 10:45:15 [main] [32mINFO [m [PodUtils:171] Pod my-cluster-2c3491e9-entity-operator-86c457ff5f-rnsfs deleted
2022-04-04 10:45:15 [main] [32mINFO [m [KafkaST:130] Entity operator was deleted
2022-04-04 10:45:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:45:15 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testEODeletion
2022-04-04 10:45:15 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2c3491e9 in namespace namespace-37
2022-04-04 10:45:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:45:25 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-37 for test case:testEODeletion
2022-04-04 10:46:08 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testEODeletion-FINISHED
2022-04-04 10:46:08 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:46:08 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:46:08 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testJvmAndResources-STARTED
2022-04-04 10:46:08 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:46:08 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-38 for test case:testJvmAndResources
2022-04-04 10:46:08 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-38
2022-04-04 10:46:08 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-38
2022-04-04 10:46:08 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-38
2022-04-04 10:46:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-f5d65d8f in namespace namespace-38
2022-04-04 10:46:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-38
2022-04-04 10:46:09 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f5d65d8f will have desired state: Ready
2022-04-04 10:47:35 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f5d65d8f is in desired state: Ready
2022-04-04 10:47:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-38 exec my-cluster-f5d65d8f-kafka-0 -c kafka -- /bin/bash -c for proc in $(ls -1 /proc/ | grep [0-9]); do if echo "$(ls -lh /proc/$proc/exe 2>/dev/null || true)" | grep -q java; then cat /proc/$proc/cmdline; fi; done
2022-04-04 10:47:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:47:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-38 exec my-cluster-f5d65d8f-zookeeper-0 -c zookeeper -- /bin/bash -c for proc in $(ls -1 /proc/ | grep [0-9]); do if echo "$(ls -lh /proc/$proc/exe 2>/dev/null || true)" | grep -q java; then cat /proc/$proc/cmdline; fi; done
2022-04-04 10:47:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:47:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-38 exec my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4 -c topic-operator -- /bin/bash -c for proc in $(ls -1 /proc/ | grep [0-9]); do if echo "$(ls -lh /proc/$proc/exe 2>/dev/null || true)" | grep -q java; then cat /proc/$proc/cmdline; fi; done
2022-04-04 10:47:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:47:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-38 exec my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4 -c user-operator -- /bin/bash -c for proc in $(ls -1 /proc/ | grep [0-9]); do if echo "$(ls -lh /proc/$proc/exe 2>/dev/null || true)" | grep -q java; then cat /proc/$proc/cmdline; fi; done
2022-04-04 10:47:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:47:36 [main] [32mINFO [m [KafkaST:533] Check if -D java options are present in topic-operator
2022-04-04 10:47:36 [main] [32mINFO [m [KafkaST:533] Check if -D java options are present in user-operator
2022-04-04 10:47:36 [main] [32mINFO [m [KafkaST:552] Checking no rolling update for Kafka cluster
2022-04-04 10:47:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 50
2022-04-04 10:47:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 49
2022-04-04 10:47:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 48
2022-04-04 10:47:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 47
2022-04-04 10:47:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 46
2022-04-04 10:47:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 45
2022-04-04 10:47:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 44
2022-04-04 10:47:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 43
2022-04-04 10:47:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 42
2022-04-04 10:47:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 41
2022-04-04 10:47:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 40
2022-04-04 10:47:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 39
2022-04-04 10:47:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 38
2022-04-04 10:47:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 37
2022-04-04 10:47:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 36
2022-04-04 10:47:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 35
2022-04-04 10:47:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 34
2022-04-04 10:47:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 33
2022-04-04 10:47:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 32
2022-04-04 10:47:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 31
2022-04-04 10:47:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 30
2022-04-04 10:47:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 29
2022-04-04 10:47:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 28
2022-04-04 10:47:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 27
2022-04-04 10:48:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 26
2022-04-04 10:48:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 25
2022-04-04 10:48:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 24
2022-04-04 10:48:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 23
2022-04-04 10:48:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 22
2022-04-04 10:48:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 21
2022-04-04 10:48:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 20
2022-04-04 10:48:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 19
2022-04-04 10:48:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 18
2022-04-04 10:48:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 17
2022-04-04 10:48:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 16
2022-04-04 10:48:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 15
2022-04-04 10:48:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 14
2022-04-04 10:48:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 13
2022-04-04 10:48:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 12
2022-04-04 10:48:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 11
2022-04-04 10:48:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 10
2022-04-04 10:48:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 9
2022-04-04 10:48:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 8
2022-04-04 10:48:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 7
2022-04-04 10:48:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 6
2022-04-04 10:48:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 5
2022-04-04 10:48:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 4
2022-04-04 10:48:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 3
2022-04-04 10:48:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 2
2022-04-04 10:48:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 1
2022-04-04 10:48:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-zookeeper-0=dce225f1-1987-40f4-a547-48c6aa0fe5d8} pods didn't roll. Remaining seconds for stability: 0
2022-04-04 10:48:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 50
2022-04-04 10:48:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 49
2022-04-04 10:48:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 48
2022-04-04 10:48:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 47
2022-04-04 10:48:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 46
2022-04-04 10:48:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 45
2022-04-04 10:48:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 44
2022-04-04 10:48:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 43
2022-04-04 10:48:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 42
2022-04-04 10:48:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 41
2022-04-04 10:48:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 40
2022-04-04 10:48:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 39
2022-04-04 10:48:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 38
2022-04-04 10:48:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 37
2022-04-04 10:48:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 36
2022-04-04 10:48:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 35
2022-04-04 10:48:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 34
2022-04-04 10:48:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 33
2022-04-04 10:48:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 32
2022-04-04 10:48:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 31
2022-04-04 10:48:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 30
2022-04-04 10:48:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 29
2022-04-04 10:48:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 28
2022-04-04 10:48:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 27
2022-04-04 10:48:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 26
2022-04-04 10:48:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 25
2022-04-04 10:48:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 24
2022-04-04 10:48:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 23
2022-04-04 10:48:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 22
2022-04-04 10:48:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 21
2022-04-04 10:48:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 20
2022-04-04 10:48:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 19
2022-04-04 10:48:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 18
2022-04-04 10:48:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 17
2022-04-04 10:49:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 16
2022-04-04 10:49:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 15
2022-04-04 10:49:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 14
2022-04-04 10:49:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 13
2022-04-04 10:49:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 12
2022-04-04 10:49:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 11
2022-04-04 10:49:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 10
2022-04-04 10:49:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 9
2022-04-04 10:49:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 8
2022-04-04 10:49:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 7
2022-04-04 10:49:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 6
2022-04-04 10:49:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 5
2022-04-04 10:49:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 4
2022-04-04 10:49:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 3
2022-04-04 10:49:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 2
2022-04-04 10:49:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 1
2022-04-04 10:49:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-f5d65d8f-kafka-0=e857b67e-440d-43db-9ea9-a5b6ec950909} pods didn't roll. Remaining seconds for stability: 0
2022-04-04 10:49:16 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 50
2022-04-04 10:49:17 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 49
2022-04-04 10:49:18 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 48
2022-04-04 10:49:19 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 47
2022-04-04 10:49:20 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 46
2022-04-04 10:49:21 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 45
2022-04-04 10:49:22 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 44
2022-04-04 10:49:23 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 43
2022-04-04 10:49:24 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 42
2022-04-04 10:49:25 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 41
2022-04-04 10:49:26 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 40
2022-04-04 10:49:27 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 39
2022-04-04 10:49:28 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 38
2022-04-04 10:49:29 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 37
2022-04-04 10:49:30 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 36
2022-04-04 10:49:31 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 35
2022-04-04 10:49:32 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 34
2022-04-04 10:49:33 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 33
2022-04-04 10:49:34 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 32
2022-04-04 10:49:35 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 31
2022-04-04 10:49:36 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 30
2022-04-04 10:49:37 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 29
2022-04-04 10:49:38 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 28
2022-04-04 10:49:39 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 27
2022-04-04 10:49:40 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 26
2022-04-04 10:49:41 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 25
2022-04-04 10:49:42 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 24
2022-04-04 10:49:43 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 23
2022-04-04 10:49:44 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 22
2022-04-04 10:49:45 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 21
2022-04-04 10:49:46 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 20
2022-04-04 10:49:47 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 19
2022-04-04 10:49:48 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 18
2022-04-04 10:49:49 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 17
2022-04-04 10:49:50 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 16
2022-04-04 10:49:51 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 15
2022-04-04 10:49:52 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 14
2022-04-04 10:49:53 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 13
2022-04-04 10:49:54 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 12
2022-04-04 10:49:55 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 11
2022-04-04 10:49:56 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 10
2022-04-04 10:49:57 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 9
2022-04-04 10:49:58 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 8
2022-04-04 10:49:59 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 7
2022-04-04 10:50:00 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 6
2022-04-04 10:50:01 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 5
2022-04-04 10:50:02 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 4
2022-04-04 10:50:03 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 3
2022-04-04 10:50:04 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 2
2022-04-04 10:50:05 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 1
2022-04-04 10:50:06 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-f5d65d8f-entity-operator-5ccfcb6cb4-wxrv4=042bb838-a3a0-4160-b19b-ce02b2578652} pods not rolling waiting, remaining seconds for stability 0
2022-04-04 10:50:06 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:50:06 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testJvmAndResources
2022-04-04 10:50:06 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-f5d65d8f in namespace namespace-38
2022-04-04 10:50:16 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:50:17 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-38 for test case:testJvmAndResources
2022-04-04 10:50:27 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testJvmAndResources-FINISHED
2022-04-04 10:50:27 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:50:27 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:50:27 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testPersistentStorageSize-STARTED
2022-04-04 10:50:27 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:50:27 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-39 for test case:testPersistentStorageSize
2022-04-04 10:50:27 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-39
2022-04-04 10:50:27 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-39
2022-04-04 10:50:27 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-39
2022-04-04 10:50:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-af702623 in namespace namespace-39
2022-04-04 10:50:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-39
2022-04-04 10:50:27 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-af702623 will have desired state: Ready
2022-04-04 10:51:34 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-af702623 is in desired state: Ready
2022-04-04 10:51:34 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2124626368-1814624660 in namespace namespace-39
2022-04-04 10:51:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-39
2022-04-04 10:51:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2124626368-1814624660 will have desired state: Ready
2022-04-04 10:51:35 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2124626368-1814624660 is in desired state: Ready
2022-04-04 10:51:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-af702623-kafka-clients in namespace namespace-39
2022-04-04 10:51:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-39
2022-04-04 10:51:35 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-af702623-kafka-clients will be ready
2022-04-04 10:51:37 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-af702623-kafka-clients is ready
2022-04-04 10:51:37 [main] [32mINFO [m [KafkaST:1694] Checking volume data-0-my-cluster-af702623-kafka-0 and size of storage 70Gi
2022-04-04 10:51:37 [main] [32mINFO [m [KafkaST:1694] Checking volume data-0-my-cluster-af702623-kafka-1 and size of storage 70Gi
2022-04-04 10:51:37 [main] [32mINFO [m [KafkaST:1694] Checking volume data-1-my-cluster-af702623-kafka-0 and size of storage 20Gi
2022-04-04 10:51:37 [main] [32mINFO [m [KafkaST:1694] Checking volume data-1-my-cluster-af702623-kafka-1 and size of storage 20Gi
2022-04-04 10:51:37 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 10:51:37 [main] [32mINFO [m [KafkaST:983] Checking produced and consumed messages to pod:my-cluster-af702623-kafka-clients-959c4bc5c-4m6j5
2022-04-04 10:51:37 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@6d3fa642, messages=[], arguments=[--topic, my-topic-2124626368-1814624660, --max-messages, 100, --bootstrap-server, my-cluster-af702623-kafka-bootstrap.namespace-39.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-af702623-kafka-clients-959c4bc5c-4m6j5', podNamespace='namespace-39', bootstrapServer='my-cluster-af702623-kafka-bootstrap.namespace-39.svc:9092', topicName='my-topic-2124626368-1814624660', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6541877}
2022-04-04 10:51:37 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-af702623-kafka-bootstrap.namespace-39.svc:9092:my-topic-2124626368-1814624660 from pod my-cluster-af702623-kafka-clients-959c4bc5c-4m6j5
2022-04-04 10:51:37 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-af702623-kafka-clients-959c4bc5c-4m6j5 -n namespace-39 -- /opt/kafka/producer.sh --topic my-topic-2124626368-1814624660 --max-messages 100 --bootstrap-server my-cluster-af702623-kafka-bootstrap.namespace-39.svc:9092
2022-04-04 10:51:39 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 10:51:39 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 10:51:39 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@12275c1a, messages=[], arguments=[--topic, my-topic-2124626368-1814624660, --max-messages, 100, --group-instance-id, instance1783811703, --group-id, my-consumer-group-1387679783, --bootstrap-server, my-cluster-af702623-kafka-bootstrap.namespace-39.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-af702623-kafka-clients-959c4bc5c-4m6j5', podNamespace='namespace-39', bootstrapServer='my-cluster-af702623-kafka-bootstrap.namespace-39.svc:9092', topicName='my-topic-2124626368-1814624660', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1387679783', consumerInstanceId='instance1783811703', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@34967d5f}
2022-04-04 10:51:39 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-af702623-kafka-bootstrap.namespace-39.svc:9092#my-topic-2124626368-1814624660 from pod my-cluster-af702623-kafka-clients-959c4bc5c-4m6j5
2022-04-04 10:51:39 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-af702623-kafka-clients-959c4bc5c-4m6j5 -n namespace-39 -- /opt/kafka/consumer.sh --topic my-topic-2124626368-1814624660 --max-messages 100 --group-instance-id instance1783811703 --group-id my-consumer-group-1387679783 --bootstrap-server my-cluster-af702623-kafka-bootstrap.namespace-39.svc:9092
2022-04-04 10:51:45 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 10:51:45 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 10:51:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:51:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testPersistentStorageSize
2022-04-04 10:51:45 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2124626368-1814624660 in namespace namespace-39
2022-04-04 10:51:45 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-af702623 in namespace namespace-39
2022-04-04 10:51:45 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-af702623-kafka-clients in namespace namespace-39
2022-04-04 10:52:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:52:35 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-39 for test case:testPersistentStorageSize
2022-04-04 10:52:40 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testPersistentStorageSize-FINISHED
2022-04-04 10:52:40 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:52:40 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:52:40 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testForTopicOperator-STARTED
2022-04-04 10:52:40 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:52:40 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-40 for test case:testForTopicOperator
2022-04-04 10:52:40 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-40
2022-04-04 10:52:40 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-40
2022-04-04 10:52:40 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-40
2022-04-04 10:52:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ec05fead in namespace namespace-40
2022-04-04 10:52:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-40
2022-04-04 10:52:40 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ec05fead will have desired state: Ready
2022-04-04 10:53:51 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ec05fead is in desired state: Ready
2022-04-04 10:53:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-412726258-306569894 in namespace namespace-40
2022-04-04 10:53:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-40
2022-04-04 10:53:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-412726258-306569894 will have desired state: Ready
2022-04-04 10:53:53 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-412726258-306569894 is in desired state: Ready
2022-04-04 10:53:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-412726258-306569894 will have desired state: Ready
2022-04-04 10:53:53 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-412726258-306569894 is in desired state: Ready
2022-04-04 10:53:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-40 exec my-cluster-ec05fead-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-04 10:53:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:53:58 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-40 exec my-cluster-ec05fead-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --create  --topic topic-from-cli --replication-factor 1 --partitions 1
2022-04-04 10:53:58 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:53:58 [main] [32mINFO [m [KafkaTopicUtils:78] Waiting for KafkaTopic topic-from-cli creation 
2022-04-04 10:54:02 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-40 exec my-cluster-ec05fead-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-04 10:54:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:54:04 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-40 exec my-cluster-ec05fead-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic my-topic-412726258-306569894 --partitions 2
2022-04-04 10:54:04 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:54:04 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ec05fead will have desired state: Ready
2022-04-04 10:54:04 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ec05fead is in desired state: Ready
2022-04-04 10:54:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-40 exec my-cluster-ec05fead-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic my-topic-412726258-306569894
2022-04-04 10:54:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:54:07 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ec05fead will have desired state: Ready
2022-04-04 10:54:07 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ec05fead is in desired state: Ready
2022-04-04 10:54:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-40 exec my-cluster-ec05fead-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic topic-from-cli
2022-04-04 10:54:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:54:13 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-40 exec my-cluster-ec05fead-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic my-topic-412726258-306569894
2022-04-04 10:54:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:54:13 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-412726258-306569894 deletion
2022-04-04 10:54:13 [main] [33mWARN [m [KafkaTopicUtils:110] KafkaTopic my-topic-412726258-306569894 is not deleted yet! Triggering force delete by cmd client!
2022-04-04 10:54:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-40 exec my-cluster-ec05fead-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-04 10:54:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:54:26 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:54:26 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testForTopicOperator
2022-04-04 10:54:26 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-412726258-306569894 in namespace namespace-40
2022-04-04 10:54:26 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ec05fead in namespace namespace-40
2022-04-04 10:54:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:54:36 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-40 for test case:testForTopicOperator
2022-04-04 10:55:03 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testForTopicOperator-FINISHED
2022-04-04 10:55:03 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:55:03 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:55:03 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testReadOnlyRootFileSystem-STARTED
2022-04-04 10:55:03 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:55:03 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-41 for test case:testReadOnlyRootFileSystem
2022-04-04 10:55:03 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-41
2022-04-04 10:55:03 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-41
2022-04-04 10:55:03 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-41
2022-04-04 10:55:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-36a6998d in namespace namespace-41
2022-04-04 10:55:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-41
2022-04-04 10:55:03 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-36a6998d will have desired state: Ready
2022-04-04 10:57:02 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-36a6998d is in desired state: Ready
2022-04-04 10:57:02 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-36a6998d will have desired state: Ready
2022-04-04 10:57:02 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-36a6998d is in desired state: Ready
2022-04-04 10:57:02 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1382406341-1426994350 in namespace namespace-41
2022-04-04 10:57:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-41
2022-04-04 10:57:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1382406341-1426994350 will have desired state: Ready
2022-04-04 10:57:03 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1382406341-1426994350 is in desired state: Ready
2022-04-04 10:57:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-36a6998d-kafka-clients in namespace namespace-41
2022-04-04 10:57:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-41
2022-04-04 10:57:03 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-36a6998d-kafka-clients will be ready
2022-04-04 10:57:05 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-36a6998d-kafka-clients is ready
2022-04-04 10:57:05 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 10:57:05 [main] [32mINFO [m [KafkaST:1652] Checking produced and consumed messages to pod:my-cluster-36a6998d-kafka-clients-5c694d6955-9dtm5
2022-04-04 10:57:05 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@510524be, messages=[], arguments=[--topic, my-topic-1382406341-1426994350, --max-messages, 100, --bootstrap-server, my-cluster-36a6998d-kafka-bootstrap.namespace-41.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-36a6998d-kafka-clients-5c694d6955-9dtm5', podNamespace='namespace-41', bootstrapServer='my-cluster-36a6998d-kafka-bootstrap.namespace-41.svc:9092', topicName='my-topic-1382406341-1426994350', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@43299f7c}
2022-04-04 10:57:05 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-36a6998d-kafka-bootstrap.namespace-41.svc:9092:my-topic-1382406341-1426994350 from pod my-cluster-36a6998d-kafka-clients-5c694d6955-9dtm5
2022-04-04 10:57:05 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-36a6998d-kafka-clients-5c694d6955-9dtm5 -n namespace-41 -- /opt/kafka/producer.sh --topic my-topic-1382406341-1426994350 --max-messages 100 --bootstrap-server my-cluster-36a6998d-kafka-bootstrap.namespace-41.svc:9092
2022-04-04 10:57:07 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 10:57:07 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 10:57:07 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2d7ed77c, messages=[], arguments=[--topic, my-topic-1382406341-1426994350, --max-messages, 100, --group-instance-id, instance1991529633, --group-id, my-consumer-group-707449195, --bootstrap-server, my-cluster-36a6998d-kafka-bootstrap.namespace-41.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-36a6998d-kafka-clients-5c694d6955-9dtm5', podNamespace='namespace-41', bootstrapServer='my-cluster-36a6998d-kafka-bootstrap.namespace-41.svc:9092', topicName='my-topic-1382406341-1426994350', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-707449195', consumerInstanceId='instance1991529633', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@22a36e2b}
2022-04-04 10:57:07 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-36a6998d-kafka-bootstrap.namespace-41.svc:9092#my-topic-1382406341-1426994350 from pod my-cluster-36a6998d-kafka-clients-5c694d6955-9dtm5
2022-04-04 10:57:07 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-36a6998d-kafka-clients-5c694d6955-9dtm5 -n namespace-41 -- /opt/kafka/consumer.sh --topic my-topic-1382406341-1426994350 --max-messages 100 --group-instance-id instance1991529633 --group-id my-consumer-group-707449195 --bootstrap-server my-cluster-36a6998d-kafka-bootstrap.namespace-41.svc:9092
2022-04-04 10:57:13 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 10:57:13 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 10:57:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:57:13 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testReadOnlyRootFileSystem
2022-04-04 10:57:13 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1382406341-1426994350 in namespace namespace-41
2022-04-04 10:57:13 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-36a6998d in namespace namespace-41
2022-04-04 10:57:13 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-36a6998d-kafka-clients in namespace namespace-41
2022-04-04 10:57:13 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-41, for cruise control Kafka cluster my-cluster-36a6998d
2022-04-04 10:57:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:57:53 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-41 for test case:testReadOnlyRootFileSystem
2022-04-04 10:58:20 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testReadOnlyRootFileSystem-FINISHED
2022-04-04 10:58:20 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:58:20 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:58:20 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testCustomAndUpdatedValues-STARTED
2022-04-04 10:58:20 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:58:20 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-42 for test case:testCustomAndUpdatedValues
2022-04-04 10:58:20 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-42
2022-04-04 10:58:20 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-42
2022-04-04 10:58:20 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-42
2022-04-04 10:58:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d3643d73 in namespace namespace-42
2022-04-04 10:58:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-42
2022-04-04 10:58:20 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d3643d73 will have desired state: Ready
2022-04-04 11:01:15 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d3643d73 is in desired state: Ready
2022-04-04 11:01:15 [main] [32mINFO [m [KafkaST:290] Verify values before update
2022-04-04 11:01:15 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-d3643d73-kafka in pod name
2022-04-04 11:01:15 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container kafka
2022-04-04 11:01:15 [main] [32mINFO [m [KafkaST:1661] Checking kafka configuration
2022-04-04 11:01:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-42 exec my-cluster-d3643d73-kafka-0 -- /bin/bash -c cat /tmp/strimzi.properties
2022-04-04 11:01:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:01:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-42 exec my-cluster-d3643d73-kafka-1 -- /bin/bash -c cat /tmp/strimzi.properties
2022-04-04 11:01:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:01:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-42 exec my-cluster-d3643d73-kafka-2 -- /bin/bash -c cat /tmp/strimzi.properties
2022-04-04 11:01:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:01:15 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-d3643d73-kafka
2022-04-04 11:01:15 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container kafka
2022-04-04 11:01:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-42 exec my-cluster-d3643d73-kafka-0 -- cat /tmp/strimzi.properties
2022-04-04 11:01:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:01:15 [main] [32mINFO [m [KafkaST:308] Testing Zookeepers
2022-04-04 11:01:15 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-d3643d73-zookeeper in pod name
2022-04-04 11:01:15 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container zookeeper
2022-04-04 11:01:15 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-d3643d73-zookeeper
2022-04-04 11:01:15 [main] [32mINFO [m [AbstractST:194] Testing configuration for container zookeeper
2022-04-04 11:01:15 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-d3643d73-zookeeper
2022-04-04 11:01:15 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container zookeeper
2022-04-04 11:01:15 [main] [32mINFO [m [KafkaST:315] Checking configuration of TO and UO
2022-04-04 11:01:15 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-d3643d73-entity-operator in pod name
2022-04-04 11:01:15 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container topic-operator
2022-04-04 11:01:15 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-d3643d73-entity-operator
2022-04-04 11:01:15 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container topic-operator
2022-04-04 11:01:15 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-d3643d73-entity-operator in pod name
2022-04-04 11:01:15 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container user-operator
2022-04-04 11:01:15 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-d3643d73-entity-operator
2022-04-04 11:01:15 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container user-operator
2022-04-04 11:01:15 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-d3643d73-entity-operator in pod name
2022-04-04 11:01:15 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container tls-sidecar
2022-04-04 11:01:15 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-d3643d73-entity-operator
2022-04-04 11:01:15 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container tls-sidecar
2022-04-04 11:01:15 [main] [32mINFO [m [KafkaST:326] Updating configuration of Kafka cluster
2022-04-04 11:01:15 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-d3643d73-zookeeper rolling update
2022-04-04 11:02:46 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-d3643d73-zookeeper has been successfully rolled
2022-04-04 11:02:46 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-d3643d73-zookeeper to be ready
2022-04-04 11:03:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d3643d73 will have desired state: Ready
2022-04-04 11:03:31 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d3643d73 is in desired state: Ready
2022-04-04 11:03:31 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-d3643d73 is ready
2022-04-04 11:03:31 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-d3643d73-kafka rolling update
2022-04-04 11:04:56 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-d3643d73-kafka has been successfully rolled
2022-04-04 11:04:56 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-d3643d73-kafka to be ready
2022-04-04 11:05:38 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d3643d73 will have desired state: Ready
2022-04-04 11:05:38 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d3643d73 is in desired state: Ready
2022-04-04 11:05:38 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-d3643d73 is ready
2022-04-04 11:05:38 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-d3643d73-entity-operator rolling update
2022-04-04 11:05:38 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d3643d73-entity-operator will be ready
2022-04-04 11:07:18 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d3643d73-entity-operator is ready
2022-04-04 11:07:28 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-d3643d73-entity-operator rolling update finished
2022-04-04 11:07:28 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d3643d73 will have desired state: Ready
2022-04-04 11:07:28 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d3643d73 is in desired state: Ready
2022-04-04 11:07:28 [main] [32mINFO [m [KafkaST:386] Verify values after update
2022-04-04 11:07:28 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-d3643d73-kafka in pod name
2022-04-04 11:07:28 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container kafka
2022-04-04 11:07:28 [main] [32mINFO [m [KafkaST:1661] Checking kafka configuration
2022-04-04 11:07:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-42 exec my-cluster-d3643d73-kafka-0 -- /bin/bash -c cat /tmp/strimzi.properties
2022-04-04 11:07:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:07:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-42 exec my-cluster-d3643d73-kafka-1 -- /bin/bash -c cat /tmp/strimzi.properties
2022-04-04 11:07:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:07:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-42 exec my-cluster-d3643d73-kafka-2 -- /bin/bash -c cat /tmp/strimzi.properties
2022-04-04 11:07:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:07:29 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-d3643d73-kafka
2022-04-04 11:07:29 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container kafka
2022-04-04 11:07:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-42 exec my-cluster-d3643d73-kafka-0 -- cat /tmp/strimzi.properties
2022-04-04 11:07:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:07:29 [main] [32mINFO [m [KafkaST:404] Testing Zookeepers
2022-04-04 11:07:29 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-d3643d73-zookeeper in pod name
2022-04-04 11:07:29 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container zookeeper
2022-04-04 11:07:29 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-d3643d73-zookeeper
2022-04-04 11:07:29 [main] [32mINFO [m [AbstractST:194] Testing configuration for container zookeeper
2022-04-04 11:07:29 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-d3643d73-zookeeper
2022-04-04 11:07:29 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container zookeeper
2022-04-04 11:07:29 [main] [32mINFO [m [KafkaST:410] Getting entity operator to check configuration of TO and UO
2022-04-04 11:07:29 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-d3643d73-entity-operator in pod name
2022-04-04 11:07:29 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container topic-operator
2022-04-04 11:07:29 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-d3643d73-entity-operator
2022-04-04 11:07:29 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container topic-operator
2022-04-04 11:07:29 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-d3643d73-entity-operator in pod name
2022-04-04 11:07:29 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container user-operator
2022-04-04 11:07:29 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-d3643d73-entity-operator
2022-04-04 11:07:29 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container user-operator
2022-04-04 11:07:29 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-d3643d73-entity-operator in pod name
2022-04-04 11:07:29 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container tls-sidecar
2022-04-04 11:07:29 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-d3643d73-entity-operator
2022-04-04 11:07:29 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container tls-sidecar
2022-04-04 11:07:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:07:29 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCustomAndUpdatedValues
2022-04-04 11:07:29 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d3643d73 in namespace namespace-42
2022-04-04 11:07:39 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:07:39 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-42 for test case:testCustomAndUpdatedValues
2022-04-04 11:08:23 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testCustomAndUpdatedValues-FINISHED
2022-04-04 11:08:23 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:08:23 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:08:23 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testKafkaJBODDeleteClaimsTrue-STARTED
2022-04-04 11:08:23 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:08:23 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-43 for test case:testKafkaJBODDeleteClaimsTrue
2022-04-04 11:08:23 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-43
2022-04-04 11:08:23 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-43
2022-04-04 11:08:23 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-43
2022-04-04 11:08:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-17986ec8 in namespace namespace-43
2022-04-04 11:08:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-43
2022-04-04 11:08:23 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-17986ec8 will have desired state: Ready
2022-04-04 11:10:05 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-17986ec8 is in desired state: Ready
2022-04-04 11:10:05 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-0-my-cluster-17986ec8-kafka-0
2022-04-04 11:10:05 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-0-my-cluster-17986ec8-kafka-1
2022-04-04 11:10:05 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-1-my-cluster-17986ec8-kafka-0
2022-04-04 11:10:05 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-1-my-cluster-17986ec8-kafka-1
2022-04-04 11:10:05 [main] [32mINFO [m [KafkaST:1717] Checking PVC names included in JBOD array
2022-04-04 11:10:05 [main] [32mINFO [m [KafkaST:1724] Checking PVC on Kafka pods
2022-04-04 11:10:05 [main] [32mINFO [m [KafkaST:1729] Getting list of mounted data sources and PVCs on Kafka pod 0
2022-04-04 11:10:05 [main] [32mINFO [m [KafkaST:1737] Verifying mounted data sources and PVCs on Kafka pod 0
2022-04-04 11:10:05 [main] [32mINFO [m [KafkaST:1729] Getting list of mounted data sources and PVCs on Kafka pod 1
2022-04-04 11:10:05 [main] [32mINFO [m [KafkaST:1737] Verifying mounted data sources and PVCs on Kafka pod 1
2022-04-04 11:10:05 [main] [32mINFO [m [KafkaST:906] Deleting cluster
2022-04-04 11:10:05 [main] [32mINFO [m [KafkaST:909] Waiting for PVC deletion
2022-04-04 11:10:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:10:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaJBODDeleteClaimsTrue
2022-04-04 11:10:45 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-17986ec8 in namespace namespace-43
2022-04-04 11:10:45 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:10:45 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-43 for test case:testKafkaJBODDeleteClaimsTrue
2022-04-04 11:10:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testKafkaJBODDeleteClaimsTrue-FINISHED
2022-04-04 11:10:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:10:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:10:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testKafkaJBODDeleteClaimsFalse-STARTED
2022-04-04 11:10:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:10:51 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-44 for test case:testKafkaJBODDeleteClaimsFalse
2022-04-04 11:10:51 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-44
2022-04-04 11:10:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-44
2022-04-04 11:10:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-44
2022-04-04 11:10:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a703f570 in namespace namespace-44
2022-04-04 11:10:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-44
2022-04-04 11:10:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a703f570 will have desired state: Ready
2022-04-04 11:12:09 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a703f570 is in desired state: Ready
2022-04-04 11:12:09 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-0-my-cluster-a703f570-kafka-0
2022-04-04 11:12:09 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-0-my-cluster-a703f570-kafka-1
2022-04-04 11:12:09 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-1-my-cluster-a703f570-kafka-0
2022-04-04 11:12:09 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-1-my-cluster-a703f570-kafka-1
2022-04-04 11:12:09 [main] [32mINFO [m [KafkaST:1717] Checking PVC names included in JBOD array
2022-04-04 11:12:09 [main] [32mINFO [m [KafkaST:1724] Checking PVC on Kafka pods
2022-04-04 11:12:09 [main] [32mINFO [m [KafkaST:1729] Getting list of mounted data sources and PVCs on Kafka pod 0
2022-04-04 11:12:09 [main] [32mINFO [m [KafkaST:1737] Verifying mounted data sources and PVCs on Kafka pod 0
2022-04-04 11:12:09 [main] [32mINFO [m [KafkaST:1729] Getting list of mounted data sources and PVCs on Kafka pod 1
2022-04-04 11:12:09 [main] [32mINFO [m [KafkaST:1737] Verifying mounted data sources and PVCs on Kafka pod 1
2022-04-04 11:12:09 [main] [32mINFO [m [KafkaST:930] Deleting cluster
2022-04-04 11:12:09 [main] [32mINFO [m [KafkaST:933] Waiting for PVC deletion
2022-04-04 11:12:09 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:12:09 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaJBODDeleteClaimsFalse
2022-04-04 11:12:09 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a703f570 in namespace namespace-44
2022-04-04 11:12:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:12:09 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-44 for test case:testKafkaJBODDeleteClaimsFalse
2022-04-04 11:12:20 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testKafkaJBODDeleteClaimsFalse-FINISHED
2022-04-04 11:12:20 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:12:20 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:12:20 [main] [32mINFO [m [ResourceManager:346] In context KafkaST is everything deleted.
2022-04-04 11:12:20 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 23, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4,536.001 s - in io.strimzi.systemtest.kafka.KafkaST
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.listeners.ListenersST
2022-04-04 11:12:28 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: listeners-st
2022-04-04 11:12:28 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: listeners-st
2022-04-04 11:12:28 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: listeners-st
2022-04-04 11:12:28 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:12:28 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesTlsAuthenticated-STARTED
2022-04-04 11:12:28 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:12:28 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-45 for test case:testSendMessagesTlsAuthenticated
2022-04-04 11:12:28 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-45
2022-04-04 11:12:28 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-45
2022-04-04 11:12:28 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-45
2022-04-04 11:12:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e35f34cf in namespace namespace-45
2022-04-04 11:12:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-45
2022-04-04 11:12:28 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e35f34cf will have desired state: Ready
2022-04-04 11:13:51 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e35f34cf is in desired state: Ready
2022-04-04 11:13:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-289399582-2015089924 in namespace namespace-45
2022-04-04 11:13:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-45
2022-04-04 11:13:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-289399582-2015089924 will have desired state: Ready
2022-04-04 11:13:52 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-289399582-2015089924 is in desired state: Ready
2022-04-04 11:13:52 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1703262388-398682254 in namespace namespace-45
2022-04-04 11:13:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-45
2022-04-04 11:13:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1703262388-398682254 will have desired state: Ready
2022-04-04 11:13:53 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1703262388-398682254 is in desired state: Ready
2022-04-04 11:13:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-e35f34cf-kafka-clients in namespace namespace-45
2022-04-04 11:13:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-45
2022-04-04 11:13:53 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-e35f34cf-kafka-clients will be ready
2022-04-04 11:13:55 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-e35f34cf-kafka-clients is ready
2022-04-04 11:13:55 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 11:13:55 [main] [32mINFO [m [ListenersST:221] Checking produced and consumed messages to pod:my-cluster-e35f34cf-kafka-clients-8567f7f94c-m2s99
2022-04-04 11:13:55 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@35fd0de5, messages=[], arguments=[--topic, my-topic-289399582-2015089924, --max-messages, 100, USER=my_user_1703262388_398682254, --bootstrap-server, my-cluster-e35f34cf-kafka-bootstrap.namespace-45.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-e35f34cf-kafka-clients-8567f7f94c-m2s99', podNamespace='namespace-45', bootstrapServer='my-cluster-e35f34cf-kafka-bootstrap.namespace-45.svc:9093', topicName='my-topic-289399582-2015089924', maxMessages=100, kafkaUsername='my-user-1703262388-398682254', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@792b67f1}
2022-04-04 11:13:55 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-e35f34cf-kafka-bootstrap.namespace-45.svc:9093:my-topic-289399582-2015089924 from pod my-cluster-e35f34cf-kafka-clients-8567f7f94c-m2s99
2022-04-04 11:13:55 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-e35f34cf-kafka-clients-8567f7f94c-m2s99 -n namespace-45 -- /opt/kafka/producer.sh --topic my-topic-289399582-2015089924 --max-messages 100 USER=my_user_1703262388_398682254 --bootstrap-server my-cluster-e35f34cf-kafka-bootstrap.namespace-45.svc:9093
2022-04-04 11:13:59 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 11:13:59 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 11:13:59 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@78111c98, messages=[], arguments=[--topic, my-topic-289399582-2015089924, --max-messages, 100, --group-instance-id, instance1291352926, USER=my_user_1703262388_398682254, --group-id, my-consumer-group-1045967280, --bootstrap-server, my-cluster-e35f34cf-kafka-bootstrap.namespace-45.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-e35f34cf-kafka-clients-8567f7f94c-m2s99', podNamespace='namespace-45', bootstrapServer='my-cluster-e35f34cf-kafka-bootstrap.namespace-45.svc:9093', topicName='my-topic-289399582-2015089924', maxMessages=100, kafkaUsername='my-user-1703262388-398682254', consumerGroupName='my-consumer-group-1045967280', consumerInstanceId='instance1291352926', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5aa7fcd2}
2022-04-04 11:13:59 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-e35f34cf-kafka-bootstrap.namespace-45.svc:9093:my-topic-289399582-2015089924 from pod my-cluster-e35f34cf-kafka-clients-8567f7f94c-m2s99
2022-04-04 11:13:59 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-e35f34cf-kafka-clients-8567f7f94c-m2s99 -n namespace-45 -- /opt/kafka/consumer.sh --topic my-topic-289399582-2015089924 --max-messages 100 --group-instance-id instance1291352926 USER=my_user_1703262388_398682254 --group-id my-consumer-group-1045967280 --bootstrap-server my-cluster-e35f34cf-kafka-bootstrap.namespace-45.svc:9093
2022-04-04 11:14:06 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 11:14:06 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 11:14:06 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:14:06 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendMessagesTlsAuthenticated
2022-04-04 11:14:06 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1703262388-398682254 in namespace namespace-45
2022-04-04 11:14:06 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-e35f34cf-kafka-clients in namespace namespace-45
2022-04-04 11:14:06 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e35f34cf in namespace namespace-45
2022-04-04 11:14:06 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-289399582-2015089924 in namespace namespace-45
2022-04-04 11:14:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:14:56 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-45 for test case:testSendMessagesTlsAuthenticated
2022-04-04 11:15:01 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesTlsAuthenticated-FINISHED
2022-04-04 11:15:01 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:15:01 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:15:01 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesCustomListenerTlsScramSha-STARTED
2022-04-04 11:15:01 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:15:01 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-46 for test case:testSendMessagesCustomListenerTlsScramSha
2022-04-04 11:15:01 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-46
2022-04-04 11:15:01 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-46
2022-04-04 11:15:01 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-46
2022-04-04 11:15:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-4e302bea in namespace namespace-46
2022-04-04 11:15:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-46
2022-04-04 11:15:01 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4e302bea will have desired state: Ready
2022-04-04 11:16:20 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4e302bea is in desired state: Ready
2022-04-04 11:16:20 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-36365083-913759817 in namespace namespace-46
2022-04-04 11:16:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-46
2022-04-04 11:16:20 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-36365083-913759817 will have desired state: Ready
2022-04-04 11:16:21 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-36365083-913759817 is in desired state: Ready
2022-04-04 11:16:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-768508341-7565265 in namespace namespace-46
2022-04-04 11:16:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-46
2022-04-04 11:16:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-768508341-7565265 will have desired state: Ready
2022-04-04 11:16:22 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-768508341-7565265 is in desired state: Ready
2022-04-04 11:16:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-4e302bea-kafka-clients in namespace namespace-46
2022-04-04 11:16:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-46
2022-04-04 11:16:22 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4e302bea-kafka-clients will be ready
2022-04-04 11:16:24 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4e302bea-kafka-clients is ready
2022-04-04 11:16:24 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 11:16:24 [main] [32mINFO [m [ListenersST:442] Checking produced and consumed messages to pod:my-cluster-4e302bea-kafka-clients-64b658f68c-fc8tr
2022-04-04 11:16:24 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@54fad1d9, messages=[], arguments=[--topic, my-topic-36365083-913759817, --max-messages, 100, USER=my_user_768508341_7565265, --bootstrap-server, my-cluster-4e302bea-kafka-bootstrap.namespace-46.svc:9122], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-4e302bea-kafka-clients-64b658f68c-fc8tr', podNamespace='namespace-46', bootstrapServer='my-cluster-4e302bea-kafka-bootstrap.namespace-46.svc:9122', topicName='my-topic-36365083-913759817', maxMessages=100, kafkaUsername='my-user-768508341-7565265', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7597bf6e}
2022-04-04 11:16:24 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-4e302bea-kafka-bootstrap.namespace-46.svc:9122:my-topic-36365083-913759817 from pod my-cluster-4e302bea-kafka-clients-64b658f68c-fc8tr
2022-04-04 11:16:24 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4e302bea-kafka-clients-64b658f68c-fc8tr -n namespace-46 -- /opt/kafka/producer.sh --topic my-topic-36365083-913759817 --max-messages 100 USER=my_user_768508341_7565265 --bootstrap-server my-cluster-4e302bea-kafka-bootstrap.namespace-46.svc:9122
2022-04-04 11:16:27 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 11:16:27 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 11:16:27 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@18208373, messages=[], arguments=[--topic, my-topic-36365083-913759817, --max-messages, 100, --group-instance-id, instance1932451192, USER=my_user_768508341_7565265, --group-id, my-consumer-group-1729977215, --bootstrap-server, my-cluster-4e302bea-kafka-bootstrap.namespace-46.svc:9122], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-4e302bea-kafka-clients-64b658f68c-fc8tr', podNamespace='namespace-46', bootstrapServer='my-cluster-4e302bea-kafka-bootstrap.namespace-46.svc:9122', topicName='my-topic-36365083-913759817', maxMessages=100, kafkaUsername='my-user-768508341-7565265', consumerGroupName='my-consumer-group-1729977215', consumerInstanceId='instance1932451192', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@50042ad2}
2022-04-04 11:16:27 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-4e302bea-kafka-bootstrap.namespace-46.svc:9122:my-topic-36365083-913759817 from pod my-cluster-4e302bea-kafka-clients-64b658f68c-fc8tr
2022-04-04 11:16:27 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4e302bea-kafka-clients-64b658f68c-fc8tr -n namespace-46 -- /opt/kafka/consumer.sh --topic my-topic-36365083-913759817 --max-messages 100 --group-instance-id instance1932451192 USER=my_user_768508341_7565265 --group-id my-consumer-group-1729977215 --bootstrap-server my-cluster-4e302bea-kafka-bootstrap.namespace-46.svc:9122
2022-04-04 11:16:34 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 11:16:34 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 11:16:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:16:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendMessagesCustomListenerTlsScramSha
2022-04-04 11:16:34 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-768508341-7565265 in namespace namespace-46
2022-04-04 11:16:34 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-4e302bea-kafka-clients in namespace namespace-46
2022-04-04 11:16:34 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-4e302bea in namespace namespace-46
2022-04-04 11:16:34 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-36365083-913759817 in namespace namespace-46
2022-04-04 11:17:15 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:17:15 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-46 for test case:testSendMessagesCustomListenerTlsScramSha
2022-04-04 11:17:25 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesCustomListenerTlsScramSha-FINISHED
2022-04-04 11:17:25 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:17:25 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:17:25 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testCertificateWithNonExistingDataCrt-STARTED
2022-04-04 11:17:25 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:17:25 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-47 for test case:testCertificateWithNonExistingDataCrt
2022-04-04 11:17:25 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-47
2022-04-04 11:17:25 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-47
2022-04-04 11:17:25 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-47
2022-04-04 11:17:25 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret my-cluster-835af067-custom-certificate-server-1
2022-04-04 11:17:25 [main] [32mINFO [m [SecretUtils:50] Secret my-cluster-835af067-custom-certificate-server-1 created
2022-04-04 11:17:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-835af067 in namespace namespace-47
2022-04-04 11:17:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-47
2022-04-04 11:17:55 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:17:55 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCertificateWithNonExistingDataCrt
2022-04-04 11:17:55 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-835af067 in namespace namespace-47
2022-04-04 11:17:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:17:55 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-47 for test case:testCertificateWithNonExistingDataCrt
2022-04-04 11:18:06 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testCertificateWithNonExistingDataCrt-FINISHED
2022-04-04 11:18:06 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:18:06 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:18:06 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testCertificateWithNonExistingDataKey-STARTED
2022-04-04 11:18:06 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:18:06 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-48 for test case:testCertificateWithNonExistingDataKey
2022-04-04 11:18:06 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-48
2022-04-04 11:18:06 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-48
2022-04-04 11:18:06 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-48
2022-04-04 11:18:06 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret my-cluster-0aa3477d-custom-certificate-server-1
2022-04-04 11:18:06 [main] [32mINFO [m [SecretUtils:50] Secret my-cluster-0aa3477d-custom-certificate-server-1 created
2022-04-04 11:18:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0aa3477d in namespace namespace-48
2022-04-04 11:18:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-48
2022-04-04 11:18:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:18:40 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCertificateWithNonExistingDataKey
2022-04-04 11:18:40 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0aa3477d in namespace namespace-48
2022-04-04 11:18:40 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:18:40 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-48 for test case:testCertificateWithNonExistingDataKey
2022-04-04 11:19:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testCertificateWithNonExistingDataKey-FINISHED
2022-04-04 11:19:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:19:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:19:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesPlainAnonymous-STARTED
2022-04-04 11:19:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:19:07 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-49 for test case:testSendMessagesPlainAnonymous
2022-04-04 11:19:07 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-49
2022-04-04 11:19:07 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-49
2022-04-04 11:19:07 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-49
2022-04-04 11:19:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-4abebcc2 in namespace namespace-49
2022-04-04 11:19:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-49
2022-04-04 11:19:07 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4abebcc2 will have desired state: Ready
2022-04-04 11:20:29 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4abebcc2 is in desired state: Ready
2022-04-04 11:20:29 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1289373728-1858097087 in namespace namespace-49
2022-04-04 11:20:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-49
2022-04-04 11:20:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1289373728-1858097087 will have desired state: Ready
2022-04-04 11:20:30 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1289373728-1858097087 is in desired state: Ready
2022-04-04 11:20:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-4abebcc2-kafka-clients in namespace namespace-49
2022-04-04 11:20:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-49
2022-04-04 11:20:30 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4abebcc2-kafka-clients will be ready
2022-04-04 11:20:32 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4abebcc2-kafka-clients is ready
2022-04-04 11:20:32 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 11:20:32 [main] [32mINFO [m [ListenersST:152] Checking produced and consumed messages to pod:my-cluster-4abebcc2-kafka-clients-6c85646557-64f7t
2022-04-04 11:20:32 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@670a5899, messages=[], arguments=[--topic, my-topic-1289373728-1858097087, --max-messages, 100, --bootstrap-server, my-cluster-4abebcc2-kafka-bootstrap.namespace-49.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-4abebcc2-kafka-clients-6c85646557-64f7t', podNamespace='namespace-49', bootstrapServer='my-cluster-4abebcc2-kafka-bootstrap.namespace-49.svc:9092', topicName='my-topic-1289373728-1858097087', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@30e89d1e}
2022-04-04 11:20:32 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-4abebcc2-kafka-bootstrap.namespace-49.svc:9092:my-topic-1289373728-1858097087 from pod my-cluster-4abebcc2-kafka-clients-6c85646557-64f7t
2022-04-04 11:20:32 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4abebcc2-kafka-clients-6c85646557-64f7t -n namespace-49 -- /opt/kafka/producer.sh --topic my-topic-1289373728-1858097087 --max-messages 100 --bootstrap-server my-cluster-4abebcc2-kafka-bootstrap.namespace-49.svc:9092
2022-04-04 11:20:35 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 11:20:35 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 11:20:35 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1253bbf2, messages=[], arguments=[--topic, my-topic-1289373728-1858097087, --max-messages, 100, --group-instance-id, instance527924378, --group-id, my-consumer-group-1110511935, --bootstrap-server, my-cluster-4abebcc2-kafka-bootstrap.namespace-49.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-4abebcc2-kafka-clients-6c85646557-64f7t', podNamespace='namespace-49', bootstrapServer='my-cluster-4abebcc2-kafka-bootstrap.namespace-49.svc:9092', topicName='my-topic-1289373728-1858097087', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1110511935', consumerInstanceId='instance527924378', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6627ca45}
2022-04-04 11:20:35 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-4abebcc2-kafka-bootstrap.namespace-49.svc:9092#my-topic-1289373728-1858097087 from pod my-cluster-4abebcc2-kafka-clients-6c85646557-64f7t
2022-04-04 11:20:35 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4abebcc2-kafka-clients-6c85646557-64f7t -n namespace-49 -- /opt/kafka/consumer.sh --topic my-topic-1289373728-1858097087 --max-messages 100 --group-instance-id instance527924378 --group-id my-consumer-group-1110511935 --bootstrap-server my-cluster-4abebcc2-kafka-bootstrap.namespace-49.svc:9092
2022-04-04 11:20:40 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 11:20:40 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 11:20:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:20:40 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendMessagesPlainAnonymous
2022-04-04 11:20:40 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1289373728-1858097087 in namespace namespace-49
2022-04-04 11:20:40 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-4abebcc2 in namespace namespace-49
2022-04-04 11:20:40 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-4abebcc2-kafka-clients in namespace namespace-49
2022-04-04 11:21:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:21:30 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-49 for test case:testSendMessagesPlainAnonymous
2022-04-04 11:21:36 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesPlainAnonymous-FINISHED
2022-04-04 11:21:36 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:21:36 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:21:36 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesPlainScramSha-STARTED
2022-04-04 11:21:36 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:21:36 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-50 for test case:testSendMessagesPlainScramSha
2022-04-04 11:21:36 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-50
2022-04-04 11:21:36 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-50
2022-04-04 11:21:36 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-50
2022-04-04 11:21:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c0ed4550 in namespace namespace-50
2022-04-04 11:21:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-50
2022-04-04 11:21:36 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c0ed4550 will have desired state: Ready
2022-04-04 11:22:55 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c0ed4550 is in desired state: Ready
2022-04-04 11:22:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-25437704-1268029577 in namespace namespace-50
2022-04-04 11:22:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-50
2022-04-04 11:22:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-25437704-1268029577 will have desired state: Ready
2022-04-04 11:22:56 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-25437704-1268029577 is in desired state: Ready
2022-04-04 11:22:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-543197935-701689716 in namespace namespace-50
2022-04-04 11:22:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-50
2022-04-04 11:22:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-543197935-701689716 will have desired state: Ready
2022-04-04 11:22:57 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-543197935-701689716 is in desired state: Ready
2022-04-04 11:22:57 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-543197935-701689716: 2022-04-04 11:22:57,153 INFO Processing override for entityPath: users/my-user-543197935-701689716 with config: HashMap(SCRAM-SHA-512 -> [hidden]) (kafka.server.DynamicConfigManager) [/config/changes-event-process-thread]
2022-04-04 11:22:57 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-543197935-701689716: 2022-04-04 11:22:57,158 INFO Removing PRODUCE quota for user my-user-543197935-701689716 (kafka.server.ClientQuotaManager) [/config/changes-event-process-thread]
2022-04-04 11:22:57 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-543197935-701689716: 2022-04-04 11:22:57,161 INFO Removing FETCH quota for user my-user-543197935-701689716 (kafka.server.ClientQuotaManager) [/config/changes-event-process-thread]
2022-04-04 11:22:57 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-543197935-701689716: 2022-04-04 11:22:57,161 INFO Removing REQUEST quota for user my-user-543197935-701689716 (kafka.server.ClientRequestQuotaManager) [/config/changes-event-process-thread]
2022-04-04 11:22:57 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-543197935-701689716: 2022-04-04 11:22:57,161 INFO Removing CONTROLLER_MUTATION quota for user my-user-543197935-701689716 (kafka.server.ControllerMutationQuotaManager) [/config/changes-event-process-thread]
2022-04-04 11:22:57 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-543197935-701689716: 2022-04-04 11:22:57,367 INFO Processing override for entityPath: users/my-user-543197935-701689716 with config: HashMap(SCRAM-SHA-512 -> [hidden]) (kafka.server.DynamicConfigManager) [/config/changes-event-process-thread]
2022-04-04 11:22:57 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-543197935-701689716: 2022-04-04 11:22:57,367 INFO Removing PRODUCE quota for user my-user-543197935-701689716 (kafka.server.ClientQuotaManager) [/config/changes-event-process-thread]
2022-04-04 11:22:57 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-543197935-701689716: 2022-04-04 11:22:57,367 INFO Removing FETCH quota for user my-user-543197935-701689716 (kafka.server.ClientQuotaManager) [/config/changes-event-process-thread]
2022-04-04 11:22:57 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-543197935-701689716: 2022-04-04 11:22:57,367 INFO Removing REQUEST quota for user my-user-543197935-701689716 (kafka.server.ClientRequestQuotaManager) [/config/changes-event-process-thread]
2022-04-04 11:22:57 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-543197935-701689716: 2022-04-04 11:22:57,367 INFO Removing CONTROLLER_MUTATION quota for user my-user-543197935-701689716 (kafka.server.ControllerMutationQuotaManager) [/config/changes-event-process-thread]
2022-04-04 11:22:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-c0ed4550-kafka-clients in namespace namespace-50
2022-04-04 11:22:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-50
2022-04-04 11:22:57 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c0ed4550-kafka-clients will be ready
2022-04-04 11:22:59 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c0ed4550-kafka-clients is ready
2022-04-04 11:22:59 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 11:22:59 [main] [32mINFO [m [ListenersST:296] Checking produced and consumed messages to pod:my-cluster-c0ed4550-kafka-clients-658d947695-cpm7g
2022-04-04 11:22:59 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@12fc7fed, messages=[], arguments=[--topic, my-topic-25437704-1268029577, --max-messages, 100, USER=my_user_543197935_701689716, --bootstrap-server, my-cluster-c0ed4550-kafka-bootstrap.namespace-50.svc:9095], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-c0ed4550-kafka-clients-658d947695-cpm7g', podNamespace='namespace-50', bootstrapServer='my-cluster-c0ed4550-kafka-bootstrap.namespace-50.svc:9095', topicName='my-topic-25437704-1268029577', maxMessages=100, kafkaUsername='my-user-543197935-701689716', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@17390f19}
2022-04-04 11:22:59 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-c0ed4550-kafka-bootstrap.namespace-50.svc:9095:my-topic-25437704-1268029577 from pod my-cluster-c0ed4550-kafka-clients-658d947695-cpm7g
2022-04-04 11:22:59 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c0ed4550-kafka-clients-658d947695-cpm7g -n namespace-50 -- /opt/kafka/producer.sh --topic my-topic-25437704-1268029577 --max-messages 100 USER=my_user_543197935_701689716 --bootstrap-server my-cluster-c0ed4550-kafka-bootstrap.namespace-50.svc:9095
2022-04-04 11:23:02 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 11:23:02 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 11:23:02 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3be361c3, messages=[], arguments=[--topic, my-topic-25437704-1268029577, --max-messages, 100, --group-instance-id, instance1618711308, USER=my_user_543197935_701689716, --group-id, my-consumer-group-1168585485, --bootstrap-server, my-cluster-c0ed4550-kafka-bootstrap.namespace-50.svc:9095], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-c0ed4550-kafka-clients-658d947695-cpm7g', podNamespace='namespace-50', bootstrapServer='my-cluster-c0ed4550-kafka-bootstrap.namespace-50.svc:9095', topicName='my-topic-25437704-1268029577', maxMessages=100, kafkaUsername='my-user-543197935-701689716', consumerGroupName='my-consumer-group-1168585485', consumerInstanceId='instance1618711308', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@64fdeb82}
2022-04-04 11:23:02 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-c0ed4550-kafka-bootstrap.namespace-50.svc:9095#my-topic-25437704-1268029577 from pod my-cluster-c0ed4550-kafka-clients-658d947695-cpm7g
2022-04-04 11:23:02 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c0ed4550-kafka-clients-658d947695-cpm7g -n namespace-50 -- /opt/kafka/consumer.sh --topic my-topic-25437704-1268029577 --max-messages 100 --group-instance-id instance1618711308 USER=my_user_543197935_701689716 --group-id my-consumer-group-1168585485 --bootstrap-server my-cluster-c0ed4550-kafka-bootstrap.namespace-50.svc:9095
2022-04-04 11:23:08 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 11:23:08 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 11:23:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:23:08 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendMessagesPlainScramSha
2022-04-04 11:23:08 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-543197935-701689716 in namespace namespace-50
2022-04-04 11:23:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-c0ed4550-kafka-clients in namespace namespace-50
2022-04-04 11:23:08 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-25437704-1268029577 in namespace namespace-50
2022-04-04 11:23:08 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c0ed4550 in namespace namespace-50
2022-04-04 11:23:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:23:48 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-50 for test case:testSendMessagesPlainScramSha
2022-04-04 11:23:59 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesPlainScramSha-FINISHED
2022-04-04 11:23:59 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:23:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:23:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesTlsScramSha-STARTED
2022-04-04 11:23:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:23:59 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-51 for test case:testSendMessagesTlsScramSha
2022-04-04 11:23:59 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-51
2022-04-04 11:23:59 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-51
2022-04-04 11:23:59 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-51
2022-04-04 11:23:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e36d65ac in namespace namespace-51
2022-04-04 11:23:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-51
2022-04-04 11:23:59 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e36d65ac will have desired state: Ready
2022-04-04 11:25:19 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e36d65ac is in desired state: Ready
2022-04-04 11:25:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-649990847-50831441 in namespace namespace-51
2022-04-04 11:25:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-51
2022-04-04 11:25:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-649990847-50831441 will have desired state: Ready
2022-04-04 11:25:20 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-649990847-50831441 is in desired state: Ready
2022-04-04 11:25:20 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1590379183-961953320 in namespace namespace-51
2022-04-04 11:25:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-51
2022-04-04 11:25:20 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1590379183-961953320 will have desired state: Ready
2022-04-04 11:25:21 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1590379183-961953320 is in desired state: Ready
2022-04-04 11:25:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-e36d65ac-kafka-clients in namespace namespace-51
2022-04-04 11:25:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-51
2022-04-04 11:25:21 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-e36d65ac-kafka-clients will be ready
2022-04-04 11:25:23 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-e36d65ac-kafka-clients is ready
2022-04-04 11:25:23 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 11:25:23 [main] [32mINFO [m [ListenersST:370] Checking produced and consumed messages to pod:my-cluster-e36d65ac-kafka-clients-65c5948c7c-dl4pt
2022-04-04 11:25:23 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@56307401, messages=[], arguments=[--topic, my-topic-649990847-50831441, --max-messages, 100, USER=my_user_1590379183_961953320, --bootstrap-server, my-cluster-e36d65ac-kafka-bootstrap.namespace-51.svc:9096], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-e36d65ac-kafka-clients-65c5948c7c-dl4pt', podNamespace='namespace-51', bootstrapServer='my-cluster-e36d65ac-kafka-bootstrap.namespace-51.svc:9096', topicName='my-topic-649990847-50831441', maxMessages=100, kafkaUsername='my-user-1590379183-961953320', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5ab35ddf}
2022-04-04 11:25:23 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-e36d65ac-kafka-bootstrap.namespace-51.svc:9096:my-topic-649990847-50831441 from pod my-cluster-e36d65ac-kafka-clients-65c5948c7c-dl4pt
2022-04-04 11:25:23 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-e36d65ac-kafka-clients-65c5948c7c-dl4pt -n namespace-51 -- /opt/kafka/producer.sh --topic my-topic-649990847-50831441 --max-messages 100 USER=my_user_1590379183_961953320 --bootstrap-server my-cluster-e36d65ac-kafka-bootstrap.namespace-51.svc:9096
2022-04-04 11:25:27 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 11:25:27 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 11:25:27 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7dc6a671, messages=[], arguments=[--topic, my-topic-649990847-50831441, --max-messages, 100, --group-instance-id, instance1371333555, USER=my_user_1590379183_961953320, --group-id, my-consumer-group-556284788, --bootstrap-server, my-cluster-e36d65ac-kafka-bootstrap.namespace-51.svc:9096], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-e36d65ac-kafka-clients-65c5948c7c-dl4pt', podNamespace='namespace-51', bootstrapServer='my-cluster-e36d65ac-kafka-bootstrap.namespace-51.svc:9096', topicName='my-topic-649990847-50831441', maxMessages=100, kafkaUsername='my-user-1590379183-961953320', consumerGroupName='my-consumer-group-556284788', consumerInstanceId='instance1371333555', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3ddb49b0}
2022-04-04 11:25:27 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-e36d65ac-kafka-bootstrap.namespace-51.svc:9096:my-topic-649990847-50831441 from pod my-cluster-e36d65ac-kafka-clients-65c5948c7c-dl4pt
2022-04-04 11:25:27 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-e36d65ac-kafka-clients-65c5948c7c-dl4pt -n namespace-51 -- /opt/kafka/consumer.sh --topic my-topic-649990847-50831441 --max-messages 100 --group-instance-id instance1371333555 USER=my_user_1590379183_961953320 --group-id my-consumer-group-556284788 --bootstrap-server my-cluster-e36d65ac-kafka-bootstrap.namespace-51.svc:9096
2022-04-04 11:25:34 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 11:25:34 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 11:25:34 [main] [32mINFO [m [ListenersST:377] Checking if generated password has 25 characters
2022-04-04 11:25:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:25:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendMessagesTlsScramSha
2022-04-04 11:25:34 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1590379183-961953320 in namespace namespace-51
2022-04-04 11:25:34 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-e36d65ac-kafka-clients in namespace namespace-51
2022-04-04 11:25:34 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-649990847-50831441 in namespace namespace-51
2022-04-04 11:25:34 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e36d65ac in namespace namespace-51
2022-04-04 11:26:14 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:26:14 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-51 for test case:testSendMessagesTlsScramSha
2022-04-04 11:26:25 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesTlsScramSha-FINISHED
2022-04-04 11:26:25 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:26:25 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:26:25 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testNonExistingCustomCertificate-STARTED
2022-04-04 11:26:25 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:26:25 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-52 for test case:testNonExistingCustomCertificate
2022-04-04 11:26:25 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-52
2022-04-04 11:26:25 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-52
2022-04-04 11:26:25 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-52
2022-04-04 11:26:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d4d6a3ff in namespace namespace-52
2022-04-04 11:26:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-52
2022-04-04 11:26:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:26:56 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testNonExistingCustomCertificate
2022-04-04 11:26:56 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d4d6a3ff in namespace namespace-52
2022-04-04 11:26:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:26:56 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-52 for test case:testNonExistingCustomCertificate
2022-04-04 11:27:01 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testNonExistingCustomCertificate-FINISHED
2022-04-04 11:27:01 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:27:01 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:27:01 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testAdvertisedHostNamesAppearsInBrokerCerts-STARTED
2022-04-04 11:27:01 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:27:01 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-53 for test case:testAdvertisedHostNamesAppearsInBrokerCerts
2022-04-04 11:27:01 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-53
2022-04-04 11:27:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-53
2022-04-04 11:27:02 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-53
2022-04-04 11:27:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-743c5ce3 in namespace namespace-53
2022-04-04 11:27:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-53
2022-04-04 11:27:02 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-743c5ce3 will have desired state: Ready
2022-04-04 11:28:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-743c5ce3 is in desired state: Ready
2022-04-04 11:28:21 [main] [32mINFO [m [ListenersST:2338] Encoding my-cluster-743c5ce3-kafka-0.crt
2022-04-04 11:28:21 [main] [32mINFO [m [ListenersST:2338] Encoding my-cluster-743c5ce3-kafka-1.crt
2022-04-04 11:28:21 [main] [32mINFO [m [ListenersST:2338] Encoding my-cluster-743c5ce3-kafka-2.crt
2022-04-04 11:28:21 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:28:21 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAdvertisedHostNamesAppearsInBrokerCerts
2022-04-04 11:28:21 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-743c5ce3 in namespace namespace-53
2022-04-04 11:28:31 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:28:31 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-53 for test case:testAdvertisedHostNamesAppearsInBrokerCerts
2022-04-04 11:29:14 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testAdvertisedHostNamesAppearsInBrokerCerts-FINISHED
2022-04-04 11:29:14 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:29:14 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:29:14 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testMessagesTlsScramShaWithPredefinedPassword-STARTED
2022-04-04 11:29:14 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:29:14 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-54 for test case:testMessagesTlsScramShaWithPredefinedPassword
2022-04-04 11:29:14 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-54
2022-04-04 11:29:14 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-54
2022-04-04 11:29:14 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-54
2022-04-04 11:29:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-4698486b in namespace namespace-54
2022-04-04 11:29:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-54
2022-04-04 11:29:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1702755515-1870330443 in namespace namespace-54
2022-04-04 11:29:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-54
2022-04-04 11:29:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1873384284-217866833 in namespace namespace-54
2022-04-04 11:29:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-54
2022-04-04 11:29:14 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4698486b will have desired state: Ready
2022-04-04 11:30:33 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4698486b is in desired state: Ready
2022-04-04 11:30:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1702755515-1870330443 will have desired state: Ready
2022-04-04 11:30:33 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1702755515-1870330443 is in desired state: Ready
2022-04-04 11:30:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1873384284-217866833 will have desired state: Ready
2022-04-04 11:30:33 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1873384284-217866833 is in desired state: Ready
2022-04-04 11:30:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-4698486b-kafka-clients in namespace namespace-54
2022-04-04 11:30:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-54
2022-04-04 11:30:33 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4698486b-kafka-clients will be ready
2022-04-04 11:30:35 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4698486b-kafka-clients is ready
2022-04-04 11:30:35 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 11:30:35 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@7dfa230a, messages=[], arguments=[--topic, my-topic-1873384284-217866833, --max-messages, 100, USER=my_user_1702755515_1870330443, --bootstrap-server, my-cluster-4698486b-kafka-bootstrap.namespace-54.svc:9096], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-4698486b-kafka-clients-5f86678fbf-c5qlf', podNamespace='namespace-54', bootstrapServer='my-cluster-4698486b-kafka-bootstrap.namespace-54.svc:9096', topicName='my-topic-1873384284-217866833', maxMessages=100, kafkaUsername='my-user-1702755515-1870330443', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@f259c57}
2022-04-04 11:30:35 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-4698486b-kafka-bootstrap.namespace-54.svc:9096:my-topic-1873384284-217866833 from pod my-cluster-4698486b-kafka-clients-5f86678fbf-c5qlf
2022-04-04 11:30:35 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4698486b-kafka-clients-5f86678fbf-c5qlf -n namespace-54 -- /opt/kafka/producer.sh --topic my-topic-1873384284-217866833 --max-messages 100 USER=my_user_1702755515_1870330443 --bootstrap-server my-cluster-4698486b-kafka-bootstrap.namespace-54.svc:9096
2022-04-04 11:30:38 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 11:30:38 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 11:30:38 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@31e1bfed, messages=[], arguments=[--topic, my-topic-1873384284-217866833, --max-messages, 100, --group-instance-id, instance333720074, USER=my_user_1702755515_1870330443, --group-id, my-consumer-group-496625787, --bootstrap-server, my-cluster-4698486b-kafka-bootstrap.namespace-54.svc:9096], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-4698486b-kafka-clients-5f86678fbf-c5qlf', podNamespace='namespace-54', bootstrapServer='my-cluster-4698486b-kafka-bootstrap.namespace-54.svc:9096', topicName='my-topic-1873384284-217866833', maxMessages=100, kafkaUsername='my-user-1702755515-1870330443', consumerGroupName='my-consumer-group-496625787', consumerInstanceId='instance333720074', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@12055ede}
2022-04-04 11:30:38 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-4698486b-kafka-bootstrap.namespace-54.svc:9096:my-topic-1873384284-217866833 from pod my-cluster-4698486b-kafka-clients-5f86678fbf-c5qlf
2022-04-04 11:30:38 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4698486b-kafka-clients-5f86678fbf-c5qlf -n namespace-54 -- /opt/kafka/consumer.sh --topic my-topic-1873384284-217866833 --max-messages 100 --group-instance-id instance333720074 USER=my_user_1702755515_1870330443 --group-id my-consumer-group-496625787 --bootstrap-server my-cluster-4698486b-kafka-bootstrap.namespace-54.svc:9096
2022-04-04 11:30:45 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 11:30:45 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 11:30:45 [main] [32mINFO [m [ListenersST:2213] Changing password in secret: my-cluster-4698486b-secret, we should be able to send/receive messages
2022-04-04 11:30:45 [main] [32mINFO [m [SecretUtils:171] Waiting for user password will be changed to Y29tcGxldGVseV9kaWZmZXJlbnRfc2VjcmV0X3Bhc3N3b3Jk in secret: my-user-1702755515-1870330443
2022-04-04 11:32:15 [main] [32mINFO [m [ListenersST:2222] We need to recreate Kafka Clients deployment, so the correct password from secret will be taken
2022-04-04 11:32:15 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-4698486b-kafka-clients in namespace namespace-54
2022-04-04 11:32:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-4698486b-kafka-clients in namespace namespace-54
2022-04-04 11:32:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-54
2022-04-04 11:32:55 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4698486b-kafka-clients will be ready
2022-04-04 11:32:57 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4698486b-kafka-clients is ready
2022-04-04 11:32:57 [main] [32mINFO [m [ListenersST:2226] Receiving messages with new password
2022-04-04 11:32:57 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5b88b949, messages=[], arguments=[--topic, my-topic-1873384284-217866833, --max-messages, 100, --group-instance-id, instance229817854, USER=my_user_1702755515_1870330443, --group-id, my-consumer-group-246827905, --bootstrap-server, my-cluster-4698486b-kafka-bootstrap.namespace-54.svc:9096], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-4698486b-kafka-clients-5cc778447c-7lxkt', podNamespace='namespace-54', bootstrapServer='my-cluster-4698486b-kafka-bootstrap.namespace-54.svc:9096', topicName='my-topic-1873384284-217866833', maxMessages=100, kafkaUsername='my-user-1702755515-1870330443', consumerGroupName='my-consumer-group-246827905', consumerInstanceId='instance229817854', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6343f851}
2022-04-04 11:32:57 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-4698486b-kafka-bootstrap.namespace-54.svc:9096:my-topic-1873384284-217866833 from pod my-cluster-4698486b-kafka-clients-5cc778447c-7lxkt
2022-04-04 11:32:57 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4698486b-kafka-clients-5cc778447c-7lxkt -n namespace-54 -- /opt/kafka/consumer.sh --topic my-topic-1873384284-217866833 --max-messages 100 --group-instance-id instance229817854 USER=my_user_1702755515_1870330443 --group-id my-consumer-group-246827905 --bootstrap-server my-cluster-4698486b-kafka-bootstrap.namespace-54.svc:9096
2022-04-04 11:33:04 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 11:33:04 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 11:33:04 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:33:04 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMessagesTlsScramShaWithPredefinedPassword
2022-04-04 11:33:04 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1873384284-217866833 in namespace namespace-54
2022-04-04 11:33:04 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1702755515-1870330443 in namespace namespace-54
2022-04-04 11:33:04 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-4698486b in namespace namespace-54
2022-04-04 11:33:04 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-4698486b-kafka-clients in namespace namespace-54
2022-04-04 11:33:04 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-4698486b-kafka-clients in namespace namespace-54
2022-04-04 11:33:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:33:44 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-54 for test case:testMessagesTlsScramShaWithPredefinedPassword
2022-04-04 11:33:49 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testMessagesTlsScramShaWithPredefinedPassword-FINISHED
2022-04-04 11:33:49 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:33:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:33:49 [main] [32mINFO [m [ResourceManager:346] In context ListenersST is everything deleted.
2022-04-04 11:33:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,288.822 s - in io.strimzi.systemtest.kafka.listeners.ListenersST
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.listeners.MultipleListenersST
2022-04-04 11:33:55 [main] [32mINFO [m [MultipleListenersST:294] Starting to generate test cases for multiple listeners
2022-04-04 11:33:55 [main] [32mINFO [m [MultipleListenersST:300] Generating INTERNAL listener
2022-04-04 11:33:55 [main] [32mINFO [m [MultipleListenersST:363] Generating listeners with type INTERNAL -> [io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@c8155196, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@fc6d1bc0]
2022-04-04 11:33:55 [main] [32mINFO [m [MultipleListenersST:300] Generating ROUTE listener
2022-04-04 11:33:55 [main] [32mINFO [m [MultipleListenersST:363] Generating listeners with type ROUTE -> [io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@49ccfeca]
2022-04-04 11:33:55 [main] [32mINFO [m [MultipleListenersST:300] Generating LOADBALANCER listener
2022-04-04 11:33:55 [main] [32mINFO [m [MultipleListenersST:363] Generating listeners with type LOADBALANCER -> [io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@884b7952, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@c9a3656e]
2022-04-04 11:33:55 [main] [32mINFO [m [MultipleListenersST:300] Generating NODEPORT listener
2022-04-04 11:33:55 [main] [32mINFO [m [MultipleListenersST:363] Generating listeners with type NODEPORT -> [io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@a294bb05, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@e3eca721, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@2544933d, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@669c7f59]
2022-04-04 11:33:55 [main] [32mINFO [m [MultipleListenersST:300] Generating INGRESS listener
2022-04-04 11:33:55 [main] [32mINFO [m [MultipleListenersST:363] Generating listeners with type INGRESS -> []
2022-04-04 11:33:55 [main] [32mINFO [m [MultipleListenersST:367] Finished with generation of test cases for multiple listeners
2022-04-04 11:33:55 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: multiple-listeners-st
2022-04-04 11:33:55 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: multiple-listeners-st
2022-04-04 11:33:55 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: multiple-listeners-st
2022-04-04 11:33:55 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:33:55 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.MultipleListenersST.testMultipleInternal-STARTED
2022-04-04 11:33:55 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:33:55 [main] [32mINFO [m [MultipleListenersST:163] This is listeners [io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@c8155196, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@fc6d1bc0], which will verified.
2022-04-04 11:33:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ce826cbb in namespace multiple-listeners-st
2022-04-04 11:33:55 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ce826cbb will have desired state: Ready
2022-04-04 11:35:13 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ce826cbb is in desired state: Ready
2022-04-04 11:35:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-415743188-2089031356 in namespace multiple-listeners-st
2022-04-04 11:35:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-415743188-2089031356 will have desired state: Ready
2022-04-04 11:35:14 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-415743188-2089031356 is in desired state: Ready
2022-04-04 11:35:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-581906706-1150057543 in namespace multiple-listeners-st
2022-04-04 11:35:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-581906706-1150057543 will have desired state: Ready
2022-04-04 11:35:15 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-581906706-1150057543 is in desired state: Ready
2022-04-04 11:35:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-ce826cbb-kafka-clients-plain in namespace multiple-listeners-st
2022-04-04 11:35:15 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ce826cbb-kafka-clients-plain will be ready
2022-04-04 11:35:17 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ce826cbb-kafka-clients-plain is ready
2022-04-04 11:35:17 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 11:35:17 [main] [32mINFO [m [MultipleListenersST:274] Checking produced and consumed messages to pod:my-cluster-ce826cbb-kafka-clients-plain-5f9bc6c875-lxhlf
2022-04-04 11:35:17 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@50752b7f, messages=[], arguments=[--topic, my-topic-581906706-1150057543, --max-messages, 100, --bootstrap-server, my-cluster-ce826cbb-kafka-bootstrap.multiple-listeners-st.svc:13900], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-ce826cbb-kafka-clients-plain-5f9bc6c875-lxhlf', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-ce826cbb-kafka-bootstrap.multiple-listeners-st.svc:13900', topicName='my-topic-581906706-1150057543', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7a450c77}
2022-04-04 11:35:17 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-ce826cbb-kafka-bootstrap.multiple-listeners-st.svc:13900:my-topic-581906706-1150057543 from pod my-cluster-ce826cbb-kafka-clients-plain-5f9bc6c875-lxhlf
2022-04-04 11:35:17 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-ce826cbb-kafka-clients-plain-5f9bc6c875-lxhlf -n multiple-listeners-st -- /opt/kafka/producer.sh --topic my-topic-581906706-1150057543 --max-messages 100 --bootstrap-server my-cluster-ce826cbb-kafka-bootstrap.multiple-listeners-st.svc:13900
2022-04-04 11:35:19 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 11:35:19 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 11:35:19 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3e0af3c, messages=[], arguments=[--topic, my-topic-581906706-1150057543, --max-messages, 100, --group-instance-id, instance1004251221, --group-id, my-consumer-group-1324922586, --bootstrap-server, my-cluster-ce826cbb-kafka-bootstrap.multiple-listeners-st.svc:13900], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-ce826cbb-kafka-clients-plain-5f9bc6c875-lxhlf', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-ce826cbb-kafka-bootstrap.multiple-listeners-st.svc:13900', topicName='my-topic-581906706-1150057543', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1324922586', consumerInstanceId='instance1004251221', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@519427cd}
2022-04-04 11:35:19 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-ce826cbb-kafka-bootstrap.multiple-listeners-st.svc:13900#my-topic-581906706-1150057543 from pod my-cluster-ce826cbb-kafka-clients-plain-5f9bc6c875-lxhlf
2022-04-04 11:35:19 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-ce826cbb-kafka-clients-plain-5f9bc6c875-lxhlf -n multiple-listeners-st -- /opt/kafka/consumer.sh --topic my-topic-581906706-1150057543 --max-messages 100 --group-instance-id instance1004251221 --group-id my-consumer-group-1324922586 --bootstrap-server my-cluster-ce826cbb-kafka-bootstrap.multiple-listeners-st.svc:13900
2022-04-04 11:35:25 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 11:35:25 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 11:35:25 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-446984193-379129875 in namespace multiple-listeners-st
2022-04-04 11:35:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-446984193-379129875 will have desired state: Ready
2022-04-04 11:35:26 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-446984193-379129875 is in desired state: Ready
2022-04-04 11:35:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-ce826cbb-kafka-clients-tls in namespace multiple-listeners-st
2022-04-04 11:35:26 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ce826cbb-kafka-clients-tls will be ready
2022-04-04 11:35:28 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ce826cbb-kafka-clients-tls is ready
2022-04-04 11:35:28 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 11:35:28 [main] [32mINFO [m [MultipleListenersST:252] Checking produced and consumed messages to pod:my-cluster-ce826cbb-kafka-clients-tls-79788cd847-gj78t
2022-04-04 11:35:28 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-960783966-562513002 in namespace multiple-listeners-st
2022-04-04 11:35:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-960783966-562513002 will have desired state: Ready
2022-04-04 11:35:29 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-960783966-562513002 is in desired state: Ready
2022-04-04 11:35:29 [main] [32mINFO [m [ClientUtils:127] Sending messages to - topic my-topic-446984193-379129875, cluster my-cluster-ce826cbb and message count of 100
2022-04-04 11:35:29 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@4b534c12, messages=[], arguments=[--topic, my-topic-960783966-562513002, --max-messages, 100, USER=my_user_415743188_2089031356, --bootstrap-server, my-cluster-ce826cbb-kafka-bootstrap.multiple-listeners-st.svc:13901], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-ce826cbb-kafka-clients-tls-79788cd847-gj78t', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-ce826cbb-kafka-bootstrap.multiple-listeners-st.svc:13901', topicName='my-topic-960783966-562513002', maxMessages=100, kafkaUsername='my-user-415743188-2089031356', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7a3742ec}
2022-04-04 11:35:29 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-ce826cbb-kafka-bootstrap.multiple-listeners-st.svc:13901:my-topic-960783966-562513002 from pod my-cluster-ce826cbb-kafka-clients-tls-79788cd847-gj78t
2022-04-04 11:35:29 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-ce826cbb-kafka-clients-tls-79788cd847-gj78t -n multiple-listeners-st -- /opt/kafka/producer.sh --topic my-topic-960783966-562513002 --max-messages 100 USER=my_user_415743188_2089031356 --bootstrap-server my-cluster-ce826cbb-kafka-bootstrap.multiple-listeners-st.svc:13901
2022-04-04 11:35:32 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 11:35:32 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 11:35:32 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3d9671f8, messages=[], arguments=[--topic, my-topic-960783966-562513002, --max-messages, 100, --group-instance-id, instance804061218, USER=my_user_415743188_2089031356, --group-id, my-consumer-group-1475686071, --bootstrap-server, my-cluster-ce826cbb-kafka-bootstrap.multiple-listeners-st.svc:13901], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-ce826cbb-kafka-clients-tls-79788cd847-gj78t', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-ce826cbb-kafka-bootstrap.multiple-listeners-st.svc:13901', topicName='my-topic-960783966-562513002', maxMessages=100, kafkaUsername='my-user-415743188-2089031356', consumerGroupName='my-consumer-group-1475686071', consumerInstanceId='instance804061218', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3b89a0fa}
2022-04-04 11:35:32 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-ce826cbb-kafka-bootstrap.multiple-listeners-st.svc:13901:my-topic-960783966-562513002 from pod my-cluster-ce826cbb-kafka-clients-tls-79788cd847-gj78t
2022-04-04 11:35:32 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-ce826cbb-kafka-clients-tls-79788cd847-gj78t -n multiple-listeners-st -- /opt/kafka/consumer.sh --topic my-topic-960783966-562513002 --max-messages 100 --group-instance-id instance804061218 USER=my_user_415743188_2089031356 --group-id my-consumer-group-1475686071 --bootstrap-server my-cluster-ce826cbb-kafka-bootstrap.multiple-listeners-st.svc:13901
2022-04-04 11:35:39 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 11:35:39 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 11:35:39 [main] [32mINFO [m [ClientUtils:133] Sent 100 and received 100
2022-04-04 11:35:39 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:35:39 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMultipleInternal
2022-04-04 11:35:39 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-446984193-379129875 in namespace multiple-listeners-st
2022-04-04 11:35:39 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-960783966-562513002 in namespace multiple-listeners-st
2022-04-04 11:35:39 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-ce826cbb-kafka-clients-tls in namespace multiple-listeners-st
2022-04-04 11:35:39 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-415743188-2089031356 in namespace multiple-listeners-st
2022-04-04 11:35:39 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-ce826cbb-kafka-clients-plain in namespace multiple-listeners-st
2022-04-04 11:35:39 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-581906706-1150057543 in namespace multiple-listeners-st
2022-04-04 11:35:39 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ce826cbb in namespace multiple-listeners-st
2022-04-04 11:36:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:36:19 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.MultipleListenersST.testMultipleInternal-FINISHED
2022-04-04 11:36:19 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:36:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:36:19 [main] [32mINFO [m [ResourceManager:346] In context MultipleListenersST is everything deleted.
2022-04-04 11:36:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 150.265 s - in io.strimzi.systemtest.kafka.listeners.MultipleListenersST
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST
2022-04-04 11:36:25 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: dynamic-conf-st
2022-04-04 11:36:25 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: dynamic-conf-st
2022-04-04 11:36:25 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: dynamic-conf-st
2022-04-04 11:36:25 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:36:25 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST.testSimpleDynamicConfiguration-STARTED
2022-04-04 11:36:25 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:36:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c50358cb in namespace dynamic-conf-st
2022-04-04 11:36:25 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c50358cb will have desired state: Ready
2022-04-04 11:37:47 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c50358cb is in desired state: Ready
2022-04-04 11:37:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-c50358cb-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:37:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:37:50 [main] [32mINFO [m [DynamicConfST:380] Updating configuration of Kafka cluster
2022-04-04 11:37:50 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-c50358cb-kafka are stable
2022-04-04 11:37:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 11:37:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 11:37:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 11:37:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 11:37:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 11:37:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 11:37:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 11:37:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 11:37:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 11:37:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 11:37:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 11:37:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 11:37:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 11:37:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 11:37:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 11:37:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 11:37:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 11:37:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 11:37:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 11:37:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 11:37:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 11:37:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 11:37:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 11:37:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 11:37:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 11:37:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 11:37:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 11:37:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 11:37:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 11:37:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 11:38:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 11:38:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 11:38:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 11:38:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 11:38:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 11:38:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 11:38:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 11:38:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 11:38:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 11:38:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 11:38:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 11:38:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 11:38:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 11:38:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 11:38:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 11:38:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 11:38:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 11:38:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 11:38:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 11:38:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 11:38:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 11:38:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 11:38:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 11:38:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 11:38:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 11:38:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 11:38:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 11:38:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 11:38:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 11:38:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 11:38:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 11:38:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 11:38:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 11:38:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 11:38:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 11:38:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 11:38:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 11:38:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 11:38:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 11:38:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 11:38:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 11:38:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 11:38:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 11:38:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 11:38:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 11:38:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 11:38:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 11:38:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 11:38:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 11:38:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 11:38:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 11:38:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 11:38:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 11:38:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 11:38:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 11:38:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 11:38:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 11:38:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 11:38:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 11:38:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 11:38:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 11:38:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 11:38:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 11:38:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 11:38:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 11:38:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 11:38:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 11:38:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 11:38:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 11:38:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 11:38:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 11:38:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 11:38:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 11:38:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 11:38:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 11:38:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 11:38:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 11:38:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 11:38:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 11:38:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 11:38:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 11:38:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 11:38:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 11:38:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 11:38:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 11:38:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 11:38:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 11:38:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 11:38:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 11:38:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 11:38:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 11:38:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 11:38:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 11:38:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 11:38:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 11:38:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 11:38:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 11:38:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 11:38:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 11:38:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 11:38:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 11:38:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 11:38:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 11:38:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 11:38:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 11:38:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 11:38:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 11:38:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 11:38:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 11:38:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 11:38:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 11:38:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 11:38:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 11:38:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 11:38:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 11:38:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 11:38:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 11:38:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 11:38:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 11:38:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c50358cb-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 11:38:39 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-c50358cb-kafka-0 ,my-cluster-c50358cb-kafka-1 ,my-cluster-c50358cb-kafka-2
2022-04-04 11:38:42 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-c50358cb-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:38:42 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:38:42 [main] [32mINFO [m [DynamicConfST:102] Verify values after update
2022-04-04 11:38:42 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:38:42 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSimpleDynamicConfiguration
2022-04-04 11:38:42 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c50358cb in namespace dynamic-conf-st
2022-04-04 11:38:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:38:52 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST.testSimpleDynamicConfiguration-FINISHED
2022-04-04 11:38:52 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:38:52 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:38:52 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST.testUpdateToExternalListenerCausesRollingRestart-STARTED
2022-04-04 11:38:52 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:38:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1aca0af5 in namespace dynamic-conf-st
2022-04-04 11:38:52 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1aca0af5 will have desired state: Ready
2022-04-04 11:40:16 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1aca0af5 is in desired state: Ready
2022-04-04 11:40:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-1aca0af5-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:40:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:40:19 [main] [32mINFO [m [DynamicConfST:380] Updating configuration of Kafka cluster
2022-04-04 11:40:19 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-1aca0af5-kafka are stable
2022-04-04 11:40:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 11:40:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 11:40:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 11:40:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 11:40:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 11:40:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 11:40:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 11:40:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 11:40:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 11:40:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 11:40:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 11:40:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 11:40:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 11:40:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 11:40:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 11:40:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 11:40:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 11:40:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 11:40:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 11:40:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 11:40:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 11:40:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 11:40:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 11:40:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 11:40:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 11:40:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 11:40:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 11:40:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 11:40:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 11:40:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 11:40:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 11:40:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 11:40:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 11:40:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 11:40:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 11:40:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 11:40:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 11:40:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 11:40:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 11:40:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 11:40:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 11:40:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 11:40:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 11:40:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 11:40:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 11:40:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 11:40:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 11:40:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 11:40:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 11:40:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 11:40:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 11:40:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 11:40:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 11:40:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 11:40:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 11:40:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 11:40:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 11:40:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 11:40:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 11:40:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 11:40:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 11:40:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 11:40:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 11:40:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 11:40:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 11:40:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 11:40:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 11:40:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 11:40:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 11:40:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 11:40:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 11:40:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 11:40:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 11:40:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 11:40:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 11:40:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 11:40:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 11:40:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 11:40:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 11:40:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 11:40:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 11:40:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 11:40:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 11:40:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 11:40:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 11:40:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 11:40:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 11:40:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 11:40:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 11:40:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 11:40:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 11:40:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 11:40:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 11:40:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 11:40:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 11:40:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 11:40:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 11:40:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 11:40:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 11:40:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 11:40:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 11:40:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 11:40:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 11:40:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 11:40:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 11:40:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 11:40:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 11:40:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 11:40:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 11:40:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 11:40:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 11:40:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 11:40:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 11:40:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 11:40:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 11:40:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 11:40:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 11:40:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 11:40:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 11:40:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 11:40:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 11:40:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 11:40:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 11:41:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 11:41:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 11:41:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 11:41:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 11:41:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 11:41:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 11:41:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 11:41:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 11:41:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 11:41:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 11:41:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 11:41:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 11:41:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 11:41:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 11:41:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 11:41:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 11:41:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 11:41:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 11:41:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 11:41:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 11:41:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 11:41:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 11:41:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 11:41:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 11:41:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 11:41:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 11:41:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 11:41:08 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-1aca0af5-kafka-0 ,my-cluster-1aca0af5-kafka-1 ,my-cluster-1aca0af5-kafka-2
2022-04-04 11:41:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-1aca0af5-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:41:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:41:12 [main] [32mINFO [m [DynamicConfST:163] Updating listeners of Kafka cluster
2022-04-04 11:41:12 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-1aca0af5-kafka rolling update
2022-04-04 11:42:27 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-1aca0af5-kafka has been successfully rolled
2022-04-04 11:42:27 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-1aca0af5-kafka to be ready
2022-04-04 11:42:53 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1aca0af5 will have desired state: Ready
2022-04-04 11:42:53 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1aca0af5 is in desired state: Ready
2022-04-04 11:42:53 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-1aca0af5 is ready
2022-04-04 11:42:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-1aca0af5-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:42:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:42:55 [main] [32mINFO [m [DynamicConfST:380] Updating configuration of Kafka cluster
2022-04-04 11:42:55 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-1aca0af5-kafka are stable
2022-04-04 11:42:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 11:42:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 11:42:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 11:42:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 11:42:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 11:42:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 11:42:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 11:42:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 11:42:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 11:42:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 11:42:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 11:42:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 11:42:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 11:42:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 11:42:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 11:43:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 11:43:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 11:43:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 11:43:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 11:43:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 11:43:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 11:43:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 11:43:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 11:43:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 11:43:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 11:43:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 11:43:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 11:43:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 11:43:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 11:43:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 11:43:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 11:43:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 11:43:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 11:43:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 11:43:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 11:43:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 11:43:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 11:43:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 11:43:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 11:43:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 11:43:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 11:43:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 11:43:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 11:43:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 11:43:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 11:43:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 11:43:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 11:43:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 11:43:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 11:43:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 11:43:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 11:43:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 11:43:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 11:43:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 11:43:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 11:43:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 11:43:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 11:43:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 11:43:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 11:43:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 11:43:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 11:43:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 11:43:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 11:43:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 11:43:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 11:43:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 11:43:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 11:43:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 11:43:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 11:43:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 11:43:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 11:43:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 11:43:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 11:43:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 11:43:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 11:43:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 11:43:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 11:43:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 11:43:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 11:43:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 11:43:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 11:43:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 11:43:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 11:43:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 11:43:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 11:43:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 11:43:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 11:43:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 11:43:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 11:43:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 11:43:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 11:43:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 11:43:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 11:43:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 11:43:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 11:43:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 11:43:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 11:43:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 11:43:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 11:43:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 11:43:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 11:43:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 11:43:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 11:43:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 11:43:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 11:43:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 11:43:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 11:43:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 11:43:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 11:43:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 11:43:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 11:43:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 11:43:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 11:43:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 11:43:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 11:43:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 11:43:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 11:43:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 11:43:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 11:43:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 11:43:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 11:43:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 11:43:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 11:43:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 11:43:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 11:43:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 11:43:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 11:43:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 11:43:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 11:43:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 11:43:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 11:43:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 11:43:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 11:43:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 11:43:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 11:43:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 11:43:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 11:43:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 11:43:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 11:43:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 11:43:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 11:43:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 11:43:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 11:43:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 11:43:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 11:43:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 11:43:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 11:43:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 11:43:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 11:43:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 11:43:45 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-1aca0af5-kafka-0 ,my-cluster-1aca0af5-kafka-1 ,my-cluster-1aca0af5-kafka-2
2022-04-04 11:43:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-1aca0af5-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:43:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:43:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-1aca0af5-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:43:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:43:50 [main] [32mINFO [m [DynamicConfST:380] Updating configuration of Kafka cluster
2022-04-04 11:43:50 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-1aca0af5-kafka are stable
2022-04-04 11:43:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 11:43:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 11:43:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 11:43:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 11:43:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 11:43:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 11:43:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 11:43:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 11:43:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 11:43:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 11:43:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 11:43:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 11:43:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 11:43:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 11:43:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 11:43:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 11:43:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 11:43:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 11:43:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 11:43:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 11:43:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 11:43:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 11:43:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 11:43:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 11:43:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 11:43:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 11:43:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 11:43:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 11:43:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 11:43:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 11:44:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 11:44:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 11:44:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 11:44:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 11:44:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 11:44:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 11:44:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 11:44:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 11:44:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 11:44:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 11:44:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 11:44:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 11:44:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 11:44:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 11:44:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 11:44:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 11:44:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 11:44:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 11:44:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 11:44:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 11:44:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 11:44:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 11:44:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 11:44:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 11:44:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 11:44:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 11:44:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 11:44:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 11:44:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 11:44:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 11:44:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 11:44:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 11:44:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 11:44:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 11:44:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 11:44:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 11:44:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 11:44:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 11:44:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 11:44:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 11:44:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 11:44:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 11:44:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 11:44:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 11:44:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 11:44:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 11:44:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 11:44:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 11:44:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 11:44:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 11:44:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 11:44:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 11:44:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 11:44:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 11:44:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 11:44:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 11:44:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 11:44:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 11:44:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 11:44:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 11:44:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 11:44:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 11:44:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 11:44:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 11:44:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 11:44:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 11:44:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 11:44:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 11:44:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 11:44:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 11:44:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 11:44:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 11:44:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 11:44:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 11:44:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 11:44:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 11:44:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 11:44:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 11:44:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 11:44:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 11:44:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 11:44:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 11:44:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 11:44:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 11:44:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 11:44:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 11:44:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 11:44:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 11:44:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 11:44:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 11:44:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 11:44:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 11:44:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 11:44:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 11:44:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 11:44:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 11:44:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 11:44:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 11:44:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 11:44:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 11:44:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 11:44:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 11:44:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 11:44:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 11:44:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 11:44:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 11:44:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 11:44:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 11:44:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 11:44:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 11:44:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 11:44:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 11:44:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 11:44:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 11:44:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 11:44:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 11:44:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 11:44:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 11:44:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 11:44:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 11:44:39 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-1aca0af5-kafka-0 ,my-cluster-1aca0af5-kafka-1 ,my-cluster-1aca0af5-kafka-2
2022-04-04 11:44:42 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-1aca0af5-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:44:42 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:44:42 [main] [32mINFO [m [DynamicConfST:214] Updating listeners of Kafka cluster
2022-04-04 11:44:42 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-1aca0af5-kafka rolling update
2022-04-04 11:46:12 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-1aca0af5-kafka has been successfully rolled
2022-04-04 11:46:12 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-1aca0af5-kafka to be ready
2022-04-04 11:46:46 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1aca0af5 will have desired state: Ready
2022-04-04 11:46:46 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1aca0af5 is in desired state: Ready
2022-04-04 11:46:46 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-1aca0af5 is ready
2022-04-04 11:46:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-1aca0af5-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:46:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:46:48 [main] [32mINFO [m [DynamicConfST:380] Updating configuration of Kafka cluster
2022-04-04 11:46:48 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-1aca0af5-kafka are stable
2022-04-04 11:46:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 11:46:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 11:46:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 11:46:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 11:46:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 11:46:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 11:46:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 11:46:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 11:46:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 11:46:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 11:46:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 11:46:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 11:46:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 11:46:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 11:46:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 11:46:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 11:46:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 11:46:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 11:46:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 11:46:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 11:46:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 11:46:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 11:46:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 11:46:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 11:46:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 11:46:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 11:46:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 11:46:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 11:46:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 11:46:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 11:46:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 11:46:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 11:46:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 11:47:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 11:47:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 11:47:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 11:47:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 11:47:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 11:47:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 11:47:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 11:47:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 11:47:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 11:47:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 11:47:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 11:47:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 11:47:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 11:47:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 11:47:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 11:47:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 11:47:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 11:47:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 11:47:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 11:47:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 11:47:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 11:47:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 11:47:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 11:47:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 11:47:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 11:47:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 11:47:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 11:47:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 11:47:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 11:47:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 11:47:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 11:47:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 11:47:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 11:47:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 11:47:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 11:47:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 11:47:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 11:47:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 11:47:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 11:47:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 11:47:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 11:47:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 11:47:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 11:47:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 11:47:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 11:47:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 11:47:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 11:47:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 11:47:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 11:47:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 11:47:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 11:47:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 11:47:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 11:47:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 11:47:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 11:47:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 11:47:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 11:47:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 11:47:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 11:47:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 11:47:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 11:47:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 11:47:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 11:47:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 11:47:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 11:47:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 11:47:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 11:47:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 11:47:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 11:47:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 11:47:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 11:47:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 11:47:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 11:47:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 11:47:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 11:47:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 11:47:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 11:47:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 11:47:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 11:47:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 11:47:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 11:47:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 11:47:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 11:47:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 11:47:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 11:47:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 11:47:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 11:47:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 11:47:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 11:47:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 11:47:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 11:47:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 11:47:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 11:47:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 11:47:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 11:47:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 11:47:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 11:47:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 11:47:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 11:47:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 11:47:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 11:47:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 11:47:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 11:47:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 11:47:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 11:47:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 11:47:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 11:47:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 11:47:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 11:47:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 11:47:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 11:47:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 11:47:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 11:47:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 11:47:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 11:47:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 11:47:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1aca0af5-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 11:47:38 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-1aca0af5-kafka-0 ,my-cluster-1aca0af5-kafka-1 ,my-cluster-1aca0af5-kafka-2
2022-04-04 11:47:42 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-1aca0af5-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:47:42 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:47:42 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:47:42 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUpdateToExternalListenerCausesRollingRestart
2022-04-04 11:47:42 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1aca0af5 in namespace dynamic-conf-st
2022-04-04 11:47:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:47:52 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST.testUpdateToExternalListenerCausesRollingRestart-FINISHED
2022-04-04 11:47:52 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:47:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:47:52 [main] [32mINFO [m [ResourceManager:346] In context DynamicConfST is everything deleted.
2022-04-04 11:47:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 731.871 s - in io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST
2022-04-04 11:48:37 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: dynamic-conf-shared-st
2022-04-04 11:48:37 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: dynamic-conf-shared-st
2022-04-04 11:48:37 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: dynamic-conf-shared-st
2022-04-04 11:48:37 [main] [32mINFO [m [DynamicConfSharedST:218] Deploying shared Kafka across all test cases!
2022-04-04 11:48:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka dynamic-configuration-shared-cluster-name in namespace dynamic-conf-shared-st
2022-04-04 11:48:37 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: dynamic-configuration-shared-cluster-name will have desired state: Ready
2022-04-04 11:50:04 [main] [32mINFO [m [ResourceManager:444] Kafka: dynamic-configuration-shared-cluster-name is in desired state: Ready
2022-04-04 11:50:04 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:50:04 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.testDynConfiguration-STARTED
2022-04-04 11:50:04 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:334] Kafka config {advertised.listeners=io.strimzi.kafka.config.model.ConfigModel@3078c800, alter.config.policy.class.name=io.strimzi.kafka.config.model.ConfigModel@3ea04bda, alter.log.dirs.replication.quota.window.num=io.strimzi.kafka.config.model.ConfigModel@321e503, alter.log.dirs.replication.quota.window.size.seconds=io.strimzi.kafka.config.model.ConfigModel@5c72ea80, authorizer.class.name=io.strimzi.kafka.config.model.ConfigModel@2abc01c6, auto.create.topics.enable=io.strimzi.kafka.config.model.ConfigModel@167e61d0, auto.leader.rebalance.enable=io.strimzi.kafka.config.model.ConfigModel@1a7b97e1, background.threads=io.strimzi.kafka.config.model.ConfigModel@511658c4, broker.heartbeat.interval.ms=io.strimzi.kafka.config.model.ConfigModel@1b6ed111, broker.id=io.strimzi.kafka.config.model.ConfigModel@7efb534d, broker.id.generation.enable=io.strimzi.kafka.config.model.ConfigModel@38f907ec, broker.rack=io.strimzi.kafka.config.model.ConfigModel@5bcab84f, broker.session.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@36c10c7e, client.quota.callback.class=io.strimzi.kafka.config.model.ConfigModel@120440d0, compression.type=io.strimzi.kafka.config.model.ConfigModel@62b2e31b, connection.failed.authentication.delay.ms=io.strimzi.kafka.config.model.ConfigModel@6cb427c2, connections.max.idle.ms=io.strimzi.kafka.config.model.ConfigModel@52a874d6, connections.max.reauth.ms=io.strimzi.kafka.config.model.ConfigModel@629aac93, control.plane.listener.name=io.strimzi.kafka.config.model.ConfigModel@17c521e0, controlled.shutdown.enable=io.strimzi.kafka.config.model.ConfigModel@5a829eed, controlled.shutdown.max.retries=io.strimzi.kafka.config.model.ConfigModel@4b1d4faf, controlled.shutdown.retry.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@7cd48c6b, controller.listener.names=io.strimzi.kafka.config.model.ConfigModel@42206830, controller.quorum.append.linger.ms=io.strimzi.kafka.config.model.ConfigModel@c9be36f, controller.quorum.election.backoff.max.ms=io.strimzi.kafka.config.model.ConfigModel@2d5aa564, controller.quorum.election.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@7535c370, controller.quorum.fetch.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@3415540e, controller.quorum.request.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@67c65978, controller.quorum.retry.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@1f4fb161, controller.quota.window.num=io.strimzi.kafka.config.model.ConfigModel@443adfbb, controller.quota.window.size.seconds=io.strimzi.kafka.config.model.ConfigModel@5a914616, controller.socket.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@f49d9a5, create.topic.policy.class.name=io.strimzi.kafka.config.model.ConfigModel@6defb594, default.replication.factor=io.strimzi.kafka.config.model.ConfigModel@7fba6895, delegation.token.expiry.check.interval.ms=io.strimzi.kafka.config.model.ConfigModel@2fcb3082, delegation.token.expiry.time.ms=io.strimzi.kafka.config.model.ConfigModel@6e8e502f, delegation.token.master.key=io.strimzi.kafka.config.model.ConfigModel@7e5d0b7f, delegation.token.max.lifetime.ms=io.strimzi.kafka.config.model.ConfigModel@520f2ae1, delegation.token.secret.key=io.strimzi.kafka.config.model.ConfigModel@24b64f02, delete.records.purgatory.purge.interval.requests=io.strimzi.kafka.config.model.ConfigModel@38a57c93, delete.topic.enable=io.strimzi.kafka.config.model.ConfigModel@2eb59e0b, fetch.max.bytes=io.strimzi.kafka.config.model.ConfigModel@5c6f11e, fetch.purgatory.purge.interval.requests=io.strimzi.kafka.config.model.ConfigModel@131e70fb, group.initial.rebalance.delay.ms=io.strimzi.kafka.config.model.ConfigModel@ccc7ef, group.max.session.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@28b443b, group.max.size=io.strimzi.kafka.config.model.ConfigModel@30770b75, group.min.session.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@508e2c28, initial.broker.registration.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@361b7a69, inter.broker.listener.name=io.strimzi.kafka.config.model.ConfigModel@6ee95a0d, inter.broker.protocol.version=io.strimzi.kafka.config.model.ConfigModel@66cdc806, kafka.metrics.polling.interval.secs=io.strimzi.kafka.config.model.ConfigModel@4783579b, kafka.metrics.reporters=io.strimzi.kafka.config.model.ConfigModel@2a26a530, leader.imbalance.check.interval.seconds=io.strimzi.kafka.config.model.ConfigModel@ebbab4b, leader.imbalance.per.broker.percentage=io.strimzi.kafka.config.model.ConfigModel@6becf62, listener.security.protocol.map=io.strimzi.kafka.config.model.ConfigModel@5bdc7fa1, listeners=io.strimzi.kafka.config.model.ConfigModel@44cc5ecf, log.cleaner.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@177e44ee, log.cleaner.dedupe.buffer.size=io.strimzi.kafka.config.model.ConfigModel@674b5cbc, log.cleaner.delete.retention.ms=io.strimzi.kafka.config.model.ConfigModel@5fd21683, log.cleaner.enable=io.strimzi.kafka.config.model.ConfigModel@79ce0190, log.cleaner.io.buffer.load.factor=io.strimzi.kafka.config.model.ConfigModel@1c726373, log.cleaner.io.buffer.size=io.strimzi.kafka.config.model.ConfigModel@216162fd, log.cleaner.io.max.bytes.per.second=io.strimzi.kafka.config.model.ConfigModel@6ec80e5c, log.cleaner.max.compaction.lag.ms=io.strimzi.kafka.config.model.ConfigModel@67035094, log.cleaner.min.cleanable.ratio=io.strimzi.kafka.config.model.ConfigModel@6865defc, log.cleaner.min.compaction.lag.ms=io.strimzi.kafka.config.model.ConfigModel@42393f87, log.cleaner.threads=io.strimzi.kafka.config.model.ConfigModel@6c2d7372, log.cleanup.policy=io.strimzi.kafka.config.model.ConfigModel@11570993, log.dir=io.strimzi.kafka.config.model.ConfigModel@5703b77b, log.dirs=io.strimzi.kafka.config.model.ConfigModel@5ccd7f1b, log.flush.interval.messages=io.strimzi.kafka.config.model.ConfigModel@5b7c2113, log.flush.interval.ms=io.strimzi.kafka.config.model.ConfigModel@724ea07e, log.flush.offset.checkpoint.interval.ms=io.strimzi.kafka.config.model.ConfigModel@38bc7923, log.flush.scheduler.interval.ms=io.strimzi.kafka.config.model.ConfigModel@fbeec88, log.flush.start.offset.checkpoint.interval.ms=io.strimzi.kafka.config.model.ConfigModel@357020d5, log.index.interval.bytes=io.strimzi.kafka.config.model.ConfigModel@323a2b55, log.index.size.max.bytes=io.strimzi.kafka.config.model.ConfigModel@69942950, log.message.downconversion.enable=io.strimzi.kafka.config.model.ConfigModel@11b65246, log.message.format.version=io.strimzi.kafka.config.model.ConfigModel@25f4be2d, log.message.timestamp.difference.max.ms=io.strimzi.kafka.config.model.ConfigModel@46f74945, log.message.timestamp.type=io.strimzi.kafka.config.model.ConfigModel@ee12662, log.preallocate=io.strimzi.kafka.config.model.ConfigModel@2de6619a, log.retention.bytes=io.strimzi.kafka.config.model.ConfigModel@2de3b7dd, log.retention.check.interval.ms=io.strimzi.kafka.config.model.ConfigModel@51226e45, log.retention.hours=io.strimzi.kafka.config.model.ConfigModel@56f78035, log.retention.minutes=io.strimzi.kafka.config.model.ConfigModel@4803d1c0, log.retention.ms=io.strimzi.kafka.config.model.ConfigModel@786eda42, log.roll.hours=io.strimzi.kafka.config.model.ConfigModel@3a7cc34c, log.roll.jitter.hours=io.strimzi.kafka.config.model.ConfigModel@50601a1e, log.roll.jitter.ms=io.strimzi.kafka.config.model.ConfigModel@6bb5c03, log.roll.ms=io.strimzi.kafka.config.model.ConfigModel@8093a5c, log.segment.bytes=io.strimzi.kafka.config.model.ConfigModel@54b3eeb2, log.segment.delete.delay.ms=io.strimzi.kafka.config.model.ConfigModel@4d3bed0, max.connection.creation.rate=io.strimzi.kafka.config.model.ConfigModel@58d4b10d, max.connections=io.strimzi.kafka.config.model.ConfigModel@19ceab91, max.connections.per.ip=io.strimzi.kafka.config.model.ConfigModel@52c31064, max.connections.per.ip.overrides=io.strimzi.kafka.config.model.ConfigModel@4bff11d2, max.incremental.fetch.session.cache.slots=io.strimzi.kafka.config.model.ConfigModel@36de8d79, message.max.bytes=io.strimzi.kafka.config.model.ConfigModel@5a202a10, metadata.log.dir=io.strimzi.kafka.config.model.ConfigModel@10aa4100, metadata.log.max.record.bytes.between.snapshots=io.strimzi.kafka.config.model.ConfigModel@23e8b346, metadata.log.segment.bytes=io.strimzi.kafka.config.model.ConfigModel@611f4707, metadata.log.segment.min.bytes=io.strimzi.kafka.config.model.ConfigModel@3ab4919e, metadata.log.segment.ms=io.strimzi.kafka.config.model.ConfigModel@78546589, metadata.max.retention.bytes=io.strimzi.kafka.config.model.ConfigModel@1e408b46, metadata.max.retention.ms=io.strimzi.kafka.config.model.ConfigModel@5fcc0f6, metric.reporters=io.strimzi.kafka.config.model.ConfigModel@1bda99b6, metrics.num.samples=io.strimzi.kafka.config.model.ConfigModel@40f9cf69, metrics.recording.level=io.strimzi.kafka.config.model.ConfigModel@5a79668b, metrics.sample.window.ms=io.strimzi.kafka.config.model.ConfigModel@3961f642, min.insync.replicas=io.strimzi.kafka.config.model.ConfigModel@76b9cff1, node.id=io.strimzi.kafka.config.model.ConfigModel@78b5d4c8, num.io.threads=io.strimzi.kafka.config.model.ConfigModel@69e9a86b, num.network.threads=io.strimzi.kafka.config.model.ConfigModel@5f0c90f2, num.partitions=io.strimzi.kafka.config.model.ConfigModel@67f21aa5, num.recovery.threads.per.data.dir=io.strimzi.kafka.config.model.ConfigModel@31379107, num.replica.alter.log.dirs.threads=io.strimzi.kafka.config.model.ConfigModel@15b9ddba, num.replica.fetchers=io.strimzi.kafka.config.model.ConfigModel@2e0944ff, offset.metadata.max.bytes=io.strimzi.kafka.config.model.ConfigModel@59d944a9, offsets.commit.required.acks=io.strimzi.kafka.config.model.ConfigModel@546b593c, offsets.commit.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@f640a06, offsets.load.buffer.size=io.strimzi.kafka.config.model.ConfigModel@6bae99a9, offsets.retention.check.interval.ms=io.strimzi.kafka.config.model.ConfigModel@78c17479, offsets.retention.minutes=io.strimzi.kafka.config.model.ConfigModel@766d60e4, offsets.topic.compression.codec=io.strimzi.kafka.config.model.ConfigModel@59766015, offsets.topic.num.partitions=io.strimzi.kafka.config.model.ConfigModel@468ad943, offsets.topic.replication.factor=io.strimzi.kafka.config.model.ConfigModel@359b1f57, offsets.topic.segment.bytes=io.strimzi.kafka.config.model.ConfigModel@28ec2340, password.encoder.cipher.algorithm=io.strimzi.kafka.config.model.ConfigModel@42708880, password.encoder.iterations=io.strimzi.kafka.config.model.ConfigModel@52a0014c, password.encoder.key.length=io.strimzi.kafka.config.model.ConfigModel@3facdde8, password.encoder.keyfactory.algorithm=io.strimzi.kafka.config.model.ConfigModel@76931f7e, password.encoder.old.secret=io.strimzi.kafka.config.model.ConfigModel@3061ada4, password.encoder.secret=io.strimzi.kafka.config.model.ConfigModel@62197085, principal.builder.class=io.strimzi.kafka.config.model.ConfigModel@3b83a2b3, process.roles=io.strimzi.kafka.config.model.ConfigModel@55053252, producer.purgatory.purge.interval.requests=io.strimzi.kafka.config.model.ConfigModel@68b4b9db, queued.max.request.bytes=io.strimzi.kafka.config.model.ConfigModel@41806110, queued.max.requests=io.strimzi.kafka.config.model.ConfigModel@67b0c5a9, quota.window.num=io.strimzi.kafka.config.model.ConfigModel@1b5becaf, quota.window.size.seconds=io.strimzi.kafka.config.model.ConfigModel@566ce47e, remote.log.index.file.cache.total.size.bytes=io.strimzi.kafka.config.model.ConfigModel@14a69742, remote.log.manager.task.interval.ms=io.strimzi.kafka.config.model.ConfigModel@755a95f2, remote.log.manager.task.retry.backoff.max.ms=io.strimzi.kafka.config.model.ConfigModel@31202162, remote.log.manager.task.retry.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@de6c2c, remote.log.manager.task.retry.jitter=io.strimzi.kafka.config.model.ConfigModel@2062f7f2, remote.log.manager.thread.pool.size=io.strimzi.kafka.config.model.ConfigModel@1b61309, remote.log.metadata.manager.class.name=io.strimzi.kafka.config.model.ConfigModel@312d196c, remote.log.metadata.manager.class.path=io.strimzi.kafka.config.model.ConfigModel@4261ac69, remote.log.metadata.manager.impl.prefix=io.strimzi.kafka.config.model.ConfigModel@750b0eb0, remote.log.metadata.manager.listener.name=io.strimzi.kafka.config.model.ConfigModel@44147543, remote.log.reader.max.pending.tasks=io.strimzi.kafka.config.model.ConfigModel@1dabe2d4, remote.log.reader.threads=io.strimzi.kafka.config.model.ConfigModel@526607ec, remote.log.storage.manager.class.name=io.strimzi.kafka.config.model.ConfigModel@7f35ed9e, remote.log.storage.manager.class.path=io.strimzi.kafka.config.model.ConfigModel@186c2156, remote.log.storage.manager.impl.prefix=io.strimzi.kafka.config.model.ConfigModel@5a93ddcd, remote.log.storage.system.enable=io.strimzi.kafka.config.model.ConfigModel@3828e814, replica.fetch.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@6821bb92, replica.fetch.max.bytes=io.strimzi.kafka.config.model.ConfigModel@113e5151, replica.fetch.min.bytes=io.strimzi.kafka.config.model.ConfigModel@55878b0e, replica.fetch.response.max.bytes=io.strimzi.kafka.config.model.ConfigModel@2a10a1e2, replica.fetch.wait.max.ms=io.strimzi.kafka.config.model.ConfigModel@4f086219, replica.high.watermark.checkpoint.interval.ms=io.strimzi.kafka.config.model.ConfigModel@2cdf0670, replica.lag.time.max.ms=io.strimzi.kafka.config.model.ConfigModel@4569271e, replica.selector.class=io.strimzi.kafka.config.model.ConfigModel@6a5981e0, replica.socket.receive.buffer.bytes=io.strimzi.kafka.config.model.ConfigModel@664d3e18, replica.socket.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@32755827, replication.quota.window.num=io.strimzi.kafka.config.model.ConfigModel@3e28c8a0, replication.quota.window.size.seconds=io.strimzi.kafka.config.model.ConfigModel@18d80804, request.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@176a48f9, reserved.broker.max.id=io.strimzi.kafka.config.model.ConfigModel@fc69e53, sasl.client.callback.handler.class=io.strimzi.kafka.config.model.ConfigModel@77533ac3, sasl.enabled.mechanisms=io.strimzi.kafka.config.model.ConfigModel@2f139405, sasl.jaas.config=io.strimzi.kafka.config.model.ConfigModel@6a7b3c9e, sasl.kerberos.kinit.cmd=io.strimzi.kafka.config.model.ConfigModel@51740384, sasl.kerberos.min.time.before.relogin=io.strimzi.kafka.config.model.ConfigModel@3f9fae4b, sasl.kerberos.principal.to.local.rules=io.strimzi.kafka.config.model.ConfigModel@c9fa601, sasl.kerberos.service.name=io.strimzi.kafka.config.model.ConfigModel@3fb3e4c0, sasl.kerberos.ticket.renew.jitter=io.strimzi.kafka.config.model.ConfigModel@4e2aa891, sasl.kerberos.ticket.renew.window.factor=io.strimzi.kafka.config.model.ConfigModel@c05aae9, sasl.login.callback.handler.class=io.strimzi.kafka.config.model.ConfigModel@7ddbaac6, sasl.login.class=io.strimzi.kafka.config.model.ConfigModel@5deed459, sasl.login.connect.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@461b8155, sasl.login.read.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@6768399d, sasl.login.refresh.buffer.seconds=io.strimzi.kafka.config.model.ConfigModel@4745222c, sasl.login.refresh.min.period.seconds=io.strimzi.kafka.config.model.ConfigModel@6ca26a81, sasl.login.refresh.window.factor=io.strimzi.kafka.config.model.ConfigModel@76295f69, sasl.login.refresh.window.jitter=io.strimzi.kafka.config.model.ConfigModel@50ab34e0, sasl.login.retry.backoff.max.ms=io.strimzi.kafka.config.model.ConfigModel@3e11389b, sasl.login.retry.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@4198abba, sasl.mechanism.controller.protocol=io.strimzi.kafka.config.model.ConfigModel@7df666f7, sasl.mechanism.inter.broker.protocol=io.strimzi.kafka.config.model.ConfigModel@7473419d, sasl.oauthbearer.clock.skew.seconds=io.strimzi.kafka.config.model.ConfigModel@43117a68, sasl.oauthbearer.expected.audience=io.strimzi.kafka.config.model.ConfigModel@4750dccb, sasl.oauthbearer.expected.issuer=io.strimzi.kafka.config.model.ConfigModel@9dfcb08, sasl.oauthbearer.jwks.endpoint.refresh.ms=io.strimzi.kafka.config.model.ConfigModel@674e1c07, sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms=io.strimzi.kafka.config.model.ConfigModel@2fc4f8bc, sasl.oauthbearer.jwks.endpoint.retry.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@6eb3df0b, sasl.oauthbearer.jwks.endpoint.url=io.strimzi.kafka.config.model.ConfigModel@19c3de5e, sasl.oauthbearer.scope.claim.name=io.strimzi.kafka.config.model.ConfigModel@efa4745, sasl.oauthbearer.sub.claim.name=io.strimzi.kafka.config.model.ConfigModel@6735f3e, sasl.oauthbearer.token.endpoint.url=io.strimzi.kafka.config.model.ConfigModel@76c8837c, sasl.server.callback.handler.class=io.strimzi.kafka.config.model.ConfigModel@717e92d5, security.inter.broker.protocol=io.strimzi.kafka.config.model.ConfigModel@2d6223d0, security.providers=io.strimzi.kafka.config.model.ConfigModel@31f403ed, socket.connection.setup.timeout.max.ms=io.strimzi.kafka.config.model.ConfigModel@315b5cc, socket.connection.setup.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@6f86741, socket.receive.buffer.bytes=io.strimzi.kafka.config.model.ConfigModel@3ab8b8ed, socket.request.max.bytes=io.strimzi.kafka.config.model.ConfigModel@2bc23f3c, socket.send.buffer.bytes=io.strimzi.kafka.config.model.ConfigModel@5d7445d, ssl.cipher.suites=io.strimzi.kafka.config.model.ConfigModel@40d0e9c9, ssl.client.auth=io.strimzi.kafka.config.model.ConfigModel@3f505eee, ssl.enabled.protocols=io.strimzi.kafka.config.model.ConfigModel@5d1bde7, ssl.endpoint.identification.algorithm=io.strimzi.kafka.config.model.ConfigModel@3a9bf4ac, ssl.engine.factory.class=io.strimzi.kafka.config.model.ConfigModel@7d42cc97, ssl.key.password=io.strimzi.kafka.config.model.ConfigModel@40584aff, ssl.keymanager.algorithm=io.strimzi.kafka.config.model.ConfigModel@486ee996, ssl.keystore.certificate.chain=io.strimzi.kafka.config.model.ConfigModel@2db55aa3, ssl.keystore.key=io.strimzi.kafka.config.model.ConfigModel@46f80df6, ssl.keystore.location=io.strimzi.kafka.config.model.ConfigModel@44f5b864, ssl.keystore.password=io.strimzi.kafka.config.model.ConfigModel@7b68cb35, ssl.keystore.type=io.strimzi.kafka.config.model.ConfigModel@7c8ff6b9, ssl.principal.mapping.rules=io.strimzi.kafka.config.model.ConfigModel@7a9ed363, ssl.protocol=io.strimzi.kafka.config.model.ConfigModel@134162cc, ssl.provider=io.strimzi.kafka.config.model.ConfigModel@2ecd32f2, ssl.secure.random.implementation=io.strimzi.kafka.config.model.ConfigModel@2df423ac, ssl.trustmanager.algorithm=io.strimzi.kafka.config.model.ConfigModel@21fdf8ba, ssl.truststore.certificates=io.strimzi.kafka.config.model.ConfigModel@39b2b94b, ssl.truststore.location=io.strimzi.kafka.config.model.ConfigModel@7e2f562d, ssl.truststore.password=io.strimzi.kafka.config.model.ConfigModel@72caf307, ssl.truststore.type=io.strimzi.kafka.config.model.ConfigModel@3cbcedcc, transaction.abort.timed.out.transaction.cleanup.interval.ms=io.strimzi.kafka.config.model.ConfigModel@10e873f1, transaction.max.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@1472d1ff, transaction.remove.expired.transaction.cleanup.interval.ms=io.strimzi.kafka.config.model.ConfigModel@31054abd, transaction.state.log.load.buffer.size=io.strimzi.kafka.config.model.ConfigModel@6a0c13dc, transaction.state.log.min.isr=io.strimzi.kafka.config.model.ConfigModel@39288297, transaction.state.log.num.partitions=io.strimzi.kafka.config.model.ConfigModel@3b574164, transaction.state.log.replication.factor=io.strimzi.kafka.config.model.ConfigModel@201cb411, transaction.state.log.segment.bytes=io.strimzi.kafka.config.model.ConfigModel@2a04d13d, transactional.id.expiration.ms=io.strimzi.kafka.config.model.ConfigModel@57c5c2d0, unclean.leader.election.enable=io.strimzi.kafka.config.model.ConfigModel@5618f52d, zookeeper.clientCnxnSocket=io.strimzi.kafka.config.model.ConfigModel@13616fc3, zookeeper.connect=io.strimzi.kafka.config.model.ConfigModel@1f60d9ab, zookeeper.connection.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@66ca5bd5, zookeeper.max.in.flight.requests=io.strimzi.kafka.config.model.ConfigModel@776a6bbc, zookeeper.session.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@6f6d1de5, zookeeper.set.acl=io.strimzi.kafka.config.model.ConfigModel@76592c22, zookeeper.ssl.cipher.suites=io.strimzi.kafka.config.model.ConfigModel@42f9c5cf, zookeeper.ssl.client.enable=io.strimzi.kafka.config.model.ConfigModel@666a61a7, zookeeper.ssl.crl.enable=io.strimzi.kafka.config.model.ConfigModel@616fdaba, zookeeper.ssl.enabled.protocols=io.strimzi.kafka.config.model.ConfigModel@5ee8c289, zookeeper.ssl.endpoint.identification.algorithm=io.strimzi.kafka.config.model.ConfigModel@5233a326, zookeeper.ssl.keystore.location=io.strimzi.kafka.config.model.ConfigModel@6761979e, zookeeper.ssl.keystore.password=io.strimzi.kafka.config.model.ConfigModel@78442bc2, zookeeper.ssl.keystore.type=io.strimzi.kafka.config.model.ConfigModel@60a042c9, zookeeper.ssl.ocsp.enable=io.strimzi.kafka.config.model.ConfigModel@2f45e768, zookeeper.ssl.protocol=io.strimzi.kafka.config.model.ConfigModel@44f35879, zookeeper.ssl.truststore.location=io.strimzi.kafka.config.model.ConfigModel@1d30711e, zookeeper.ssl.truststore.password=io.strimzi.kafka.config.model.ConfigModel@7f64de7b, zookeeper.ssl.truststore.type=io.strimzi.kafka.config.model.ConfigModel@7f1a0858, zookeeper.sync.time.ms=io.strimzi.kafka.config.model.ConfigModel@21f4a752}
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:336] Number of all kafka configs 261
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:356] Number of dynamic-configs 40
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:364] Number of forbidden-exception-configs 7
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:371] Size of dynamic-configs with forbidden-exception-configs 46
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] compression.type -> CLUSTER_WIDE:STRING
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.min.compaction.lag.ms -> CLUSTER_WIDE:LONG
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] log.retention.ms -> CLUSTER_WIDE:LONG
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] max.connections.per.ip.overrides -> CLUSTER_WIDE:STRING
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] metric.reporters -> CLUSTER_WIDE:LIST
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] log.flush.interval.messages -> CLUSTER_WIDE:LONG
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] log.message.timestamp.difference.max.ms -> CLUSTER_WIDE:LONG
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] log.flush.interval.ms -> CLUSTER_WIDE:LONG
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] principal.builder.class -> PER_BROKER:CLASS
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.delete.retention.ms -> CLUSTER_WIDE:LONG
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.io.buffer.size -> CLUSTER_WIDE:INT
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] min.insync.replicas -> CLUSTER_WIDE:INT
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] zookeeper.connection.timeout.ms -> READ_ONLY:INT
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.threads -> CLUSTER_WIDE:INT
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.io.max.bytes.per.second -> CLUSTER_WIDE:DOUBLE
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.min.cleanable.ratio -> CLUSTER_WIDE:DOUBLE
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] num.recovery.threads.per.data.dir -> CLUSTER_WIDE:INT
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] log.retention.bytes -> CLUSTER_WIDE:LONG
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] num.network.threads -> CLUSTER_WIDE:INT
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] log.cleanup.policy -> CLUSTER_WIDE:LIST
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] log.message.timestamp.type -> CLUSTER_WIDE:STRING
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] log.preallocate -> CLUSTER_WIDE:BOOLEAN
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] log.roll.jitter.ms -> CLUSTER_WIDE:LONG
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] max.connections -> CLUSTER_WIDE:INT
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] max.connections.per.ip -> CLUSTER_WIDE:INT
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] background.threads -> CLUSTER_WIDE:INT
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] log.message.downconversion.enable -> CLUSTER_WIDE:BOOLEAN
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] message.max.bytes -> CLUSTER_WIDE:INT
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] ssl.protocol -> PER_BROKER:STRING
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] num.partitions -> READ_ONLY:INT
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] num.io.threads -> CLUSTER_WIDE:INT
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] ssl.enabled.protocols -> PER_BROKER:LIST
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] max.connection.creation.rate -> CLUSTER_WIDE:INT
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] log.roll.ms -> CLUSTER_WIDE:LONG
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] ssl.cipher.suites -> PER_BROKER:LIST
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] unclean.leader.election.enable -> CLUSTER_WIDE:BOOLEAN
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] log.index.interval.bytes -> CLUSTER_WIDE:INT
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.backoff.ms -> CLUSTER_WIDE:LONG
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] log.segment.bytes -> CLUSTER_WIDE:INT
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.io.buffer.load.factor -> CLUSTER_WIDE:DOUBLE
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] log.index.size.max.bytes -> CLUSTER_WIDE:INT
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] zookeeper.connect -> READ_ONLY:STRING
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] log.segment.delete.delay.ms -> CLUSTER_WIDE:LONG
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.max.compaction.lag.ms -> CLUSTER_WIDE:LONG
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] num.replica.fetchers -> CLUSTER_WIDE:INT
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.dedupe.buffer.size -> CLUSTER_WIDE:LONG
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:234] Kafka config before updating '{default.replication.factor=3, inter.broker.protocol.version=3.1, log.message.format.version=3.1, min.insync.replicas=2, offsets.topic.replication.factor=3, transaction.state.log.min.isr=2, transaction.state.log.replication.factor=3}'
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:238] Kafka config after updating '{default.replication.factor=3, inter.broker.protocol.version=3.1, log.message.format.version=3.1, min.insync.replicas=2, offsets.topic.replication.factor=3, transaction.state.log.min.isr=2, transaction.state.log.replication.factor=3, log.flush.interval.ms=41076}'
2022-04-04 11:50:04 [main] [32mINFO [m [KafkaUtils:180] Waiting for cluster stability
2022-04-04 11:51:07 [main] [32mINFO [m [KafkaUtils:208] Kafka cluster is stable after 61 polls.
2022-04-04 11:51:07 [main] [32mINFO [m [KafkaUtils:262] Dynamic Configuration in Kafka CR is log.flush.interval.ms=41076 and expected is log.flush.interval.ms=41076
2022-04-04 11:51:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:51:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:51:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-1 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:51:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:51:21 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-2 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:51:21 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:51:21 [main] [32mINFO [m [KafkaUtils:234] Kafka config before updating '{default.replication.factor=3, inter.broker.protocol.version=3.1, log.flush.interval.ms=41076, log.message.format.version=3.1, min.insync.replicas=2, offsets.topic.replication.factor=3, transaction.state.log.min.isr=2, transaction.state.log.replication.factor=3}'
2022-04-04 11:51:21 [main] [32mINFO [m [KafkaUtils:238] Kafka config after updating '{default.replication.factor=3, inter.broker.protocol.version=3.1, log.flush.interval.ms=41076, log.message.format.version=3.1, min.insync.replicas=2, offsets.topic.replication.factor=3, transaction.state.log.min.isr=2, transaction.state.log.replication.factor=3, max.connections.per.ip.overrides= }'
2022-04-04 11:51:21 [main] [32mINFO [m [KafkaUtils:180] Waiting for cluster stability
2022-04-04 11:52:24 [main] [32mINFO [m [KafkaUtils:208] Kafka cluster is stable after 61 polls.
2022-04-04 11:52:24 [main] [32mINFO [m [KafkaUtils:262] Dynamic Configuration in Kafka CR is max.connections.per.ip.overrides=  and expected is max.connections.per.ip.overrides= 
2022-04-04 11:52:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:52:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:52:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-1 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:52:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:52:32 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-2 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:52:32 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:52:32 [main] [32mINFO [m [KafkaUtils:234] Kafka config before updating '{default.replication.factor=3, inter.broker.protocol.version=3.1, log.flush.interval.ms=41076, log.message.format.version=3.1, max.connections.per.ip.overrides= , min.insync.replicas=2, offsets.topic.replication.factor=3, transaction.state.log.min.isr=2, transaction.state.log.replication.factor=3}'
2022-04-04 11:52:32 [main] [32mINFO [m [KafkaUtils:238] Kafka config after updating '{default.replication.factor=3, inter.broker.protocol.version=3.1, log.flush.interval.ms=41076, log.message.format.version=3.1, max.connections.per.ip.overrides= , min.insync.replicas=2, offsets.topic.replication.factor=3, transaction.state.log.min.isr=2, transaction.state.log.replication.factor=3, metric.reporters= }'
2022-04-04 11:52:32 [main] [32mINFO [m [KafkaUtils:180] Waiting for cluster stability
2022-04-04 11:53:34 [main] [32mINFO [m [KafkaUtils:208] Kafka cluster is stable after 61 polls.
2022-04-04 11:53:34 [main] [32mINFO [m [KafkaUtils:262] Dynamic Configuration in Kafka CR is metric.reporters=  and expected is metric.reporters= 
2022-04-04 11:53:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:53:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:53:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-1 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:53:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:53:42 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-2 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:53:42 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:53:42 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:53:42 [main] [32mINFO [m [ResourceManager:346] In context testDynConfiguration is everything deleted.
2022-04-04 11:53:42 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:53:42 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.testDynConfiguration-FINISHED
2022-04-04 11:53:42 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:53:42 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:53:42 [main] [32mINFO [m [ResourceManager:348] Delete all resources for DynamicConfSharedST
2022-04-04 11:53:42 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka dynamic-configuration-shared-cluster-name in namespace dynamic-conf-shared-st
2022-04-04 11:53:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 358.257 s - in io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.ConfigProviderST
2022-04-04 11:54:35 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: config-provider-st
2022-04-04 11:54:35 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: config-provider-st
2022-04-04 11:54:35 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: config-provider-st
2022-04-04 11:54:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:54:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.ConfigProviderST.testConnectWithConnectorUsingConfigAndEnvProvider-STARTED
2022-04-04 11:54:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:54:35 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-55 for test case:testConnectWithConnectorUsingConfigAndEnvProvider
2022-04-04 11:54:35 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-55
2022-04-04 11:54:35 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-55
2022-04-04 11:54:35 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-55
2022-04-04 11:54:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7f1dc8e9 in namespace namespace-55
2022-04-04 11:54:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-55
2022-04-04 11:54:35 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7f1dc8e9 will have desired state: Ready
2022-04-04 11:55:55 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7f1dc8e9 is in desired state: Ready
2022-04-04 11:55:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-7f1dc8e9 in namespace namespace-55
2022-04-04 11:55:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-55
2022-04-04 11:55:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-7f1dc8e9 will have desired state: Ready
2022-04-04 11:57:00 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-7f1dc8e9 is in desired state: Ready
2022-04-04 11:57:00 [main] [32mINFO [m [ConfigProviderST:100] Creating needed RoleBinding and Role for Kubernetes Config Provider
2022-04-04 11:57:00 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding connector-config-rb in namespace namespace-55
2022-04-04 11:57:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-55
2022-04-04 11:57:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-7f1dc8e9 in namespace namespace-55
2022-04-04 11:57:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-55
2022-04-04 11:57:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-7f1dc8e9 will have desired state: Ready
2022-04-04 11:57:01 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-7f1dc8e9 is in desired state: Ready
2022-04-04 11:57:01 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 11:57:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-my-consumer-group-1763356807 in namespace namespace-55
2022-04-04 11:57:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-55
2022-04-04 11:57:01 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-my-consumer-group-1763356807 will be in active state
2022-04-04 11:57:02 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-7f1dc8e9-connect-6c475c6585-nl7qh
2022-04-04 11:57:07 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-7f1dc8e9-connect-6c475c6585-nl7qh
2022-04-04 11:57:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:57:07 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConnectWithConnectorUsingConfigAndEnvProvider
2022-04-04 11:57:07 [main] [32mINFO [m [ResourceManager:241] Delete of RoleBinding connector-config-rb in namespace namespace-55
2022-04-04 11:57:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7f1dc8e9 in namespace namespace-55
2022-04-04 11:57:07 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job producer-my-consumer-group-1763356807 in namespace namespace-55
2022-04-04 11:57:07 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-7f1dc8e9 in namespace namespace-55
2022-04-04 11:57:07 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-7f1dc8e9 in namespace namespace-55
2022-04-04 11:57:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:57:17 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-55 for test case:testConnectWithConnectorUsingConfigAndEnvProvider
2022-04-04 11:57:55 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.ConfigProviderST.testConnectWithConnectorUsingConfigAndEnvProvider-FINISHED
2022-04-04 11:57:55 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:57:55 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:57:55 [main] [32mINFO [m [ResourceManager:346] In context ConfigProviderST is everything deleted.
2022-04-04 11:57:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 205.916 s - in io.strimzi.systemtest.kafka.ConfigProviderST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.OpaIntegrationST
2022-04-04 11:58:01 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: opa-integration-st
2022-04-04 11:58:01 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: opa-integration-st
2022-04-04 11:58:01 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: opa-integration-st
2022-04-04 11:58:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka opa-cluster in namespace opa-integration-st
2022-04-04 11:58:01 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: opa-cluster will have desired state: Ready
2022-04-04 11:59:23 [main] [32mINFO [m [ResourceManager:444] Kafka: opa-cluster is in desired state: Ready
2022-04-04 11:59:23 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:59:23 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.OpaIntegrationST.testOpaAuthorizationSuperUser-STARTED
2022-04-04 11:59:23 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:59:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-980903154-1365760219 in namespace opa-integration-st
2022-04-04 11:59:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-980903154-1365760219 will have desired state: Ready
2022-04-04 11:59:24 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-980903154-1365760219 is in desired state: Ready
2022-04-04 11:59:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser arnost in namespace opa-integration-st
2022-04-04 11:59:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: arnost will have desired state: Ready
2022-04-04 11:59:26 [main] [32mINFO [m [ResourceManager:444] KafkaUser: arnost is in desired state: Ready
2022-04-04 11:59:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-2fdf0389-kafka-clients in namespace opa-integration-st
2022-04-04 11:59:26 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-2fdf0389-kafka-clients will be ready
2022-04-04 11:59:29 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-2fdf0389-kafka-clients is ready
2022-04-04 11:59:29 [main] [32mINFO [m [OpaIntegrationST:120] Checking KafkaUser good-user that is able to send and receive messages to/from topic 'my-topic-980903154-1365760219'
2022-04-04 11:59:29 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@4b608ae6, messages=[], arguments=[--topic, my-topic-980903154-1365760219, --max-messages, 100, USER=arnost, --bootstrap-server, opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-2fdf0389-kafka-clients-794d64986b-82fms', podNamespace='opa-integration-st', bootstrapServer='opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093', topicName='my-topic-980903154-1365760219', maxMessages=100, kafkaUsername='arnost', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6d330342}
2022-04-04 11:59:29 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093:my-topic-980903154-1365760219 from pod my-cluster-2fdf0389-kafka-clients-794d64986b-82fms
2022-04-04 11:59:29 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2fdf0389-kafka-clients-794d64986b-82fms -n opa-integration-st -- /opt/kafka/producer.sh --topic my-topic-980903154-1365760219 --max-messages 100 USER=arnost --bootstrap-server opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093
2022-04-04 11:59:37 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 11:59:37 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 11:59:37 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@21f982c0, messages=[], arguments=[--topic, my-topic-980903154-1365760219, --max-messages, 100, --group-instance-id, instance831858173, USER=arnost, --group-id, consumer-group-name-2, --bootstrap-server, opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-2fdf0389-kafka-clients-794d64986b-82fms', podNamespace='opa-integration-st', bootstrapServer='opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093', topicName='my-topic-980903154-1365760219', maxMessages=100, kafkaUsername='arnost', consumerGroupName='consumer-group-name-2', consumerInstanceId='instance831858173', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@54a5a205}
2022-04-04 11:59:37 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093:my-topic-980903154-1365760219 from pod my-cluster-2fdf0389-kafka-clients-794d64986b-82fms
2022-04-04 11:59:37 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2fdf0389-kafka-clients-794d64986b-82fms -n opa-integration-st -- /opt/kafka/consumer.sh --topic my-topic-980903154-1365760219 --max-messages 100 --group-instance-id instance831858173 USER=arnost --group-id consumer-group-name-2 --bootstrap-server opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093
2022-04-04 11:59:51 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 11:59:51 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 11:59:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:59:51 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testOpaAuthorizationSuperUser
2022-04-04 11:59:51 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser arnost in namespace opa-integration-st
2022-04-04 11:59:51 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-980903154-1365760219 in namespace opa-integration-st
2022-04-04 11:59:51 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-2fdf0389-kafka-clients in namespace opa-integration-st
2022-04-04 12:00:41 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 12:00:41 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.OpaIntegrationST.testOpaAuthorizationSuperUser-FINISHED
2022-04-04 12:00:41 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 12:00:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 12:00:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.OpaIntegrationST.testOpaAuthorization-STARTED
2022-04-04 12:00:41 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 12:00:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser good-user in namespace opa-integration-st
2022-04-04 12:00:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: good-user will have desired state: Ready
2022-04-04 12:00:42 [main] [32mINFO [m [ResourceManager:444] KafkaUser: good-user is in desired state: Ready
2022-04-04 12:00:42 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser bad-user in namespace opa-integration-st
2022-04-04 12:00:42 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: bad-user will have desired state: Ready
2022-04-04 12:00:43 [main] [32mINFO [m [ResourceManager:444] KafkaUser: bad-user is in desired state: Ready
2022-04-04 12:00:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-05e69603-kafka-clients in namespace opa-integration-st
2022-04-04 12:00:43 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-05e69603-kafka-clients will be ready
2022-04-04 12:00:46 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-05e69603-kafka-clients is ready
2022-04-04 12:00:46 [main] [32mINFO [m [OpaIntegrationST:72] Checking KafkaUser good-user that is able to send and receive messages to/from topic 'my-topic-2071090599-804959110'
2022-04-04 12:00:46 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@e84ea69, messages=[], arguments=[--topic, my-topic-2071090599-804959110, --max-messages, 100, USER=good_user, --bootstrap-server, opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-05e69603-kafka-clients-765b7cd4bd-878w7', podNamespace='opa-integration-st', bootstrapServer='opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093', topicName='my-topic-2071090599-804959110', maxMessages=100, kafkaUsername='good-user', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@77c8db1f}
2022-04-04 12:00:46 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093:my-topic-2071090599-804959110 from pod my-cluster-05e69603-kafka-clients-765b7cd4bd-878w7
2022-04-04 12:00:46 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-05e69603-kafka-clients-765b7cd4bd-878w7 -n opa-integration-st -- /opt/kafka/producer.sh --topic my-topic-2071090599-804959110 --max-messages 100 USER=good_user --bootstrap-server opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093
2022-04-04 12:00:54 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 12:00:54 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 12:00:54 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5bc553b, messages=[], arguments=[--topic, my-topic-2071090599-804959110, --max-messages, 100, --group-instance-id, instance1981255212, USER=good_user, --group-id, my-consumer-group-1928800966, --bootstrap-server, opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-05e69603-kafka-clients-765b7cd4bd-878w7', podNamespace='opa-integration-st', bootstrapServer='opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093', topicName='my-topic-2071090599-804959110', maxMessages=100, kafkaUsername='good-user', consumerGroupName='my-consumer-group-1928800966', consumerInstanceId='instance1981255212', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@630696fb}
2022-04-04 12:00:54 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093:my-topic-2071090599-804959110 from pod my-cluster-05e69603-kafka-clients-765b7cd4bd-878w7
2022-04-04 12:00:54 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-05e69603-kafka-clients-765b7cd4bd-878w7 -n opa-integration-st -- /opt/kafka/consumer.sh --topic my-topic-2071090599-804959110 --max-messages 100 --group-instance-id instance1981255212 USER=good_user --group-id my-consumer-group-1928800966 --bootstrap-server opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093
2022-04-04 12:01:02 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 12:01:02 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 12:01:02 [main] [32mINFO [m [OpaIntegrationST:89] Checking KafkaUser bad-user that is not able to send or receive messages to/from topic 'my-topic-2071090599-804959110'
2022-04-04 12:01:02 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1de315e8, messages=[], arguments=[--topic, my-topic-2071090599-804959110, --max-messages, 100, USER=bad_user, --bootstrap-server, opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-05e69603-kafka-clients-765b7cd4bd-878w7', podNamespace='opa-integration-st', bootstrapServer='opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093', topicName='my-topic-2071090599-804959110', maxMessages=100, kafkaUsername='bad-user', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@349d76b0}
2022-04-04 12:01:02 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093:my-topic-2071090599-804959110 from pod my-cluster-05e69603-kafka-clients-765b7cd4bd-878w7
2022-04-04 12:01:02 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-05e69603-kafka-clients-765b7cd4bd-878w7 -n opa-integration-st -- /opt/kafka/producer.sh --topic my-topic-2071090599-804959110 --max-messages 100 USER=bad_user --bootstrap-server opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093
2022-04-04 12:01:07 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 12:01:07 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced -1 messages
2022-04-04 12:01:07 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2df76807, messages=[], arguments=[--topic, my-topic-2071090599-804959110, --max-messages, 100, --group-instance-id, instance1587068327, USER=bad_user, --group-id, my-consumer-group-1928800966, --bootstrap-server, opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-05e69603-kafka-clients-765b7cd4bd-878w7', podNamespace='opa-integration-st', bootstrapServer='opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093', topicName='my-topic-2071090599-804959110', maxMessages=100, kafkaUsername='bad-user', consumerGroupName='my-consumer-group-1928800966', consumerInstanceId='instance1587068327', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4a85e9e1}
2022-04-04 12:01:07 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093:my-topic-2071090599-804959110 from pod my-cluster-05e69603-kafka-clients-765b7cd4bd-878w7
2022-04-04 12:01:07 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-05e69603-kafka-clients-765b7cd4bd-878w7 -n opa-integration-st -- /opt/kafka/consumer.sh --topic my-topic-2071090599-804959110 --max-messages 100 --group-instance-id instance1587068327 USER=bad_user --group-id my-consumer-group-1928800966 --bootstrap-server opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093
2022-04-04 12:01:33 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 12:01:33 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 0 messages
2022-04-04 12:01:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 12:01:33 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testOpaAuthorization
2022-04-04 12:01:33 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser bad-user in namespace opa-integration-st
2022-04-04 12:01:33 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaUser good-user in namespace opa-integration-st
2022-04-04 12:01:33 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-05e69603-kafka-clients in namespace opa-integration-st
2022-04-04 12:02:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 12:02:23 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.OpaIntegrationST.testOpaAuthorization-FINISHED
2022-04-04 12:02:23 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 12:02:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 12:02:23 [main] [32mINFO [m [ResourceManager:348] Delete all resources for OpaIntegrationST
2022-04-04 12:02:23 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka opa-cluster in namespace opa-integration-st
2022-04-04 12:02:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 316.62 s - in io.strimzi.systemtest.security.OpaIntegrationST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.SecurityST
2022-04-04 12:03:17 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: security-st
2022-04-04 12:03:18 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: security-st
2022-04-04 12:03:18 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: security-st
2022-04-04 12:03:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 12:03:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoRenewCaCertsTriggerByExpiredCertificate-STARTED
2022-04-04 12:03:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 12:03:18 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-56 for test case:testAutoRenewCaCertsTriggerByExpiredCertificate
2022-04-04 12:03:18 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-56
2022-04-04 12:03:18 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-56
2022-04-04 12:03:18 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-56
2022-04-04 12:03:18 [main] [32mINFO [m [SecretUtils:70] Creating secret my-cluster-0ef1f5f2-cluster-ca-cert
2022-04-04 12:03:18 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-04 12:03:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0ef1f5f2 in namespace namespace-56
2022-04-04 12:03:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-56
2022-04-04 12:03:18 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0ef1f5f2 will have desired state: Ready
2022-04-04 12:05:41 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0ef1f5f2 is in desired state: Ready
2022-04-04 12:05:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1737621113-453669237 in namespace namespace-56
2022-04-04 12:05:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-56
2022-04-04 12:05:42 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1737621113-453669237 will have desired state: Ready
2022-04-04 12:05:43 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1737621113-453669237 is in desired state: Ready
2022-04-04 12:05:43 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-38266565-1610389006 in namespace namespace-56
2022-04-04 12:05:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-56
2022-04-04 12:05:43 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-38266565-1610389006 will have desired state: Ready
2022-04-04 12:05:44 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-38266565-1610389006 is in desired state: Ready
2022-04-04 12:05:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-0ef1f5f2-kafka-clients in namespace namespace-56
2022-04-04 12:05:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-56
2022-04-04 12:05:44 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-0ef1f5f2-kafka-clients will be ready
2022-04-04 12:05:46 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-0ef1f5f2-kafka-clients is ready
2022-04-04 12:05:46 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 12:05:46 [main] [32mINFO [m [SecurityST:660] Checking produced and consumed messages to pod:my-cluster-0ef1f5f2-kafka-clients-5bdc4f676f-5wxj7
2022-04-04 12:05:46 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@732fb0cc, messages=[], arguments=[--topic, my-topic-38266565-1610389006, --max-messages, 100, --bootstrap-server, my-cluster-0ef1f5f2-kafka-bootstrap.namespace-56.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-0ef1f5f2-kafka-clients-5bdc4f676f-5wxj7', podNamespace='namespace-56', bootstrapServer='my-cluster-0ef1f5f2-kafka-bootstrap.namespace-56.svc:9092', topicName='my-topic-38266565-1610389006', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@44774e0}
2022-04-04 12:05:46 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-0ef1f5f2-kafka-bootstrap.namespace-56.svc:9092:my-topic-38266565-1610389006 from pod my-cluster-0ef1f5f2-kafka-clients-5bdc4f676f-5wxj7
2022-04-04 12:05:46 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0ef1f5f2-kafka-clients-5bdc4f676f-5wxj7 -n namespace-56 -- /opt/kafka/producer.sh --topic my-topic-38266565-1610389006 --max-messages 100 --bootstrap-server my-cluster-0ef1f5f2-kafka-bootstrap.namespace-56.svc:9092
2022-04-04 12:05:48 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 12:05:48 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 12:05:48 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@50ec43f0, messages=[], arguments=[--topic, my-topic-38266565-1610389006, --max-messages, 100, --group-instance-id, instance543564532, --group-id, my-consumer-group-1522504734, --bootstrap-server, my-cluster-0ef1f5f2-kafka-bootstrap.namespace-56.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-0ef1f5f2-kafka-clients-5bdc4f676f-5wxj7', podNamespace='namespace-56', bootstrapServer='my-cluster-0ef1f5f2-kafka-bootstrap.namespace-56.svc:9092', topicName='my-topic-38266565-1610389006', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1522504734', consumerInstanceId='instance543564532', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6f33da82}
2022-04-04 12:05:48 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-0ef1f5f2-kafka-bootstrap.namespace-56.svc:9092#my-topic-38266565-1610389006 from pod my-cluster-0ef1f5f2-kafka-clients-5bdc4f676f-5wxj7
2022-04-04 12:05:48 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0ef1f5f2-kafka-clients-5bdc4f676f-5wxj7 -n namespace-56 -- /opt/kafka/consumer.sh --topic my-topic-38266565-1610389006 --max-messages 100 --group-instance-id instance543564532 --group-id my-consumer-group-1522504734 --bootstrap-server my-cluster-0ef1f5f2-kafka-bootstrap.namespace-56.svc:9092
2022-04-04 12:05:54 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 12:05:54 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 12:05:54 [main] [32mINFO [m [SecretUtils:131] Waiting for Secret my-cluster-0ef1f5f2-cluster-ca-cert certificate change
2022-04-04 12:05:54 [main] [32mINFO [m [SecretUtils:138] Certificate in Secret my-cluster-0ef1f5f2-cluster-ca-cert has changed, was -----BEGIN CERTIFICATE-----
MIIDKjCCAhKgAwIBAgIJAJBt0u1FFTG+MA0GCSqGSIb3DQEBCwUAMCoxEzARBgNV
BAoMCnN0cmltemkuaW8xEzARBgNVBAMMCmNsdXN0ZXItY2EwHhcNMTgxMDIzMTAw
MTExWhcNMTgxMDI0MTAwMTExWjAqMRMwEQYDVQQKDApzdHJpbXppLmlvMRMwEQYD
VQQDDApjbHVzdGVyLWNhMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA
xpuYrNXYHqw3ajwd12aAeuTlAX4rVwVdPuIex6A4NL8J3d2DV+ngXgNTH//RhiF5
If5KRWSsLei5BUIrwuQutOUNCQwyACmri9+yrx6+tevligiokAUwhHxcDHZpwC3T
+2dzk/BkI++vbSuvjFmBKGQi9gfyoTnStTEQ85KVJUS170hzwDjzaEiJsKpOPx/G
+KTdkAopLucoxr4sxhYeO4mQ2PkT0QL+R8Ohs6LD6v/bqalFP+rS8vibolfxjMNm
lXQCOd8UfXy8OEOaNoNCvhnn/cT/hbEG/ARbV3hHmUh9COV+TSV5dhsbmS5h4MKw
LzP449nGQBmLSkZMu984DQIDAQABo1MwUTAdBgNVHQ4EFgQUOXubcHBZJ7vSzjpi
pfXdFSP3dsEwHwYDVR0jBBgwFoAUOXubcHBZJ7vSzjpipfXdFSP3dsEwDwYDVR0T
AQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAQEAFFPGykbzUREDMzh+33i3a8TF
UTQnPMN/SuVbpLfQdpkpLO+aVWjVvJP6qMrI7jRO5zhj4MecAf7YKpe+dyRTTz9B
Dy9BZcujHYjCKdcKBnBFQ7B1xQm9tL1bw+a3ABzSTlhLiBcCxhJEawlWy1Gh18ab
3x/Kqnz0mk/jt5+n9HwlKHuBQVIxRCsfHWwq+WvIfoxM+N//akV8/29hLUf5TlYH
F5CX4G2pA5sSdaDHQ4ekQWuqM6tfvsGLl2KOmEFEgVR4GfaWI4BsUCzlpBNcCGWv
V7klZvBxQPG7MVy0cB8yzTDtUpR0jUFUkZOSp5Pr3yWcwPWEgWkaXYfO+FWETA==
-----END CERTIFICATE-----
, is now -----BEGIN CERTIFICATE-----
MIIFLTCCAxWgAwIBAgIUBdTd5Bfzl8tEPnASBaSLPuePlcswDQYJKoZIhvcNAQEN
BQAwLTETMBEGA1UECgwKaW8uc3RyaW16aTEWMBQGA1UEAwwNY2x1c3Rlci1jYSB2
MDAeFw0yMjA0MDQxMjAzMThaFw0yMzA0MDQxMjAzMThaMC0xEzARBgNVBAoMCmlv
LnN0cmltemkxFjAUBgNVBAMMDWNsdXN0ZXItY2EgdjAwggIiMA0GCSqGSIb3DQEB
AQUAA4ICDwAwggIKAoICAQCijAs1RwTADrNFraLaM4vReXsn08fawZpM9GLbtB4j
UKR23FuKTlEXrHDC/w/lHA5PdfsD2Yq+Tpxi69AkQPSts4Tjc1IF9T4xm8716iaq
nswcjlmUYPxwLHGFKlWNtCDSec6N7Yd3N0hub/Br/E9dMGgi7G3OYRQEwyLA8ZZK
GFBAGCX5PkGYd7sdUWKR07IgdtOGYbJLzIE1o8DQRtwHK9myuTMGmPKb9u5ushlg
08fvSY59WWiGpkU5mU7JPonm5DGMrbA9vBspGoQEP9vRtAxGeZgyWgPZl69Vce/v
xGmL7Pbv7TnrAl/CRLjMkEVIz3gOl98wcKRdSp68Hshc3MAjniPl/950d/hixA4w
yQ60v47HpOwirO7XClxkdIoND63YFSZ+yqqj4EZFCCgbof4wGVFegXmvMyWm2PzA
ieSCWYzdpxYR15jXs3DEfGuLfLPvtZfLf/21GCtnn9oNKubrDe38H4qeMtv+XaWK
ES0AX96zAiu697rvhs7koy5tc/XGKxq3RmWGo+15Cm0ofh6chCiRUIfIo9d5obm5
CcHceLdaCdnwJx1EgBFdcXa7H0a/rdvIik0y/2MDn4TeWeatmHirK0RinDdJBPkP
AdG1uR29mZSK4EvZjNrr7Nhc7yUQDyf/hYZMljVJvt4blR/INvlN7XQfwRkUGSvE
LQIDAQABo0UwQzAdBgNVHQ4EFgQUSpxj8qpLZhVMdY2GVHfwrBi0/4EwEgYDVR0T
AQH/BAgwBgEB/wIBADAOBgNVHQ8BAf8EBAMCAQYwDQYJKoZIhvcNAQENBQADggIB
AFP2+K1CXdzPJ5z9tiOUZOI3DuSwDNzcndBPVZqnJHPNTTjmLRMD/IFyGQhzBEf8
F2G0taf4C2CrDMaj/G3ycOwWsg5ZJj4zEa34bpqryylJ76gOrjilkhxEeFe0YjR8
z/+lCPtwaVmTsqO18iAj9zPAhhhuPWALOnQYh4RYX/LUUMvbFmuS/z+rOnmZjYLY
rQBBRhSCqlFndJy6eVK2CzLAj/L8q8KkllxJ3/I0mP+wrhD3OnbXsv8ZUa8Q5gqF
AvCfr/QQGCHuDL9BTk0FctpKJs5JyXPGISaxZ/Z04e9kH4q0QW+LSckJk87Sba9d
uHIytK6yCzddFJsUOQT0wq4P+jwidqP7py+98GriHx4aGEyh5wSsRp/qlwWvVW9g
MiRMV5CD5bOwsURwedo5BXDmL0MrfD1fdTQnev6xoLr8qFib3kIhDJ5JEWfAxzE7
fhTpcC4eULZ5k4EPqNsXydR34dF6qZ5BNr8lM5NAUTvuNYtbx1RwpUgQ3wU7C4L1
TyJi48XQ1Fg1yHyycVwCV4Q0IH/QFhw7Bq3g1PTQJ+yhkvJI/9lVZSyW8BbDB0YP
i3XDcJ/Qt0dfWZ1FSU4s+bauaPXAM/DtkdhcYpSPpdKzKFp2QG4ninpUXhw5UXpj
i8Kl9bcBjklyfztXZVHtKGi7ViGBxNLDOeCAUzgWItTU
-----END CERTIFICATE-----

2022-04-04 12:05:54 [main] [32mINFO [m [KafkaUtils:180] Waiting for cluster stability
2022-04-04 12:06:57 [main] [32mINFO [m [KafkaUtils:208] Kafka cluster is stable after 61 polls.
2022-04-04 12:06:57 [main] [32mINFO [m [SecurityST:672] Checking produced and consumed messages to pod:my-cluster-0ef1f5f2-kafka-clients-5bdc4f676f-5wxj7
2022-04-04 12:06:57 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@597e374, messages=[], arguments=[--topic, my-topic-38266565-1610389006, --max-messages, 100, --bootstrap-server, my-cluster-0ef1f5f2-kafka-bootstrap.namespace-56.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-0ef1f5f2-kafka-clients-5bdc4f676f-5wxj7', podNamespace='namespace-56', bootstrapServer='my-cluster-0ef1f5f2-kafka-bootstrap.namespace-56.svc:9092', topicName='my-topic-38266565-1610389006', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7481c0ac}
2022-04-04 12:06:57 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-0ef1f5f2-kafka-bootstrap.namespace-56.svc:9092:my-topic-38266565-1610389006 from pod my-cluster-0ef1f5f2-kafka-clients-5bdc4f676f-5wxj7
2022-04-04 12:06:57 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0ef1f5f2-kafka-clients-5bdc4f676f-5wxj7 -n namespace-56 -- /opt/kafka/producer.sh --topic my-topic-38266565-1610389006 --max-messages 100 --bootstrap-server my-cluster-0ef1f5f2-kafka-bootstrap.namespace-56.svc:9092
2022-04-04 12:06:59 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 12:06:59 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 12:06:59 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4a630349, messages=[], arguments=[--topic, my-topic-38266565-1610389006, --max-messages, 100, --group-instance-id, instance1835276443, --group-id, my-consumer-group-1522504734, --bootstrap-server, my-cluster-0ef1f5f2-kafka-bootstrap.namespace-56.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-0ef1f5f2-kafka-clients-5bdc4f676f-5wxj7', podNamespace='namespace-56', bootstrapServer='my-cluster-0ef1f5f2-kafka-bootstrap.namespace-56.svc:9092', topicName='my-topic-38266565-1610389006', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1522504734', consumerInstanceId='instance1835276443', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@309d2156}
2022-04-04 12:06:59 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-0ef1f5f2-kafka-bootstrap.namespace-56.svc:9092#my-topic-38266565-1610389006 from pod my-cluster-0ef1f5f2-kafka-clients-5bdc4f676f-5wxj7
2022-04-04 12:06:59 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0ef1f5f2-kafka-clients-5bdc4f676f-5wxj7 -n namespace-56 -- /opt/kafka/consumer.sh --topic my-topic-38266565-1610389006 --max-messages 100 --group-instance-id instance1835276443 --group-id my-consumer-group-1522504734 --bootstrap-server my-cluster-0ef1f5f2-kafka-bootstrap.namespace-56.svc:9092
2022-04-04 12:07:05 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 12:07:05 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 12:07:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 12:07:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoRenewCaCertsTriggerByExpiredCertificate
2022-04-04 12:07:05 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-38266565-1610389006 in namespace namespace-56
2022-04-04 12:07:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0ef1f5f2 in namespace namespace-56
2022-04-04 12:07:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-56, for cruise control Kafka cluster my-cluster-0ef1f5f2
2022-04-04 12:07:05 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1737621113-453669237 in namespace namespace-56
2022-04-04 12:07:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-0ef1f5f2-kafka-clients in namespace namespace-56
2022-04-04 12:07:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 12:07:55 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-56 for test case:testAutoRenewCaCertsTriggerByExpiredCertificate
2022-04-04 12:08:01 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoRenewCaCertsTriggerByExpiredCertificate-FINISHED
2022-04-04 12:08:01 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 12:08:01 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 12:08:01 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClientsCaKeysTriggeredByAnno-STARTED
2022-04-04 12:08:01 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 12:08:01 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-57 for test case:testAutoReplaceClientsCaKeysTriggeredByAnno
2022-04-04 12:08:01 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-57
2022-04-04 12:08:01 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-57
2022-04-04 12:08:01 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-57
2022-04-04 12:08:01 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-04 12:08:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-eab42edd in namespace namespace-57
2022-04-04 12:08:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-57
2022-04-04 12:08:01 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-eab42edd will have desired state: Ready
2022-04-04 12:10:36 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-eab42edd is in desired state: Ready
2022-04-04 12:10:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1819510416-1052818427 in namespace namespace-57
2022-04-04 12:10:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-57
2022-04-04 12:10:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1819510416-1052818427 will have desired state: Ready
2022-04-04 12:10:38 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1819510416-1052818427 is in desired state: Ready
2022-04-04 12:10:38 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1001063748-1954687256 in namespace namespace-57
2022-04-04 12:10:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-57
2022-04-04 12:10:38 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1001063748-1954687256 will have desired state: Ready
2022-04-04 12:10:39 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1001063748-1954687256 is in desired state: Ready
2022-04-04 12:10:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-eab42edd-kafka-clients in namespace namespace-57
2022-04-04 12:10:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-57
2022-04-04 12:10:39 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-eab42edd-kafka-clients will be ready
2022-04-04 12:10:41 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-eab42edd-kafka-clients is ready
2022-04-04 12:10:41 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 12:10:41 [main] [32mINFO [m [SecurityST:453] Checking produced and consumed messages to pod:my-cluster-eab42edd-kafka-clients-58744467bf-cn7h6
2022-04-04 12:10:41 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@7af8c65a, messages=[], arguments=[--topic, my-topic-1001063748-1954687256, --max-messages, 100, --bootstrap-server, my-cluster-eab42edd-kafka-bootstrap.namespace-57.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-eab42edd-kafka-clients-58744467bf-cn7h6', podNamespace='namespace-57', bootstrapServer='my-cluster-eab42edd-kafka-bootstrap.namespace-57.svc:9092', topicName='my-topic-1001063748-1954687256', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@28d3e142}
2022-04-04 12:10:41 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-eab42edd-kafka-bootstrap.namespace-57.svc:9092:my-topic-1001063748-1954687256 from pod my-cluster-eab42edd-kafka-clients-58744467bf-cn7h6
2022-04-04 12:10:41 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-eab42edd-kafka-clients-58744467bf-cn7h6 -n namespace-57 -- /opt/kafka/producer.sh --topic my-topic-1001063748-1954687256 --max-messages 100 --bootstrap-server my-cluster-eab42edd-kafka-bootstrap.namespace-57.svc:9092
2022-04-04 12:10:43 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 12:10:43 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 12:10:43 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@d7ac2f7, messages=[], arguments=[--topic, my-topic-1001063748-1954687256, --max-messages, 100, --group-instance-id, instance1286752209, --group-id, my-consumer-group-719180486, --bootstrap-server, my-cluster-eab42edd-kafka-bootstrap.namespace-57.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-eab42edd-kafka-clients-58744467bf-cn7h6', podNamespace='namespace-57', bootstrapServer='my-cluster-eab42edd-kafka-bootstrap.namespace-57.svc:9092', topicName='my-topic-1001063748-1954687256', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-719180486', consumerInstanceId='instance1286752209', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3a94fd16}
2022-04-04 12:10:43 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-eab42edd-kafka-bootstrap.namespace-57.svc:9092#my-topic-1001063748-1954687256 from pod my-cluster-eab42edd-kafka-clients-58744467bf-cn7h6
2022-04-04 12:10:43 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-eab42edd-kafka-clients-58744467bf-cn7h6 -n namespace-57 -- /opt/kafka/consumer.sh --topic my-topic-1001063748-1954687256 --max-messages 100 --group-instance-id instance1286752209 --group-id my-consumer-group-719180486 --bootstrap-server my-cluster-eab42edd-kafka-bootstrap.namespace-57.svc:9092
2022-04-04 12:10:49 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 12:10:49 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 12:10:49 [main] [32mINFO [m [SecurityST:467] Triggering CA cert renewal by adding the annotation
2022-04-04 12:10:49 [main] [32mINFO [m [SecurityST:479] Patching secret my-cluster-eab42edd-clients-ca with strimzi.io/force-replace
2022-04-04 12:10:49 [main] [32mINFO [m [SecurityST:489] Wait for kafka to rolling restart (1)...
2022-04-04 12:10:49 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-eab42edd-kafka rolling update
2022-04-04 12:12:14 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-eab42edd-kafka has been successfully rolled
2022-04-04 12:12:14 [main] [32mINFO [m [SecurityST:510] Wait for kafka to rolling restart (2)...
2022-04-04 12:12:14 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-eab42edd-kafka rolling update
2022-04-04 12:13:59 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-eab42edd-kafka has been successfully rolled
2022-04-04 12:13:59 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-eab42edd-kafka to be ready
2022-04-04 12:14:21 [main] [32mINFO [m [SecurityST:525] Checking the certificates have been replaced
2022-04-04 12:14:21 [main] [32mINFO [m [SecurityST:536] Checking consumed messages to pod:my-cluster-eab42edd-kafka-clients-58744467bf-cn7h6
2022-04-04 12:14:21 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4a7449fa, messages=[], arguments=[--topic, my-topic-1001063748-1954687256, --max-messages, 100, --group-instance-id, instance1230153331, --group-id, my-consumer-group-574074663, --bootstrap-server, my-cluster-eab42edd-kafka-bootstrap.namespace-57.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-eab42edd-kafka-clients-58744467bf-cn7h6', podNamespace='namespace-57', bootstrapServer='my-cluster-eab42edd-kafka-bootstrap.namespace-57.svc:9092', topicName='my-topic-1001063748-1954687256', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-574074663', consumerInstanceId='instance1230153331', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2a2ff592}
2022-04-04 12:14:21 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-eab42edd-kafka-bootstrap.namespace-57.svc:9092#my-topic-1001063748-1954687256 from pod my-cluster-eab42edd-kafka-clients-58744467bf-cn7h6
2022-04-04 12:14:21 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-eab42edd-kafka-clients-58744467bf-cn7h6 -n namespace-57 -- /opt/kafka/consumer.sh --topic my-topic-1001063748-1954687256 --max-messages 100 --group-instance-id instance1230153331 --group-id my-consumer-group-574074663 --bootstrap-server my-cluster-eab42edd-kafka-bootstrap.namespace-57.svc:9092
2022-04-04 12:14:30 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 12:14:30 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 12:14:30 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-89444863-2137581245 in namespace namespace-57
2022-04-04 12:14:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-57
2022-04-04 12:14:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-89444863-2137581245 will have desired state: Ready
2022-04-04 12:14:31 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-89444863-2137581245 is in desired state: Ready
2022-04-04 12:14:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-eab42edd-kafka-clients-tls in namespace namespace-57
2022-04-04 12:14:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-57
2022-04-04 12:14:31 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-eab42edd-kafka-clients-tls will be ready
2022-04-04 12:14:34 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-eab42edd-kafka-clients-tls is ready
2022-04-04 12:14:34 [main] [32mINFO [m [SecurityST:561] Checking consumed messages to pod:my-cluster-eab42edd-kafka-clients-tls-5bbccb8469-x8mwq
2022-04-04 12:14:34 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@27ef23de, messages=[], arguments=[--topic, my-topic-1001063748-1954687256, --max-messages, 100, --group-instance-id, instance760281265, --group-id, my-consumer-group-1674182752, --bootstrap-server, my-cluster-eab42edd-kafka-bootstrap.namespace-57.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-eab42edd-kafka-clients-tls-5bbccb8469-x8mwq', podNamespace='namespace-57', bootstrapServer='my-cluster-eab42edd-kafka-bootstrap.namespace-57.svc:9092', topicName='my-topic-1001063748-1954687256', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1674182752', consumerInstanceId='instance760281265', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7239cb6e}
2022-04-04 12:14:34 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-eab42edd-kafka-bootstrap.namespace-57.svc:9092#my-topic-1001063748-1954687256 from pod my-cluster-eab42edd-kafka-clients-tls-5bbccb8469-x8mwq
2022-04-04 12:14:34 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-eab42edd-kafka-clients-tls-5bbccb8469-x8mwq -n namespace-57 -- /opt/kafka/consumer.sh --topic my-topic-1001063748-1954687256 --max-messages 100 --group-instance-id instance760281265 --group-id my-consumer-group-1674182752 --bootstrap-server my-cluster-eab42edd-kafka-bootstrap.namespace-57.svc:9092
2022-04-04 12:14:44 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 12:14:44 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 12:14:44 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 12:14:44 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoReplaceClientsCaKeysTriggeredByAnno
2022-04-04 12:14:44 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-eab42edd-kafka-clients in namespace namespace-57
2022-04-04 12:14:44 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-eab42edd in namespace namespace-57
2022-04-04 12:14:44 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-57, for cruise control Kafka cluster my-cluster-eab42edd
2022-04-04 12:14:44 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1819510416-1052818427 in namespace namespace-57
2022-04-04 12:14:44 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1001063748-1954687256 in namespace namespace-57
2022-04-04 12:14:44 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-89444863-2137581245 in namespace namespace-57
2022-04-04 12:14:44 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-eab42edd-kafka-clients-tls in namespace namespace-57
2022-04-04 12:15:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 12:15:44 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-57 for test case:testAutoReplaceClientsCaKeysTriggeredByAnno
2022-04-04 12:15:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClientsCaKeysTriggeredByAnno-FINISHED
2022-04-04 12:15:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 12:15:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 12:15:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testTlsHostnameVerificationWithMirrorMaker-STARTED
2022-04-04 12:15:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 12:15:51 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-58 for test case:testTlsHostnameVerificationWithMirrorMaker
2022-04-04 12:15:51 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-58
2022-04-04 12:15:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-58
2022-04-04 12:15:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-58
2022-04-04 12:15:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-962915f1-source in namespace namespace-58
2022-04-04 12:15:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-58
2022-04-04 12:15:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-962915f1-source will have desired state: Ready
2022-04-04 12:17:11 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-962915f1-source is in desired state: Ready
2022-04-04 12:17:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-962915f1-target in namespace namespace-58
2022-04-04 12:17:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-58
2022-04-04 12:17:11 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-962915f1-target will have desired state: Ready
2022-04-04 12:18:25 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-962915f1-target is in desired state: Ready
2022-04-04 12:18:25 [main] [32mINFO [m [SecurityST:888] Getting IP of the source bootstrap service for consumer
2022-04-04 12:18:25 [main] [32mINFO [m [SecurityST:891] Getting IP of the target bootstrap service for producer
2022-04-04 12:18:25 [main] [32mINFO [m [SecurityST:894] KafkaMirrorMaker without config ssl.endpoint.identification.algorithm will not connect to consumer with address 10.106.51.39:9093
2022-04-04 12:18:25 [main] [32mINFO [m [SecurityST:895] KafkaMirrorMaker without config ssl.endpoint.identification.algorithm will not connect to producer with address 10.105.181.74:9093
2022-04-04 12:18:25 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-962915f1 in namespace namespace-58
2022-04-04 12:18:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-58
2022-04-04 12:18:25 [main] [32mINFO [m [PodUtils:245] Wait until Pod my-cluster-962915f1-mirror-maker is present
2022-04-04 12:18:26 [main] [32mINFO [m [PodUtils:249] Pod my-cluster-962915f1-mirror-maker is present
2022-04-04 12:18:26 [main] [32mINFO [m [PodUtils:236] Wait until Pod my-cluster-962915f1-mirror-maker-6c8bfd49cb-mjr2s is in CrashLoopBackOff state
2022-04-04 12:18:47 [main] [32mINFO [m [PodUtils:241] Pod my-cluster-962915f1-mirror-maker-6c8bfd49cb-mjr2s is in CrashLoopBackOff state
2022-04-04 12:18:47 [main] [32mINFO [m [SecurityST:930] KafkaMirrorMaker with config ssl.endpoint.identification.algorithm will connect to consumer with address 10.106.51.39:9093
2022-04-04 12:18:47 [main] [32mINFO [m [SecurityST:931] KafkaMirrorMaker with config ssl.endpoint.identification.algorithm will connect to producer with address 10.105.181.74:9093
2022-04-04 12:18:47 [main] [32mINFO [m [SecurityST:933] Adding configuration ssl.endpoint.identification.algorithm to the mirror maker...
2022-04-04 12:18:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-962915f1 will have desired state: Ready
2022-04-04 12:24:38 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-962915f1 is in desired state: Ready
2022-04-04 12:24:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 12:24:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTlsHostnameVerificationWithMirrorMaker
2022-04-04 12:24:38 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-962915f1-target in namespace namespace-58
2022-04-04 12:24:38 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-962915f1-source in namespace namespace-58
2022-04-04 12:24:38 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-962915f1 in namespace namespace-58
2022-04-04 12:24:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 12:24:58 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-58 for test case:testTlsHostnameVerificationWithMirrorMaker
2022-04-04 12:25:08 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testTlsHostnameVerificationWithMirrorMaker-FINISHED
2022-04-04 12:25:08 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 12:25:08 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 12:25:08 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoRenewClusterCaCertsTriggeredByAnno-STARTED
2022-04-04 12:25:08 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 12:25:08 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-59 for test case:testAutoRenewClusterCaCertsTriggeredByAnno
2022-04-04 12:25:08 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-59
2022-04-04 12:25:09 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-59
2022-04-04 12:25:09 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-59
2022-04-04 12:25:09 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-04 12:25:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e8840f5f in namespace namespace-59
2022-04-04 12:25:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-59
2022-04-04 12:25:09 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e8840f5f will have desired state: Ready
2022-04-04 12:27:32 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e8840f5f is in desired state: Ready
2022-04-04 12:27:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-278929185-1458360672 in namespace namespace-59
2022-04-04 12:27:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-59
2022-04-04 12:27:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-278929185-1458360672 will have desired state: Ready
2022-04-04 12:27:33 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-278929185-1458360672 is in desired state: Ready
2022-04-04 12:27:33 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-698784298-1350232266 in namespace namespace-59
2022-04-04 12:27:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-59
2022-04-04 12:27:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-698784298-1350232266 will have desired state: Ready
2022-04-04 12:27:34 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-698784298-1350232266 is in desired state: Ready
2022-04-04 12:27:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-e8840f5f-kafka-clients in namespace namespace-59
2022-04-04 12:27:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-59
2022-04-04 12:27:34 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-e8840f5f-kafka-clients will be ready
2022-04-04 12:27:35 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-e8840f5f-kafka-clients is ready
2022-04-04 12:27:35 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 12:27:35 [main] [32mINFO [m [SecurityST:260] Checking produced and consumed messages to pod:my-cluster-e8840f5f-kafka-clients-847fb6c6f-v7rf8
2022-04-04 12:27:35 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@18a60105, messages=[], arguments=[--topic, my-topic-698784298-1350232266, --max-messages, 100, --bootstrap-server, my-cluster-e8840f5f-kafka-bootstrap.namespace-59.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-e8840f5f-kafka-clients-847fb6c6f-v7rf8', podNamespace='namespace-59', bootstrapServer='my-cluster-e8840f5f-kafka-bootstrap.namespace-59.svc:9092', topicName='my-topic-698784298-1350232266', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@133d23d8}
2022-04-04 12:27:35 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-e8840f5f-kafka-bootstrap.namespace-59.svc:9092:my-topic-698784298-1350232266 from pod my-cluster-e8840f5f-kafka-clients-847fb6c6f-v7rf8
2022-04-04 12:27:35 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-e8840f5f-kafka-clients-847fb6c6f-v7rf8 -n namespace-59 -- /opt/kafka/producer.sh --topic my-topic-698784298-1350232266 --max-messages 100 --bootstrap-server my-cluster-e8840f5f-kafka-bootstrap.namespace-59.svc:9092
2022-04-04 12:27:38 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 12:27:38 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 12:27:38 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@25225a98, messages=[], arguments=[--topic, my-topic-698784298-1350232266, --max-messages, 100, --group-instance-id, instance1217326286, --group-id, my-consumer-group-1586860728, --bootstrap-server, my-cluster-e8840f5f-kafka-bootstrap.namespace-59.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-e8840f5f-kafka-clients-847fb6c6f-v7rf8', podNamespace='namespace-59', bootstrapServer='my-cluster-e8840f5f-kafka-bootstrap.namespace-59.svc:9092', topicName='my-topic-698784298-1350232266', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1586860728', consumerInstanceId='instance1217326286', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5ffb815c}
2022-04-04 12:27:38 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-e8840f5f-kafka-bootstrap.namespace-59.svc:9092#my-topic-698784298-1350232266 from pod my-cluster-e8840f5f-kafka-clients-847fb6c6f-v7rf8
2022-04-04 12:27:38 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-e8840f5f-kafka-clients-847fb6c6f-v7rf8 -n namespace-59 -- /opt/kafka/consumer.sh --topic my-topic-698784298-1350232266 --max-messages 100 --group-instance-id instance1217326286 --group-id my-consumer-group-1586860728 --bootstrap-server my-cluster-e8840f5f-kafka-bootstrap.namespace-59.svc:9092
2022-04-04 12:27:43 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 12:27:43 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 12:27:43 [main] [32mINFO [m [SecurityST:274] Triggering CA cert renewal by adding the annotation
2022-04-04 12:27:43 [main] [32mINFO [m [SecurityST:286] Patching secret my-cluster-e8840f5f-cluster-ca-cert with strimzi.io/force-renew
2022-04-04 12:27:43 [main] [32mINFO [m [SecurityST:291] Wait for zk to rolling restart ...
2022-04-04 12:27:43 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-e8840f5f-zookeeper rolling update
2022-04-04 12:29:08 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-e8840f5f-zookeeper has been successfully rolled
2022-04-04 12:29:08 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-e8840f5f-zookeeper to be ready
2022-04-04 12:29:34 [main] [32mINFO [m [SecurityST:295] Wait for kafka to rolling restart ...
2022-04-04 12:29:34 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-e8840f5f-kafka rolling update
2022-04-04 12:30:39 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-e8840f5f-kafka has been successfully rolled
2022-04-04 12:30:39 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-e8840f5f-kafka to be ready
2022-04-04 12:31:14 [main] [32mINFO [m [SecurityST:299] Wait for EO to rolling restart ...
2022-04-04 12:31:14 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-e8840f5f-entity-operator rolling update
2022-04-04 12:31:19 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-e8840f5f-entity-operator will be ready
2022-04-04 12:31:58 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-e8840f5f-entity-operator is ready
2022-04-04 12:32:08 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-e8840f5f-entity-operator rolling update finished
2022-04-04 12:32:08 [main] [32mINFO [m [SecurityST:303] Wait for CC and KE to rolling restart ...
2022-04-04 12:32:08 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-e8840f5f-kafka-exporter rolling update
2022-04-04 12:32:48 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-e8840f5f-kafka-exporter will be ready
2022-04-04 12:32:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-e8840f5f-kafka-exporter is ready
2022-04-04 12:32:58 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-e8840f5f-kafka-exporter rolling update finished
2022-04-04 12:32:58 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-e8840f5f-cruise-control rolling update
2022-04-04 12:32:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-e8840f5f-cruise-control will be ready
2022-04-04 12:32:58 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-e8840f5f-cruise-control is ready
2022-04-04 12:33:08 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-e8840f5f-cruise-control rolling update finished
2022-04-04 12:33:08 [main] [32mINFO [m [SecurityST:308] Checking the certificates have been replaced
2022-04-04 12:33:08 [main] [32mINFO [m [SecurityST:322] Checking consumed messages to pod:my-cluster-e8840f5f-kafka-clients-847fb6c6f-v7rf8
2022-04-04 12:33:08 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@66c1db11, messages=[], arguments=[--topic, my-topic-698784298-1350232266, --max-messages, 100, --group-instance-id, instance153731262, --group-id, my-consumer-group-76105181, --bootstrap-server, my-cluster-e8840f5f-kafka-bootstrap.namespace-59.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-e8840f5f-kafka-clients-847fb6c6f-v7rf8', podNamespace='namespace-59', bootstrapServer='my-cluster-e8840f5f-kafka-bootstrap.namespace-59.svc:9092', topicName='my-topic-698784298-1350232266', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-76105181', consumerInstanceId='instance153731262', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@253a5359}
2022-04-04 12:33:08 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-e8840f5f-kafka-bootstrap.namespace-59.svc:9092#my-topic-698784298-1350232266 from pod my-cluster-e8840f5f-kafka-clients-847fb6c6f-v7rf8
2022-04-04 12:33:08 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-e8840f5f-kafka-clients-847fb6c6f-v7rf8 -n namespace-59 -- /opt/kafka/consumer.sh --topic my-topic-698784298-1350232266 --max-messages 100 --group-instance-id instance153731262 --group-id my-consumer-group-76105181 --bootstrap-server my-cluster-e8840f5f-kafka-bootstrap.namespace-59.svc:9092
2022-04-04 12:33:14 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 12:33:14 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 12:33:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser bob-my-cluster-e8840f5f in namespace namespace-59
2022-04-04 12:33:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-59
2022-04-04 12:33:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: bob-my-cluster-e8840f5f will have desired state: Ready
2022-04-04 12:33:15 [main] [32mINFO [m [ResourceManager:444] KafkaUser: bob-my-cluster-e8840f5f is in desired state: Ready
2022-04-04 12:33:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-e8840f5f-kafka-clients-tls in namespace namespace-59
2022-04-04 12:33:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-59
2022-04-04 12:33:15 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-e8840f5f-kafka-clients-tls will be ready
2022-04-04 12:33:17 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-e8840f5f-kafka-clients-tls is ready
2022-04-04 12:33:17 [main] [32mINFO [m [SecurityST:346] Checking consumed messages to pod:my-cluster-e8840f5f-kafka-clients-tls-57668f4788-r9mkv
2022-04-04 12:33:17 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@14533c3, messages=[], arguments=[--topic, my-topic-698784298-1350232266, --max-messages, 100, --group-instance-id, instance1226807629, USER=bob_my_cluster_e8840f5f, --group-id, my-consumer-group-2069661721, --bootstrap-server, my-cluster-e8840f5f-kafka-bootstrap.namespace-59.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-e8840f5f-kafka-clients-tls-57668f4788-r9mkv', podNamespace='namespace-59', bootstrapServer='my-cluster-e8840f5f-kafka-bootstrap.namespace-59.svc:9093', topicName='my-topic-698784298-1350232266', maxMessages=100, kafkaUsername='bob-my-cluster-e8840f5f', consumerGroupName='my-consumer-group-2069661721', consumerInstanceId='instance1226807629', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@769216d3}
2022-04-04 12:33:17 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-e8840f5f-kafka-bootstrap.namespace-59.svc:9093#my-topic-698784298-1350232266 from pod my-cluster-e8840f5f-kafka-clients-tls-57668f4788-r9mkv
2022-04-04 12:33:17 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-e8840f5f-kafka-clients-tls-57668f4788-r9mkv -n namespace-59 -- /opt/kafka/consumer.sh --topic my-topic-698784298-1350232266 --max-messages 100 --group-instance-id instance1226807629 USER=bob_my_cluster_e8840f5f --group-id my-consumer-group-2069661721 --bootstrap-server my-cluster-e8840f5f-kafka-bootstrap.namespace-59.svc:9093
2022-04-04 12:33:24 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 12:33:24 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 12:33:24 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 12:33:24 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoRenewClusterCaCertsTriggeredByAnno
2022-04-04 12:33:24 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-e8840f5f-kafka-clients in namespace namespace-59
2022-04-04 12:33:24 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e8840f5f in namespace namespace-59
2022-04-04 12:33:24 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-59, for cruise control Kafka cluster my-cluster-e8840f5f
2022-04-04 12:33:24 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-698784298-1350232266 in namespace namespace-59
2022-04-04 12:33:24 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-e8840f5f-kafka-clients-tls in namespace namespace-59
2022-04-04 12:33:24 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser bob-my-cluster-e8840f5f in namespace namespace-59
2022-04-04 12:33:24 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-278929185-1458360672 in namespace namespace-59
2022-04-04 12:34:24 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 12:34:24 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-59 for test case:testAutoRenewClusterCaCertsTriggeredByAnno
2022-04-04 12:34:30 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoRenewClusterCaCertsTriggeredByAnno-FINISHED
2022-04-04 12:34:30 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 12:34:30 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 12:34:30 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCaRenewalBreakInMiddle-STARTED
2022-04-04 12:34:30 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 12:34:30 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-60 for test case:testCaRenewalBreakInMiddle
2022-04-04 12:34:30 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-60
2022-04-04 12:34:30 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-60
2022-04-04 12:34:30 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-60
2022-04-04 12:34:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d36063a2 in namespace namespace-60
2022-04-04 12:34:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-60
2022-04-04 12:34:30 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d36063a2 will have desired state: Ready
2022-04-04 12:35:55 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d36063a2 is in desired state: Ready
2022-04-04 12:35:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-176160346-1417612999 in namespace namespace-60
2022-04-04 12:35:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-60
2022-04-04 12:35:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-176160346-1417612999 will have desired state: Ready
2022-04-04 12:35:56 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-176160346-1417612999 is in desired state: Ready
2022-04-04 12:35:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-636540722-1838665560 in namespace namespace-60
2022-04-04 12:35:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-60
2022-04-04 12:35:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-636540722-1838665560 will have desired state: Ready
2022-04-04 12:35:57 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-636540722-1838665560 is in desired state: Ready
2022-04-04 12:35:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-d36063a2-kafka-clients in namespace namespace-60
2022-04-04 12:35:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-60
2022-04-04 12:35:57 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d36063a2-kafka-clients will be ready
2022-04-04 12:35:59 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d36063a2-kafka-clients is ready
2022-04-04 12:35:59 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 12:35:59 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@58067dcc, messages=[], arguments=[--topic, my-topic-636540722-1838665560, --max-messages, 100, USER=my_user_176160346_1417612999, --bootstrap-server, my-cluster-d36063a2-kafka-bootstrap.namespace-60.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-d36063a2-kafka-clients-688fb98f5d-4jkkh', podNamespace='namespace-60', bootstrapServer='my-cluster-d36063a2-kafka-bootstrap.namespace-60.svc:9093', topicName='my-topic-636540722-1838665560', maxMessages=100, kafkaUsername='my-user-176160346-1417612999', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2adf3235}
2022-04-04 12:35:59 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-d36063a2-kafka-bootstrap.namespace-60.svc:9093:my-topic-636540722-1838665560 from pod my-cluster-d36063a2-kafka-clients-688fb98f5d-4jkkh
2022-04-04 12:35:59 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d36063a2-kafka-clients-688fb98f5d-4jkkh -n namespace-60 -- /opt/kafka/producer.sh --topic my-topic-636540722-1838665560 --max-messages 100 USER=my_user_176160346_1417612999 --bootstrap-server my-cluster-d36063a2-kafka-bootstrap.namespace-60.svc:9093
2022-04-04 12:36:02 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 12:36:02 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 12:36:02 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@bd9f64, messages=[], arguments=[--topic, my-topic-636540722-1838665560, --max-messages, 100, --group-instance-id, instance2014189811, USER=my_user_176160346_1417612999, --group-id, my-consumer-group-61369147, --bootstrap-server, my-cluster-d36063a2-kafka-bootstrap.namespace-60.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d36063a2-kafka-clients-688fb98f5d-4jkkh', podNamespace='namespace-60', bootstrapServer='my-cluster-d36063a2-kafka-bootstrap.namespace-60.svc:9093', topicName='my-topic-636540722-1838665560', maxMessages=100, kafkaUsername='my-user-176160346-1417612999', consumerGroupName='my-consumer-group-61369147', consumerInstanceId='instance2014189811', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@53a051bf}
2022-04-04 12:36:02 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-d36063a2-kafka-bootstrap.namespace-60.svc:9093:my-topic-636540722-1838665560 from pod my-cluster-d36063a2-kafka-clients-688fb98f5d-4jkkh
2022-04-04 12:36:02 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d36063a2-kafka-clients-688fb98f5d-4jkkh -n namespace-60 -- /opt/kafka/consumer.sh --topic my-topic-636540722-1838665560 --max-messages 100 --group-instance-id instance2014189811 USER=my_user_176160346_1417612999 --group-id my-consumer-group-61369147 --bootstrap-server my-cluster-d36063a2-kafka-bootstrap.namespace-60.svc:9093
2022-04-04 12:36:09 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 12:36:09 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 12:36:09 [main] [32mINFO [m [SecretUtils:70] Creating secret my-cluster-d36063a2-cluster-ca-cert
2022-04-04 12:36:09 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-d36063a2-zookeeper are in desired state
2022-04-04 12:36:10 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-d36063a2-zookeeper are in desired state
2022-04-04 12:36:11 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-d36063a2-zookeeper are in desired state
2022-04-04 12:36:12 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-d36063a2-zookeeper are in desired state
2022-04-04 12:36:13 [main] [32mINFO [m [SecurityST:1221] Pod in 'Pending' state: my-cluster-d36063a2-zookeeper-0
2022-04-04 12:36:13 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4d00d0dc, messages=[], arguments=[--topic, my-topic-636540722-1838665560, --max-messages, 100, --group-instance-id, instance299730568, USER=my_user_176160346_1417612999, --group-id, my-consumer-group-1976235178, --bootstrap-server, my-cluster-d36063a2-kafka-bootstrap.namespace-60.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d36063a2-kafka-clients-688fb98f5d-4jkkh', podNamespace='namespace-60', bootstrapServer='my-cluster-d36063a2-kafka-bootstrap.namespace-60.svc:9093', topicName='my-topic-636540722-1838665560', maxMessages=100, kafkaUsername='my-user-176160346-1417612999', consumerGroupName='my-consumer-group-1976235178', consumerInstanceId='instance299730568', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1503a120}
2022-04-04 12:36:13 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-d36063a2-kafka-bootstrap.namespace-60.svc:9093:my-topic-636540722-1838665560 from pod my-cluster-d36063a2-kafka-clients-688fb98f5d-4jkkh
2022-04-04 12:36:13 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d36063a2-kafka-clients-688fb98f5d-4jkkh -n namespace-60 -- /opt/kafka/consumer.sh --topic my-topic-636540722-1838665560 --max-messages 100 --group-instance-id instance299730568 USER=my_user_176160346_1417612999 --group-id my-consumer-group-1976235178 --bootstrap-server my-cluster-d36063a2-kafka-bootstrap.namespace-60.svc:9093
2022-04-04 12:36:20 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 12:36:20 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 12:36:20 [main] [32mINFO [m [SecretUtils:131] Waiting for Secret my-cluster-d36063a2-cluster-ca-cert certificate change
2022-04-04 12:36:20 [main] [32mINFO [m [SecretUtils:138] Certificate in Secret my-cluster-d36063a2-cluster-ca-cert has changed, was -----BEGIN CERTIFICATE-----
MIIDKjCCAhKgAwIBAgIJAJBt0u1FFTG+MA0GCSqGSIb3DQEBCwUAMCoxEzARBgNV
BAoMCnN0cmltemkuaW8xEzARBgNVBAMMCmNsdXN0ZXItY2EwHhcNMTgxMDIzMTAw
MTExWhcNMTgxMDI0MTAwMTExWjAqMRMwEQYDVQQKDApzdHJpbXppLmlvMRMwEQYD
VQQDDApjbHVzdGVyLWNhMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA
xpuYrNXYHqw3ajwd12aAeuTlAX4rVwVdPuIex6A4NL8J3d2DV+ngXgNTH//RhiF5
If5KRWSsLei5BUIrwuQutOUNCQwyACmri9+yrx6+tevligiokAUwhHxcDHZpwC3T
+2dzk/BkI++vbSuvjFmBKGQi9gfyoTnStTEQ85KVJUS170hzwDjzaEiJsKpOPx/G
+KTdkAopLucoxr4sxhYeO4mQ2PkT0QL+R8Ohs6LD6v/bqalFP+rS8vibolfxjMNm
lXQCOd8UfXy8OEOaNoNCvhnn/cT/hbEG/ARbV3hHmUh9COV+TSV5dhsbmS5h4MKw
LzP449nGQBmLSkZMu984DQIDAQABo1MwUTAdBgNVHQ4EFgQUOXubcHBZJ7vSzjpi
pfXdFSP3dsEwHwYDVR0jBBgwFoAUOXubcHBZJ7vSzjpipfXdFSP3dsEwDwYDVR0T
AQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAQEAFFPGykbzUREDMzh+33i3a8TF
UTQnPMN/SuVbpLfQdpkpLO+aVWjVvJP6qMrI7jRO5zhj4MecAf7YKpe+dyRTTz9B
Dy9BZcujHYjCKdcKBnBFQ7B1xQm9tL1bw+a3ABzSTlhLiBcCxhJEawlWy1Gh18ab
3x/Kqnz0mk/jt5+n9HwlKHuBQVIxRCsfHWwq+WvIfoxM+N//akV8/29hLUf5TlYH
F5CX4G2pA5sSdaDHQ4ekQWuqM6tfvsGLl2KOmEFEgVR4GfaWI4BsUCzlpBNcCGWv
V7klZvBxQPG7MVy0cB8yzTDtUpR0jUFUkZOSp5Pr3yWcwPWEgWkaXYfO+FWETA==
-----END CERTIFICATE-----
, is now -----BEGIN CERTIFICATE-----
MIIFLTCCAxWgAwIBAgIUKtY4a69GJrZzUlid418pVIykzNMwDQYJKoZIhvcNAQEN
BQAwLTETMBEGA1UECgwKaW8uc3RyaW16aTEWMBQGA1UEAwwNY2x1c3Rlci1jYSB2
MDAeFw0yMjA0MDQxMjM2MDlaFw0yMjA0MTExMjM2MDlaMC0xEzARBgNVBAoMCmlv
LnN0cmltemkxFjAUBgNVBAMMDWNsdXN0ZXItY2EgdjAwggIiMA0GCSqGSIb3DQEB
AQUAA4ICDwAwggIKAoICAQDQ/W6uhmNf97QEyWOkP1ROGRNlUDUm6eF/etmzh90/
Razl/7nhJQ6IOwa6JK+GhRdxuulXls/okrgZj9g3xGEXQ2W+4MuT+KyCaBcDoYoh
zVQY9xl5HyXVphJb+Q2VDQTIz+EmZs2zdlGR3l+OwNcfrwvGClEeGRdwUUnKgvQA
2NWyEQCFE/+a4UE5M3qP1taCRiS1Y4ffevg1l3xFrwR3weNHLP9+Qd3Aywo3aCqC
xNV1oubPusIRpEO+zmabrVwtUC/t2PsU/5tOYtloug8q4j0bjyXmW59+vLPQ3305
VaZAsRql1MvYNNR57lvHge27fJ8vXWV6NgxIknFlSV9c7SuykfQrMT0KC9DDJrVi
JBo0Lv8HHV2HiEMpzkD8QV6HSnBLPpVpfR9nHmlohw4Zdu+fN8K2TBGtAIdGs5yy
amx73g9k5l6TjIQ8wdf++SfZeUfurkattPfLcAMooLH7vCIiigcVOTdi+FxAuj4M
phs9OwonP19ZVT/kG0lGILUejQlb5FZRwA0Y4cGusTVWu4U4fL4LsM1XQIMI159j
GWVkPG8vx8csw5VyIba0eIgZdlrJK1Ynwj3cA9O44HaxmBAQtS+2EpV9lOjRM/1G
JxJ0E0UCmv9JeXB7bP2gqpz/sjW2pVmH9NAJ2YLSJ+3Pd5XJYERNWcCI+ZSu8Fob
IQIDAQABo0UwQzAdBgNVHQ4EFgQULXlw3GLTQ0xz9OzW91LJoTQngo8wEgYDVR0T
AQH/BAgwBgEB/wIBADAOBgNVHQ8BAf8EBAMCAQYwDQYJKoZIhvcNAQENBQADggIB
AIKRiRLueG0ia0uxexuvYTHD4+g9a3x0DkWtIqgiO0cucnRNQgdsdv2smThFCLs/
B0IbNVjKeAkH/FfkqupHJ/z7Vj2ccIgX1JWJj9QXv78MfekwfpTdHWM7lDjEm3KM
jDtkUvoEHhM9ezmf7KXScNjousrHfexg8TU1Pb3T7BjEeB3rL12vS/Dy97aesIji
dZ9T44mNYG+1ehS+lqId+UFeJ243mY+DQXbIvDzJ3/uxG8kopkzKrGhX8wH3cKsI
dWK63oJJpju69wXwjVXxHTn46FaODM5fXHFIdUCiyNUDzAAYGIEEz7s39hZicE1t
WCpuuWJ9J8FOBDfazd84fsgP5PeCzOkrdS+rlQexiVh0z4mPcPWY2/o+DVhmhAgR
hIBNPzFhQW+nppD2TuSZrqZA4hZsiqw+xC0mPI8qlP5TqNjqqoNFeVMjbgqxus9q
JLrgBMWQNMU+cdK+WRKs2Kje8jQeTE7DPqiCzDwiBGPtPFblnsVmR5oGrSMHiJTp
g2COzCIrkWaVYGQhyi67qwEqXj0WT0caY1dNXqDDAOLNt5d7hkXOqd6zqX8dfbjj
Uh0BgwroPGiPWEcDg7tzdQynN78XYoCLBQY4qyq+N6G5Cwi/Nfx64Yc5hMw+JEkA
545FRZ5o9ZVietdjzX2GUWDMM2zt5Q1RQSVxmdwOlIxW
-----END CERTIFICATE-----

2022-04-04 12:36:20 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-d36063a2-zookeeper rolling update
2022-04-04 12:42:45 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-d36063a2-zookeeper has been successfully rolled
2022-04-04 12:42:45 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-d36063a2-zookeeper to be ready
2022-04-04 12:43:18 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-d36063a2-kafka rolling update
2022-04-04 12:44:29 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-d36063a2-kafka has been successfully rolled
2022-04-04 12:44:29 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-d36063a2-kafka to be ready
2022-04-04 12:44:53 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-d36063a2-entity-operator rolling update
2022-04-04 12:44:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d36063a2-entity-operator will be ready
2022-04-04 12:45:29 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d36063a2-entity-operator is ready
2022-04-04 12:45:39 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-d36063a2-entity-operator rolling update finished
2022-04-04 12:45:39 [main] [32mINFO [m [SecurityST:1252] Checking produced and consumed messages to pod:my-cluster-d36063a2-kafka-clients-688fb98f5d-4jkkh
2022-04-04 12:45:39 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2b810995, messages=[], arguments=[--topic, my-topic-636540722-1838665560, --max-messages, 100, --group-instance-id, instance154067977, USER=my_user_176160346_1417612999, --group-id, my-consumer-group-1196686603, --bootstrap-server, my-cluster-d36063a2-kafka-bootstrap.namespace-60.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d36063a2-kafka-clients-688fb98f5d-4jkkh', podNamespace='namespace-60', bootstrapServer='my-cluster-d36063a2-kafka-bootstrap.namespace-60.svc:9093', topicName='my-topic-636540722-1838665560', maxMessages=100, kafkaUsername='my-user-176160346-1417612999', consumerGroupName='my-consumer-group-1196686603', consumerInstanceId='instance154067977', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@565a0285}
2022-04-04 12:45:39 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-d36063a2-kafka-bootstrap.namespace-60.svc:9093:my-topic-636540722-1838665560 from pod my-cluster-d36063a2-kafka-clients-688fb98f5d-4jkkh
2022-04-04 12:45:39 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d36063a2-kafka-clients-688fb98f5d-4jkkh -n namespace-60 -- /opt/kafka/consumer.sh --topic my-topic-636540722-1838665560 --max-messages 100 --group-instance-id instance154067977 USER=my_user_176160346_1417612999 --group-id my-consumer-group-1196686603 --bootstrap-server my-cluster-d36063a2-kafka-bootstrap.namespace-60.svc:9093
2022-04-04 12:45:46 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 12:45:46 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 12:45:46 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1035059419-1832286756 in namespace namespace-60
2022-04-04 12:45:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-60
2022-04-04 12:45:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1035059419-1832286756 will have desired state: Ready
2022-04-04 12:45:47 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1035059419-1832286756 is in desired state: Ready
2022-04-04 12:45:47 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5649bcb6, messages=[], arguments=[--topic, my-topic-1035059419-1832286756, --max-messages, 100, USER=my_user_176160346_1417612999, --bootstrap-server, my-cluster-d36063a2-kafka-bootstrap.namespace-60.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-d36063a2-kafka-clients-688fb98f5d-4jkkh', podNamespace='namespace-60', bootstrapServer='my-cluster-d36063a2-kafka-bootstrap.namespace-60.svc:9093', topicName='my-topic-1035059419-1832286756', maxMessages=100, kafkaUsername='my-user-176160346-1417612999', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5001d219}
2022-04-04 12:45:47 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-d36063a2-kafka-bootstrap.namespace-60.svc:9093:my-topic-1035059419-1832286756 from pod my-cluster-d36063a2-kafka-clients-688fb98f5d-4jkkh
2022-04-04 12:45:47 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d36063a2-kafka-clients-688fb98f5d-4jkkh -n namespace-60 -- /opt/kafka/producer.sh --topic my-topic-1035059419-1832286756 --max-messages 100 USER=my_user_176160346_1417612999 --bootstrap-server my-cluster-d36063a2-kafka-bootstrap.namespace-60.svc:9093
2022-04-04 12:45:50 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 12:45:50 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 12:45:50 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@505e5963, messages=[], arguments=[--topic, my-topic-1035059419-1832286756, --max-messages, 100, --group-instance-id, instance954424420, USER=my_user_176160346_1417612999, --group-id, my-consumer-group-632307743, --bootstrap-server, my-cluster-d36063a2-kafka-bootstrap.namespace-60.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d36063a2-kafka-clients-688fb98f5d-4jkkh', podNamespace='namespace-60', bootstrapServer='my-cluster-d36063a2-kafka-bootstrap.namespace-60.svc:9093', topicName='my-topic-1035059419-1832286756', maxMessages=100, kafkaUsername='my-user-176160346-1417612999', consumerGroupName='my-consumer-group-632307743', consumerInstanceId='instance954424420', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@75a7da4b}
2022-04-04 12:45:50 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-d36063a2-kafka-bootstrap.namespace-60.svc:9093:my-topic-1035059419-1832286756 from pod my-cluster-d36063a2-kafka-clients-688fb98f5d-4jkkh
2022-04-04 12:45:50 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d36063a2-kafka-clients-688fb98f5d-4jkkh -n namespace-60 -- /opt/kafka/consumer.sh --topic my-topic-1035059419-1832286756 --max-messages 100 --group-instance-id instance954424420 USER=my_user_176160346_1417612999 --group-id my-consumer-group-632307743 --bootstrap-server my-cluster-d36063a2-kafka-bootstrap.namespace-60.svc:9093
2022-04-04 12:45:57 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 12:45:57 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 12:45:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 12:45:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCaRenewalBreakInMiddle
2022-04-04 12:45:57 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-636540722-1838665560 in namespace namespace-60
2022-04-04 12:45:57 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-176160346-1417612999 in namespace namespace-60
2022-04-04 12:45:57 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d36063a2 in namespace namespace-60
2022-04-04 12:45:57 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1035059419-1832286756 in namespace namespace-60
2022-04-04 12:45:57 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-d36063a2-kafka-clients in namespace namespace-60
2022-04-04 12:46:37 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 12:46:37 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-60 for test case:testCaRenewalBreakInMiddle
2022-04-04 12:46:43 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCaRenewalBreakInMiddle-FINISHED
2022-04-04 12:46:43 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 12:46:43 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 12:46:43 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoRenewAllCaCertsTriggeredByAnno-STARTED
2022-04-04 12:46:43 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 12:46:43 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-61 for test case:testAutoRenewAllCaCertsTriggeredByAnno
2022-04-04 12:46:43 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-61
2022-04-04 12:46:43 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-61
2022-04-04 12:46:43 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-61
2022-04-04 12:46:43 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-04 12:46:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-12f688e9 in namespace namespace-61
2022-04-04 12:46:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-61
2022-04-04 12:46:43 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-12f688e9 will have desired state: Ready
2022-04-04 12:48:49 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-12f688e9 is in desired state: Ready
2022-04-04 12:48:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1829583356-1469284007 in namespace namespace-61
2022-04-04 12:48:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-61
2022-04-04 12:48:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1829583356-1469284007 will have desired state: Ready
2022-04-04 12:48:50 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1829583356-1469284007 is in desired state: Ready
2022-04-04 12:48:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-317066560-1510589357 in namespace namespace-61
2022-04-04 12:48:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-61
2022-04-04 12:48:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-317066560-1510589357 will have desired state: Ready
2022-04-04 12:48:51 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-317066560-1510589357 is in desired state: Ready
2022-04-04 12:48:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-12f688e9-kafka-clients in namespace namespace-61
2022-04-04 12:48:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-61
2022-04-04 12:48:51 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-12f688e9-kafka-clients will be ready
2022-04-04 12:48:53 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-12f688e9-kafka-clients is ready
2022-04-04 12:48:53 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 12:48:53 [main] [32mINFO [m [SecurityST:260] Checking produced and consumed messages to pod:my-cluster-12f688e9-kafka-clients-94b547d9b-w6tk7
2022-04-04 12:48:53 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@a526b3a, messages=[], arguments=[--topic, my-topic-317066560-1510589357, --max-messages, 100, --bootstrap-server, my-cluster-12f688e9-kafka-bootstrap.namespace-61.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-12f688e9-kafka-clients-94b547d9b-w6tk7', podNamespace='namespace-61', bootstrapServer='my-cluster-12f688e9-kafka-bootstrap.namespace-61.svc:9092', topicName='my-topic-317066560-1510589357', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@406aa363}
2022-04-04 12:48:53 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-12f688e9-kafka-bootstrap.namespace-61.svc:9092:my-topic-317066560-1510589357 from pod my-cluster-12f688e9-kafka-clients-94b547d9b-w6tk7
2022-04-04 12:48:53 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-12f688e9-kafka-clients-94b547d9b-w6tk7 -n namespace-61 -- /opt/kafka/producer.sh --topic my-topic-317066560-1510589357 --max-messages 100 --bootstrap-server my-cluster-12f688e9-kafka-bootstrap.namespace-61.svc:9092
2022-04-04 12:48:55 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 12:48:55 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 12:48:55 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@70e75ffa, messages=[], arguments=[--topic, my-topic-317066560-1510589357, --max-messages, 100, --group-instance-id, instance700551766, --group-id, my-consumer-group-29048098, --bootstrap-server, my-cluster-12f688e9-kafka-bootstrap.namespace-61.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-12f688e9-kafka-clients-94b547d9b-w6tk7', podNamespace='namespace-61', bootstrapServer='my-cluster-12f688e9-kafka-bootstrap.namespace-61.svc:9092', topicName='my-topic-317066560-1510589357', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-29048098', consumerInstanceId='instance700551766', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@65039982}
2022-04-04 12:48:55 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-12f688e9-kafka-bootstrap.namespace-61.svc:9092#my-topic-317066560-1510589357 from pod my-cluster-12f688e9-kafka-clients-94b547d9b-w6tk7
2022-04-04 12:48:55 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-12f688e9-kafka-clients-94b547d9b-w6tk7 -n namespace-61 -- /opt/kafka/consumer.sh --topic my-topic-317066560-1510589357 --max-messages 100 --group-instance-id instance700551766 --group-id my-consumer-group-29048098 --bootstrap-server my-cluster-12f688e9-kafka-bootstrap.namespace-61.svc:9092
2022-04-04 12:49:01 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 12:49:01 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 12:49:01 [main] [32mINFO [m [SecurityST:274] Triggering CA cert renewal by adding the annotation
2022-04-04 12:49:01 [main] [32mINFO [m [SecurityST:286] Patching secret my-cluster-12f688e9-cluster-ca-cert with strimzi.io/force-renew
2022-04-04 12:49:01 [main] [32mINFO [m [SecurityST:286] Patching secret my-cluster-12f688e9-clients-ca-cert with strimzi.io/force-renew
2022-04-04 12:49:01 [main] [32mINFO [m [SecurityST:291] Wait for zk to rolling restart ...
2022-04-04 12:49:01 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-12f688e9-zookeeper rolling update
2022-04-04 12:50:46 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-12f688e9-zookeeper has been successfully rolled
2022-04-04 12:50:46 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-12f688e9-zookeeper to be ready
2022-04-04 12:51:12 [main] [32mINFO [m [SecurityST:295] Wait for kafka to rolling restart ...
2022-04-04 12:51:12 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-12f688e9-kafka rolling update
2022-04-04 12:52:12 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-12f688e9-kafka has been successfully rolled
2022-04-04 12:52:12 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-12f688e9-kafka to be ready
2022-04-04 12:52:44 [main] [32mINFO [m [SecurityST:299] Wait for EO to rolling restart ...
2022-04-04 12:52:44 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-12f688e9-entity-operator rolling update
2022-04-04 12:52:49 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-12f688e9-entity-operator will be ready
2022-04-04 12:53:26 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-12f688e9-entity-operator is ready
2022-04-04 12:53:36 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-12f688e9-entity-operator rolling update finished
2022-04-04 12:53:36 [main] [32mINFO [m [SecurityST:303] Wait for CC and KE to rolling restart ...
2022-04-04 12:53:36 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-12f688e9-kafka-exporter rolling update
2022-04-04 12:54:36 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-12f688e9-kafka-exporter will be ready
2022-04-04 12:54:36 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-12f688e9-kafka-exporter is ready
2022-04-04 12:54:46 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-12f688e9-kafka-exporter rolling update finished
2022-04-04 12:54:46 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-12f688e9-cruise-control rolling update
2022-04-04 12:54:46 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-12f688e9-cruise-control will be ready
2022-04-04 12:54:46 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-12f688e9-cruise-control is ready
2022-04-04 12:54:56 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-12f688e9-cruise-control rolling update finished
2022-04-04 12:54:56 [main] [32mINFO [m [SecurityST:308] Checking the certificates have been replaced
2022-04-04 12:54:56 [main] [32mINFO [m [SecurityST:322] Checking consumed messages to pod:my-cluster-12f688e9-kafka-clients-94b547d9b-w6tk7
2022-04-04 12:54:56 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@18b4ea2a, messages=[], arguments=[--topic, my-topic-317066560-1510589357, --max-messages, 100, --group-instance-id, instance266323155, --group-id, my-consumer-group-1957841188, --bootstrap-server, my-cluster-12f688e9-kafka-bootstrap.namespace-61.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-12f688e9-kafka-clients-94b547d9b-w6tk7', podNamespace='namespace-61', bootstrapServer='my-cluster-12f688e9-kafka-bootstrap.namespace-61.svc:9092', topicName='my-topic-317066560-1510589357', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1957841188', consumerInstanceId='instance266323155', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1e8056f6}
2022-04-04 12:54:56 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-12f688e9-kafka-bootstrap.namespace-61.svc:9092#my-topic-317066560-1510589357 from pod my-cluster-12f688e9-kafka-clients-94b547d9b-w6tk7
2022-04-04 12:54:56 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-12f688e9-kafka-clients-94b547d9b-w6tk7 -n namespace-61 -- /opt/kafka/consumer.sh --topic my-topic-317066560-1510589357 --max-messages 100 --group-instance-id instance266323155 --group-id my-consumer-group-1957841188 --bootstrap-server my-cluster-12f688e9-kafka-bootstrap.namespace-61.svc:9092
2022-04-04 12:55:02 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 12:55:02 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 12:55:02 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser bob-my-cluster-12f688e9 in namespace namespace-61
2022-04-04 12:55:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-61
2022-04-04 12:55:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: bob-my-cluster-12f688e9 will have desired state: Ready
2022-04-04 12:55:03 [main] [32mINFO [m [ResourceManager:444] KafkaUser: bob-my-cluster-12f688e9 is in desired state: Ready
2022-04-04 12:55:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-12f688e9-kafka-clients-tls in namespace namespace-61
2022-04-04 12:55:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-61
2022-04-04 12:55:03 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-12f688e9-kafka-clients-tls will be ready
2022-04-04 12:55:05 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-12f688e9-kafka-clients-tls is ready
2022-04-04 12:55:05 [main] [32mINFO [m [SecurityST:346] Checking consumed messages to pod:my-cluster-12f688e9-kafka-clients-tls-d57b4c7b5-jvqbz
2022-04-04 12:55:05 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@32865239, messages=[], arguments=[--topic, my-topic-317066560-1510589357, --max-messages, 100, --group-instance-id, instance1341164624, USER=bob_my_cluster_12f688e9, --group-id, my-consumer-group-42142814, --bootstrap-server, my-cluster-12f688e9-kafka-bootstrap.namespace-61.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-12f688e9-kafka-clients-tls-d57b4c7b5-jvqbz', podNamespace='namespace-61', bootstrapServer='my-cluster-12f688e9-kafka-bootstrap.namespace-61.svc:9093', topicName='my-topic-317066560-1510589357', maxMessages=100, kafkaUsername='bob-my-cluster-12f688e9', consumerGroupName='my-consumer-group-42142814', consumerInstanceId='instance1341164624', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2ead86fc}
2022-04-04 12:55:05 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-12f688e9-kafka-bootstrap.namespace-61.svc:9093#my-topic-317066560-1510589357 from pod my-cluster-12f688e9-kafka-clients-tls-d57b4c7b5-jvqbz
2022-04-04 12:55:05 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-12f688e9-kafka-clients-tls-d57b4c7b5-jvqbz -n namespace-61 -- /opt/kafka/consumer.sh --topic my-topic-317066560-1510589357 --max-messages 100 --group-instance-id instance1341164624 USER=bob_my_cluster_12f688e9 --group-id my-consumer-group-42142814 --bootstrap-server my-cluster-12f688e9-kafka-bootstrap.namespace-61.svc:9093
2022-04-04 12:55:12 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 12:55:12 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 12:55:12 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 12:55:12 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoRenewAllCaCertsTriggeredByAnno
2022-04-04 12:55:12 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-12f688e9-kafka-clients in namespace namespace-61
2022-04-04 12:55:12 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-12f688e9 in namespace namespace-61
2022-04-04 12:55:12 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-61, for cruise control Kafka cluster my-cluster-12f688e9
2022-04-04 12:55:12 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser bob-my-cluster-12f688e9 in namespace namespace-61
2022-04-04 12:55:12 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-12f688e9-kafka-clients-tls in namespace namespace-61
2022-04-04 12:55:12 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-317066560-1510589357 in namespace namespace-61
2022-04-04 12:55:12 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1829583356-1469284007 in namespace namespace-61
2022-04-04 12:56:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 12:56:12 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-61 for test case:testAutoRenewAllCaCertsTriggeredByAnno
2022-04-04 12:56:18 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoRenewAllCaCertsTriggeredByAnno-FINISHED
2022-04-04 12:56:18 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 12:56:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 12:56:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCertRegeneratedAfterInternalCAisDeleted-STARTED
2022-04-04 12:56:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 12:56:18 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-62 for test case:testCertRegeneratedAfterInternalCAisDeleted
2022-04-04 12:56:18 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-62
2022-04-04 12:56:18 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-62
2022-04-04 12:56:18 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-62
2022-04-04 12:56:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-f820eb51 in namespace namespace-62
2022-04-04 12:56:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-62
2022-04-04 12:56:18 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f820eb51 will have desired state: Ready
2022-04-04 12:57:27 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f820eb51 is in desired state: Ready
2022-04-04 12:57:27 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1503528123-139308726 in namespace namespace-62
2022-04-04 12:57:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-62
2022-04-04 12:57:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1503528123-139308726 will have desired state: Ready
2022-04-04 12:57:28 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1503528123-139308726 is in desired state: Ready
2022-04-04 12:57:28 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1145344744-473554865 in namespace namespace-62
2022-04-04 12:57:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-62
2022-04-04 12:57:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1145344744-473554865 will have desired state: Ready
2022-04-04 12:57:29 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1145344744-473554865 is in desired state: Ready
2022-04-04 12:57:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-f820eb51-kafka-clients in namespace namespace-62
2022-04-04 12:57:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-62
2022-04-04 12:57:29 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f820eb51-kafka-clients will be ready
2022-04-04 12:57:31 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f820eb51-kafka-clients is ready
2022-04-04 12:57:31 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 12:57:31 [main] [32mINFO [m [SecurityST:797] Verifying that secret Secret(apiVersion=v1, data={ca.crt=LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUZMVENDQXhXZ0F3SUJBZ0lVUkF1QWpHZ01wYi9MZHJtYmRESXdFSmlSamNjd0RRWUpLb1pJaHZjTkFRRU4KQlFBd0xURVRNQkVHQTFVRUNnd0thVzh1YzNSeWFXMTZhVEVXTUJRR0ExVUVBd3dOWTJ4cFpXNTBjeTFqWVNCMgpNREFlRncweU1qQTBNRFF4TWpVMk1qQmFGdzB5TXpBME1EUXhNalUyTWpCYU1DMHhFekFSQmdOVkJBb01DbWx2CkxuTjBjbWx0ZW1reEZqQVVCZ05WQkFNTURXTnNhV1Z1ZEhNdFkyRWdkakF3Z2dJaU1BMEdDU3FHU0liM0RRRUIKQVFVQUE0SUNEd0F3Z2dJS0FvSUNBUURUQ0w4ZXg0VEhvZk9WSWNwSVp6cUUrN0FGb2MvUDRVaUtWU1VXT1I1MApDblRRWjZISXpFeElUbGg4ZnRCMGJ0L21KbEhhdzhqeW52LytVcUphd3VTNUpVb29BZDMrMzQ0V2tpNzVlN05wCk0zQ01CeTB4bHlreUlOWEw3UjA1U3BvajFwMU9EL0FqdG8raXltKzJrcnZHbkN2b1FsQlp2ZFBaVndwYUY0anMKWkhWendmU0lBZlk2SkZXY3FuUEhRcGRiMVhaQ0VUWHZlU2pYZjBQSGRDQ1U1Y0FUamV1SGtOVkdjWGZsTEpNcwo0VDRFZ28yV04wN0VNTDVJWDBaQnNLTE8zZHZ4Rnl0ZEZsK3VhU2VyY0dQUDY4YnhwNndvZWorL3FHeENIbkpVCjhTNHN6eTJvbXdtVmd0cUJxRkNONDFIazhRUHVQdUNZWFdDS1VjSmgxWXhnOHFjeWFSVVAvckZRaGJtTHNmamcKbXJjT2FXTWFPWXl4U0JYcGJLbnFLcExjaTBVRTNPZ0xyWUxneGoyeXgzakJ1dFQzeENhbVY4VlJxM3pZcGswcQpiZlRqUTVqaE1sMkh4UzFXQVV4K2RuVjIrY1pHSmQ2L0tNdVFER0ZqRkhzd09OOHpoN0VJMDJ5dTBkSlB4cVYxCmNsZGtPZURJOGlTaDRMMEtZenFlRjhWc29TeDM2QVFjSWRUdVV5YkdydUd3Wnk0a0ozOUxjVTZxeVBVVzZST0MKSWJmUndMNHJIUHd2Q2d6NjJXRHFFYTg3VE50cDR3WHA5WGtBdkszVi9vTWJLWk4rdjZwVklPbVNlUnRaMmh1QQpJYWNad2c4WU9TMHZ6MGVhbWZpMlhTK1JTUlBCUjgwVjVKVzdqaUZYT3RCSVU2VE9BV1BtdTFBN3hHdWprNlJGCmJ3SURBUUFCbzBVd1F6QWRCZ05WSFE0RUZnUVVqQkh1VHdRLzRwbnBQMW9nTDNDTDJiMm9HUFF3RWdZRFZSMFQKQVFIL0JBZ3dCZ0VCL3dJQkFEQU9CZ05WSFE4QkFmOEVCQU1DQVFZd0RRWUpLb1pJaHZjTkFRRU5CUUFEZ2dJQgpBSFR0L20xOU0yU1h6ODdTZSt2UU1FQ0tvcXJGVGE2SmYwbU0wakV4dGdHbHdrSXNQTUNJZlBGZDBZKzlIRHR1CmRsM2tYYTlGbjROdksxTW1LMnh5WW05dXRaaFB0alE4QlpySU5sWkZSVXBiZk9OQnd4RUNrNXYvWjVVN01VN1gKa3JnMkNhaXdGRTdxZTcvR29VellhWkRFTWFKd21QdDBJUFk4UEMvOHFFb09LOVZsTnV4Y1l5YXk0bU8xVUxrMApiQkh6ZHJQeTVtMzJPN0k4YTFDQ2dLMkdNWGJ2ckZYQjArb29tT0JQYVdFaTZjenlDSVhjTVVEMEZJMmt2UlQvCno2MGl6SVRHMHN3bC80OFoyYyttVng3R2c3aldwak1Cakdoa0RaUzNybjl5YThKcXZCUEdaVElmalgvU1BQalEKcXRFODFJWkFobWlDNkVvQi9QMWlsNU5tb2ptUTdpdTBIalIvUHdGUG1adjdpblB4VVdSaG9Zb3hkWTVlUUZETwpJLzdRdFA1ZkRVb3dVb1FERHpJWVhxeVpUeVFkUUZ5T3U0d1ZHTlF3K2QyRmVobTdnU1Y1MFlVNzZMUkVqT1JUCi9zWHpFTFpnTHRJTEFTSzBxRU5oTDNlcGdld05jeU0xZ2F0L3J6YzJsZE9ON3Rpem1aN05WWjRTNTRHV1lpRUcKTEpaV3dSRjNLRTdoVjVFZFA1ZSsrV2h4UkJqeHFIRzNoUDNhNUNpM2l4TUVQOE80ZXgrSFBHbTRhUDNzN0pPegpTcnVrMlNYZVdtS3lEZEFjSkMvcTQrZVVRNGZHaHZkeFJOdmo3WEdsOTJNREpEVGZYdGlwUWlQNHU3VDBiWnMwCk5nWTM2ejNPZldmV0oxVi9Ea3VEU2tLbENXVFlhbTlsUnFydWZjaklDZkRzCi0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K, ca.p12=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, ca.password=bVFZbDQ4Y2pDU2RO}, immutable=null, kind=Secret, metadata=ObjectMeta(annotations={strimzi.io/ca-cert-generation=0}, clusterName=null, creationTimestamp=2022-04-04T12:56:20Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-f820eb51, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-f820eb51, strimzi.io/cluster=my-cluster-f820eb51, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testCertRegeneratedAfterInternalCAisDeleted}, managedFields=[], name=my-cluster-f820eb51-clients-ca-cert, namespace=namespace-62, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=Kafka, name=my-cluster-f820eb51, uid=b8b8a71a-c327-4c74-8eea-1bb90cb76e75, additionalProperties={})], resourceVersion=61522, selfLink=/api/v1/namespaces/namespace-62/secrets/my-cluster-f820eb51-clients-ca-cert, uid=d6ede431-6ba2-46f9-beee-e93235c92905, additionalProperties={}), stringData=null, type=Opaque, additionalProperties={}) with name my-cluster-f820eb51-clients-ca-cert is present
2022-04-04 12:57:31 [main] [32mINFO [m [SecurityST:797] Verifying that secret Secret(apiVersion=v1, data={ca.crt=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, ca.p12=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, ca.password=alVjdmsxR3ZXVjAz}, immutable=null, kind=Secret, metadata=ObjectMeta(annotations={strimzi.io/ca-cert-generation=0}, clusterName=null, creationTimestamp=2022-04-04T12:56:20Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-f820eb51, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-f820eb51, strimzi.io/cluster=my-cluster-f820eb51, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testCertRegeneratedAfterInternalCAisDeleted}, managedFields=[], name=my-cluster-f820eb51-cluster-ca-cert, namespace=namespace-62, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=Kafka, name=my-cluster-f820eb51, uid=b8b8a71a-c327-4c74-8eea-1bb90cb76e75, additionalProperties={})], resourceVersion=61521, selfLink=/api/v1/namespaces/namespace-62/secrets/my-cluster-f820eb51-cluster-ca-cert, uid=37bd8969-2f15-435a-9542-9b2586da76d2, additionalProperties={}), stringData=null, type=Opaque, additionalProperties={}) with name my-cluster-f820eb51-cluster-ca-cert is present
2022-04-04 12:57:31 [main] [32mINFO [m [SecurityST:802] Deleting secret my-cluster-f820eb51-clients-ca-cert
2022-04-04 12:57:31 [main] [32mINFO [m [SecurityST:802] Deleting secret my-cluster-f820eb51-cluster-ca-cert
2022-04-04 12:57:31 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-f820eb51-kafka are stable
2022-04-04 12:57:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:57:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:57:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:57:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:57:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:57:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:57:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:57:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:57:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:57:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:57:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:57:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:57:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:57:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:57:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:57:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:57:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:57:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:57:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:57:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:57:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:57:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:57:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:57:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:57:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:57:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:57:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:57:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:57:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:57:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:57:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:57:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:57:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:57:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:57:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:57:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:57:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:57:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:57:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:57:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:57:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:57:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:57:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:57:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:57:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:57:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:57:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:57:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:57:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:57:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:57:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:57:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:57:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:57:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:57:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:57:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:57:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:57:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:57:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:57:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:57:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:57:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:57:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:57:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:57:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:57:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:57:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:57:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:57:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:57:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:57:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:57:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:57:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:57:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:57:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:57:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:57:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:57:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:57:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:57:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:57:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:57:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:57:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:57:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:57:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:57:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:57:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:57:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:57:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:57:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:57:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:57:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:57:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:57:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:57:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:57:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:57:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:57:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:57:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:57:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:57:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:57:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:57:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:57:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:57:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 12:57:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 12:57:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 12:57:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 12:57:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 12:57:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 12:57:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 12:57:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 12:57:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 12:57:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 12:57:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 12:57:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 12:58:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 12:58:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 12:58:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 12:58:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 12:58:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 12:58:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 12:58:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 12:58:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 12:58:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 12:58:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 12:58:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 12:58:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 12:58:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 12:58:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 12:58:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 12:58:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 12:58:04 [main] [32mINFO [m [PodUtils:326] Pod my-cluster-f820eb51-kafka-0 is not stable in phase following phase Pending reset the stability counter from 33 to 0
2022-04-04 12:58:05 [main] [32mINFO [m [PodUtils:326] Pod my-cluster-f820eb51-kafka-0 is not stable in phase following phase Pending reset the stability counter from 0 to 0
2022-04-04 12:58:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:58:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:58:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:58:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:58:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:58:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:58:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:58:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:58:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:58:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:58:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:58:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:58:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:58:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:58:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:58:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:58:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:58:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:58:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:58:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:58:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:58:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:58:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:58:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:58:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:58:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:58:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:58:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:58:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:58:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:58:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:58:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:58:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:58:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:58:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:58:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:58:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:58:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:58:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:58:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:58:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:58:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:58:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:58:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:58:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:58:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:58:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:58:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:58:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:58:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:58:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:58:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:58:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:58:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:58:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:58:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:58:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:58:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:58:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:58:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:58:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:58:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:58:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:58:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:58:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:58:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:58:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:58:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:58:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:58:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:58:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:58:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:58:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:58:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:58:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:58:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:58:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:58:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:58:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:58:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:58:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:58:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:58:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:58:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:58:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:58:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:58:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:58:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:58:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:58:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:58:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:58:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:58:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:58:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:58:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:58:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:58:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:58:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:58:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:58:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:58:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:58:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:58:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:58:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:58:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 12:58:32 [main] [32mINFO [m [PodUtils:326] Pod my-cluster-f820eb51-kafka-1 is not stable in phase following phase Pending reset the stability counter from 26 to 0
2022-04-04 12:58:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:58:33 [main] [32mINFO [m [PodUtils:326] Pod my-cluster-f820eb51-kafka-1 is not stable in phase following phase Pending reset the stability counter from 0 to 0
2022-04-04 12:58:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:58:34 [main] [32mINFO [m [PodUtils:326] Pod my-cluster-f820eb51-kafka-1 is not stable in phase following phase Pending reset the stability counter from 0 to 0
2022-04-04 12:58:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:58:35 [main] [32mINFO [m [PodUtils:326] Pod my-cluster-f820eb51-kafka-1 is not stable in phase following phase Pending reset the stability counter from 0 to 0
2022-04-04 12:58:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:58:36 [main] [32mINFO [m [PodUtils:326] Pod my-cluster-f820eb51-kafka-1 is not stable in phase following phase Pending reset the stability counter from 0 to 0
2022-04-04 12:58:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:58:37 [main] [32mINFO [m [PodUtils:326] Pod my-cluster-f820eb51-kafka-1 is not stable in phase following phase Pending reset the stability counter from 0 to 0
2022-04-04 12:58:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:58:38 [main] [32mINFO [m [PodUtils:326] Pod my-cluster-f820eb51-kafka-1 is not stable in phase following phase Pending reset the stability counter from 0 to 0
2022-04-04 12:58:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:58:39 [main] [32mINFO [m [PodUtils:326] Pod my-cluster-f820eb51-kafka-1 is not stable in phase following phase Pending reset the stability counter from 0 to 0
2022-04-04 12:58:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:58:40 [main] [32mINFO [m [PodUtils:326] Pod my-cluster-f820eb51-kafka-1 is not stable in phase following phase Pending reset the stability counter from 0 to 0
2022-04-04 12:58:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:58:41 [main] [32mINFO [m [PodUtils:326] Pod my-cluster-f820eb51-kafka-1 is not stable in phase following phase Pending reset the stability counter from 0 to 0
2022-04-04 12:58:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:58:42 [main] [32mINFO [m [PodUtils:326] Pod my-cluster-f820eb51-kafka-1 is not stable in phase following phase Pending reset the stability counter from 0 to 0
2022-04-04 12:58:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:58:43 [main] [32mINFO [m [PodUtils:326] Pod my-cluster-f820eb51-kafka-1 is not stable in phase following phase Pending reset the stability counter from 0 to 0
2022-04-04 12:58:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:58:44 [main] [32mINFO [m [PodUtils:326] Pod my-cluster-f820eb51-kafka-1 is not stable in phase following phase Pending reset the stability counter from 0 to 0
2022-04-04 12:58:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:58:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:58:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:58:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:58:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:58:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:58:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:58:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:58:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:58:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:58:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:58:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:58:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:58:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:58:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:58:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:58:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:58:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:58:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:58:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:58:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:58:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:58:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:58:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:58:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:58:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:58:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:58:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:58:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:58:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:58:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:58:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:58:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:58:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:58:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:58:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:58:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:58:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:58:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:58:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:58:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:58:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:58:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:58:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:58:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:58:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:58:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:58:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:58:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:58:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:58:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:58:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:58:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:58:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:58:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:58:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:59:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:59:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:59:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:59:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:59:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:59:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:59:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:59:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:59:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:59:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:59:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:59:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:59:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:59:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:59:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:59:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:59:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:59:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:59:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:59:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:59:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:59:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:59:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:59:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:59:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:59:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:59:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:59:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:59:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:59:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:59:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:59:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:59:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:59:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:59:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:59:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:59:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:59:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:59:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:59:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:59:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:59:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:59:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:59:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:59:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:59:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:59:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:59:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:59:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 12:59:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 12:59:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 12:59:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 12:59:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 12:59:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 12:59:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 12:59:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 12:59:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 12:59:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 12:59:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 12:59:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 12:59:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 12:59:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 12:59:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 12:59:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 12:59:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 12:59:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 12:59:16 [main] [32mINFO [m [PodUtils:326] Pod my-cluster-f820eb51-kafka-2 is not stable in phase following phase Pending reset the stability counter from 30 to 0
2022-04-04 12:59:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:59:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:59:17 [main] [32mINFO [m [PodUtils:326] Pod my-cluster-f820eb51-kafka-2 is not stable in phase following phase Pending reset the stability counter from 0 to 0
2022-04-04 12:59:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:59:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:59:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:59:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:59:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:59:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:59:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:59:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:59:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:59:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:59:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:59:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:59:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:59:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:59:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:59:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:59:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:59:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:59:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:59:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:59:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:59:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:59:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:59:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:59:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:59:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:59:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:59:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:59:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:59:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:59:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:59:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:59:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:59:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:59:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:59:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:59:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:59:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:59:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:59:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:59:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:59:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:59:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:59:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:59:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:59:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:59:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:59:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:59:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:59:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:59:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:59:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:59:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:59:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:59:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:59:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:59:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:59:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:59:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:59:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:59:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:59:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:59:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:59:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:59:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:59:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:59:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:59:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:59:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:59:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:59:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:59:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:59:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:59:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:59:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:59:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:59:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:59:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:59:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:59:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:59:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:59:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:59:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:59:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:59:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:59:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:59:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:59:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:59:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:59:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:59:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:59:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:59:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:59:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:59:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:59:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:59:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:59:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:59:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:59:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:59:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:59:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:59:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:59:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:59:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 12:59:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 12:59:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 12:59:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 12:59:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 12:59:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 12:59:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 12:59:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 12:59:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 12:59:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 12:59:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 12:59:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 12:59:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 12:59:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 12:59:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 12:59:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 12:59:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 12:59:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 12:59:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 12:59:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 12:59:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 12:59:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 12:59:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 12:59:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 12:59:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 12:59:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 12:59:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 12:59:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 12:59:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 12:59:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 12:59:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 12:59:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 12:59:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 12:59:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 12:59:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 12:59:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 12:59:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 12:59:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 12:59:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 12:59:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 12:59:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 12:59:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 12:59:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 12:59:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 12:59:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 12:59:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 12:59:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 12:59:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 12:59:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 12:59:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 12:59:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 12:59:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 12:59:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 12:59:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 12:59:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 12:59:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 12:59:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 12:59:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 12:59:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 12:59:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 12:59:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 12:59:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 12:59:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 12:59:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 13:00:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 13:00:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 13:00:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 13:00:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 13:00:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 13:00:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 13:00:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 13:00:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 13:00:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 13:00:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 13:00:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 13:00:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 13:00:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 13:00:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 13:00:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 13:00:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 13:00:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 13:00:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 13:00:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 13:00:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 13:00:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 13:00:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 13:00:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 13:00:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 13:00:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 13:00:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 13:00:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 13:00:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 13:00:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 13:00:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 13:00:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 13:00:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 13:00:07 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-f820eb51-kafka-0 ,my-cluster-f820eb51-kafka-1 ,my-cluster-f820eb51-kafka-2 ,my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h
2022-04-04 13:00:07 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-f820eb51-kafka rolling update
2022-04-04 13:00:07 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-f820eb51-kafka has been successfully rolled
2022-04-04 13:00:07 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-f820eb51-kafka to be ready
2022-04-04 13:00:17 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f820eb51 will have desired state: Ready
2022-04-04 13:01:55 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f820eb51 is in desired state: Ready
2022-04-04 13:01:55 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-f820eb51 is ready
2022-04-04 13:01:55 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret my-cluster-f820eb51-clients-ca-cert
2022-04-04 13:01:55 [main] [32mINFO [m [SecretUtils:50] Secret my-cluster-f820eb51-clients-ca-cert created
2022-04-04 13:01:55 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret my-cluster-f820eb51-cluster-ca-cert
2022-04-04 13:01:55 [main] [32mINFO [m [SecretUtils:50] Secret my-cluster-f820eb51-cluster-ca-cert created
2022-04-04 13:01:55 [main] [32mINFO [m [SecurityST:821] Checking consumed messages to pod:my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h
2022-04-04 13:01:55 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@125e9032, messages=[], arguments=[--topic, my-topic-1145344744-473554865, --max-messages, 100, USER=my_user_1503528123_139308726, --bootstrap-server, my-cluster-f820eb51-kafka-bootstrap.namespace-62.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h', podNamespace='namespace-62', bootstrapServer='my-cluster-f820eb51-kafka-bootstrap.namespace-62.svc:9093', topicName='my-topic-1145344744-473554865', maxMessages=100, kafkaUsername='my-user-1503528123-139308726', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@24ce3dbd}
2022-04-04 13:01:55 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-f820eb51-kafka-bootstrap.namespace-62.svc:9093:my-topic-1145344744-473554865 from pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h
2022-04-04 13:01:55 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h -n namespace-62 -- /opt/kafka/producer.sh --topic my-topic-1145344744-473554865 --max-messages 100 USER=my_user_1503528123_139308726 --bootstrap-server my-cluster-f820eb51-kafka-bootstrap.namespace-62.svc:9093
2022-04-04 13:01:58 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 13:01:58 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 13:01:58 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@8ef83b8, messages=[], arguments=[--topic, my-topic-1145344744-473554865, --max-messages, 100, --group-instance-id, instance210927516, USER=my_user_1503528123_139308726, --group-id, my-consumer-group-1988048109, --bootstrap-server, my-cluster-f820eb51-kafka-bootstrap.namespace-62.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h', podNamespace='namespace-62', bootstrapServer='my-cluster-f820eb51-kafka-bootstrap.namespace-62.svc:9093', topicName='my-topic-1145344744-473554865', maxMessages=100, kafkaUsername='my-user-1503528123-139308726', consumerGroupName='my-consumer-group-1988048109', consumerInstanceId='instance210927516', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5d996e63}
2022-04-04 13:01:58 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-f820eb51-kafka-bootstrap.namespace-62.svc:9093:my-topic-1145344744-473554865 from pod my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h
2022-04-04 13:01:58 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f820eb51-kafka-clients-64d769bd75-qgd5h -n namespace-62 -- /opt/kafka/consumer.sh --topic my-topic-1145344744-473554865 --max-messages 100 --group-instance-id instance210927516 USER=my_user_1503528123_139308726 --group-id my-consumer-group-1988048109 --bootstrap-server my-cluster-f820eb51-kafka-bootstrap.namespace-62.svc:9093
2022-04-04 13:02:05 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 13:02:05 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 13:02:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 13:02:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCertRegeneratedAfterInternalCAisDeleted
2022-04-04 13:02:05 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1145344744-473554865 in namespace namespace-62
2022-04-04 13:02:05 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-f820eb51-kafka-clients in namespace namespace-62
2022-04-04 13:02:05 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1503528123-139308726 in namespace namespace-62
2022-04-04 13:02:05 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-f820eb51 in namespace namespace-62
2022-04-04 13:02:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 13:02:55 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-62 for test case:testCertRegeneratedAfterInternalCAisDeleted
2022-04-04 13:03:01 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCertRegeneratedAfterInternalCAisDeleted-FINISHED
2022-04-04 13:03:01 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 13:03:01 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 13:03:01 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testKafkaAndKafkaConnectCipherSuites-STARTED
2022-04-04 13:03:01 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 13:03:01 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-63 for test case:testKafkaAndKafkaConnectCipherSuites
2022-04-04 13:03:01 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-63
2022-04-04 13:03:01 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-63
2022-04-04 13:03:01 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-63
2022-04-04 13:03:01 [main] [32mINFO [m [SecurityST:1362] Deploying Kafka cluster with the support TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 cipher algorithms
2022-04-04 13:03:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-04356699 in namespace namespace-63
2022-04-04 13:03:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-63
2022-04-04 13:03:01 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-04356699 will have desired state: Ready
2022-04-04 13:04:14 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-04356699 is in desired state: Ready
2022-04-04 13:04:14 [main] [32mINFO [m [SecurityST:1374] Verifying that Kafka Connect has the accepted configuration:
 ssl.cipher.suites -> TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
2022-04-04 13:04:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-04356699-kafka-clients in namespace namespace-63
2022-04-04 13:04:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-63
2022-04-04 13:04:14 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-04356699-kafka-clients will be ready
2022-04-04 13:04:16 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-04356699-kafka-clients is ready
2022-04-04 13:04:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-04356699-scraper in namespace namespace-63
2022-04-04 13:04:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-63
2022-04-04 13:04:16 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-04356699-scraper will be ready
2022-04-04 13:04:18 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-04356699-scraper is ready
2022-04-04 13:04:18 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-04356699-scraper to be ready
2022-04-04 13:04:28 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-04356699-scraper is ready
2022-04-04 13:04:28 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-04356699-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 13:04:28 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-04356699-allow in namespace namespace-63
2022-04-04 13:04:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-63
2022-04-04 13:04:28 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 13:04:28 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-04356699 in namespace namespace-63
2022-04-04 13:04:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-63
2022-04-04 13:04:28 [main] [32mINFO [m [SecurityST:1391] Verifying that Kafka Connect status is NotReady because of different cipher suites complexity of algorithm
2022-04-04 13:04:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-04356699 will have desired state: NotReady
2022-04-04 13:09:30 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-04356699 is in desired state: NotReady
2022-04-04 13:09:30 [main] [32mINFO [m [SecurityST:1395] Replacing Kafka Connect config to the cipher suites same as the Kafka broker has.
2022-04-04 13:09:30 [main] [32mINFO [m [SecurityST:1399] Verifying that Kafka Connect has the accepted configuration:
 ssl.cipher.suites -> TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
2022-04-04 13:09:30 [main] [32mINFO [m [KafkaConnectUtils:101] Waiting for Kafka Connect property ssl.cipher.suites -> TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 change
2022-04-04 13:09:30 [main] [32mINFO [m [KafkaConnectUtils:109] Kafka Connect property ssl.cipher.suites -> TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 change
2022-04-04 13:09:30 [main] [32mINFO [m [SecurityST:1404] Verifying that Kafka Connect is stable
2022-04-04 13:09:30 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-04356699-connect are stable
2022-04-04 13:09:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 13:09:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 13:09:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 13:09:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 13:09:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 13:09:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 13:09:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 13:09:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 13:09:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 13:09:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 13:09:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 13:09:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 13:09:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 13:09:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 13:09:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 13:09:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 13:09:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 13:09:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 13:09:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 13:09:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 13:09:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 13:09:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 13:09:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 13:09:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 13:09:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 13:09:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 13:09:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 13:09:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 13:09:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 13:09:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 13:10:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 13:10:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 13:10:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 13:10:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 13:10:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 13:10:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 13:10:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 13:10:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 13:10:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 13:10:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 13:10:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 13:10:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 13:10:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 13:10:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 13:10:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 13:10:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 13:10:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 13:10:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 13:10:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 13:10:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-04356699-connect-8778f4b7c-4rr7x is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 13:10:19 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-04356699-connect-8778f4b7c-4rr7x
2022-04-04 13:10:19 [main] [32mINFO [m [SecurityST:1408] Verifying that Kafka Connect status is Ready because of the same cipher suites complexity of algorithm
2022-04-04 13:10:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-04356699 will have desired state: Ready
2022-04-04 13:15:34 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-04356699 is in desired state: Ready
2022-04-04 13:15:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 13:15:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaAndKafkaConnectCipherSuites
2022-04-04 13:15:34 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-04356699-scraper in namespace namespace-63
2022-04-04 13:15:34 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-04356699 in namespace namespace-63
2022-04-04 13:15:34 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-04356699-allow in namespace namespace-63
2022-04-04 13:15:34 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-04356699 in namespace namespace-63
2022-04-04 13:15:34 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-04356699-kafka-clients in namespace namespace-63
2022-04-04 13:16:24 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 13:16:24 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-63 for test case:testKafkaAndKafkaConnectCipherSuites
2022-04-04 13:16:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testKafkaAndKafkaConnectCipherSuites-FINISHED
2022-04-04 13:16:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 13:16:29 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 13:16:29 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCertRenewalInMaintenanceWindow-STARTED
2022-04-04 13:16:29 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 13:16:29 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-64 for test case:testCertRenewalInMaintenanceWindow
2022-04-04 13:16:29 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-64
2022-04-04 13:16:30 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-64
2022-04-04 13:16:30 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-64
2022-04-04 13:16:30 [main] [32mINFO [m [SecurityST:698] Maintenance window is: * 21-35 * * * ? *
2022-04-04 13:16:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-526011fc in namespace namespace-64
2022-04-04 13:16:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-64
2022-04-04 13:16:30 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-526011fc will have desired state: Ready
2022-04-04 13:17:47 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-526011fc is in desired state: Ready
2022-04-04 13:17:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-916527188-1164663361 in namespace namespace-64
2022-04-04 13:17:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-64
2022-04-04 13:17:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-916527188-1164663361 will have desired state: Ready
2022-04-04 13:17:48 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-916527188-1164663361 is in desired state: Ready
2022-04-04 13:17:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-95414961-1163060349 in namespace namespace-64
2022-04-04 13:17:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-64
2022-04-04 13:17:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-95414961-1163060349 will have desired state: Ready
2022-04-04 13:17:49 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-95414961-1163060349 is in desired state: Ready
2022-04-04 13:17:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-95414961-1163060349 in namespace namespace-64
2022-04-04 13:17:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-64
2022-04-04 13:17:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-95414961-1163060349 will have desired state: Ready
2022-04-04 13:17:49 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-95414961-1163060349 is in desired state: Ready
2022-04-04 13:17:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-526011fc-kafka-clients in namespace namespace-64
2022-04-04 13:17:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-64
2022-04-04 13:17:49 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-526011fc-kafka-clients will be ready
2022-04-04 13:17:51 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-526011fc-kafka-clients is ready
2022-04-04 13:17:51 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 13:17:51 [main] [32mINFO [m [SecurityST:728] Annotate secret my-cluster-526011fc-cluster-ca-cert with secret force-renew annotation
2022-04-04 13:17:51 [main] [32mINFO [m [SecurityST:735] Wait until maintenance windows starts
2022-04-04 13:21:00 [main] [32mINFO [m [SecurityST:741] Maintenance window starts
2022-04-04 13:21:00 [main] [32mINFO [m [SecurityST:745] Wait until rolling update is triggered during maintenance window
2022-04-04 13:21:00 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-526011fc-kafka rolling update
2022-04-04 13:22:35 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-526011fc-kafka has been successfully rolled
2022-04-04 13:22:35 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-526011fc-kafka to be ready
2022-04-04 13:23:08 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-526011fc will have desired state: Ready
2022-04-04 13:23:08 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-526011fc is in desired state: Ready
2022-04-04 13:23:08 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-526011fc is ready
2022-04-04 13:23:08 [main] [32mINFO [m [SecurityST:750] Checking consumed messages to pod:my-cluster-526011fc-kafka-clients-84f8fb978f-v7gb9
2022-04-04 13:23:08 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@6ab23bf0, messages=[], arguments=[--topic, my-topic-95414961-1163060349, --max-messages, 100, USER=my_user_916527188_1164663361, --bootstrap-server, my-cluster-526011fc-kafka-bootstrap.namespace-64.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-526011fc-kafka-clients-84f8fb978f-v7gb9', podNamespace='namespace-64', bootstrapServer='my-cluster-526011fc-kafka-bootstrap.namespace-64.svc:9093', topicName='my-topic-95414961-1163060349', maxMessages=100, kafkaUsername='my-user-916527188-1164663361', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@53df16bf}
2022-04-04 13:23:08 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-526011fc-kafka-bootstrap.namespace-64.svc:9093:my-topic-95414961-1163060349 from pod my-cluster-526011fc-kafka-clients-84f8fb978f-v7gb9
2022-04-04 13:23:08 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-526011fc-kafka-clients-84f8fb978f-v7gb9 -n namespace-64 -- /opt/kafka/producer.sh --topic my-topic-95414961-1163060349 --max-messages 100 USER=my_user_916527188_1164663361 --bootstrap-server my-cluster-526011fc-kafka-bootstrap.namespace-64.svc:9093
2022-04-04 13:23:12 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 13:23:12 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 13:23:12 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4a6b67f4, messages=[], arguments=[--topic, my-topic-95414961-1163060349, --max-messages, 100, --group-instance-id, instance1092486027, USER=my_user_916527188_1164663361, --group-id, my-consumer-group-1529182550, --bootstrap-server, my-cluster-526011fc-kafka-bootstrap.namespace-64.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-526011fc-kafka-clients-84f8fb978f-v7gb9', podNamespace='namespace-64', bootstrapServer='my-cluster-526011fc-kafka-bootstrap.namespace-64.svc:9093', topicName='my-topic-95414961-1163060349', maxMessages=100, kafkaUsername='my-user-916527188-1164663361', consumerGroupName='my-consumer-group-1529182550', consumerInstanceId='instance1092486027', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@612aef80}
2022-04-04 13:23:12 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-526011fc-kafka-bootstrap.namespace-64.svc:9093:my-topic-95414961-1163060349 from pod my-cluster-526011fc-kafka-clients-84f8fb978f-v7gb9
2022-04-04 13:23:12 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-526011fc-kafka-clients-84f8fb978f-v7gb9 -n namespace-64 -- /opt/kafka/consumer.sh --topic my-topic-95414961-1163060349 --max-messages 100 --group-instance-id instance1092486027 USER=my_user_916527188_1164663361 --group-id my-consumer-group-1529182550 --bootstrap-server my-cluster-526011fc-kafka-bootstrap.namespace-64.svc:9093
2022-04-04 13:23:19 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 13:23:19 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 13:23:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 13:23:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCertRenewalInMaintenanceWindow
2022-04-04 13:23:19 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-95414961-1163060349 in namespace namespace-64
2022-04-04 13:23:19 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-526011fc in namespace namespace-64
2022-04-04 13:23:19 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-916527188-1164663361 in namespace namespace-64
2022-04-04 13:23:19 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-526011fc-kafka-clients in namespace namespace-64
2022-04-04 13:23:19 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-95414961-1163060349 in namespace namespace-64
2022-04-04 13:23:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 13:23:59 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-64 for test case:testCertRenewalInMaintenanceWindow
2022-04-04 13:24:04 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCertRenewalInMaintenanceWindow-FINISHED
2022-04-04 13:24:04 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 13:24:04 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 13:24:04 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testOwnerReferenceOfCASecrets-STARTED
2022-04-04 13:24:04 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 13:24:04 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-65 for test case:testOwnerReferenceOfCASecrets
2022-04-04 13:24:04 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-65
2022-04-04 13:24:04 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-65
2022-04-04 13:24:04 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-65
2022-04-04 13:24:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-08579004 in namespace namespace-65
2022-04-04 13:24:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-65
2022-04-04 13:24:04 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-08579004 will have desired state: Ready
2022-04-04 13:25:19 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-08579004 is in desired state: Ready
2022-04-04 13:25:19 [main] [32mINFO [m [SecurityST:1432] Listing all cluster CAs for my-cluster-08579004
2022-04-04 13:25:19 [main] [32mINFO [m [SecurityST:1436] Deleting Kafka:my-cluster-08579004
2022-04-04 13:25:19 [main] [32mINFO [m [KafkaUtils:399] Waiting for deletion of Kafka:my-cluster-08579004
2022-04-04 13:25:21 [main] [32mINFO [m [SecurityST:1440] Checking actual secrets after Kafka deletion
2022-04-04 13:25:21 [main] [32mINFO [m [SecurityST:1443] Checking that my-cluster-08579004-clients-ca secret is still present
2022-04-04 13:25:21 [main] [32mINFO [m [SecurityST:1446] Deleting secret: my-cluster-08579004-clients-ca
2022-04-04 13:25:21 [main] [32mINFO [m [SecurityST:1443] Checking that my-cluster-08579004-clients-ca-cert secret is still present
2022-04-04 13:25:21 [main] [32mINFO [m [SecurityST:1446] Deleting secret: my-cluster-08579004-clients-ca-cert
2022-04-04 13:25:21 [main] [32mINFO [m [SecurityST:1443] Checking that my-cluster-08579004-cluster-ca secret is still present
2022-04-04 13:25:21 [main] [32mINFO [m [SecurityST:1446] Deleting secret: my-cluster-08579004-cluster-ca
2022-04-04 13:25:21 [main] [32mINFO [m [SecurityST:1443] Checking that my-cluster-08579004-cluster-ca-cert secret is still present
2022-04-04 13:25:21 [main] [32mINFO [m [SecurityST:1446] Deleting secret: my-cluster-08579004-cluster-ca-cert
2022-04-04 13:25:21 [main] [32mINFO [m [SecurityST:1450] Deploying Kafka with generateSecretOwnerReference set to true
2022-04-04 13:25:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-second-cluster-my-cluster-08579004 in namespace namespace-65
2022-04-04 13:25:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-65
2022-04-04 13:25:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-second-cluster-my-cluster-08579004 will have desired state: Ready
2022-04-04 13:27:44 [main] [32mINFO [m [ResourceManager:444] Kafka: my-second-cluster-my-cluster-08579004 is in desired state: Ready
2022-04-04 13:27:44 [main] [32mINFO [m [SecurityST:1465] Deleting Kafka:my-second-cluster-my-cluster-08579004
2022-04-04 13:27:44 [main] [32mINFO [m [KafkaUtils:399] Waiting for deletion of Kafka:my-second-cluster-my-cluster-08579004
2022-04-04 13:27:46 [main] [32mINFO [m [SecurityST:1469] Checking actual secrets after Kafka deletion
2022-04-04 13:27:46 [main] [32mINFO [m [SecurityST:1472] Checking that my-second-cluster-my-cluster-08579004-clients-ca secret is deleted
2022-04-04 13:27:46 [main] [32mINFO [m [SecurityST:1472] Checking that my-second-cluster-my-cluster-08579004-clients-ca-cert secret is deleted
2022-04-04 13:27:46 [main] [32mINFO [m [SecurityST:1472] Checking that my-second-cluster-my-cluster-08579004-cluster-ca secret is deleted
2022-04-04 13:27:46 [main] [32mINFO [m [SecurityST:1472] Checking that my-second-cluster-my-cluster-08579004-cluster-ca-cert secret is deleted
2022-04-04 13:27:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 13:27:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testOwnerReferenceOfCASecrets
2022-04-04 13:27:46 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-second-cluster-my-cluster-08579004 in namespace namespace-65
2022-04-04 13:27:46 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-08579004 in namespace namespace-65
2022-04-04 13:27:46 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 13:27:46 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-65 for test case:testOwnerReferenceOfCASecrets
2022-04-04 13:28:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testOwnerReferenceOfCASecrets-FINISHED
2022-04-04 13:28:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 13:28:29 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 13:28:29 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoRenewClientsCaCertsTriggeredByAnno-STARTED
2022-04-04 13:28:29 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 13:28:29 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-66 for test case:testAutoRenewClientsCaCertsTriggeredByAnno
2022-04-04 13:28:29 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-66
2022-04-04 13:28:29 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-66
2022-04-04 13:28:29 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-66
2022-04-04 13:28:29 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-04 13:28:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5e165093 in namespace namespace-66
2022-04-04 13:28:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-66
2022-04-04 13:28:29 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5e165093 will have desired state: Ready
2022-04-04 13:31:38 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5e165093 is in desired state: Ready
2022-04-04 13:31:38 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1660015998-1528051069 in namespace namespace-66
2022-04-04 13:31:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-66
2022-04-04 13:31:38 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1660015998-1528051069 will have desired state: Ready
2022-04-04 13:31:39 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1660015998-1528051069 is in desired state: Ready
2022-04-04 13:31:39 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1199795749-1401748660 in namespace namespace-66
2022-04-04 13:31:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-66
2022-04-04 13:31:39 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1199795749-1401748660 will have desired state: Ready
2022-04-04 13:31:40 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1199795749-1401748660 is in desired state: Ready
2022-04-04 13:31:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-5e165093-kafka-clients in namespace namespace-66
2022-04-04 13:31:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-66
2022-04-04 13:31:40 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-5e165093-kafka-clients will be ready
2022-04-04 13:31:42 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-5e165093-kafka-clients is ready
2022-04-04 13:31:42 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 13:31:42 [main] [32mINFO [m [SecurityST:260] Checking produced and consumed messages to pod:my-cluster-5e165093-kafka-clients-6cd676897c-z5v89
2022-04-04 13:31:42 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@32da0224, messages=[], arguments=[--topic, my-topic-1199795749-1401748660, --max-messages, 100, --bootstrap-server, my-cluster-5e165093-kafka-bootstrap.namespace-66.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-5e165093-kafka-clients-6cd676897c-z5v89', podNamespace='namespace-66', bootstrapServer='my-cluster-5e165093-kafka-bootstrap.namespace-66.svc:9092', topicName='my-topic-1199795749-1401748660', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@78a2d456}
2022-04-04 13:31:42 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-5e165093-kafka-bootstrap.namespace-66.svc:9092:my-topic-1199795749-1401748660 from pod my-cluster-5e165093-kafka-clients-6cd676897c-z5v89
2022-04-04 13:31:42 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5e165093-kafka-clients-6cd676897c-z5v89 -n namespace-66 -- /opt/kafka/producer.sh --topic my-topic-1199795749-1401748660 --max-messages 100 --bootstrap-server my-cluster-5e165093-kafka-bootstrap.namespace-66.svc:9092
2022-04-04 13:31:44 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 13:31:44 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 13:31:44 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5d9e0453, messages=[], arguments=[--topic, my-topic-1199795749-1401748660, --max-messages, 100, --group-instance-id, instance1367693941, --group-id, my-consumer-group-1755132400, --bootstrap-server, my-cluster-5e165093-kafka-bootstrap.namespace-66.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-5e165093-kafka-clients-6cd676897c-z5v89', podNamespace='namespace-66', bootstrapServer='my-cluster-5e165093-kafka-bootstrap.namespace-66.svc:9092', topicName='my-topic-1199795749-1401748660', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1755132400', consumerInstanceId='instance1367693941', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@33f0661f}
2022-04-04 13:31:44 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-5e165093-kafka-bootstrap.namespace-66.svc:9092#my-topic-1199795749-1401748660 from pod my-cluster-5e165093-kafka-clients-6cd676897c-z5v89
2022-04-04 13:31:44 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5e165093-kafka-clients-6cd676897c-z5v89 -n namespace-66 -- /opt/kafka/consumer.sh --topic my-topic-1199795749-1401748660 --max-messages 100 --group-instance-id instance1367693941 --group-id my-consumer-group-1755132400 --bootstrap-server my-cluster-5e165093-kafka-bootstrap.namespace-66.svc:9092
2022-04-04 13:31:50 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 13:31:50 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 13:31:50 [main] [32mINFO [m [SecurityST:274] Triggering CA cert renewal by adding the annotation
2022-04-04 13:31:50 [main] [32mINFO [m [SecurityST:286] Patching secret my-cluster-5e165093-clients-ca-cert with strimzi.io/force-renew
2022-04-04 13:31:50 [main] [32mINFO [m [SecurityST:295] Wait for kafka to rolling restart ...
2022-04-04 13:31:50 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-5e165093-kafka rolling update
2022-04-04 13:33:15 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-5e165093-kafka has been successfully rolled
2022-04-04 13:33:15 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-5e165093-kafka to be ready
2022-04-04 13:33:49 [main] [32mINFO [m [SecurityST:308] Checking the certificates have been replaced
2022-04-04 13:33:49 [main] [32mINFO [m [SecurityST:322] Checking consumed messages to pod:my-cluster-5e165093-kafka-clients-6cd676897c-z5v89
2022-04-04 13:33:49 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1051b86f, messages=[], arguments=[--topic, my-topic-1199795749-1401748660, --max-messages, 100, --group-instance-id, instance1814265885, --group-id, my-consumer-group-344223100, --bootstrap-server, my-cluster-5e165093-kafka-bootstrap.namespace-66.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-5e165093-kafka-clients-6cd676897c-z5v89', podNamespace='namespace-66', bootstrapServer='my-cluster-5e165093-kafka-bootstrap.namespace-66.svc:9092', topicName='my-topic-1199795749-1401748660', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-344223100', consumerInstanceId='instance1814265885', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@67b19b53}
2022-04-04 13:33:49 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-5e165093-kafka-bootstrap.namespace-66.svc:9092#my-topic-1199795749-1401748660 from pod my-cluster-5e165093-kafka-clients-6cd676897c-z5v89
2022-04-04 13:33:49 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5e165093-kafka-clients-6cd676897c-z5v89 -n namespace-66 -- /opt/kafka/consumer.sh --topic my-topic-1199795749-1401748660 --max-messages 100 --group-instance-id instance1814265885 --group-id my-consumer-group-344223100 --bootstrap-server my-cluster-5e165093-kafka-bootstrap.namespace-66.svc:9092
2022-04-04 13:33:55 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 13:33:55 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 13:33:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser bob-my-cluster-5e165093 in namespace namespace-66
2022-04-04 13:33:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-66
2022-04-04 13:33:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: bob-my-cluster-5e165093 will have desired state: Ready
2022-04-04 13:33:56 [main] [32mINFO [m [ResourceManager:444] KafkaUser: bob-my-cluster-5e165093 is in desired state: Ready
2022-04-04 13:33:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-5e165093-kafka-clients-tls in namespace namespace-66
2022-04-04 13:33:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-66
2022-04-04 13:33:56 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-5e165093-kafka-clients-tls will be ready
2022-04-04 13:33:58 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-5e165093-kafka-clients-tls is ready
2022-04-04 13:33:58 [main] [32mINFO [m [SecurityST:346] Checking consumed messages to pod:my-cluster-5e165093-kafka-clients-tls-7894f9464b-ds42n
2022-04-04 13:33:58 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@62824af7, messages=[], arguments=[--topic, my-topic-1199795749-1401748660, --max-messages, 100, --group-instance-id, instance363912778, USER=bob_my_cluster_5e165093, --group-id, my-consumer-group-502429282, --bootstrap-server, my-cluster-5e165093-kafka-bootstrap.namespace-66.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-5e165093-kafka-clients-tls-7894f9464b-ds42n', podNamespace='namespace-66', bootstrapServer='my-cluster-5e165093-kafka-bootstrap.namespace-66.svc:9093', topicName='my-topic-1199795749-1401748660', maxMessages=100, kafkaUsername='bob-my-cluster-5e165093', consumerGroupName='my-consumer-group-502429282', consumerInstanceId='instance363912778', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@9823397}
2022-04-04 13:33:58 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-5e165093-kafka-bootstrap.namespace-66.svc:9093#my-topic-1199795749-1401748660 from pod my-cluster-5e165093-kafka-clients-tls-7894f9464b-ds42n
2022-04-04 13:33:58 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5e165093-kafka-clients-tls-7894f9464b-ds42n -n namespace-66 -- /opt/kafka/consumer.sh --topic my-topic-1199795749-1401748660 --max-messages 100 --group-instance-id instance363912778 USER=bob_my_cluster_5e165093 --group-id my-consumer-group-502429282 --bootstrap-server my-cluster-5e165093-kafka-bootstrap.namespace-66.svc:9093
2022-04-04 13:34:05 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 13:34:05 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 13:34:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 13:34:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoRenewClientsCaCertsTriggeredByAnno
2022-04-04 13:34:05 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-5e165093-kafka-clients in namespace namespace-66
2022-04-04 13:34:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5e165093 in namespace namespace-66
2022-04-04 13:34:05 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-5e165093-kafka-clients-tls in namespace namespace-66
2022-04-04 13:34:05 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1199795749-1401748660 in namespace namespace-66
2022-04-04 13:34:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-66, for cruise control Kafka cluster my-cluster-5e165093
2022-04-04 13:34:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1660015998-1528051069 in namespace namespace-66
2022-04-04 13:34:05 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaUser bob-my-cluster-5e165093 in namespace namespace-66
2022-04-04 13:34:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 13:34:55 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-66 for test case:testAutoRenewClientsCaCertsTriggeredByAnno
2022-04-04 13:35:02 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoRenewClientsCaCertsTriggeredByAnno-FINISHED
2022-04-04 13:35:02 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 13:35:02 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 13:35:02 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno-STARTED
2022-04-04 13:35:02 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 13:35:02 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-67 for test case:testAutoReplaceClusterCaKeysTriggeredByAnno
2022-04-04 13:35:02 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-67
2022-04-04 13:35:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-67
2022-04-04 13:35:02 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-67
2022-04-04 13:35:02 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-04 13:35:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-889bc1a1 in namespace namespace-67
2022-04-04 13:35:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-67
2022-04-04 13:35:02 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-889bc1a1 will have desired state: Ready
2022-04-04 13:37:44 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-889bc1a1 is in desired state: Ready
2022-04-04 13:37:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1968699200-507363078 in namespace namespace-67
2022-04-04 13:37:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-67
2022-04-04 13:37:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1968699200-507363078 will have desired state: Ready
2022-04-04 13:37:45 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1968699200-507363078 is in desired state: Ready
2022-04-04 13:37:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1235895205-21321177 in namespace namespace-67
2022-04-04 13:37:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-67
2022-04-04 13:37:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1235895205-21321177 will have desired state: Ready
2022-04-04 13:37:46 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1235895205-21321177 is in desired state: Ready
2022-04-04 13:37:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-889bc1a1-kafka-clients in namespace namespace-67
2022-04-04 13:37:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-67
2022-04-04 13:37:46 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-889bc1a1-kafka-clients will be ready
2022-04-04 13:37:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-889bc1a1-kafka-clients is ready
2022-04-04 13:37:48 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 13:37:48 [main] [32mINFO [m [SecurityST:453] Checking produced and consumed messages to pod:my-cluster-889bc1a1-kafka-clients-9f68f5985-w25hk
2022-04-04 13:37:48 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@30d88d5e, messages=[], arguments=[--topic, my-topic-1235895205-21321177, --max-messages, 100, --bootstrap-server, my-cluster-889bc1a1-kafka-bootstrap.namespace-67.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-889bc1a1-kafka-clients-9f68f5985-w25hk', podNamespace='namespace-67', bootstrapServer='my-cluster-889bc1a1-kafka-bootstrap.namespace-67.svc:9092', topicName='my-topic-1235895205-21321177', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@51438d11}
2022-04-04 13:37:48 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-889bc1a1-kafka-bootstrap.namespace-67.svc:9092:my-topic-1235895205-21321177 from pod my-cluster-889bc1a1-kafka-clients-9f68f5985-w25hk
2022-04-04 13:37:48 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-889bc1a1-kafka-clients-9f68f5985-w25hk -n namespace-67 -- /opt/kafka/producer.sh --topic my-topic-1235895205-21321177 --max-messages 100 --bootstrap-server my-cluster-889bc1a1-kafka-bootstrap.namespace-67.svc:9092
2022-04-04 13:37:51 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 13:37:51 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 13:37:51 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@65fe5b12, messages=[], arguments=[--topic, my-topic-1235895205-21321177, --max-messages, 100, --group-instance-id, instance1212609420, --group-id, my-consumer-group-22265449, --bootstrap-server, my-cluster-889bc1a1-kafka-bootstrap.namespace-67.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-889bc1a1-kafka-clients-9f68f5985-w25hk', podNamespace='namespace-67', bootstrapServer='my-cluster-889bc1a1-kafka-bootstrap.namespace-67.svc:9092', topicName='my-topic-1235895205-21321177', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-22265449', consumerInstanceId='instance1212609420', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@28987015}
2022-04-04 13:37:51 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-889bc1a1-kafka-bootstrap.namespace-67.svc:9092#my-topic-1235895205-21321177 from pod my-cluster-889bc1a1-kafka-clients-9f68f5985-w25hk
2022-04-04 13:37:51 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-889bc1a1-kafka-clients-9f68f5985-w25hk -n namespace-67 -- /opt/kafka/consumer.sh --topic my-topic-1235895205-21321177 --max-messages 100 --group-instance-id instance1212609420 --group-id my-consumer-group-22265449 --bootstrap-server my-cluster-889bc1a1-kafka-bootstrap.namespace-67.svc:9092
2022-04-04 13:37:57 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 13:37:57 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 13:37:57 [main] [32mINFO [m [SecurityST:467] Triggering CA cert renewal by adding the annotation
2022-04-04 13:37:57 [main] [32mINFO [m [SecurityST:479] Patching secret my-cluster-889bc1a1-cluster-ca with strimzi.io/force-replace
2022-04-04 13:37:57 [main] [32mINFO [m [SecurityST:484] Wait for zk to rolling restart (1)...
2022-04-04 13:37:57 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-889bc1a1-zookeeper rolling update
2022-04-04 13:39:02 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-889bc1a1-zookeeper has been successfully rolled
2022-04-04 13:39:02 [main] [32mINFO [m [SecurityST:489] Wait for kafka to rolling restart (1)...
2022-04-04 13:39:02 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-889bc1a1-kafka rolling update
2022-04-04 13:40:42 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-889bc1a1-kafka has been successfully rolled
2022-04-04 13:40:42 [main] [32mINFO [m [SecurityST:494] Wait for EO to rolling restart (1)...
2022-04-04 13:40:42 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-889bc1a1-entity-operator rolling update
2022-04-04 13:41:07 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-889bc1a1-entity-operator will be ready
2022-04-04 13:41:51 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-889bc1a1-entity-operator is ready
2022-04-04 13:42:01 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-889bc1a1-entity-operator rolling update finished
2022-04-04 13:42:01 [main] [32mINFO [m [SecurityST:499] Wait for KafkaExporter and CruiseControl to rolling restart (1)...
2022-04-04 13:42:01 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-889bc1a1-kafka-exporter rolling update
2022-04-04 13:42:01 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-889bc1a1-kafka-exporter will be ready
2022-04-04 13:42:22 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-889bc1a1-kafka-exporter is ready
2022-04-04 13:42:32 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-889bc1a1-kafka-exporter rolling update finished
2022-04-04 13:42:32 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-889bc1a1-cruise-control rolling update
2022-04-04 13:42:32 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-889bc1a1-cruise-control will be ready
2022-04-04 13:42:40 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-889bc1a1-cruise-control is ready
2022-04-04 13:42:50 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-889bc1a1-cruise-control rolling update finished
2022-04-04 13:42:50 [main] [32mINFO [m [SecurityST:505] Wait for zk to rolling restart (2)...
2022-04-04 13:42:50 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-889bc1a1-zookeeper rolling update
2022-04-04 13:43:55 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-889bc1a1-zookeeper has been successfully rolled
2022-04-04 13:43:55 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-889bc1a1-zookeeper to be ready
2022-04-04 13:44:26 [main] [32mINFO [m [SecurityST:510] Wait for kafka to rolling restart (2)...
2022-04-04 13:44:26 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-889bc1a1-kafka rolling update
2022-04-04 13:45:36 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-889bc1a1-kafka has been successfully rolled
2022-04-04 13:45:36 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-889bc1a1-kafka to be ready
2022-04-04 13:46:08 [main] [32mINFO [m [SecurityST:515] Wait for EO to rolling restart (2)...
2022-04-04 13:46:08 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-889bc1a1-entity-operator rolling update
2022-04-04 13:46:08 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-889bc1a1-entity-operator will be ready
2022-04-04 13:46:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-889bc1a1-entity-operator is ready
2022-04-04 13:46:58 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-889bc1a1-entity-operator rolling update finished
2022-04-04 13:46:58 [main] [32mINFO [m [SecurityST:520] Wait for KafkaExporter and CruiseControl to rolling restart (2)...
2022-04-04 13:46:58 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-889bc1a1-kafka-exporter rolling update
2022-04-04 13:47:38 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-889bc1a1-kafka-exporter will be ready
2022-04-04 13:47:38 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-889bc1a1-kafka-exporter is ready
2022-04-04 13:47:48 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-889bc1a1-kafka-exporter rolling update finished
2022-04-04 13:47:48 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-889bc1a1-cruise-control rolling update
2022-04-04 13:47:48 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-889bc1a1-cruise-control will be ready
2022-04-04 13:47:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-889bc1a1-cruise-control is ready
2022-04-04 13:47:58 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-889bc1a1-cruise-control rolling update finished
2022-04-04 13:47:58 [main] [32mINFO [m [SecurityST:525] Checking the certificates have been replaced
2022-04-04 13:47:58 [main] [32mINFO [m [SecurityST:536] Checking consumed messages to pod:my-cluster-889bc1a1-kafka-clients-9f68f5985-w25hk
2022-04-04 13:47:58 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@735a2243, messages=[], arguments=[--topic, my-topic-1235895205-21321177, --max-messages, 100, --group-instance-id, instance617760575, --group-id, my-consumer-group-421768649, --bootstrap-server, my-cluster-889bc1a1-kafka-bootstrap.namespace-67.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-889bc1a1-kafka-clients-9f68f5985-w25hk', podNamespace='namespace-67', bootstrapServer='my-cluster-889bc1a1-kafka-bootstrap.namespace-67.svc:9092', topicName='my-topic-1235895205-21321177', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-421768649', consumerInstanceId='instance617760575', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@52aaa2ea}
2022-04-04 13:47:58 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-889bc1a1-kafka-bootstrap.namespace-67.svc:9092#my-topic-1235895205-21321177 from pod my-cluster-889bc1a1-kafka-clients-9f68f5985-w25hk
2022-04-04 13:47:58 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-889bc1a1-kafka-clients-9f68f5985-w25hk -n namespace-67 -- /opt/kafka/consumer.sh --topic my-topic-1235895205-21321177 --max-messages 100 --group-instance-id instance617760575 --group-id my-consumer-group-421768649 --bootstrap-server my-cluster-889bc1a1-kafka-bootstrap.namespace-67.svc:9092
2022-04-04 13:48:04 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 13:48:04 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 13:48:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-885611732-251832674 in namespace namespace-67
2022-04-04 13:48:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-67
2022-04-04 13:48:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-885611732-251832674 will have desired state: Ready
2022-04-04 13:48:05 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-885611732-251832674 is in desired state: Ready
2022-04-04 13:48:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-889bc1a1-kafka-clients-tls in namespace namespace-67
2022-04-04 13:48:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-67
2022-04-04 13:48:05 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-889bc1a1-kafka-clients-tls will be ready
2022-04-04 13:48:07 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-889bc1a1-kafka-clients-tls is ready
2022-04-04 13:48:07 [main] [32mINFO [m [SecurityST:561] Checking consumed messages to pod:my-cluster-889bc1a1-kafka-clients-tls-5455966978-5lswj
2022-04-04 13:48:07 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5630c8f1, messages=[], arguments=[--topic, my-topic-1235895205-21321177, --max-messages, 100, --group-instance-id, instance604672613, --group-id, my-consumer-group-502632293, --bootstrap-server, my-cluster-889bc1a1-kafka-bootstrap.namespace-67.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-889bc1a1-kafka-clients-tls-5455966978-5lswj', podNamespace='namespace-67', bootstrapServer='my-cluster-889bc1a1-kafka-bootstrap.namespace-67.svc:9092', topicName='my-topic-1235895205-21321177', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-502632293', consumerInstanceId='instance604672613', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@518a8dd8}
2022-04-04 13:48:07 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-889bc1a1-kafka-bootstrap.namespace-67.svc:9092#my-topic-1235895205-21321177 from pod my-cluster-889bc1a1-kafka-clients-tls-5455966978-5lswj
2022-04-04 13:48:07 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-889bc1a1-kafka-clients-tls-5455966978-5lswj -n namespace-67 -- /opt/kafka/consumer.sh --topic my-topic-1235895205-21321177 --max-messages 100 --group-instance-id instance604672613 --group-id my-consumer-group-502632293 --bootstrap-server my-cluster-889bc1a1-kafka-bootstrap.namespace-67.svc:9092
2022-04-04 13:48:13 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 13:48:13 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 13:48:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 13:48:13 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoReplaceClusterCaKeysTriggeredByAnno
2022-04-04 13:48:13 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-889bc1a1-kafka-clients in namespace namespace-67
2022-04-04 13:48:13 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-889bc1a1 in namespace namespace-67
2022-04-04 13:48:13 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-67, for cruise control Kafka cluster my-cluster-889bc1a1
2022-04-04 13:48:13 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-889bc1a1-kafka-clients-tls in namespace namespace-67
2022-04-04 13:48:13 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1235895205-21321177 in namespace namespace-67
2022-04-04 13:48:13 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-885611732-251832674 in namespace namespace-67
2022-04-04 13:48:13 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1968699200-507363078 in namespace namespace-67
2022-04-04 13:49:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 13:49:13 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-67 for test case:testAutoReplaceClusterCaKeysTriggeredByAnno
2022-04-04 13:49:19 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno-FINISHED
2022-04-04 13:49:19 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 13:49:19 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 13:49:19 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoReplaceAllCaKeysTriggeredByAnno-STARTED
2022-04-04 13:49:19 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 13:49:19 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-68 for test case:testAutoReplaceAllCaKeysTriggeredByAnno
2022-04-04 13:49:19 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-68
2022-04-04 13:49:19 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-68
2022-04-04 13:49:19 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-68
2022-04-04 13:49:19 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-04 13:49:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-14afbd5a in namespace namespace-68
2022-04-04 13:49:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-68
2022-04-04 13:49:19 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-14afbd5a will have desired state: Ready
2022-04-04 13:51:26 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-14afbd5a is in desired state: Ready
2022-04-04 13:51:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1462699543-1968266507 in namespace namespace-68
2022-04-04 13:51:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-68
2022-04-04 13:51:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1462699543-1968266507 will have desired state: Ready
2022-04-04 13:51:27 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1462699543-1968266507 is in desired state: Ready
2022-04-04 13:51:27 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1632301831-394096799 in namespace namespace-68
2022-04-04 13:51:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-68
2022-04-04 13:51:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1632301831-394096799 will have desired state: Ready
2022-04-04 13:51:28 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1632301831-394096799 is in desired state: Ready
2022-04-04 13:51:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-14afbd5a-kafka-clients in namespace namespace-68
2022-04-04 13:51:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-68
2022-04-04 13:51:28 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-14afbd5a-kafka-clients will be ready
2022-04-04 13:51:30 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-14afbd5a-kafka-clients is ready
2022-04-04 13:51:30 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 13:51:30 [main] [32mINFO [m [SecurityST:453] Checking produced and consumed messages to pod:my-cluster-14afbd5a-kafka-clients-6b655c485b-2f62j
2022-04-04 13:51:30 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@71e8a99b, messages=[], arguments=[--topic, my-topic-1632301831-394096799, --max-messages, 100, --bootstrap-server, my-cluster-14afbd5a-kafka-bootstrap.namespace-68.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-14afbd5a-kafka-clients-6b655c485b-2f62j', podNamespace='namespace-68', bootstrapServer='my-cluster-14afbd5a-kafka-bootstrap.namespace-68.svc:9092', topicName='my-topic-1632301831-394096799', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4fd44b7c}
2022-04-04 13:51:30 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-14afbd5a-kafka-bootstrap.namespace-68.svc:9092:my-topic-1632301831-394096799 from pod my-cluster-14afbd5a-kafka-clients-6b655c485b-2f62j
2022-04-04 13:51:30 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-14afbd5a-kafka-clients-6b655c485b-2f62j -n namespace-68 -- /opt/kafka/producer.sh --topic my-topic-1632301831-394096799 --max-messages 100 --bootstrap-server my-cluster-14afbd5a-kafka-bootstrap.namespace-68.svc:9092
2022-04-04 13:51:32 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 13:51:32 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 13:51:32 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@59747e36, messages=[], arguments=[--topic, my-topic-1632301831-394096799, --max-messages, 100, --group-instance-id, instance1137984139, --group-id, my-consumer-group-346850429, --bootstrap-server, my-cluster-14afbd5a-kafka-bootstrap.namespace-68.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-14afbd5a-kafka-clients-6b655c485b-2f62j', podNamespace='namespace-68', bootstrapServer='my-cluster-14afbd5a-kafka-bootstrap.namespace-68.svc:9092', topicName='my-topic-1632301831-394096799', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-346850429', consumerInstanceId='instance1137984139', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@34964c73}
2022-04-04 13:51:32 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-14afbd5a-kafka-bootstrap.namespace-68.svc:9092#my-topic-1632301831-394096799 from pod my-cluster-14afbd5a-kafka-clients-6b655c485b-2f62j
2022-04-04 13:51:32 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-14afbd5a-kafka-clients-6b655c485b-2f62j -n namespace-68 -- /opt/kafka/consumer.sh --topic my-topic-1632301831-394096799 --max-messages 100 --group-instance-id instance1137984139 --group-id my-consumer-group-346850429 --bootstrap-server my-cluster-14afbd5a-kafka-bootstrap.namespace-68.svc:9092
2022-04-04 13:51:38 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 13:51:38 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 13:51:38 [main] [32mINFO [m [SecurityST:467] Triggering CA cert renewal by adding the annotation
2022-04-04 13:51:38 [main] [32mINFO [m [SecurityST:479] Patching secret my-cluster-14afbd5a-cluster-ca with strimzi.io/force-replace
2022-04-04 13:51:38 [main] [32mINFO [m [SecurityST:479] Patching secret my-cluster-14afbd5a-clients-ca with strimzi.io/force-replace
2022-04-04 13:51:38 [main] [32mINFO [m [SecurityST:484] Wait for zk to rolling restart (1)...
2022-04-04 13:51:38 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-14afbd5a-zookeeper rolling update
2022-04-04 13:53:18 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-14afbd5a-zookeeper has been successfully rolled
2022-04-04 13:53:18 [main] [32mINFO [m [SecurityST:489] Wait for kafka to rolling restart (1)...
2022-04-04 13:53:18 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-14afbd5a-kafka rolling update
2022-04-04 13:54:44 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-14afbd5a-kafka has been successfully rolled
2022-04-04 13:54:44 [main] [32mINFO [m [SecurityST:494] Wait for EO to rolling restart (1)...
2022-04-04 13:54:44 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-14afbd5a-entity-operator rolling update
2022-04-04 13:55:04 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-14afbd5a-entity-operator will be ready
2022-04-04 13:55:47 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-14afbd5a-entity-operator is ready
2022-04-04 13:55:57 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-14afbd5a-entity-operator rolling update finished
2022-04-04 13:55:57 [main] [32mINFO [m [SecurityST:499] Wait for KafkaExporter and CruiseControl to rolling restart (1)...
2022-04-04 13:55:57 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-14afbd5a-kafka-exporter rolling update
2022-04-04 13:55:57 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-14afbd5a-kafka-exporter will be ready
2022-04-04 13:56:07 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-14afbd5a-kafka-exporter is ready
2022-04-04 13:56:17 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-14afbd5a-kafka-exporter rolling update finished
2022-04-04 13:56:17 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-14afbd5a-cruise-control rolling update
2022-04-04 13:56:17 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-14afbd5a-cruise-control will be ready
2022-04-04 13:56:28 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-14afbd5a-cruise-control is ready
2022-04-04 13:56:38 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-14afbd5a-cruise-control rolling update finished
2022-04-04 13:56:38 [main] [32mINFO [m [SecurityST:505] Wait for zk to rolling restart (2)...
2022-04-04 13:56:38 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-14afbd5a-zookeeper rolling update
2022-04-04 13:57:18 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-14afbd5a-zookeeper has been successfully rolled
2022-04-04 13:57:18 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-14afbd5a-zookeeper to be ready
2022-04-04 13:57:47 [main] [32mINFO [m [SecurityST:510] Wait for kafka to rolling restart (2)...
2022-04-04 13:57:47 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-14afbd5a-kafka rolling update
2022-04-04 13:59:08 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-14afbd5a-kafka has been successfully rolled
2022-04-04 13:59:08 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-14afbd5a-kafka to be ready
2022-04-04 13:59:38 [main] [32mINFO [m [SecurityST:515] Wait for EO to rolling restart (2)...
2022-04-04 13:59:38 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-14afbd5a-entity-operator rolling update
2022-04-04 13:59:38 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-14afbd5a-entity-operator will be ready
2022-04-04 14:00:20 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-14afbd5a-entity-operator is ready
2022-04-04 14:00:30 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-14afbd5a-entity-operator rolling update finished
2022-04-04 14:00:30 [main] [32mINFO [m [SecurityST:520] Wait for KafkaExporter and CruiseControl to rolling restart (2)...
2022-04-04 14:00:30 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-14afbd5a-kafka-exporter rolling update
2022-04-04 14:01:25 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-14afbd5a-kafka-exporter will be ready
2022-04-04 14:01:25 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-14afbd5a-kafka-exporter is ready
2022-04-04 14:01:35 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-14afbd5a-kafka-exporter rolling update finished
2022-04-04 14:01:35 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-14afbd5a-cruise-control rolling update
2022-04-04 14:01:35 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-14afbd5a-cruise-control will be ready
2022-04-04 14:01:35 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-14afbd5a-cruise-control is ready
2022-04-04 14:01:45 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-14afbd5a-cruise-control rolling update finished
2022-04-04 14:01:45 [main] [32mINFO [m [SecurityST:525] Checking the certificates have been replaced
2022-04-04 14:01:45 [main] [32mINFO [m [SecurityST:536] Checking consumed messages to pod:my-cluster-14afbd5a-kafka-clients-6b655c485b-2f62j
2022-04-04 14:01:45 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3d71384d, messages=[], arguments=[--topic, my-topic-1632301831-394096799, --max-messages, 100, --group-instance-id, instance1311455978, --group-id, my-consumer-group-1175147043, --bootstrap-server, my-cluster-14afbd5a-kafka-bootstrap.namespace-68.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-14afbd5a-kafka-clients-6b655c485b-2f62j', podNamespace='namespace-68', bootstrapServer='my-cluster-14afbd5a-kafka-bootstrap.namespace-68.svc:9092', topicName='my-topic-1632301831-394096799', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1175147043', consumerInstanceId='instance1311455978', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4d1020f6}
2022-04-04 14:01:45 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-14afbd5a-kafka-bootstrap.namespace-68.svc:9092#my-topic-1632301831-394096799 from pod my-cluster-14afbd5a-kafka-clients-6b655c485b-2f62j
2022-04-04 14:01:45 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-14afbd5a-kafka-clients-6b655c485b-2f62j -n namespace-68 -- /opt/kafka/consumer.sh --topic my-topic-1632301831-394096799 --max-messages 100 --group-instance-id instance1311455978 --group-id my-consumer-group-1175147043 --bootstrap-server my-cluster-14afbd5a-kafka-bootstrap.namespace-68.svc:9092
2022-04-04 14:01:51 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 14:01:51 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 14:01:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1168528859-57782052 in namespace namespace-68
2022-04-04 14:01:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-68
2022-04-04 14:01:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1168528859-57782052 will have desired state: Ready
2022-04-04 14:01:52 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1168528859-57782052 is in desired state: Ready
2022-04-04 14:01:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-14afbd5a-kafka-clients-tls in namespace namespace-68
2022-04-04 14:01:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-68
2022-04-04 14:01:52 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-14afbd5a-kafka-clients-tls will be ready
2022-04-04 14:01:54 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-14afbd5a-kafka-clients-tls is ready
2022-04-04 14:01:54 [main] [32mINFO [m [SecurityST:561] Checking consumed messages to pod:my-cluster-14afbd5a-kafka-clients-tls-b85968898-fwgtn
2022-04-04 14:01:54 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@28ff23a, messages=[], arguments=[--topic, my-topic-1632301831-394096799, --max-messages, 100, --group-instance-id, instance815094770, --group-id, my-consumer-group-241824929, --bootstrap-server, my-cluster-14afbd5a-kafka-bootstrap.namespace-68.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-14afbd5a-kafka-clients-tls-b85968898-fwgtn', podNamespace='namespace-68', bootstrapServer='my-cluster-14afbd5a-kafka-bootstrap.namespace-68.svc:9092', topicName='my-topic-1632301831-394096799', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-241824929', consumerInstanceId='instance815094770', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4ed47c86}
2022-04-04 14:01:54 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-14afbd5a-kafka-bootstrap.namespace-68.svc:9092#my-topic-1632301831-394096799 from pod my-cluster-14afbd5a-kafka-clients-tls-b85968898-fwgtn
2022-04-04 14:01:54 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-14afbd5a-kafka-clients-tls-b85968898-fwgtn -n namespace-68 -- /opt/kafka/consumer.sh --topic my-topic-1632301831-394096799 --max-messages 100 --group-instance-id instance815094770 --group-id my-consumer-group-241824929 --bootstrap-server my-cluster-14afbd5a-kafka-bootstrap.namespace-68.svc:9092
2022-04-04 14:02:00 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 14:02:00 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 14:02:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 14:02:00 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoReplaceAllCaKeysTriggeredByAnno
2022-04-04 14:02:00 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-14afbd5a-kafka-clients in namespace namespace-68
2022-04-04 14:02:00 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-14afbd5a in namespace namespace-68
2022-04-04 14:02:00 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-68, for cruise control Kafka cluster my-cluster-14afbd5a
2022-04-04 14:02:00 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-14afbd5a-kafka-clients-tls in namespace namespace-68
2022-04-04 14:02:00 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1632301831-394096799 in namespace namespace-68
2022-04-04 14:02:00 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1462699543-1968266507 in namespace namespace-68
2022-04-04 14:02:00 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1168528859-57782052 in namespace namespace-68
2022-04-04 14:03:00 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 14:03:00 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-68 for test case:testAutoReplaceAllCaKeysTriggeredByAnno
2022-04-04 14:03:06 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoReplaceAllCaKeysTriggeredByAnno-FINISHED
2022-04-04 14:03:06 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 14:03:06 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 14:03:06 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testClusterCACertRenew-STARTED
2022-04-04 14:03:06 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 14:03:06 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-69 for test case:testClusterCACertRenew
2022-04-04 14:03:06 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-69
2022-04-04 14:03:06 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-69
2022-04-04 14:03:06 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-69
2022-04-04 14:03:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3a84c54b in namespace namespace-69
2022-04-04 14:03:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-69
2022-04-04 14:03:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3a84c54b will have desired state: Ready
2022-04-04 14:04:27 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3a84c54b is in desired state: Ready
2022-04-04 14:04:27 [main] [32mINFO [m [SecurityST:1512] Change of kafka validity and renewal days - reconciliation should start.
2022-04-04 14:04:27 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-3a84c54b-zookeeper rolling update
2022-04-04 14:05:37 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-3a84c54b-zookeeper has been successfully rolled
2022-04-04 14:05:37 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-3a84c54b-zookeeper to be ready
2022-04-04 14:06:02 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-3a84c54b-kafka rolling update
2022-04-04 14:07:17 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-3a84c54b-kafka has been successfully rolled
2022-04-04 14:07:17 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-3a84c54b-kafka to be ready
2022-04-04 14:07:41 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-3a84c54b-entity-operator rolling update
2022-04-04 14:07:41 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-3a84c54b-entity-operator will be ready
2022-04-04 14:08:20 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-3a84c54b-entity-operator is ready
2022-04-04 14:08:30 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-3a84c54b-entity-operator rolling update finished
2022-04-04 14:08:30 [main] [32mINFO [m [SecurityST:1545] Initial ClusterCA cert dates: Mon Apr 04 14:03:06 UTC 2022 --> Sun Apr 24 14:03:06 UTC 2022
2022-04-04 14:08:30 [main] [32mINFO [m [SecurityST:1546] Changed ClusterCA cert dates: Mon Apr 04 14:04:28 UTC 2022 --> Fri Oct 21 14:04:28 UTC 2022
2022-04-04 14:08:30 [main] [32mINFO [m [SecurityST:1547] KafkaBroker cert creation dates: Mon Apr 04 14:03:36 UTC 2022 --> Sun Apr 24 14:03:36 UTC 2022
2022-04-04 14:08:30 [main] [32mINFO [m [SecurityST:1548] KafkaBroker cert changed dates:  Mon Apr 04 14:05:53 UTC 2022 --> Fri Oct 21 14:05:53 UTC 2022
2022-04-04 14:08:30 [main] [32mINFO [m [SecurityST:1549] Zookeeper cert creation dates: Mon Apr 04 14:03:09 UTC 2022 --> Sun Apr 24 14:03:09 UTC 2022
2022-04-04 14:08:30 [main] [32mINFO [m [SecurityST:1550] Zookeeper cert changed dates:  Mon Apr 04 14:04:29 UTC 2022 --> Fri Oct 21 14:04:29 UTC 2022
2022-04-04 14:08:30 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 14:08:30 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testClusterCACertRenew
2022-04-04 14:08:30 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3a84c54b in namespace namespace-69
2022-04-04 14:08:40 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 14:08:40 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-69 for test case:testClusterCACertRenew
2022-04-04 14:09:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testClusterCACertRenew-FINISHED
2022-04-04 14:09:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 14:09:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 14:09:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testKafkaAndKafkaConnectTlsVersion-STARTED
2022-04-04 14:09:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 14:09:07 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-70 for test case:testKafkaAndKafkaConnectTlsVersion
2022-04-04 14:09:07 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-70
2022-04-04 14:09:07 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-70
2022-04-04 14:09:07 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-70
2022-04-04 14:09:07 [main] [32mINFO [m [SecurityST:1287] Deploying Kafka cluster with the support TLSv1.2 TLS
2022-04-04 14:09:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b31b91db in namespace namespace-70
2022-04-04 14:09:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-70
2022-04-04 14:09:07 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b31b91db will have desired state: Ready
2022-04-04 14:10:18 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b31b91db is in desired state: Ready
2022-04-04 14:10:18 [main] [32mINFO [m [SecurityST:1299] Verifying that Kafka cluster has the accepted configuration:
ssl.enabled.protocols -> TLSv1.2
ssl.protocol -> TLSv1.3
2022-04-04 14:10:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b31b91db-kafka-clients in namespace namespace-70
2022-04-04 14:10:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-70
2022-04-04 14:10:18 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b31b91db-kafka-clients will be ready
2022-04-04 14:10:20 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b31b91db-kafka-clients is ready
2022-04-04 14:10:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b31b91db-scraper in namespace namespace-70
2022-04-04 14:10:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-70
2022-04-04 14:10:20 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b31b91db-scraper will be ready
2022-04-04 14:10:22 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b31b91db-scraper is ready
2022-04-04 14:10:22 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-b31b91db-scraper to be ready
2022-04-04 14:10:32 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-b31b91db-scraper is ready
2022-04-04 14:10:32 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-b31b91db-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 14:10:32 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-b31b91db-allow in namespace namespace-70
2022-04-04 14:10:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-70
2022-04-04 14:10:32 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 14:10:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-b31b91db in namespace namespace-70
2022-04-04 14:10:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-70
2022-04-04 14:10:32 [main] [32mINFO [m [SecurityST:1322] Verifying that Kafka Connect status is NotReady because of different TLS version
2022-04-04 14:10:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-b31b91db will have desired state: NotReady
2022-04-04 14:15:33 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-b31b91db is in desired state: NotReady
2022-04-04 14:15:33 [main] [32mINFO [m [SecurityST:1326] Replacing Kafka Connect config to the newest(TLSv1.2) one same as the Kafka broker has.
2022-04-04 14:15:33 [main] [32mINFO [m [SecurityST:1330] Verifying that Kafka Connect has the accepted configuration:
 ssl.enabled.protocols -> TLSv1.2
 ssl.protocol -> TLSv1.3
2022-04-04 14:15:33 [main] [32mINFO [m [KafkaConnectUtils:101] Waiting for Kafka Connect property ssl.enabled.protocols -> TLSv1.2 change
2022-04-04 14:15:33 [main] [32mINFO [m [KafkaConnectUtils:109] Kafka Connect property ssl.enabled.protocols -> TLSv1.2 change
2022-04-04 14:15:33 [main] [32mINFO [m [KafkaConnectUtils:101] Waiting for Kafka Connect property ssl.protocol -> TLSv1.3 change
2022-04-04 14:15:33 [main] [32mINFO [m [KafkaConnectUtils:109] Kafka Connect property ssl.protocol -> TLSv1.3 change
2022-04-04 14:15:33 [main] [32mINFO [m [SecurityST:1339] Verifying that Kafka Connect is stable
2022-04-04 14:15:33 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-b31b91db-connect are stable
2022-04-04 14:15:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 14:15:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 14:15:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 14:15:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 14:15:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 14:15:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 14:15:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 14:15:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 14:15:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 14:15:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 14:15:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 14:15:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 14:15:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 14:15:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 14:15:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 14:15:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 14:15:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 14:15:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 14:15:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 14:15:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 14:15:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 14:15:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 14:15:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 14:15:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 14:15:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 14:15:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 14:15:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 14:16:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 14:16:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 14:16:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 14:16:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 14:16:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 14:16:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 14:16:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 14:16:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 14:16:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 14:16:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 14:16:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 14:16:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 14:16:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 14:16:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 14:16:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 14:16:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 14:16:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 14:16:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 14:16:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 14:16:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 14:16:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 14:16:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 14:16:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-b31b91db-connect-bbc6dc46b-mthlv is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 14:16:22 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-b31b91db-connect-bbc6dc46b-mthlv
2022-04-04 14:16:22 [main] [32mINFO [m [SecurityST:1343] Verifying that Kafka Connect status is Ready because of same TLS version
2022-04-04 14:16:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-b31b91db will have desired state: Ready
2022-04-04 14:21:38 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-b31b91db is in desired state: Ready
2022-04-04 14:21:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 14:21:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaAndKafkaConnectTlsVersion
2022-04-04 14:21:38 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b31b91db-scraper in namespace namespace-70
2022-04-04 14:21:38 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b31b91db in namespace namespace-70
2022-04-04 14:21:38 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b31b91db-kafka-clients in namespace namespace-70
2022-04-04 14:21:38 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-b31b91db-allow in namespace namespace-70
2022-04-04 14:21:38 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-b31b91db in namespace namespace-70
2022-04-04 14:22:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 14:22:28 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-70 for test case:testKafkaAndKafkaConnectTlsVersion
2022-04-04 14:22:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testKafkaAndKafkaConnectTlsVersion-FINISHED
2022-04-04 14:22:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 14:22:34 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 14:22:34 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testTlsHostnameVerificationWithKafkaConnect-STARTED
2022-04-04 14:22:34 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 14:22:34 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-71 for test case:testTlsHostnameVerificationWithKafkaConnect
2022-04-04 14:22:34 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-71
2022-04-04 14:22:34 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-71
2022-04-04 14:22:34 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-71
2022-04-04 14:22:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c508638b in namespace namespace-71
2022-04-04 14:22:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-71
2022-04-04 14:22:34 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c508638b will have desired state: Ready
2022-04-04 14:23:52 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c508638b is in desired state: Ready
2022-04-04 14:23:52 [main] [32mINFO [m [SecurityST:838] Getting IP of the bootstrap service
2022-04-04 14:23:52 [main] [32mINFO [m [SecurityST:842] KafkaConnect without config ssl.endpoint.identification.algorithm will not connect to 10.111.31.128:9093
2022-04-04 14:23:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-c508638b-kafka-clients in namespace namespace-71
2022-04-04 14:23:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-71
2022-04-04 14:23:52 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c508638b-kafka-clients will be ready
2022-04-04 14:23:54 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c508638b-kafka-clients is ready
2022-04-04 14:23:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-c508638b-scraper in namespace namespace-71
2022-04-04 14:23:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-71
2022-04-04 14:23:54 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c508638b-scraper will be ready
2022-04-04 14:23:56 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c508638b-scraper is ready
2022-04-04 14:23:56 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-c508638b-scraper to be ready
2022-04-04 14:24:06 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-c508638b-scraper is ready
2022-04-04 14:24:06 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-c508638b-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 14:24:06 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-c508638b-allow in namespace namespace-71
2022-04-04 14:24:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-71
2022-04-04 14:24:06 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 14:24:06 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-c508638b in namespace namespace-71
2022-04-04 14:24:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-71
2022-04-04 14:24:06 [main] [32mINFO [m [PodUtils:245] Wait until Pod my-cluster-c508638b-connect is present
2022-04-04 14:24:07 [main] [32mINFO [m [PodUtils:249] Pod my-cluster-c508638b-connect is present
2022-04-04 14:24:07 [main] [32mINFO [m [PodUtils:236] Wait until Pod my-cluster-c508638b-connect-985787f77-ks8ds is in CrashLoopBackOff state
2022-04-04 14:24:24 [main] [32mINFO [m [PodUtils:241] Pod my-cluster-c508638b-connect-985787f77-ks8ds is in CrashLoopBackOff state
2022-04-04 14:24:24 [main] [32mINFO [m [SecurityST:872] KafkaConnect with config ssl.endpoint.identification.algorithm will connect to 10.111.31.128:9093
2022-04-04 14:24:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-c508638b will have desired state: Ready
2022-04-04 14:30:10 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-c508638b is in desired state: Ready
2022-04-04 14:30:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 14:30:10 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTlsHostnameVerificationWithKafkaConnect
2022-04-04 14:30:10 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-c508638b-scraper in namespace namespace-71
2022-04-04 14:30:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c508638b in namespace namespace-71
2022-04-04 14:30:10 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-c508638b-kafka-clients in namespace namespace-71
2022-04-04 14:30:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-c508638b in namespace namespace-71
2022-04-04 14:30:10 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-c508638b-allow in namespace namespace-71
2022-04-04 14:31:00 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 14:31:00 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-71 for test case:testTlsHostnameVerificationWithKafkaConnect
2022-04-04 14:31:06 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testTlsHostnameVerificationWithKafkaConnect-FINISHED
2022-04-04 14:31:06 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 14:31:06 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 14:31:06 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testClientsCACertRenew-STARTED
2022-04-04 14:31:06 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 14:31:06 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-72 for test case:testClientsCACertRenew
2022-04-04 14:31:06 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-72
2022-04-04 14:31:06 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-72
2022-04-04 14:31:06 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-72
2022-04-04 14:31:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-95fc0a0b in namespace namespace-72
2022-04-04 14:31:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-72
2022-04-04 14:31:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-95fc0a0b will have desired state: Ready
2022-04-04 14:32:23 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-95fc0a0b is in desired state: Ready
2022-04-04 14:32:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser strimzi-tls-user-753821767 in namespace namespace-72
2022-04-04 14:32:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-72
2022-04-04 14:32:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: strimzi-tls-user-753821767 will have desired state: Ready
2022-04-04 14:32:24 [main] [32mINFO [m [ResourceManager:444] KafkaUser: strimzi-tls-user-753821767 is in desired state: Ready
2022-04-04 14:32:24 [main] [32mINFO [m [SecurityST:1596] Change of kafka validity and renewal days - reconciliation should start.
2022-04-04 14:32:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 50
2022-04-04 14:32:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 49
2022-04-04 14:32:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 48
2022-04-04 14:32:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 47
2022-04-04 14:32:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 46
2022-04-04 14:32:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 45
2022-04-04 14:32:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 44
2022-04-04 14:32:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 43
2022-04-04 14:32:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 42
2022-04-04 14:32:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 41
2022-04-04 14:32:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 40
2022-04-04 14:32:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 39
2022-04-04 14:32:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 38
2022-04-04 14:32:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 37
2022-04-04 14:32:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 36
2022-04-04 14:32:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 35
2022-04-04 14:32:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 34
2022-04-04 14:32:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 33
2022-04-04 14:32:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 32
2022-04-04 14:32:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 31
2022-04-04 14:32:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 30
2022-04-04 14:32:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 29
2022-04-04 14:32:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 28
2022-04-04 14:32:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 27
2022-04-04 14:32:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 26
2022-04-04 14:32:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 25
2022-04-04 14:32:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 24
2022-04-04 14:32:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 23
2022-04-04 14:32:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 22
2022-04-04 14:32:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 21
2022-04-04 14:32:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 20
2022-04-04 14:32:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 19
2022-04-04 14:32:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 18
2022-04-04 14:32:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 17
2022-04-04 14:32:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 16
2022-04-04 14:32:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 15
2022-04-04 14:33:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 14
2022-04-04 14:33:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 13
2022-04-04 14:33:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 12
2022-04-04 14:33:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 11
2022-04-04 14:33:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 10
2022-04-04 14:33:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 9
2022-04-04 14:33:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 8
2022-04-04 14:33:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 7
2022-04-04 14:33:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 6
2022-04-04 14:33:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 5
2022-04-04 14:33:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 4
2022-04-04 14:33:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 3
2022-04-04 14:33:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 2
2022-04-04 14:33:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 1
2022-04-04 14:33:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-95fc0a0b-zookeeper-2=56687e0e-02fe-4acf-b9cd-01269341c03b, my-cluster-95fc0a0b-zookeeper-1=51ad551a-7a25-4c47-af31-599fe0de213c, my-cluster-95fc0a0b-zookeeper-0=68bc381b-7cac-4154-ba77-f97364f52140} pods didn't roll. Remaining seconds for stability: 0
2022-04-04 14:33:14 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-95fc0a0b-kafka rolling update
2022-04-04 14:33:34 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-95fc0a0b-kafka has been successfully rolled
2022-04-04 14:33:34 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-95fc0a0b-kafka to be ready
2022-04-04 14:34:11 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-95fc0a0b-entity-operator rolling update
2022-04-04 14:34:16 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-95fc0a0b-entity-operator will be ready
2022-04-04 14:34:51 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-95fc0a0b-entity-operator is ready
2022-04-04 14:35:01 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-95fc0a0b-entity-operator rolling update finished
2022-04-04 14:35:01 [main] [32mINFO [m [SecurityST:1624] Initial ClientsCA cert dates: Mon Apr 04 14:31:08 UTC 2022 --> Sun Apr 24 14:31:08 UTC 2022
2022-04-04 14:35:01 [main] [32mINFO [m [SecurityST:1625] Changed ClientsCA cert dates: Mon Apr 04 14:32:24 UTC 2022 --> Fri Oct 21 14:32:24 UTC 2022
2022-04-04 14:35:01 [main] [32mINFO [m [SecurityST:1626] Initial userCert dates: Mon Apr 04 14:32:23 UTC 2022 --> Sun Apr 24 14:32:23 UTC 2022
2022-04-04 14:35:01 [main] [32mINFO [m [SecurityST:1627] Changed userCert dates: Mon Apr 04 14:34:19 UTC 2022 --> Fri Oct 21 14:34:19 UTC 2022
2022-04-04 14:35:01 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 14:35:01 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testClientsCACertRenew
2022-04-04 14:35:01 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser strimzi-tls-user-753821767 in namespace namespace-72
2022-04-04 14:35:01 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-95fc0a0b in namespace namespace-72
2022-04-04 14:35:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 14:35:11 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-72 for test case:testClientsCACertRenew
2022-04-04 14:35:55 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testClientsCACertRenew-FINISHED
2022-04-04 14:35:55 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 14:35:55 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 14:35:55 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCertificates-STARTED
2022-04-04 14:35:55 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 14:35:55 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-73 for test case:testCertificates
2022-04-04 14:35:55 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-73
2022-04-04 14:35:55 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-73
2022-04-04 14:35:55 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-73
2022-04-04 14:35:55 [main] [32mINFO [m [SecurityST:118] Running testCertificates my-cluster-602849fc
2022-04-04 14:35:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-602849fc in namespace namespace-73
2022-04-04 14:35:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-73
2022-04-04 14:35:55 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-602849fc will have desired state: Ready
2022-04-04 14:37:16 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-602849fc is in desired state: Ready
2022-04-04 14:37:16 [main] [32mINFO [m [SecurityST:122] Check Kafka bootstrap certificate
2022-04-04 14:37:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-602849fc-kafka-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-602849fc-kafka-bootstrap:9093 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-602849fc-kafka-bootstrap
2022-04-04 14:37:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 14:37:17 [main] [32mINFO [m [SecurityST:125] OPENSSL OUTPUT: 

CONNECTED(00000003)
---
Certificate chain
 0 s:O = io.strimzi, CN = my-cluster-602849fc-kafka
   i:O = io.strimzi, CN = cluster-ca v0
-----BEGIN CERTIFICATE-----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-----END CERTIFICATE-----
 1 s:O = io.strimzi, CN = cluster-ca v0
   i:O = io.strimzi, CN = cluster-ca v0
-----BEGIN CERTIFICATE-----
MIIFLTCCAxWgAwIBAgIUCPiFcHiQp7NBXOPqPRXwL1J2Na8wDQYJKoZIhvcNAQEN
BQAwLTETMBEGA1UECgwKaW8uc3RyaW16aTEWMBQGA1UEAwwNY2x1c3Rlci1jYSB2
MDAeFw0yMjA0MDQxNDM1NTVaFw0yMzA0MDQxNDM1NTVaMC0xEzARBgNVBAoMCmlv
LnN0cmltemkxFjAUBgNVBAMMDWNsdXN0ZXItY2EgdjAwggIiMA0GCSqGSIb3DQEB
AQUAA4ICDwAwggIKAoICAQC+ptmaxtJoIxNS6VuAkp2yPXI7/cl1d3R4QYFrQWVY
YUTDcRFHM/3CL8GwU/L0EPDWZvP1w64MBTX8OcbxulH7G0cNDTg+n+j7xzWmT+QY
IapN8VZ/IYAFhDpVc0xu0jw9LMTWbGK1nlTnJmbkkZSl/rCMCzsuX90V/s1lW6ug
wtiMUkWaIgS84jdn5M6c4JrzswFX0/AJ3V0MmLDKMW4hi+m4LXaDhVx5mdZ8CPnV
ZYZ7lTGycruOTzZlnpN/WVa6Srm/01xEK6HosXVsxWVQHPi8LSxEteRXzdQT4GDr
leZtcINTAO0i837FxIYrSweWCxyXmUxiB30A1cfHJPYcX6TwPqETgp8rSKX9u89M
1S/pXWylM3olXka7gBO2mQuUQdY6RLTdBQQOKKLHy28e+pBW3MX9w2O0wDJQ7YXC
5rPkX3nS+FdAKox5aBFfOGCB1/i79uNihFASGrB/6/pGJU3t0O4KHtBhBSLjCheg
tbDxlT2TZvX5MlENnc/bANj7gpDhE6aMcmgU3HwAo3SxQhPVcyP7dXeRSElce58z
Pd8QAUnB3kIfcfpgN+/0qIT9KXtoRx3AuvO1dv9tN7voQQEcDDtVp7W/JeqGsuRM
CqDZOOp9lfnIi/5JNOLV6Bji0fVjE6mqQrxLEaWF0GJFbtK9/+NJNLk+WM+kaoMD
7QIDAQABo0UwQzAdBgNVHQ4EFgQUn2JwDiTnXHOj2BvXA6LQapoZ5jQwEgYDVR0T
AQH/BAgwBgEB/wIBADAOBgNVHQ8BAf8EBAMCAQYwDQYJKoZIhvcNAQENBQADggIB
ALvzDtqwUSkSk2ZmZA0FNwvIe61Q3TtElTCbzOgaJOpzorEOYcsjs9+rbYMcGU7u
Ov0qi08aq47uM85O6W7Y4ZjOiXzjsOQB8EEbGGg4BBihKNgDtZ7z8cqO75cmgi1Z
kfKmdN20eaUB6FXEVOBJEgaJCaZW9ZnQhStyuX0gAkQ0QOCx0fmQ2smVncEEj7tx
/mFa8fKlY/Ql8E8agH8X4v3AYB+TaVYJb11nHcz8W0fyT+WX8iJRrBiKkMKfXUm3
Abvejmxi04y/w+1v52sq5S6h4ykYs/2kvAAXYopHGXokipcGOgsBKsNe0fX0ROAw
jDIY5aljAldnnFdIqaJ8qqlHDIDciIQKxW5iqsEIBZKF5H2wDxUS6qjfo3OVFYgS
Tz+mUhH9Eiq/UubHWa18Xm9ZdQwNqEWhNsQjv7zJQlPMO0YJxBnBRD5vxYJwp5ax
DuVZVxeQYhN1ww2fgI+lmiSyLMIHBppyk1ZFiArvp/TuFSRA+gzSQD0QjOy5AkS4
d5ZlBQ+asU2/kAvApXd40AAzYPqRYW6fzrqz2MP2K6bLDVLOc39vJavp6+NvbZTQ
zSGKFaDSug4GnhoNh12ozBL+YKrJPbycr/dU8ZmgwjWCH30W4G4kXEv9hyvzt5pV
LZgxES5Li0EGsHtL9oMoNzrtNuhGbxPKjwjGH/MOXkcI
-----END CERTIFICATE-----
---
Server certificate
subject=O = io.strimzi, CN = my-cluster-602849fc-kafka

issuer=O = io.strimzi, CN = cluster-ca v0

---
No client certificate CA names sent
Peer signing digest: SHA256
Peer signature type: RSA-PSS
Server Temp Key: X25519, 253 bits
---
SSL handshake has read 3489 bytes and written 369 bytes
Verification: OK
Verified peername: my-cluster-602849fc-kafka-bootstrap
---
New, TLSv1.3, Cipher is TLS_AES_256_GCM_SHA384
Server public key is 2048 bit
Secure Renegotiation IS NOT supported
Compression: NONE
Expansion: NONE
No ALPN negotiated
Early data was not sent
Verify return code: 0 (ok)
---



2022-04-04 14:37:17 [main] [32mINFO [m [SecurityST:128] Check zookeeper client certificate
2022-04-04 14:37:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-602849fc-kafka-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-602849fc-zookeeper-client:2181 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-602849fc-zookeeper-client -cert /opt/kafka/broker-certs/my-cluster-602849fc-kafka-0.crt -key /opt/kafka/broker-certs/my-cluster-602849fc-kafka-0.key
2022-04-04 14:37:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 14:37:17 [main] [32mINFO [m [SecurityST:139] Checking certificates for podId 0
2022-04-04 14:37:17 [main] [32mINFO [m [SecurityST:141] Check kafka certificate for port 9091
2022-04-04 14:37:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-602849fc-kafka-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-602849fc-kafka-0.my-cluster-602849fc-kafka-brokers:9091 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-602849fc-kafka-0.my-cluster-602849fc-kafka-brokers.namespace-73.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-602849fc-kafka-0.crt -key /opt/kafka/broker-certs/my-cluster-602849fc-kafka-0.key
2022-04-04 14:37:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 14:37:17 [main] [32mINFO [m [SecurityST:141] Check kafka certificate for port 9093
2022-04-04 14:37:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-602849fc-kafka-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-602849fc-kafka-0.my-cluster-602849fc-kafka-brokers:9093 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-602849fc-kafka-0.my-cluster-602849fc-kafka-brokers.namespace-73.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-602849fc-kafka-0.crt -key /opt/kafka/broker-certs/my-cluster-602849fc-kafka-0.key
2022-04-04 14:37:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 14:37:17 [main] [32mINFO [m [SecurityST:148] Check zookeeper certificate for port 2181
2022-04-04 14:37:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-602849fc-zookeeper-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-602849fc-zookeeper-0.my-cluster-602849fc-zookeeper-nodes:2181 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-602849fc-zookeeper-0.my-cluster-602849fc-zookeeper-nodes.namespace-73.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-602849fc-zookeeper-0.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-602849fc-zookeeper-0.key
2022-04-04 14:37:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 14:37:18 [main] [32mINFO [m [SecurityST:148] Check zookeeper certificate for port 3888
2022-04-04 14:37:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-602849fc-zookeeper-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-602849fc-zookeeper-0.my-cluster-602849fc-zookeeper-nodes:3888 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-602849fc-zookeeper-0.my-cluster-602849fc-zookeeper-nodes.namespace-73.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-602849fc-zookeeper-0.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-602849fc-zookeeper-0.key
2022-04-04 14:37:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 14:37:18 [main] [32mINFO [m [SecurityST:139] Checking certificates for podId 1
2022-04-04 14:37:18 [main] [32mINFO [m [SecurityST:141] Check kafka certificate for port 9091
2022-04-04 14:37:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-602849fc-kafka-1 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-602849fc-kafka-1.my-cluster-602849fc-kafka-brokers:9091 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-602849fc-kafka-1.my-cluster-602849fc-kafka-brokers.namespace-73.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-602849fc-kafka-1.crt -key /opt/kafka/broker-certs/my-cluster-602849fc-kafka-1.key
2022-04-04 14:37:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 14:37:18 [main] [32mINFO [m [SecurityST:141] Check kafka certificate for port 9093
2022-04-04 14:37:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-602849fc-kafka-1 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-602849fc-kafka-1.my-cluster-602849fc-kafka-brokers:9093 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-602849fc-kafka-1.my-cluster-602849fc-kafka-brokers.namespace-73.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-602849fc-kafka-1.crt -key /opt/kafka/broker-certs/my-cluster-602849fc-kafka-1.key
2022-04-04 14:37:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 14:37:19 [main] [32mINFO [m [SecurityST:148] Check zookeeper certificate for port 2181
2022-04-04 14:37:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-602849fc-zookeeper-1 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-602849fc-zookeeper-1.my-cluster-602849fc-zookeeper-nodes:2181 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-602849fc-zookeeper-1.my-cluster-602849fc-zookeeper-nodes.namespace-73.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-602849fc-zookeeper-1.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-602849fc-zookeeper-1.key
2022-04-04 14:37:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 14:37:19 [main] [32mINFO [m [SecurityST:148] Check zookeeper certificate for port 3888
2022-04-04 14:37:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-602849fc-zookeeper-1 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-602849fc-zookeeper-1.my-cluster-602849fc-zookeeper-nodes:3888 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-602849fc-zookeeper-1.my-cluster-602849fc-zookeeper-nodes.namespace-73.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-602849fc-zookeeper-1.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-602849fc-zookeeper-1.key
2022-04-04 14:37:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 14:37:19 [main] [32mINFO [m [SecurityST:139] Checking certificates for podId 2
2022-04-04 14:37:19 [main] [32mINFO [m [SecurityST:141] Check kafka certificate for port 9091
2022-04-04 14:37:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-602849fc-kafka-2 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-602849fc-kafka-2.my-cluster-602849fc-kafka-brokers:9091 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-602849fc-kafka-2.my-cluster-602849fc-kafka-brokers.namespace-73.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-602849fc-kafka-2.crt -key /opt/kafka/broker-certs/my-cluster-602849fc-kafka-2.key
2022-04-04 14:37:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 14:37:20 [main] [32mINFO [m [SecurityST:141] Check kafka certificate for port 9093
2022-04-04 14:37:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-602849fc-kafka-2 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-602849fc-kafka-2.my-cluster-602849fc-kafka-brokers:9093 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-602849fc-kafka-2.my-cluster-602849fc-kafka-brokers.namespace-73.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-602849fc-kafka-2.crt -key /opt/kafka/broker-certs/my-cluster-602849fc-kafka-2.key
2022-04-04 14:37:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 14:37:20 [main] [32mINFO [m [SecurityST:148] Check zookeeper certificate for port 2181
2022-04-04 14:37:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-602849fc-zookeeper-2 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-602849fc-zookeeper-2.my-cluster-602849fc-zookeeper-nodes:2181 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-602849fc-zookeeper-2.my-cluster-602849fc-zookeeper-nodes.namespace-73.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-602849fc-zookeeper-2.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-602849fc-zookeeper-2.key
2022-04-04 14:37:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 14:37:20 [main] [32mINFO [m [SecurityST:148] Check zookeeper certificate for port 3888
2022-04-04 14:37:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-602849fc-zookeeper-2 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-602849fc-zookeeper-2.my-cluster-602849fc-zookeeper-nodes:3888 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-602849fc-zookeeper-2.my-cluster-602849fc-zookeeper-nodes.namespace-73.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-602849fc-zookeeper-2.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-602849fc-zookeeper-2.key
2022-04-04 14:37:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 14:37:20 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 14:37:20 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCertificates
2022-04-04 14:37:20 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-602849fc in namespace namespace-73
2022-04-04 14:37:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 14:37:30 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-73 for test case:testCertificates
2022-04-04 14:38:14 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCertificates-FINISHED
2022-04-04 14:38:14 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 14:38:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 14:38:14 [main] [32mINFO [m [ResourceManager:346] In context SecurityST is everything deleted.
2022-04-04 14:38:14 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9,302.176 s - in io.strimzi.systemtest.security.SecurityST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.custom.CustomAuthorizerST
2022-04-04 14:38:20 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: custom-authorizer-st
2022-04-04 14:38:20 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: custom-authorizer-st
2022-04-04 14:38:20 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: custom-authorizer-st
2022-04-04 14:38:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka custom-authorizer in namespace custom-authorizer-st
2022-04-04 14:38:20 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: custom-authorizer will have desired state: Ready
2022-04-04 14:39:27 [main] [32mINFO [m [ResourceManager:444] Kafka: custom-authorizer is in desired state: Ready
2022-04-04 14:39:27 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 14:39:27 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.custom.CustomAuthorizerST.testAclWithSuperUser-STARTED
2022-04-04 14:39:27 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 14:39:27 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1481490776-1767287233 in namespace custom-authorizer-st
2022-04-04 14:39:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1481490776-1767287233 will have desired state: Ready
2022-04-04 14:39:28 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1481490776-1767287233 is in desired state: Ready
2022-04-04 14:39:28 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser sre-admin in namespace custom-authorizer-st
2022-04-04 14:39:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: sre-admin will have desired state: Ready
2022-04-04 14:39:29 [main] [32mINFO [m [ResourceManager:444] KafkaUser: sre-admin is in desired state: Ready
2022-04-04 14:39:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-eafe12c2-kafka-clients in namespace custom-authorizer-st
2022-04-04 14:39:29 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-eafe12c2-kafka-clients will be ready
2022-04-04 14:39:31 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-eafe12c2-kafka-clients is ready
2022-04-04 14:39:31 [main] [32mINFO [m [CustomAuthorizerST:173] Checking kafka super user:sre-admin that is able to send messages to topic:my-topic-1481490776-1767287233
2022-04-04 14:39:31 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 14:39:31 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@4739033b, messages=[], arguments=[--topic, my-topic-1481490776-1767287233, --max-messages, 100, USER=sre_admin, --bootstrap-server, custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-eafe12c2-kafka-clients-7858596486-hdmr8', podNamespace='custom-authorizer-st', bootstrapServer='custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093', topicName='my-topic-1481490776-1767287233', maxMessages=100, kafkaUsername='sre-admin', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@123c674d}
2022-04-04 14:39:31 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093:my-topic-1481490776-1767287233 from pod my-cluster-eafe12c2-kafka-clients-7858596486-hdmr8
2022-04-04 14:39:31 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-eafe12c2-kafka-clients-7858596486-hdmr8 -n custom-authorizer-st -- /opt/kafka/producer.sh --topic my-topic-1481490776-1767287233 --max-messages 100 USER=sre_admin --bootstrap-server custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093
2022-04-04 14:39:35 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 14:39:35 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 14:39:35 [main] [32mINFO [m [CustomAuthorizerST:187] Checking kafka super user:sre-admin that is able to read messages to topic:my-topic-335653399-1112350690 regardless that we configured Acls with only write operation
2022-04-04 14:39:35 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4b0fd54b, messages=[], arguments=[--topic, my-topic-1481490776-1767287233, --max-messages, 100, --group-instance-id, instance1785268523, USER=sre_admin, --group-id, my-consumer-group-830774774, --bootstrap-server, custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-eafe12c2-kafka-clients-7858596486-hdmr8', podNamespace='custom-authorizer-st', bootstrapServer='custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093', topicName='my-topic-1481490776-1767287233', maxMessages=100, kafkaUsername='sre-admin', consumerGroupName='my-consumer-group-830774774', consumerInstanceId='instance1785268523', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3a78db46}
2022-04-04 14:39:35 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093:my-topic-1481490776-1767287233 from pod my-cluster-eafe12c2-kafka-clients-7858596486-hdmr8
2022-04-04 14:39:35 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-eafe12c2-kafka-clients-7858596486-hdmr8 -n custom-authorizer-st -- /opt/kafka/consumer.sh --topic my-topic-1481490776-1767287233 --max-messages 100 --group-instance-id instance1785268523 USER=sre_admin --group-id my-consumer-group-830774774 --bootstrap-server custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093
2022-04-04 14:39:43 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 14:39:43 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 14:39:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 14:39:43 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAclWithSuperUser
2022-04-04 14:39:43 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser sre-admin in namespace custom-authorizer-st
2022-04-04 14:39:43 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-eafe12c2-kafka-clients in namespace custom-authorizer-st
2022-04-04 14:39:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1481490776-1767287233 in namespace custom-authorizer-st
2022-04-04 14:40:33 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 14:40:33 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.custom.CustomAuthorizerST.testAclWithSuperUser-FINISHED
2022-04-04 14:40:33 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 14:40:33 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 14:40:33 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.custom.CustomAuthorizerST.testAclRuleReadAndWrite-STARTED
2022-04-04 14:40:33 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 14:40:33 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-152682052-1764178647 in namespace custom-authorizer-st
2022-04-04 14:40:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-152682052-1764178647 will have desired state: Ready
2022-04-04 14:40:34 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-152682052-1764178647 is in desired state: Ready
2022-04-04 14:40:34 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser kafka-user-write in namespace custom-authorizer-st
2022-04-04 14:40:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: kafka-user-write will have desired state: Ready
2022-04-04 14:40:35 [main] [32mINFO [m [ResourceManager:444] KafkaUser: kafka-user-write is in desired state: Ready
2022-04-04 14:40:35 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser kafka-user-read in namespace custom-authorizer-st
2022-04-04 14:40:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: kafka-user-read will have desired state: Ready
2022-04-04 14:40:36 [main] [32mINFO [m [ResourceManager:444] KafkaUser: kafka-user-read is in desired state: Ready
2022-04-04 14:40:36 [main] [32mINFO [m [CustomAuthorizerST:105] Checking KafkaUser kafka-user-write that is able to send messages to topic 'my-topic-152682052-1764178647'
2022-04-04 14:40:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a0a75e42-kafka-clients in namespace custom-authorizer-st
2022-04-04 14:40:36 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a0a75e42-kafka-clients will be ready
2022-04-04 14:40:38 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a0a75e42-kafka-clients is ready
2022-04-04 14:40:38 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 14:40:38 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@51567040, messages=[], arguments=[--topic, my-topic-152682052-1764178647, --max-messages, 500, USER=kafka_user_write, --bootstrap-server, custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-a0a75e42-kafka-clients-d98fb8c5b-bmkk6', podNamespace='custom-authorizer-st', bootstrapServer='custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093', topicName='my-topic-152682052-1764178647', maxMessages=500, kafkaUsername='kafka-user-write', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@72321d0d}
2022-04-04 14:40:38 [main] [32mINFO [m [InternalKafkaClient:124] Producing 500 messages to custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093:my-topic-152682052-1764178647 from pod my-cluster-a0a75e42-kafka-clients-d98fb8c5b-bmkk6
2022-04-04 14:40:38 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a0a75e42-kafka-clients-d98fb8c5b-bmkk6 -n custom-authorizer-st -- /opt/kafka/producer.sh --topic my-topic-152682052-1764178647 --max-messages 500 USER=kafka_user_write --bootstrap-server custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093
2022-04-04 14:40:42 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 14:40:42 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 500 messages
2022-04-04 14:40:42 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5ddd34b, messages=[], arguments=[--topic, my-topic-152682052-1764178647, --max-messages, 500, --group-instance-id, instance1365746753, USER=kafka_user_write, --group-id, my-consumer-group-214666679, --bootstrap-server, custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a0a75e42-kafka-clients-d98fb8c5b-bmkk6', podNamespace='custom-authorizer-st', bootstrapServer='custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093', topicName='my-topic-152682052-1764178647', maxMessages=500, kafkaUsername='kafka-user-write', consumerGroupName='my-consumer-group-214666679', consumerInstanceId='instance1365746753', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@733a1bc9}
2022-04-04 14:40:42 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 500 messages from custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093:my-topic-152682052-1764178647 from pod my-cluster-a0a75e42-kafka-clients-d98fb8c5b-bmkk6
2022-04-04 14:40:42 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a0a75e42-kafka-clients-d98fb8c5b-bmkk6 -n custom-authorizer-st -- /opt/kafka/consumer.sh --topic my-topic-152682052-1764178647 --max-messages 500 --group-instance-id instance1365746753 USER=kafka_user_write --group-id my-consumer-group-214666679 --bootstrap-server custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093
2022-04-04 14:40:46 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 14:40:46 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 0 messages
2022-04-04 14:40:46 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5d3d454, messages=[], arguments=[--topic, my-topic-152682052-1764178647, --max-messages, 500, --group-instance-id, instance984838210, USER=kafka_user_read, --group-id, consumer-group-name-1, --bootstrap-server, custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a0a75e42-kafka-clients-d98fb8c5b-bmkk6', podNamespace='custom-authorizer-st', bootstrapServer='custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093', topicName='my-topic-152682052-1764178647', maxMessages=500, kafkaUsername='kafka-user-read', consumerGroupName='consumer-group-name-1', consumerInstanceId='instance984838210', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@67657c88}
2022-04-04 14:40:46 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 500 messages from custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093:my-topic-152682052-1764178647 from pod my-cluster-a0a75e42-kafka-clients-d98fb8c5b-bmkk6
2022-04-04 14:40:46 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a0a75e42-kafka-clients-d98fb8c5b-bmkk6 -n custom-authorizer-st -- /opt/kafka/consumer.sh --topic my-topic-152682052-1764178647 --max-messages 500 --group-instance-id instance984838210 USER=kafka_user_read --group-id consumer-group-name-1 --bootstrap-server custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093
2022-04-04 14:40:53 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 14:40:53 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 500 messages
2022-04-04 14:40:53 [main] [32mINFO [m [CustomAuthorizerST:137] Checking KafkaUser kafka-user-read that is not able to send messages to topic 'my-topic-152682052-1764178647'
2022-04-04 14:40:53 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@4d38bb66, messages=[], arguments=[--topic, my-topic-152682052-1764178647, --max-messages, 500, USER=kafka_user_read, --bootstrap-server, custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-a0a75e42-kafka-clients-d98fb8c5b-bmkk6', podNamespace='custom-authorizer-st', bootstrapServer='custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093', topicName='my-topic-152682052-1764178647', maxMessages=500, kafkaUsername='kafka-user-read', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@26946374}
2022-04-04 14:40:53 [main] [32mINFO [m [InternalKafkaClient:124] Producing 500 messages to custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093:my-topic-152682052-1764178647 from pod my-cluster-a0a75e42-kafka-clients-d98fb8c5b-bmkk6
2022-04-04 14:40:53 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a0a75e42-kafka-clients-d98fb8c5b-bmkk6 -n custom-authorizer-st -- /opt/kafka/producer.sh --topic my-topic-152682052-1764178647 --max-messages 500 USER=kafka_user_read --bootstrap-server custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093
2022-04-04 14:40:57 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 14:40:58 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced -1 messages
2022-04-04 14:40:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 14:40:58 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAclRuleReadAndWrite
2022-04-04 14:40:58 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser kafka-user-read in namespace custom-authorizer-st
2022-04-04 14:40:58 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a0a75e42-kafka-clients in namespace custom-authorizer-st
2022-04-04 14:40:58 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-152682052-1764178647 in namespace custom-authorizer-st
2022-04-04 14:40:58 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaUser kafka-user-write in namespace custom-authorizer-st
2022-04-04 14:41:38 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 14:41:38 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.custom.CustomAuthorizerST.testAclRuleReadAndWrite-FINISHED
2022-04-04 14:41:38 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 14:41:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 14:41:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for CustomAuthorizerST
2022-04-04 14:41:38 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka custom-authorizer in namespace custom-authorizer-st
2022-04-04 14:41:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 219.002 s - in io.strimzi.systemtest.security.custom.CustomAuthorizerST
[[1;34mINFO[m] Running io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST
2022-04-04 14:41:59 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: alternative-reconcile-triggers-st
2022-04-04 14:41:59 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: alternative-reconcile-triggers-st
2022-04-04 14:41:59 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: alternative-reconcile-triggers-st
2022-04-04 14:41:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 14:41:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testManualRollingUpdateForSinglePod-STARTED
2022-04-04 14:41:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 14:41:59 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-74 for test case:testManualRollingUpdateForSinglePod
2022-04-04 14:41:59 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-74
2022-04-04 14:41:59 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-74
2022-04-04 14:41:59 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-74
2022-04-04 14:41:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-51c2acab in namespace namespace-74
2022-04-04 14:41:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-74
2022-04-04 14:41:59 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-51c2acab will have desired state: Ready
2022-04-04 14:43:12 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-51c2acab is in desired state: Ready
2022-04-04 14:43:12 [main] [32mINFO [m [AlternativeReconcileTriggersST:290] Trying to roll just single Kafka and single ZK pod
2022-04-04 14:43:12 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-51c2acab-kafka rolling update
2022-04-04 14:43:23 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-51c2acab-kafka has been successfully rolled
2022-04-04 14:43:23 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-51c2acab-kafka to be ready
2022-04-04 14:43:45 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-51c2acab will have desired state: Ready
2022-04-04 14:43:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-51c2acab is in desired state: Ready
2022-04-04 14:43:45 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-51c2acab is ready
2022-04-04 14:43:45 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-51c2acab-zookeeper rolling update
2022-04-04 14:44:15 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-51c2acab-zookeeper has been successfully rolled
2022-04-04 14:44:15 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-51c2acab-zookeeper to be ready
2022-04-04 14:44:43 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-51c2acab will have desired state: Ready
2022-04-04 14:44:43 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-51c2acab is in desired state: Ready
2022-04-04 14:44:43 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-51c2acab is ready
2022-04-04 14:44:43 [main] [32mINFO [m [AlternativeReconcileTriggersST:311] Adding anno to all ZK and Kafka pods
2022-04-04 14:44:43 [main] [32mINFO [m [AlternativeReconcileTriggersST:320] Checking if the rolling update will be successful for Kafka
2022-04-04 14:44:43 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-51c2acab-kafka rolling update
2022-04-04 14:46:18 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-51c2acab-kafka has been successfully rolled
2022-04-04 14:46:18 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-51c2acab-kafka to be ready
2022-04-04 14:46:47 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-51c2acab will have desired state: Ready
2022-04-04 14:46:47 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-51c2acab is in desired state: Ready
2022-04-04 14:46:47 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-51c2acab is ready
2022-04-04 14:46:47 [main] [32mINFO [m [AlternativeReconcileTriggersST:331] Checking if the rolling update will be successful for ZK
2022-04-04 14:46:47 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-51c2acab-zookeeper rolling update
2022-04-04 14:48:02 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-51c2acab-zookeeper has been successfully rolled
2022-04-04 14:48:02 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-51c2acab-zookeeper to be ready
2022-04-04 14:48:33 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-51c2acab will have desired state: Ready
2022-04-04 14:48:33 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-51c2acab is in desired state: Ready
2022-04-04 14:48:33 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-51c2acab is ready
2022-04-04 14:48:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 14:48:33 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testManualRollingUpdateForSinglePod
2022-04-04 14:48:33 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-51c2acab in namespace namespace-74
2022-04-04 14:48:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 14:48:43 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-74 for test case:testManualRollingUpdateForSinglePod
2022-04-04 14:49:26 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testManualRollingUpdateForSinglePod-FINISHED
2022-04-04 14:49:26 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 14:49:26 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 14:49:26 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testManualTriggeringRollingUpdate-STARTED
2022-04-04 14:49:26 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 14:49:26 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-75 for test case:testManualTriggeringRollingUpdate
2022-04-04 14:49:26 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-75
2022-04-04 14:49:26 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-75
2022-04-04 14:49:26 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-75
2022-04-04 14:49:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1a97fefe in namespace namespace-75
2022-04-04 14:49:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-04 14:49:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1a97fefe will have desired state: Ready
2022-04-04 14:50:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1a97fefe is in desired state: Ready
2022-04-04 14:50:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2766765-1480634972 in namespace namespace-75
2022-04-04 14:50:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-04 14:50:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2766765-1480634972 will have desired state: Ready
2022-04-04 14:50:46 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2766765-1480634972 is in desired state: Ready
2022-04-04 14:50:46 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic continuous-topic in namespace namespace-75
2022-04-04 14:50:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-04 14:50:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: continuous-topic will have desired state: Ready
2022-04-04 14:50:47 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: continuous-topic is in desired state: Ready
2022-04-04 14:50:47 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 14:50:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-producer in namespace namespace-75
2022-04-04 14:50:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-04 14:50:47 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-producer will be in active state
2022-04-04 14:50:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-consumer in namespace namespace-75
2022-04-04 14:50:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-04 14:50:48 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-consumer will be in active state
2022-04-04 14:50:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-275223097-1088348738 in namespace namespace-75
2022-04-04 14:50:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-04 14:50:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-275223097-1088348738 will have desired state: Ready
2022-04-04 14:50:50 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-275223097-1088348738 is in desired state: Ready
2022-04-04 14:50:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-1a97fefe-kafka-clients in namespace namespace-75
2022-04-04 14:50:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-04 14:51:00 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 14:51:00 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@7f90e015, messages=[], arguments=[--topic, my-topic-2766765-1480634972, --max-messages, 100, USER=my_user_275223097_1088348738, --bootstrap-server, my-cluster-1a97fefe-kafka-bootstrap.namespace-75.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-1a97fefe-kafka-clients-5c9f78f4fd-pc5rb', podNamespace='namespace-75', bootstrapServer='my-cluster-1a97fefe-kafka-bootstrap.namespace-75.svc:9093', topicName='my-topic-2766765-1480634972', maxMessages=100, kafkaUsername='my-user-275223097-1088348738', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4aadf2d}
2022-04-04 14:51:00 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-1a97fefe-kafka-bootstrap.namespace-75.svc:9093:my-topic-2766765-1480634972 from pod my-cluster-1a97fefe-kafka-clients-5c9f78f4fd-pc5rb
2022-04-04 14:51:00 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1a97fefe-kafka-clients-5c9f78f4fd-pc5rb -n namespace-75 -- /opt/kafka/producer.sh --topic my-topic-2766765-1480634972 --max-messages 100 USER=my_user_275223097_1088348738 --bootstrap-server my-cluster-1a97fefe-kafka-bootstrap.namespace-75.svc:9093
2022-04-04 14:51:04 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 14:51:04 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 14:51:04 [main] [32mINFO [m [AlternativeReconcileTriggersST:145] Annotate Kafka StatefulSet my-cluster-1a97fefe-kafka with manual rolling update annotation
2022-04-04 14:51:05 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-1a97fefe-kafka rolling update
2022-04-04 14:52:40 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-1a97fefe-kafka has been successfully rolled
2022-04-04 14:52:40 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-1a97fefe-kafka to be ready
2022-04-04 14:53:11 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1a97fefe will have desired state: Ready
2022-04-04 14:53:11 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1a97fefe is in desired state: Ready
2022-04-04 14:53:11 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-1a97fefe is ready
2022-04-04 14:53:11 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@67e8d6ab, messages=[], arguments=[--topic, my-topic-2766765-1480634972, --max-messages, 100, --group-instance-id, instance1454559951, USER=my_user_275223097_1088348738, --group-id, my-consumer-group-725323407, --bootstrap-server, my-cluster-1a97fefe-kafka-bootstrap.namespace-75.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-1a97fefe-kafka-clients-5c9f78f4fd-pc5rb', podNamespace='namespace-75', bootstrapServer='my-cluster-1a97fefe-kafka-bootstrap.namespace-75.svc:9093', topicName='my-topic-2766765-1480634972', maxMessages=100, kafkaUsername='my-user-275223097-1088348738', consumerGroupName='my-consumer-group-725323407', consumerInstanceId='instance1454559951', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@46af2d0a}
2022-04-04 14:53:11 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-1a97fefe-kafka-bootstrap.namespace-75.svc:9093:my-topic-2766765-1480634972 from pod my-cluster-1a97fefe-kafka-clients-5c9f78f4fd-pc5rb
2022-04-04 14:53:11 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1a97fefe-kafka-clients-5c9f78f4fd-pc5rb -n namespace-75 -- /opt/kafka/consumer.sh --topic my-topic-2766765-1480634972 --max-messages 100 --group-instance-id instance1454559951 USER=my_user_275223097_1088348738 --group-id my-consumer-group-725323407 --bootstrap-server my-cluster-1a97fefe-kafka-bootstrap.namespace-75.svc:9093
2022-04-04 14:53:19 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 14:53:19 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 14:53:19 [main] [32mINFO [m [AlternativeReconcileTriggersST:166] Annotate Zookeeper StatefulSet my-cluster-1a97fefe-zookeeper with manual rolling update annotation
2022-04-04 14:53:19 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-1a97fefe-zookeeper rolling update
2022-04-04 14:54:34 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-1a97fefe-zookeeper has been successfully rolled
2022-04-04 14:54:34 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-1a97fefe-zookeeper to be ready
2022-04-04 14:55:07 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1a97fefe will have desired state: Ready
2022-04-04 14:55:07 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1a97fefe is in desired state: Ready
2022-04-04 14:55:07 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-1a97fefe is ready
2022-04-04 14:55:07 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@686013ff, messages=[], arguments=[--topic, my-topic-2766765-1480634972, --max-messages, 100, --group-instance-id, instance143232066, USER=my_user_275223097_1088348738, --group-id, my-consumer-group-1405583240, --bootstrap-server, my-cluster-1a97fefe-kafka-bootstrap.namespace-75.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-1a97fefe-kafka-clients-5c9f78f4fd-pc5rb', podNamespace='namespace-75', bootstrapServer='my-cluster-1a97fefe-kafka-bootstrap.namespace-75.svc:9093', topicName='my-topic-2766765-1480634972', maxMessages=100, kafkaUsername='my-user-275223097-1088348738', consumerGroupName='my-consumer-group-1405583240', consumerInstanceId='instance143232066', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@35228a3e}
2022-04-04 14:55:07 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-1a97fefe-kafka-bootstrap.namespace-75.svc:9093:my-topic-2766765-1480634972 from pod my-cluster-1a97fefe-kafka-clients-5c9f78f4fd-pc5rb
2022-04-04 14:55:07 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1a97fefe-kafka-clients-5c9f78f4fd-pc5rb -n namespace-75 -- /opt/kafka/consumer.sh --topic my-topic-2766765-1480634972 --max-messages 100 --group-instance-id instance143232066 USER=my_user_275223097_1088348738 --group-id my-consumer-group-1405583240 --bootstrap-server my-cluster-1a97fefe-kafka-bootstrap.namespace-75.svc:9093
2022-04-04 14:55:15 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 14:55:15 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 14:55:15 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1372468178-2113757327 in namespace namespace-75
2022-04-04 14:55:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-04 14:55:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1372468178-2113757327 will have desired state: Ready
2022-04-04 14:55:16 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1372468178-2113757327 is in desired state: Ready
2022-04-04 14:55:16 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3abd53c9, messages=[], arguments=[--topic, my-topic-1372468178-2113757327, --max-messages, 100, USER=my_user_275223097_1088348738, --bootstrap-server, my-cluster-1a97fefe-kafka-bootstrap.namespace-75.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-1a97fefe-kafka-clients-5c9f78f4fd-pc5rb', podNamespace='namespace-75', bootstrapServer='my-cluster-1a97fefe-kafka-bootstrap.namespace-75.svc:9093', topicName='my-topic-1372468178-2113757327', maxMessages=100, kafkaUsername='my-user-275223097-1088348738', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1bef49f0}
2022-04-04 14:55:16 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-1a97fefe-kafka-bootstrap.namespace-75.svc:9093:my-topic-1372468178-2113757327 from pod my-cluster-1a97fefe-kafka-clients-5c9f78f4fd-pc5rb
2022-04-04 14:55:16 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1a97fefe-kafka-clients-5c9f78f4fd-pc5rb -n namespace-75 -- /opt/kafka/producer.sh --topic my-topic-1372468178-2113757327 --max-messages 100 USER=my_user_275223097_1088348738 --bootstrap-server my-cluster-1a97fefe-kafka-bootstrap.namespace-75.svc:9093
2022-04-04 14:55:20 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 14:55:20 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 14:55:20 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@632cdf81, messages=[], arguments=[--topic, my-topic-1372468178-2113757327, --max-messages, 100, --group-instance-id, instance972627371, USER=my_user_275223097_1088348738, --group-id, my-consumer-group-1437268221, --bootstrap-server, my-cluster-1a97fefe-kafka-bootstrap.namespace-75.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-1a97fefe-kafka-clients-5c9f78f4fd-pc5rb', podNamespace='namespace-75', bootstrapServer='my-cluster-1a97fefe-kafka-bootstrap.namespace-75.svc:9093', topicName='my-topic-1372468178-2113757327', maxMessages=100, kafkaUsername='my-user-275223097-1088348738', consumerGroupName='my-consumer-group-1437268221', consumerInstanceId='instance972627371', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@522a508a}
2022-04-04 14:55:20 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-1a97fefe-kafka-bootstrap.namespace-75.svc:9093:my-topic-1372468178-2113757327 from pod my-cluster-1a97fefe-kafka-clients-5c9f78f4fd-pc5rb
2022-04-04 14:55:20 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1a97fefe-kafka-clients-5c9f78f4fd-pc5rb -n namespace-75 -- /opt/kafka/consumer.sh --topic my-topic-1372468178-2113757327 --max-messages 100 --group-instance-id instance972627371 USER=my_user_275223097_1088348738 --group-id my-consumer-group-1437268221 --bootstrap-server my-cluster-1a97fefe-kafka-bootstrap.namespace-75.svc:9093
2022-04-04 14:55:27 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 14:55:27 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 14:55:27 [main] [32mINFO [m [ClientUtils:61] Waiting till producer hello-world-producer and consumer hello-world-consumer finish
2022-04-04 14:59:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 14:59:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testManualTriggeringRollingUpdate
2022-04-04 14:59:38 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-consumer in namespace namespace-75
2022-04-04 14:59:38 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-1a97fefe-kafka-clients in namespace namespace-75
2022-04-04 14:59:38 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1372468178-2113757327 in namespace namespace-75
2022-04-04 14:59:38 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2766765-1480634972 in namespace namespace-75
2022-04-04 14:59:38 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-275223097-1088348738 in namespace namespace-75
2022-04-04 14:59:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1a97fefe in namespace namespace-75
2022-04-04 14:59:38 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic continuous-topic in namespace namespace-75
2022-04-04 14:59:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-producer in namespace namespace-75
2022-04-04 15:00:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 15:00:28 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-75 for test case:testManualTriggeringRollingUpdate
2022-04-04 15:00:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testManualTriggeringRollingUpdate-FINISHED
2022-04-04 15:00:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 15:00:34 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 15:00:34 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testAddingAndRemovingJbodVolumes-STARTED
2022-04-04 15:00:34 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 15:00:34 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-76 for test case:testAddingAndRemovingJbodVolumes
2022-04-04 15:00:34 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-76
2022-04-04 15:00:34 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-76
2022-04-04 15:00:34 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-76
2022-04-04 15:00:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5f466e34 in namespace namespace-76
2022-04-04 15:00:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-04 15:00:34 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5f466e34 will have desired state: Ready
2022-04-04 15:01:46 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5f466e34 is in desired state: Ready
2022-04-04 15:01:46 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-788144473-3087648 in namespace namespace-76
2022-04-04 15:01:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-04 15:01:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-788144473-3087648 will have desired state: Ready
2022-04-04 15:01:47 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-788144473-3087648 is in desired state: Ready
2022-04-04 15:01:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic continuous-topic in namespace namespace-76
2022-04-04 15:01:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-04 15:01:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: continuous-topic will have desired state: Ready
2022-04-04 15:01:48 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: continuous-topic is in desired state: Ready
2022-04-04 15:01:48 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 15:01:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-producer in namespace namespace-76
2022-04-04 15:01:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-04 15:01:48 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-producer will be in active state
2022-04-04 15:01:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-consumer in namespace namespace-76
2022-04-04 15:01:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-04 15:01:49 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-consumer will be in active state
2022-04-04 15:01:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-373303554-2011997964 in namespace namespace-76
2022-04-04 15:01:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-04 15:01:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-373303554-2011997964 will have desired state: Ready
2022-04-04 15:01:51 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-373303554-2011997964 is in desired state: Ready
2022-04-04 15:01:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-5f466e34-kafka-clients in namespace namespace-76
2022-04-04 15:01:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-04 15:02:01 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 15:02:01 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@4ac1c18c, messages=[], arguments=[--topic, my-topic-788144473-3087648, --max-messages, 100, USER=my_user_373303554_2011997964, --bootstrap-server, my-cluster-5f466e34-kafka-bootstrap.namespace-76.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-5f466e34-kafka-clients-79b7df4776-k62xp', podNamespace='namespace-76', bootstrapServer='my-cluster-5f466e34-kafka-bootstrap.namespace-76.svc:9093', topicName='my-topic-788144473-3087648', maxMessages=100, kafkaUsername='my-user-373303554-2011997964', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@735a14c5}
2022-04-04 15:02:01 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-5f466e34-kafka-bootstrap.namespace-76.svc:9093:my-topic-788144473-3087648 from pod my-cluster-5f466e34-kafka-clients-79b7df4776-k62xp
2022-04-04 15:02:01 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5f466e34-kafka-clients-79b7df4776-k62xp -n namespace-76 -- /opt/kafka/producer.sh --topic my-topic-788144473-3087648 --max-messages 100 USER=my_user_373303554_2011997964 --bootstrap-server my-cluster-5f466e34-kafka-bootstrap.namespace-76.svc:9093
2022-04-04 15:02:05 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 15:02:05 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 15:02:05 [main] [32mINFO [m [AlternativeReconcileTriggersST:408] Add JBOD volume to the Kafka cluster my-cluster-5f466e34-kafka
2022-04-04 15:02:05 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-5f466e34-kafka rolling update
2022-04-04 15:03:16 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-5f466e34-kafka has been successfully rolled
2022-04-04 15:03:16 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-5f466e34-kafka to be ready
2022-04-04 15:03:49 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5f466e34 will have desired state: Ready
2022-04-04 15:03:49 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5f466e34 is in desired state: Ready
2022-04-04 15:03:49 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-5f466e34 is ready
2022-04-04 15:03:49 [main] [32mINFO [m [AlternativeReconcileTriggersST:419] Remove JBOD volume to the Kafka cluster my-cluster-5f466e34-kafka
2022-04-04 15:03:49 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-5f466e34-kafka rolling update
2022-04-04 15:05:14 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-5f466e34-kafka has been successfully rolled
2022-04-04 15:05:14 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-5f466e34-kafka to be ready
2022-04-04 15:05:41 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5f466e34 will have desired state: Ready
2022-04-04 15:05:41 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5f466e34 is in desired state: Ready
2022-04-04 15:05:41 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-5f466e34 is ready
2022-04-04 15:05:41 [main] [32mINFO [m [ClientUtils:61] Waiting till producer hello-world-producer and consumer hello-world-consumer finish
2022-04-04 15:10:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 15:10:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAddingAndRemovingJbodVolumes
2022-04-04 15:10:45 [main] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-consumer in namespace namespace-76
2022-04-04 15:10:45 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5f466e34 in namespace namespace-76
2022-04-04 15:10:45 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-producer in namespace namespace-76
2022-04-04 15:10:45 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic continuous-topic in namespace namespace-76
2022-04-04 15:10:45 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-788144473-3087648 in namespace namespace-76
2022-04-04 15:10:45 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-5f466e34-kafka-clients in namespace namespace-76
2022-04-04 15:10:45 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-373303554-2011997964 in namespace namespace-76
2022-04-04 15:11:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 15:11:35 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-76 for test case:testAddingAndRemovingJbodVolumes
2022-04-04 15:11:46 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testAddingAndRemovingJbodVolumes-FINISHED
2022-04-04 15:11:46 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 15:11:46 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 15:11:46 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testTriggerRollingUpdateAfterOverrideBootstrap-STARTED
2022-04-04 15:11:46 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 15:11:46 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-77 for test case:testTriggerRollingUpdateAfterOverrideBootstrap
2022-04-04 15:11:46 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-77
2022-04-04 15:11:47 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-77
2022-04-04 15:11:47 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-77
2022-04-04 15:11:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-17ed772d in namespace namespace-77
2022-04-04 15:11:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-77
2022-04-04 15:11:47 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-17ed772d will have desired state: Ready
2022-04-04 15:13:34 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-17ed772d is in desired state: Ready
2022-04-04 15:13:34 [main] [32mINFO [m [AlternativeReconcileTriggersST:228] Adding new bootstrap dns: kafka-test.XXXX.azure.XXXX.net to external listeners
2022-04-04 15:13:34 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-17ed772d-kafka rolling update
2022-04-04 15:14:44 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-17ed772d-kafka has been successfully rolled
2022-04-04 15:14:44 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-17ed772d-kafka to be ready
2022-04-04 15:15:16 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-17ed772d will have desired state: Ready
2022-04-04 15:15:16 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-17ed772d is in desired state: Ready
2022-04-04 15:15:16 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-17ed772d is ready
2022-04-04 15:15:16 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-17ed772d will have desired state: Ready
2022-04-04 15:15:16 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-17ed772d is in desired state: Ready
2022-04-04 15:15:16 [main] [32mINFO [m [AlternativeReconcileTriggersST:258] Encoding my-cluster-17ed772d-kafka-0.crt cert
2022-04-04 15:15:16 [main] [32mINFO [m [AlternativeReconcileTriggersST:263] Verifying that new DNS is in certificate subject alternative names
2022-04-04 15:15:16 [main] [32mINFO [m [AlternativeReconcileTriggersST:258] Encoding my-cluster-17ed772d-kafka-1.crt cert
2022-04-04 15:15:16 [main] [32mINFO [m [AlternativeReconcileTriggersST:263] Verifying that new DNS is in certificate subject alternative names
2022-04-04 15:15:16 [main] [32mINFO [m [AlternativeReconcileTriggersST:258] Encoding my-cluster-17ed772d-kafka-2.crt cert
2022-04-04 15:15:16 [main] [32mINFO [m [AlternativeReconcileTriggersST:263] Verifying that new DNS is in certificate subject alternative names
2022-04-04 15:15:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 15:15:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTriggerRollingUpdateAfterOverrideBootstrap
2022-04-04 15:15:16 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-17ed772d in namespace namespace-77
2022-04-04 15:15:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 15:15:26 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-77 for test case:testTriggerRollingUpdateAfterOverrideBootstrap
2022-04-04 15:16:09 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testTriggerRollingUpdateAfterOverrideBootstrap-FINISHED
2022-04-04 15:16:09 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 15:16:09 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 15:16:09 [main] [32mINFO [m [ResourceManager:346] In context AlternativeReconcileTriggersST is everything deleted.
2022-04-04 15:16:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2,056.253 s - in io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST
[[1;34mINFO[m] Running io.strimzi.systemtest.rollingupdate.RollingUpdateST
2022-04-04 15:16:15 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: rolling-update-st
2022-04-04 15:16:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: rolling-update-st
2022-04-04 15:16:15 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: rolling-update-st
2022-04-04 15:16:15 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 15:16:15 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testMetricsChange-STARTED
2022-04-04 15:16:15 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 15:16:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c3245ed0 in namespace rolling-update-st
2022-04-04 15:16:15 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c3245ed0 will have desired state: Ready
2022-04-04 15:17:47 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c3245ed0 is in desired state: Ready
2022-04-04 15:17:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-c3245ed0-kafka-clients in namespace rolling-update-st
2022-04-04 15:17:57 [main] [32mINFO [m [RollingUpdateST:755] Check if metrics are present in pod of Kafka and Zookeeper
2022-04-04 15:17:58 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.10 from Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 finished with return code: 0
2022-04-04 15:17:59 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.11 from Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 finished with return code: 0
2022-04-04 15:17:59 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.12 from Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 finished with return code: 0
2022-04-04 15:18:00 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.8 from Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 finished with return code: 0
2022-04-04 15:18:00 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.9 from Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 finished with return code: 0
2022-04-04 15:18:01 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.7 from Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 finished with return code: 0
2022-04-04 15:18:01 [main] [32mINFO [m [RollingUpdateST:765] Changing metrics to something else
2022-04-04 15:18:01 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-c3245ed0-zookeeper are stable
2022-04-04 15:18:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:18:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:18:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:18:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:18:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:18:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:18:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:18:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:18:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:18:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:18:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:18:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:18:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:18:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:18:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:18:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:18:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:18:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:18:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:18:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:18:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:18:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:18:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:18:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:18:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:18:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:18:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:18:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:18:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:18:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:18:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:18:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:18:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:18:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:18:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:18:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:18:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:18:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:18:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:18:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:18:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:18:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:18:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:18:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:18:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:18:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:18:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:18:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:18:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:18:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:18:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:18:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:18:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:18:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:18:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:18:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:18:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:18:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:18:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:18:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:18:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:18:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:18:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:18:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:18:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:18:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:18:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:18:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:18:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:18:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:18:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:18:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:18:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:18:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:18:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:18:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:18:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:18:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:18:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:18:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:18:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:18:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:18:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:18:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:18:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:18:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:18:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:18:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:18:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:18:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:18:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:18:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:18:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:18:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:18:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:18:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:18:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:18:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:18:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:18:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:18:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:18:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:18:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:18:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:18:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:18:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:18:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:18:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:18:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:18:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:18:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:18:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:18:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:18:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:18:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:18:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:18:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:18:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:18:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:18:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:18:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:18:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:18:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:18:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:18:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:18:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:18:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:18:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:18:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:18:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:18:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:18:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:18:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:18:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:18:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:18:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:18:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:18:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:18:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:18:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:18:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:18:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:18:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:18:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:18:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:18:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:18:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:18:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:18:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:18:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:18:50 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-c3245ed0-zookeeper-0 ,my-cluster-c3245ed0-zookeeper-1 ,my-cluster-c3245ed0-zookeeper-2
2022-04-04 15:18:50 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-c3245ed0-kafka are stable
2022-04-04 15:18:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:18:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:18:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:18:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:18:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:18:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:18:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:18:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:18:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:18:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:18:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:18:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:18:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:18:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:18:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:18:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:18:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:18:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:18:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:18:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:18:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:18:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:18:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:18:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:18:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:18:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:18:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:18:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:18:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:18:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:18:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:18:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:18:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:18:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:18:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:18:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:18:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:18:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:18:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:18:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:18:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:18:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:18:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:18:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:18:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:18:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:18:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:18:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:18:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:18:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:19:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:19:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:19:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:19:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:19:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:19:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:19:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:19:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:19:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:19:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:19:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:19:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:19:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:19:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:19:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:19:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:19:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:19:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:19:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:19:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:19:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:19:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:19:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:19:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:19:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:19:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:19:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:19:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:19:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:19:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:19:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:19:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:19:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:19:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:19:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:19:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:19:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:19:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:19:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:19:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:19:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:19:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:19:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:19:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:19:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:19:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:19:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:19:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:19:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:19:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:19:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:19:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:19:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:19:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:19:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:19:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:19:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:19:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:19:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:19:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:19:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:19:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:19:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:19:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:19:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:19:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:19:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:19:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:19:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:19:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:19:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:19:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:19:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:19:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:19:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:19:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:19:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:19:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:19:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:19:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:19:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:19:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:19:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:19:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:19:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:19:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:19:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:19:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:19:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:19:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:19:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:19:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:19:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:19:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:19:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:19:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:19:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:19:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:19:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:19:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:19:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:19:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:19:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:19:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:19:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:19:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:19:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:19:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:19:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:19:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:19:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:19:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:19:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:19:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:19:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:19:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:19:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:19:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:19:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:19:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:19:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:19:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:19:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:19:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:19:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:19:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:19:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:19:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:19:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:19:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:19:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:19:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:19:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:19:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:19:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:19:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:19:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:19:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:19:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:19:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:19:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:19:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:19:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:19:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:19:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:19:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:19:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:19:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:19:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:19:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:19:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:19:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:19:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:19:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:19:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:19:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:19:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:19:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:19:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:19:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:19:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:19:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:19:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:19:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:19:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:19:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:19:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:19:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:19:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:19:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:19:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:19:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:19:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:19:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:19:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:19:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:19:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:19:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:19:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:19:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:19:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:19:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:19:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:19:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:19:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:19:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:19:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:19:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:19:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:19:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:19:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:19:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:19:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:19:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:19:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:19:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:19:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:19:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:19:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:19:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:19:40 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-c3245ed0-kafka-0 ,my-cluster-c3245ed0-kafka-1 ,my-cluster-c3245ed0-kafka-2 ,my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 ,my-cluster-c3245ed0-kafka-exporter-fc946996-hrpgg
2022-04-04 15:19:40 [main] [32mINFO [m [RollingUpdateST:800] Check if Kafka and Zookeeper pods didn't roll
2022-04-04 15:19:40 [main] [32mINFO [m [RollingUpdateST:804] Check if Kafka and Zookeeper metrics are changed
2022-04-04 15:19:40 [main] [32mINFO [m [RollingUpdateST:818] Check if metrics are present in pod of Kafka and Zookeeper
2022-04-04 15:19:40 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.10 from Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 finished with return code: 0
2022-04-04 15:19:41 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.11 from Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 finished with return code: 0
2022-04-04 15:19:41 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.12 from Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 finished with return code: 0
2022-04-04 15:19:41 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.8 from Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 finished with return code: 0
2022-04-04 15:19:41 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.9 from Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 finished with return code: 0
2022-04-04 15:19:42 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.7 from Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 finished with return code: 0
2022-04-04 15:19:42 [main] [32mINFO [m [RollingUpdateST:829] Removing metrics from Kafka and Zookeeper and setting them to null
2022-04-04 15:19:42 [main] [32mINFO [m [RollingUpdateST:836] Wait if Kafka and Zookeeper pods will roll
2022-04-04 15:19:42 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-c3245ed0-zookeeper rolling update
2022-04-04 15:20:42 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-c3245ed0-zookeeper has been successfully rolled
2022-04-04 15:20:42 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-c3245ed0-zookeeper to be ready
2022-04-04 15:21:14 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-c3245ed0-kafka rolling update
2022-04-04 15:22:09 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-c3245ed0-kafka has been successfully rolled
2022-04-04 15:22:09 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-c3245ed0-kafka to be ready
2022-04-04 15:22:45 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c3245ed0 will have desired state: Ready
2022-04-04 15:22:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c3245ed0 is in desired state: Ready
2022-04-04 15:22:45 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-c3245ed0 is ready
2022-04-04 15:22:45 [main] [32mINFO [m [RollingUpdateST:840] Check if metrics are not existing in pods
2022-04-04 15:22:46 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.10 from Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 finished with return code: 7
2022-04-04 15:22:46 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.11 from Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 finished with return code: 7
2022-04-04 15:22:46 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.12 from Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 finished with return code: 7
2022-04-04 15:22:47 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.8 from Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 finished with return code: 7
2022-04-04 15:22:47 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.9 from Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 finished with return code: 7
2022-04-04 15:22:47 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.7 from Pod my-cluster-c3245ed0-kafka-clients-5679cdbd99-2l9j7 finished with return code: 7
2022-04-04 15:22:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 15:22:47 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMetricsChange
2022-04-04 15:22:47 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-c3245ed0-kafka-clients in namespace rolling-update-st
2022-04-04 15:22:47 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c3245ed0 in namespace rolling-update-st
2022-04-04 15:23:37 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 15:23:37 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testMetricsChange-FINISHED
2022-04-04 15:23:37 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 15:23:37 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 15:23:37 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testExternalLoggingChangeTriggerRollingUpdate-STARTED
2022-04-04 15:23:37 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 15:23:37 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-78 for test case:testExternalLoggingChangeTriggerRollingUpdate
2022-04-04 15:23:37 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-78
2022-04-04 15:23:37 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-78
2022-04-04 15:23:37 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-78
2022-04-04 15:23:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-bcae5b30 in namespace namespace-78
2022-04-04 15:23:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-78
2022-04-04 15:23:37 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-bcae5b30 will have desired state: Ready
2022-04-04 15:24:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-bcae5b30 is in desired state: Ready
2022-04-04 15:24:45 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-bcae5b30-zookeeper rolling update
2022-04-04 15:25:40 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-bcae5b30-zookeeper has been successfully rolled
2022-04-04 15:25:40 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-bcae5b30-zookeeper to be ready
2022-04-04 15:26:10 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-bcae5b30-kafka rolling update
2022-04-04 15:27:15 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-bcae5b30-kafka has been successfully rolled
2022-04-04 15:27:15 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-bcae5b30-kafka to be ready
2022-04-04 15:27:41 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-bcae5b30 will have desired state: Ready
2022-04-04 15:27:41 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-bcae5b30 is in desired state: Ready
2022-04-04 15:27:41 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-bcae5b30 is ready
2022-04-04 15:27:41 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-bcae5b30-zookeeper rolling update
2022-04-04 15:29:16 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-bcae5b30-zookeeper has been successfully rolled
2022-04-04 15:29:16 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-bcae5b30-zookeeper to be ready
2022-04-04 15:29:42 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-bcae5b30-kafka rolling update
2022-04-04 15:30:47 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-bcae5b30-kafka has been successfully rolled
2022-04-04 15:30:47 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-bcae5b30-kafka to be ready
2022-04-04 15:31:11 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-bcae5b30 will have desired state: Ready
2022-04-04 15:31:11 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-bcae5b30 is in desired state: Ready
2022-04-04 15:31:11 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-bcae5b30 is ready
2022-04-04 15:31:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 15:31:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testExternalLoggingChangeTriggerRollingUpdate
2022-04-04 15:31:11 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-bcae5b30 in namespace namespace-78
2022-04-04 15:31:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 15:31:21 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-78 for test case:testExternalLoggingChangeTriggerRollingUpdate
2022-04-04 15:32:05 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testExternalLoggingChangeTriggerRollingUpdate-FINISHED
2022-04-04 15:32:05 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 15:32:05 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 15:32:05 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testBrokerConfigurationChangeTriggerRollingUpdate-STARTED
2022-04-04 15:32:05 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 15:32:05 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-79 for test case:testBrokerConfigurationChangeTriggerRollingUpdate
2022-04-04 15:32:05 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-79
2022-04-04 15:32:05 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-79
2022-04-04 15:32:05 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-79
2022-04-04 15:32:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a3dc596f in namespace namespace-79
2022-04-04 15:32:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-79
2022-04-04 15:32:05 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a3dc596f will have desired state: Ready
2022-04-04 15:33:16 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a3dc596f is in desired state: Ready
2022-04-04 15:33:16 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-a3dc596f-kafka rolling update
2022-04-04 15:34:36 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-a3dc596f-kafka has been successfully rolled
2022-04-04 15:34:36 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-a3dc596f-kafka to be ready
2022-04-04 15:35:01 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a3dc596f will have desired state: Ready
2022-04-04 15:35:01 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a3dc596f is in desired state: Ready
2022-04-04 15:35:01 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-a3dc596f is ready
2022-04-04 15:35:01 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 15:35:01 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBrokerConfigurationChangeTriggerRollingUpdate
2022-04-04 15:35:01 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a3dc596f in namespace namespace-79
2022-04-04 15:35:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 15:35:11 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-79 for test case:testBrokerConfigurationChangeTriggerRollingUpdate
2022-04-04 15:35:55 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testBrokerConfigurationChangeTriggerRollingUpdate-FINISHED
2022-04-04 15:35:55 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 15:35:55 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 15:35:55 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testManualKafkaConfigMapChangeDontTriggerRollingUpdate-STARTED
2022-04-04 15:35:55 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 15:35:55 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-80 for test case:testManualKafkaConfigMapChangeDontTriggerRollingUpdate
2022-04-04 15:35:55 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-80
2022-04-04 15:35:55 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-80
2022-04-04 15:35:55 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-80
2022-04-04 15:35:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-fab0933f in namespace namespace-80
2022-04-04 15:35:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-80
2022-04-04 15:35:55 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-fab0933f will have desired state: Ready
2022-04-04 15:37:40 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-fab0933f is in desired state: Ready
2022-04-04 15:37:40 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-fab0933f are stable
2022-04-04 15:37:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:37:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:37:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:37:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:37:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:37:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:37:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:37:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:37:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:37:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:37:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:37:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:37:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:37:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:37:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:37:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:37:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:37:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:37:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:37:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:37:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:37:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:37:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:37:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:37:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:37:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:37:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:37:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:37:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:37:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:37:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:37:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:37:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:37:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:37:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:37:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:37:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:37:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:37:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:37:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:37:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:37:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:37:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:37:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:37:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:37:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:37:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:37:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:37:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:37:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:37:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:37:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:37:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:37:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:37:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:37:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:37:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:37:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:37:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:37:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:37:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:37:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:37:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:37:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:37:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:37:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:37:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:37:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:37:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:37:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:37:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:37:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:37:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:37:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:37:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:37:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:37:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:37:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:37:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:37:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:37:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:37:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:37:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:37:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:37:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:37:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:37:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:37:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:37:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:37:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:37:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:37:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:37:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:37:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:37:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:37:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:37:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:37:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:37:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:37:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:37:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:37:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:37:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:37:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:37:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:37:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:37:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:37:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:37:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:37:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:37:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:37:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:37:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:37:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:37:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:37:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:37:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:37:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:37:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:37:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:37:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:37:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:37:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:37:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:37:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:37:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:37:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:37:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:37:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:37:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:37:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:37:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:37:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:37:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:37:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:37:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:37:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:37:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:37:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:37:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:38:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:38:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:38:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:38:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:38:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:38:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:38:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:38:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:38:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:38:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:38:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:38:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:38:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:38:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:38:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:38:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:38:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:38:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:38:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:38:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:38:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:38:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:38:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:38:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:38:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:38:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:38:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:38:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:38:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:38:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:38:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:38:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:38:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:38:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:38:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:38:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:38:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:38:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:38:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:38:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:38:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:38:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:38:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:38:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:38:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:38:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:38:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:38:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:38:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:38:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:38:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:38:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:38:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:38:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:38:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:38:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:38:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:38:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:38:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:38:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:38:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:38:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:38:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:38:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:38:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:38:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:38:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:38:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:38:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:38:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:38:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:38:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:38:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:38:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:38:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:38:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:38:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:38:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:38:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:38:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:38:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:38:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:38:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:38:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:38:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:38:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:38:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:38:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:38:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:38:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:38:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:38:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:38:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:38:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:38:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:38:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:38:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:38:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:38:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:38:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:38:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:38:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:38:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:38:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:38:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:38:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:38:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:38:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:38:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:38:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:38:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:38:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:38:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:38:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:38:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:38:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:38:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:38:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:38:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:38:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:38:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:38:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:38:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:38:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:38:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:38:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:38:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:38:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:38:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:38:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:38:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:38:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:38:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:38:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:38:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:38:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:38:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:38:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:38:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:38:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:38:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:38:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:38:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:38:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:38:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:38:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:38:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:38:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:38:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:38:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:38:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:38:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:38:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:38:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:38:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:38:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:38:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:38:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:38:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:38:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:38:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:38:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:38:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:38:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:38:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:38:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:38:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:38:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:38:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:38:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:38:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:38:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:38:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:38:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:38:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:38:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:38:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:38:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:38:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:38:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:38:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:38:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:38:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:38:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:38:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:38:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:38:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:38:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:38:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:38:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:38:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:38:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:38:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:38:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:38:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:38:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:38:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:38:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:38:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:38:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:38:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:38:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:38:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:38:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:38:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:38:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:38:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:38:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:38:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:38:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fab0933f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:38:30 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-fab0933f-entity-operator-7696bb7976-vmlnn ,my-cluster-fab0933f-kafka-0 ,my-cluster-fab0933f-kafka-1 ,my-cluster-fab0933f-kafka-2 ,my-cluster-fab0933f-zookeeper-0 ,my-cluster-fab0933f-zookeeper-1 ,my-cluster-fab0933f-zookeeper-2
2022-04-04 15:38:30 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 15:38:30 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testManualKafkaConfigMapChangeDontTriggerRollingUpdate
2022-04-04 15:38:30 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-fab0933f in namespace namespace-80
2022-04-04 15:38:40 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 15:38:40 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-80 for test case:testManualKafkaConfigMapChangeDontTriggerRollingUpdate
2022-04-04 15:39:23 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testManualKafkaConfigMapChangeDontTriggerRollingUpdate-FINISHED
2022-04-04 15:39:23 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 15:39:23 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 15:39:23 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testZookeeperScaleUpScaleDown-STARTED
2022-04-04 15:39:23 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 15:39:23 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-81 for test case:testZookeeperScaleUpScaleDown
2022-04-04 15:39:23 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-81
2022-04-04 15:39:23 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-81
2022-04-04 15:39:23 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-81
2022-04-04 15:39:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5cf5b805 in namespace namespace-81
2022-04-04 15:39:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-81
2022-04-04 15:39:23 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5cf5b805 will have desired state: Ready
2022-04-04 15:40:43 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5cf5b805 is in desired state: Ready
2022-04-04 15:40:43 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-943968668-1936113941 in namespace namespace-81
2022-04-04 15:40:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-81
2022-04-04 15:40:43 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-943968668-1936113941 will have desired state: Ready
2022-04-04 15:40:44 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-943968668-1936113941 is in desired state: Ready
2022-04-04 15:40:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-2024143818-666842333 in namespace namespace-81
2022-04-04 15:40:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-81
2022-04-04 15:40:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-2024143818-666842333 will have desired state: Ready
2022-04-04 15:40:45 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-2024143818-666842333 is in desired state: Ready
2022-04-04 15:40:45 [main] [32mINFO [m [RollingUpdateST:398] Running zookeeperScaleUpScaleDown with cluster my-cluster-5cf5b805
2022-04-04 15:40:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-5cf5b805-kafka-clients in namespace namespace-81
2022-04-04 15:40:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-81
2022-04-04 15:40:55 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 15:40:55 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@7e24fc5b, messages=[], arguments=[--topic, my-topic-943968668-1936113941, --max-messages, 100, USER=my_user_2024143818_666842333, --bootstrap-server, my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-5cf5b805-kafka-clients-5f7978fd4b-ggd7h', podNamespace='namespace-81', bootstrapServer='my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-943968668-1936113941', maxMessages=100, kafkaUsername='my-user-2024143818-666842333', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1e3a421}
2022-04-04 15:40:55 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093:my-topic-943968668-1936113941 from pod my-cluster-5cf5b805-kafka-clients-5f7978fd4b-ggd7h
2022-04-04 15:40:55 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5cf5b805-kafka-clients-5f7978fd4b-ggd7h -n namespace-81 -- /opt/kafka/producer.sh --topic my-topic-943968668-1936113941 --max-messages 100 USER=my_user_2024143818_666842333 --bootstrap-server my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093
2022-04-04 15:40:58 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 15:40:58 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 15:40:58 [main] [32mINFO [m [RollingUpdateST:426] Scale up Zookeeper to 7
2022-04-04 15:40:58 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@50d866c6, messages=[], arguments=[--topic, my-topic-943968668-1936113941, --max-messages, 100, --group-instance-id, instance1101883854, USER=my_user_2024143818_666842333, --group-id, my-consumer-group-645515957, --bootstrap-server, my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-5cf5b805-kafka-clients-5f7978fd4b-ggd7h', podNamespace='namespace-81', bootstrapServer='my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-943968668-1936113941', maxMessages=100, kafkaUsername='my-user-2024143818-666842333', consumerGroupName='my-consumer-group-645515957', consumerInstanceId='instance1101883854', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4b2faf08}
2022-04-04 15:40:58 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093:my-topic-943968668-1936113941 from pod my-cluster-5cf5b805-kafka-clients-5f7978fd4b-ggd7h
2022-04-04 15:40:58 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5cf5b805-kafka-clients-5f7978fd4b-ggd7h -n namespace-81 -- /opt/kafka/consumer.sh --topic my-topic-943968668-1936113941 --max-messages 100 --group-instance-id instance1101883854 USER=my_user_2024143818_666842333 --group-id my-consumer-group-645515957 --bootstrap-server my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093
2022-04-04 15:41:05 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 15:41:05 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 15:41:05 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 7 Pod(s) of my-cluster-5cf5b805-zookeeper to be ready
2022-04-04 15:43:37 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5cf5b805 will have desired state: Ready
2022-04-04 15:43:37 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5cf5b805 is in desired state: Ready
2022-04-04 15:43:37 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-5cf5b805 is ready
2022-04-04 15:43:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-5cf5b805-zookeeper-0 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-04 15:43:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 15:43:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-5cf5b805-zookeeper-1 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-04 15:43:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 15:43:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-5cf5b805-zookeeper-2 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-04 15:43:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 15:43:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-5cf5b805-zookeeper-3 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-04 15:43:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 15:43:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-5cf5b805-zookeeper-4 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-04 15:43:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 15:43:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-5cf5b805-zookeeper-5 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-04 15:43:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 15:43:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-5cf5b805-zookeeper-6 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-04 15:43:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 15:43:38 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@46d2c993, messages=[], arguments=[--topic, my-topic-943968668-1936113941, --max-messages, 100, --group-instance-id, instance1198237370, USER=my_user_2024143818_666842333, --group-id, my-consumer-group-40415702, --bootstrap-server, my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-5cf5b805-kafka-clients-5f7978fd4b-ggd7h', podNamespace='namespace-81', bootstrapServer='my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-943968668-1936113941', maxMessages=100, kafkaUsername='my-user-2024143818-666842333', consumerGroupName='my-consumer-group-40415702', consumerInstanceId='instance1198237370', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@64f3bc6c}
2022-04-04 15:43:38 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093:my-topic-943968668-1936113941 from pod my-cluster-5cf5b805-kafka-clients-5f7978fd4b-ggd7h
2022-04-04 15:43:38 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5cf5b805-kafka-clients-5f7978fd4b-ggd7h -n namespace-81 -- /opt/kafka/consumer.sh --topic my-topic-943968668-1936113941 --max-messages 100 --group-instance-id instance1198237370 USER=my_user_2024143818_666842333 --group-id my-consumer-group-40415702 --bootstrap-server my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093
2022-04-04 15:43:45 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 15:43:45 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 15:43:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1644618621-1126522533 in namespace namespace-81
2022-04-04 15:43:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-81
2022-04-04 15:43:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1644618621-1126522533 will have desired state: Ready
2022-04-04 15:43:46 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1644618621-1126522533 is in desired state: Ready
2022-04-04 15:43:46 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@381c23d4, messages=[], arguments=[--topic, my-topic-1644618621-1126522533, --max-messages, 100, USER=my_user_2024143818_666842333, --bootstrap-server, my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-5cf5b805-kafka-clients-5f7978fd4b-ggd7h', podNamespace='namespace-81', bootstrapServer='my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-1644618621-1126522533', maxMessages=100, kafkaUsername='my-user-2024143818-666842333', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5fd1a6aa}
2022-04-04 15:43:46 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093:my-topic-1644618621-1126522533 from pod my-cluster-5cf5b805-kafka-clients-5f7978fd4b-ggd7h
2022-04-04 15:43:46 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5cf5b805-kafka-clients-5f7978fd4b-ggd7h -n namespace-81 -- /opt/kafka/producer.sh --topic my-topic-1644618621-1126522533 --max-messages 100 USER=my_user_2024143818_666842333 --bootstrap-server my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093
2022-04-04 15:43:50 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 15:43:50 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 15:43:50 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@11bb3f9b, messages=[], arguments=[--topic, my-topic-1644618621-1126522533, --max-messages, 100, --group-instance-id, instance849739311, USER=my_user_2024143818_666842333, --group-id, my-consumer-group-824514106, --bootstrap-server, my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-5cf5b805-kafka-clients-5f7978fd4b-ggd7h', podNamespace='namespace-81', bootstrapServer='my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-1644618621-1126522533', maxMessages=100, kafkaUsername='my-user-2024143818-666842333', consumerGroupName='my-consumer-group-824514106', consumerInstanceId='instance849739311', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@41f5f867}
2022-04-04 15:43:50 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093:my-topic-1644618621-1126522533 from pod my-cluster-5cf5b805-kafka-clients-5f7978fd4b-ggd7h
2022-04-04 15:43:50 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5cf5b805-kafka-clients-5f7978fd4b-ggd7h -n namespace-81 -- /opt/kafka/consumer.sh --topic my-topic-1644618621-1126522533 --max-messages 100 --group-instance-id instance849739311 USER=my_user_2024143818_666842333 --group-id my-consumer-group-824514106 --bootstrap-server my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093
2022-04-04 15:43:57 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 15:43:57 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 15:43:57 [main] [32mINFO [m [RollingUpdateST:453] Scale down Zookeeper to 3
2022-04-04 15:43:57 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-5cf5b805-zookeeper to be ready
2022-04-04 15:44:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5cf5b805 will have desired state: Ready
2022-04-04 15:44:44 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5cf5b805 is in desired state: Ready
2022-04-04 15:44:44 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-5cf5b805 is ready
2022-04-04 15:44:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-5cf5b805-zookeeper-0 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-04 15:44:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 15:44:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-5cf5b805-zookeeper-1 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-04 15:44:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 15:44:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-5cf5b805-zookeeper-2 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-04 15:44:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 15:44:45 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@748e432b, messages=[], arguments=[--topic, my-topic-1644618621-1126522533, --max-messages, 100, --group-instance-id, instance597970848, USER=my_user_2024143818_666842333, --group-id, my-consumer-group-1326980378, --bootstrap-server, my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-5cf5b805-kafka-clients-5f7978fd4b-ggd7h', podNamespace='namespace-81', bootstrapServer='my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-1644618621-1126522533', maxMessages=100, kafkaUsername='my-user-2024143818-666842333', consumerGroupName='my-consumer-group-1326980378', consumerInstanceId='instance597970848', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1a56a6c6}
2022-04-04 15:44:45 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093:my-topic-1644618621-1126522533 from pod my-cluster-5cf5b805-kafka-clients-5f7978fd4b-ggd7h
2022-04-04 15:44:45 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5cf5b805-kafka-clients-5f7978fd4b-ggd7h -n namespace-81 -- /opt/kafka/consumer.sh --topic my-topic-1644618621-1126522533 --max-messages 100 --group-instance-id instance597970848 USER=my_user_2024143818_666842333 --group-id my-consumer-group-1326980378 --bootstrap-server my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093
2022-04-04 15:44:52 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 15:44:52 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 15:44:52 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1617348568-1470907286 in namespace namespace-81
2022-04-04 15:44:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-81
2022-04-04 15:44:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1617348568-1470907286 will have desired state: Ready
2022-04-04 15:44:53 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1617348568-1470907286 is in desired state: Ready
2022-04-04 15:44:53 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@16d9a719, messages=[], arguments=[--topic, my-topic-1617348568-1470907286, --max-messages, 100, USER=my_user_2024143818_666842333, --bootstrap-server, my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-5cf5b805-kafka-clients-5f7978fd4b-ggd7h', podNamespace='namespace-81', bootstrapServer='my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-1617348568-1470907286', maxMessages=100, kafkaUsername='my-user-2024143818-666842333', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3c81edc6}
2022-04-04 15:44:53 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093:my-topic-1617348568-1470907286 from pod my-cluster-5cf5b805-kafka-clients-5f7978fd4b-ggd7h
2022-04-04 15:44:53 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5cf5b805-kafka-clients-5f7978fd4b-ggd7h -n namespace-81 -- /opt/kafka/producer.sh --topic my-topic-1617348568-1470907286 --max-messages 100 USER=my_user_2024143818_666842333 --bootstrap-server my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093
2022-04-04 15:44:56 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 15:44:56 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 15:44:56 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3f07d890, messages=[], arguments=[--topic, my-topic-1617348568-1470907286, --max-messages, 100, --group-instance-id, instance211617303, USER=my_user_2024143818_666842333, --group-id, my-consumer-group-1925915896, --bootstrap-server, my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-5cf5b805-kafka-clients-5f7978fd4b-ggd7h', podNamespace='namespace-81', bootstrapServer='my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-1617348568-1470907286', maxMessages=100, kafkaUsername='my-user-2024143818-666842333', consumerGroupName='my-consumer-group-1925915896', consumerInstanceId='instance211617303', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@39964392}
2022-04-04 15:44:56 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093:my-topic-1617348568-1470907286 from pod my-cluster-5cf5b805-kafka-clients-5f7978fd4b-ggd7h
2022-04-04 15:44:56 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5cf5b805-kafka-clients-5f7978fd4b-ggd7h -n namespace-81 -- /opt/kafka/consumer.sh --topic my-topic-1617348568-1470907286 --max-messages 100 --group-instance-id instance211617303 USER=my_user_2024143818_666842333 --group-id my-consumer-group-1925915896 --bootstrap-server my-cluster-5cf5b805-kafka-bootstrap.namespace-81.svc:9093
2022-04-04 15:45:03 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 15:45:03 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 15:45:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 15:45:03 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testZookeeperScaleUpScaleDown
2022-04-04 15:45:03 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-5cf5b805-kafka-clients in namespace namespace-81
2022-04-04 15:45:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1617348568-1470907286 in namespace namespace-81
2022-04-04 15:45:03 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1644618621-1126522533 in namespace namespace-81
2022-04-04 15:45:03 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-943968668-1936113941 in namespace namespace-81
2022-04-04 15:45:03 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-2024143818-666842333 in namespace namespace-81
2022-04-04 15:45:03 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5cf5b805 in namespace namespace-81
2022-04-04 15:45:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 15:45:43 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-81 for test case:testZookeeperScaleUpScaleDown
2022-04-04 15:45:49 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testZookeeperScaleUpScaleDown-FINISHED
2022-04-04 15:45:49 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 15:45:49 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 15:45:49 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testRecoveryDuringZookeeperRollingUpdate-STARTED
2022-04-04 15:45:49 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 15:45:49 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-82 for test case:testRecoveryDuringZookeeperRollingUpdate
2022-04-04 15:45:49 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-82
2022-04-04 15:45:49 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-82
2022-04-04 15:45:49 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-82
2022-04-04 15:45:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-145158bc in namespace namespace-82
2022-04-04 15:45:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-82
2022-04-04 15:45:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1213730633-459640807 in namespace namespace-82
2022-04-04 15:45:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-82
2022-04-04 15:45:49 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-145158bc will have desired state: Ready
2022-04-04 15:47:29 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-145158bc is in desired state: Ready
2022-04-04 15:47:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1213730633-459640807 will have desired state: Ready
2022-04-04 15:47:29 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1213730633-459640807 is in desired state: Ready
2022-04-04 15:47:29 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-2098311081-988766631 in namespace namespace-82
2022-04-04 15:47:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-82
2022-04-04 15:47:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-2098311081-988766631 will have desired state: Ready
2022-04-04 15:47:30 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-2098311081-988766631 is in desired state: Ready
2022-04-04 15:47:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-145158bc-kafka-clients in namespace namespace-82
2022-04-04 15:47:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-82
2022-04-04 15:47:40 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 15:47:40 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@64ffd1ef, messages=[], arguments=[--topic, my-topic-1213730633-459640807, --max-messages, 100, USER=my_user_2098311081_988766631, --bootstrap-server, my-cluster-145158bc-kafka-bootstrap.namespace-82.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl', podNamespace='namespace-82', bootstrapServer='my-cluster-145158bc-kafka-bootstrap.namespace-82.svc:9093', topicName='my-topic-1213730633-459640807', maxMessages=100, kafkaUsername='my-user-2098311081-988766631', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@543edb9}
2022-04-04 15:47:40 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-145158bc-kafka-bootstrap.namespace-82.svc:9093:my-topic-1213730633-459640807 from pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl
2022-04-04 15:47:40 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl -n namespace-82 -- /opt/kafka/producer.sh --topic my-topic-1213730633-459640807 --max-messages 100 USER=my_user_2098311081_988766631 --bootstrap-server my-cluster-145158bc-kafka-bootstrap.namespace-82.svc:9093
2022-04-04 15:47:44 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 15:47:44 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 15:47:44 [main] [32mINFO [m [RollingUpdateST:117] Update resources for pods
2022-04-04 15:47:44 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@72fcca2e, messages=[], arguments=[--topic, my-topic-1213730633-459640807, --max-messages, 100, --group-instance-id, instance1135276810, USER=my_user_2098311081_988766631, --group-id, my-consumer-group-335985178, --bootstrap-server, my-cluster-145158bc-kafka-bootstrap.namespace-82.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl', podNamespace='namespace-82', bootstrapServer='my-cluster-145158bc-kafka-bootstrap.namespace-82.svc:9093', topicName='my-topic-1213730633-459640807', maxMessages=100, kafkaUsername='my-user-2098311081-988766631', consumerGroupName='my-consumer-group-335985178', consumerInstanceId='instance1135276810', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@68960e7a}
2022-04-04 15:47:44 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-145158bc-kafka-bootstrap.namespace-82.svc:9093:my-topic-1213730633-459640807 from pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl
2022-04-04 15:47:44 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl -n namespace-82 -- /opt/kafka/consumer.sh --topic my-topic-1213730633-459640807 --max-messages 100 --group-instance-id instance1135276810 USER=my_user_2098311081_988766631 --group-id my-consumer-group-335985178 --bootstrap-server my-cluster-145158bc-kafka-bootstrap.namespace-82.svc:9093
2022-04-04 15:47:51 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 15:47:51 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 15:47:51 [main] [32mINFO [m [ClientUtils:45] Consumer successfully consumed 100 messages for the 1 time
2022-04-04 15:47:51 [main] [32mINFO [m [PodUtils:277] Wait for at least one pod with prefix: my-cluster-145158bc-zookeeper will be in pending phase
2022-04-04 15:47:51 [main] [32mINFO [m [RollingUpdateST:130] Verifying stability of zookeeper pods except the one, which is in pending phase
2022-04-04 15:47:51 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-145158bc-zookeeper are stable
2022-04-04 15:47:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:47:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:47:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:47:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:47:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:47:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:47:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:47:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:47:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:47:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:47:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:47:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:47:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:47:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:47:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:47:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:47:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:47:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:48:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:48:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:48:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:48:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:48:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:48:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:48:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:48:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:48:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:48:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:48:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:48:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:48:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:48:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:48:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:48:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:48:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:48:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:48:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:48:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:48:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:48:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:48:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:48:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:48:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:48:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:48:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:48:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:48:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:48:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:48:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:48:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:48:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:48:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:48:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:48:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:48:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:48:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:48:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:48:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:48:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:48:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:48:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:48:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:48:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:48:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:48:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:48:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:48:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:48:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:48:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:48:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:48:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:48:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:48:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:48:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:48:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:48:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:48:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:48:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:48:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:48:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:48:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:48:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:48:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:48:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:48:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:48:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:48:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:48:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:48:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:48:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:48:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:48:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:48:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:48:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:48:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:48:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:48:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:48:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:48:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:48:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:48:40 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-145158bc-zookeeper-0 ,my-cluster-145158bc-zookeeper-2
2022-04-04 15:48:40 [main] [32mINFO [m [RollingUpdateST:133] Verifying stability of kafka pods
2022-04-04 15:48:40 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-145158bc-kafka are stable
2022-04-04 15:48:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:48:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:48:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:48:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:48:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:48:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:48:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:48:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:48:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:48:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:48:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:48:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:48:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:48:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:48:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:48:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:48:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:48:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:48:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:48:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:48:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:48:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:48:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:48:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:48:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:48:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:48:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:48:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:48:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:48:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:48:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:48:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:48:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:48:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:48:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:48:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:48:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:48:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:48:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:48:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:48:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:48:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:48:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:48:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:48:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:48:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:48:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:48:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:48:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:48:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:48:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:48:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:48:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:48:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:48:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:48:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:48:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:48:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:48:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:48:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:48:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:48:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:48:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:48:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:48:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:48:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:48:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:48:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:48:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:48:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:48:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:48:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:48:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:48:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:48:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:48:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:48:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:48:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:48:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:48:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:49:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:49:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:49:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:49:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:49:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:49:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:49:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:49:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:49:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:49:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:49:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:49:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:49:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:49:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:49:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:49:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:49:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:49:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:49:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:49:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:49:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:49:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:49:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:49:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:49:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:49:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:49:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:49:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:49:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:49:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:49:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:49:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:49:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:49:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:49:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:49:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:49:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:49:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:49:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:49:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:49:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:49:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:49:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:49:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:49:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:49:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:49:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:49:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:49:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:49:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:49:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:49:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:49:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:49:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:49:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:49:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:49:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:49:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:49:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:49:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:49:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:49:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:49:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:49:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:49:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:49:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:49:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:49:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:49:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:49:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:49:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:49:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:49:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:49:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:49:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:49:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:49:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:49:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:49:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:49:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:49:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:49:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:49:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:49:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:49:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:49:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:49:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:49:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:49:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:49:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:49:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:49:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:49:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:49:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:49:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:49:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:49:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:49:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:49:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:49:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:49:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:49:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:49:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:49:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:49:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:49:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:49:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:49:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:49:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:49:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:49:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:49:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:49:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:49:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:49:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:49:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:49:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:49:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:49:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:49:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:49:30 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-145158bc-kafka-0 ,my-cluster-145158bc-kafka-1 ,my-cluster-145158bc-kafka-2 ,my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl
2022-04-04 15:49:30 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-145158bc-zookeeper to be ready
2022-04-04 15:54:46 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-145158bc will have desired state: Ready
2022-04-04 15:54:46 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-145158bc is in desired state: Ready
2022-04-04 15:54:46 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-145158bc is ready
2022-04-04 15:54:46 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@648640c0, messages=[], arguments=[--topic, my-topic-1213730633-459640807, --max-messages, 100, --group-instance-id, instance1092665645, USER=my_user_2098311081_988766631, --group-id, my-consumer-group-963697339, --bootstrap-server, my-cluster-145158bc-kafka-bootstrap.namespace-82.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl', podNamespace='namespace-82', bootstrapServer='my-cluster-145158bc-kafka-bootstrap.namespace-82.svc:9093', topicName='my-topic-1213730633-459640807', maxMessages=100, kafkaUsername='my-user-2098311081-988766631', consumerGroupName='my-consumer-group-963697339', consumerInstanceId='instance1092665645', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@14a00933}
2022-04-04 15:54:46 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-145158bc-kafka-bootstrap.namespace-82.svc:9093:my-topic-1213730633-459640807 from pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl
2022-04-04 15:54:46 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl -n namespace-82 -- /opt/kafka/consumer.sh --topic my-topic-1213730633-459640807 --max-messages 100 --group-instance-id instance1092665645 USER=my_user_2098311081_988766631 --group-id my-consumer-group-963697339 --bootstrap-server my-cluster-145158bc-kafka-bootstrap.namespace-82.svc:9093
2022-04-04 15:54:53 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 15:54:53 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 15:54:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-698346910-635023561 in namespace namespace-82
2022-04-04 15:54:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-82
2022-04-04 15:54:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-698346910-635023561 will have desired state: Ready
2022-04-04 15:54:54 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-698346910-635023561 is in desired state: Ready
2022-04-04 15:54:54 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@41f2b5f6, messages=[], arguments=[--topic, my-topic-698346910-635023561, --max-messages, 100, USER=my_user_2098311081_988766631, --bootstrap-server, my-cluster-145158bc-kafka-bootstrap.namespace-82.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl', podNamespace='namespace-82', bootstrapServer='my-cluster-145158bc-kafka-bootstrap.namespace-82.svc:9093', topicName='my-topic-698346910-635023561', maxMessages=100, kafkaUsername='my-user-2098311081-988766631', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@550fc7f5}
2022-04-04 15:54:54 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-145158bc-kafka-bootstrap.namespace-82.svc:9093:my-topic-698346910-635023561 from pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl
2022-04-04 15:54:54 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl -n namespace-82 -- /opt/kafka/producer.sh --topic my-topic-698346910-635023561 --max-messages 100 USER=my_user_2098311081_988766631 --bootstrap-server my-cluster-145158bc-kafka-bootstrap.namespace-82.svc:9093
2022-04-04 15:54:58 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 15:54:58 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 15:54:58 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@527c2420, messages=[], arguments=[--topic, my-topic-698346910-635023561, --max-messages, 100, --group-instance-id, instance172789608, USER=my_user_2098311081_988766631, --group-id, my-consumer-group-1244191537, --bootstrap-server, my-cluster-145158bc-kafka-bootstrap.namespace-82.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl', podNamespace='namespace-82', bootstrapServer='my-cluster-145158bc-kafka-bootstrap.namespace-82.svc:9093', topicName='my-topic-698346910-635023561', maxMessages=100, kafkaUsername='my-user-2098311081-988766631', consumerGroupName='my-consumer-group-1244191537', consumerInstanceId='instance172789608', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@17a47d48}
2022-04-04 15:54:58 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-145158bc-kafka-bootstrap.namespace-82.svc:9093:my-topic-698346910-635023561 from pod my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl
2022-04-04 15:54:58 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-145158bc-kafka-clients-c9cbd47f-7jvbl -n namespace-82 -- /opt/kafka/consumer.sh --topic my-topic-698346910-635023561 --max-messages 100 --group-instance-id instance172789608 USER=my_user_2098311081_988766631 --group-id my-consumer-group-1244191537 --bootstrap-server my-cluster-145158bc-kafka-bootstrap.namespace-82.svc:9093
2022-04-04 15:55:05 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 15:55:05 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 15:55:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 15:55:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryDuringZookeeperRollingUpdate
2022-04-04 15:55:05 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-2098311081-988766631 in namespace namespace-82
2022-04-04 15:55:05 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-698346910-635023561 in namespace namespace-82
2022-04-04 15:55:05 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-145158bc-kafka-clients in namespace namespace-82
2022-04-04 15:55:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-145158bc in namespace namespace-82
2022-04-04 15:55:05 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1213730633-459640807 in namespace namespace-82
2022-04-04 15:55:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 15:55:55 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-82 for test case:testRecoveryDuringZookeeperRollingUpdate
2022-04-04 15:56:00 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testRecoveryDuringZookeeperRollingUpdate-FINISHED
2022-04-04 15:56:00 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 15:56:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 15:56:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testRecoveryDuringKafkaRollingUpdate-STARTED
2022-04-04 15:56:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 15:56:00 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-83 for test case:testRecoveryDuringKafkaRollingUpdate
2022-04-04 15:56:00 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-83
2022-04-04 15:56:00 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-83
2022-04-04 15:56:00 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-83
2022-04-04 15:56:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-fa779179 in namespace namespace-83
2022-04-04 15:56:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-83
2022-04-04 15:56:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-fa779179 will have desired state: Ready
2022-04-04 15:57:53 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-fa779179 is in desired state: Ready
2022-04-04 15:57:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-864621860-2063496845 in namespace namespace-83
2022-04-04 15:57:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-83
2022-04-04 15:57:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-864621860-2063496845 will have desired state: Ready
2022-04-04 15:57:54 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-864621860-2063496845 is in desired state: Ready
2022-04-04 15:57:54 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1500968370-1215770243 in namespace namespace-83
2022-04-04 15:57:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-83
2022-04-04 15:57:54 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1500968370-1215770243 will have desired state: Ready
2022-04-04 15:57:55 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1500968370-1215770243 is in desired state: Ready
2022-04-04 15:57:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-fa779179-kafka-clients in namespace namespace-83
2022-04-04 15:57:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-83
2022-04-04 15:58:05 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 15:58:05 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@77602ba7, messages=[], arguments=[--topic, my-topic-864621860-2063496845, --max-messages, 100, USER=my_user_1500968370_1215770243, --bootstrap-server, my-cluster-fa779179-kafka-bootstrap.namespace-83.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj', podNamespace='namespace-83', bootstrapServer='my-cluster-fa779179-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-864621860-2063496845', maxMessages=100, kafkaUsername='my-user-1500968370-1215770243', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6519c4f4}
2022-04-04 15:58:05 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-fa779179-kafka-bootstrap.namespace-83.svc:9093:my-topic-864621860-2063496845 from pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj
2022-04-04 15:58:05 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj -n namespace-83 -- /opt/kafka/producer.sh --topic my-topic-864621860-2063496845 --max-messages 100 USER=my_user_1500968370_1215770243 --bootstrap-server my-cluster-fa779179-kafka-bootstrap.namespace-83.svc:9093
2022-04-04 15:58:08 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 15:58:08 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 15:58:08 [main] [32mINFO [m [RollingUpdateST:203] Update resources for pods
2022-04-04 15:58:08 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6ef996b8, messages=[], arguments=[--topic, my-topic-864621860-2063496845, --max-messages, 100, --group-instance-id, instance950767048, USER=my_user_1500968370_1215770243, --group-id, my-consumer-group-853512213, --bootstrap-server, my-cluster-fa779179-kafka-bootstrap.namespace-83.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj', podNamespace='namespace-83', bootstrapServer='my-cluster-fa779179-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-864621860-2063496845', maxMessages=100, kafkaUsername='my-user-1500968370-1215770243', consumerGroupName='my-consumer-group-853512213', consumerInstanceId='instance950767048', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1832ab0a}
2022-04-04 15:58:08 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-fa779179-kafka-bootstrap.namespace-83.svc:9093:my-topic-864621860-2063496845 from pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj
2022-04-04 15:58:08 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj -n namespace-83 -- /opt/kafka/consumer.sh --topic my-topic-864621860-2063496845 --max-messages 100 --group-instance-id instance950767048 USER=my_user_1500968370_1215770243 --group-id my-consumer-group-853512213 --bootstrap-server my-cluster-fa779179-kafka-bootstrap.namespace-83.svc:9093
2022-04-04 15:58:16 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 15:58:16 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 15:58:16 [main] [32mINFO [m [ClientUtils:45] Consumer successfully consumed 100 messages for the 1 time
2022-04-04 15:58:16 [main] [32mINFO [m [PodUtils:277] Wait for at least one pod with prefix: my-cluster-fa779179-kafka will be in pending phase
2022-04-04 15:58:17 [main] [32mINFO [m [RollingUpdateST:220] Verifying stability of kafka pods except the one, which is in pending phase
2022-04-04 15:58:17 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-fa779179-kafka are stable
2022-04-04 15:58:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:58:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:58:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:58:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:58:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:58:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:58:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:58:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:58:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:58:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:58:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:58:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:58:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:58:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:58:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:58:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:58:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:58:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:58:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:58:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:58:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:58:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:58:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:58:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:58:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:58:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:58:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:58:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:58:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:58:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:58:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:58:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:58:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:58:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:58:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:58:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:58:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:58:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:58:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:58:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:58:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:58:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:58:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:58:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:58:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:58:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:58:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:58:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:58:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:58:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:58:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:58:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:58:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:58:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:58:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:58:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:58:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:58:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:58:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:58:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:58:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:58:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:58:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:58:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:58:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:58:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:58:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:58:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:58:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:58:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:58:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:58:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:58:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:58:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:58:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:58:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:58:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:58:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:58:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:58:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:58:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:58:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:58:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:58:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:58:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:58:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:58:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:58:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:58:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:58:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:58:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:58:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:58:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:58:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:58:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:58:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:58:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:58:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:58:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:58:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:58:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:58:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:58:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:58:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:58:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:58:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:58:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:58:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:58:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:58:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:58:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:58:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:58:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:58:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:58:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:58:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:58:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:58:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:58:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:58:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:58:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:58:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:58:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:58:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:58:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:58:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:58:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:58:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:58:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:59:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:59:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:59:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:59:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:59:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:59:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:59:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:59:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:59:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:59:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:59:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:59:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:59:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:59:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:59:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:59:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:59:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:59:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:59:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:59:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:59:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:59:06 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-fa779179-kafka-0 ,my-cluster-fa779179-kafka-2 ,my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj
2022-04-04 15:59:06 [main] [32mINFO [m [RollingUpdateST:223] Verifying stability of zookeeper pods
2022-04-04 15:59:06 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-fa779179-zookeeper are stable
2022-04-04 15:59:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:59:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:59:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:59:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:59:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:59:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:59:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:59:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:59:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:59:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:59:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:59:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:59:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:59:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:59:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:59:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:59:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:59:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:59:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:59:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:59:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:59:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:59:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:59:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:59:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:59:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:59:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:59:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:59:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:59:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:59:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:59:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:59:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:59:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:59:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:59:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:59:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:59:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:59:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:59:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:59:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:59:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:59:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:59:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:59:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:59:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:59:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:59:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:59:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:59:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:59:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:59:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:59:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:59:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:59:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:59:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:59:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:59:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:59:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:59:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:59:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:59:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:59:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:59:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:59:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:59:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:59:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:59:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:59:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:59:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:59:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:59:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:59:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:59:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:59:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:59:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:59:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:59:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:59:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:59:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:59:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:59:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:59:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:59:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:59:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:59:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:59:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:59:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:59:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:59:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:59:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:59:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:59:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:59:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:59:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:59:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:59:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:59:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:59:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:59:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:59:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:59:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:59:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:59:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:59:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:59:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:59:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:59:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:59:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:59:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:59:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:59:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:59:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:59:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:59:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:59:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:59:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:59:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:59:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:59:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:59:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:59:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:59:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:59:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:59:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:59:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:59:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:59:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:59:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:59:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:59:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:59:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:59:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:59:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:59:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:59:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:59:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:59:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:59:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:59:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:59:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:59:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:59:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:59:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:59:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:59:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:59:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:59:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:59:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:59:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-fa779179-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:59:56 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-fa779179-zookeeper-0 ,my-cluster-fa779179-zookeeper-1 ,my-cluster-fa779179-zookeeper-2
2022-04-04 15:59:56 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4126af70, messages=[], arguments=[--topic, my-topic-864621860-2063496845, --max-messages, 100, --group-instance-id, instance393037296, USER=my_user_1500968370_1215770243, --group-id, my-consumer-group-878283777, --bootstrap-server, my-cluster-fa779179-kafka-bootstrap.namespace-83.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj', podNamespace='namespace-83', bootstrapServer='my-cluster-fa779179-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-864621860-2063496845', maxMessages=100, kafkaUsername='my-user-1500968370-1215770243', consumerGroupName='my-consumer-group-878283777', consumerInstanceId='instance393037296', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4d3229bf}
2022-04-04 15:59:56 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-fa779179-kafka-bootstrap.namespace-83.svc:9093:my-topic-864621860-2063496845 from pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj
2022-04-04 15:59:56 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj -n namespace-83 -- /opt/kafka/consumer.sh --topic my-topic-864621860-2063496845 --max-messages 100 --group-instance-id instance393037296 USER=my_user_1500968370_1215770243 --group-id my-consumer-group-878283777 --bootstrap-server my-cluster-fa779179-kafka-bootstrap.namespace-83.svc:9093
2022-04-04 16:00:02 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 16:00:02 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 16:00:02 [main] [32mINFO [m [ClientUtils:45] Consumer successfully consumed 100 messages for the 1 time
2022-04-04 16:00:02 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-fa779179-kafka to be ready
2022-04-04 16:05:23 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-fa779179 will have desired state: Ready
2022-04-04 16:05:23 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-fa779179 is in desired state: Ready
2022-04-04 16:05:23 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-fa779179 is ready
2022-04-04 16:05:23 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4625f276, messages=[], arguments=[--topic, my-topic-864621860-2063496845, --max-messages, 100, --group-instance-id, instance138807881, USER=my_user_1500968370_1215770243, --group-id, my-consumer-group-1815936486, --bootstrap-server, my-cluster-fa779179-kafka-bootstrap.namespace-83.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj', podNamespace='namespace-83', bootstrapServer='my-cluster-fa779179-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-864621860-2063496845', maxMessages=100, kafkaUsername='my-user-1500968370-1215770243', consumerGroupName='my-consumer-group-1815936486', consumerInstanceId='instance138807881', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@328c8678}
2022-04-04 16:05:23 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-fa779179-kafka-bootstrap.namespace-83.svc:9093:my-topic-864621860-2063496845 from pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj
2022-04-04 16:05:23 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj -n namespace-83 -- /opt/kafka/consumer.sh --topic my-topic-864621860-2063496845 --max-messages 100 --group-instance-id instance138807881 USER=my_user_1500968370_1215770243 --group-id my-consumer-group-1815936486 --bootstrap-server my-cluster-fa779179-kafka-bootstrap.namespace-83.svc:9093
2022-04-04 16:05:30 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 16:05:30 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 16:05:30 [main] [32mINFO [m [ClientUtils:45] Consumer successfully consumed 100 messages for the 1 time
2022-04-04 16:05:30 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1925243530-1296583443 in namespace namespace-83
2022-04-04 16:05:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-83
2022-04-04 16:05:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1925243530-1296583443 will have desired state: Ready
2022-04-04 16:05:31 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1925243530-1296583443 is in desired state: Ready
2022-04-04 16:05:31 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@42ebd72b, messages=[], arguments=[--topic, my-topic-1925243530-1296583443, --max-messages, 100, USER=my_user_1500968370_1215770243, --bootstrap-server, my-cluster-fa779179-kafka-bootstrap.namespace-83.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj', podNamespace='namespace-83', bootstrapServer='my-cluster-fa779179-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-1925243530-1296583443', maxMessages=100, kafkaUsername='my-user-1500968370-1215770243', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@14022c95}
2022-04-04 16:05:31 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-fa779179-kafka-bootstrap.namespace-83.svc:9093:my-topic-1925243530-1296583443 from pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj
2022-04-04 16:05:31 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj -n namespace-83 -- /opt/kafka/producer.sh --topic my-topic-1925243530-1296583443 --max-messages 100 USER=my_user_1500968370_1215770243 --bootstrap-server my-cluster-fa779179-kafka-bootstrap.namespace-83.svc:9093
2022-04-04 16:05:35 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 16:05:35 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 16:05:35 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@c077275, messages=[], arguments=[--topic, my-topic-1925243530-1296583443, --max-messages, 100, --group-instance-id, instance1828050999, USER=my_user_1500968370_1215770243, --group-id, my-consumer-group-332837184, --bootstrap-server, my-cluster-fa779179-kafka-bootstrap.namespace-83.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj', podNamespace='namespace-83', bootstrapServer='my-cluster-fa779179-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-1925243530-1296583443', maxMessages=100, kafkaUsername='my-user-1500968370-1215770243', consumerGroupName='my-consumer-group-332837184', consumerInstanceId='instance1828050999', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2bb42b42}
2022-04-04 16:05:35 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-fa779179-kafka-bootstrap.namespace-83.svc:9093:my-topic-1925243530-1296583443 from pod my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj
2022-04-04 16:05:35 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fa779179-kafka-clients-5b9b698bd9-5w4pj -n namespace-83 -- /opt/kafka/consumer.sh --topic my-topic-1925243530-1296583443 --max-messages 100 --group-instance-id instance1828050999 USER=my_user_1500968370_1215770243 --group-id my-consumer-group-332837184 --bootstrap-server my-cluster-fa779179-kafka-bootstrap.namespace-83.svc:9093
2022-04-04 16:05:42 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 16:05:42 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 16:05:42 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 16:05:42 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryDuringKafkaRollingUpdate
2022-04-04 16:05:42 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1500968370-1215770243 in namespace namespace-83
2022-04-04 16:05:42 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1925243530-1296583443 in namespace namespace-83
2022-04-04 16:05:42 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-fa779179 in namespace namespace-83
2022-04-04 16:05:42 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-864621860-2063496845 in namespace namespace-83
2022-04-04 16:05:42 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-fa779179-kafka-clients in namespace namespace-83
2022-04-04 16:06:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 16:06:22 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-83 for test case:testRecoveryDuringKafkaRollingUpdate
2022-04-04 16:06:27 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testRecoveryDuringKafkaRollingUpdate-FINISHED
2022-04-04 16:06:27 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 16:06:27 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 16:06:27 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testClusterOperatorFinishAllRollingUpdates-STARTED
2022-04-04 16:06:27 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 16:06:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-6c12d295 in namespace rolling-update-st
2022-04-04 16:06:27 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-6c12d295 will have desired state: Ready
2022-04-04 16:07:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-6c12d295 is in desired state: Ready
io.strimzi.test.WaitException: Timeout after 180000 ms waiting for rolling update starts
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.rollingupdate.RollingUpdateST.testClusterOperatorFinishAllRollingUpdates(RollingUpdateST.java:625)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-04 16:10:46 [main] [1;31mERROR[m [TestExecutionWatcher:28] RollingUpdateST - Exception Timeout after 180000 ms waiting for rolling update starts has been thrown in @Test. Going to collect logs from components.
2022-04-04 16:10:46 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-04-04 16:10:46 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-04-04 16:10:46 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-04-04 16:10:59 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-04-04 16:10:59 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-04-04 16:10:59 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-04-04 16:10:59 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-04-04 16:10:59 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-04 16:11:00 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace rolling-update-st
2022-04-04 16:11:00 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace rolling-update-st
2022-04-04 16:11:00 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace rolling-update-st
2022-04-04 16:11:01 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace rolling-update-st
2022-04-04 16:11:02 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace rolling-update-st
2022-04-04 16:11:02 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace rolling-update-st
2022-04-04 16:11:02 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace rolling-update-st
2022-04-04 16:11:02 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-04 16:11:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 16:11:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testClusterOperatorFinishAllRollingUpdates
2022-04-04 16:11:02 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-6c12d295 in namespace rolling-update-st
2022-04-04 16:11:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 16:11:12 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testClusterOperatorFinishAllRollingUpdates-FINISHED
2022-04-04 16:11:12 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 16:11:12 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 16:11:12 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testKafkaAndZookeeperScaleUpScaleDown-STARTED
2022-04-04 16:11:12 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 16:11:12 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-84 for test case:testKafkaAndZookeeperScaleUpScaleDown
2022-04-04 16:11:12 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-84
2022-04-04 16:11:12 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-84
2022-04-04 16:11:12 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-84
2022-04-04 16:11:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2334dd33 in namespace namespace-84
2022-04-04 16:11:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-84
2022-04-04 16:11:12 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2334dd33 will have desired state: Ready
2022-04-04 16:12:30 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2334dd33 is in desired state: Ready
2022-04-04 16:12:30 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-577824546-927829714 in namespace namespace-84
2022-04-04 16:12:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-84
2022-04-04 16:12:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-577824546-927829714 will have desired state: Ready
2022-04-04 16:12:31 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-577824546-927829714 is in desired state: Ready
2022-04-04 16:12:31 [main] [32mINFO [m [AbstractST:489] Verifying docker image names
2022-04-04 16:12:31 [main] [32mINFO [m [AbstractST:172] strimzi-cluster-operator
2022-04-04 16:12:32 [main] [32mINFO [m [AbstractST:525] Docker images verified
2022-04-04 16:12:32 [main] [32mINFO [m [RollingUpdateST:292] Running kafkaScaleUpScaleDown my-cluster-2334dd33
2022-04-04 16:12:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1829722037-1636610528 in namespace namespace-84
2022-04-04 16:12:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-84
2022-04-04 16:12:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1829722037-1636610528 will have desired state: Ready
2022-04-04 16:12:33 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1829722037-1636610528 is in desired state: Ready
2022-04-04 16:12:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-2334dd33-kafka-clients in namespace namespace-84
2022-04-04 16:12:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-84
2022-04-04 16:12:43 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 16:12:43 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5de06c37, messages=[], arguments=[--topic, my-topic-1829722037-1636610528, --max-messages, 100, USER=my_user_577824546_927829714, --bootstrap-server, my-cluster-2334dd33-kafka-bootstrap.namespace-84.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-2334dd33-kafka-clients-677fc65b48-twt7j', podNamespace='namespace-84', bootstrapServer='my-cluster-2334dd33-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-1829722037-1636610528', maxMessages=100, kafkaUsername='my-user-577824546-927829714', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4cb63ce2}
2022-04-04 16:12:43 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-2334dd33-kafka-bootstrap.namespace-84.svc:9093:my-topic-1829722037-1636610528 from pod my-cluster-2334dd33-kafka-clients-677fc65b48-twt7j
2022-04-04 16:12:43 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2334dd33-kafka-clients-677fc65b48-twt7j -n namespace-84 -- /opt/kafka/producer.sh --topic my-topic-1829722037-1636610528 --max-messages 100 USER=my_user_577824546_927829714 --bootstrap-server my-cluster-2334dd33-kafka-bootstrap.namespace-84.svc:9093
2022-04-04 16:12:46 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 16:12:46 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 16:12:46 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@51dd465a, messages=[], arguments=[--topic, my-topic-1829722037-1636610528, --max-messages, 100, --group-instance-id, instance1995579550, USER=my_user_577824546_927829714, --group-id, my-consumer-group-1453777629, --bootstrap-server, my-cluster-2334dd33-kafka-bootstrap.namespace-84.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-2334dd33-kafka-clients-677fc65b48-twt7j', podNamespace='namespace-84', bootstrapServer='my-cluster-2334dd33-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-1829722037-1636610528', maxMessages=100, kafkaUsername='my-user-577824546-927829714', consumerGroupName='my-consumer-group-1453777629', consumerInstanceId='instance1995579550', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@30f14c8}
2022-04-04 16:12:46 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-2334dd33-kafka-bootstrap.namespace-84.svc:9093:my-topic-1829722037-1636610528 from pod my-cluster-2334dd33-kafka-clients-677fc65b48-twt7j
2022-04-04 16:12:46 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2334dd33-kafka-clients-677fc65b48-twt7j -n namespace-84 -- /opt/kafka/consumer.sh --topic my-topic-1829722037-1636610528 --max-messages 100 --group-instance-id instance1995579550 USER=my_user_577824546_927829714 --group-id my-consumer-group-1453777629 --bootstrap-server my-cluster-2334dd33-kafka-bootstrap.namespace-84.svc:9093
2022-04-04 16:12:53 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 16:12:53 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 16:12:53 [main] [32mINFO [m [RollingUpdateST:317] Scale up Kafka to 7
2022-04-04 16:12:53 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-2334dd33-kafka rolling update
2022-04-04 16:14:08 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-2334dd33-kafka has been successfully rolled
2022-04-04 16:14:08 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 7 Pod(s) of my-cluster-2334dd33-kafka to be ready
2022-04-04 16:15:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2334dd33 will have desired state: Ready
2022-04-04 16:15:00 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2334dd33 is in desired state: Ready
2022-04-04 16:15:00 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-2334dd33 is ready
2022-04-04 16:15:01 [main] [32mINFO [m [RollingUpdateST:327] Kafka scale up to 7 finished
2022-04-04 16:15:01 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5c015cc0, messages=[], arguments=[--topic, my-topic-1829722037-1636610528, --max-messages, 100, --group-instance-id, instance40529793, USER=my_user_577824546_927829714, --group-id, my-consumer-group-1223274257, --bootstrap-server, my-cluster-2334dd33-kafka-bootstrap.namespace-84.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-2334dd33-kafka-clients-677fc65b48-twt7j', podNamespace='namespace-84', bootstrapServer='my-cluster-2334dd33-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-1829722037-1636610528', maxMessages=100, kafkaUsername='my-user-577824546-927829714', consumerGroupName='my-consumer-group-1223274257', consumerInstanceId='instance40529793', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1ddadccf}
2022-04-04 16:15:01 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-2334dd33-kafka-bootstrap.namespace-84.svc:9093:my-topic-1829722037-1636610528 from pod my-cluster-2334dd33-kafka-clients-677fc65b48-twt7j
2022-04-04 16:15:01 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2334dd33-kafka-clients-677fc65b48-twt7j -n namespace-84 -- /opt/kafka/consumer.sh --topic my-topic-1829722037-1636610528 --max-messages 100 --group-instance-id instance40529793 USER=my_user_577824546_927829714 --group-id my-consumer-group-1223274257 --bootstrap-server my-cluster-2334dd33-kafka-bootstrap.namespace-84.svc:9093
2022-04-04 16:15:07 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 16:15:07 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 16:15:07 [main] [32mINFO [m [RollingUpdateST:339] Scale up Zookeeper to 5
2022-04-04 16:15:07 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 5 Pod(s) of my-cluster-2334dd33-zookeeper to be ready
2022-04-04 16:16:42 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2334dd33 will have desired state: Ready
2022-04-04 16:16:42 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2334dd33 is in desired state: Ready
2022-04-04 16:16:42 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-2334dd33 is ready
2022-04-04 16:16:42 [main] [32mINFO [m [RollingUpdateST:342] Kafka scale up to 5 finished
2022-04-04 16:16:42 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@601d2441, messages=[], arguments=[--topic, my-topic-1829722037-1636610528, --max-messages, 100, --group-instance-id, instance30672046, USER=my_user_577824546_927829714, --group-id, my-consumer-group-1860048681, --bootstrap-server, my-cluster-2334dd33-kafka-bootstrap.namespace-84.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-2334dd33-kafka-clients-677fc65b48-twt7j', podNamespace='namespace-84', bootstrapServer='my-cluster-2334dd33-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-1829722037-1636610528', maxMessages=100, kafkaUsername='my-user-577824546-927829714', consumerGroupName='my-consumer-group-1860048681', consumerInstanceId='instance30672046', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@76df0c48}
2022-04-04 16:16:42 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-2334dd33-kafka-bootstrap.namespace-84.svc:9093:my-topic-1829722037-1636610528 from pod my-cluster-2334dd33-kafka-clients-677fc65b48-twt7j
2022-04-04 16:16:42 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2334dd33-kafka-clients-677fc65b48-twt7j -n namespace-84 -- /opt/kafka/consumer.sh --topic my-topic-1829722037-1636610528 --max-messages 100 --group-instance-id instance30672046 USER=my_user_577824546_927829714 --group-id my-consumer-group-1860048681 --bootstrap-server my-cluster-2334dd33-kafka-bootstrap.namespace-84.svc:9093
2022-04-04 16:16:49 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 16:16:49 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 16:16:49 [main] [32mINFO [m [RollingUpdateST:351] Scale down Kafka to 3
2022-04-04 16:16:49 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-2334dd33-kafka rolling update
2022-04-04 16:18:54 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-2334dd33-kafka has been successfully rolled
2022-04-04 16:18:54 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-2334dd33-kafka to be ready
2022-04-04 16:19:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2334dd33 will have desired state: Ready
2022-04-04 16:19:26 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2334dd33 is in desired state: Ready
2022-04-04 16:19:26 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-2334dd33 is ready
2022-04-04 16:19:26 [main] [32mINFO [m [RollingUpdateST:356] Kafka scale down to 3 finished
2022-04-04 16:19:26 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2fe52917, messages=[], arguments=[--topic, my-topic-1829722037-1636610528, --max-messages, 100, --group-instance-id, instance155261511, USER=my_user_577824546_927829714, --group-id, my-consumer-group-395029902, --bootstrap-server, my-cluster-2334dd33-kafka-bootstrap.namespace-84.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-2334dd33-kafka-clients-677fc65b48-twt7j', podNamespace='namespace-84', bootstrapServer='my-cluster-2334dd33-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-1829722037-1636610528', maxMessages=100, kafkaUsername='my-user-577824546-927829714', consumerGroupName='my-consumer-group-395029902', consumerInstanceId='instance155261511', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5439d63f}
2022-04-04 16:19:26 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-2334dd33-kafka-bootstrap.namespace-84.svc:9093:my-topic-1829722037-1636610528 from pod my-cluster-2334dd33-kafka-clients-677fc65b48-twt7j
2022-04-04 16:19:26 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2334dd33-kafka-clients-677fc65b48-twt7j -n namespace-84 -- /opt/kafka/consumer.sh --topic my-topic-1829722037-1636610528 --max-messages 100 --group-instance-id instance155261511 USER=my_user_577824546_927829714 --group-id my-consumer-group-395029902 --bootstrap-server my-cluster-2334dd33-kafka-bootstrap.namespace-84.svc:9093
2022-04-04 16:19:33 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 16:19:33 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 16:19:33 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2116406940-1840350545 in namespace namespace-84
2022-04-04 16:19:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-84
2022-04-04 16:19:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2116406940-1840350545 will have desired state: Ready
2022-04-04 16:20:23 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2116406940-1840350545 is in desired state: Ready
2022-04-04 16:20:23 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@6edd063d, messages=[], arguments=[--topic, my-topic-2116406940-1840350545, --max-messages, 100, USER=my_user_577824546_927829714, --bootstrap-server, my-cluster-2334dd33-kafka-bootstrap.namespace-84.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-2334dd33-kafka-clients-677fc65b48-twt7j', podNamespace='namespace-84', bootstrapServer='my-cluster-2334dd33-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-2116406940-1840350545', maxMessages=100, kafkaUsername='my-user-577824546-927829714', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@68f637a5}
2022-04-04 16:20:23 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-2334dd33-kafka-bootstrap.namespace-84.svc:9093:my-topic-2116406940-1840350545 from pod my-cluster-2334dd33-kafka-clients-677fc65b48-twt7j
2022-04-04 16:20:23 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2334dd33-kafka-clients-677fc65b48-twt7j -n namespace-84 -- /opt/kafka/producer.sh --topic my-topic-2116406940-1840350545 --max-messages 100 USER=my_user_577824546_927829714 --bootstrap-server my-cluster-2334dd33-kafka-bootstrap.namespace-84.svc:9093
2022-04-04 16:20:26 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 16:20:26 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 16:20:26 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6475ea1d, messages=[], arguments=[--topic, my-topic-2116406940-1840350545, --max-messages, 100, --group-instance-id, instance124829564, USER=my_user_577824546_927829714, --group-id, my-consumer-group-2009944810, --bootstrap-server, my-cluster-2334dd33-kafka-bootstrap.namespace-84.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-2334dd33-kafka-clients-677fc65b48-twt7j', podNamespace='namespace-84', bootstrapServer='my-cluster-2334dd33-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-2116406940-1840350545', maxMessages=100, kafkaUsername='my-user-577824546-927829714', consumerGroupName='my-consumer-group-2009944810', consumerInstanceId='instance124829564', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3238b87d}
2022-04-04 16:20:26 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-2334dd33-kafka-bootstrap.namespace-84.svc:9093:my-topic-2116406940-1840350545 from pod my-cluster-2334dd33-kafka-clients-677fc65b48-twt7j
2022-04-04 16:20:26 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2334dd33-kafka-clients-677fc65b48-twt7j -n namespace-84 -- /opt/kafka/consumer.sh --topic my-topic-2116406940-1840350545 --max-messages 100 --group-instance-id instance124829564 USER=my_user_577824546_927829714 --group-id my-consumer-group-2009944810 --bootstrap-server my-cluster-2334dd33-kafka-bootstrap.namespace-84.svc:9093
2022-04-04 16:20:33 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 16:20:33 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 16:20:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 16:20:33 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaAndZookeeperScaleUpScaleDown
2022-04-04 16:20:33 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1829722037-1636610528 in namespace namespace-84
2022-04-04 16:20:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-577824546-927829714 in namespace namespace-84
2022-04-04 16:20:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2334dd33 in namespace namespace-84
2022-04-04 16:20:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2116406940-1840350545 in namespace namespace-84
2022-04-04 16:20:33 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-2334dd33-kafka-clients in namespace namespace-84
2022-04-04 16:21:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 16:21:23 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-84 for test case:testKafkaAndZookeeperScaleUpScaleDown
2022-04-04 16:21:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testKafkaAndZookeeperScaleUpScaleDown-FINISHED
2022-04-04 16:21:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 16:21:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 16:21:29 [main] [32mINFO [m [ResourceManager:346] In context RollingUpdateST is everything deleted.
2022-04-04 16:21:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;31mERROR[m] Tests run: 9, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 3,920.424 s <<< FAILURE! - in io.strimzi.systemtest.rollingupdate.RollingUpdateST
[[1;31mERROR[m] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testClusterOperatorFinishAllRollingUpdates(ExtensionContext)  Time elapsed: 284.858 s  <<< ERROR!
io.strimzi.test.WaitException: Timeout after 180000 ms waiting for rolling update starts
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.rollingupdate.RollingUpdateST.testClusterOperatorFinishAllRollingUpdates(RollingUpdateST.java:625)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)

[[1;34mINFO[m] Running io.strimzi.systemtest.log.LoggingChangeST
2022-04-04 16:21:35 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: logging-change-st
2022-04-04 16:21:35 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: logging-change-st
2022-04-04 16:21:35 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: logging-change-st
2022-04-04 16:21:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 16:21:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetClusterOperatorLoggingLevels-STARTED
2022-04-04 16:21:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 16:21:35 [main] [32mINFO [m [LoggingChangeST:617] Checking that original logging config is different from the new one
2022-04-04 16:21:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:21:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:21:36 [main] [32mINFO [m [LoggingChangeST:620] Changing logging for cluster-operator
2022-04-04 16:21:36 [main] [32mINFO [m [LoggingChangeST:623] Waiting for log4j2.properties will contain desired settings
2022-04-04 16:21:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:21:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:21:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:21:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:21:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:21:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:21:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:21:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:21:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:21:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:21:42 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:21:42 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:21:43 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:21:43 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:21:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:21:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:21:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:21:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:21:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:21:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:21:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:21:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:21:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:21:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:21:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:21:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:21:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:21:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:21:52 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:21:52 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:21:53 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:21:53 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:21:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:21:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:21:56 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:21:56 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:21:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:21:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:21:58 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:21:58 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:21:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:21:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:02 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:04 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:04 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:14 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:14 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:21 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:21 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:30 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:32 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:32 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:40 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:40 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:41 [main] [32mINFO [m [LoggingChangeST:628] Checking log4j2.properties in CO pod
2022-04-04 16:22:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:22:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:22:41 [main] [32mINFO [m [LoggingChangeST:632] Checking if CO rolled its pod
2022-04-04 16:22:44 [main] [33mWARN [m [LoggingChangeST:638] 2022-04-04 16:22:31 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-04 16:22:33 INFO  AbstractOperator:373 - Reconciliation #2034(watch) Kafka(namespace-84/my-cluster-2334dd33): Reconciliation is in progress

2022-04-04 16:22:48 [main] [33mWARN [m [LoggingChangeST:638] 2022-04-04 16:22:31 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-04 16:22:33 INFO  AbstractOperator:373 - Reconciliation #2034(watch) Kafka(namespace-84/my-cluster-2334dd33): Reconciliation is in progress

2022-04-04 16:22:51 [main] [33mWARN [m [LoggingChangeST:638] 2022-04-04 16:22:31 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-04 16:22:33 INFO  AbstractOperator:373 - Reconciliation #2034(watch) Kafka(namespace-84/my-cluster-2334dd33): Reconciliation is in progress

2022-04-04 16:22:54 [main] [33mWARN [m [LoggingChangeST:638] 2022-04-04 16:22:31 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-04 16:22:33 INFO  AbstractOperator:373 - Reconciliation #2034(watch) Kafka(namespace-84/my-cluster-2334dd33): Reconciliation is in progress

2022-04-04 16:22:58 [main] [33mWARN [m [LoggingChangeST:638] 2022-04-04 16:22:31 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-04 16:22:33 INFO  AbstractOperator:373 - Reconciliation #2034(watch) Kafka(namespace-84/my-cluster-2334dd33): Reconciliation is in progress

2022-04-04 16:23:01 [main] [33mWARN [m [LoggingChangeST:638] 2022-04-04 16:22:31 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-04 16:22:33 INFO  AbstractOperator:373 - Reconciliation #2034(watch) Kafka(namespace-84/my-cluster-2334dd33): Reconciliation is in progress

2022-04-04 16:23:04 [main] [33mWARN [m [LoggingChangeST:638] 2022-04-04 16:22:33 INFO  AbstractOperator:373 - Reconciliation #2034(watch) Kafka(namespace-84/my-cluster-2334dd33): Reconciliation is in progress

2022-04-04 16:23:08 [main] [33mWARN [m [LoggingChangeST:638] 
2022-04-04 16:23:08 [main] [32mINFO [m [LoggingChangeST:642] Changing all levels from OFF to INFO/WARN
2022-04-04 16:23:08 [main] [32mINFO [m [LoggingChangeST:646] Changing logging for cluster-operator
2022-04-04 16:23:08 [main] [32mINFO [m [LoggingChangeST:649] Waiting for log4j2.properties will contain desired settings
2022-04-04 16:23:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:13 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:14 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:14 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:21 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:21 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:31 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:31 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:32 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:32 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:40 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:40 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:42 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:42 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:52 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:52 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:53 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:53 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:54 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:54 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:58 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:58 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:58 [main] [32mINFO [m [LoggingChangeST:654] Checking log4j2.properties in CO pod
2022-04-04 16:23:58 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-d55zd -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:23:58 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:23:58 [main] [32mINFO [m [LoggingChangeST:658] Checking if CO rolled its pod
2022-04-04 16:24:01 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 16:24:01 [main] [32mINFO [m [ResourceManager:346] In context testDynamicallySetClusterOperatorLoggingLevels is everything deleted.
2022-04-04 16:24:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 16:24:01 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetClusterOperatorLoggingLevels-FINISHED
2022-04-04 16:24:01 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 16:24:01 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 16:24:01 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetUnknownKafkaLogger-STARTED
2022-04-04 16:24:01 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 16:24:01 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-85 for test case:testDynamicallySetUnknownKafkaLogger
2022-04-04 16:24:01 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-85
2022-04-04 16:24:01 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-85
2022-04-04 16:24:01 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-85
2022-04-04 16:24:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-6c107107 in namespace namespace-85
2022-04-04 16:24:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-85
2022-04-04 16:24:01 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-6c107107 will have desired state: Ready
2022-04-04 16:25:14 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-6c107107 is in desired state: Ready
2022-04-04 16:25:14 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-6c107107-kafka rolling update
2022-04-04 16:26:19 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-6c107107-kafka has been successfully rolled
2022-04-04 16:26:21 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 16:26:21 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetUnknownKafkaLogger
2022-04-04 16:26:21 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-6c107107 in namespace namespace-85
2022-04-04 16:26:31 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 16:26:31 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-85 for test case:testDynamicallySetUnknownKafkaLogger
2022-04-04 16:27:15 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetUnknownKafkaLogger-FINISHED
2022-04-04 16:27:15 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 16:27:15 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 16:27:15 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetKafkaExternalLogging-STARTED
2022-04-04 16:27:15 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 16:27:15 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-86 for test case:testDynamicallySetKafkaExternalLogging
2022-04-04 16:27:15 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-86
2022-04-04 16:27:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-86
2022-04-04 16:27:15 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-86
2022-04-04 16:27:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-af53542b in namespace namespace-86
2022-04-04 16:27:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-86
2022-04-04 16:27:15 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-af53542b will have desired state: Ready
2022-04-04 16:28:31 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-af53542b is in desired state: Ready
2022-04-04 16:28:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 50
2022-04-04 16:28:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 49
2022-04-04 16:28:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 48
2022-04-04 16:28:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 47
2022-04-04 16:28:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 46
2022-04-04 16:28:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 45
2022-04-04 16:28:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 44
2022-04-04 16:28:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 43
2022-04-04 16:28:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 42
2022-04-04 16:28:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 41
2022-04-04 16:28:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 40
2022-04-04 16:28:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 39
2022-04-04 16:28:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 38
2022-04-04 16:28:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 37
2022-04-04 16:28:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 36
2022-04-04 16:28:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 35
2022-04-04 16:28:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 34
2022-04-04 16:28:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 33
2022-04-04 16:28:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 32
2022-04-04 16:28:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 31
2022-04-04 16:28:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 30
2022-04-04 16:28:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 29
2022-04-04 16:28:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 28
2022-04-04 16:28:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 27
2022-04-04 16:28:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 26
2022-04-04 16:28:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 25
2022-04-04 16:28:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 24
2022-04-04 16:28:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 23
2022-04-04 16:28:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 22
2022-04-04 16:29:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 21
2022-04-04 16:29:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 20
2022-04-04 16:29:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 19
2022-04-04 16:29:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 18
2022-04-04 16:29:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 17
2022-04-04 16:29:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 16
2022-04-04 16:29:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 15
2022-04-04 16:29:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 14
2022-04-04 16:29:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 13
2022-04-04 16:29:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 12
2022-04-04 16:29:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 11
2022-04-04 16:29:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 10
2022-04-04 16:29:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 9
2022-04-04 16:29:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 8
2022-04-04 16:29:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 7
2022-04-04 16:29:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 6
2022-04-04 16:29:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 5
2022-04-04 16:29:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 4
2022-04-04 16:29:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 3
2022-04-04 16:29:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 2
2022-04-04 16:29:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 1
2022-04-04 16:29:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af53542b-kafka-2=f0c912ea-7970-4bde-9713-88cbbc9f233b, my-cluster-af53542b-kafka-1=33c01145-32c4-4e81-8dc8-7ebff51175f3, my-cluster-af53542b-kafka-0=6e56af12-ab47-4d68-a988-e075dc9d78d1} pods didn't roll. Remaining seconds for stability: 0
2022-04-04 16:29:24 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-af53542b-kafka rolling update
2022-04-04 16:30:34 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-af53542b-kafka has been successfully rolled
2022-04-04 16:30:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 16:30:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetKafkaExternalLogging
2022-04-04 16:30:37 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-af53542b in namespace namespace-86
2022-04-04 16:30:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 16:30:47 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-86 for test case:testDynamicallySetKafkaExternalLogging
2022-04-04 16:31:30 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetKafkaExternalLogging-FINISHED
2022-04-04 16:31:30 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 16:31:30 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 16:31:30 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testNotExistingCMSetsDefaultLogging-STARTED
2022-04-04 16:31:30 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 16:31:30 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-87 for test case:testNotExistingCMSetsDefaultLogging
2022-04-04 16:31:30 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-87
2022-04-04 16:31:31 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-87
2022-04-04 16:31:31 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-87
2022-04-04 16:31:31 [main] [32mINFO [m [TestUtils:197] /home/ec2-user/strimzi-kafka-operator/systemtest/../cluster-operator/src/main/resources/kafkaDefaultLoggingProperties
2022-04-04 16:31:31 [main] [32mINFO [m [LoggingChangeST:1321] Deploying Kafka with custom logging
2022-04-04 16:31:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-92d76d64 in namespace namespace-87
2022-04-04 16:31:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-87
2022-04-04 16:31:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-92d76d64 will have desired state: Ready
2022-04-04 16:32:48 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-92d76d64 is in desired state: Ready
2022-04-04 16:32:48 [main] [32mINFO [m [LoggingChangeST:1345] Changing external logging's CM to not existing one
2022-04-04 16:32:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 50
2022-04-04 16:32:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 49
2022-04-04 16:32:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 48
2022-04-04 16:32:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 47
2022-04-04 16:32:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 46
2022-04-04 16:32:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 45
2022-04-04 16:32:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 44
2022-04-04 16:32:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 43
2022-04-04 16:32:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 42
2022-04-04 16:32:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 41
2022-04-04 16:32:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 40
2022-04-04 16:32:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 39
2022-04-04 16:33:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 38
2022-04-04 16:33:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 37
2022-04-04 16:33:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 36
2022-04-04 16:33:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 35
2022-04-04 16:33:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 34
2022-04-04 16:33:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 33
2022-04-04 16:33:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 32
2022-04-04 16:33:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 31
2022-04-04 16:33:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 30
2022-04-04 16:33:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 29
2022-04-04 16:33:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 28
2022-04-04 16:33:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 27
2022-04-04 16:33:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 26
2022-04-04 16:33:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 25
2022-04-04 16:33:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 24
2022-04-04 16:33:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 23
2022-04-04 16:33:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 22
2022-04-04 16:33:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 21
2022-04-04 16:33:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 20
2022-04-04 16:33:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 19
2022-04-04 16:33:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 18
2022-04-04 16:33:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 17
2022-04-04 16:33:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 16
2022-04-04 16:33:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 15
2022-04-04 16:33:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 14
2022-04-04 16:33:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 13
2022-04-04 16:33:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 12
2022-04-04 16:33:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 11
2022-04-04 16:33:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 10
2022-04-04 16:33:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 9
2022-04-04 16:33:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 8
2022-04-04 16:33:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 7
2022-04-04 16:33:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 6
2022-04-04 16:33:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 5
2022-04-04 16:33:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 4
2022-04-04 16:33:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 3
2022-04-04 16:33:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 2
2022-04-04 16:33:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 1
2022-04-04 16:33:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-92d76d64-kafka-0=95939adc-cae7-41e0-bfc2-6974d30fe64b, my-cluster-92d76d64-kafka-1=42a6cc51-d1f8-4c66-b138-fd8dd1ec0f9b, my-cluster-92d76d64-kafka-2=dc9ea29a-3198-4f5c-a979-92beda0b7ae8} pods didn't roll. Remaining seconds for stability: 0
2022-04-04 16:33:38 [main] [32mINFO [m [LoggingChangeST:1359] Checking that log4j.properties in custom-config isn't empty and configuration is default
2022-04-04 16:33:38 [main] [32mINFO [m [LoggingChangeST:1367] Checking if Kafka:my-cluster-92d76d64 contains error about non-existing CM
2022-04-04 16:33:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 16:33:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testNotExistingCMSetsDefaultLogging
2022-04-04 16:33:38 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-92d76d64 in namespace namespace-87
2022-04-04 16:33:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 16:33:48 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-87 for test case:testNotExistingCMSetsDefaultLogging
2022-04-04 16:34:15 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testNotExistingCMSetsDefaultLogging-FINISHED
2022-04-04 16:34:15 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 16:34:15 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 16:34:15 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetConnectLoggingLevels-STARTED
2022-04-04 16:34:15 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 16:34:15 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-88 for test case:testDynamicallySetConnectLoggingLevels
2022-04-04 16:34:15 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-88
2022-04-04 16:34:16 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-88
2022-04-04 16:34:16 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-88
2022-04-04 16:34:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-6b3bf119 in namespace namespace-88
2022-04-04 16:34:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-88
2022-04-04 16:34:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-6b3bf119-kafka-clients in namespace namespace-88
2022-04-04 16:34:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-88
2022-04-04 16:34:16 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-6b3bf119 will have desired state: Ready
2022-04-04 16:35:32 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-6b3bf119 is in desired state: Ready
2022-04-04 16:35:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-6b3bf119-scraper in namespace namespace-88
2022-04-04 16:35:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-88
2022-04-04 16:35:32 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-6b3bf119-scraper will be ready
2022-04-04 16:35:34 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-6b3bf119-scraper is ready
2022-04-04 16:35:34 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-6b3bf119-scraper to be ready
2022-04-04 16:35:44 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-6b3bf119-scraper is ready
2022-04-04 16:35:44 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-6b3bf119-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 16:35:44 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-6b3bf119-allow in namespace namespace-88
2022-04-04 16:35:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-88
2022-04-04 16:35:44 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 16:35:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-6b3bf119 in namespace namespace-88
2022-04-04 16:35:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-88
2022-04-04 16:35:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-6b3bf119 will have desired state: Ready
2022-04-04 16:36:52 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-6b3bf119 is in desired state: Ready
2022-04-04 16:36:52 [main] [32mINFO [m [LoggingChangeST:704] Asserting if log is without records
2022-04-04 16:36:52 [main] [32mINFO [m [LoggingChangeST:707] Changing rootLogger level to DEBUG with inline logging
2022-04-04 16:36:52 [main] [32mINFO [m [LoggingChangeST:716] Waiting for log4j.properties will contain desired settings
2022-04-04 16:36:52 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-88 exec my-cluster-6b3bf119-kafka-clients-78b77fc459-txndw -- curl http://my-cluster-6b3bf119-connect-api:8083/admin/loggers/root
2022-04-04 16:36:52 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:36:53 [main] [32mINFO [m [LoggingChangeST:761] Setting log level of Connect to OFF
2022-04-04 16:36:53 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-88 exec my-cluster-6b3bf119-kafka-clients-78b77fc459-txndw -- curl http://my-cluster-6b3bf119-connect-api:8083/admin/loggers/root
2022-04-04 16:36:53 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:37:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 16:37:23 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetConnectLoggingLevels
2022-04-04 16:37:23 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-6b3bf119-scraper in namespace namespace-88
2022-04-04 16:37:23 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-6b3bf119 in namespace namespace-88
2022-04-04 16:37:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-6b3bf119 in namespace namespace-88
2022-04-04 16:37:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-6b3bf119-kafka-clients in namespace namespace-88
2022-04-04 16:37:23 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-6b3bf119-allow in namespace namespace-88
2022-04-04 16:38:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 16:38:23 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-88 for test case:testDynamicallySetConnectLoggingLevels
2022-04-04 16:38:28 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetConnectLoggingLevels-FINISHED
2022-04-04 16:38:28 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 16:38:28 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 16:38:28 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testMM2LoggingLevelsHierarchy-STARTED
2022-04-04 16:38:28 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 16:38:28 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-89 for test case:testMM2LoggingLevelsHierarchy
2022-04-04 16:38:28 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-89
2022-04-04 16:38:29 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-89
2022-04-04 16:38:29 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-89
2022-04-04 16:38:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3b99eda5-source in namespace namespace-89
2022-04-04 16:38:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-89
2022-04-04 16:38:29 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3b99eda5-source will have desired state: Ready
2022-04-04 16:39:39 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3b99eda5-source is in desired state: Ready
2022-04-04 16:39:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3b99eda5-target in namespace namespace-89
2022-04-04 16:39:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-89
2022-04-04 16:39:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3b99eda5-target will have desired state: Ready
2022-04-04 16:40:56 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3b99eda5-target is in desired state: Ready
2022-04-04 16:40:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-3b99eda5-kafka-clients in namespace namespace-89
2022-04-04 16:40:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-89
2022-04-04 16:40:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-3b99eda5 in namespace namespace-89
2022-04-04 16:40:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-89
2022-04-04 16:40:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-3b99eda5 will have desired state: Ready
2022-04-04 16:41:59 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-3b99eda5 is in desired state: Ready
2022-04-04 16:41:59 [main] [32mINFO [m [LoggingChangeST:1254] Waiting for log4j.properties will contain desired settings
2022-04-04 16:42:00 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-3b99eda5-mirrormaker2-f9d8b447b-fscmt -- curl http://localhost:8083/admin/loggers/root
2022-04-04 16:42:00 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:42:00 [main] [32mINFO [m [LoggingChangeST:1259] Changing log levels
2022-04-04 16:42:00 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-3b99eda5-mirrormaker2-f9d8b447b-fscmt -- curl http://localhost:8083/admin/loggers/root
2022-04-04 16:42:00 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:42:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-3b99eda5-mirrormaker2-f9d8b447b-fscmt -- curl http://localhost:8083/admin/loggers/root
2022-04-04 16:42:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:42:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-3b99eda5-mirrormaker2-f9d8b447b-fscmt -- curl http://localhost:8083/admin/loggers/org.eclipse.jetty.util.thread.strategy.EatWhatYouKill
2022-04-04 16:42:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:42:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-3b99eda5-mirrormaker2-f9d8b447b-fscmt -- curl http://localhost:8083/admin/loggers/org.apache.kafka.connect.runtime.WorkerTask
2022-04-04 16:42:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:42:01 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 16:42:01 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMM2LoggingLevelsHierarchy
2022-04-04 16:42:01 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-3b99eda5-kafka-clients in namespace namespace-89
2022-04-04 16:42:01 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-3b99eda5 in namespace namespace-89
2022-04-04 16:42:01 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3b99eda5-target in namespace namespace-89
2022-04-04 16:42:01 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3b99eda5-source in namespace namespace-89
2022-04-04 16:42:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 16:42:51 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-89 for test case:testMM2LoggingLevelsHierarchy
2022-04-04 16:42:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testMM2LoggingLevelsHierarchy-FINISHED
2022-04-04 16:42:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 16:42:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 16:42:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testLoggingHierarchy-STARTED
2022-04-04 16:42:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 16:42:58 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-90 for test case:testLoggingHierarchy
2022-04-04 16:42:58 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-90
2022-04-04 16:42:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-90
2022-04-04 16:42:58 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-90
2022-04-04 16:42:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1020841e in namespace namespace-90
2022-04-04 16:42:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-90
2022-04-04 16:42:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-1020841e-kafka-clients in namespace namespace-90
2022-04-04 16:42:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-90
2022-04-04 16:42:58 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1020841e will have desired state: Ready
2022-04-04 16:44:15 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1020841e is in desired state: Ready
2022-04-04 16:44:15 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1020841e-kafka-clients will be ready
2022-04-04 16:44:15 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1020841e-kafka-clients is ready
2022-04-04 16:44:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-1020841e-scraper in namespace namespace-90
2022-04-04 16:44:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-90
2022-04-04 16:44:15 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1020841e-scraper will be ready
2022-04-04 16:44:17 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1020841e-scraper is ready
2022-04-04 16:44:17 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-1020841e-scraper to be ready
2022-04-04 16:44:27 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-1020841e-scraper is ready
2022-04-04 16:44:27 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-1020841e-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 16:44:27 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-1020841e-allow in namespace namespace-90
2022-04-04 16:44:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-90
2022-04-04 16:44:27 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 16:44:27 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-1020841e in namespace namespace-90
2022-04-04 16:44:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-90
2022-04-04 16:44:27 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-1020841e in namespace namespace-90
2022-04-04 16:44:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-90
2022-04-04 16:44:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-1020841e will have desired state: Ready
2022-04-04 16:45:34 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-1020841e is in desired state: Ready
2022-04-04 16:45:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-1020841e will have desired state: Ready
2022-04-04 16:45:34 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-1020841e is in desired state: Ready
2022-04-04 16:45:34 [main] [32mINFO [m [LoggingChangeST:1401] Changing rootLogger level in KafkaConnector to ERROR with inline logging
2022-04-04 16:45:34 [main] [32mINFO [m [LoggingChangeST:1407] Waiting for Connect API loggers will contain desired settings
2022-04-04 16:45:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:45:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:45:34 [main] [32mINFO [m [LoggingChangeST:1413] Restarting Kafka connector my-cluster-1020841e with class name org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:45:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl -X POST http://my-cluster-1020841e-connect-api:8083/connectors/my-cluster-1020841e/restart
2022-04-04 16:45:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:45:34 [main] [32mINFO [m [KafkaConnectorUtils:168] Wait until KafkaConnector my-cluster-1020841e's worker will be in RUNNING state
2022-04-04 16:45:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl GET http://my-cluster-1020841e-connect-api:8083/connectors/my-cluster-1020841e/status
2022-04-04 16:45:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:45:34 [main] [32mINFO [m [LoggingChangeST:1420] Checking that logger is same for connector with class name org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:45:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:45:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:45:35 [main] [32mINFO [m [LoggingChangeST:1426] Changing KafkaConnect's root logger to WARN, KafkaConnector: my-cluster-1020841e shouldn't inherit it
2022-04-04 16:45:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/root
2022-04-04 16:45:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:45:35 [main] [32mINFO [m [LoggingChangeST:1440] Checking if KafkaConnector org.apache.kafka.connect.file.FileStreamSourceConnector doesn't inherit logger from KafkaConnect
2022-04-04 16:45:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:45:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:45:35 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 49
2022-04-04 16:45:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:45:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:45:36 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 48
2022-04-04 16:45:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:45:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:45:37 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 47
2022-04-04 16:45:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:45:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:45:39 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 46
2022-04-04 16:45:40 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:45:40 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:45:40 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 45
2022-04-04 16:45:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:45:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:45:41 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 44
2022-04-04 16:45:42 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:45:42 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:45:42 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 43
2022-04-04 16:45:43 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:45:43 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:45:43 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 42
2022-04-04 16:45:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:45:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:45:45 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 41
2022-04-04 16:45:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:45:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:45:46 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 40
2022-04-04 16:45:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:45:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:45:47 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 39
2022-04-04 16:45:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:45:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:45:48 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 38
2022-04-04 16:45:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:45:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:45:49 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 37
2022-04-04 16:45:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:45:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:45:51 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 36
2022-04-04 16:45:52 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:45:52 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:45:52 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 35
2022-04-04 16:45:53 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:45:53 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:45:53 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 34
2022-04-04 16:45:54 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:45:54 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:45:54 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 33
2022-04-04 16:45:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:45:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:45:55 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 32
2022-04-04 16:45:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:45:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:45:57 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 31
2022-04-04 16:45:58 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:45:58 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:45:58 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 30
2022-04-04 16:45:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:45:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:45:59 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 29
2022-04-04 16:46:00 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:46:00 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:00 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 28
2022-04-04 16:46:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:46:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:01 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 27
2022-04-04 16:46:02 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:46:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:02 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 26
2022-04-04 16:46:04 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:46:04 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:04 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 25
2022-04-04 16:46:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:46:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:05 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 24
2022-04-04 16:46:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:46:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:06 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 23
2022-04-04 16:46:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:46:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:07 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 22
2022-04-04 16:46:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:46:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:08 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 21
2022-04-04 16:46:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:46:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:10 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 20
2022-04-04 16:46:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:46:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:11 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 19
2022-04-04 16:46:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:46:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:12 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 18
2022-04-04 16:46:13 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:46:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:13 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 17
2022-04-04 16:46:14 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:46:14 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:14 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 16
2022-04-04 16:46:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:46:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:16 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 15
2022-04-04 16:46:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:46:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:17 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 14
2022-04-04 16:46:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:46:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:18 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 13
2022-04-04 16:46:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:46:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:19 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 12
2022-04-04 16:46:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:46:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:20 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 11
2022-04-04 16:46:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:46:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:22 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 10
2022-04-04 16:46:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:46:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:23 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 9
2022-04-04 16:46:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:46:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:24 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 8
2022-04-04 16:46:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:46:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:25 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 7
2022-04-04 16:46:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:46:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:26 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 6
2022-04-04 16:46:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:46:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:28 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 5
2022-04-04 16:46:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:46:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:29 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 4
2022-04-04 16:46:30 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:46:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:30 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 3
2022-04-04 16:46:31 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:46:31 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:31 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 2
2022-04-04 16:46:32 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:46:32 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:32 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 1
2022-04-04 16:46:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1020841e-kafka-clients-856989bb46-s5w5p -- curl http://my-cluster-1020841e-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:46:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:34 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 0
2022-04-04 16:46:34 [main] [32mINFO [m [KafkaConnectorUtils:196] Logger for connector org.apache.kafka.connect.file.FileStreamSourceConnector is stable
2022-04-04 16:46:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 16:46:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testLoggingHierarchy
2022-04-04 16:46:34 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-1020841e-allow in namespace namespace-90
2022-04-04 16:46:34 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-1020841e in namespace namespace-90
2022-04-04 16:46:34 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-1020841e in namespace namespace-90
2022-04-04 16:46:34 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-1020841e-scraper in namespace namespace-90
2022-04-04 16:46:34 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1020841e in namespace namespace-90
2022-04-04 16:46:34 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-1020841e-kafka-clients in namespace namespace-90
2022-04-04 16:47:24 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 16:47:24 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-90 for test case:testLoggingHierarchy
2022-04-04 16:47:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testLoggingHierarchy-FINISHED
2022-04-04 16:47:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 16:47:29 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 16:47:29 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testJSONFormatLogging-STARTED
2022-04-04 16:47:29 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 16:47:29 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-91 for test case:testJSONFormatLogging
2022-04-04 16:47:29 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-91
2022-04-04 16:47:29 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-91
2022-04-04 16:47:29 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-91
2022-04-04 16:47:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b6562338 in namespace namespace-91
2022-04-04 16:47:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-91
2022-04-04 16:47:29 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b6562338 will have desired state: Ready
2022-04-04 16:49:25 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b6562338 is in desired state: Ready
2022-04-04 16:49:25 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: strimzi-cluster-operator-78689684d4-d55zd
2022-04-04 16:49:25 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-b6562338-kafka-1
2022-04-04 16:49:25 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-b6562338-kafka-2
2022-04-04 16:49:25 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-b6562338-kafka-0
2022-04-04 16:49:25 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-b6562338-zookeeper-0
2022-04-04 16:49:25 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-b6562338-zookeeper-2
2022-04-04 16:49:25 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-b6562338-zookeeper-1
2022-04-04 16:49:26 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-b6562338-entity-operator-7cdcf7cd59-9b9ft
2022-04-04 16:49:26 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-b6562338-entity-operator-7cdcf7cd59-9b9ft
2022-04-04 16:49:26 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 16:49:26 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testJSONFormatLogging
2022-04-04 16:49:26 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b6562338 in namespace namespace-91
2022-04-04 16:49:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 16:49:36 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-91 for test case:testJSONFormatLogging
2022-04-04 16:50:03 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testJSONFormatLogging-FINISHED
2022-04-04 16:50:03 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 16:50:03 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 16:50:03 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetKafkaLoggingLevels-STARTED
2022-04-04 16:50:03 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 16:50:03 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-92 for test case:testDynamicallySetKafkaLoggingLevels
2022-04-04 16:50:03 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-92
2022-04-04 16:50:03 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-92
2022-04-04 16:50:03 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-92
2022-04-04 16:50:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-710a4d5f in namespace namespace-92
2022-04-04 16:50:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-92
2022-04-04 16:50:03 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-710a4d5f will have desired state: Ready
2022-04-04 16:51:14 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-710a4d5f is in desired state: Ready
2022-04-04 16:51:14 [main] [32mINFO [m [LoggingChangeST:829] Changing rootLogger level to DEBUG with inline logging
2022-04-04 16:51:14 [main] [32mINFO [m [LoggingChangeST:836] Waiting for dynamic change in the kafka pod
2022-04-04 16:51:17 [main] [32mINFO [m [LoggingChangeST:854] Setting external logging INFO
2022-04-04 16:51:17 [main] [32mINFO [m [LoggingChangeST:890] Setting log level of kafka INFO
2022-04-04 16:51:17 [main] [32mINFO [m [LoggingChangeST:896] Waiting for dynamic change in the kafka pod
2022-04-04 16:51:24 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 16:51:24 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetKafkaLoggingLevels
2022-04-04 16:51:24 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-710a4d5f in namespace namespace-92
2022-04-04 16:51:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 16:51:34 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-92 for test case:testDynamicallySetKafkaLoggingLevels
2022-04-04 16:52:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetKafkaLoggingLevels-FINISHED
2022-04-04 16:52:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 16:52:17 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 16:52:17 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetEOloggingLevels-STARTED
2022-04-04 16:52:17 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 16:52:17 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-93 for test case:testDynamicallySetEOloggingLevels
2022-04-04 16:52:17 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-93
2022-04-04 16:52:18 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-93
2022-04-04 16:52:18 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-93
2022-04-04 16:52:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d279468a in namespace namespace-93
2022-04-04 16:52:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-93
2022-04-04 16:52:18 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d279468a will have desired state: Ready
2022-04-04 16:53:28 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d279468a is in desired state: Ready
2022-04-04 16:53:28 [main] [32mINFO [m [LoggingChangeST:284] Checking if EO pod contains any log (except configuration)
2022-04-04 16:53:28 [main] [32mINFO [m [LoggingChangeST:287] Changing rootLogger level to DEBUG with inline logging
2022-04-04 16:53:28 [main] [32mINFO [m [LoggingChangeST:295] Waiting for log4j2.properties will contain desired settings
2022-04-04 16:54:42 [main] [32mINFO [m [LoggingChangeST:312] Setting external logging OFF
2022-04-04 16:54:42 [main] [32mINFO [m [LoggingChangeST:370] Setting log level of TO and UO to OFF - records should not appear in log
2022-04-04 16:54:42 [main] [32mINFO [m [LoggingChangeST:377] Waiting for log4j2.properties will contain desired settings
2022-04-04 16:56:36 [main] [32mINFO [m [LoggingChangeST:395] Setting external logging OFF
2022-04-04 16:56:36 [main] [32mINFO [m [LoggingChangeST:431] Waiting for log4j2.properties will contain desired settings
2022-04-04 16:57:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 16:57:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetEOloggingLevels
2022-04-04 16:57:11 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d279468a in namespace namespace-93
2022-04-04 16:57:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 16:57:21 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-93 for test case:testDynamicallySetEOloggingLevels
2022-04-04 16:57:27 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetEOloggingLevels-FINISHED
2022-04-04 16:57:27 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 16:57:27 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 16:57:27 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetUnknownKafkaLoggerValue-STARTED
2022-04-04 16:57:27 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 16:57:27 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-94 for test case:testDynamicallySetUnknownKafkaLoggerValue
2022-04-04 16:57:27 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-94
2022-04-04 16:57:27 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-94
2022-04-04 16:57:27 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-94
2022-04-04 16:57:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-4f45547f in namespace namespace-94
2022-04-04 16:57:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-94
2022-04-04 16:57:27 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4f45547f will have desired state: Ready
2022-04-04 16:58:46 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4f45547f is in desired state: Ready
2022-04-04 16:58:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 50
2022-04-04 16:58:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 49
2022-04-04 16:58:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 48
2022-04-04 16:58:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 47
2022-04-04 16:58:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 46
2022-04-04 16:58:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 45
2022-04-04 16:58:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 44
2022-04-04 16:58:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 43
2022-04-04 16:58:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 42
2022-04-04 16:58:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 41
2022-04-04 16:58:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 40
2022-04-04 16:58:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 39
2022-04-04 16:58:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 38
2022-04-04 16:58:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 37
2022-04-04 16:59:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 36
2022-04-04 16:59:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 35
2022-04-04 16:59:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 34
2022-04-04 16:59:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 33
2022-04-04 16:59:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 32
2022-04-04 16:59:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 31
2022-04-04 16:59:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 30
2022-04-04 16:59:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 29
2022-04-04 16:59:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 28
2022-04-04 16:59:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 27
2022-04-04 16:59:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 26
2022-04-04 16:59:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 25
2022-04-04 16:59:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 24
2022-04-04 16:59:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 23
2022-04-04 16:59:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 22
2022-04-04 16:59:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 21
2022-04-04 16:59:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 20
2022-04-04 16:59:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 19
2022-04-04 16:59:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 18
2022-04-04 16:59:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 17
2022-04-04 16:59:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 16
2022-04-04 16:59:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 15
2022-04-04 16:59:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 14
2022-04-04 16:59:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 13
2022-04-04 16:59:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 12
2022-04-04 16:59:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 11
2022-04-04 16:59:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 10
2022-04-04 16:59:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 9
2022-04-04 16:59:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 8
2022-04-04 16:59:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 7
2022-04-04 16:59:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 6
2022-04-04 16:59:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 5
2022-04-04 16:59:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 4
2022-04-04 16:59:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 3
2022-04-04 16:59:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 2
2022-04-04 16:59:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 1
2022-04-04 16:59:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-4f45547f-kafka-0=33394a12-ced1-403f-927d-dd7442ea6839, my-cluster-4f45547f-kafka-1=9d43e0a6-f1aa-4ae1-a68b-b09e0ed75698, my-cluster-4f45547f-kafka-2=f38686dc-8ae7-42f8-b68d-049e7f1e2464} pods didn't roll. Remaining seconds for stability: 0
2022-04-04 16:59:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 16:59:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetUnknownKafkaLoggerValue
2022-04-04 16:59:37 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-4f45547f in namespace namespace-94
2022-04-04 16:59:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 16:59:47 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-94 for test case:testDynamicallySetUnknownKafkaLoggerValue
2022-04-04 17:00:30 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetUnknownKafkaLoggerValue-FINISHED
2022-04-04 17:00:30 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 17:00:30 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 17:00:30 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetBridgeLoggingLevels-STARTED
2022-04-04 17:00:30 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 17:00:30 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-95 for test case:testDynamicallySetBridgeLoggingLevels
2022-04-04 17:00:30 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-95
2022-04-04 17:00:30 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-95
2022-04-04 17:00:30 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-95
2022-04-04 17:00:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d4986064 in namespace namespace-95
2022-04-04 17:00:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-95
2022-04-04 17:00:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-d4986064-kafka-clients in namespace namespace-95
2022-04-04 17:00:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-95
2022-04-04 17:00:30 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge my-cluster-d4986064 in namespace namespace-95
2022-04-04 17:00:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-95
2022-04-04 17:00:30 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d4986064 will have desired state: Ready
2022-04-04 17:01:43 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d4986064 is in desired state: Ready
2022-04-04 17:01:43 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d4986064-kafka-clients will be ready
2022-04-04 17:01:43 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d4986064-kafka-clients is ready
2022-04-04 17:01:43 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: my-cluster-d4986064 will have desired state: Ready
2022-04-04 17:01:43 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: my-cluster-d4986064 is in desired state: Ready
2022-04-04 17:01:43 [main] [32mINFO [m [LoggingChangeST:484] Asserting if log is without records
2022-04-04 17:01:43 [main] [32mINFO [m [LoggingChangeST:487] Changing rootLogger level to DEBUG with inline logging
2022-04-04 17:01:43 [main] [32mINFO [m [LoggingChangeST:499] Waiting for log4j2.properties will contain desired settings
2022-04-04 17:02:39 [main] [32mINFO [m [LoggingChangeST:556] Setting log level of Bridge to OFF - records should not appear in the log
2022-04-04 17:02:39 [main] [32mINFO [m [LoggingChangeST:562] Waiting for log4j2.properties will contain desired settings
2022-04-04 17:04:39 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:04:39 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetBridgeLoggingLevels
2022-04-04 17:04:39 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-d4986064-kafka-clients in namespace namespace-95
2022-04-04 17:04:39 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d4986064 in namespace namespace-95
2022-04-04 17:04:39 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge my-cluster-d4986064 in namespace namespace-95
2022-04-04 17:05:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:05:29 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-95 for test case:testDynamicallySetBridgeLoggingLevels
2022-04-04 17:05:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetBridgeLoggingLevels-FINISHED
2022-04-04 17:05:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 17:05:34 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 17:05:34 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetMM2LoggingLevels-STARTED
2022-04-04 17:05:34 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 17:05:34 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-96 for test case:testDynamicallySetMM2LoggingLevels
2022-04-04 17:05:34 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-96
2022-04-04 17:05:34 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-96
2022-04-04 17:05:34 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-96
2022-04-04 17:05:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-170ec067-source in namespace namespace-96
2022-04-04 17:05:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-96
2022-04-04 17:05:34 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-170ec067-source will have desired state: Ready
2022-04-04 17:06:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-170ec067-source is in desired state: Ready
2022-04-04 17:06:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-170ec067-target in namespace namespace-96
2022-04-04 17:06:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-96
2022-04-04 17:06:45 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-170ec067-target will have desired state: Ready
2022-04-04 17:07:56 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-170ec067-target is in desired state: Ready
2022-04-04 17:07:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-170ec067-kafka-clients in namespace namespace-96
2022-04-04 17:07:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-96
2022-04-04 17:07:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-170ec067 in namespace namespace-96
2022-04-04 17:07:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-96
2022-04-04 17:07:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-170ec067 will have desired state: Ready
2022-04-04 17:09:06 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-170ec067 is in desired state: Ready
2022-04-04 17:09:06 [main] [32mINFO [m [LoggingChangeST:1124] Changing rootLogger level to DEBUG with inline logging
2022-04-04 17:09:06 [main] [32mINFO [m [LoggingChangeST:1133] Waiting for log4j.properties will contain desired settings
2022-04-04 17:09:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-96 exec my-cluster-170ec067-mirrormaker2-745fc79d4c-j8j2t -- curl http://localhost:8083/admin/loggers/root
2022-04-04 17:09:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 17:09:07 [main] [32mINFO [m [LoggingChangeST:1177] Setting log level of MM2 to OFF
2022-04-04 17:09:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-96 exec my-cluster-170ec067-mirrormaker2-745fc79d4c-j8j2t -- curl http://localhost:8083/admin/loggers/root
2022-04-04 17:09:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 17:09:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-96 exec my-cluster-170ec067-mirrormaker2-745fc79d4c-j8j2t -- curl http://localhost:8083/admin/loggers/root
2022-04-04 17:09:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 17:09:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:09:08 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetMM2LoggingLevels
2022-04-04 17:09:08 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-170ec067-kafka-clients in namespace namespace-96
2022-04-04 17:09:08 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-170ec067-source in namespace namespace-96
2022-04-04 17:09:08 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-170ec067 in namespace namespace-96
2022-04-04 17:09:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-170ec067-target in namespace namespace-96
2022-04-04 17:09:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:09:58 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-96 for test case:testDynamicallySetMM2LoggingLevels
2022-04-04 17:10:09 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetMM2LoggingLevels-FINISHED
2022-04-04 17:10:09 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 17:10:09 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:10:09 [main] [32mINFO [m [ResourceManager:346] In context LoggingChangeST is everything deleted.
2022-04-04 17:10:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2,919.45 s - in io.strimzi.systemtest.log.LoggingChangeST
[[1;34mINFO[m] Running io.strimzi.systemtest.log.LogSettingST
2022-04-04 17:10:15 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: log-setting-st
2022-04-04 17:10:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: log-setting-st
2022-04-04 17:10:15 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: log-setting-st
2022-04-04 17:10:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka log-setting-cluster-name in namespace log-setting-st
2022-04-04 17:10:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka gc-set-logging in namespace log-setting-st
2022-04-04 17:10:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment shared-kafka-clients in namespace log-setting-st
2022-04-04 17:10:15 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: log-setting-cluster-name will have desired state: Ready
2022-04-04 17:12:13 [main] [32mINFO [m [ResourceManager:444] Kafka: log-setting-cluster-name is in desired state: Ready
2022-04-04 17:12:13 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: gc-set-logging will have desired state: Ready
2022-04-04 17:12:13 [main] [32mINFO [m [ResourceManager:444] Kafka: gc-set-logging is in desired state: Ready
2022-04-04 17:12:13 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: shared-kafka-clients will be ready
2022-04-04 17:12:13 [main] [32mINFO [m [DeploymentUtils:168] Deployment: shared-kafka-clients is ready
2022-04-04 17:12:13 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 17:12:13 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LogSettingST.testMirrorMaker2LogSetting-STARTED
2022-04-04 17:12:13 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 17:12:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-ddf51171-mirror-maker-2 in namespace log-setting-st
2022-04-04 17:12:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-ddf51171-mirror-maker-2 will have desired state: Ready
2022-04-04 17:13:18 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-ddf51171-mirror-maker-2 is in desired state: Ready
2022-04-04 17:13:18 [main] [32mINFO [m [LogSettingST:357] Checking if MirrorMaker2 has log level set properly
2022-04-04 17:13:18 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: mirrormaker.root.logger Expected: TRACE
2022-04-04 17:13:18 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.mirrormaker.logger.level Expected: TRACE
2022-04-04 17:13:18 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-ddf51171-mirror-maker-2-mirrormaker2
2022-04-04 17:13:18 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-ddf51171-mirror-maker-2-mirrormaker2
2022-04-04 17:13:18 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-04 17:13:18 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-ddf51171-mirror-maker-2-mirrormaker2 rolling update
2022-04-04 17:14:33 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ddf51171-mirror-maker-2-mirrormaker2 will be ready
2022-04-04 17:14:33 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ddf51171-mirror-maker-2-mirrormaker2 is ready
2022-04-04 17:14:43 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-ddf51171-mirror-maker-2-mirrormaker2 rolling update finished
2022-04-04 17:14:43 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-ddf51171-mirror-maker-2-mirrormaker2
2022-04-04 17:14:43 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-ddf51171-mirror-maker-2-mirrormaker2
2022-04-04 17:14:43 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-04 17:14:43 [main] [32mINFO [m [PodUtils:343] Waiting for Pod my-cluster-ddf51171-mirror-maker-2-mirrormaker2-b8488ccc5-kpgc8 container my-cluster-ddf51171-mirror-maker-2-mirrormaker2 will be ready
2022-04-04 17:14:43 [main] [32mINFO [m [PodUtils:347] Pod my-cluster-ddf51171-mirror-maker-2-mirrormaker2-b8488ccc5-kpgc8 container my-cluster-ddf51171-mirror-maker-2-mirrormaker2 is ready
2022-04-04 17:14:43 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod my-cluster-ddf51171-mirror-maker-2-mirrormaker2-b8488ccc5-kpgc8 with container my-cluster-ddf51171-mirror-maker-2-mirrormaker2
2022-04-04 17:14:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:14:43 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker2LogSetting
2022-04-04 17:14:43 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-ddf51171-mirror-maker-2 in namespace log-setting-st
2022-04-04 17:14:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:14:53 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LogSettingST.testMirrorMaker2LogSetting-FINISHED
2022-04-04 17:14:53 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 17:14:53 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 17:14:53 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LogSettingST.testCruiseControlLogChange-STARTED
2022-04-04 17:14:53 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 17:14:53 [main] [32mINFO [m [LogSettingST:409] Check that default/actual root logging level is info
2022-04-04 17:14:54 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-7588db9f8b-5ncv5 -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-04 17:14:54 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 17:14:54 [main] [32mINFO [m [LogSettingST:414] Check logs in CruiseControl - make sure no DEBUG is found there.
2022-04-04 17:14:54 [main] [32mINFO [m [LogSettingST:422] Wait for change of root logger in log-setting-cluster-name-cruise-control-7588db9f8b-5ncv5.
2022-04-04 17:14:54 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-7588db9f8b-5ncv5 -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-04 17:14:54 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 17:14:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-7588db9f8b-5ncv5 -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-04 17:14:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 17:15:04 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-7588db9f8b-5ncv5 -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-04 17:15:04 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 17:15:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-7588db9f8b-5ncv5 -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-04 17:15:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 17:15:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-7588db9f8b-5ncv5 -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-04 17:15:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 17:15:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-7588db9f8b-5ncv5 -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-04 17:15:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 17:15:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-7588db9f8b-5ncv5 -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-04 17:15:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 17:15:30 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-7588db9f8b-5ncv5 -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-04 17:15:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 17:15:30 [main] [32mINFO [m [LogSettingST:428] Check cruise control logs in pod log-setting-cluster-name-cruise-control-7588db9f8b-5ncv5 and it's container cruise-control .
2022-04-04 17:15:41 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:15:41 [main] [32mINFO [m [ResourceManager:346] In context testCruiseControlLogChange is everything deleted.
2022-04-04 17:15:41 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:15:41 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LogSettingST.testCruiseControlLogChange-FINISHED
2022-04-04 17:15:41 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 17:15:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 17:15:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LogSettingST.testMirrorMakerLogSetting-STARTED
2022-04-04 17:15:41 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 17:15:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-5407182b-mirror-maker in namespace log-setting-st
2022-04-04 17:15:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-5407182b-mirror-maker will have desired state: Ready
2022-04-04 17:16:48 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-5407182b-mirror-maker is in desired state: Ready
2022-04-04 17:16:48 [main] [32mINFO [m [LogSettingST:322] Checking if MirrorMaker has log level set properly
2022-04-04 17:16:48 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: mirrormaker.root.logger Expected: TRACE
2022-04-04 17:16:48 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.mirrormaker.logger.level Expected: TRACE
2022-04-04 17:16:48 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-5407182b-mirror-maker-mirror-maker
2022-04-04 17:16:48 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-5407182b-mirror-maker-mirror-maker
2022-04-04 17:16:48 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-04 17:16:48 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-5407182b-mirror-maker-mirror-maker rolling update
2022-04-04 17:17:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-5407182b-mirror-maker-mirror-maker will be ready
2022-04-04 17:17:58 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-5407182b-mirror-maker-mirror-maker is ready
2022-04-04 17:18:08 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-5407182b-mirror-maker-mirror-maker rolling update finished
2022-04-04 17:18:08 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-5407182b-mirror-maker-mirror-maker
2022-04-04 17:18:08 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-5407182b-mirror-maker-mirror-maker
2022-04-04 17:18:08 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-04 17:18:08 [main] [32mINFO [m [PodUtils:343] Waiting for Pod my-cluster-5407182b-mirror-maker-mirror-maker-84477646c5-85dbz container my-cluster-5407182b-mirror-maker-mirror-maker will be ready
2022-04-04 17:18:08 [main] [32mINFO [m [PodUtils:347] Pod my-cluster-5407182b-mirror-maker-mirror-maker-84477646c5-85dbz container my-cluster-5407182b-mirror-maker-mirror-maker is ready
2022-04-04 17:18:08 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod my-cluster-5407182b-mirror-maker-mirror-maker-84477646c5-85dbz with container my-cluster-5407182b-mirror-maker-mirror-maker
2022-04-04 17:18:09 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:18:09 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMakerLogSetting
2022-04-04 17:18:09 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-5407182b-mirror-maker in namespace log-setting-st
2022-04-04 17:18:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:18:19 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LogSettingST.testMirrorMakerLogSetting-FINISHED
2022-04-04 17:18:19 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 17:18:19 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 17:18:19 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LogSettingST.testConnectLogSetting-STARTED
2022-04-04 17:18:19 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 17:18:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a823395f-connect-scraper in namespace log-setting-st
2022-04-04 17:18:19 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a823395f-connect-scraper will be ready
2022-04-04 17:18:21 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a823395f-connect-scraper is ready
2022-04-04 17:18:21 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-a823395f-connect-scraper to be ready
2022-04-04 17:18:31 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-a823395f-connect-scraper is ready
2022-04-04 17:18:31 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-a823395f-connect-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 17:18:31 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-a823395f-connect-allow in namespace log-setting-st
2022-04-04 17:18:31 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 17:18:31 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-a823395f-connect in namespace log-setting-st
2022-04-04 17:18:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-a823395f-connect will have desired state: Ready
2022-04-04 17:19:35 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-a823395f-connect is in desired state: Ready
2022-04-04 17:19:35 [main] [32mINFO [m [LogSettingST:287] Checking if Connect has log level set properly
2022-04-04 17:19:35 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.org.I0Itec.zkclient Expected: ERROR
2022-04-04 17:19:35 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: connect.root.logger.level Expected: INFO
2022-04-04 17:19:35 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.connect.logger.level Expected: DEBUG
2022-04-04 17:19:35 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.org.reflections Expected: WARN
2022-04-04 17:19:35 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-a823395f-connect-connect
2022-04-04 17:19:35 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-a823395f-connect-connect
2022-04-04 17:19:35 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-04 17:19:35 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-a823395f-connect-connect rolling update
2022-04-04 17:20:45 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a823395f-connect-connect will be ready
2022-04-04 17:20:45 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a823395f-connect-connect is ready
2022-04-04 17:20:55 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-a823395f-connect-connect rolling update finished
2022-04-04 17:20:55 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-a823395f-connect-connect
2022-04-04 17:20:55 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-a823395f-connect-connect
2022-04-04 17:20:55 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-04 17:20:55 [main] [32mINFO [m [PodUtils:343] Waiting for Pod my-cluster-a823395f-connect-connect-5d458cbfc6-bk48f container my-cluster-a823395f-connect-connect will be ready
2022-04-04 17:20:55 [main] [32mINFO [m [PodUtils:347] Pod my-cluster-a823395f-connect-connect-5d458cbfc6-bk48f container my-cluster-a823395f-connect-connect is ready
2022-04-04 17:20:55 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod my-cluster-a823395f-connect-connect-5d458cbfc6-bk48f with container my-cluster-a823395f-connect-connect
2022-04-04 17:20:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:20:56 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConnectLogSetting
2022-04-04 17:20:56 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-a823395f-connect-allow in namespace log-setting-st
2022-04-04 17:20:56 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a823395f-connect-scraper in namespace log-setting-st
2022-04-04 17:20:56 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-a823395f-connect in namespace log-setting-st
2022-04-04 17:21:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:21:36 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LogSettingST.testConnectLogSetting-FINISHED
2022-04-04 17:21:36 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 17:21:36 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 17:21:36 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LogSettingST.testKafkaLogSetting-STARTED
2022-04-04 17:21:36 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 17:21:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1754687848-308584365 in namespace log-setting-st
2022-04-04 17:21:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1754687848-308584365 will have desired state: Ready
2022-04-04 17:21:37 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1754687848-308584365 is in desired state: Ready
2022-04-04 17:21:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1767632367-259834453 in namespace log-setting-st
2022-04-04 17:21:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1767632367-259834453 will have desired state: Ready
2022-04-04 17:21:38 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1767632367-259834453 is in desired state: Ready
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:217] Checking if Kafka, Zookeeper, TO and UO of cluster:log-setting-cluster-name has log level set properly
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.org.apache.zookeeper Expected: WARN
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.network.Processor Expected: OFF
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.request.logger Expected: FATAL
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.controller Expected: WARN
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: kafka.root.logger.level Expected: INFO
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.state.change.logger Expected: DEBUG
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.network.RequestChannel$ Expected: ERROR
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.server.KafkaApis Expected: INFO
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka Expected: TRACE
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.org.apache.kafka Expected: DEBUG
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.authorizer.logger Expected: FATAL
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.log.LogCleaner Expected: TRACE
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.org.I0Itec.zkclient.ZkClient Expected: ERROR
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.kafka.logger.level Expected: INFO
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: zookeeper.root.logger Expected: OFF
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.zookeeper.logger.level Expected: DEBUG
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: rootLogger.level Expected: DEBUG
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.operator.logger.level Expected: DEBUG
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: rootLogger.level Expected: DEBUG
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.operator.logger.level Expected: DEBUG
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:226] Checking if Kafka, Zookeeper, TO and UO of cluster:log-setting-cluster-name has GC logging enabled in stateful sets/deployments
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:512] Checking pods with selector: LabelSelector(matchExpressions=[], matchLabels={strimzi.io/name=log-setting-cluster-name-kafka, strimzi.io/cluster=log-setting-cluster-name, strimzi.io/kind=Kafka}, additionalProperties={})
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-0, container: kafka
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-1, container: kafka
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-2, container: kafka
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:512] Checking pods with selector: LabelSelector(matchExpressions=[], matchLabels={strimzi.io/name=log-setting-cluster-name-zookeeper, strimzi.io/cluster=log-setting-cluster-name, strimzi.io/kind=Kafka}, additionalProperties={})
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-zookeeper-0, container: zookeeper
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:490] Checking deployment: log-setting-cluster-name-entity-operator
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:493] Checking container with name: topic-operator
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=true
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:490] Checking deployment: log-setting-cluster-name-entity-operator
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:493] Checking container with name: user-operator
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=true
2022-04-04 17:21:38 [main] [32mINFO [m [LogSettingST:232] Changing JVM options - setting GC logging to false
2022-04-04 17:21:38 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: log-setting-cluster-name-zookeeper rolling update
2022-04-04 17:21:43 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: log-setting-cluster-name-zookeeper has been successfully rolled
2022-04-04 17:21:43 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 1 Pod(s) of log-setting-cluster-name-zookeeper to be ready
2022-04-04 17:22:13 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: log-setting-cluster-name-kafka rolling update
2022-04-04 17:23:13 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: log-setting-cluster-name-kafka has been successfully rolled
2022-04-04 17:23:13 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of log-setting-cluster-name-kafka to be ready
2022-04-04 17:23:43 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment log-setting-cluster-name-entity-operator rolling update
2022-04-04 17:23:43 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: log-setting-cluster-name-entity-operator will be ready
2022-04-04 17:24:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: log-setting-cluster-name-entity-operator is ready
2022-04-04 17:24:37 [main] [32mINFO [m [DeploymentUtils:141] Deployment log-setting-cluster-name-entity-operator rolling update finished
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:244] Checking if Kafka, Zookeeper, TO and UO of cluster: log-setting-cluster-name has GC logging disabled in stateful sets/deployments
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:512] Checking pods with selector: LabelSelector(matchExpressions=[], matchLabels={strimzi.io/name=log-setting-cluster-name-kafka, strimzi.io/cluster=log-setting-cluster-name, strimzi.io/kind=Kafka}, additionalProperties={})
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-0, container: kafka
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-1, container: kafka
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-2, container: kafka
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:512] Checking pods with selector: LabelSelector(matchExpressions=[], matchLabels={strimzi.io/name=log-setting-cluster-name-zookeeper, strimzi.io/cluster=log-setting-cluster-name, strimzi.io/kind=Kafka}, additionalProperties={})
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-zookeeper-0, container: zookeeper
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:490] Checking deployment: log-setting-cluster-name-entity-operator
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:493] Checking container with name: topic-operator
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=false
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:490] Checking deployment: log-setting-cluster-name-entity-operator
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:493] Checking container with name: user-operator
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=false
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:250] Checking if Kafka, Zookeeper, TO and UO of cluster: gc-set-logging has GC logging disabled in stateful sets/deployments
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:512] Checking pods with selector: LabelSelector(matchExpressions=[], matchLabels={strimzi.io/name=log-setting-cluster-name-kafka, strimzi.io/cluster=log-setting-cluster-name, strimzi.io/kind=Kafka}, additionalProperties={})
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-0, container: kafka
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-1, container: kafka
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-2, container: kafka
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:512] Checking pods with selector: LabelSelector(matchExpressions=[], matchLabels={strimzi.io/name=log-setting-cluster-name-zookeeper, strimzi.io/cluster=log-setting-cluster-name, strimzi.io/kind=Kafka}, additionalProperties={})
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-zookeeper-0, container: zookeeper
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:490] Checking deployment: log-setting-cluster-name-entity-operator
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:493] Checking container with name: topic-operator
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=false
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:490] Checking deployment: log-setting-cluster-name-entity-operator
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:493] Checking container with name: user-operator
2022-04-04 17:24:37 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=false
2022-04-04 17:24:38 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-cruise-control-7588db9f8b-5ncv5 container cruise-control will be ready
2022-04-04 17:24:38 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-cruise-control-7588db9f8b-5ncv5 container cruise-control is ready
2022-04-04 17:24:38 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-cruise-control-7588db9f8b-5ncv5 with container cruise-control
2022-04-04 17:24:38 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-cruise-control-7588db9f8b-5ncv5 container tls-sidecar will be ready
2022-04-04 17:24:38 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-cruise-control-7588db9f8b-5ncv5 container tls-sidecar is ready
2022-04-04 17:24:38 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-cruise-control-7588db9f8b-5ncv5 with container tls-sidecar
2022-04-04 17:24:38 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-entity-operator-d78c874cf-ll82b container topic-operator will be ready
2022-04-04 17:24:38 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-entity-operator-d78c874cf-ll82b container topic-operator is ready
2022-04-04 17:24:38 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-entity-operator-d78c874cf-ll82b with container topic-operator
2022-04-04 17:24:38 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-entity-operator-d78c874cf-ll82b container user-operator will be ready
2022-04-04 17:24:38 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-entity-operator-d78c874cf-ll82b container user-operator is ready
2022-04-04 17:24:38 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-entity-operator-d78c874cf-ll82b with container user-operator
2022-04-04 17:24:39 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-entity-operator-d78c874cf-ll82b container tls-sidecar will be ready
2022-04-04 17:24:39 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-entity-operator-d78c874cf-ll82b container tls-sidecar is ready
2022-04-04 17:24:39 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-entity-operator-d78c874cf-ll82b with container tls-sidecar
2022-04-04 17:24:39 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-kafka-0 container kafka will be ready
2022-04-04 17:24:39 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-kafka-0 container kafka is ready
2022-04-04 17:24:39 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-kafka-0 with container kafka
2022-04-04 17:24:39 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-kafka-1 container kafka will be ready
2022-04-04 17:24:39 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-kafka-1 container kafka is ready
2022-04-04 17:24:39 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-kafka-1 with container kafka
2022-04-04 17:24:39 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-kafka-2 container kafka will be ready
2022-04-04 17:24:39 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-kafka-2 container kafka is ready
2022-04-04 17:24:39 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-kafka-2 with container kafka
2022-04-04 17:24:39 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-kafka-exporter-7b59f7cd48-t8s76 container log-setting-cluster-name-kafka-exporter will be ready
2022-04-04 17:24:39 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-kafka-exporter-7b59f7cd48-t8s76 container log-setting-cluster-name-kafka-exporter is ready
2022-04-04 17:24:39 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-kafka-exporter-7b59f7cd48-t8s76 with container log-setting-cluster-name-kafka-exporter
2022-04-04 17:24:40 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-zookeeper-0 container zookeeper will be ready
2022-04-04 17:24:40 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-zookeeper-0 container zookeeper is ready
2022-04-04 17:24:40 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-zookeeper-0 with container zookeeper
2022-04-04 17:24:40 [main] [32mINFO [m [PodUtils:343] Waiting for Pod gc-set-logging-entity-operator-6dccd5cb65-jb8ml container topic-operator will be ready
2022-04-04 17:24:40 [main] [32mINFO [m [PodUtils:347] Pod gc-set-logging-entity-operator-6dccd5cb65-jb8ml container topic-operator is ready
2022-04-04 17:24:40 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod gc-set-logging-entity-operator-6dccd5cb65-jb8ml with container topic-operator
2022-04-04 17:24:40 [main] [32mINFO [m [PodUtils:343] Waiting for Pod gc-set-logging-entity-operator-6dccd5cb65-jb8ml container user-operator will be ready
2022-04-04 17:24:40 [main] [32mINFO [m [PodUtils:347] Pod gc-set-logging-entity-operator-6dccd5cb65-jb8ml container user-operator is ready
2022-04-04 17:24:40 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod gc-set-logging-entity-operator-6dccd5cb65-jb8ml with container user-operator
2022-04-04 17:24:40 [main] [32mINFO [m [PodUtils:343] Waiting for Pod gc-set-logging-entity-operator-6dccd5cb65-jb8ml container tls-sidecar will be ready
2022-04-04 17:24:40 [main] [32mINFO [m [PodUtils:347] Pod gc-set-logging-entity-operator-6dccd5cb65-jb8ml container tls-sidecar is ready
2022-04-04 17:24:40 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod gc-set-logging-entity-operator-6dccd5cb65-jb8ml with container tls-sidecar
2022-04-04 17:24:40 [main] [32mINFO [m [PodUtils:343] Waiting for Pod gc-set-logging-kafka-0 container kafka will be ready
2022-04-04 17:24:40 [main] [32mINFO [m [PodUtils:347] Pod gc-set-logging-kafka-0 container kafka is ready
2022-04-04 17:24:40 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod gc-set-logging-kafka-0 with container kafka
2022-04-04 17:24:41 [main] [32mINFO [m [PodUtils:343] Waiting for Pod gc-set-logging-zookeeper-0 container zookeeper will be ready
2022-04-04 17:24:41 [main] [32mINFO [m [PodUtils:347] Pod gc-set-logging-zookeeper-0 container zookeeper is ready
2022-04-04 17:24:41 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod gc-set-logging-zookeeper-0 with container zookeeper
2022-04-04 17:24:41 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:24:41 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaLogSetting
2022-04-04 17:24:41 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1767632367-259834453 in namespace log-setting-st
2022-04-04 17:24:41 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1754687848-308584365 in namespace log-setting-st
2022-04-04 17:24:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:24:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LogSettingST.testKafkaLogSetting-FINISHED
2022-04-04 17:24:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 17:24:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 17:24:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LogSettingST.testBridgeLogSetting-STARTED
2022-04-04 17:24:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 17:24:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge my-cluster-06211e36-bridge in namespace log-setting-st
2022-04-04 17:24:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: my-cluster-06211e36-bridge will have desired state: Ready
2022-04-04 17:25:14 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: my-cluster-06211e36-bridge is in desired state: Ready
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:392] Checking if Bridge has log level set properly
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.subscribe.name Expected: http.openapi.operation.subscribe
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.createConsumer.name Expected: http.openapi.operation.createConsumer
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.createConsumer.level Expected: INFO
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.deleteConsumer.name Expected: http.openapi.operation.deleteConsumer
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.poll.name Expected: http.openapi.operation.poll
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.sendToPartition.level Expected: TRACE
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.unsubscribe.name Expected: http.openapi.operation.unsubscribe
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.unsubscribe.level Expected: DEBUG
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.ready.level Expected: WARN
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.assign.name Expected: http.openapi.operation.assign
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.seekToEnd.name Expected: http.openapi.operation.seekToEnd
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.poll.level Expected: INFO
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.deleteConsumer.level Expected: DEBUG
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.subscribe.level Expected: TRACE
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.openapi.level Expected: TRACE
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.commit.name Expected: http.openapi.operation.commit
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.send.level Expected: ERROR
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.seek.name Expected: http.openapi.operation.seek
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.healthy.level Expected: ERROR
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.ready.name Expected: http.openapi.operation.ready
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.logger.bridge.level Expected: ERROR
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.seek.level Expected: INFO
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.assign.level Expected: TRACE
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.sendToPartition.name Expected: http.openapi.operation.sendToPartition
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.send.name Expected: http.openapi.operation.send
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.openapi.name Expected: http.openapi.operation.openapi
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.healthy.name Expected: http.openapi.operation.healthy
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.commit.level Expected: DEBUG
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.seekToEnd.level Expected: WARN
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.seekToBeginning.name Expected: http.openapi.operation.seekToBeginning
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.seekToBeginning.level Expected: DEBUG
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-06211e36-bridge-bridge
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-06211e36-bridge-bridge
2022-04-04 17:25:14 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=true
2022-04-04 17:25:14 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-06211e36-bridge-bridge rolling update
2022-04-04 17:25:44 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-06211e36-bridge-bridge will be ready
2022-04-04 17:25:44 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-06211e36-bridge-bridge is ready
2022-04-04 17:25:54 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-06211e36-bridge-bridge rolling update finished
2022-04-04 17:25:54 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-06211e36-bridge-bridge
2022-04-04 17:25:54 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-06211e36-bridge-bridge
2022-04-04 17:25:54 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=false
2022-04-04 17:25:54 [main] [32mINFO [m [PodUtils:343] Waiting for Pod my-cluster-06211e36-bridge-bridge-79c74fd7df-hkw7q container my-cluster-06211e36-bridge-bridge will be ready
2022-04-04 17:25:54 [main] [32mINFO [m [PodUtils:347] Pod my-cluster-06211e36-bridge-bridge-79c74fd7df-hkw7q container my-cluster-06211e36-bridge-bridge is ready
2022-04-04 17:25:54 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod my-cluster-06211e36-bridge-bridge-79c74fd7df-hkw7q with container my-cluster-06211e36-bridge-bridge
2022-04-04 17:25:55 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:25:55 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBridgeLogSetting
2022-04-04 17:25:55 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge my-cluster-06211e36-bridge in namespace log-setting-st
2022-04-04 17:26:05 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:26:05 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LogSettingST.testBridgeLogSetting-FINISHED
2022-04-04 17:26:05 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 17:26:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:26:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for LogSettingST
2022-04-04 17:26:05 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka gc-set-logging in namespace log-setting-st
2022-04-04 17:26:05 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka log-setting-cluster-name in namespace log-setting-st
2022-04-04 17:26:05 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace log-setting-st, for cruise control Kafka cluster log-setting-cluster-name
2022-04-04 17:26:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment shared-kafka-clients in namespace log-setting-st
2022-04-04 17:26:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,006.424 s - in io.strimzi.systemtest.log.LogSettingST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.FeatureGatesIsolatedST
2022-04-04 17:27:01 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 17:27:26 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 17:27:26 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.FeatureGatesIsolatedST.testSwitchingStrimziPodSetFeatureGateOnAndOff-STARTED
2022-04-04 17:27:26 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 17:27:26 [main] [32mINFO [m [FeatureGatesIsolatedST:270] Deploying CO with STS - SPS is disabled
2022-04-04 17:27:26 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 17:27:26 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 17:27:26 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 17:27:26 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:27:26 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 17:27:26 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 17:27:26 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 17:27:26 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 17:27:26 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 17:27:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 17:27:26 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:27:26 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 17:27:26 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 17:27:26 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:27:26 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 17:27:26 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 17:27:26 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 17:27:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:27:26 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 17:27:26 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:27:26 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 17:27:26 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 17:27:26 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 17:27:26 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 17:27:26 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 17:27:36 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 17:27:36 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:27:36 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:27:36 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 17:27:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 17:27:46 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:27:51 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
, extraEnvVars=[EnvVar(name=STRIMZI_FEATURE_GATES, value=-UseStrimziPodSets, valueFrom=null, additionalProperties={})]
2022-04-04 17:27:51 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 17:27:51 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 17:27:52 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 17:27:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:27:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 17:27:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 17:27:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 17:27:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 17:27:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 17:27:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 17:27:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 17:27:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 17:27:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 17:27:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:27:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:27:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 17:27:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 17:27:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 17:27:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 17:27:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:27:52 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 17:27:52 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 17:27:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 17:27:52 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 17:27:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 17:27:52 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 17:27:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 17:27:52 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 17:27:52 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:27:52 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 17:27:52 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 17:27:52 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 17:27:52 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 17:27:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 17:27:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 17:27:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:27:52 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 17:28:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 17:28:27 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 17:28:37 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 17:28:37 [main] [32mINFO [m [FeatureGatesIsolatedST:281] Deploying Kafka
2022-04-04 17:28:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-96d26f32 in namespace infra-namespace
2022-04-04 17:28:37 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-96d26f32 will have desired state: Ready
2022-04-04 17:30:00 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-96d26f32 is in desired state: Ready
2022-04-04 17:30:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-167592529-1368979535 in namespace infra-namespace
2022-04-04 17:30:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-167592529-1368979535 will have desired state: Ready
2022-04-04 17:30:01 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-167592529-1368979535 is in desired state: Ready
2022-04-04 17:30:01 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 17:30:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-test-160857859 in namespace infra-namespace
2022-04-04 17:30:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-test-150645684 in namespace infra-namespace
2022-04-04 17:30:01 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-test-160857859 will be in active state
2022-04-04 17:30:01 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-test-150645684 will be in active state
2022-04-04 17:30:01 [main] [32mINFO [m [FeatureGatesIsolatedST:304] Changing FG env variable to enable SPS
2022-04-04 17:30:01 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment strimzi-cluster-operator rolling update
2022-04-04 17:30:06 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 17:30:30 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 17:30:40 [main] [32mINFO [m [DeploymentUtils:141] Deployment strimzi-cluster-operator rolling update finished
2022-04-04 17:30:40 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-96d26f32-zookeeper rolling update
2022-04-04 17:31:05 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-96d26f32-zookeeper has been successfully rolled
2022-04-04 17:31:05 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-96d26f32-zookeeper to be ready
2022-04-04 17:31:34 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-96d26f32 will have desired state: Ready
2022-04-04 17:31:34 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-96d26f32 is in desired state: Ready
2022-04-04 17:31:34 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-96d26f32 is ready
2022-04-04 17:31:34 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-96d26f32-kafka rolling update
2022-04-04 17:32:44 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-96d26f32-kafka has been successfully rolled
2022-04-04 17:32:44 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-96d26f32-kafka to be ready
2022-04-04 17:33:17 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-96d26f32 will have desired state: Ready
2022-04-04 17:33:17 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-96d26f32 is in desired state: Ready
2022-04-04 17:33:17 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-96d26f32 is ready
2022-04-04 17:33:17 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-96d26f32 will have desired state: Ready
2022-04-04 17:33:17 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-96d26f32 is in desired state: Ready
2022-04-04 17:33:17 [main] [32mINFO [m [FeatureGatesIsolatedST:319] Changing FG env variable to disable again SPS
2022-04-04 17:33:17 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment strimzi-cluster-operator rolling update
2022-04-04 17:33:27 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 17:33:52 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 17:34:02 [main] [32mINFO [m [DeploymentUtils:141] Deployment strimzi-cluster-operator rolling update finished
2022-04-04 17:34:02 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-96d26f32-zookeeper rolling update
2022-04-04 17:34:32 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-96d26f32-zookeeper has been successfully rolled
2022-04-04 17:34:32 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-96d26f32-zookeeper to be ready
2022-04-04 17:34:59 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-96d26f32 will have desired state: Ready
2022-04-04 17:34:59 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-96d26f32 is in desired state: Ready
2022-04-04 17:34:59 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-96d26f32 is ready
2022-04-04 17:34:59 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-96d26f32-kafka rolling update
2022-04-04 17:36:09 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-96d26f32-kafka has been successfully rolled
2022-04-04 17:36:09 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-96d26f32-kafka to be ready
2022-04-04 17:36:36 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-96d26f32 will have desired state: Ready
2022-04-04 17:36:36 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-96d26f32 is in desired state: Ready
2022-04-04 17:36:36 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-96d26f32 is ready
2022-04-04 17:36:36 [main] [32mINFO [m [ClientUtils:61] Waiting till producer producer-test-160857859 and consumer consumer-test-150645684 finish
2022-04-04 17:39:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:39:03 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSwitchingStrimziPodSetFeatureGateOnAndOff
2022-04-04 17:39:03 [main] [32mINFO [m [ResourceManager:241] Delete of Job producer-test-160857859 in namespace infra-namespace
2022-04-04 17:39:03 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job consumer-test-150645684 in namespace infra-namespace
2022-04-04 17:39:03 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-96d26f32 in namespace infra-namespace
2022-04-04 17:39:03 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-167592529-1368979535 in namespace infra-namespace
2022-04-04 17:39:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:39:13 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.FeatureGatesIsolatedST.testSwitchingStrimziPodSetFeatureGateOnAndOff-FINISHED
2022-04-04 17:39:13 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 17:39:13 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 17:39:13 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.FeatureGatesIsolatedST.testControlPlaneListenerFeatureGate-STARTED
2022-04-04 17:39:13 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 17:39:13 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 17:39:13 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 17:39:13 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 17:39:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:39:13 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 17:39:13 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:13 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:13 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:13 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 17:39:13 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 17:39:13 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 17:39:13 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 17:39:13 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:13 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:39:13 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 17:39:13 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:13 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:39:13 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:39:13 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 17:39:13 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 17:39:13 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 17:39:13 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 17:39:14 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 17:39:14 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 17:39:14 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:14 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:39:14 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:14 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:14 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:23 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 17:39:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:39:44 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
, extraEnvVars=[EnvVar(name=STRIMZI_FEATURE_GATES, value=-ControlPlaneListener, valueFrom=null, additionalProperties={})]
2022-04-04 17:39:44 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 17:39:44 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 17:39:44 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 17:39:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:39:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 17:39:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 17:39:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 17:39:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 17:39:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 17:39:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 17:39:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:39:45 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 17:39:45 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 17:39:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 17:39:45 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 17:39:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 17:39:45 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 17:39:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 17:39:45 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 17:39:45 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:39:45 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 17:39:45 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 17:39:45 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 17:39:45 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 17:39:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 17:39:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 17:39:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:39:45 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 17:40:24 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 17:40:24 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 17:40:34 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 17:40:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-38006864 in namespace infra-namespace
2022-04-04 17:40:34 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-38006864 will have desired state: Ready
2022-04-04 17:42:27 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-38006864 is in desired state: Ready
2022-04-04 17:42:27 [main] [32mINFO [m [FeatureGatesIsolatedST:96] Check for presence of ContainerPort 9090/tcp (tcp-ctrlplane) in first Kafka pod.
2022-04-04 17:42:27 [main] [32mINFO [m [FeatureGatesIsolatedST:104] Try to send some messages to Kafka over next few minutes.
2022-04-04 17:42:27 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-266290461-1693288555 in namespace infra-namespace
2022-04-04 17:42:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-266290461-1693288555 will have desired state: Ready
2022-04-04 17:42:29 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-266290461-1693288555 is in desired state: Ready
2022-04-04 17:42:29 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 17:42:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-test-1440395329 in namespace infra-namespace
2022-04-04 17:42:29 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-test-1440395329 will be in active state
2022-04-04 17:42:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-test-1010691752 in namespace infra-namespace
2022-04-04 17:42:30 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-test-1010691752 will be in active state
2022-04-04 17:42:31 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-test-1010691752 will be in active state
2022-04-04 17:42:31 [main] [32mINFO [m [FeatureGatesIsolatedST:127] Delete first found Kafka broker pod.
2022-04-04 17:42:31 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-38006864-zookeeper to be ready
2022-04-04 17:42:41 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-38006864 will have desired state: Ready
2022-04-04 17:42:41 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-38006864 is in desired state: Ready
2022-04-04 17:42:41 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-38006864 is ready
2022-04-04 17:42:41 [main] [32mINFO [m [FeatureGatesIsolatedST:131] Force Rolling Update of Kafka via annotation.
2022-04-04 17:42:41 [main] [32mINFO [m [FeatureGatesIsolatedST:139] Wait for next reconciliation to happen.
2022-04-04 17:42:41 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-38006864-zookeeper rolling update
2022-04-04 17:44:16 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-38006864-zookeeper has been successfully rolled
2022-04-04 17:44:16 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-38006864-zookeeper to be ready
2022-04-04 17:44:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-38006864 will have desired state: Ready
2022-04-04 17:44:44 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-38006864 is in desired state: Ready
2022-04-04 17:44:44 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-38006864 is ready
2022-04-04 17:44:44 [main] [32mINFO [m [FeatureGatesIsolatedST:142] Waiting for clients to finish sending/receiving messages.
2022-04-04 17:44:44 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:producer-test-1440395329 to finished
2022-04-04 17:45:29 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:consumer-test-1010691752 to finished
2022-04-04 17:45:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:45:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testControlPlaneListenerFeatureGate
2022-04-04 17:45:34 [main] [32mINFO [m [ResourceManager:241] Delete of Job producer-test-1440395329 in namespace infra-namespace
2022-04-04 17:45:34 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job consumer-test-1010691752 in namespace infra-namespace
2022-04-04 17:45:34 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-266290461-1693288555 in namespace infra-namespace
2022-04-04 17:45:34 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-38006864 in namespace infra-namespace
2022-04-04 17:45:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:45:44 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.FeatureGatesIsolatedST.testControlPlaneListenerFeatureGate-FINISHED
2022-04-04 17:45:44 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 17:45:44 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 17:45:44 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.FeatureGatesIsolatedST.testStrimziPodSetsFeatureGate-STARTED
2022-04-04 17:45:44 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 17:45:44 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 17:45:44 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 17:45:44 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 17:45:44 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:45:44 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 17:45:44 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 17:45:44 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 17:45:44 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 17:45:44 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 17:45:44 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 17:45:44 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 17:45:44 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 17:45:44 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 17:45:44 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 17:45:44 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 17:45:44 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:45:44 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:45:44 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 17:45:44 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 17:45:44 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:45:44 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:45:44 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 17:45:44 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:45:44 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 17:45:44 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 17:45:44 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 17:45:44 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 17:45:54 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 17:45:54 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 17:45:54 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:46:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:46:15 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
, extraEnvVars=[EnvVar(name=STRIMZI_FEATURE_GATES, value=+UseStrimziPodSets, valueFrom=null, additionalProperties={})]
2022-04-04 17:46:15 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 17:46:15 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 17:46:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 17:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 17:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 17:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 17:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 17:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 17:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 17:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 17:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 17:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 17:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 17:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 17:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 17:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 17:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:46:15 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 17:46:15 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 17:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 17:46:15 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 17:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 17:46:15 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 17:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 17:46:15 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 17:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:46:15 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 17:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 17:46:15 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 17:46:15 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 17:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 17:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 17:46:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:46:16 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 17:46:39 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 17:46:39 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 17:46:49 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 17:46:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a4f4123c in namespace infra-namespace
2022-04-04 17:46:49 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a4f4123c will have desired state: Ready
2022-04-04 17:48:56 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a4f4123c is in desired state: Ready
2022-04-04 17:48:56 [main] [32mINFO [m [FeatureGatesIsolatedST:182] Try to send some messages to Kafka over next few minutes.
2022-04-04 17:48:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-478192088-1029903874 in namespace infra-namespace
2022-04-04 17:48:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-478192088-1029903874 will have desired state: Ready
2022-04-04 17:48:57 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-478192088-1029903874 is in desired state: Ready
2022-04-04 17:48:57 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 17:48:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-test-1466744156 in namespace infra-namespace
2022-04-04 17:48:57 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-test-1466744156 will be in active state
2022-04-04 17:48:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-test-818953866 in namespace infra-namespace
2022-04-04 17:48:58 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-test-818953866 will be in active state
2022-04-04 17:48:59 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-test-818953866 will be in active state
2022-04-04 17:48:59 [main] [32mINFO [m [FeatureGatesIsolatedST:207] Delete first found ZooKeeper pod my-cluster-a4f4123c-zookeeper-0
2022-04-04 17:48:59 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-a4f4123c-zookeeper to be ready
2022-04-04 17:49:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a4f4123c will have desired state: Ready
2022-04-04 17:49:32 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a4f4123c is in desired state: Ready
2022-04-04 17:49:32 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-a4f4123c is ready
2022-04-04 17:49:32 [main] [32mINFO [m [FeatureGatesIsolatedST:213] Delete first found Kafka broker pod my-cluster-a4f4123c-kafka-0
2022-04-04 17:49:32 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-a4f4123c-kafka to be ready
2022-04-04 17:50:12 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a4f4123c will have desired state: Ready
2022-04-04 17:50:12 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a4f4123c is in desired state: Ready
2022-04-04 17:50:12 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-a4f4123c is ready
2022-04-04 17:50:12 [main] [32mINFO [m [FeatureGatesIsolatedST:218] Force Rolling Update of ZooKeeper via annotation.
2022-04-04 17:50:12 [main] [32mINFO [m [FeatureGatesIsolatedST:228] Wait for next reconciliation to happen.
2022-04-04 17:50:12 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-a4f4123c-zookeeper rolling update
2022-04-04 17:51:18 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-a4f4123c-zookeeper has been successfully rolled
2022-04-04 17:51:18 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-a4f4123c-zookeeper to be ready
2022-04-04 17:51:52 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a4f4123c will have desired state: Ready
2022-04-04 17:51:52 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a4f4123c is in desired state: Ready
2022-04-04 17:51:52 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-a4f4123c is ready
2022-04-04 17:51:52 [main] [32mINFO [m [FeatureGatesIsolatedST:232] Force Rolling Update of Kafka via annotation.
2022-04-04 17:51:52 [main] [32mINFO [m [FeatureGatesIsolatedST:242] Wait for next reconciliation to happen.
2022-04-04 17:51:52 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-a4f4123c-kafka rolling update
2022-04-04 17:53:07 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-a4f4123c-kafka has been successfully rolled
2022-04-04 17:53:07 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-a4f4123c-kafka to be ready
2022-04-04 17:53:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a4f4123c will have desired state: Ready
2022-04-04 17:53:39 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a4f4123c is in desired state: Ready
2022-04-04 17:53:39 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-a4f4123c is ready
2022-04-04 17:53:39 [main] [32mINFO [m [FeatureGatesIsolatedST:245] Waiting for clients to finish sending/receiving messages.
2022-04-04 17:53:39 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:producer-test-1466744156 to finished
2022-04-04 17:54:14 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:consumer-test-818953866 to finished
2022-04-04 17:54:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:54:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testStrimziPodSetsFeatureGate
2022-04-04 17:54:19 [main] [32mINFO [m [ResourceManager:241] Delete of Job producer-test-1466744156 in namespace infra-namespace
2022-04-04 17:54:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job consumer-test-818953866 in namespace infra-namespace
2022-04-04 17:54:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-478192088-1029903874 in namespace infra-namespace
2022-04-04 17:54:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a4f4123c in namespace infra-namespace
2022-04-04 17:54:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:54:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.FeatureGatesIsolatedST.testStrimziPodSetsFeatureGate-FINISHED
2022-04-04 17:54:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 17:54:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:54:29 [main] [32mINFO [m [ResourceManager:346] In context FeatureGatesIsolatedST is everything deleted.
2022-04-04 17:54:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,647.992 s - in io.strimzi.systemtest.operators.FeatureGatesIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.NamespaceRbacScopeOperatorIsolatedST
2022-04-04 17:54:29 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 17:54:54 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 17:54:54 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.NamespaceRbacScopeOperatorIsolatedST.testNamespacedRbacScopeDeploysRoles-STARTED
2022-04-04 17:54:54 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 17:54:54 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 17:54:54 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 17:54:54 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 17:54:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:54:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 17:54:54 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 17:54:54 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 17:54:54 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 17:54:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 17:54:54 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:54:54 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 17:54:54 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 17:54:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 17:54:54 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:54:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 17:54:54 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 17:54:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 17:54:54 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:54:54 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 17:54:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 17:54:54 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 17:54:54 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 17:54:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 17:54:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:54:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 17:55:04 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 17:55:04 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:55:04 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:55:04 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 17:55:04 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 17:55:14 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:55:20 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
, extraEnvVars=[EnvVar(name=STRIMZI_RBAC_SCOPE, value=NAMESPACE, valueFrom=null, additionalProperties={})]
2022-04-04 17:55:20 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 17:55:20 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 17:55:20 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 17:55:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:55:20 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-04 17:55:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-04 17:55:20 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-04 17:55:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-04 17:55:20 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRole-strimzi-kafka-broker.yaml
2022-04-04 17:55:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-broker in namespace infra-namespace
2022-04-04 17:55:20 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-ClusterRole-strimzi-entity-operator.yaml
2022-04-04 17:55:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-entity-operator in namespace infra-namespace
2022-04-04 17:55:20 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRole-strimzi-kafka-client.yaml
2022-04-04 17:55:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-client in namespace infra-namespace
2022-04-04 17:55:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 17:55:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 17:55:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 17:55:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 17:55:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:55:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:55:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 17:55:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 17:55:21 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 17:55:21 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 17:55:21 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:55:21 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 17:55:21 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 17:55:21 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 17:55:21 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 17:55:21 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 17:55:21 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 17:55:21 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 17:55:21 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml
2022-04-04 17:55:21 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/020-Role-strimzi-cluster-operator1643293443017685908.yaml in namespace infra-namespace
2022-04-04 17:55:21 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:55:21 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml
2022-04-04 17:55:21 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/031-Role-strimzi-cluster-operator-entity-operator-delegation18004033929961555672.yaml in namespace infra-namespace
2022-04-04 17:55:21 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 17:55:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:55:21 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 17:55:45 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 17:55:45 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 17:55:55 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 17:55:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2eee0f6e in namespace infra-namespace
2022-04-04 17:55:55 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2eee0f6e will have desired state: Ready
2022-04-04 17:57:15 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2eee0f6e is in desired state: Ready
2022-04-04 17:57:15 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2eee0f6e will have desired state: Ready
2022-04-04 17:57:15 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2eee0f6e is in desired state: Ready
2022-04-04 17:57:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:57:15 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testNamespacedRbacScopeDeploysRoles
2022-04-04 17:57:15 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2eee0f6e in namespace infra-namespace
2022-04-04 17:57:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:57:25 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.NamespaceRbacScopeOperatorIsolatedST.testNamespacedRbacScopeDeploysRoles-FINISHED
2022-04-04 17:57:25 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 17:57:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:57:25 [main] [32mINFO [m [ResourceManager:346] In context NamespaceRbacScopeOperatorIsolatedST is everything deleted.
2022-04-04 17:57:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 175.86 s - in io.strimzi.systemtest.operators.NamespaceRbacScopeOperatorIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.RecoveryIsolatedST
2022-04-04 17:57:25 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 17:57:50 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 17:57:50 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperMetricsConfigDeletion-STARTED
2022-04-04 17:57:50 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 17:57:50 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 17:57:50 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 17:57:50 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 17:57:50 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:57:50 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 17:57:50 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 17:57:50 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:57:50 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 17:57:50 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 17:57:50 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:57:50 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 17:57:50 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 17:57:50 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 17:57:50 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:57:50 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 17:57:50 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:57:50 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 17:57:50 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-04 17:57:50 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-04 17:57:50 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-entity-operator in namespace infra-namespace
2022-04-04 17:57:50 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:57:50 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-broker in namespace infra-namespace
2022-04-04 17:57:50 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 17:57:50 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-client in namespace infra-namespace
2022-04-04 17:57:50 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 17:58:00 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 17:58:00 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 17:58:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:58:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:58:15 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 17:58:15 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 17:58:15 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 17:58:16 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 17:58:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:58:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 17:58:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 17:58:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 17:58:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 17:58:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 17:58:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 17:58:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 17:58:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 17:58:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 17:58:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:58:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:58:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 17:58:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 17:58:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 17:58:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 17:58:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:58:16 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 17:58:16 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 17:58:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 17:58:16 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 17:58:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 17:58:16 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 17:58:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 17:58:16 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 17:58:16 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:58:16 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 17:58:16 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 17:58:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:58:16 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 17:58:55 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 17:58:55 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 17:59:05 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 17:59:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-727134126 in namespace infra-namespace
2022-04-04 17:59:05 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-727134126 will have desired state: Ready
2022-04-04 18:00:25 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-727134126 is in desired state: Ready
2022-04-04 18:00:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-727134126 in namespace infra-namespace
2022-04-04 18:00:25 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-727134126 will be ready
2022-04-04 18:00:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-727134126 is ready
2022-04-04 18:00:27 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-727134126 in namespace infra-namespace
2022-04-04 18:00:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-727134126 will have desired state: Ready
2022-04-04 18:00:45 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-727134126 is in desired state: Ready
2022-04-04 18:00:45 [main] [32mINFO [m [RecoveryIsolatedST:191] Running deleteZookeeperMetricsConfig with cluster recovery-cluster-727134126
2022-04-04 18:00:45 [main] [32mINFO [m [RecoveryIsolatedST:199] Waiting for creation recovery-cluster-727134126-zookeeper-config
2022-04-04 18:00:45 [main] [32mINFO [m [ConfigMapUtils:30] Waiting for config map recovery-cluster-727134126-zookeeper-config-fb2e5647-0147-49b9-b00e-37bc4e9f94ad recovery in namespace infra-namespace
2022-04-04 18:00:54 [main] [32mINFO [m [ConfigMapUtils:33] Config map recovery-cluster-727134126-zookeeper-config was recovered
2022-04-04 18:00:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:00:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromZookeeperMetricsConfigDeletion
2022-04-04 18:00:54 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-727134126 in namespace infra-namespace
2022-04-04 18:00:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-727134126 in namespace infra-namespace
2022-04-04 18:00:54 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-727134126 in namespace infra-namespace
2022-04-04 18:01:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:01:44 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperMetricsConfigDeletion-FINISHED
2022-04-04 18:01:44 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 18:01:44 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 18:01:44 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaBridgeServiceDeletion-STARTED
2022-04-04 18:01:44 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 18:01:44 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 18:01:44 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 18:01:44 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 18:01:44 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:01:44 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 18:01:44 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:01:44 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:01:44 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:01:44 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:01:44 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:01:44 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:01:44 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:01:44 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:01:44 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:01:44 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:01:44 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:01:44 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:01:44 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:01:44 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:01:44 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:01:44 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:01:44 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:01:44 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:01:44 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:01:54 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:01:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:01:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:01:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:02:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:02:09 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 18:02:09 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 18:02:09 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 18:02:09 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 18:02:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:02:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:02:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:02:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:02:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:02:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:02:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:02:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:02:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:02:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:02:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:02:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:02:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:02:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:02:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:02:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:02:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:02:10 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 18:02:10 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:02:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:02:10 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 18:02:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:02:10 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 18:02:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:02:10 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:02:10 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:02:10 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 18:02:10 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:02:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:02:10 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 18:02:23 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 18:02:23 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 18:02:33 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 18:02:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-890599309 in namespace infra-namespace
2022-04-04 18:02:33 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-890599309 will have desired state: Ready
2022-04-04 18:04:54 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-890599309 is in desired state: Ready
2022-04-04 18:04:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-890599309 in namespace infra-namespace
2022-04-04 18:04:54 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-890599309 will be ready
2022-04-04 18:04:56 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-890599309 is ready
2022-04-04 18:04:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-890599309 in namespace infra-namespace
2022-04-04 18:04:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-890599309 will have desired state: Ready
2022-04-04 18:05:15 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-890599309 is in desired state: Ready
2022-04-04 18:05:15 [main] [32mINFO [m [RecoveryIsolatedST:222] Running deleteKafkaBridgeService with cluster recovery-cluster-890599309
2022-04-04 18:05:15 [main] [32mINFO [m [RecoveryIsolatedST:227] Waiting for service recovery-cluster-890599309-bridge-service recovery
2022-04-04 18:05:15 [main] [32mINFO [m [ServiceUtils:58] Waiting when Service recovery-cluster-890599309-bridge-service-09639ba6-df38-4083-b336-2b781273c0da in namespace infra-namespace will be recovered
2022-04-04 18:05:47 [main] [32mINFO [m [ServiceUtils:62] recovery-cluster-890599309-bridge-service in namespace infra-namespace is recovered
2022-04-04 18:05:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:05:47 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaBridgeServiceDeletion
2022-04-04 18:05:47 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-890599309 in namespace infra-namespace
2022-04-04 18:05:47 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-890599309 in namespace infra-namespace
2022-04-04 18:05:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-890599309 in namespace infra-namespace
2022-04-04 18:06:37 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:06:37 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaBridgeServiceDeletion-FINISHED
2022-04-04 18:06:37 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 18:06:37 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 18:06:37 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaHeadlessServiceDeletion-STARTED
2022-04-04 18:06:37 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 18:06:37 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 18:06:37 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 18:06:37 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 18:06:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:06:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 18:06:37 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:06:37 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:06:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:06:37 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:06:37 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:06:37 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:06:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:06:37 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:06:37 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:06:37 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:06:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:06:37 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:06:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:06:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:06:37 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:06:47 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:06:47 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:06:47 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:06:47 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:06:47 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:06:47 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:06:47 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:06:47 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:06:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:07:02 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 18:07:02 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 18:07:02 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 18:07:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 18:07:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:07:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:07:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:07:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:07:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:07:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:07:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:07:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:07:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:07:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:07:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:07:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:07:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:07:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:07:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:07:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:07:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:07:03 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 18:07:03 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:07:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:07:03 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 18:07:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:07:03 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 18:07:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:07:03 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:07:03 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:07:03 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 18:07:03 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:07:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:07:03 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 18:07:34 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 18:07:34 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 18:07:44 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 18:07:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-466592418 in namespace infra-namespace
2022-04-04 18:07:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-466592418 will have desired state: Ready
2022-04-04 18:09:09 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-466592418 is in desired state: Ready
2022-04-04 18:09:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-466592418 in namespace infra-namespace
2022-04-04 18:09:09 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-466592418 will be ready
2022-04-04 18:09:11 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-466592418 is ready
2022-04-04 18:09:11 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-466592418 in namespace infra-namespace
2022-04-04 18:09:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-466592418 will have desired state: Ready
2022-04-04 18:09:30 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-466592418 is in desired state: Ready
2022-04-04 18:09:30 [main] [32mINFO [m [RecoveryIsolatedST:143] Running deleteKafkaHeadlessService with cluster recovery-cluster-466592418
2022-04-04 18:09:30 [main] [32mINFO [m [RecoveryIsolatedST:150] Waiting for creation recovery-cluster-466592418-kafka-brokers
2022-04-04 18:09:30 [main] [32mINFO [m [ServiceUtils:58] Waiting when Service recovery-cluster-466592418-kafka-brokers-67b0361a-18ab-478f-be69-a3f39699ace8 in namespace infra-namespace will be recovered
2022-04-04 18:09:41 [main] [32mINFO [m [ServiceUtils:62] recovery-cluster-466592418-kafka-brokers in namespace infra-namespace is recovered
2022-04-04 18:09:41 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:09:41 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaHeadlessServiceDeletion
2022-04-04 18:09:41 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-466592418 in namespace infra-namespace
2022-04-04 18:09:41 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-466592418 in namespace infra-namespace
2022-04-04 18:09:41 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-466592418 in namespace infra-namespace
2022-04-04 18:10:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:10:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaHeadlessServiceDeletion-FINISHED
2022-04-04 18:10:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 18:10:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 18:10:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaStatefulSetDeletion-STARTED
2022-04-04 18:10:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 18:10:22 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 18:10:22 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 18:10:22 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 18:10:22 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:10:22 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 18:10:22 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:10:22 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:10:22 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:10:22 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:10:22 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:10:22 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:10:22 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:10:22 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:10:22 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:10:22 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:10:22 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:10:22 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:10:22 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:10:22 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:10:22 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:10:22 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:10:32 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:10:32 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:10:32 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:10:32 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:10:32 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:10:32 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:10:32 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:10:42 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:10:47 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 18:10:47 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 18:10:47 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 18:10:47 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 18:10:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:10:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:10:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:10:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:10:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:10:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:10:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:10:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:10:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:10:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:10:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:10:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:10:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:10:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:10:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:10:48 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:10:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:10:48 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 18:10:48 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:10:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:10:48 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 18:10:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:10:48 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 18:10:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:10:48 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:10:48 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:10:48 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 18:10:48 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:10:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:10:48 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 18:11:21 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 18:11:21 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 18:11:31 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 18:11:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-527162591 in namespace infra-namespace
2022-04-04 18:11:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-527162591 will have desired state: Ready
2022-04-04 18:12:50 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-527162591 is in desired state: Ready
2022-04-04 18:12:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-527162591 in namespace infra-namespace
2022-04-04 18:12:50 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-527162591 will be ready
2022-04-04 18:12:52 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-527162591 is ready
2022-04-04 18:12:52 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-527162591 in namespace infra-namespace
2022-04-04 18:12:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-527162591 will have desired state: Ready
2022-04-04 18:13:16 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-527162591 is in desired state: Ready
2022-04-04 18:13:16 [main] [32mINFO [m [PodUtils:121] Waiting when all Pods with prefix recovery-cluster-527162591-kafka will be deleted
2022-04-04 18:13:16 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-527162591-kafka-0 will be deleted
2022-04-04 18:13:36 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-527162591-kafka-0 deleted
2022-04-04 18:13:36 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-527162591-kafka-1 will be deleted
2022-04-04 18:13:36 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-527162591-kafka-1 deleted
2022-04-04 18:13:36 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-527162591-kafka-2 will be deleted
2022-04-04 18:13:36 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-527162591-kafka-2 deleted
2022-04-04 18:13:36 [main] [32mINFO [m [RecoveryIsolatedST:90] Waiting for recovery recovery-cluster-527162591-kafka
2022-04-04 18:13:36 [main] [32mINFO [m [StatefulSetUtils:73] Waiting for StatefulSet recovery-cluster-527162591-kafka-f5a34467-305a-4110-9fa0-825cb66ce5ea recovery in namespace infra-namespace
2022-04-04 18:13:48 [main] [32mINFO [m [StatefulSetUtils:76] StatefulSet recovery-cluster-527162591-kafka was recovered
2022-04-04 18:13:48 [main] [32mINFO [m [StatefulSetUtils:39] Waiting for StatefulSet recovery-cluster-527162591-kafka to be ready
2022-04-04 18:14:11 [main] [32mINFO [m [StatefulSetUtils:44] Waiting for 3 Pod(s) of StatefulSet recovery-cluster-527162591-kafka to be ready
2022-04-04 18:14:21 [main] [32mINFO [m [StatefulSetUtils:47] StatefulSet recovery-cluster-527162591-kafka is ready
2022-04-04 18:14:21 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:14:21 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaStatefulSetDeletion
2022-04-04 18:14:21 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-527162591 in namespace infra-namespace
2022-04-04 18:14:21 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-527162591 in namespace infra-namespace
2022-04-04 18:14:21 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-527162591 in namespace infra-namespace
2022-04-04 18:15:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:15:11 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaStatefulSetDeletion-FINISHED
2022-04-04 18:15:11 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 18:15:11 [main] [32mINFO [m [StrimziPodSetTestCondition:23] According to STRIMZI_FEATURE_GATES env variable with value: , the StatefulSets are used, skipping this StrimziPodSet related test
2022-04-04 18:15:11 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 18:15:11 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromEntityOperatorDeletion-STARTED
2022-04-04 18:15:11 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 18:15:11 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 18:15:11 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 18:15:11 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 18:15:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:15:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 18:15:11 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:15:11 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:15:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:15:11 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:15:11 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:15:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:15:11 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:15:11 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:15:11 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:15:11 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:15:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:15:11 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:15:11 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:15:11 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:15:11 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:15:11 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:15:11 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:15:11 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:15:11 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:15:21 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:15:21 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:15:21 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:15:21 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:15:31 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:15:36 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 18:15:36 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 18:15:36 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 18:15:36 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 18:15:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:15:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:15:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:15:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:15:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:15:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:15:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:15:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:15:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:15:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:15:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:15:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:15:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:15:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:15:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:15:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:15:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:15:37 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 18:15:37 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:15:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:15:37 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 18:15:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:15:37 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 18:15:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:15:37 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:15:37 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:15:37 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 18:15:37 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:15:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:15:37 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 18:16:03 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 18:16:03 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 18:16:13 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 18:16:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-740658368 in namespace infra-namespace
2022-04-04 18:16:13 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-740658368 will have desired state: Ready
2022-04-04 18:17:38 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-740658368 is in desired state: Ready
2022-04-04 18:17:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-740658368 in namespace infra-namespace
2022-04-04 18:17:38 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-740658368 will be ready
2022-04-04 18:17:40 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-740658368 is ready
2022-04-04 18:17:40 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-740658368 in namespace infra-namespace
2022-04-04 18:17:40 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-740658368 will have desired state: Ready
2022-04-04 18:17:58 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-740658368 is in desired state: Ready
2022-04-04 18:17:58 [main] [32mINFO [m [RecoveryIsolatedST:64] Running testRecoveryFromEntityOperatorDeletion with cluster recovery-cluster-740658368
2022-04-04 18:17:58 [main] [32mINFO [m [PodUtils:121] Waiting when all Pods with prefix recovery-cluster-740658368-entity-operator will be deleted
2022-04-04 18:17:58 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-740658368-entity-operator-849774ddcf-x7ghd will be deleted
2022-04-04 18:18:08 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-740658368-entity-operator-849774ddcf-x7ghd deleted
2022-04-04 18:18:08 [main] [32mINFO [m [RecoveryIsolatedST:72] Waiting for recovery recovery-cluster-740658368-entity-operator
2022-04-04 18:18:08 [main] [32mINFO [m [DeploymentUtils:154] Waiting for Deployment recovery-cluster-740658368-entity-operator-fa886ec4-c110-4bde-afa1-0af235f62017 recovery in namespace infra-namespace
2022-04-04 18:18:16 [main] [32mINFO [m [DeploymentUtils:157] Deployment recovery-cluster-740658368-entity-operator was recovered
2022-04-04 18:18:16 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: recovery-cluster-740658368-entity-operator will be ready
2022-04-04 18:18:49 [main] [32mINFO [m [DeploymentUtils:168] Deployment: recovery-cluster-740658368-entity-operator is ready
2022-04-04 18:18:49 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment recovery-cluster-740658368-entity-operator to be ready
2022-04-04 18:18:59 [main] [32mINFO [m [DeploymentUtils:197] Deployment recovery-cluster-740658368-entity-operator is ready
2022-04-04 18:18:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:18:59 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromEntityOperatorDeletion
2022-04-04 18:18:59 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-740658368 in namespace infra-namespace
2022-04-04 18:18:59 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-740658368 in namespace infra-namespace
2022-04-04 18:18:59 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-740658368 in namespace infra-namespace
2022-04-04 18:19:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:19:49 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromEntityOperatorDeletion-FINISHED
2022-04-04 18:19:49 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 18:19:49 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 18:19:49 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaBridgeDeploymentDeletion-STARTED
2022-04-04 18:19:49 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 18:19:49 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 18:19:49 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 18:19:49 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 18:19:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:19:49 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 18:19:49 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:19:49 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:19:49 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:19:49 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:19:49 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:19:49 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:19:49 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:19:49 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:19:49 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:19:49 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:19:49 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:19:49 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:19:49 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:19:49 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:19:49 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:19:49 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:19:59 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:19:59 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:19:59 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:19:59 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:19:59 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:19:59 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:19:59 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:19:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:20:04 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 18:20:04 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 18:20:04 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 18:20:05 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 18:20:05 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:20:05 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:20:05 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:20:05 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:20:05 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:20:05 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:20:05 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:20:05 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:20:05 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:20:05 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:20:05 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:20:05 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:20:05 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:20:05 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:20:05 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:20:05 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:20:05 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:20:05 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 18:20:05 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:20:05 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:20:05 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 18:20:05 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:20:05 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 18:20:05 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:20:05 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:20:05 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:20:05 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 18:20:05 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:20:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:20:05 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 18:20:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 18:20:27 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 18:20:37 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 18:20:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-279709205 in namespace infra-namespace
2022-04-04 18:20:37 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-279709205 will have desired state: Ready
2022-04-04 18:22:04 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-279709205 is in desired state: Ready
2022-04-04 18:22:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-279709205 in namespace infra-namespace
2022-04-04 18:22:04 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-279709205 will be ready
2022-04-04 18:22:06 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-279709205 is ready
2022-04-04 18:22:06 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-279709205 in namespace infra-namespace
2022-04-04 18:22:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-279709205 will have desired state: Ready
2022-04-04 18:22:33 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-279709205 is in desired state: Ready
2022-04-04 18:22:33 [main] [32mINFO [m [RecoveryIsolatedST:206] Running deleteKafkaBridgeDeployment with cluster recovery-cluster-279709205
2022-04-04 18:22:33 [main] [32mINFO [m [PodUtils:121] Waiting when all Pods with prefix recovery-cluster-279709205-bridge will be deleted
2022-04-04 18:22:33 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-279709205-bridge-6dbf6c8685-vl9wx will be deleted
2022-04-04 18:22:48 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-279709205-bridge-6dbf6c8685-vl9wx deleted
2022-04-04 18:22:48 [main] [32mINFO [m [RecoveryIsolatedST:215] Waiting for deployment recovery-cluster-279709205-bridge recovery
2022-04-04 18:22:48 [main] [32mINFO [m [DeploymentUtils:154] Waiting for Deployment recovery-cluster-279709205-bridge-751f7ceb-009f-4215-9b9e-e9ef177e613f recovery in namespace infra-namespace
2022-04-04 18:27:43 [main] [32mINFO [m [DeploymentUtils:157] Deployment recovery-cluster-279709205-bridge was recovered
2022-04-04 18:27:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:27:43 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaBridgeDeploymentDeletion
2022-04-04 18:27:43 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-279709205 in namespace infra-namespace
2022-04-04 18:27:43 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-279709205 in namespace infra-namespace
2022-04-04 18:27:43 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-279709205 in namespace infra-namespace
2022-04-04 18:28:33 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:28:33 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaBridgeDeploymentDeletion-FINISHED
2022-04-04 18:28:33 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 18:28:33 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 18:28:33 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaServiceDeletion-STARTED
2022-04-04 18:28:33 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 18:28:33 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 18:28:33 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 18:28:33 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 18:28:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:28:33 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 18:28:33 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:28:33 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:28:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:28:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:28:33 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:28:33 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:28:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:28:33 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:28:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:28:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:28:33 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:28:33 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:28:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:28:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:28:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:28:33 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:28:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:28:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:28:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:28:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:28:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:28:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:28:43 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:28:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:28:58 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 18:28:58 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 18:28:58 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 18:28:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 18:28:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:28:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:28:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:28:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:28:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:28:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:28:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:28:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:28:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:28:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:28:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:28:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:28:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:28:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:28:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:28:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:28:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:28:59 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 18:28:59 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:28:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:28:59 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 18:28:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:28:59 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 18:28:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:28:59 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:28:59 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:28:59 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 18:28:59 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:28:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:28:59 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 18:29:30 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 18:29:30 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 18:29:40 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 18:29:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-593470984 in namespace infra-namespace
2022-04-04 18:29:40 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-593470984 will have desired state: Ready
2022-04-04 18:31:00 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-593470984 is in desired state: Ready
2022-04-04 18:31:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-593470984 in namespace infra-namespace
2022-04-04 18:31:00 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-593470984 will be ready
2022-04-04 18:31:02 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-593470984 is ready
2022-04-04 18:31:02 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-593470984 in namespace infra-namespace
2022-04-04 18:31:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-593470984 will have desired state: Ready
2022-04-04 18:31:21 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-593470984 is in desired state: Ready
2022-04-04 18:31:21 [main] [32mINFO [m [RecoveryIsolatedST:115] Running deleteKafkaService with cluster recovery-cluster-593470984
2022-04-04 18:31:21 [main] [32mINFO [m [RecoveryIsolatedST:122] Waiting for creation recovery-cluster-593470984-kafka-bootstrap
2022-04-04 18:31:21 [main] [32mINFO [m [ServiceUtils:58] Waiting when Service recovery-cluster-593470984-kafka-bootstrap-d3c99fed-8bd3-4434-afbe-df435eb6a7d1 in namespace infra-namespace will be recovered
2022-04-04 18:31:38 [main] [32mINFO [m [ServiceUtils:62] recovery-cluster-593470984-kafka-bootstrap in namespace infra-namespace is recovered
2022-04-04 18:31:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:31:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaServiceDeletion
2022-04-04 18:31:38 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-593470984 in namespace infra-namespace
2022-04-04 18:31:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-593470984 in namespace infra-namespace
2022-04-04 18:31:38 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-593470984 in namespace infra-namespace
2022-04-04 18:32:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:32:18 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaServiceDeletion-FINISHED
2022-04-04 18:32:18 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 18:32:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 18:32:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperStatefulSetDeletion-STARTED
2022-04-04 18:32:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 18:32:18 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 18:32:18 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 18:32:18 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 18:32:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:32:18 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 18:32:18 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:32:18 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:32:18 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:32:18 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:32:18 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:32:18 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:32:18 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:32:18 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:32:18 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:32:18 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:32:18 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:32:18 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:32:18 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:32:18 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:32:18 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:32:18 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:32:18 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:32:18 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:32:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:32:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:32:28 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:32:28 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:32:28 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:32:38 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:32:43 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 18:32:43 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 18:32:43 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 18:32:44 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 18:32:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:32:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:32:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:32:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:32:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:32:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:32:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:32:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:32:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:32:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:32:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:32:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:32:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:32:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:32:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:32:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:32:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:32:44 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 18:32:44 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:32:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:32:44 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 18:32:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:32:44 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 18:32:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:32:44 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:32:44 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:32:44 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 18:32:44 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:32:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:32:44 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 18:33:02 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 18:33:02 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 18:33:12 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 18:33:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1348922581 in namespace infra-namespace
2022-04-04 18:33:12 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1348922581 will have desired state: Ready
2022-04-04 18:34:39 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1348922581 is in desired state: Ready
2022-04-04 18:34:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1348922581 in namespace infra-namespace
2022-04-04 18:34:39 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1348922581 will be ready
2022-04-04 18:34:41 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1348922581 is ready
2022-04-04 18:34:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1348922581 in namespace infra-namespace
2022-04-04 18:34:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1348922581 will have desired state: Ready
2022-04-04 18:35:03 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1348922581 is in desired state: Ready
2022-04-04 18:35:03 [main] [32mINFO [m [PodUtils:121] Waiting when all Pods with prefix recovery-cluster-1348922581-zookeeper will be deleted
2022-04-04 18:35:03 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-1348922581-zookeeper-0 will be deleted
2022-04-04 18:35:18 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-1348922581-zookeeper-0 deleted
2022-04-04 18:35:18 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-1348922581-zookeeper-1 will be deleted
2022-04-04 18:35:18 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-1348922581-zookeeper-1 deleted
2022-04-04 18:35:18 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-1348922581-zookeeper-2 will be deleted
2022-04-04 18:35:18 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-1348922581-zookeeper-2 deleted
2022-04-04 18:35:18 [main] [32mINFO [m [RecoveryIsolatedST:107] Waiting for recovery recovery-cluster-1348922581-zookeeper
2022-04-04 18:35:18 [main] [32mINFO [m [StatefulSetUtils:73] Waiting for StatefulSet recovery-cluster-1348922581-zookeeper-e46461e3-e2d2-499a-9aa4-a6cabcc9be0f recovery in namespace infra-namespace
2022-04-04 18:35:27 [main] [32mINFO [m [StatefulSetUtils:76] StatefulSet recovery-cluster-1348922581-zookeeper was recovered
2022-04-04 18:35:27 [main] [32mINFO [m [StatefulSetUtils:39] Waiting for StatefulSet recovery-cluster-1348922581-zookeeper to be ready
2022-04-04 18:36:45 [main] [32mINFO [m [StatefulSetUtils:44] Waiting for 3 Pod(s) of StatefulSet recovery-cluster-1348922581-zookeeper to be ready
2022-04-04 18:36:55 [main] [32mINFO [m [StatefulSetUtils:47] StatefulSet recovery-cluster-1348922581-zookeeper is ready
2022-04-04 18:36:55 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:36:55 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromZookeeperStatefulSetDeletion
2022-04-04 18:36:55 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1348922581 in namespace infra-namespace
2022-04-04 18:36:55 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1348922581 in namespace infra-namespace
2022-04-04 18:36:55 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1348922581 in namespace infra-namespace
2022-04-04 18:37:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:37:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperStatefulSetDeletion-FINISHED
2022-04-04 18:37:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 18:37:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 18:37:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaBridgeMetricsConfigDeletion-STARTED
2022-04-04 18:37:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 18:37:35 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 18:37:35 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 18:37:35 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 18:37:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:37:35 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 18:37:35 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:37:35 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:37:35 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:37:35 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:37:35 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:37:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:37:35 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:37:35 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:37:35 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:37:35 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:37:35 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:37:35 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:37:36 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:37:36 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:37:36 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:37:45 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:37:45 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:37:46 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:37:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:37:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:37:46 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:37:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:37:46 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:37:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:38:01 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 18:38:01 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 18:38:01 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 18:38:01 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 18:38:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:38:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:38:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:38:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:38:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:38:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:38:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:38:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:38:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:38:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:38:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:38:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:38:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:38:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:38:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:38:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:38:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:38:02 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 18:38:02 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:38:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:38:02 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 18:38:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:38:02 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 18:38:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:38:02 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:38:02 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:38:02 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 18:38:02 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:38:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:38:02 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 18:38:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 18:38:27 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 18:38:37 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 18:38:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1660717286 in namespace infra-namespace
2022-04-04 18:38:37 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1660717286 will have desired state: Ready
2022-04-04 18:40:25 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1660717286 is in desired state: Ready
2022-04-04 18:40:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1660717286 in namespace infra-namespace
2022-04-04 18:40:25 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1660717286 will be ready
2022-04-04 18:40:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1660717286 is ready
2022-04-04 18:40:27 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1660717286 in namespace infra-namespace
2022-04-04 18:40:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1660717286 will have desired state: Ready
2022-04-04 18:40:46 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1660717286 is in desired state: Ready
2022-04-04 18:40:46 [main] [32mINFO [m [RecoveryIsolatedST:234] Running deleteKafkaBridgeMetricsConfig with cluster recovery-cluster-1660717286
2022-04-04 18:40:46 [main] [32mINFO [m [RecoveryIsolatedST:239] Waiting for metric config recovery-cluster-1660717286-bridge-config re-creation
2022-04-04 18:40:46 [main] [32mINFO [m [ConfigMapUtils:30] Waiting for config map recovery-cluster-1660717286-bridge-config-fe50c66c-9e35-4867-84ea-8debae2bbf67 recovery in namespace infra-namespace
2022-04-04 18:41:09 [main] [32mINFO [m [ConfigMapUtils:33] Config map recovery-cluster-1660717286-bridge-config was recovered
2022-04-04 18:41:09 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:41:09 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaBridgeMetricsConfigDeletion
2022-04-04 18:41:09 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1660717286 in namespace infra-namespace
2022-04-04 18:41:09 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1660717286 in namespace infra-namespace
2022-04-04 18:41:09 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1660717286 in namespace infra-namespace
2022-04-04 18:41:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:41:49 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaBridgeMetricsConfigDeletion-FINISHED
2022-04-04 18:41:49 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 18:41:49 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 18:41:49 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperHeadlessServiceDeletion-STARTED
2022-04-04 18:41:49 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 18:41:49 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 18:41:49 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 18:41:49 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 18:41:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:41:49 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 18:41:49 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:41:49 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:41:49 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:41:49 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:41:49 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:41:49 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:41:49 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:41:49 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:41:49 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:41:49 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:41:50 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:41:50 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:41:50 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:41:50 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:41:50 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:42:00 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:42:00 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:42:00 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:42:00 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:42:00 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:42:00 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:42:00 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:42:00 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:42:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:42:20 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 18:42:20 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 18:42:20 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 18:42:20 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 18:42:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:42:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:42:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:42:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:42:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:42:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:42:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:42:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:42:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:42:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:42:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:42:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:42:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:42:21 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:42:21 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:42:21 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:42:21 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:42:21 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 18:42:21 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:42:21 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:42:21 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 18:42:21 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:42:21 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 18:42:21 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:42:21 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:42:21 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:42:21 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 18:42:21 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:42:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:42:21 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 18:42:35 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 18:42:35 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 18:42:45 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 18:42:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1316401285 in namespace infra-namespace
2022-04-04 18:42:45 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1316401285 will have desired state: Ready
2022-04-04 18:44:07 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1316401285 is in desired state: Ready
2022-04-04 18:44:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1316401285 in namespace infra-namespace
2022-04-04 18:44:07 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1316401285 will be ready
2022-04-04 18:44:09 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1316401285 is ready
2022-04-04 18:44:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1316401285 in namespace infra-namespace
2022-04-04 18:44:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1316401285 will have desired state: Ready
2022-04-04 18:44:32 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1316401285 is in desired state: Ready
2022-04-04 18:44:32 [main] [32mINFO [m [RecoveryIsolatedST:157] Running deleteKafkaHeadlessService with cluster recovery-cluster-1316401285
2022-04-04 18:44:32 [main] [32mINFO [m [RecoveryIsolatedST:164] Waiting for creation recovery-cluster-1316401285-zookeeper-nodes
2022-04-04 18:44:32 [main] [32mINFO [m [ServiceUtils:58] Waiting when Service recovery-cluster-1316401285-zookeeper-nodes-5fe66a79-d1f1-44b3-a136-fa2af43131ad in namespace infra-namespace will be recovered
2022-04-04 18:44:58 [main] [32mINFO [m [ServiceUtils:62] recovery-cluster-1316401285-zookeeper-nodes in namespace infra-namespace is recovered
2022-04-04 18:44:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:44:58 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromZookeeperHeadlessServiceDeletion
2022-04-04 18:44:58 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1316401285 in namespace infra-namespace
2022-04-04 18:44:58 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1316401285 in namespace infra-namespace
2022-04-04 18:44:58 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1316401285 in namespace infra-namespace
2022-04-04 18:45:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:45:48 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperHeadlessServiceDeletion-FINISHED
2022-04-04 18:45:48 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 18:45:48 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 18:45:48 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaMetricsConfigDeletion-STARTED
2022-04-04 18:45:48 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 18:45:48 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 18:45:48 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 18:45:48 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 18:45:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:45:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 18:45:48 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:45:48 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:45:48 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:45:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:45:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:45:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:45:48 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:45:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:45:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:45:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:45:48 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:45:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:45:49 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:45:49 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:45:49 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:45:49 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:45:49 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:45:49 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:45:49 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:45:49 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:45:58 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:45:59 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:45:59 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:46:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:46:14 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 18:46:14 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 18:46:14 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 18:46:14 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 18:46:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:46:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:46:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:46:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:46:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:46:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:46:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:46:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:46:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:46:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:46:15 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 18:46:15 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:46:15 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 18:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:46:15 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 18:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:46:15 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:46:15 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 18:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:46:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:46:15 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 18:46:45 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 18:46:45 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 18:46:55 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 18:46:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1925224323 in namespace infra-namespace
2022-04-04 18:46:55 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1925224323 will have desired state: Ready
2022-04-04 18:48:16 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1925224323 is in desired state: Ready
2022-04-04 18:48:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1925224323 in namespace infra-namespace
2022-04-04 18:48:16 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1925224323 will be ready
2022-04-04 18:48:18 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1925224323 is ready
2022-04-04 18:48:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1925224323 in namespace infra-namespace
2022-04-04 18:48:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1925224323 will have desired state: Ready
2022-04-04 18:48:36 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1925224323 is in desired state: Ready
2022-04-04 18:48:36 [main] [32mINFO [m [RecoveryIsolatedST:171] Running deleteKafkaMetricsConfig with cluster recovery-cluster-1925224323
2022-04-04 18:48:36 [main] [32mINFO [m [RecoveryIsolatedST:185] Waiting for creation recovery-cluster-1925224323-kafka-config
2022-04-04 18:48:36 [main] [32mINFO [m [ConfigMapUtils:30] Waiting for config map recovery-cluster-1925224323-kafka-config-5b979945-2bf1-4531-84bb-f80b753438a2 recovery in namespace infra-namespace
2022-04-04 18:48:53 [main] [32mINFO [m [ConfigMapUtils:33] Config map recovery-cluster-1925224323-kafka-config was recovered
2022-04-04 18:48:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:48:53 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaMetricsConfigDeletion
2022-04-04 18:48:53 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1925224323 in namespace infra-namespace
2022-04-04 18:48:53 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1925224323 in namespace infra-namespace
2022-04-04 18:48:53 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1925224323 in namespace infra-namespace
2022-04-04 18:49:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:49:43 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaMetricsConfigDeletion-FINISHED
2022-04-04 18:49:43 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 18:49:43 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 18:49:43 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperServiceDeletion-STARTED
2022-04-04 18:49:43 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 18:49:43 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 18:49:43 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 18:49:43 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 18:49:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:49:43 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 18:49:43 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:49:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:49:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:49:43 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:49:43 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:49:43 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:49:43 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:49:43 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:49:43 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:49:43 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:49:43 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:49:43 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:49:43 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:49:43 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:49:44 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:49:53 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:49:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:49:53 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:49:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:49:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:49:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:49:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:49:54 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:50:03 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:50:09 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 18:50:09 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 18:50:09 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 18:50:09 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 18:50:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:50:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:50:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:50:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:50:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:50:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:50:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:50:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:50:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:50:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:50:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:50:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:50:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:50:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:50:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:50:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:50:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:50:10 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 18:50:10 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:50:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:50:10 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 18:50:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:50:10 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 18:50:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:50:10 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:50:10 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:50:10 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 18:50:10 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:50:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:50:10 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 18:50:42 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 18:50:42 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 18:50:52 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 18:50:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1991124947 in namespace infra-namespace
2022-04-04 18:50:52 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1991124947 will have desired state: Ready
2022-04-04 18:53:06 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1991124947 is in desired state: Ready
2022-04-04 18:53:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1991124947 in namespace infra-namespace
2022-04-04 18:53:06 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1991124947 will be ready
2022-04-04 18:53:08 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1991124947 is ready
2022-04-04 18:53:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1991124947 in namespace infra-namespace
2022-04-04 18:53:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1991124947 will have desired state: Ready
2022-04-04 18:53:28 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1991124947 is in desired state: Ready
2022-04-04 18:53:28 [main] [32mINFO [m [RecoveryIsolatedST:129] Running deleteKafkaService with cluster recovery-cluster-1991124947
2022-04-04 18:53:28 [main] [32mINFO [m [RecoveryIsolatedST:136] Waiting for creation recovery-cluster-1991124947-zookeeper-client
2022-04-04 18:53:28 [main] [32mINFO [m [ServiceUtils:58] Waiting when Service recovery-cluster-1991124947-zookeeper-client-d5590cec-2f3c-455c-ba49-42f9a8cb9571 in namespace infra-namespace will be recovered
2022-04-04 18:53:48 [main] [32mINFO [m [ServiceUtils:62] recovery-cluster-1991124947-zookeeper-client in namespace infra-namespace is recovered
2022-04-04 18:53:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:53:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromZookeeperServiceDeletion
2022-04-04 18:53:48 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1991124947 in namespace infra-namespace
2022-04-04 18:53:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1991124947 in namespace infra-namespace
2022-04-04 18:53:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1991124947 in namespace infra-namespace
2022-04-04 18:54:38 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:54:38 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperServiceDeletion-FINISHED
2022-04-04 18:54:38 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 18:54:38 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 18:54:38 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromImpossibleMemoryRequest-STARTED
2022-04-04 18:54:38 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 18:54:38 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 18:54:38 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 18:54:38 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 18:54:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:54:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 18:54:38 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:54:38 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:54:38 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:54:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:54:38 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:54:38 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:54:38 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:54:38 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:54:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:54:38 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:54:38 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:54:38 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:54:38 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:54:38 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:54:38 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:54:48 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:54:48 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:54:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:54:48 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:54:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:54:48 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:54:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:54:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:54:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:55:08 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 18:55:08 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 18:55:08 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 18:55:08 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 18:55:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:55:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:55:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:55:09 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 18:55:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:55:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 18:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:55:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 18:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:55:09 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:55:09 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 18:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:55:09 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 18:55:43 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 18:55:43 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 18:55:53 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 18:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1867793475 in namespace infra-namespace
2022-04-04 18:55:53 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1867793475 will have desired state: Ready
2022-04-04 18:57:12 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1867793475 is in desired state: Ready
2022-04-04 18:57:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1867793475 in namespace infra-namespace
2022-04-04 18:57:12 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1867793475 will be ready
2022-04-04 18:57:14 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1867793475 is ready
2022-04-04 18:57:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1867793475 in namespace infra-namespace
2022-04-04 18:57:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1867793475 will have desired state: Ready
2022-04-04 18:57:33 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1867793475 is in desired state: Ready
2022-04-04 18:57:33 [main] [32mINFO [m [PodUtils:277] Wait for at least one pod with prefix: recovery-cluster-1867793475-kafka will be in pending phase
2022-04-04 18:57:40 [main] [32mINFO [m [PodUtils:306] Verify that all pods with prefix: recovery-cluster-1867793475-kafka are stable in pending phase
2022-04-04 18:57:40 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 50
2022-04-04 18:57:41 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 49
2022-04-04 18:57:42 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 48
2022-04-04 18:57:43 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 47
2022-04-04 18:57:44 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 46
2022-04-04 18:57:45 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 45
2022-04-04 18:57:46 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 44
2022-04-04 18:57:47 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 43
2022-04-04 18:57:48 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 42
2022-04-04 18:57:49 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 41
2022-04-04 18:57:50 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 40
2022-04-04 18:57:51 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 39
2022-04-04 18:57:52 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 38
2022-04-04 18:57:53 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 37
2022-04-04 18:57:54 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 36
2022-04-04 18:57:55 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 35
2022-04-04 18:57:56 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 34
2022-04-04 18:57:57 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 33
2022-04-04 18:57:58 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 32
2022-04-04 18:57:59 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 31
2022-04-04 18:58:00 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 30
2022-04-04 18:58:01 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 29
2022-04-04 18:58:02 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 28
2022-04-04 18:58:03 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 27
2022-04-04 18:58:04 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 26
2022-04-04 18:58:05 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 25
2022-04-04 18:58:06 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 24
2022-04-04 18:58:07 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 23
2022-04-04 18:58:08 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 22
2022-04-04 18:58:09 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 21
2022-04-04 18:58:10 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 20
2022-04-04 18:58:11 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 19
2022-04-04 18:58:12 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 18
2022-04-04 18:58:13 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 17
2022-04-04 18:58:14 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 16
2022-04-04 18:58:15 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 15
2022-04-04 18:58:16 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 14
2022-04-04 18:58:17 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 13
2022-04-04 18:58:18 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 12
2022-04-04 18:58:19 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 11
2022-04-04 18:58:20 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 10
2022-04-04 18:58:21 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 9
2022-04-04 18:58:22 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 8
2022-04-04 18:58:23 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 7
2022-04-04 18:58:24 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 6
2022-04-04 18:58:25 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 5
2022-04-04 18:58:26 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 4
2022-04-04 18:58:27 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 3
2022-04-04 18:58:28 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 2
2022-04-04 18:58:29 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1867793475-kafka-1 is in the Pending state. Remaining seconds pod to be stable 1
2022-04-04 18:58:29 [main] [32mINFO [m [PodUtils:335] All pods are stable recovery-cluster-1867793475-kafka-1
2022-04-04 18:58:29 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of recovery-cluster-1867793475-kafka to be ready
2022-04-04 19:05:09 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1867793475 will have desired state: Ready
2022-04-04 19:05:09 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1867793475 is in desired state: Ready
2022-04-04 19:05:09 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: recovery-cluster-1867793475 is ready
2022-04-04 19:05:09 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1867793475 will have desired state: Ready
2022-04-04 19:05:09 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1867793475 is in desired state: Ready
2022-04-04 19:05:09 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:05:09 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromImpossibleMemoryRequest
2022-04-04 19:05:09 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1867793475 in namespace infra-namespace
2022-04-04 19:05:09 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1867793475 in namespace infra-namespace
2022-04-04 19:05:09 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1867793475 in namespace infra-namespace
2022-04-04 19:05:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:05:49 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromImpossibleMemoryRequest-FINISHED
2022-04-04 19:05:49 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:05:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:05:49 [main] [32mINFO [m [ResourceManager:346] In context RecoveryIsolatedST is everything deleted.
2022-04-04 19:05:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;33mWARNING[m] Tests run: 14, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 4,104.043 s - in io.strimzi.systemtest.operators.RecoveryIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST
2022-04-04 19:05:49 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 19:06:14 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 19:06:14 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 19:06:14 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 19:06:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:06:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 19:06:14 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 19:06:14 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 19:06:14 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 19:06:14 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:06:14 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 19:06:14 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:06:14 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 19:06:14 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:06:14 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 19:06:14 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:06:14 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 19:06:14 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 19:06:14 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 19:06:14 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:06:14 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 19:06:14 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 19:06:24 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:06:24 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 19:06:24 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 19:06:24 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 19:06:24 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 19:06:24 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 19:06:24 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 19:06:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:06:40 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=30000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 19:06:40 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 19:06:40 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 19:06:40 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 19:06:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:06:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 19:06:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 19:06:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 19:06:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 19:06:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 19:06:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 19:06:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 19:06:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 19:06:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 19:06:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:06:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:06:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 19:06:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 19:06:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 19:06:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 19:06:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:06:40 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 19:06:40 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 19:06:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 19:06:40 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 19:06:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 19:06:40 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 19:06:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 19:06:40 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 19:06:40 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:06:40 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 19:06:40 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 19:06:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:06:40 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 19:07:06 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 19:07:06 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 19:07:16 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 19:07:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka custom-resource-status-cluster-name in namespace infra-namespace
2022-04-04 19:07:16 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: custom-resource-status-cluster-name will have desired state: Ready
2022-04-04 19:08:44 [main] [32mINFO [m [ResourceManager:444] Kafka: custom-resource-status-cluster-name is in desired state: Ready
2022-04-04 19:08:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-335653399-1112350690 in namespace infra-namespace
2022-04-04 19:08:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-335653399-1112350690 will have desired state: Ready
2022-04-04 19:08:45 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-335653399-1112350690 is in desired state: Ready
2022-04-04 19:08:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment infra-namespace-shared-kafka-clients in namespace infra-namespace
2022-04-04 19:08:45 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: infra-namespace-shared-kafka-clients will be ready
2022-04-04 19:08:47 [main] [32mINFO [m [DeploymentUtils:168] Deployment: infra-namespace-shared-kafka-clients is ready
2022-04-04 19:08:47 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:08:47 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicChangingInSyncReplicasStatus-STARTED
2022-04-04 19:08:47 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:08:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-540718156-307614577 in namespace infra-namespace
2022-04-04 19:08:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-540718156-307614577 will have desired state: Ready
2022-04-04 19:08:48 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-540718156-307614577 is in desired state: Ready
2022-04-04 19:08:48 [main] [32mINFO [m [CustomResourceStatusIsolatedST:481] Changing min.insync.replicas to random char
2022-04-04 19:08:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-540718156-307614577 will have desired state: NotReady
2022-04-04 19:08:49 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-540718156-307614577 is in desired state: NotReady
2022-04-04 19:08:49 [main] [32mINFO [m [CustomResourceStatusIsolatedST:488] Wait 245000 ms for next reconciliation
2022-04-04 19:12:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:12:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaTopicChangingInSyncReplicasStatus
2022-04-04 19:12:54 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-540718156-307614577 in namespace infra-namespace
2022-04-04 19:13:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:13:04 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicChangingInSyncReplicasStatus-FINISHED
2022-04-04 19:13:04 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:13:04 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:13:04 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaUserStatusNotReady-STARTED
2022-04-04 19:13:04 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:13:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef in namespace infra-namespace
2022-04-04 19:13:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef will have desired state: NotReady
2022-04-04 19:13:05 [main] [32mINFO [m [ResourceManager:444] KafkaUser: sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef is in desired state: NotReady
2022-04-04 19:13:05 [main] [32mINFO [m [CustomResourceStatusIsolatedST:179] Checking status of deployed KafkaUser sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef
2022-04-04 19:13:05 [main] [32mINFO [m [CustomResourceStatusIsolatedST:181] KafkaUser Status: True
2022-04-04 19:13:05 [main] [32mINFO [m [CustomResourceStatusIsolatedST:182] KafkaUser Type: NotReady
2022-04-04 19:13:05 [main] [32mINFO [m [CustomResourceStatusIsolatedST:183] KafkaUser Message: Spec cannot be null
2022-04-04 19:13:05 [main] [32mINFO [m [CustomResourceStatusIsolatedST:184] KafkaUser Reason: InvalidResourceException
2022-04-04 19:13:05 [main] [32mINFO [m [CustomResourceStatusIsolatedST:186] KafkaUser sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef is in desired state: NotReady
2022-04-04 19:13:05 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef
2022-04-04 19:13:05 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef deleted
2022-04-04 19:13:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:13:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaUserStatusNotReady
2022-04-04 19:13:05 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef in namespace infra-namespace
2022-04-04 19:13:05 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:13:05 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaUserStatusNotReady-FINISHED
2022-04-04 19:13:05 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:13:05 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:13:05 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaUserStatus-STARTED
2022-04-04 19:13:05 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:13:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1033521371-910890463 in namespace infra-namespace
2022-04-04 19:13:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1033521371-910890463 will have desired state: Ready
2022-04-04 19:13:06 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1033521371-910890463 is in desired state: Ready
2022-04-04 19:13:06 [main] [32mINFO [m [CustomResourceStatusIsolatedST:162] Checking status of deployed KafkaUser
2022-04-04 19:13:06 [main] [32mINFO [m [CustomResourceStatusIsolatedST:164] KafkaUser Status: True
2022-04-04 19:13:06 [main] [32mINFO [m [CustomResourceStatusIsolatedST:165] KafkaUser Type: Ready
2022-04-04 19:13:06 [main] [32mINFO [m [CustomResourceStatusIsolatedST:167] KafkaUser is in desired state: Ready
2022-04-04 19:13:06 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:13:06 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaUserStatus
2022-04-04 19:13:06 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1033521371-910890463 in namespace infra-namespace
2022-04-04 19:13:16 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:13:16 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaUserStatus-FINISHED
2022-04-04 19:13:16 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:13:16 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:13:16 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicStatusNotReady-STARTED
2022-04-04 19:13:16 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:13:16 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-470802507-584396741 in namespace infra-namespace
2022-04-04 19:13:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-470802507-584396741 will have desired state: NotReady
2022-04-04 19:13:17 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-470802507-584396741 is in desired state: NotReady
2022-04-04 19:13:17 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-470802507-584396741 deletion
2022-04-04 19:13:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:13:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaTopicStatusNotReady
2022-04-04 19:13:17 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-470802507-584396741 in namespace infra-namespace
2022-04-04 19:13:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:13:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicStatusNotReady-FINISHED
2022-04-04 19:13:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:13:17 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:13:17 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaStatusCertificate-STARTED
2022-04-04 19:13:17 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:13:17 [main] [32mINFO [m [CustomResourceStatusIsolatedST:381] Check if KafkaStatus certificates are the same as secret certificates
2022-04-04 19:13:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:13:17 [main] [32mINFO [m [ResourceManager:346] In context testKafkaStatusCertificate is everything deleted.
2022-04-04 19:13:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:13:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaStatusCertificate-FINISHED
2022-04-04 19:13:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:13:17 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:13:17 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaBridgeStatus-STARTED
2022-04-04 19:13:17 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:13:17 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge custom-resource-status-cluster-name in namespace infra-namespace
2022-04-04 19:13:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: custom-resource-status-cluster-name will have desired state: Ready
2022-04-04 19:13:36 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: custom-resource-status-cluster-name is in desired state: Ready
2022-04-04 19:13:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: custom-resource-status-cluster-name will have desired state: Ready
2022-04-04 19:13:36 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: custom-resource-status-cluster-name is in desired state: Ready
2022-04-04 19:13:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: custom-resource-status-cluster-name will have desired state: NotReady
2022-04-04 19:14:07 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: custom-resource-status-cluster-name is in desired state: NotReady
2022-04-04 19:14:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: custom-resource-status-cluster-name will have desired state: Ready
2022-04-04 19:15:05 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: custom-resource-status-cluster-name is in desired state: Ready
2022-04-04 19:15:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:15:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaBridgeStatus
2022-04-04 19:15:05 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge custom-resource-status-cluster-name in namespace infra-namespace
2022-04-04 19:15:15 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:15:15 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaBridgeStatus-FINISHED
2022-04-04 19:15:15 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:15:15 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:15:15 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicStatus-STARTED
2022-04-04 19:15:15 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:15:15 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-147802122-532615084 in namespace infra-namespace
2022-04-04 19:15:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-147802122-532615084 will have desired state: Ready
2022-04-04 19:15:16 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-147802122-532615084 is in desired state: Ready
2022-04-04 19:15:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-147802122-532615084 will have desired state: Ready
2022-04-04 19:15:16 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-147802122-532615084 is in desired state: Ready
2022-04-04 19:15:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:15:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaTopicStatus
2022-04-04 19:15:16 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-147802122-532615084 in namespace infra-namespace
2022-04-04 19:15:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:15:26 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicStatus-FINISHED
2022-04-04 19:15:26 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:15:26 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:15:26 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMaker2Status-STARTED
2022-04-04 19:15:26 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:15:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-74ca4d44 in namespace infra-namespace
2022-04-04 19:15:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-74ca4d44 will have desired state: Ready
2022-04-04 19:16:34 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-74ca4d44 is in desired state: Ready
2022-04-04 19:16:34 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-74ca4d44-mirror-maker-2 in namespace infra-namespace
2022-04-04 19:16:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-74ca4d44-mirror-maker-2 will have desired state: Ready
2022-04-04 19:17:49 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-74ca4d44-mirror-maker-2 is in desired state: Ready
2022-04-04 19:17:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-74ca4d44-mirror-maker-2 will have desired state: Ready
2022-04-04 19:17:49 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-74ca4d44-mirror-maker-2 is in desired state: Ready
2022-04-04 19:17:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-74ca4d44-mirror-maker-2 will have desired state: NotReady
2022-04-04 19:18:21 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-74ca4d44-mirror-maker-2 is in desired state: NotReady
2022-04-04 19:18:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-74ca4d44-mirror-maker-2 will have desired state: Ready
2022-04-04 19:20:01 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-74ca4d44-mirror-maker-2 is in desired state: Ready
2022-04-04 19:20:18 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-74ca4d44-mirror-maker-2-mirrormaker2 are stable
2022-04-04 19:20:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 19:20:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 19:20:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 19:20:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 19:20:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 19:20:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 19:20:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 19:20:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 19:20:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 19:20:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 19:20:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 19:20:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 19:20:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 19:20:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 19:20:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 19:20:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 19:20:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 19:20:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 19:20:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 19:20:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 19:20:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 19:20:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 19:20:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 19:20:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 19:20:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 19:20:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 19:20:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 19:20:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 19:20:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 19:20:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 19:20:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 19:20:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 19:20:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 19:20:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 19:20:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 19:20:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 19:20:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 19:20:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 19:20:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 19:20:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 19:20:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 19:20:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 19:21:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 19:21:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 19:21:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 19:21:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 19:21:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 19:21:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 19:21:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 19:21:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 19:21:07 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-74ca4d44-mirror-maker-2-mirrormaker2-84d9675474mdm6d
2022-04-04 19:21:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:21:07 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaMirrorMaker2Status
2022-04-04 19:21:07 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-74ca4d44-mirror-maker-2 in namespace infra-namespace
2022-04-04 19:21:07 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-74ca4d44 in namespace infra-namespace
2022-04-04 19:21:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:21:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMaker2Status-FINISHED
2022-04-04 19:21:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:21:17 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:21:17 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaConnectorWithoutClusterConfig-STARTED
2022-04-04 19:21:17 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:21:17 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-e7cb29d1 in namespace infra-namespace
2022-04-04 19:21:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-e7cb29d1 will have desired state: NotReady
2022-04-04 19:21:18 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-e7cb29d1 is in desired state: NotReady
2022-04-04 19:21:18 [main] [32mINFO [m [KafkaConnectorUtils:98] KafkaConnector: my-cluster-e7cb29d1 is not deleted yet, triggering force delete
2022-04-04 19:21:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:21:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectorWithoutClusterConfig
2022-04-04 19:21:19 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-e7cb29d1 in namespace infra-namespace
2022-04-04 19:21:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:21:19 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaConnectorWithoutClusterConfig-FINISHED
2022-04-04 19:21:19 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:21:19 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:21:19 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMakerStatusWrongBootstrap-STARTED
2022-04-04 19:21:19 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:21:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-6e9420b1 in namespace infra-namespace
2022-04-04 19:21:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-6e9420b1 will have desired state: Ready
2022-04-04 19:22:23 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-6e9420b1 is in desired state: Ready
2022-04-04 19:22:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-6e9420b1 will have desired state: Ready
2022-04-04 19:22:23 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-6e9420b1 is in desired state: Ready
2022-04-04 19:22:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-6e9420b1 will have desired state: NotReady
2022-04-04 19:22:54 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-6e9420b1 is in desired state: NotReady
2022-04-04 19:22:54 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-6e9420b1 will have desired state: Ready
2022-04-04 19:23:25 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-6e9420b1 is in desired state: Ready
2022-04-04 19:23:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:23:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaMirrorMakerStatusWrongBootstrap
2022-04-04 19:23:25 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-6e9420b1 in namespace infra-namespace
2022-04-04 19:23:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:23:36 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMakerStatusWrongBootstrap-FINISHED
2022-04-04 19:23:36 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:23:36 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:23:36 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaConnectAndConnectorStatus-STARTED
2022-04-04 19:23:36 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:23:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment custom-resource-status-cluster-name-scraper in namespace infra-namespace
2022-04-04 19:23:36 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: custom-resource-status-cluster-name-scraper will be ready
2022-04-04 19:23:38 [main] [32mINFO [m [DeploymentUtils:168] Deployment: custom-resource-status-cluster-name-scraper is ready
2022-04-04 19:23:38 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment custom-resource-status-cluster-name-scraper to be ready
2022-04-04 19:23:48 [main] [32mINFO [m [DeploymentUtils:197] Deployment custom-resource-status-cluster-name-scraper is ready
2022-04-04 19:23:48 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to custom-resource-status-cluster-name-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 19:23:48 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy custom-resource-status-cluster-name-allow in namespace infra-namespace
2022-04-04 19:23:48 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 19:23:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect custom-resource-status-cluster-name in namespace infra-namespace
2022-04-04 19:23:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: custom-resource-status-cluster-name will have desired state: Ready
2022-04-04 19:24:58 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: custom-resource-status-cluster-name is in desired state: Ready
2022-04-04 19:24:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector custom-resource-status-cluster-name in namespace infra-namespace
2022-04-04 19:24:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: custom-resource-status-cluster-name will have desired state: Ready
2022-04-04 19:24:59 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: custom-resource-status-cluster-name is in desired state: Ready
2022-04-04 19:24:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: custom-resource-status-cluster-name will have desired state: NotReady
2022-04-04 19:25:30 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: custom-resource-status-cluster-name is in desired state: NotReady
2022-04-04 19:25:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: custom-resource-status-cluster-name will have desired state: Ready
2022-04-04 19:27:20 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: custom-resource-status-cluster-name is in desired state: Ready
2022-04-04 19:27:20 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: custom-resource-status-cluster-name will have desired state: NotReady
2022-04-04 19:27:21 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: custom-resource-status-cluster-name is in desired state: NotReady
2022-04-04 19:27:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: custom-resource-status-cluster-name will have desired state: Ready
2022-04-04 19:27:22 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: custom-resource-status-cluster-name is in desired state: Ready
2022-04-04 19:27:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: custom-resource-status-cluster-name will have desired state: NotReady
2022-04-04 19:27:23 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: custom-resource-status-cluster-name is in desired state: NotReady
2022-04-04 19:27:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: custom-resource-status-cluster-name will have desired state: Ready
2022-04-04 19:27:24 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: custom-resource-status-cluster-name is in desired state: Ready
2022-04-04 19:27:24 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:27:24 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectAndConnectorStatus
2022-04-04 19:27:24 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect custom-resource-status-cluster-name in namespace infra-namespace
2022-04-04 19:27:24 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector custom-resource-status-cluster-name in namespace infra-namespace
2022-04-04 19:27:24 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy custom-resource-status-cluster-name-allow in namespace infra-namespace
2022-04-04 19:27:24 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment custom-resource-status-cluster-name-scraper in namespace infra-namespace
2022-04-04 19:28:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:28:04 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaConnectAndConnectorStatus-FINISHED
2022-04-04 19:28:04 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:28:04 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:28:04 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMaker2WrongBootstrap-STARTED
2022-04-04 19:28:04 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:28:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-37f1a755-mirror-maker-2 in namespace infra-namespace
2022-04-04 19:28:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-37f1a755-mirror-maker-2 will have desired state: NotReady
2022-04-04 19:28:36 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-37f1a755-mirror-maker-2 is in desired state: NotReady
2022-04-04 19:28:36 [main] [33mWARN [m [DeploymentUtils:213] Deployment my-cluster-37f1a755-mirror-maker-2-mirrormaker2 is not deleted yet! Triggering force delete by cmd client!
2022-04-04 19:28:41 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:28:41 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaMirrorMaker2WrongBootstrap
2022-04-04 19:28:41 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-37f1a755-mirror-maker-2 in namespace infra-namespace
2022-04-04 19:28:41 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:28:41 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMaker2WrongBootstrap-FINISHED
2022-04-04 19:28:41 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:28:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:28:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicDecreaseStatus-STARTED
2022-04-04 19:28:41 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:28:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1250530642-1011746816 in namespace infra-namespace
2022-04-04 19:28:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1250530642-1011746816 will have desired state: Ready
2022-04-04 19:28:42 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1250530642-1011746816 is in desired state: Ready
2022-04-04 19:28:42 [main] [32mINFO [m [CustomResourceStatusIsolatedST:457] Decreasing number of partitions to 1
2022-04-04 19:28:42 [main] [32mINFO [m [KafkaTopicUtils:124] Waiting for KafkaTopic change my-topic-1250530642-1011746816
2022-04-04 19:28:42 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1250530642-1011746816 will have desired state: NotReady
2022-04-04 19:28:43 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1250530642-1011746816 is in desired state: NotReady
2022-04-04 19:28:43 [main] [32mINFO [m [CustomResourceStatusIsolatedST:465] Wait 245000 ms for next reconciliation
2022-04-04 19:32:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:32:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaTopicDecreaseStatus
2022-04-04 19:32:48 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1250530642-1011746816 in namespace infra-namespace
2022-04-04 19:32:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:32:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicDecreaseStatus-FINISHED
2022-04-04 19:32:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:32:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:32:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMakerStatus-STARTED
2022-04-04 19:32:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:32:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-fd91f8b4-mirror-maker in namespace infra-namespace
2022-04-04 19:32:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-fd91f8b4-mirror-maker will have desired state: Ready
2022-04-04 19:34:17 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-fd91f8b4-mirror-maker is in desired state: Ready
2022-04-04 19:34:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-fd91f8b4-mirror-maker will have desired state: Ready
2022-04-04 19:34:17 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-fd91f8b4-mirror-maker is in desired state: Ready
2022-04-04 19:34:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-fd91f8b4-mirror-maker will have desired state: NotReady
2022-04-04 19:34:49 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-fd91f8b4-mirror-maker is in desired state: NotReady
2022-04-04 19:34:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-fd91f8b4-mirror-maker will have desired state: Ready
2022-04-04 19:36:39 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-fd91f8b4-mirror-maker is in desired state: Ready
2022-04-04 19:36:39 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:36:39 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaMirrorMakerStatus
2022-04-04 19:36:39 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-fd91f8b4-mirror-maker in namespace infra-namespace
2022-04-04 19:36:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:36:49 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMakerStatus-FINISHED
2022-04-04 19:36:49 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:36:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:36:49 [main] [32mINFO [m [ResourceManager:348] Delete all resources for CustomResourceStatusIsolatedST
2022-04-04 19:36:49 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-335653399-1112350690 in namespace infra-namespace
2022-04-04 19:36:49 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka custom-resource-status-cluster-name in namespace infra-namespace
2022-04-04 19:36:49 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment infra-namespace-shared-kafka-clients in namespace infra-namespace
2022-04-04 19:37:39 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,909.517 s - in io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST
2022-04-04 19:37:39 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 19:38:04 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 19:38:04 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 19:38:04 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 19:38:04 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:38:04 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 19:38:04 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 19:38:04 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 19:38:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 19:38:04 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 19:38:04 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:38:04 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:38:04 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 19:38:04 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:38:04 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 19:38:04 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 19:38:04 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 19:38:04 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 19:38:04 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 19:38:04 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 19:38:04 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 19:38:04 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:38:04 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 19:38:04 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 19:38:04 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 19:38:04 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 19:38:14 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:38:14 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 19:38:14 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:38:24 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:38:29 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:38:29 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testKafkaCCAndRebalanceWithMultipleCOs-STARTED
2022-04-04 19:38:30 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:38:30 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:230] Creating first-strimzi-cluster-operator in multiple-co-cluster-test namespace
2022-04-04 19:38:30 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@4e1f8140, extensionContext=org.junit.jupiter.engine.descriptor.MethodExtensionContext@1fa80224, clusterOperatorName='first-strimzi-cluster-operator', namespaceInstallTo='multiple-co-cluster-test', namespaceToWatch='multiple-co-cluster-test', bindingsNamespaces=[multiple-co-cluster-test], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[EnvVar(name=STRIMZI_CUSTOM_RESOURCE_SELECTOR, value=app.kubernetes.io/operator=first-strimzi-cluster-operator, valueFrom=null, additionalProperties={})], extraLabels={app.kubernetes.io/operator=first-strimzi-cluster-operator}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-04 19:38:30 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 19:38:30 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: multiple-co-cluster-test
2022-04-04 19:38:30 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: multiple-co-cluster-test
2022-04-04 19:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 19:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 19:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 19:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 19:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 19:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 19:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 19:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 19:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 19:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 19:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 19:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 19:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 19:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 19:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 19:38:30 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: multiple-co-cluster-test
2022-04-04 19:38:30 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace multiple-co-cluster-test
2022-04-04 19:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 19:38:30 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace multiple-co-cluster-test
2022-04-04 19:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 19:38:30 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace multiple-co-cluster-test
2022-04-04 19:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 19:38:30 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace multiple-co-cluster-test
2022-04-04 19:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 19:38:30 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace multiple-co-cluster-test
2022-04-04 19:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace multiple-co-cluster-test
2022-04-04 19:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment first-strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 19:38:30 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: first-strimzi-cluster-operator will be ready
2022-04-04 19:38:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: first-strimzi-cluster-operator is ready
2022-04-04 19:38:48 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment first-strimzi-cluster-operator to be ready
2022-04-04 19:38:58 [main] [32mINFO [m [DeploymentUtils:197] Deployment first-strimzi-cluster-operator is ready
2022-04-04 19:38:58 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:230] Creating second-strimzi-cluster-operator in multiple-co-cluster-test namespace
2022-04-04 19:38:58 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@4e1f8140, extensionContext=org.junit.jupiter.engine.descriptor.MethodExtensionContext@1fa80224, clusterOperatorName='second-strimzi-cluster-operator', namespaceInstallTo='multiple-co-cluster-test', namespaceToWatch='multiple-co-cluster-test', bindingsNamespaces=[multiple-co-cluster-test], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[EnvVar(name=STRIMZI_CUSTOM_RESOURCE_SELECTOR, value=app.kubernetes.io/operator=second-strimzi-cluster-operator, valueFrom=null, additionalProperties={})], extraLabels={app.kubernetes.io/operator=second-strimzi-cluster-operator}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-04 19:38:58 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 19:38:58 [main] [32mINFO [m [SetupClusterOperator:254] Environment for ClusterOperator was already prepared! Going to install it now.
2022-04-04 19:38:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 19:38:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 19:38:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 19:38:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 19:38:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 19:38:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 19:38:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 19:38:59 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: multiple-co-cluster-test
2022-04-04 19:38:59 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace multiple-co-cluster-test
2022-04-04 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 19:38:59 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace multiple-co-cluster-test
2022-04-04 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 19:38:59 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace multiple-co-cluster-test
2022-04-04 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 19:38:59 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace multiple-co-cluster-test
2022-04-04 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 19:38:59 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace multiple-co-cluster-test
2022-04-04 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace multiple-co-cluster-test
2022-04-04 19:38:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment second-strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 19:38:59 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: second-strimzi-cluster-operator will be ready
2022-04-04 19:39:30 [main] [32mINFO [m [DeploymentUtils:168] Deployment: second-strimzi-cluster-operator is ready
2022-04-04 19:39:30 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment second-strimzi-cluster-operator to be ready
2022-04-04 19:39:40 [main] [32mINFO [m [DeploymentUtils:197] Deployment second-strimzi-cluster-operator is ready
2022-04-04 19:39:40 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:171] Deploying Kafka with {app.kubernetes.io/operator=first-strimzi-cluster-operator} selector of first-strimzi-cluster-operator
2022-04-04 19:39:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-8cc0d873 in namespace multiple-co-cluster-test
2022-04-04 19:39:40 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8cc0d873 will have desired state: Ready
2022-04-04 19:41:25 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8cc0d873 is in desired state: Ready
2022-04-04 19:41:25 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:180] Removing CR selector from Kafka and increasing number of replicas to 4, new pod should not appear
2022-04-04 19:41:25 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:188] Creating KafkaRebalance when CC doesn't have label for CO, the KR should be ignored
2022-04-04 19:41:25 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-8cc0d873 in namespace multiple-co-cluster-test
2022-04-04 19:41:25 [main] [32mINFO [m [KafkaUtils:180] Waiting for cluster stability
2022-04-04 19:42:27 [main] [32mINFO [m [KafkaUtils:208] Kafka cluster is stable after 61 polls.
2022-04-04 19:42:27 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:204] Checking if KafkaRebalance is still ignored, after the cluster stability wait
2022-04-04 19:42:27 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:209] Adding {app.kubernetes.io/operator=second-strimzi-cluster-operator} selector of second-strimzi-cluster-operator to Kafka
2022-04-04 19:42:27 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:212] Waiting for Kafka to scales pods to 4
2022-04-04 19:42:27 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 4 Pod(s) of my-cluster-8cc0d873-kafka to be ready
2022-04-04 19:46:05 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8cc0d873 will have desired state: Ready
2022-04-04 19:46:05 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8cc0d873 is in desired state: Ready
2022-04-04 19:46:05 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-8cc0d873 is ready
2022-04-04 19:46:05 [main] [32mINFO [m [KafkaRebalanceUtils:75] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-8cc0d873): ============================================================================
2022-04-04 19:46:05 [main] [32mINFO [m [KafkaRebalanceUtils:76] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-8cc0d873): PendingProposal
2022-04-04 19:46:05 [main] [32mINFO [m [KafkaRebalanceUtils:77] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-8cc0d873): ============================================================================
2022-04-04 19:46:05 [main] [32mINFO [m [KafkaRebalanceUtils:81] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-8cc0d873): Verifying that KafkaRebalance resource is in PendingProposal state
2022-04-04 19:46:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-8cc0d873 will have desired state: PendingProposal
2022-04-04 19:46:05 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-8cc0d873 is in desired state: PendingProposal
2022-04-04 19:46:05 [main] [32mINFO [m [KafkaRebalanceUtils:85] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-8cc0d873): Verifying that KafkaRebalance resource is in ProposalReady state
2022-04-04 19:46:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-8cc0d873 will have desired state: ProposalReady
2022-04-04 19:46:16 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-8cc0d873 is in desired state: ProposalReady
2022-04-04 19:46:16 [main] [32mINFO [m [KafkaRebalanceUtils:90] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-8cc0d873): ============================================================================
2022-04-04 19:46:16 [main] [32mINFO [m [KafkaRebalanceUtils:91] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-8cc0d873): ProposalReady
2022-04-04 19:46:16 [main] [32mINFO [m [KafkaRebalanceUtils:92] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-8cc0d873): ============================================================================
2022-04-04 19:46:16 [main] [32mINFO [m [KafkaRebalanceUtils:94] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-8cc0d873): Triggering the rebalance with annotation strimzi.io/rebalance=approve of KafkaRebalance resource
2022-04-04 19:46:16 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-8cc0d873): Annotating KafkaRebalance:my-cluster-8cc0d873 with annotation approve
2022-04-04 19:46:17 [main] [32mINFO [m [KafkaRebalanceUtils:98] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-8cc0d873): Response from the annotation process kafkarebalance.kafka.strimzi.io/my-cluster-8cc0d873 annotated
2022-04-04 19:46:17 [main] [32mINFO [m [KafkaRebalanceUtils:100] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-8cc0d873): Verifying that annotation triggers the Rebalancing state
2022-04-04 19:46:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-8cc0d873 will have desired state: Rebalancing
2022-04-04 19:46:18 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-8cc0d873 is in desired state: Rebalancing
2022-04-04 19:46:18 [main] [32mINFO [m [KafkaRebalanceUtils:104] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-8cc0d873): Verifying that KafkaRebalance is in the Ready state
2022-04-04 19:46:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-8cc0d873 will have desired state: Ready
2022-04-04 19:46:23 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-8cc0d873 is in desired state: Ready
2022-04-04 19:46:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:46:23 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaCCAndRebalanceWithMultipleCOs
2022-04-04 19:46:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 19:46:23 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 19:46:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 19:46:23 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace multiple-co-cluster-test
2022-04-04 19:46:23 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 19:46:23 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 19:46:23 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 19:46:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 19:46:23 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 19:46:23 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 19:46:23 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 19:46:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 19:46:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace multiple-co-cluster-test
2022-04-04 19:46:23 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment first-strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 19:46:23 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 19:46:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 19:46:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 19:46:23 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 19:46:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-8cc0d873 in namespace multiple-co-cluster-test
2022-04-04 19:46:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace multiple-co-cluster-test, for cruise control Kafka cluster my-cluster-8cc0d873
2022-04-04 19:46:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:46:23 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 19:46:23 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 19:46:23 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 19:46:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-8cc0d873 in namespace multiple-co-cluster-test
2022-04-04 19:46:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment second-strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 19:46:33 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 19:46:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 19:46:33 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 19:46:33 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 19:46:33 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:46:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 19:46:33 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 19:46:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:46:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 19:46:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:46:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 19:46:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 19:46:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 19:46:33 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 19:46:33 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 19:46:33 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 19:46:33 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 19:46:33 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 19:46:33 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 19:46:33 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 19:46:33 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 19:46:33 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 19:46:33 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 19:46:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:46:43 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testKafkaCCAndRebalanceWithMultipleCOs-FINISHED
2022-04-04 19:46:43 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:46:43 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:46:43 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testMultipleCOsInDifferentNamespaces-STARTED
2022-04-04 19:46:43 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:46:43 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 19:46:43 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding first-strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 19:46:43 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding first-strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 19:46:43 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:230] Creating first-strimzi-cluster-operator in first-co-namespace namespace
2022-04-04 19:46:43 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@4e1f8140, extensionContext=org.junit.jupiter.engine.descriptor.MethodExtensionContext@3c37e224, clusterOperatorName='first-strimzi-cluster-operator', namespaceInstallTo='first-co-namespace', namespaceToWatch='*', bindingsNamespaces=[first-co-namespace], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[EnvVar(name=STRIMZI_CUSTOM_RESOURCE_SELECTOR, value=app.kubernetes.io/operator=first-strimzi-cluster-operator, valueFrom=null, additionalProperties={})], extraLabels={app.kubernetes.io/operator=first-strimzi-cluster-operator}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-04 19:46:43 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 19:46:43 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: first-co-namespace
2022-04-04 19:46:43 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: first-co-namespace
2022-04-04 19:46:43 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace first-co-namespace
2022-04-04 19:46:43 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 19:46:43 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 19:46:43 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 19:46:43 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 19:46:43 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 19:46:43 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 19:46:43 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 19:46:43 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 19:46:43 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 19:46:43 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:46:43 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:46:43 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 19:46:43 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 19:46:43 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 19:46:43 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 19:46:43 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace first-co-namespace
2022-04-04 19:46:43 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: first-co-namespace
2022-04-04 19:46:43 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace first-co-namespace
2022-04-04 19:46:43 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 19:46:43 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace first-co-namespace
2022-04-04 19:46:43 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 19:46:43 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace first-co-namespace
2022-04-04 19:46:43 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 19:46:43 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace first-co-namespace
2022-04-04 19:46:43 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace first-co-namespace
2022-04-04 19:46:43 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace first-co-namespace
2022-04-04 19:46:43 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace first-co-namespace
2022-04-04 19:46:43 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 19:46:43 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 19:46:43 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 19:46:43 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 19:46:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment first-strimzi-cluster-operator in namespace first-co-namespace
2022-04-04 19:46:44 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: first-strimzi-cluster-operator will be ready
2022-04-04 19:47:13 [main] [32mINFO [m [DeploymentUtils:168] Deployment: first-strimzi-cluster-operator is ready
2022-04-04 19:47:13 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment first-strimzi-cluster-operator to be ready
2022-04-04 19:47:23 [main] [32mINFO [m [DeploymentUtils:197] Deployment first-strimzi-cluster-operator is ready
2022-04-04 19:47:23 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 19:47:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding second-strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 19:47:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding second-strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 19:47:23 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:230] Creating second-strimzi-cluster-operator in second-co-namespace namespace
2022-04-04 19:47:23 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@4e1f8140, extensionContext=org.junit.jupiter.engine.descriptor.MethodExtensionContext@3c37e224, clusterOperatorName='second-strimzi-cluster-operator', namespaceInstallTo='second-co-namespace', namespaceToWatch='*', bindingsNamespaces=[second-co-namespace], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[EnvVar(name=STRIMZI_CUSTOM_RESOURCE_SELECTOR, value=app.kubernetes.io/operator=second-strimzi-cluster-operator, valueFrom=null, additionalProperties={})], extraLabels={app.kubernetes.io/operator=second-strimzi-cluster-operator}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-04 19:47:23 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 19:47:23 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: second-co-namespace
2022-04-04 19:47:23 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-co-namespace
2022-04-04 19:47:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace second-co-namespace
2022-04-04 19:47:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 19:47:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 19:47:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 19:47:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 19:47:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 19:47:23 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 19:47:23 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 19:47:23 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 19:47:23 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 19:47:23 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:47:23 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:47:23 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 19:47:23 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 19:47:23 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 19:47:23 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 19:47:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace second-co-namespace
2022-04-04 19:47:23 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: second-co-namespace
2022-04-04 19:47:23 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace second-co-namespace
2022-04-04 19:47:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 19:47:23 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace second-co-namespace
2022-04-04 19:47:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 19:47:23 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace second-co-namespace
2022-04-04 19:47:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 19:47:23 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace second-co-namespace
2022-04-04 19:47:23 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace second-co-namespace
2022-04-04 19:47:24 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace second-co-namespace
2022-04-04 19:47:24 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-co-namespace
2022-04-04 19:47:24 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 19:47:24 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 19:47:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 19:47:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 19:47:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment second-strimzi-cluster-operator in namespace second-co-namespace
2022-04-04 19:47:24 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: second-strimzi-cluster-operator will be ready
2022-04-04 19:47:56 [main] [32mINFO [m [DeploymentUtils:168] Deployment: second-strimzi-cluster-operator is ready
2022-04-04 19:47:56 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment second-strimzi-cluster-operator to be ready
2022-04-04 19:48:06 [main] [32mINFO [m [DeploymentUtils:197] Deployment second-strimzi-cluster-operator is ready
2022-04-04 19:48:06 [main] [33mWARN [m [KubeClusterResource:151] Namespace multiple-co-cluster-test is already created, going to delete it
2022-04-04 19:48:12 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: multiple-co-cluster-test
2022-04-04 19:48:12 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: multiple-co-cluster-test
2022-04-04 19:48:12 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: multiple-co-cluster-test
2022-04-04 19:48:12 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:100] Deploying Kafka without CR selector
2022-04-04 19:48:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c642ef64 in namespace multiple-co-cluster-test
2022-04-04 19:48:12 [main] [32mINFO [m [PodUtils:209] Wait until Pod my-cluster-c642ef64 will have stable 0 replicas
2022-04-04 19:48:12 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 19 polls
2022-04-04 19:48:13 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 18 polls
2022-04-04 19:48:14 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 17 polls
2022-04-04 19:48:15 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 16 polls
2022-04-04 19:48:16 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 15 polls
2022-04-04 19:48:17 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 14 polls
2022-04-04 19:48:18 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 13 polls
2022-04-04 19:48:19 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 12 polls
2022-04-04 19:48:20 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 11 polls
2022-04-04 19:48:21 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 10 polls
2022-04-04 19:48:22 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 9 polls
2022-04-04 19:48:23 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 8 polls
2022-04-04 19:48:24 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 7 polls
2022-04-04 19:48:25 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 6 polls
2022-04-04 19:48:26 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 5 polls
2022-04-04 19:48:27 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 4 polls
2022-04-04 19:48:28 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 3 polls
2022-04-04 19:48:29 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 2 polls
2022-04-04 19:48:30 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 1 polls
2022-04-04 19:48:31 [main] [32mINFO [m [PodUtils:217] Pod replicas are stable for 20 polls intervals
2022-04-04 19:48:31 [main] [32mINFO [m [PodUtils:228] Pod my-cluster-c642ef64 has 0 replicas
2022-04-04 19:48:31 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:110] Adding {app.kubernetes.io/operator=first-strimzi-cluster-operator} selector of first-strimzi-cluster-operator into Kafka CR
2022-04-04 19:48:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c642ef64 will have desired state: Ready
2022-04-04 19:49:53 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c642ef64 is in desired state: Ready
2022-04-04 19:49:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1699704277-23494393 in namespace multiple-co-cluster-test
2022-04-04 19:49:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-c642ef64 in namespace multiple-co-cluster-test
2022-04-04 19:49:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1699704277-23494393 will have desired state: Ready
2022-04-04 19:49:54 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1699704277-23494393 is in desired state: Ready
2022-04-04 19:49:54 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-c642ef64 will have desired state: Ready
2022-04-04 19:50:57 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-c642ef64 is in desired state: Ready
2022-04-04 19:50:57 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:130] Deploying KafkaConnector with file sink and CR selector - {app.kubernetes.io/operator=second-strimzi-cluster-operator} - different than selector in Kafka
2022-04-04 19:50:57 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-c642ef64 in namespace multiple-co-cluster-test
2022-04-04 19:50:57 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-c642ef64 will have desired state: Ready
2022-04-04 19:50:58 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-c642ef64 is in desired state: Ready
2022-04-04 19:50:58 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 19:50:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-producer in namespace multiple-co-cluster-test
2022-04-04 19:50:58 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-producer will be in active state
2022-04-04 19:50:59 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:hello-world-producer to finished
2022-04-04 19:51:07 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-c642ef64-connect-5bcb775889-rn5mp
2022-04-04 19:51:07 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-c642ef64-connect-5bcb775889-rn5mp
2022-04-04 19:51:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:51:07 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMultipleCOsInDifferentNamespaces
2022-04-04 19:51:07 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 19:51:07 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 19:51:07 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 19:51:07 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment second-strimzi-cluster-operator in namespace second-co-namespace
2022-04-04 19:51:07 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 19:51:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 19:51:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 19:51:07 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:51:07 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c642ef64 in namespace multiple-co-cluster-test
2022-04-04 19:51:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment first-strimzi-cluster-operator in namespace first-co-namespace
2022-04-04 19:51:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 19:51:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding second-strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 19:51:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 19:51:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding second-strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 19:51:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 19:51:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace first-co-namespace
2022-04-04 19:51:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 19:51:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 19:51:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace first-co-namespace
2022-04-04 19:51:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 19:51:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace first-co-namespace
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 19:51:17 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-c642ef64 in namespace multiple-co-cluster-test
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-producer in namespace multiple-co-cluster-test
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1699704277-23494393 in namespace multiple-co-cluster-test
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-c642ef64 in namespace multiple-co-cluster-test
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace second-co-namespace
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-co-namespace
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace second-co-namespace
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace second-co-namespace
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding first-strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace first-co-namespace
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding first-strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 19:51:17 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 19:51:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 19:51:27 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 19:51:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:51:27 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testMultipleCOsInDifferentNamespaces-FINISHED
2022-04-04 19:51:27 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:51:27 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:51:27 [main] [32mINFO [m [ResourceManager:346] In context MultipleClusterOperatorsIsolatedST is everything deleted.
2022-04-04 19:51:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 828.733 s - in io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST
2022-04-04 19:51:27 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 19:51:52 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:51:52 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST.testCRBDeletionErrorsWhenRackAwarenessIsEnabled-STARTED
2022-04-04 19:51:52 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:51:52 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 19:51:52 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 19:51:52 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 19:51:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:51:52 [main] [32mINFO [m [ResourceManager:346] In context JUnit Jupiter is everything deleted.
2022-04-04 19:51:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:52:34 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@4e1f8140, extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6, clusterOperatorName='strimzi-cluster-operator', namespaceInstallTo='infra-namespace', namespaceToWatch='infra-namespace', bindingsNamespaces=[infra-namespace], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[], extraLabels={}, clusterOperatorRBACType=NAMESPACE, testClassName='null', testMethodName='null'}
2022-04-04 19:52:34 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 19:52:34 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 19:52:34 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 19:52:34 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:52:34 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-04 19:52:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-04 19:52:34 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-04 19:52:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-04 19:52:34 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRole-strimzi-kafka-broker.yaml
2022-04-04 19:52:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-broker in namespace infra-namespace
2022-04-04 19:52:34 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-ClusterRole-strimzi-entity-operator.yaml
2022-04-04 19:52:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-entity-operator in namespace infra-namespace
2022-04-04 19:52:34 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRole-strimzi-kafka-client.yaml
2022-04-04 19:52:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-client in namespace infra-namespace
2022-04-04 19:52:34 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 19:52:34 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 19:52:35 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 19:52:35 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 19:52:35 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:52:35 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:52:35 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 19:52:35 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 19:52:35 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 19:52:35 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 19:52:35 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:52:35 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 19:52:35 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-04 19:52:35 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/020-Role-strimzi-cluster-operator-role14171966532355790361.yaml in namespace infra-namespace
2022-04-04 19:52:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-04 19:52:35 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-04 19:52:35 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/021-Role-strimzi-cluster-operator-role14480637797854033464.yaml in namespace infra-namespace
2022-04-04 19:52:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-04 19:52:35 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRole-strimzi-kafka-broker.yaml
2022-04-04 19:52:35 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/030-Role-strimzi-kafka-broker16888401248999057737.yaml in namespace infra-namespace
2022-04-04 19:52:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-broker in namespace infra-namespace
2022-04-04 19:52:35 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-ClusterRole-strimzi-entity-operator.yaml
2022-04-04 19:52:35 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/031-Role-strimzi-entity-operator7894695647120030336.yaml in namespace infra-namespace
2022-04-04 19:52:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-entity-operator in namespace infra-namespace
2022-04-04 19:52:35 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRole-strimzi-kafka-client.yaml
2022-04-04 19:52:35 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/033-Role-strimzi-kafka-client6246103646558526058.yaml in namespace infra-namespace
2022-04-04 19:52:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-client in namespace infra-namespace
2022-04-04 19:52:35 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml
2022-04-04 19:52:35 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/020-Role-strimzi-cluster-operator5745109112181066663.yaml in namespace infra-namespace
2022-04-04 19:52:35 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:52:35 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml
2022-04-04 19:52:35 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/031-Role-strimzi-cluster-operator-entity-operator-delegation11725764748893912128.yaml in namespace infra-namespace
2022-04-04 19:52:35 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 19:52:35 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml
2022-04-04 19:52:35 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/020-Role-strimzi-cluster-operator17855570883795118283.yaml in namespace infra-namespace
2022-04-04 19:52:35 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:52:35 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml
2022-04-04 19:52:35 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/031-Role-strimzi-cluster-operator-entity-operator-delegation13007651318415751260.yaml in namespace infra-namespace
2022-04-04 19:52:35 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 19:52:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:52:35 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 19:52:50 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 19:52:50 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 19:53:00 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 19:53:00 [main] [32mINFO [m [ClusterOperatorRbacIsolatedST:99] Deploying Kafka: my-cluster-5d981a32, which should not be deployed and error should be present in CR status message
2022-04-04 19:53:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5d981a32 in namespace infra-namespace
2022-04-04 19:53:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-5d981a32-kafka-clients in namespace infra-namespace
2022-04-04 19:53:33 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-5d981a32-kafka-clients will be ready
2022-04-04 19:53:35 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-5d981a32-kafka-clients is ready
2022-04-04 19:53:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-5d981a32-scraper in namespace infra-namespace
2022-04-04 19:53:35 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-5d981a32-scraper will be ready
2022-04-04 19:53:37 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-5d981a32-scraper is ready
2022-04-04 19:53:37 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-5d981a32-scraper to be ready
2022-04-04 19:53:47 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-5d981a32-scraper is ready
2022-04-04 19:53:47 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-5d981a32-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 19:53:47 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-5d981a32-allow in namespace infra-namespace
2022-04-04 19:53:47 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 19:53:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-5d981a32 in namespace infra-namespace
2022-04-04 19:53:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:53:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCRBDeletionErrorsWhenRackAwarenessIsEnabled
2022-04-04 19:53:48 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-5d981a32-scraper in namespace infra-namespace
2022-04-04 19:53:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-5d981a32 in namespace infra-namespace
2022-04-04 19:53:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-5d981a32-allow in namespace infra-namespace
2022-04-04 19:53:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-5d981a32-kafka-clients in namespace infra-namespace
2022-04-04 19:53:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5d981a32 in namespace infra-namespace
2022-04-04 19:54:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:54:28 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST.testCRBDeletionErrorsWhenRackAwarenessIsEnabled-FINISHED
2022-04-04 19:54:28 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:54:28 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:54:28 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST.testCRBDeletionErrorIsIgnoredWhenRackAwarenessIsNotEnabled-STARTED
2022-04-04 19:54:28 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:54:28 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 19:54:28 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 19:54:28 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 19:54:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:54:28 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 19:54:28 [main] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-04 19:54:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 19:54:28 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-04 19:54:28 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:54:28 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:54:28 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-04 19:54:28 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-broker in namespace infra-namespace
2022-04-04 19:54:28 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:54:28 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:54:28 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 19:54:28 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-client in namespace infra-namespace
2022-04-04 19:54:28 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 19:54:28 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 19:54:28 [main] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-broker in namespace infra-namespace
2022-04-04 19:54:28 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-entity-operator in namespace infra-namespace
2022-04-04 19:54:28 [main] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-04 19:54:28 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:54:28 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 19:54:28 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 19:54:28 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:54:38 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 19:54:38 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 19:54:38 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-entity-operator in namespace infra-namespace
2022-04-04 19:54:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 19:54:38 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-client in namespace infra-namespace
2022-04-04 19:54:38 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:54:38 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 19:54:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:54:54 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@4e1f8140, extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6, clusterOperatorName='strimzi-cluster-operator', namespaceInstallTo='infra-namespace', namespaceToWatch='infra-namespace', bindingsNamespaces=[infra-namespace], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[], extraLabels={}, clusterOperatorRBACType=NAMESPACE, testClassName='null', testMethodName='null'}
2022-04-04 19:54:54 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 19:54:54 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 19:54:54 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 19:54:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:54:54 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-04 19:54:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-04 19:54:54 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-04 19:54:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-04 19:54:54 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRole-strimzi-kafka-broker.yaml
2022-04-04 19:54:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-broker in namespace infra-namespace
2022-04-04 19:54:54 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-ClusterRole-strimzi-entity-operator.yaml
2022-04-04 19:54:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-entity-operator in namespace infra-namespace
2022-04-04 19:54:54 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRole-strimzi-kafka-client.yaml
2022-04-04 19:54:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-client in namespace infra-namespace
2022-04-04 19:54:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 19:54:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 19:54:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 19:54:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 19:54:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:54:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:54:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 19:54:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 19:54:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 19:54:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 19:54:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:54:54 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 19:54:54 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-04 19:54:54 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/020-Role-strimzi-cluster-operator-role16905610523643351226.yaml in namespace infra-namespace
2022-04-04 19:54:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-04 19:54:54 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-04 19:54:54 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/021-Role-strimzi-cluster-operator-role10628537634672271048.yaml in namespace infra-namespace
2022-04-04 19:54:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-04 19:54:54 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRole-strimzi-kafka-broker.yaml
2022-04-04 19:54:54 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/030-Role-strimzi-kafka-broker10940321379386710451.yaml in namespace infra-namespace
2022-04-04 19:54:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-broker in namespace infra-namespace
2022-04-04 19:54:54 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-ClusterRole-strimzi-entity-operator.yaml
2022-04-04 19:54:54 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/031-Role-strimzi-entity-operator11224400885935095473.yaml in namespace infra-namespace
2022-04-04 19:54:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-entity-operator in namespace infra-namespace
2022-04-04 19:54:54 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRole-strimzi-kafka-client.yaml
2022-04-04 19:54:54 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/033-Role-strimzi-kafka-client4654684236109830691.yaml in namespace infra-namespace
2022-04-04 19:54:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-client in namespace infra-namespace
2022-04-04 19:54:54 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml
2022-04-04 19:54:54 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/020-Role-strimzi-cluster-operator12293456343651644867.yaml in namespace infra-namespace
2022-04-04 19:54:54 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:54:54 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml
2022-04-04 19:54:54 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/031-Role-strimzi-cluster-operator-entity-operator-delegation2366978483928557663.yaml in namespace infra-namespace
2022-04-04 19:54:54 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 19:54:54 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml
2022-04-04 19:54:54 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/020-Role-strimzi-cluster-operator5713667694172388577.yaml in namespace infra-namespace
2022-04-04 19:54:54 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:54:54 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml
2022-04-04 19:54:54 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/031-Role-strimzi-cluster-operator-entity-operator-delegation14835846180708885132.yaml in namespace infra-namespace
2022-04-04 19:54:54 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 19:54:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:54:54 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 19:55:14 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 19:55:14 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 19:55:24 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 19:55:24 [main] [32mINFO [m [ClusterOperatorRbacIsolatedST:63] Deploying Kafka: my-cluster-cf679c3a, which should be deployed even the CRBs are not present
2022-04-04 19:55:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-cf679c3a in namespace infra-namespace
2022-04-04 19:55:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-cf679c3a will have desired state: Ready
2022-04-04 19:56:44 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-cf679c3a is in desired state: Ready
2022-04-04 19:56:44 [main] [32mINFO [m [ClusterOperatorRbacIsolatedST:67] CO log should contain some information about ignoring forbidden access to CRB for Kafka
2022-04-04 19:56:44 [main] [32mINFO [m [ClusterOperatorRbacIsolatedST:71] Deploying KafkaConnect: my-cluster-cf679c3a without rack awareness, the CR should be deployed without error
2022-04-04 19:56:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-cf679c3a in namespace infra-namespace
2022-04-04 19:56:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-cf679c3a will have desired state: Ready
2022-04-04 19:57:46 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-cf679c3a is in desired state: Ready
2022-04-04 19:57:46 [main] [32mINFO [m [ClusterOperatorRbacIsolatedST:74] CO log should contain some information about ignoring forbidden access to CRB for KafkaConnect
2022-04-04 19:57:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:57:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCRBDeletionErrorIsIgnoredWhenRackAwarenessIsNotEnabled
2022-04-04 19:57:46 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-cf679c3a in namespace infra-namespace
2022-04-04 19:57:46 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-cf679c3a in namespace infra-namespace
2022-04-04 19:57:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:57:56 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST.testCRBDeletionErrorIsIgnoredWhenRackAwarenessIsNotEnabled-FINISHED
2022-04-04 19:57:56 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:57:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:57:56 [main] [32mINFO [m [ResourceManager:346] In context ClusterOperatorRbacIsolatedST is everything deleted.
2022-04-04 19:57:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 388.883 s - in io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.bridge.HttpBridgeIsolatedST
2022-04-04 19:57:56 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 19:58:21 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 19:58:21 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 19:58:21 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 19:58:21 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:58:21 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 19:58:21 [main] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-04 19:58:21 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 19:58:21 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-broker in namespace infra-namespace
2022-04-04 19:58:21 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:58:21 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 19:58:21 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:58:21 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-broker in namespace infra-namespace
2022-04-04 19:58:21 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:58:21 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-client in namespace infra-namespace
2022-04-04 19:58:21 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-04 19:58:21 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 19:58:21 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-client in namespace infra-namespace
2022-04-04 19:58:21 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:58:21 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:58:21 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:58:21 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-entity-operator in namespace infra-namespace
2022-04-04 19:58:21 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-entity-operator in namespace infra-namespace
2022-04-04 19:58:21 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-04 19:58:21 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 19:58:21 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-04 19:58:21 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 19:58:21 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:58:21 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 19:58:31 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 19:58:31 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 19:58:31 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 19:58:31 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 19:58:41 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:58:47 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
, extraEnvVars=[EnvVar(name=STRIMZI_CUSTOM_KAFKA_BRIDGE_SERVICE_LABELS, value=app=bar, valueFrom=null, additionalProperties={}), EnvVar(name=STRIMZI_CUSTOM_KAFKA_BRIDGE_SERVICE_ANNOTATIONS, value=bar=app, valueFrom=null, additionalProperties={})]
2022-04-04 19:58:47 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 19:58:47 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 19:58:47 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 19:58:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:58:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 19:58:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 19:58:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 19:58:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 19:58:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 19:58:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 19:58:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 19:58:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 19:58:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 19:58:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:58:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:58:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 19:58:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 19:58:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 19:58:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 19:58:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:58:47 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 19:58:47 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 19:58:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 19:58:47 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 19:58:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 19:58:47 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 19:58:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 19:58:47 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 19:58:47 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:58:47 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 19:58:47 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 19:58:47 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 19:58:47 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 19:58:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 19:58:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 19:58:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:58:47 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 19:59:13 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 19:59:13 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 19:59:23 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 19:59:23 [main] [32mINFO [m [HttpBridgeIsolatedST:434] Deploy Kafka and KafkaBridge before tests
2022-04-04 19:59:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka http-bridge-cluster-name in namespace infra-namespace
2022-04-04 19:59:23 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: http-bridge-cluster-name will have desired state: Ready
2022-04-04 20:00:32 [main] [32mINFO [m [ResourceManager:444] Kafka: http-bridge-cluster-name is in desired state: Ready
2022-04-04 20:00:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment infra-namespace-shared-kafka-clients in namespace infra-namespace
2022-04-04 20:00:32 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: infra-namespace-shared-kafka-clients will be ready
2022-04-04 20:00:33 [main] [32mINFO [m [DeploymentUtils:168] Deployment: infra-namespace-shared-kafka-clients is ready
2022-04-04 20:00:33 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge http-bridge-cluster-name in namespace infra-namespace
2022-04-04 20:00:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: http-bridge-cluster-name will have desired state: Ready
2022-04-04 20:00:59 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: http-bridge-cluster-name is in desired state: Ready
2022-04-04 20:00:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:00:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testReceiveSimpleMessage-STARTED
2022-04-04 20:00:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:00:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1863998277-1740001902 in namespace infra-namespace
2022-04-04 20:00:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1863998277-1740001902 will have desired state: Ready
2022-04-04 20:01:00 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1863998277-1740001902 is in desired state: Ready
2022-04-04 20:01:00 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 20:01:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-483965651 in namespace infra-namespace
2022-04-04 20:01:00 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-483965651 will be in active state
2022-04-04 20:01:01 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 20:01:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-1974414974 in namespace infra-namespace
2022-04-04 20:01:01 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-1974414974 will be in active state
2022-04-04 20:01:02 [main] [32mINFO [m [ClientUtils:61] Waiting till producer producer-1974414974 and consumer consumer-483965651 finish
2022-04-04 20:01:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:01:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testReceiveSimpleMessage
2022-04-04 20:01:17 [main] [32mINFO [m [ResourceManager:241] Delete of Job consumer-483965651 in namespace infra-namespace
2022-04-04 20:01:17 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1863998277-1740001902 in namespace infra-namespace
2022-04-04 20:01:17 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job producer-1974414974 in namespace infra-namespace
2022-04-04 20:01:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:01:27 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testReceiveSimpleMessage-FINISHED
2022-04-04 20:01:27 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:01:27 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:01:27 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testConfigureDeploymentStrategy-STARTED
2022-04-04 20:01:27 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:01:27 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge example-bridge in namespace infra-namespace
2022-04-04 20:01:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: example-bridge will have desired state: Ready
2022-04-04 20:01:49 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: example-bridge is in desired state: Ready
2022-04-04 20:01:49 [main] [32mINFO [m [HttpBridgeIsolatedST:351] Adding label to KafkaBridge resource, the CR should be recreated
2022-04-04 20:01:49 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: example-bridge-bridge will be ready
2022-04-04 20:01:49 [main] [32mINFO [m [DeploymentUtils:168] Deployment: example-bridge-bridge is ready
2022-04-04 20:01:49 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment example-bridge-bridge to be ready
2022-04-04 20:02:25 [main] [32mINFO [m [DeploymentUtils:197] Deployment example-bridge-bridge is ready
2022-04-04 20:02:25 [main] [32mINFO [m [HttpBridgeIsolatedST:358] Checking that observed gen. is still on 1 (recreation) and new label is present
2022-04-04 20:02:25 [main] [32mINFO [m [HttpBridgeIsolatedST:363] Changing deployment strategy to ROLLING_UPDATE
2022-04-04 20:02:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: example-bridge will have desired state: Ready
2022-04-04 20:02:25 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: example-bridge is in desired state: Ready
2022-04-04 20:02:25 [main] [32mINFO [m [HttpBridgeIsolatedST:368] Adding another label to KafkaBridge resource, pods should be rolled
2022-04-04 20:02:25 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: example-bridge-bridge will be ready
2022-04-04 20:02:25 [main] [32mINFO [m [DeploymentUtils:168] Deployment: example-bridge-bridge is ready
2022-04-04 20:02:25 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment example-bridge-bridge to be ready
2022-04-04 20:03:02 [main] [32mINFO [m [DeploymentUtils:197] Deployment example-bridge-bridge is ready
2022-04-04 20:03:02 [main] [32mINFO [m [HttpBridgeIsolatedST:372] Checking that observed gen. higher (rolling update) and label is changed
2022-04-04 20:03:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:03:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigureDeploymentStrategy
2022-04-04 20:03:02 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge example-bridge in namespace infra-namespace
2022-04-04 20:03:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:03:12 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testConfigureDeploymentStrategy-FINISHED
2022-04-04 20:03:12 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:03:12 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:03:12 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testScaleBridgeToZero-STARTED
2022-04-04 20:03:12 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:03:12 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge scaling-bridge-down in namespace infra-namespace
2022-04-04 20:03:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: scaling-bridge-down will have desired state: Ready
2022-04-04 20:03:34 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: scaling-bridge-down is in desired state: Ready
2022-04-04 20:03:34 [main] [32mINFO [m [HttpBridgeIsolatedST:285] Scaling KafkaBridge to zero replicas
2022-04-04 20:03:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: http-bridge-cluster-name will have desired state: Ready
2022-04-04 20:03:34 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: http-bridge-cluster-name is in desired state: Ready
2022-04-04 20:03:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:03:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleBridgeToZero
2022-04-04 20:03:36 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge scaling-bridge-down in namespace infra-namespace
2022-04-04 20:03:46 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:03:46 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testScaleBridgeToZero-FINISHED
2022-04-04 20:03:46 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:03:46 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:03:46 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testDiscoveryAnnotation-STARTED
2022-04-04 20:03:46 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:03:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:03:46 [main] [32mINFO [m [ResourceManager:346] In context testDiscoveryAnnotation is everything deleted.
2022-04-04 20:03:46 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:03:46 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testDiscoveryAnnotation-FINISHED
2022-04-04 20:03:46 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:03:46 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:03:46 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testCustomBridgeLabelsAreProperlySet-STARTED
2022-04-04 20:03:46 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:03:46 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge bridge-my-cluster-f30093da in namespace infra-namespace
2022-04-04 20:03:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: bridge-my-cluster-f30093da will have desired state: Ready
2022-04-04 20:04:05 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: bridge-my-cluster-f30093da is in desired state: Ready
2022-04-04 20:04:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:04:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCustomBridgeLabelsAreProperlySet
2022-04-04 20:04:05 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge bridge-my-cluster-f30093da in namespace infra-namespace
2022-04-04 20:04:15 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:04:15 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testCustomBridgeLabelsAreProperlySet-FINISHED
2022-04-04 20:04:15 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:04:15 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:04:15 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testScaleBridgeSubresource-STARTED
2022-04-04 20:04:15 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:04:15 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge scaling-bridge-up in namespace infra-namespace
2022-04-04 20:04:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: scaling-bridge-up will have desired state: Ready
2022-04-04 20:04:39 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: scaling-bridge-up is in desired state: Ready
2022-04-04 20:04:39 [main] [32mINFO [m [HttpBridgeIsolatedST:312] -------> Scaling KafkaBridge subresource <-------
2022-04-04 20:04:39 [main] [32mINFO [m [HttpBridgeIsolatedST:313] Scaling subresource replicas to 4
2022-04-04 20:04:40 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: scaling-bridge-up-bridge will be ready
2022-04-04 20:04:40 [main] [32mINFO [m [DeploymentUtils:168] Deployment: scaling-bridge-up-bridge is ready
2022-04-04 20:04:40 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 4 Pod(s) of Deployment scaling-bridge-up-bridge to be ready
2022-04-04 20:05:15 [main] [32mINFO [m [DeploymentUtils:197] Deployment scaling-bridge-up-bridge is ready
2022-04-04 20:05:15 [main] [32mINFO [m [HttpBridgeIsolatedST:317] Check if replicas is set to 4, naming prefix should be same and observed generation higher
2022-04-04 20:05:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:05:15 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleBridgeSubresource
2022-04-04 20:05:15 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge scaling-bridge-up in namespace infra-namespace
2022-04-04 20:05:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:05:25 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testScaleBridgeSubresource-FINISHED
2022-04-04 20:05:25 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:05:25 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:05:25 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testCustomAndUpdatedValues-STARTED
2022-04-04 20:05:25 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:05:25 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge custom-bridge in namespace infra-namespace
2022-04-04 20:05:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: custom-bridge will have desired state: Ready
2022-04-04 20:06:04 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: custom-bridge is in desired state: Ready
2022-04-04 20:06:04 [main] [32mINFO [m [HttpBridgeIsolatedST:225] Verify values before update
2022-04-04 20:06:04 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix custom-bridge-bridge in pod name
2022-04-04 20:06:04 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container custom-bridge-bridge
2022-04-04 20:06:04 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name custom-bridge-bridge
2022-04-04 20:06:04 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container custom-bridge-bridge
2022-04-04 20:06:04 [main] [32mINFO [m [HttpBridgeIsolatedST:230] Check if actual env variable KAFKA_BRIDGE_PRODUCER_CONFIG has different value than test.value
2022-04-04 20:06:04 [main] [32mINFO [m [HttpBridgeIsolatedST:236] Updating values in Bridge container
2022-04-04 20:06:04 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment custom-bridge-bridge rolling update
2022-04-04 20:06:44 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: custom-bridge-bridge will be ready
2022-04-04 20:06:44 [main] [32mINFO [m [DeploymentUtils:168] Deployment: custom-bridge-bridge is ready
2022-04-04 20:06:54 [main] [32mINFO [m [DeploymentUtils:141] Deployment custom-bridge-bridge rolling update finished
2022-04-04 20:06:54 [main] [32mINFO [m [HttpBridgeIsolatedST:253] Verify values after update
2022-04-04 20:06:54 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix custom-bridge-bridge in pod name
2022-04-04 20:06:54 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container custom-bridge-bridge
2022-04-04 20:06:54 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name custom-bridge-bridge
2022-04-04 20:06:54 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container custom-bridge-bridge
2022-04-04 20:06:54 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name custom-bridge-bridge
2022-04-04 20:06:54 [main] [32mINFO [m [AbstractST:194] Testing configuration for container custom-bridge-bridge
2022-04-04 20:06:54 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name custom-bridge-bridge
2022-04-04 20:06:54 [main] [32mINFO [m [AbstractST:194] Testing configuration for container custom-bridge-bridge
2022-04-04 20:06:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:06:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCustomAndUpdatedValues
2022-04-04 20:06:54 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge custom-bridge in namespace infra-namespace
2022-04-04 20:07:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:07:04 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testCustomAndUpdatedValues-FINISHED
2022-04-04 20:07:04 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:07:04 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:07:04 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testSendSimpleMessage-STARTED
2022-04-04 20:07:04 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:07:04 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 20:07:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1643068181-88432434 in namespace infra-namespace
2022-04-04 20:07:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1643068181-88432434 will have desired state: Ready
2022-04-04 20:07:05 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1643068181-88432434 is in desired state: Ready
2022-04-04 20:07:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-1811902213 in namespace infra-namespace
2022-04-04 20:07:05 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-1811902213 will be in active state
2022-04-04 20:07:06 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:producer-1811902213 to finished
2022-04-04 20:08:55 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 20:08:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-1271689699 in namespace infra-namespace
2022-04-04 20:08:55 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-1271689699 will be in active state
2022-04-04 20:08:56 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:consumer-1271689699 to finished
2022-04-04 20:09:06 [main] [32mINFO [m [AbstractST:311] Verifying labels on pod type my-bridge
2022-04-04 20:09:06 [main] [32mINFO [m [AbstractST:356] Verifying labels for Kafka Connect Services
2022-04-04 20:09:06 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:09:06 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendSimpleMessage
2022-04-04 20:09:06 [main] [32mINFO [m [ResourceManager:241] Delete of Job producer-1811902213 in namespace infra-namespace
2022-04-04 20:09:06 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1643068181-88432434 in namespace infra-namespace
2022-04-04 20:09:06 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job consumer-1271689699 in namespace infra-namespace
2022-04-04 20:09:16 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:09:16 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testSendSimpleMessage-FINISHED
2022-04-04 20:09:16 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:09:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:09:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for HttpBridgeIsolatedST
2022-04-04 20:09:16 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment infra-namespace-shared-kafka-clients in namespace infra-namespace
2022-04-04 20:09:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge http-bridge-cluster-name in namespace infra-namespace
2022-04-04 20:09:16 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka http-bridge-cluster-name in namespace infra-namespace
2022-04-04 20:10:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 729.544 s - in io.strimzi.systemtest.bridge.HttpBridgeIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.specific.HelmChartIsolatedST
2022-04-04 20:10:06 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:10:31 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 20:10:31 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 20:10:31 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 20:10:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:10:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 20:10:31 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:10:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:10:31 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:10:31 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:10:31 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:10:31 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:10:31 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:10:31 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:10:31 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:10:31 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:10:31 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:10:31 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:10:31 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:10:31 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:10:31 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:10:31 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:10:31 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:10:31 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 20:10:31 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:10:31 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:10:31 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:10:31 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:10:41 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:10:41 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:10:41 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:10:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:10:57 [main] [32mINFO [m [HelmChartIsolatedST:67] Creating resources before the test class
2022-04-04 20:10:57 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 20:10:57 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:10:57 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: kube-system
2022-04-04 20:10:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace kube-system apply -f -
2022-04-04 20:10:57 [main] [32mINFO [m [Exec:417] Input: apiVersion: v1
kind: ServiceAccount
metadata:
  name: tiller
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: tiller
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
  - kind: ServiceAccount
    name: tiller
    namespace: kube-system
2022-04-04 20:10:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 20:10:57 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:10:57 [main] [32mINFO [m [HelmClient:44] Installing helm-chart strimzi-systemtests
2022-04-04 20:11:16 [main] [32mINFO [m [Exec:417] Command: helm install strimzi-systemtests --set defaultImageRegistry=quay.io,defaultImageRepository=strimzi,fullReconciliationIntervalMs=30000,kafkaBridge.image.tag=latest,resources.limits.memory=512Mi,kafkaBridge.image.repository=strimzi,featureGates=,image.imagePullPolicy=Always,watchAnyNamespace=false,resources.requests.memory=512Mi,operationTimeoutMs=300000,resources.limits.cpu=1000m,logLevelOverride=DEBUG,defaultImageTag=latest,resources.requests.cpu=200m,kafkaBridge.image.registry=quay.io --timeout 120s --debug /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/helm-charts/helm3/strimzi-kafka-operator --namespace infra-namespace --wait
2022-04-04 20:11:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 20:11:16 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 20:11:16 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 20:11:16 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:11:16 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.specific.HelmChartIsolatedST.testStrimziComponentsViaHelmChart-STARTED
2022-04-04 20:11:16 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:11:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-eb9ca934-kafka-clients in namespace infra-namespace
2022-04-04 20:11:16 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-eb9ca934-kafka-clients will be ready
2022-04-04 20:11:18 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-eb9ca934-kafka-clients is ready
2022-04-04 20:11:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-eb9ca934 in namespace infra-namespace
2022-04-04 20:11:18 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-eb9ca934 will have desired state: Ready
2022-04-04 20:12:50 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-eb9ca934 is in desired state: Ready
2022-04-04 20:12:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-eb9ca934-scraper in namespace infra-namespace
2022-04-04 20:12:50 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-eb9ca934-scraper will be ready
2022-04-04 20:12:52 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-eb9ca934-scraper is ready
2022-04-04 20:12:52 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-eb9ca934-scraper to be ready
2022-04-04 20:13:03 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-eb9ca934-scraper is ready
2022-04-04 20:13:03 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-eb9ca934-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 20:13:03 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-eb9ca934-allow in namespace infra-namespace
2022-04-04 20:13:03 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 20:13:03 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1079506018-659103206 in namespace infra-namespace
2022-04-04 20:13:03 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-eb9ca934 in namespace infra-namespace
2022-04-04 20:13:03 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge my-cluster-eb9ca934 in namespace infra-namespace
2022-04-04 20:13:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1079506018-659103206 will have desired state: Ready
2022-04-04 20:13:05 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1079506018-659103206 is in desired state: Ready
2022-04-04 20:13:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-eb9ca934 will have desired state: Ready
2022-04-04 20:14:22 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-eb9ca934 is in desired state: Ready
2022-04-04 20:14:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: my-cluster-eb9ca934 will have desired state: Ready
2022-04-04 20:14:22 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: my-cluster-eb9ca934 is in desired state: Ready
2022-04-04 20:14:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-eb9ca934 in namespace infra-namespace
2022-04-04 20:14:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-eb9ca934 will have desired state: Ready
2022-04-04 20:14:23 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-eb9ca934 is in desired state: Ready
2022-04-04 20:14:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:14:23 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testStrimziComponentsViaHelmChart
2022-04-04 20:14:23 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-eb9ca934 in namespace infra-namespace
2022-04-04 20:14:23 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-eb9ca934-allow in namespace infra-namespace
2022-04-04 20:14:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-eb9ca934-scraper in namespace infra-namespace
2022-04-04 20:14:23 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-eb9ca934 in namespace infra-namespace
2022-04-04 20:14:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1079506018-659103206 in namespace infra-namespace
2022-04-04 20:14:23 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-eb9ca934 in namespace infra-namespace
2022-04-04 20:14:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge my-cluster-eb9ca934 in namespace infra-namespace
2022-04-04 20:14:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-eb9ca934-kafka-clients in namespace infra-namespace
2022-04-04 20:15:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:15:23 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.specific.HelmChartIsolatedST.testStrimziComponentsViaHelmChart-FINISHED
2022-04-04 20:15:23 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:15:23 [main] [32mINFO [m [HelmClient:71] Deleting helm-chart:strimzi-systemtests in namespace:infra-namespace
2022-04-04 20:15:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:15:23 [main] [32mINFO [m [ResourceManager:348] Delete all resources for HelmChartIsolatedST
2022-04-04 20:15:23 [main] [32mINFO [m [HelmClient:71] Deleting helm-chart:strimzi-systemtests in namespace:infra-namespace
2022-04-04 20:15:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:15:23 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 20:15:23 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 20:15:23 [main] [33mWARN [m [KubeClusterResource:151] Namespace infra-namespace is already created, going to delete it
2022-04-04 20:15:34 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 20:15:34 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:15:34 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:15:34 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:15:34 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:15:34 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:15:34 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:15:34 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:15:34 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:15:35 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:15:35 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:15:35 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:15:35 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:15:35 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:15:35 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:15:35 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:15:35 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:15:35 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:15:35 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:15:35 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 20:15:35 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:15:35 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:15:35 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 20:15:35 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:15:35 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 20:15:35 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:15:35 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:15:35 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:15:35 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 20:15:35 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:15:35 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 20:15:35 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 20:15:35 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:15:35 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 20:15:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:15:35 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 20:15:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 20:15:48 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 20:15:58 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 352.349 s - in io.strimzi.systemtest.specific.HelmChartIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.specific.SpecificIsolatedST
2022-04-04 20:15:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:16:23 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 20:16:23 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 20:16:23 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 20:16:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:16:23 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 20:16:23 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:16:23 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:16:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:16:23 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:16:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:16:23 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:16:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:16:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:16:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:16:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:16:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:16:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:16:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:16:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:16:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:16:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:16:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:16:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:16:23 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:16:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:16:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 20:16:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:16:33 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:16:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:16:33 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:16:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:16:48 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 20:16:48 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 20:16:48 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 20:16:49 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:16:49 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 20:16:49 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:16:49 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 20:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:16:49 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 20:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:16:49 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:16:49 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 20:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:16:49 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 20:16:49 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 20:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 20:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:16:49 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 20:17:09 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 20:17:09 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 20:17:19 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 20:17:19 [main] [32mINFO [m [SpecificIsolatedST:508] 0.21.4
2022-04-04 20:17:19 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:17:19 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.specific.SpecificIsolatedST.testRackAware-STARTED
2022-04-04 20:17:19 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:17:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5f83935a in namespace infra-namespace
2022-04-04 20:17:19 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5f83935a will have desired state: Ready
2022-04-04 20:18:35 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5f83935a is in desired state: Ready
2022-04-04 20:18:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-5f83935a-kafka-0 -- /bin/bash -c cat /opt/kafka/init/rack.id
2022-04-04 20:18:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 20:18:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-5f83935a-kafka-0 -- /bin/bash -c cat /tmp/strimzi.properties | grep broker.rack
2022-04-04 20:18:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 20:18:36 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 20:18:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-producer in namespace infra-namespace
2022-04-04 20:18:36 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-producer will be in active state
2022-04-04 20:18:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-consumer in namespace infra-namespace
2022-04-04 20:18:37 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-consumer will be in active state
2022-04-04 20:18:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:18:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRackAware
2022-04-04 20:18:38 [main] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-producer in namespace infra-namespace
2022-04-04 20:18:38 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5f83935a in namespace infra-namespace
2022-04-04 20:18:38 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-consumer in namespace infra-namespace
2022-04-04 20:18:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:18:48 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.specific.SpecificIsolatedST.testRackAware-FINISHED
2022-04-04 20:18:48 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:18:48 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:18:48 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.specific.SpecificIsolatedST.testRackAwareConnectWrongDeployment-STARTED
2022-04-04 20:18:48 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:18:48 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 20:18:48 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 20:18:48 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 20:18:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:18:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 20:18:48 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:18:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:18:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:18:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:18:48 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:18:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:18:48 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:18:48 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:18:48 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:18:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:18:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:18:48 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:18:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:18:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:18:48 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:18:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 20:18:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:18:48 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:18:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:18:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:18:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:18:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:18:58 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:18:58 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:18:58 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:19:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:19:13 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@4e1f8140, extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6, clusterOperatorName='strimzi-cluster-operator', namespaceInstallTo='infra-namespace', namespaceToWatch='infra-namespace', bindingsNamespaces=[infra-namespace], operationTimeout=30000, reconciliationInterval=30000, extraEnvVars=[], extraLabels={}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-04 20:19:13 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 20:19:13 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 20:19:13 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:19:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:19:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:19:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:19:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:19:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:19:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:19:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:19:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:19:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:19:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:19:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:19:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:19:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:19:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:19:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:19:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:19:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:19:14 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 20:19:14 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:19:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:19:14 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 20:19:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:19:14 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 20:19:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:19:14 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:19:14 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:19:14 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 20:19:14 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:19:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:19:14 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 20:19:34 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 20:19:34 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 20:19:44 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 20:19:44 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment strimzi-cluster-operator rolling update
2022-04-04 20:19:44 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 20:19:44 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 20:19:54 [main] [32mINFO [m [DeploymentUtils:141] Deployment strimzi-cluster-operator rolling update finished
2022-04-04 20:19:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a85680ac in namespace infra-namespace
2022-04-04 20:19:54 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a85680ac will have desired state: Ready
2022-04-04 20:21:09 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a85680ac is in desired state: Ready
2022-04-04 20:21:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a85680ac-kafka-clients in namespace infra-namespace
2022-04-04 20:21:09 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a85680ac-kafka-clients will be ready
2022-04-04 20:21:11 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a85680ac-kafka-clients is ready
2022-04-04 20:21:11 [main] [32mINFO [m [SpecificIsolatedST:196] Deploy KafkaConnect with wrong rack-aware topology key: wrong-key
2022-04-04 20:21:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a85680ac-scraper in namespace infra-namespace
2022-04-04 20:21:11 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a85680ac-scraper will be ready
2022-04-04 20:21:13 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a85680ac-scraper is ready
2022-04-04 20:21:13 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-a85680ac-scraper to be ready
2022-04-04 20:21:23 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-a85680ac-scraper is ready
2022-04-04 20:21:23 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-a85680ac-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 20:21:23 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-a85680ac-allow in namespace infra-namespace
2022-04-04 20:21:23 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 20:21:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-a85680ac in namespace infra-namespace
2022-04-04 20:21:23 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-a85680ac-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 20:21:23 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-a85680ac-allow in namespace infra-namespace
2022-04-04 20:21:23 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 20:21:23 [main] [32mINFO [m [PodUtils:277] Wait for at least one pod with prefix: my-cluster-a85680ac-connect will be in pending phase
2022-04-04 20:21:24 [main] [32mINFO [m [SpecificIsolatedST:227] Waiting for ClusterOperator to get timeout operation of incorrectly set up KafkaConnect
2022-04-04 20:21:54 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-a85680ac will have desired state: Ready
2022-04-04 20:23:38 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-a85680ac is in desired state: Ready
2022-04-04 20:23:38 [main] [32mINFO [m [SpecificIsolatedST:238] KafkaConnect is ready with changed rack key: 'rack-key'.
2022-04-04 20:23:38 [main] [32mINFO [m [SpecificIsolatedST:239] Verify KafkaConnect rack key update
2022-04-04 20:23:38 [main] [32mINFO [m [KafkaConnectUtils:156] Send and receive messages through KafkaConnect
2022-04-04 20:23:38 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-04 20:23:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-a85680ac-connect-7c496cfc64-4xps4 -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-04 20:23:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 20:23:38 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-04 20:23:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-a85680ac-scraper-998f6f6b8-qtthh -- /bin/bash -c curl -X POST -H "Content-Type: application/json" --data '{ "name": "sink-test", "config": { "connector.class": "FileStreamSink", "tasks.max": "1", "topics": "my-topic-335653399-1112350690", "file": "/tmp/test-file-sink.txt" } }' http://my-cluster-a85680ac-connect-api.infra-namespace.svc:8083/connectors
2022-04-04 20:23:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 20:23:38 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 20:23:38 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@11252b76, messages=[], arguments=[--topic, my-topic-335653399-1112350690, --max-messages, 100, --bootstrap-server, my-cluster-a85680ac-kafka-bootstrap.infra-namespace.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-a85680ac-kafka-clients-57447c7985-2j8hh', podNamespace='infra-namespace', bootstrapServer='my-cluster-a85680ac-kafka-bootstrap.infra-namespace.svc:9092', topicName='my-topic-335653399-1112350690', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@561bb13a}
2022-04-04 20:23:38 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-a85680ac-kafka-bootstrap.infra-namespace.svc:9092:my-topic-335653399-1112350690 from pod my-cluster-a85680ac-kafka-clients-57447c7985-2j8hh
2022-04-04 20:23:38 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a85680ac-kafka-clients-57447c7985-2j8hh -n infra-namespace -- /opt/kafka/producer.sh --topic my-topic-335653399-1112350690 --max-messages 100 --bootstrap-server my-cluster-a85680ac-kafka-bootstrap.infra-namespace.svc:9092
2022-04-04 20:23:41 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 20:23:41 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 20:23:41 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@320f3ae7, messages=[], arguments=[--topic, my-topic-335653399-1112350690, --max-messages, 100, --group-instance-id, instance1793652577, --group-id, my-consumer-group-1202675320, --bootstrap-server, my-cluster-a85680ac-kafka-bootstrap.infra-namespace.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a85680ac-kafka-clients-57447c7985-2j8hh', podNamespace='infra-namespace', bootstrapServer='my-cluster-a85680ac-kafka-bootstrap.infra-namespace.svc:9092', topicName='my-topic-335653399-1112350690', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1202675320', consumerInstanceId='instance1793652577', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@25fc78ef}
2022-04-04 20:23:41 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-a85680ac-kafka-bootstrap.infra-namespace.svc:9092#my-topic-335653399-1112350690 from pod my-cluster-a85680ac-kafka-clients-57447c7985-2j8hh
2022-04-04 20:23:41 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a85680ac-kafka-clients-57447c7985-2j8hh -n infra-namespace -- /opt/kafka/consumer.sh --topic my-topic-335653399-1112350690 --max-messages 100 --group-instance-id instance1793652577 --group-id my-consumer-group-1202675320 --bootstrap-server my-cluster-a85680ac-kafka-bootstrap.infra-namespace.svc:9092
2022-04-04 20:23:46 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 20:23:46 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 20:23:46 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-a85680ac-connect-7c496cfc64-4xps4
2022-04-04 20:23:46 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-a85680ac-connect-7c496cfc64-4xps4
2022-04-04 20:23:46 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 20:23:46 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 20:23:46 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 20:23:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:23:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 20:23:46 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:23:46 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:23:46 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:23:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:23:46 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:23:46 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:23:46 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:23:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:23:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:23:46 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:23:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:23:46 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:23:46 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:23:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:23:46 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:23:47 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:23:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:23:57 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:23:57 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:23:57 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:23:57 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:23:57 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:23:57 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:24:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:24:55 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@4e1f8140, extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6, clusterOperatorName='strimzi-cluster-operator', namespaceInstallTo='infra-namespace', namespaceToWatch='infra-namespace', bindingsNamespaces=[infra-namespace], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[], extraLabels={}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-04 20:24:55 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 20:24:55 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 20:24:55 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:24:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:24:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:24:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:24:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:24:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:24:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:24:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:24:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:24:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:24:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:24:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:24:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:24:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:24:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:24:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:24:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:24:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:24:56 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 20:24:56 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:24:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:24:56 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 20:24:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:24:56 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 20:24:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:24:56 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:24:56 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:24:56 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 20:24:56 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:24:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:24:56 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 20:25:20 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 20:25:20 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 20:25:30 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 20:25:30 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment strimzi-cluster-operator rolling update
2022-04-04 20:25:30 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 20:25:30 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 20:25:40 [main] [32mINFO [m [DeploymentUtils:141] Deployment strimzi-cluster-operator rolling update finished
2022-04-04 20:25:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:25:40 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRackAwareConnectWrongDeployment
2022-04-04 20:25:40 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-a85680ac-allow in namespace infra-namespace
2022-04-04 20:25:40 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-a85680ac-allow in namespace infra-namespace
2022-04-04 20:25:40 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a85680ac-scraper in namespace infra-namespace
2022-04-04 20:25:40 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-a85680ac in namespace infra-namespace
2022-04-04 20:25:40 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a85680ac-kafka-clients in namespace infra-namespace
2022-04-04 20:25:40 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a85680ac in namespace infra-namespace
2022-04-04 20:25:40 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:25:40 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.specific.SpecificIsolatedST.testRackAwareConnectWrongDeployment-FINISHED
2022-04-04 20:25:40 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:25:40 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:25:40 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.specific.SpecificIsolatedST.testDeployUnsupportedKafka-STARTED
2022-04-04 20:25:40 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:25:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-aaf22436 in namespace infra-namespace
2022-04-04 20:25:40 [main] [32mINFO [m [SpecificIsolatedST:414] Kafka with version 6.6.6 deployed.
2022-04-04 20:25:40 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-aaf22436 will have desired state: NotReady
2022-04-04 20:25:41 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-aaf22436 is in desired state: NotReady
2022-04-04 20:25:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:25:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeployUnsupportedKafka
2022-04-04 20:25:45 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-aaf22436 in namespace infra-namespace
2022-04-04 20:25:45 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:25:45 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.specific.SpecificIsolatedST.testDeployUnsupportedKafka-FINISHED
2022-04-04 20:25:45 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:25:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:25:45 [main] [32mINFO [m [ResourceManager:346] In context SpecificIsolatedST is everything deleted.
2022-04-04 20:25:45 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 586.998 s - in io.strimzi.systemtest.specific.SpecificIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.specific.DrainCleanerIsolatedST
2022-04-04 20:25:45 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:26:10 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 20:26:10 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 20:26:10 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 20:26:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:26:10 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 20:26:10 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:26:10 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:26:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:26:10 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:26:10 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:26:10 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:26:10 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:26:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:26:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:26:10 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:26:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:26:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:26:10 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:26:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:26:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:26:10 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:26:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:26:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:26:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:26:20 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:26:20 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:26:20 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:26:20 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:26:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:26:35 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=strimzi-drain-cleaner
namespaceToWatch=strimzi-drain-cleaner
bindingsNamespaces=[strimzi-drain-cleaner]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 20:26:35 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 20:26:35 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: strimzi-drain-cleaner
2022-04-04 20:26:36 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: strimzi-drain-cleaner
2022-04-04 20:26:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-04 20:26:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:26:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:26:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:26:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:26:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:26:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:26:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:26:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:26:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:26:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:26:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:26:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:26:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:26:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:26:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:26:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-04 20:26:36 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: strimzi-drain-cleaner
2022-04-04 20:26:36 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace strimzi-drain-cleaner
2022-04-04 20:26:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:26:36 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace strimzi-drain-cleaner
2022-04-04 20:26:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:26:36 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace strimzi-drain-cleaner
2022-04-04 20:26:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:26:36 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace strimzi-drain-cleaner
2022-04-04 20:26:36 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-04 20:26:36 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace strimzi-drain-cleaner
2022-04-04 20:26:36 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace strimzi-drain-cleaner
2022-04-04 20:26:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-04 20:26:36 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 20:26:53 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 20:26:53 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 20:27:03 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 20:27:03 [main] [32mINFO [m [RequiredMinKubeApiVersionCondition:30] testDrainCleanerWithComponents is @RequiredMinKubeApiVersion with version 1.17, but the running on cluster with 1.16: Ignoring testDrainCleanerWithComponents
2022-04-04 20:27:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:27:03 [main] [32mINFO [m [ResourceManager:346] In context DrainCleanerIsolatedST is everything deleted.
2022-04-04 20:27:03 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;33mWARNING[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 2, Time elapsed: 78.219 s - in io.strimzi.systemtest.specific.DrainCleanerIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST
2022-04-04 20:27:03 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:27:28 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 20:27:28 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 20:27:28 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 20:27:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:27:28 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 20:27:28 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:27:28 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:27:28 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:27:28 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-04 20:27:28 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:27:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:27:28 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:27:28 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:27:28 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-04 20:27:28 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:27:28 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:27:28 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace strimzi-drain-cleaner
2022-04-04 20:27:28 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:27:28 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:27:28 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:27:28 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:27:28 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-04 20:27:29 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:27:29 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-04 20:27:29 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:27:29 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:27:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:27:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:27:39 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:28:05 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace,second-namespace-test
bindingsNamespaces=[infra-namespace, second-namespace-test]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 20:28:05 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 20:28:05 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 20:28:05 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: second-namespace-test
2022-04-04 20:28:05 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:28:05 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:28:05 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:28:05 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:28:05 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:28:05 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:28:05 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:28:05 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:28:05 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:28:05 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:28:05 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:28:05 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:28:05 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:28:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:28:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:28:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:28:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:28:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:28:06 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 20:28:06 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: second-namespace-test
2022-04-04 20:28:06 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:28:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:28:06 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 20:28:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:28:06 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 20:28:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:28:06 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:28:06 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:28:06 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 20:28:06 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:28:06 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:28:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:28:06 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 20:28:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:28:06 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 20:28:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:28:06 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:28:06 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace second-namespace-test
2022-04-04 20:28:06 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 20:28:06 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-namespace-test
2022-04-04 20:28:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:28:06 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 20:28:44 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 20:28:44 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 20:28:54 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 20:28:54 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-04 20:28:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster in namespace second-namespace-test
2022-04-04 20:28:54 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster will have desired state: Ready
2022-04-04 20:30:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster is in desired state: Ready
2022-04-04 20:30:21 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:30:21 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:30:21 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST.testKafkaInDifferentNsThanClusterOperator-STARTED
2022-04-04 20:30:21 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:30:21 [main] [32mINFO [m [MultipleNamespaceIsolatedST:59] Deploying Kafka in different namespace than CO when CO watches multiple namespaces
2022-04-04 20:30:21 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-04 20:30:21 [main] [32mINFO [m [AbstractNamespaceST:46] Check if Kafka Cluster my-cluster in namespace second-namespace-test
2022-04-04 20:30:21 [main] [32mINFO [m [AbstractNamespaceST:51] Kafka condition status: True
2022-04-04 20:30:21 [main] [32mINFO [m [AbstractNamespaceST:52] Kafka condition type: Ready
2022-04-04 20:30:21 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:30:21 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:30:21 [main] [32mINFO [m [ResourceManager:346] In context testKafkaInDifferentNsThanClusterOperator is everything deleted.
2022-04-04 20:30:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:30:21 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST.testKafkaInDifferentNsThanClusterOperator-FINISHED
2022-04-04 20:30:21 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:30:21 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:30:21 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST.testTopicOperatorWatchingOtherNamespace-STARTED
2022-04-04 20:30:21 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:30:21 [main] [32mINFO [m [MultipleNamespaceIsolatedST:45] Deploying TO to watch a different namespace that it is deployed in
2022-04-04 20:30:21 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-04 20:30:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace second-namespace-test exec my-cluster-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-04 20:30:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 20:30:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1561130928-1215586232 in namespace infra-namespace
2022-04-04 20:30:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1561130928-1215586232 will have desired state: Ready
2022-04-04 20:30:25 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1561130928-1215586232 is in desired state: Ready
2022-04-04 20:30:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:30:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTopicOperatorWatchingOtherNamespace
2022-04-04 20:30:25 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1561130928-1215586232 in namespace infra-namespace
2022-04-04 20:30:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:30:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST.testTopicOperatorWatchingOtherNamespace-FINISHED
2022-04-04 20:30:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:30:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:30:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST.testDeployMirrorMakerAcrossMultipleNamespace-STARTED
2022-04-04 20:30:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:30:35 [main] [32mINFO [m [MultipleNamespaceIsolatedST:69] Deploying KafkaMirrorMaker in different namespace than CO when CO watches multiple namespaces
2022-04-04 20:30:35 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-04 20:30:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-target in namespace second-namespace-test
2022-04-04 20:30:35 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-target will have desired state: Ready
2022-04-04 20:31:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-target is in desired state: Ready
2022-04-04 20:31:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster in namespace second-namespace-test
2022-04-04 20:31:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster will have desired state: Ready
2022-04-04 20:32:55 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster is in desired state: Ready
2022-04-04 20:32:55 [main] [32mINFO [m [AbstractNamespaceST:71] Waiting for creation my-cluster-mirror-maker in namespace second-namespace-test
2022-04-04 20:32:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster will have desired state: Ready
2022-04-04 20:32:55 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster is in desired state: Ready
2022-04-04 20:32:55 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-04 20:32:55 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:32:55 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeployMirrorMakerAcrossMultipleNamespace
2022-04-04 20:32:55 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster in namespace second-namespace-test
2022-04-04 20:32:55 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-target in namespace second-namespace-test
2022-04-04 20:33:05 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:33:05 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST.testDeployMirrorMakerAcrossMultipleNamespace-FINISHED
2022-04-04 20:33:05 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:33:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:33:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for MultipleNamespaceIsolatedST
2022-04-04 20:33:05 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster in namespace second-namespace-test
2022-04-04 20:33:15 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 372.007 s - in io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.watcher.AllNamespaceIsolatedST
2022-04-04 20:33:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:33:40 [main] [32mINFO [m [AllNamespaceIsolatedST:190] Creating resources before the test class
2022-04-04 20:33:40 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 20:33:40 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 20:33:40 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 20:33:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:33:40 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 20:33:40 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:33:40 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:33:40 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:33:40 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:33:40 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:33:40 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace second-namespace-test
2022-04-04 20:33:40 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:33:40 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:33:40 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:33:40 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:33:40 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:33:40 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:33:40 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:33:40 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:33:40 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:33:40 [main] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:33:40 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:33:41 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:33:41 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:33:41 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:33:41 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:33:50 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:33:51 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:33:51 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:33:51 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:33:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:33:51 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-namespace-test
2022-04-04 20:33:51 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:34:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:34:06 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace, second-namespace-test, third-namespace-test]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 20:34:06 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 20:34:06 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 20:34:06 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: second-namespace-test
2022-04-04 20:34:06 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: third-namespace-test
2022-04-04 20:34:06 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:34:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:34:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:34:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:34:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:34:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:34:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:34:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:34:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:34:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:34:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:34:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:34:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:34:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:34:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:34:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:34:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:34:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:34:07 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 20:34:07 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: second-namespace-test
2022-04-04 20:34:07 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: third-namespace-test
2022-04-04 20:34:07 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:34:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:34:07 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 20:34:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:34:07 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 20:34:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:34:07 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:34:07 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:34:07 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 20:34:07 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:34:07 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:34:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:34:07 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 20:34:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:34:07 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 20:34:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:34:07 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:34:07 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace second-namespace-test
2022-04-04 20:34:07 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 20:34:07 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-namespace-test
2022-04-04 20:34:07 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:34:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:34:07 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 20:34:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:34:07 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 20:34:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:34:07 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:34:07 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace third-namespace-test
2022-04-04 20:34:07 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 20:34:07 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace third-namespace-test
2022-04-04 20:34:07 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 20:34:07 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 20:34:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:34:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 20:34:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:34:07 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 20:34:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 20:34:27 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 20:34:37 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 20:34:37 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: third-namespace-test
2022-04-04 20:34:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster in namespace third-namespace-test
2022-04-04 20:34:37 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster will have desired state: Ready
2022-04-04 20:35:48 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster is in desired state: Ready
2022-04-04 20:35:48 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-04 20:35:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-second in namespace second-namespace-test
2022-04-04 20:35:48 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-second will have desired state: Ready
2022-04-04 20:37:10 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-second is in desired state: Ready
2022-04-04 20:37:10 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:37:10 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:37:10 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testKafkaInDifferentNsThanClusterOperator-STARTED
2022-04-04 20:37:10 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:37:10 [main] [32mINFO [m [AllNamespaceIsolatedST:82] Deploying Kafka cluster in different namespace than CO when CO watches all namespaces
2022-04-04 20:37:10 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-04 20:37:10 [main] [32mINFO [m [AbstractNamespaceST:46] Check if Kafka Cluster my-cluster-second in namespace second-namespace-test
2022-04-04 20:37:10 [main] [32mINFO [m [AbstractNamespaceST:51] Kafka condition status: True
2022-04-04 20:37:10 [main] [32mINFO [m [AbstractNamespaceST:52] Kafka condition type: Ready
2022-04-04 20:37:10 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:37:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:37:10 [main] [32mINFO [m [ResourceManager:346] In context testKafkaInDifferentNsThanClusterOperator is everything deleted.
2022-04-04 20:37:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:37:10 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testKafkaInDifferentNsThanClusterOperator-FINISHED
2022-04-04 20:37:10 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:37:10 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:37:10 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testTopicOperatorWatchingOtherNamespace-STARTED
2022-04-04 20:37:10 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:37:10 [main] [32mINFO [m [AllNamespaceIsolatedST:66] Deploying TO to watch a different namespace that it is deployed in
2022-04-04 20:37:10 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: third-namespace-test
2022-04-04 20:37:13 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace third-namespace-test exec my-cluster-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-04 20:37:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 20:37:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-562019021-964949962 in namespace second-namespace-test
2022-04-04 20:37:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-562019021-964949962 will have desired state: Ready
2022-04-04 20:37:14 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-562019021-964949962 is in desired state: Ready
2022-04-04 20:37:14 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:37:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:37:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTopicOperatorWatchingOtherNamespace
2022-04-04 20:37:14 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-562019021-964949962 in namespace second-namespace-test
2022-04-04 20:37:24 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:37:24 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testTopicOperatorWatchingOtherNamespace-FINISHED
2022-04-04 20:37:24 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:37:24 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:37:24 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testUOWatchingOtherNamespace-STARTED
2022-04-04 20:37:24 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:37:24 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-04 20:37:24 [main] [32mINFO [m [AllNamespaceIsolatedST:121] Creating user in other namespace than CO and Kafka cluster with UO
2022-04-04 20:37:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1370630507-669433604 in namespace second-namespace-test
2022-04-04 20:37:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1370630507-669433604 will have desired state: Ready
2022-04-04 20:37:25 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1370630507-669433604 is in desired state: Ready
2022-04-04 20:37:25 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:37:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:37:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUOWatchingOtherNamespace
2022-04-04 20:37:25 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1370630507-669433604 in namespace second-namespace-test
2022-04-04 20:37:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:37:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testUOWatchingOtherNamespace-FINISHED
2022-04-04 20:37:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:37:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:37:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testUserInDifferentNamespace-STARTED
2022-04-04 20:37:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:37:35 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-04 20:37:35 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1370630507-669433604 in namespace second-namespace-test
2022-04-04 20:37:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1370630507-669433604 will have desired state: Ready
2022-04-04 20:37:36 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1370630507-669433604 is in desired state: Ready
2022-04-04 20:37:36 [main] [32mINFO [m [AllNamespaceIsolatedST:137] KafkaUser condition status: True
2022-04-04 20:37:36 [main] [32mINFO [m [AllNamespaceIsolatedST:138] KafkaUser condition type: Ready
2022-04-04 20:37:36 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: third-namespace-test
2022-04-04 20:37:36 [main] [32mINFO [m [AllNamespaceIsolatedST:148] Copying secret Secret(apiVersion=v1, data={ca.crt=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, user.crt=LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUVJVENDQWdtZ0F3SUJBZ0lVZW1ZMnU4ZjJpemgwNlUxMCtLTnFrV2JyMC9Vd0RRWUpLb1pJaHZjTkFRRU4KQlFBd0xURVRNQkVHQTFVRUNnd0thVzh1YzNSeWFXMTZhVEVXTUJRR0ExVUVBd3dOWTJ4cFpXNTBjeTFqWVNCMgpNREFlRncweU1qQTBNRFF5TURNM016VmFGdzB5TXpBME1EUXlNRE0zTXpWYU1DY3hKVEFqQmdOVkJBTU1IRzE1CkxYVnpaWEl0TVRNM01EWXpNRFV3TnkwMk5qazBNek0yTURRd2dnRWlNQTBHQ1NxR1NJYjNEUUVCQVFVQUE0SUIKRHdBd2dnRUtBb0lCQVFEU0V2L1dhcG9aQmJLRnU3L1pyZjF2dDJ6b2pvVUJaNkZRTWQ3Zm5tcyt0Z2xoRE1iTwpISFdGcjlxeTFJYjNhUXZmWWswaHNTQzZuYzhhNFpnMnlmaXVXbjc3bXIrMG9qbFVJdmoyTkM1YVQxRytUaUJvCk54OHRyaEFwU1cybkNScXpMaEhBSXcxVCtqNTUwRXhkR3ROUTYzTW1ZbXN6UmtsVmtmU3dvMDlIMWkvVTh2VHkKM3RDL0dyQllheG90SmZLNVltZkFnV3pKU204Y3ZmQ3A0M3lFVXpSMUtjS0lYZytRNUZHUTAxU2dmanByQ2NUUApKaXBUbDhubTFBU2NDZXBDSTBkeHdMWjUrS1RJZ3lDbmtGMStSS0xSbzNJSlNhMmlWRkNjR1JNcVNTQ24rMmdTCnBmZUdZYVhndWFnSEFtL3FCU28xN0drMmt1Rk9ReEZURnY4VkFnTUJBQUdqUHpBOU1CMEdBMVVkRGdRV0JCU0EKTkp4ckFiekwwZUprWjZVQUp1U2t6TTBBNERBTUJnTlZIUk1CQWY4RUFqQUFNQTRHQTFVZER3RUIvd1FFQXdJRgpvREFOQmdrcWhraUc5dzBCQVEwRkFBT0NBZ0VBdm1kMWRkTTFsR1F1SlN1ZzhBSlJJQVhESkpyWGo3eFJMcEROCnN0U1RLOFVhblFCVmpqTHA3Um5weFhvSllaY0NHUFVuSUJaZml2dkprcWd5aVdiRGhJQ1NyTUNEUkNOLzQweEMKdVhqNlNGVkU2MG8wZ2dDS0RsT1p1NmtzNjhFYzJRditOOWJHMDE2eGtHSEdIR1Z4bVZ0WW92WWs4NEdDeDhnTQpNeVd2bXFqckJXUnlibjlpeFBrN29RVlQvYk5xNFVHWUU4SC85VkJJYW42SUMyeXc4TWpnTTA4VkpYRTBKb1ZhCnNmem53eHpyK1NnOG1MUEtjYnFOc0E5ak9JQzZyRUF5ZWdQUHZCZDFYV3BvbUhRNzRoTFkwZlF4M0JEdHcrYW8KWEZCamc3bTlEbkVPVU5JTzF3RXVlajVvdkswUk9oc3NrN0ZjZlZBdVNzUHRJZU9wT1B2bmhtaUxkMWo4NG13QQp3d0pvQzdtLzl0M2RVWEdCMzd4eGFiN1ZBcEtZaHo5NVlBQUMrZ3VROTBac2FkMnpkL0xoQ2U0OTFNTVYxWGZYCis1QXNYdmk1dkRNQU8xYXk1Y3JZL3ZzVGlaZlVJOHkvQmZxcXltcjlrWktZTDJLYWViNUlrbDFnQnRnWVhzL2QKYktvdEtzblJoTHpUa1FhRXlVTFNscCtWSnRLUitkbVo4OW9rUmtNVXM2MS9RcFdVdWI3aUdUTnlldHFGNERnTwpRc1diLzB1V1F5K0tMbDJhT0p4RzVob0F0eWhIT081cUx3L1BtYUxPMkNWTkFLaXczSjc0SS9hTWtYY1BUS1FLCk43TVByTGVVSzdSRDdid0pPRiswWnd2ODJZbXVpSFpwd2Z6MTkrTUVGL1BXblNHeG14ekhreFFSdzVMTmJoNmsKbXZiVmUrOD0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=, user.key=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, user.p12=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, user.password=ZmgyQ0ZOT2ZKT2NL}, immutable=null, kind=Secret, metadata=ObjectMeta(annotations=null, clusterName=null, creationTimestamp=2022-04-04T20:37:36Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-user-1370630507-669433604, app.kubernetes.io/managed-by=strimzi-user-operator, app.kubernetes.io/name=strimzi-user-operator, app.kubernetes.io/part-of=strimzi-my-user-1370630507-669433604, strimzi.io/cluster=my-cluster, strimzi.io/kind=KafkaUser, test.case=testUserInDifferentNamespace}, managedFields=[], name=my-user-1370630507-669433604, namespace=second-namespace-test, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=KafkaUser, name=my-user-1370630507-669433604, uid=ffa6e55c-52ea-406c-89b3-7ea026bb7f55, additionalProperties={})], resourceVersion=134838, selfLink=/api/v1/namespaces/second-namespace-test/secrets/my-user-1370630507-669433604, uid=903c17df-4c74-4182-ac5c-018d922924d5, additionalProperties={}), stringData=null, type=Opaque, additionalProperties={}) from namespace second-namespace-test to namespace third-namespace-test
2022-04-04 20:37:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-kafka-clients in namespace third-namespace-test
2022-04-04 20:37:36 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-kafka-clients will be ready
2022-04-04 20:37:38 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-kafka-clients is ready
2022-04-04 20:37:38 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 20:37:38 [main] [32mINFO [m [AllNamespaceIsolatedST:168] Checking produced and consumed messages to pod:my-cluster-kafka-clients-7d6fc99995-xp7ws
2022-04-04 20:37:38 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@43e6cb9e, messages=[], arguments=[--topic, my-topic-335653399-1112350690, --max-messages, 100, USER=my_user_1370630507_669433604, --bootstrap-server, my-cluster-kafka-bootstrap.third-namespace-test.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-kafka-clients-7d6fc99995-xp7ws', podNamespace='third-namespace-test', bootstrapServer='my-cluster-kafka-bootstrap.third-namespace-test.svc:9093', topicName='my-topic-335653399-1112350690', maxMessages=100, kafkaUsername='my-user-1370630507-669433604', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1c4ef349}
2022-04-04 20:37:38 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-kafka-bootstrap.third-namespace-test.svc:9093:my-topic-335653399-1112350690 from pod my-cluster-kafka-clients-7d6fc99995-xp7ws
2022-04-04 20:37:38 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-kafka-clients-7d6fc99995-xp7ws -n third-namespace-test -- /opt/kafka/producer.sh --topic my-topic-335653399-1112350690 --max-messages 100 USER=my_user_1370630507_669433604 --bootstrap-server my-cluster-kafka-bootstrap.third-namespace-test.svc:9093
2022-04-04 20:37:42 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 20:37:42 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 20:37:42 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@531ec4fb, messages=[], arguments=[--topic, my-topic-335653399-1112350690, --max-messages, 100, --group-instance-id, instance1366468347, USER=my_user_1370630507_669433604, --group-id, my-consumer-group-841223793, --bootstrap-server, my-cluster-kafka-bootstrap.third-namespace-test.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-kafka-clients-7d6fc99995-xp7ws', podNamespace='third-namespace-test', bootstrapServer='my-cluster-kafka-bootstrap.third-namespace-test.svc:9093', topicName='my-topic-335653399-1112350690', maxMessages=100, kafkaUsername='my-user-1370630507-669433604', consumerGroupName='my-consumer-group-841223793', consumerInstanceId='instance1366468347', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@19bbfd7}
2022-04-04 20:37:42 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-kafka-bootstrap.third-namespace-test.svc:9093:my-topic-335653399-1112350690 from pod my-cluster-kafka-clients-7d6fc99995-xp7ws
2022-04-04 20:37:42 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-kafka-clients-7d6fc99995-xp7ws -n third-namespace-test -- /opt/kafka/consumer.sh --topic my-topic-335653399-1112350690 --max-messages 100 --group-instance-id instance1366468347 USER=my_user_1370630507_669433604 --group-id my-consumer-group-841223793 --bootstrap-server my-cluster-kafka-bootstrap.third-namespace-test.svc:9093
2022-04-04 20:37:49 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 20:37:49 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 20:37:49 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:37:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:37:49 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUserInDifferentNamespace
2022-04-04 20:37:49 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-kafka-clients in namespace third-namespace-test
2022-04-04 20:37:49 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1370630507-669433604 in namespace second-namespace-test
2022-04-04 20:38:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:38:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testUserInDifferentNamespace-FINISHED
2022-04-04 20:38:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:38:29 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:38:29 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testDeployMirrorMakerAcrossMultipleNamespace-STARTED
2022-04-04 20:38:29 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:38:29 [main] [32mINFO [m [AllNamespaceIsolatedST:92] Deploying KafkaMirrorMaker in different namespace than CO when CO watches all namespaces
2022-04-04 20:38:29 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-04 20:38:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-target in namespace second-namespace-test
2022-04-04 20:38:29 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-target will have desired state: Ready
2022-04-04 20:39:42 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-target is in desired state: Ready
2022-04-04 20:39:42 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster in namespace second-namespace-test
2022-04-04 20:39:42 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster will have desired state: Ready
2022-04-04 20:40:49 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster is in desired state: Ready
2022-04-04 20:40:49 [main] [32mINFO [m [AbstractNamespaceST:71] Waiting for creation my-cluster-mirror-maker in namespace second-namespace-test
2022-04-04 20:40:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster will have desired state: Ready
2022-04-04 20:40:49 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster is in desired state: Ready
2022-04-04 20:40:49 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:40:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:40:49 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeployMirrorMakerAcrossMultipleNamespace
2022-04-04 20:40:49 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster in namespace second-namespace-test
2022-04-04 20:40:49 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-target in namespace second-namespace-test
2022-04-04 20:41:00 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:41:00 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testDeployMirrorMakerAcrossMultipleNamespace-FINISHED
2022-04-04 20:41:00 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:41:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:41:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testDeployKafkaConnectAndKafkaConnectorInOtherNamespaceThanCO-STARTED
2022-04-04 20:41:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:41:00 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-04 20:41:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b278513f-kafka-clients in namespace second-namespace-test
2022-04-04 20:41:00 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b278513f-kafka-clients will be ready
2022-04-04 20:41:02 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b278513f-kafka-clients is ready
2022-04-04 20:41:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b278513fkafka-connect-scraper in namespace second-namespace-test
2022-04-04 20:41:02 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b278513fkafka-connect-scraper will be ready
2022-04-04 20:41:04 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b278513fkafka-connect-scraper is ready
2022-04-04 20:41:04 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-b278513fkafka-connect-scraper to be ready
2022-04-04 20:41:14 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-b278513fkafka-connect-scraper is ready
2022-04-04 20:41:14 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-b278513fkafka-connect-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 20:41:14 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-b278513fkafka-connect-allow in namespace second-namespace-test
2022-04-04 20:41:14 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 20:41:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-b278513fkafka-connect in namespace second-namespace-test
2022-04-04 20:41:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-b278513fkafka-connect will have desired state: Ready
2022-04-04 20:42:24 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-b278513fkafka-connect is in desired state: Ready
2022-04-04 20:42:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-b278513fkafka-connect in namespace second-namespace-test
2022-04-04 20:42:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-b278513fkafka-connect will have desired state: Ready
2022-04-04 20:42:25 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-b278513fkafka-connect is in desired state: Ready
2022-04-04 20:42:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-b278513fkafka-connect will have desired state: Ready
2022-04-04 20:42:25 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-b278513fkafka-connect is in desired state: Ready
2022-04-04 20:42:25 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-04 20:42:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace second-namespace-test exec my-cluster-b278513fkafka-connect-connect-6dc8584fc6-dpjpv -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-04 20:42:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 20:42:25 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-04 20:42:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b278513fkafka-connect-kafka-clients in namespace second-namespace-test
2022-04-04 20:42:25 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b278513fkafka-connect-kafka-clients will be ready
2022-04-04 20:42:26 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b278513fkafka-connect-kafka-clients is ready
2022-04-04 20:42:26 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 20:42:26 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@24c00ad6, messages=[], arguments=[--topic, my-topic-335653399-1112350690, --max-messages, 100, --bootstrap-server, my-cluster-second-kafka-bootstrap.second-namespace-test.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b278513f-kafka-clients-754f75c446-fcvcp', podNamespace='second-namespace-test', bootstrapServer='my-cluster-second-kafka-bootstrap.second-namespace-test.svc:9092', topicName='my-topic-335653399-1112350690', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@36f69f05}
2022-04-04 20:42:26 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-second-kafka-bootstrap.second-namespace-test.svc:9092:my-topic-335653399-1112350690 from pod my-cluster-b278513f-kafka-clients-754f75c446-fcvcp
2022-04-04 20:42:26 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b278513f-kafka-clients-754f75c446-fcvcp -n second-namespace-test -- /opt/kafka/producer.sh --topic my-topic-335653399-1112350690 --max-messages 100 --bootstrap-server my-cluster-second-kafka-bootstrap.second-namespace-test.svc:9092
2022-04-04 20:42:28 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 20:42:28 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 20:42:28 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-b278513fkafka-connect-connect-6dc8584fc6-dpjpv
2022-04-04 20:42:31 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-b278513fkafka-connect-connect-6dc8584fc6-dpjpv
2022-04-04 20:42:31 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:42:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:42:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeployKafkaConnectAndKafkaConnectorInOtherNamespaceThanCO
2022-04-04 20:42:31 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-b278513fkafka-connect in namespace second-namespace-test
2022-04-04 20:42:31 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-b278513fkafka-connect in namespace second-namespace-test
2022-04-04 20:42:31 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b278513fkafka-connect-kafka-clients in namespace second-namespace-test
2022-04-04 20:42:31 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b278513f-kafka-clients in namespace second-namespace-test
2022-04-04 20:42:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b278513fkafka-connect-scraper in namespace second-namespace-test
2022-04-04 20:42:31 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-b278513fkafka-connect-allow in namespace second-namespace-test
2022-04-04 20:43:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:43:11 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testDeployKafkaConnectAndKafkaConnectorInOtherNamespaceThanCO-FINISHED
2022-04-04 20:43:11 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:43:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:43:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for AllNamespaceIsolatedST
2022-04-04 20:43:11 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-second in namespace second-namespace-test
2022-04-04 20:43:11 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster in namespace third-namespace-test
2022-04-04 20:43:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 605.642 s - in io.strimzi.systemtest.watcher.AllNamespaceIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST
2022-04-04 20:43:21 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:43:46 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 20:43:46 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 20:43:46 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 20:43:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:43:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 20:43:46 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:43:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace third-namespace-test
2022-04-04 20:43:46 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:43:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:43:46 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:43:46 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:43:46 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:43:46 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:43:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace third-namespace-test
2022-04-04 20:43:46 [main] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:43:46 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:43:46 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:43:46 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:43:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace second-namespace-test
2022-04-04 20:43:46 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:43:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 20:43:46 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:43:46 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:43:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:43:46 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:43:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:43:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:43:46 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:43:46 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:43:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:43:56 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:43:56 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:43:56 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:43:56 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:43:56 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:43:56 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:43:56 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:43:56 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:43:56 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:43:56 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-namespace-test
2022-04-04 20:44:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:44:17 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 20:44:17 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 20:44:17 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 20:44:17 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:44:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:44:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:44:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:44:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:44:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:44:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:44:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:44:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:44:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:44:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:44:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:44:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:44:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:44:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:44:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:44:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:44:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:44:17 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 20:44:17 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:44:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:44:17 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 20:44:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:44:17 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 20:44:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:44:17 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:44:17 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:44:17 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 20:44:17 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:44:17 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 20:44:17 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 20:44:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:44:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 20:44:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:44:17 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 20:44:42 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 20:44:42 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 20:44:52 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 20:44:52 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-04 20:44:52 [main] [32mINFO [m [OauthAbstractST:125] Deploying keycloak...
2022-04-04 20:44:52 [main] [32mINFO [m [KeycloakUtils:35] Prepare Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-04 20:47:06 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/prepare_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-04 20:47:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 20:47:06 [main] [32mINFO [m [KeycloakUtils:48] Keycloak in namespace infra-namespace is ready
2022-04-04 20:47:06 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret credential-example-keycloak
2022-04-04 20:47:06 [main] [32mINFO [m [SecretUtils:50] Secret credential-example-keycloak created
2022-04-04 20:47:06 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-producer-secret
2022-04-04 20:47:06 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-consumer-secret
2022-04-04 20:47:06 [main] [32mINFO [m [SecretUtils:70] Creating secret team-a-client-secret
2022-04-04 20:47:06 [main] [32mINFO [m [SecretUtils:70] Creating secret team-b-client-secret
2022-04-04 20:47:06 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-broker-secret
2022-04-04 20:47:06 [main] [32mINFO [m [SecretUtils:70] Creating secret my-connect-oauth
2022-04-04 20:47:06 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-oauth
2022-04-04 20:47:06 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-2-oauth
2022-04-04 20:47:06 [main] [32mINFO [m [SecretUtils:70] Creating secret my-bridge-oauth
2022-04-04 20:47:06 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-audience-secret
2022-04-04 20:47:06 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-client-secret
2022-04-04 20:47:06 [main] [32mINFO [m [KeycloakInstance:50] Replacing validIssuerUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal to pointing to internal realm
2022-04-04 20:47:06 [main] [32mINFO [m [KeycloakInstance:51] Replacing jwksEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/certs to pointing to internal realm
2022-04-04 20:47:06 [main] [32mINFO [m [KeycloakInstance:52] Replacing oauthTokenEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token to pointing to internal realm
2022-04-04 20:47:06 [main] [32mINFO [m [KeycloakInstance:60] Using HTTP endpoints
2022-04-04 20:47:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-plain-name in namespace infra-namespace
2022-04-04 20:47:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-plain-name will have desired state: Ready
2022-04-04 20:48:26 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-plain-name is in desired state: Ready
2022-04-04 20:48:27 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:48:27 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testSaslPlainProducerConsumer-STARTED
2022-04-04 20:48:27 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:48:27 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 20:48:27 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 20:48:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Job kafka-audience-producer-my-cluster-d29cb137 in namespace infra-namespace
2022-04-04 20:48:27 [main] [32mINFO [m [JobUtils:81] Waiting for job: kafka-audience-producer-my-cluster-d29cb137 will be in active state
2022-04-04 20:48:28 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:kafka-audience-producer-my-cluster-d29cb137 to finished
2022-04-04 20:48:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Job kafka-audience-consumer-my-cluster-d29cb137 in namespace infra-namespace
2022-04-04 20:48:36 [main] [32mINFO [m [JobUtils:81] Waiting for job: kafka-audience-consumer-my-cluster-d29cb137 will be in active state
2022-04-04 20:48:37 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:kafka-audience-consumer-my-cluster-d29cb137 to finished
2022-04-04 20:48:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:48:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSaslPlainProducerConsumer
2022-04-04 20:48:48 [main] [32mINFO [m [ResourceManager:241] Delete of Job kafka-audience-consumer-my-cluster-d29cb137 in namespace infra-namespace
2022-04-04 20:48:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job kafka-audience-producer-my-cluster-d29cb137 in namespace infra-namespace
2022-04-04 20:48:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:48:48 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testSaslPlainProducerConsumer-FINISHED
2022-04-04 20:48:48 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:48:48 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:48:48 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testSaslPlainAuthenticationKafkaConnectIsAbleToConnectToKafkaOAuth-STARTED
2022-04-04 20:48:48 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:48:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-9deb7a8e-kafka-clients in namespace infra-namespace
2022-04-04 20:48:48 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-9deb7a8e-kafka-clients will be ready
2022-04-04 20:48:50 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-9deb7a8e-kafka-clients is ready
2022-04-04 20:48:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-9deb7a8e-scraper in namespace infra-namespace
2022-04-04 20:48:50 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-9deb7a8e-scraper will be ready
2022-04-04 20:48:52 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-9deb7a8e-scraper is ready
2022-04-04 20:48:52 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-9deb7a8e-scraper to be ready
2022-04-04 20:49:02 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-9deb7a8e-scraper is ready
2022-04-04 20:49:02 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-9deb7a8e-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 20:49:02 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-9deb7a8e-allow in namespace infra-namespace
2022-04-04 20:49:02 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 20:49:02 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-9deb7a8e in namespace infra-namespace
2022-04-04 20:49:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-9deb7a8e will have desired state: Ready
2022-04-04 20:50:11 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-9deb7a8e is in desired state: Ready
2022-04-04 20:50:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:50:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSaslPlainAuthenticationKafkaConnectIsAbleToConnectToKafkaOAuth
2022-04-04 20:50:11 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-9deb7a8e-allow in namespace infra-namespace
2022-04-04 20:50:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-9deb7a8e in namespace infra-namespace
2022-04-04 20:50:11 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-9deb7a8e-scraper in namespace infra-namespace
2022-04-04 20:50:11 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-9deb7a8e-kafka-clients in namespace infra-namespace
2022-04-04 20:51:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:51:01 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testSaslPlainAuthenticationKafkaConnectIsAbleToConnectToKafkaOAuth-FINISHED
2022-04-04 20:51:01 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:51:01 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:51:01 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerMirrorMaker-STARTED
2022-04-04 20:51:01 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:51:01 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 20:51:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-664644014-2142129813 in namespace infra-namespace
2022-04-04 20:51:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-664644014-2142129813 will have desired state: Ready
2022-04-04 20:51:02 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-664644014-2142129813 is in desired state: Ready
2022-04-04 20:51:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-9e947abc in namespace infra-namespace
2022-04-04 20:51:02 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-9e947abc will be in active state
2022-04-04 20:51:03 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-9e947abc to finished
2022-04-04 20:51:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-9e947abc in namespace infra-namespace
2022-04-04 20:51:11 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-9e947abc will be in active state
2022-04-04 20:51:12 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-9e947abc to finished
2022-04-04 20:51:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-9e947abc-target in namespace infra-namespace
2022-04-04 20:51:23 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-9e947abc-target will have desired state: Ready
2022-04-04 20:52:30 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-9e947abc-target is in desired state: Ready
2022-04-04 20:52:30 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker oauth-cluster-plain-name in namespace infra-namespace
2022-04-04 20:52:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: oauth-cluster-plain-name will have desired state: Ready
2022-04-04 20:53:36 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: oauth-cluster-plain-name is in desired state: Ready
2022-04-04 20:53:36 [main] [32mINFO [m [OauthPlainIsolatedST:443] Deleting the Job
2022-04-04 20:53:36 [main] [32mINFO [m [OauthPlainIsolatedST:446] Creating new client with new consumer-group and also to point on my-cluster-9e947abc-target cluster
2022-04-04 20:53:36 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 20:53:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer in namespace infra-namespace
2022-04-04 20:53:36 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer will be in active state
2022-04-04 20:53:37 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer to finished
2022-04-04 20:53:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:53:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerMirrorMaker
2022-04-04 20:53:48 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-9e947abc-target in namespace infra-namespace
2022-04-04 20:53:48 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer in namespace infra-namespace
2022-04-04 20:53:48 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-664644014-2142129813 in namespace infra-namespace
2022-04-04 20:53:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker oauth-cluster-plain-name in namespace infra-namespace
2022-04-04 20:53:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-9e947abc in namespace infra-namespace
2022-04-04 20:53:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-9e947abc in namespace infra-namespace
2022-04-04 20:53:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:53:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerMirrorMaker-FINISHED
2022-04-04 20:53:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:53:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:53:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerBridge-STARTED
2022-04-04 20:53:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:53:58 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 20:53:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1389865138-1143153710 in namespace infra-namespace
2022-04-04 20:53:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1389865138-1143153710 will have desired state: Ready
2022-04-04 20:53:59 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1389865138-1143153710 is in desired state: Ready
2022-04-04 20:53:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-4e5d74c1 in namespace infra-namespace
2022-04-04 20:53:59 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-4e5d74c1 will be in active state
2022-04-04 20:54:00 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-4e5d74c1 to finished
2022-04-04 20:54:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-4e5d74c1 in namespace infra-namespace
2022-04-04 20:54:08 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-4e5d74c1 will be in active state
2022-04-04 20:54:09 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-4e5d74c1 to finished
2022-04-04 20:54:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-4e5d74c1-kafka-clients in namespace infra-namespace
2022-04-04 20:54:15 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4e5d74c1-kafka-clients will be ready
2022-04-04 20:54:16 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4e5d74c1-kafka-clients is ready
2022-04-04 20:54:16 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge oauth-cluster-plain-name in namespace infra-namespace
2022-04-04 20:54:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: oauth-cluster-plain-name will have desired state: Ready
2022-04-04 20:54:41 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: oauth-cluster-plain-name is in desired state: Ready
2022-04-04 20:54:41 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 20:54:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Job bridge-producer-my-cluster-4e5d74c1 in namespace infra-namespace
2022-04-04 20:54:41 [main] [32mINFO [m [JobUtils:81] Waiting for job: bridge-producer-my-cluster-4e5d74c1 will be in active state
2022-04-04 20:54:42 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:bridge-producer-my-cluster-4e5d74c1 to finished
2022-04-04 20:56:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:56:32 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerBridge
2022-04-04 20:56:32 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-4e5d74c1-kafka-clients in namespace infra-namespace
2022-04-04 20:56:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-4e5d74c1 in namespace infra-namespace
2022-04-04 20:56:32 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-4e5d74c1 in namespace infra-namespace
2022-04-04 20:56:32 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1389865138-1143153710 in namespace infra-namespace
2022-04-04 20:56:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job bridge-producer-my-cluster-4e5d74c1 in namespace infra-namespace
2022-04-04 20:56:32 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge oauth-cluster-plain-name in namespace infra-namespace
2022-04-04 20:57:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:57:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerBridge-FINISHED
2022-04-04 20:57:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:57:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:57:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumer-STARTED
2022-04-04 20:57:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:57:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1197060268-456299485 in namespace infra-namespace
2022-04-04 20:57:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1197060268-456299485 will have desired state: Ready
2022-04-04 20:57:23 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1197060268-456299485 is in desired state: Ready
2022-04-04 20:57:23 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 20:57:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-39bba086 in namespace infra-namespace
2022-04-04 20:57:23 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-39bba086 will be in active state
2022-04-04 20:57:24 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-39bba086 to finished
2022-04-04 20:57:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-39bba086 in namespace infra-namespace
2022-04-04 20:57:32 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-39bba086 will be in active state
2022-04-04 20:57:33 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-39bba086 to finished
2022-04-04 20:57:39 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:57:39 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumer
2022-04-04 20:57:39 [main] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-39bba086 in namespace infra-namespace
2022-04-04 20:57:39 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1197060268-456299485 in namespace infra-namespace
2022-04-04 20:57:39 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-39bba086 in namespace infra-namespace
2022-04-04 20:57:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:57:49 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumer-FINISHED
2022-04-04 20:57:49 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:57:49 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:57:49 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerMirrorMaker2-STARTED
2022-04-04 20:57:49 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:57:49 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 20:57:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2088562972-453544931 in namespace infra-namespace
2022-04-04 20:57:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2088562972-453544931 will have desired state: Ready
2022-04-04 20:57:50 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2088562972-453544931 is in desired state: Ready
2022-04-04 20:57:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-0745b9fb in namespace infra-namespace
2022-04-04 20:57:50 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-0745b9fb will be in active state
2022-04-04 20:57:51 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-0745b9fb to finished
2022-04-04 20:57:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-0745b9fb in namespace infra-namespace
2022-04-04 20:57:59 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-0745b9fb will be in active state
2022-04-04 20:58:00 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-0745b9fb to finished
2022-04-04 20:58:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0745b9fb-target in namespace infra-namespace
2022-04-04 20:58:11 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0745b9fb-target will have desired state: Ready
2022-04-04 20:59:13 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0745b9fb-target is in desired state: Ready
2022-04-04 20:59:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 oauth-cluster-plain-name in namespace infra-namespace
2022-04-04 20:59:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: oauth-cluster-plain-name will have desired state: Ready
2022-04-04 21:00:24 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: oauth-cluster-plain-name is in desired state: Ready
2022-04-04 21:00:25 [main] [32mINFO [m [OauthPlainIsolatedST:593] Deleting the Job oauth-consumer-my-cluster-0745b9fb
2022-04-04 21:00:25 [main] [32mINFO [m [OauthPlainIsolatedST:596] Creating new client with new consumer-group and also to point on my-cluster-0745b9fb-target cluster
2022-04-04 21:00:25 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 21:00:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-0745b9fb in namespace infra-namespace
2022-04-04 21:00:25 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-0745b9fb will be in active state
2022-04-04 21:00:26 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-0745b9fb to finished
2022-04-04 21:00:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:00:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerMirrorMaker2
2022-04-04 21:00:37 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0745b9fb-target in namespace infra-namespace
2022-04-04 21:00:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2088562972-453544931 in namespace infra-namespace
2022-04-04 21:00:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-0745b9fb in namespace infra-namespace
2022-04-04 21:00:37 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-0745b9fb in namespace infra-namespace
2022-04-04 21:00:37 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 oauth-cluster-plain-name in namespace infra-namespace
2022-04-04 21:00:37 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-0745b9fb in namespace infra-namespace
2022-04-04 21:00:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:00:57 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerMirrorMaker2-FINISHED
2022-04-04 21:00:57 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:00:57 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:00:57 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerAudienceTokenChecks-STARTED
2022-04-04 21:00:57 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:00:57 [main] [32mINFO [m [OauthPlainIsolatedST:161] Setting producer and consumer properties
2022-04-04 21:00:57 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 21:00:57 [main] [32mINFO [m [OauthPlainIsolatedST:174] Use clients without access token containing audience token
2022-04-04 21:00:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-513d6f93 in namespace infra-namespace
2022-04-04 21:00:57 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-513d6f93 will be in active state
2022-04-04 21:00:58 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:oauth-producer-my-cluster-513d6f93 to finish with failure.
2022-04-04 21:04:38 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
io.strimzi.test.WaitException: Timeout after 220000 ms waiting for Job did not finish within time limit (as expected).
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientTimeout(ClientUtils.java:91)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.lambda$testProducerConsumerAudienceTokenChecks$0(OauthPlainIsolatedST.java:176)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:50)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:37)
	at org.junit.jupiter.api.Assertions.assertDoesNotThrow(Assertions.java:3135)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerAudienceTokenChecks(OauthPlainIsolatedST.java:176)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-04 21:04:38 [main] [32mINFO [m [ClientUtils:100] Client job 'oauth-producer-my-cluster-513d6f93' finished with expected timeout.
2022-04-04 21:04:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-513d6f93 in namespace infra-namespace
2022-04-04 21:04:38 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-513d6f93 will be in active state
2022-04-04 21:04:39 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:oauth-consumer-my-cluster-513d6f93 to finish with failure.
2022-04-04 21:08:19 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
io.strimzi.test.WaitException: Timeout after 220000 ms waiting for Job did not finish within time limit (as expected).
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientTimeout(ClientUtils.java:91)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.lambda$testProducerConsumerAudienceTokenChecks$1(OauthPlainIsolatedST.java:178)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:50)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:37)
	at org.junit.jupiter.api.Assertions.assertDoesNotThrow(Assertions.java:3135)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerAudienceTokenChecks(OauthPlainIsolatedST.java:178)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-04 21:08:19 [main] [32mINFO [m [ClientUtils:100] Client job 'oauth-consumer-my-cluster-513d6f93' finished with expected timeout.
2022-04-04 21:08:29 [main] [32mINFO [m [OauthPlainIsolatedST:183] Use clients with Access token containing audience token
2022-04-04 21:08:29 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 21:08:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Job kafka-audience-producer-my-cluster-513d6f93 in namespace infra-namespace
2022-04-04 21:08:29 [main] [32mINFO [m [JobUtils:81] Waiting for job: kafka-audience-producer-my-cluster-513d6f93 will be in active state
2022-04-04 21:08:30 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:kafka-audience-producer-my-cluster-513d6f93 to finished
2022-04-04 21:08:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Job kafka-audience-consumer-my-cluster-513d6f93 in namespace infra-namespace
2022-04-04 21:08:33 [main] [32mINFO [m [JobUtils:81] Waiting for job: kafka-audience-consumer-my-cluster-513d6f93 will be in active state
2022-04-04 21:08:34 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:kafka-audience-consumer-my-cluster-513d6f93 to finished
2022-04-04 21:08:44 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:08:44 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerAudienceTokenChecks
2022-04-04 21:08:44 [main] [32mINFO [m [ResourceManager:241] Delete of Job kafka-audience-producer-my-cluster-513d6f93 in namespace infra-namespace
2022-04-04 21:08:44 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job kafka-audience-consumer-my-cluster-513d6f93 in namespace infra-namespace
2022-04-04 21:08:44 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-513d6f93 in namespace infra-namespace
2022-04-04 21:08:44 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-513d6f93 in namespace infra-namespace
2022-04-04 21:08:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:08:44 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerAudienceTokenChecks-FINISHED
2022-04-04 21:08:44 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:08:44 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:08:44 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect-STARTED
2022-04-04 21:08:44 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:08:44 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 21:08:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1889499726-140583362 in namespace infra-namespace
2022-04-04 21:08:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1889499726-140583362 will have desired state: Ready
2022-04-04 21:08:45 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1889499726-140583362 is in desired state: Ready
2022-04-04 21:08:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-a0284bb2 in namespace infra-namespace
2022-04-04 21:08:45 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-a0284bb2 will be in active state
2022-04-04 21:08:46 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-a0284bb2 to finished
2022-04-04 21:08:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-a0284bb2 in namespace infra-namespace
2022-04-04 21:08:54 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-a0284bb2 will be in active state
2022-04-04 21:08:55 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-a0284bb2 to finished
2022-04-04 21:09:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a0284bb2-kafka-clients in namespace infra-namespace
2022-04-04 21:09:01 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a0284bb2-kafka-clients will be ready
2022-04-04 21:09:03 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a0284bb2-kafka-clients is ready
2022-04-04 21:09:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a0284bb2-scraper in namespace infra-namespace
2022-04-04 21:09:03 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a0284bb2-scraper will be ready
2022-04-04 21:09:05 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a0284bb2-scraper is ready
2022-04-04 21:09:05 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-a0284bb2-scraper to be ready
2022-04-04 21:09:15 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-a0284bb2-scraper is ready
2022-04-04 21:09:15 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-a0284bb2-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 21:09:15 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-a0284bb2-allow in namespace infra-namespace
2022-04-04 21:09:15 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 21:09:15 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-a0284bb2 in namespace infra-namespace
2022-04-04 21:09:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-a0284bb2 will have desired state: Ready
2022-04-04 21:19:15 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for KafkaConnect: my-cluster-a0284bb2 will have desired state: Ready, null
2022-04-04 21:19:15 [main] [32mINFO [m [ResourceManager:414] KafkaConnect status:

Conditions:
	Type: NotReady
	Message: Exceeded timeout of 300000ms while waiting for Deployment resource my-cluster-a0284bb2-connect in namespace infra-namespace to be ready

Pods with conditions and messages:

my-cluster-a0284bb2-connect-5c7448898d-pxg8l:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: Ready
	Message: containers with unready status: [my-cluster-a0284bb2-connect]

	Type: ContainersReady
	Message: containers with unready status: [my-cluster-a0284bb2-connect]

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-a0284bb2-kafka-clients-7cb5bd8c96-nbwsv:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-a0284bb2-scraper-69dc87fc8f-6k6s9:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>
io.strimzi.test.WaitException: Timeout after 600000 ms waiting for KafkaConnect: my-cluster-a0284bb2 will have desired state: Ready
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.systemtest.resources.ResourceManager.waitForResourceStatus(ResourceManager.java:435)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils.waitForConnectStatus(KafkaConnectUtils.java:42)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils.waitForConnectReady(KafkaConnectUtils.java:47)
	at io.strimzi.systemtest.resources.crd.KafkaConnectResource.waitForReadiness(KafkaConnectResource.java:42)
	at io.strimzi.systemtest.resources.crd.KafkaConnectResource.waitForReadiness(KafkaConnectResource.java:19)
	at io.strimzi.systemtest.resources.ResourceManager.lambda$waitResourceCondition$2(ResourceManager.java:268)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:142)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.resources.ResourceManager.waitResourceCondition(ResourceManager.java:264)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:226)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:148)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect(OauthPlainIsolatedST.java:287)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
io.strimzi.test.WaitException: Timeout after 600000 ms waiting for Resource condition: readiness is fulfilled for resource KafkaConnect:my-cluster-a0284bb2
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.resources.ResourceManager.waitResourceCondition(ResourceManager.java:264)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:226)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:148)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect(OauthPlainIsolatedST.java:287)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-04 21:19:15 [main] [1;31mERROR[m [TestExecutionWatcher:28] OauthPlainIsolatedST - Exception Timeout after 600000 ms waiting for Resource condition: readiness is fulfilled for resource KafkaConnect:my-cluster-a0284bb2 has been thrown in @Test. Going to collect logs from components.
2022-04-04 21:19:15 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-04-04 21:19:15 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-04-04 21:19:15 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-04-04 21:19:15 [main] [33mWARN [m [LogCollector:247] Searching for logs in all pods failed! Some of the logs will not be stored. Exception messagenull
2022-04-04 21:19:15 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-04-04 21:19:16 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-04-04 21:19:16 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-04-04 21:19:16 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-04-04 21:19:16 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-04 21:19:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:19:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerConnect
2022-04-04 21:19:16 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1889499726-140583362 in namespace infra-namespace
2022-04-04 21:19:16 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-a0284bb2-allow in namespace infra-namespace
2022-04-04 21:19:16 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a0284bb2-scraper in namespace infra-namespace
2022-04-04 21:19:16 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a0284bb2-kafka-clients in namespace infra-namespace
2022-04-04 21:19:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-a0284bb2 in namespace infra-namespace
2022-04-04 21:19:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-a0284bb2 in namespace infra-namespace
2022-04-04 21:19:16 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-a0284bb2 in namespace infra-namespace
2022-04-04 21:19:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:19:56 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect-FINISHED
2022-04-04 21:19:56 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:19:56 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:19:56 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testAccessTokenClaimCheck-STARTED
2022-04-04 21:19:56 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:19:56 [main] [32mINFO [m [OauthPlainIsolatedST:213] Use clients with clientId not containing 'hello-world' in access token.
2022-04-04 21:19:56 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 21:19:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Job kafka-audience-producer-my-cluster-c3a9cbc2 in namespace infra-namespace
2022-04-04 21:19:56 [main] [32mINFO [m [JobUtils:81] Waiting for job: kafka-audience-producer-my-cluster-c3a9cbc2 will be in active state
2022-04-04 21:19:56 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:kafka-audience-producer-my-cluster-c3a9cbc2 to finish with failure.
2022-04-04 21:23:36 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
io.strimzi.test.WaitException: Timeout after 220000 ms waiting for Job did not finish within time limit (as expected).
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientTimeout(ClientUtils.java:91)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.lambda$testAccessTokenClaimCheck$2(OauthPlainIsolatedST.java:229)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:50)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:37)
	at org.junit.jupiter.api.Assertions.assertDoesNotThrow(Assertions.java:3135)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testAccessTokenClaimCheck(OauthPlainIsolatedST.java:229)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-04 21:23:36 [main] [32mINFO [m [ClientUtils:100] Client job 'kafka-audience-producer-my-cluster-c3a9cbc2' finished with expected timeout.
2022-04-04 21:23:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Job kafka-audience-consumer-my-cluster-c3a9cbc2 in namespace infra-namespace
2022-04-04 21:23:36 [main] [32mINFO [m [JobUtils:81] Waiting for job: kafka-audience-consumer-my-cluster-c3a9cbc2 will be in active state
2022-04-04 21:23:37 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:kafka-audience-consumer-my-cluster-c3a9cbc2 to finish with failure.
2022-04-04 21:27:17 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
io.strimzi.test.WaitException: Timeout after 220000 ms waiting for Job did not finish within time limit (as expected).
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientTimeout(ClientUtils.java:91)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.lambda$testAccessTokenClaimCheck$3(OauthPlainIsolatedST.java:231)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:50)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:37)
	at org.junit.jupiter.api.Assertions.assertDoesNotThrow(Assertions.java:3135)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testAccessTokenClaimCheck(OauthPlainIsolatedST.java:231)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-04 21:27:17 [main] [32mINFO [m [ClientUtils:100] Client job 'kafka-audience-consumer-my-cluster-c3a9cbc2' finished with expected timeout.
2022-04-04 21:27:27 [main] [32mINFO [m [OauthPlainIsolatedST:236] Use clients with clientId containing 'hello-world' in access token.
2022-04-04 21:27:27 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 21:27:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-c3a9cbc2 in namespace infra-namespace
2022-04-04 21:27:27 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-c3a9cbc2 will be in active state
2022-04-04 21:27:28 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-c3a9cbc2 to finished
2022-04-04 21:27:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-c3a9cbc2 in namespace infra-namespace
2022-04-04 21:27:36 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-c3a9cbc2 will be in active state
2022-04-04 21:27:37 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-c3a9cbc2 to finished
2022-04-04 21:27:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:27:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAccessTokenClaimCheck
2022-04-04 21:27:48 [main] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-c3a9cbc2 in namespace infra-namespace
2022-04-04 21:27:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-c3a9cbc2 in namespace infra-namespace
2022-04-04 21:27:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job kafka-audience-producer-my-cluster-c3a9cbc2 in namespace infra-namespace
2022-04-04 21:27:48 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job kafka-audience-consumer-my-cluster-c3a9cbc2 in namespace infra-namespace
2022-04-04 21:27:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:27:48 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testAccessTokenClaimCheck-FINISHED
2022-04-04 21:27:48 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:27:48 [main] [32mINFO [m [KeycloakUtils:52] Teardown Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-04 21:27:53 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/teardown_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-04 21:27:53 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 21:27:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:27:53 [main] [32mINFO [m [ResourceManager:348] Delete all resources for OauthPlainIsolatedST
2022-04-04 21:27:53 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-plain-name in namespace infra-namespace
2022-04-04 21:27:53 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-04 21:28:03 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:28:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:28:03 [main] [32mINFO [m [ResourceManager:346] In context OauthPlainIsolatedST is everything deleted.
2022-04-04 21:28:03 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;31mERROR[m] Tests run: 9, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 2,681.728 s <<< FAILURE! - in io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST
[[1;31mERROR[m] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect(ExtensionContext)  Time elapsed: 672.378 s  <<< ERROR!
io.strimzi.test.WaitException: Timeout after 600000 ms waiting for Resource condition: readiness is fulfilled for resource KafkaConnect:my-cluster-a0284bb2
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.resources.ResourceManager.waitResourceCondition(ResourceManager.java:264)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:226)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:148)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect(OauthPlainIsolatedST.java:287)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)

[[1;34mINFO[m] Running io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST
2022-04-04 21:28:03 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 21:28:28 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 21:28:28 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 21:28:28 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 21:28:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:28:28 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 21:28:28 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 21:28:28 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 21:28:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 21:28:28 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 21:28:28 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 21:28:28 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 21:28:28 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:28:28 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 21:28:28 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:28:28 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 21:28:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 21:28:28 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 21:28:28 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 21:28:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 21:28:28 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:28:28 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 21:28:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:28:28 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 21:28:28 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 21:28:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 21:28:28 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 21:28:38 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 21:28:38 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 21:28:38 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 21:28:38 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 21:28:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:28:54 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 21:28:54 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 21:28:54 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 21:28:54 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 21:28:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:28:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 21:28:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 21:28:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 21:28:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 21:28:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 21:28:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 21:28:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 21:28:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 21:28:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 21:28:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 21:28:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 21:28:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 21:28:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 21:28:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 21:28:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 21:28:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:28:54 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 21:28:54 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 21:28:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 21:28:54 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 21:28:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 21:28:54 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 21:28:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 21:28:55 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 21:28:55 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:28:55 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 21:28:55 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 21:28:55 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 21:28:55 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 21:28:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 21:28:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 21:28:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:28:55 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 21:29:12 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 21:29:12 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 21:29:22 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 21:29:22 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-04 21:29:22 [main] [32mINFO [m [OauthAbstractST:125] Deploying keycloak...
2022-04-04 21:29:22 [main] [32mINFO [m [KeycloakUtils:35] Prepare Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-04 21:31:13 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/prepare_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-04 21:31:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 21:31:13 [main] [32mINFO [m [KeycloakUtils:48] Keycloak in namespace infra-namespace is ready
2022-04-04 21:31:13 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret credential-example-keycloak
2022-04-04 21:31:13 [main] [32mINFO [m [SecretUtils:50] Secret credential-example-keycloak created
2022-04-04 21:31:13 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-producer-secret
2022-04-04 21:31:13 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-consumer-secret
2022-04-04 21:31:13 [main] [32mINFO [m [SecretUtils:70] Creating secret team-a-client-secret
2022-04-04 21:31:13 [main] [32mINFO [m [SecretUtils:70] Creating secret team-b-client-secret
2022-04-04 21:31:13 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-broker-secret
2022-04-04 21:31:13 [main] [32mINFO [m [SecretUtils:70] Creating secret my-connect-oauth
2022-04-04 21:31:13 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-oauth
2022-04-04 21:31:13 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-2-oauth
2022-04-04 21:31:13 [main] [32mINFO [m [SecretUtils:70] Creating secret my-bridge-oauth
2022-04-04 21:31:13 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-audience-secret
2022-04-04 21:31:13 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-client-secret
2022-04-04 21:31:13 [main] [32mINFO [m [KeycloakInstance:50] Replacing validIssuerUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal to pointing to kafka-authz realm
2022-04-04 21:31:13 [main] [32mINFO [m [KeycloakInstance:51] Replacing jwksEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/certs to pointing to kafka-authz realm
2022-04-04 21:31:13 [main] [32mINFO [m [KeycloakInstance:52] Replacing oauthTokenEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token to pointing to kafka-authz realm
2022-04-04 21:31:13 [main] [32mINFO [m [KeycloakInstance:55] Using HTTPS endpoints
2022-04-04 21:31:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-authz-name in namespace infra-namespace
2022-04-04 21:31:13 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-authz-name will have desired state: Ready
2022-04-04 21:32:21 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-authz-name is in desired state: Ready
2022-04-04 21:32:21 [main] [32mINFO [m [OauthAuthorizationIsolatedST:680] Setting producer and consumer properties
2022-04-04 21:32:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser team-a-client in namespace infra-namespace
2022-04-04 21:32:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: team-a-client will have desired state: Ready
2022-04-04 21:32:22 [main] [32mINFO [m [ResourceManager:444] KafkaUser: team-a-client is in desired state: Ready
2022-04-04 21:32:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser team-b-client in namespace infra-namespace
2022-04-04 21:32:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: team-b-client will have desired state: Ready
2022-04-04 21:32:23 [main] [32mINFO [m [ResourceManager:444] KafkaUser: team-b-client is in desired state: Ready
2022-04-04 21:32:23 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:32:23 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.smokeTestForClients-STARTED
2022-04-04 21:32:23 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:32:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic a-topic-my-topic-1768423713-989470207 in namespace infra-namespace
2022-04-04 21:32:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: a-topic-my-topic-1768423713-989470207 will have desired state: Ready
2022-04-04 21:32:24 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: a-topic-my-topic-1768423713-989470207 is in desired state: Ready
2022-04-04 21:32:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-f9cb12b8 in namespace infra-namespace
2022-04-04 21:32:24 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-f9cb12b8 will be in active state
2022-04-04 21:32:25 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-f9cb12b8 to finished
2022-04-04 21:32:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-consumer-my-cluster-f9cb12b8 in namespace infra-namespace
2022-04-04 21:32:35 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-consumer-my-cluster-f9cb12b8 will be in active state
2022-04-04 21:32:36 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-consumer-my-cluster-f9cb12b8 to finished
2022-04-04 21:32:42 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:32:42 [main] [32mINFO [m [ResourceManager:348] Delete all resources for smokeTestForClients
2022-04-04 21:32:42 [main] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-f9cb12b8 in namespace infra-namespace
2022-04-04 21:32:42 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic a-topic-my-topic-1768423713-989470207 in namespace infra-namespace
2022-04-04 21:32:42 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-consumer-my-cluster-f9cb12b8 in namespace infra-namespace
2022-04-04 21:32:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:32:52 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.smokeTestForClients-FINISHED
2022-04-04 21:32:52 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:32:52 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:32:52 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamAWriteToTopic-STARTED
2022-04-04 21:32:52 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:32:52 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-405425617-80304729 in namespace infra-namespace
2022-04-04 21:32:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-405425617-80304729 will have desired state: Ready
2022-04-04 21:32:53 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-405425617-80304729 is in desired state: Ready
2022-04-04 21:32:53 [main] [32mINFO [m [OauthAuthorizationIsolatedST:146] Sending 100 messages to broker with topic name my-topic-405425617-80304729
2022-04-04 21:32:53 [main] [32mINFO [m [OauthAuthorizationIsolatedST:147] Producer will not produce messages because authorization topic will failed. Team A can write only to topic starting with 'x-'
2022-04-04 21:32:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-28f8c6e8 in namespace infra-namespace
2022-04-04 21:32:53 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-28f8c6e8 will be in active state
2022-04-04 21:32:54 [main] [32mINFO [m [JobUtils:70] Waiting for job: team-a-client-producer-my-cluster-28f8c6e8 will be in error state
2022-04-04 21:33:13 [main] [32mINFO [m [OauthAuthorizationIsolatedST:154] Sending 100 messages to broker with topic name x-topic-my-cluster-28f8c6e8
2022-04-04 21:33:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-28f8c6e8 in namespace infra-namespace
2022-04-04 21:33:13 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-28f8c6e8 will be in active state
2022-04-04 21:33:14 [main] [32mINFO [m [JobUtils:70] Waiting for job: team-a-client-producer-my-cluster-28f8c6e8 will be in error state
2022-04-04 21:33:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic x-topic-my-cluster-28f8c6e8 in namespace infra-namespace
2022-04-04 21:33:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: x-topic-my-cluster-28f8c6e8 will have desired state: Ready
2022-04-04 21:33:33 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: x-topic-my-cluster-28f8c6e8 is in desired state: Ready
2022-04-04 21:33:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-28f8c6e8 in namespace infra-namespace
2022-04-04 21:33:33 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-28f8c6e8 will be in active state
2022-04-04 21:33:34 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-28f8c6e8 to finished
2022-04-04 21:33:42 [main] [32mINFO [m [OauthAuthorizationIsolatedST:172] Sending 100 messages to broker with topic name a-topic-my-cluster-28f8c6e8
2022-04-04 21:33:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-28f8c6e8 in namespace infra-namespace
2022-04-04 21:33:42 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-28f8c6e8 will be in active state
2022-04-04 21:33:43 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-28f8c6e8 to finished
2022-04-04 21:33:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:33:51 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTeamAWriteToTopic
2022-04-04 21:33:51 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic x-topic-my-cluster-28f8c6e8 in namespace infra-namespace
2022-04-04 21:33:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-28f8c6e8 in namespace infra-namespace
2022-04-04 21:33:51 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-28f8c6e8 in namespace infra-namespace
2022-04-04 21:33:51 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-405425617-80304729 in namespace infra-namespace
2022-04-04 21:33:51 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-28f8c6e8 in namespace infra-namespace
2022-04-04 21:33:51 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-28f8c6e8 in namespace infra-namespace
2022-04-04 21:34:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:34:01 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamAWriteToTopic-FINISHED
2022-04-04 21:34:01 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:34:01 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:34:01 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamAReadFromTopic-STARTED
2022-04-04 21:34:01 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:34:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic a-topic-my-topic-215609275-1765159885 in namespace infra-namespace
2022-04-04 21:34:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: a-topic-my-topic-215609275-1765159885 will have desired state: Ready
2022-04-04 21:34:02 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: a-topic-my-topic-215609275-1765159885 is in desired state: Ready
2022-04-04 21:34:02 [main] [32mINFO [m [OauthAuthorizationIsolatedST:208] Sending 100 messages to broker with topic name a-topic-my-topic-215609275-1765159885
2022-04-04 21:34:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-9c89a8ff in namespace infra-namespace
2022-04-04 21:34:02 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-9c89a8ff will be in active state
2022-04-04 21:34:03 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-9c89a8ff to finished
2022-04-04 21:34:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-consumer-my-cluster-9c89a8ff in namespace infra-namespace
2022-04-04 21:34:12 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-consumer-my-cluster-9c89a8ff will be in active state
2022-04-04 21:34:13 [main] [32mINFO [m [JobUtils:70] Waiting for job: team-a-client-consumer-my-cluster-9c89a8ff will be in error state
2022-04-04 21:34:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-9c89a8ff in namespace infra-namespace
2022-04-04 21:34:16 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-9c89a8ff will be in active state
2022-04-04 21:34:17 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-9c89a8ff to finished
2022-04-04 21:34:26 [main] [32mINFO [m [OauthAbstractST:153] Deleting team-a-client-consumer-my-cluster-9c89a8ff job
2022-04-04 21:34:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:34:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTeamAReadFromTopic
2022-04-04 21:34:31 [main] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-consumer-my-cluster-9c89a8ff in namespace infra-namespace
2022-04-04 21:34:31 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic a-topic-my-topic-215609275-1765159885 in namespace infra-namespace
2022-04-04 21:34:31 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-9c89a8ff in namespace infra-namespace
2022-04-04 21:34:31 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-9c89a8ff in namespace infra-namespace
2022-04-04 21:34:41 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:34:41 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamAReadFromTopic-FINISHED
2022-04-04 21:34:41 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:34:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:34:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamBWriteToTopic-STARTED
2022-04-04 21:34:41 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:34:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1100643581-1263608440 in namespace infra-namespace
2022-04-04 21:34:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1100643581-1263608440 will have desired state: Ready
2022-04-04 21:34:42 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1100643581-1263608440 is in desired state: Ready
2022-04-04 21:34:42 [main] [32mINFO [m [OauthAuthorizationIsolatedST:259] Sending 100 messages to broker with topic name my-topic-335653399-1112350690
2022-04-04 21:34:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-b-client-producer-my-cluster-859f8212 in namespace infra-namespace
2022-04-04 21:34:42 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-b-client-producer-my-cluster-859f8212 will be in active state
2022-04-04 21:34:43 [main] [32mINFO [m [JobUtils:70] Waiting for job: team-b-client-producer-my-cluster-859f8212 will be in error state
2022-04-04 21:35:01 [main] [32mINFO [m [OauthAuthorizationIsolatedST:265] Sending 100 messages to broker with topic name b-topic
2022-04-04 21:35:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-b-client-producer-my-cluster-859f8212 in namespace infra-namespace
2022-04-04 21:35:01 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-b-client-producer-my-cluster-859f8212 will be in active state
2022-04-04 21:35:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-b-client-consumer-my-cluster-859f8212 in namespace infra-namespace
2022-04-04 21:35:02 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-b-client-consumer-my-cluster-859f8212 will be in active state
2022-04-04 21:35:03 [main] [32mINFO [m [ClientUtils:61] Waiting till producer team-b-client-producer-my-cluster-859f8212 and consumer team-b-client-consumer-my-cluster-859f8212 finish
2022-04-04 21:35:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:35:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTeamBWriteToTopic
2022-04-04 21:35:14 [main] [32mINFO [m [ResourceManager:241] Delete of Job team-b-client-producer-my-cluster-859f8212 in namespace infra-namespace
2022-04-04 21:35:14 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job team-b-client-consumer-my-cluster-859f8212 in namespace infra-namespace
2022-04-04 21:35:14 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job team-b-client-producer-my-cluster-859f8212 in namespace infra-namespace
2022-04-04 21:35:14 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1100643581-1263608440 in namespace infra-namespace
2022-04-04 21:35:24 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:35:24 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamBWriteToTopic-FINISHED
2022-04-04 21:35:24 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:35:24 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:35:24 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamAWriteToTopicStartingWithXAndTeamBReadFromTopicStartingWithX-STARTED
2022-04-04 21:35:24 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:35:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic x-topicmy-topic-1260105814-1997216257 in namespace infra-namespace
2022-04-04 21:35:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: x-topicmy-topic-1260105814-1997216257 will have desired state: Ready
2022-04-04 21:35:25 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: x-topicmy-topic-1260105814-1997216257 is in desired state: Ready
2022-04-04 21:35:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-4964aed1 in namespace infra-namespace
2022-04-04 21:35:25 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-4964aed1 will be in active state
2022-04-04 21:35:26 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-4964aed1 to finished
2022-04-04 21:35:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-b-client-consumer-my-cluster-4964aed1 in namespace infra-namespace
2022-04-04 21:35:35 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-b-client-consumer-my-cluster-4964aed1 will be in active state
2022-04-04 21:35:36 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-b-client-consumer-my-cluster-4964aed1 to finished
2022-04-04 21:35:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:35:47 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTeamAWriteToTopicStartingWithXAndTeamBReadFromTopicStartingWithX
2022-04-04 21:35:47 [main] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-4964aed1 in namespace infra-namespace
2022-04-04 21:35:47 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic x-topicmy-topic-1260105814-1997216257 in namespace infra-namespace
2022-04-04 21:35:47 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job team-b-client-consumer-my-cluster-4964aed1 in namespace infra-namespace
2022-04-04 21:35:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:35:57 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamAWriteToTopicStartingWithXAndTeamBReadFromTopicStartingWithX-FINISHED
2022-04-04 21:35:57 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:35:57 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:35:57 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testSuperUserWithOauthAuthorization-STARTED
2022-04-04 21:35:57 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:35:57 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic x-topicmy-topic-909333333-781776088 in namespace infra-namespace
2022-04-04 21:35:57 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: x-topicmy-topic-909333333-781776088 will have desired state: Ready
2022-04-04 21:35:58 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: x-topicmy-topic-909333333-781776088 is in desired state: Ready
2022-04-04 21:35:58 [main] [32mINFO [m [OauthAuthorizationIsolatedST:347] Verifying that team B is not able write to topic starting with 'x-' because in kafka clusterdoes not have super-users to break authorization rules
2022-04-04 21:35:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-2024304231-1590289604 in namespace infra-namespace
2022-04-04 21:35:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-2024304231-1590289604 will have desired state: Ready
2022-04-04 21:35:59 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-2024304231-1590289604 is in desired state: Ready
2022-04-04 21:35:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-b-client-producer-my-cluster-c8ab4614 in namespace infra-namespace
2022-04-04 21:35:59 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-b-client-producer-my-cluster-c8ab4614 will be in active state
2022-04-04 21:36:00 [main] [32mINFO [m [JobUtils:70] Waiting for job: team-b-client-producer-my-cluster-c8ab4614 will be in error state
2022-04-04 21:36:03 [main] [32mINFO [m [OauthAuthorizationIsolatedST:370] Verifying that team A is not able read to topic starting with 'x-' because in kafka clusterdoes not have super-users to break authorization rules
2022-04-04 21:36:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-consumer-my-cluster-c8ab4614 in namespace infra-namespace
2022-04-04 21:36:03 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-consumer-my-cluster-c8ab4614 will be in active state
2022-04-04 21:36:05 [main] [32mINFO [m [JobUtils:70] Waiting for job: team-a-client-consumer-my-cluster-c8ab4614 will be in error state
2022-04-04 21:36:13 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: oauth-cluster-authz-name-kafka rolling update
2022-04-04 21:36:28 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: oauth-cluster-authz-name-kafka has been successfully rolled
2022-04-04 21:36:28 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 1 Pod(s) of oauth-cluster-authz-name-kafka to be ready
2022-04-04 21:36:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-authz-name will have desired state: Ready
2022-04-04 21:36:51 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-authz-name is in desired state: Ready
2022-04-04 21:36:51 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: oauth-cluster-authz-name is ready
2022-04-04 21:36:51 [main] [32mINFO [m [OauthAuthorizationIsolatedST:404] Verifying that team B is able to write to topic starting with 'x-' and break authorization rule
2022-04-04 21:36:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-b-client-producer-my-cluster-c8ab4614 in namespace infra-namespace
2022-04-04 21:36:51 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-b-client-producer-my-cluster-c8ab4614 will be in active state
2022-04-04 21:36:52 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-b-client-producer-my-cluster-c8ab4614 to finished
2022-04-04 21:37:01 [main] [32mINFO [m [OauthAuthorizationIsolatedST:409] Verifying that team A is able to write to topic starting with 'x-' and break authorization rule
2022-04-04 21:37:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-consumer-my-cluster-c8ab4614 in namespace infra-namespace
2022-04-04 21:37:01 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-consumer-my-cluster-c8ab4614 will be in active state
2022-04-04 21:37:02 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-consumer-my-cluster-c8ab4614 to finished
2022-04-04 21:37:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:37:13 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSuperUserWithOauthAuthorization
2022-04-04 21:37:13 [main] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-consumer-my-cluster-c8ab4614 in namespace infra-namespace
2022-04-04 21:37:13 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic x-topicmy-topic-909333333-781776088 in namespace infra-namespace
2022-04-04 21:37:13 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job team-b-client-producer-my-cluster-c8ab4614 in namespace infra-namespace
2022-04-04 21:37:13 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-2024304231-1590289604 in namespace infra-namespace
2022-04-04 21:37:13 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-consumer-my-cluster-c8ab4614 in namespace infra-namespace
2022-04-04 21:37:13 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job team-b-client-producer-my-cluster-c8ab4614 in namespace infra-namespace
2022-04-04 21:37:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:37:23 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testSuperUserWithOauthAuthorization-FINISHED
2022-04-04 21:37:23 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:37:23 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:37:23 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testSessionReAuthentication-STARTED
2022-04-04 21:37:23 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:37:23 [main] [32mINFO [m [OauthAuthorizationIsolatedST:443] Verifying that team A producer is able to send messages to the x-topic-example-topic topic -> the topic starting with 'x'
2022-04-04 21:37:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic x-topic-example-topic in namespace infra-namespace
2022-04-04 21:37:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: x-topic-example-topic will have desired state: Ready
2022-04-04 21:37:24 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: x-topic-example-topic is in desired state: Ready
2022-04-04 21:37:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic a-topic-example-topic in namespace infra-namespace
2022-04-04 21:37:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: a-topic-example-topic will have desired state: Ready
2022-04-04 21:37:25 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: a-topic-example-topic is in desired state: Ready
2022-04-04 21:37:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-ef5722bc in namespace infra-namespace
2022-04-04 21:37:25 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-ef5722bc will be in active state
2022-04-04 21:37:26 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-ef5722bc to finished
2022-04-04 21:37:34 [main] [32mINFO [m [OauthAuthorizationIsolatedST:465] Adding the maxSecondsWithoutReauthentication to Kafka listener with OAuth authentication
2022-04-04 21:37:34 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-authz-name will have desired state: Ready
2022-04-04 21:37:34 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-authz-name is in desired state: Ready
2022-04-04 21:37:34 [main] [32mINFO [m [OauthAuthorizationIsolatedST:493] Setting the master realm token's lifespan to 3600s
2022-04-04 21:37:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-sd9kq -- curl -v --insecure -X POST -d client_id=admin-cli&client_secret=aGVsbG8td29ybGQtcHJvZHVjZXItc2VjcmV0&grant_type=password&username=admin&password=XqdN8agTm6rLkA== https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/master/protocol/openid-connect/token
2022-04-04 21:37:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 21:37:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-sd9kq -- curl -v --insecure -X GET https://keycloak.infra-namespace.svc.cluster.local:8443/auth/admin/realms/master -H Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJ4YUFnLWhoeFQtMjVvTUVvUjU0Y2pnbDRlTGU3TzVGeVZlY2lYS014SmZJIn0.eyJleHAiOjE2NDkxMDgzMTQsImlhdCI6MTY0OTEwODI1NCwianRpIjoiMGRjMjMxY2MtM2NjZi00NTE3LTliZTYtMDY0OGRmNjdiZDU1IiwiaXNzIjoiaHR0cHM6Ly9rZXljbG9hay5pbmZyYS1uYW1lc3BhY2Uuc3ZjLmNsdXN0ZXIubG9jYWw6ODQ0My9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJzdWIiOiI1YzA0NDRiZC1kNmY3LTRmMTEtYmRhYy02ZDBjNGE1NThiMzMiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhZG1pbi1jbGkiLCJzZXNzaW9uX3N0YXRlIjoiOWYyYWVhYmItNzc4My00MzI3LWJlOWEtMTc2ZDQ0YWIyNzBjIiwiYWNyIjoiMSIsInNjb3BlIjoicHJvZmlsZSBlbWFpbCIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4ifQ.SxrTtqW-kQ4T2OWfcifMYOexgiScAJzVk3ETYcA7IfhpsHed9mquLJpCcmtk3Jn7Y8OSbOzS3aC26y21VDMwvL85_5q-NrrveOFDijAs_Flmaq89-S-Nvh85COkA1qAXddQZvqf3gePXQY-LotolDQnPUKkPY_62dfYvYm8BAhyvQyuGzPcAxRvB-3INg2_O4MZrI6cE1vpM9lL_JTljYhFbBD66GcPyGafMSmRJjebKbkL2bd6xWaXVridd9RmdZDMsIiMfvR_jwQQq_1sZv6CBRmByMCr8klxBlDQqjJBAxcuOxhQxk4A-p7-nqDuWYQKsUVb8Dm3tONXYXA4FhQ
2022-04-04 21:37:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 21:37:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-sd9kq -- curl -v --insecure -X PUT https://keycloak.infra-namespace.svc.cluster.local:8443/auth/admin/realms/master -H Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJ4YUFnLWhoeFQtMjVvTUVvUjU0Y2pnbDRlTGU3TzVGeVZlY2lYS014SmZJIn0.eyJleHAiOjE2NDkxMDgzMTQsImlhdCI6MTY0OTEwODI1NCwianRpIjoiMGRjMjMxY2MtM2NjZi00NTE3LTliZTYtMDY0OGRmNjdiZDU1IiwiaXNzIjoiaHR0cHM6Ly9rZXljbG9hay5pbmZyYS1uYW1lc3BhY2Uuc3ZjLmNsdXN0ZXIubG9jYWw6ODQ0My9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJzdWIiOiI1YzA0NDRiZC1kNmY3LTRmMTEtYmRhYy02ZDBjNGE1NThiMzMiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhZG1pbi1jbGkiLCJzZXNzaW9uX3N0YXRlIjoiOWYyYWVhYmItNzc4My00MzI3LWJlOWEtMTc2ZDQ0YWIyNzBjIiwiYWNyIjoiMSIsInNjb3BlIjoicHJvZmlsZSBlbWFpbCIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4ifQ.SxrTtqW-kQ4T2OWfcifMYOexgiScAJzVk3ETYcA7IfhpsHed9mquLJpCcmtk3Jn7Y8OSbOzS3aC26y21VDMwvL85_5q-NrrveOFDijAs_Flmaq89-S-Nvh85COkA1qAXddQZvqf3gePXQY-LotolDQnPUKkPY_62dfYvYm8BAhyvQyuGzPcAxRvB-3INg2_O4MZrI6cE1vpM9lL_JTljYhFbBD66GcPyGafMSmRJjebKbkL2bd6xWaXVridd9RmdZDMsIiMfvR_jwQQq_1sZv6CBRmByMCr8klxBlDQqjJBAxcuOxhQxk4A-p7-nqDuWYQKsUVb8Dm3tONXYXA4FhQ -d {"id":"master","realm":"master","displayName":"Keycloak","displayNameHtml":"<div class=\"kc-logo-text\"><span>Keycloak</span></div>","notBefore":0,"revokeRefreshToken":false,"refreshTokenMaxReuse":0,"accessTokenLifespan":"3600","accessTokenLifespanForImplicitFlow":900,"ssoSessionIdleTimeout":1800,"ssoSessionMaxLifespan":36000,"ssoSessionIdleTimeoutRememberMe":0,"ssoSessionMaxLifespanRememberMe":0,"offlineSessionIdleTimeout":2592000,"offlineSessionMaxLifespanEnabled":false,"offlineSessionMaxLifespan":5184000,"clientSessionIdleTimeout":0,"clientSessionMaxLifespan":0,"clientOfflineSessionIdleTimeout":0,"clientOfflineSessionMaxLifespan":0,"accessCodeLifespan":60,"accessCodeLifespanUserAction":300,"accessCodeLifespanLogin":1800,"actionTokenGeneratedByAdminLifespan":43200,"actionTokenGeneratedByUserLifespan":300,"enabled":true,"sslRequired":"external","registrationAllowed":false,"registrationEmailAsUsername":false,"rememberMe":false,"verifyEmail":false,"loginWithEmailAllowed":true,"duplicateEmailsAllowed":false,"resetPasswordAllowed":false,"editUsernameAllowed":false,"bruteForceProtected":false,"permanentLockout":false,"maxFailureWaitSeconds":900,"minimumQuickLoginWaitSeconds":60,"waitIncrementSeconds":60,"quickLoginCheckMilliSeconds":1000,"maxDeltaTimeSeconds":43200,"failureFactor":30,"defaultRoles":["offline_access","uma_authorization"],"requiredCredentials":["password"],"otpPolicyType":"totp","otpPolicyAlgorithm":"HmacSHA1","otpPolicyInitialCounter":0,"otpPolicyDigits":6,"otpPolicyLookAheadWindow":1,"otpPolicyPeriod":30,"otpSupportedApplications":["FreeOTP","Google Authenticator"],"webAuthnPolicyRpEntityName":"keycloak","webAuthnPolicySignatureAlgorithms":["ES256"],"webAuthnPolicyRpId":"","webAuthnPolicyAttestationConveyancePreference":"not specified","webAuthnPolicyAuthenticatorAttachment":"not specified","webAuthnPolicyRequireResidentKey":"not specified","webAuthnPolicyUserVerificationRequirement":"not specified","webAuthnPolicyCreateTimeout":0,"webAuthnPolicyAvoidSameAuthenticatorRegister":false,"webAuthnPolicyAcceptableAaguids":[],"webAuthnPolicyPasswordlessRpEntityName":"keycloak","webAuthnPolicyPasswordlessSignatureAlgorithms":["ES256"],"webAuthnPolicyPasswordlessRpId":"","webAuthnPolicyPasswordlessAttestationConveyancePreference":"not specified","webAuthnPolicyPasswordlessAuthenticatorAttachment":"not specified","webAuthnPolicyPasswordlessRequireResidentKey":"not specified","webAuthnPolicyPasswordlessUserVerificationRequirement":"not specified","webAuthnPolicyPasswordlessCreateTimeout":0,"webAuthnPolicyPasswordlessAvoidSameAuthenticatorRegister":false,"webAuthnPolicyPasswordlessAcceptableAaguids":[],"browserSecurityHeaders":{"contentSecurityPolicyReportOnly":"","xContentTypeOptions":"nosniff","xRobotsTag":"none","xFrameOptions":"SAMEORIGIN","xXSSProtection":"1; mode=block","contentSecurityPolicy":"frame-src 'self'; frame-ancestors 'self'; object-src 'none';","strictTransportSecurity":"max-age=31536000; includeSubDomains"},"smtpServer":{},"eventsEnabled":false,"eventsListeners":["jboss-logging"],"enabledEventTypes":[],"adminEventsEnabled":false,"adminEventsDetailsEnabled":false,"internationalizationEnabled":false,"supportedLocales":[],"browserFlow":"browser","registrationFlow":"registration","directGrantFlow":"direct grant","resetCredentialsFlow":"reset credentials","clientAuthenticationFlow":"clients","dockerAuthenticationFlow":"docker auth","attributes":{},"userManagedAccessAllowed":false} -H Content-Type: application/json
2022-04-04 21:37:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 21:37:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-sd9kq -- curl -v --insecure -X POST -d client_id=admin-cli&client_secret=aGVsbG8td29ybGQtcHJvZHVjZXItc2VjcmV0&grant_type=password&username=admin&password=XqdN8agTm6rLkA== https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/master/protocol/openid-connect/token
2022-04-04 21:37:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 21:37:35 [main] [32mINFO [m [OauthAuthorizationIsolatedST:508] Getting the kafka-authz kafka client for obtaining the Dev A Team policy for the x topics
2022-04-04 21:37:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-sd9kq -- curl -v --insecure -X GET https://keycloak.infra-namespace.svc.cluster.local:8443/auth/admin/realms/kafka-authz/clients -H Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJ4YUFnLWhoeFQtMjVvTUVvUjU0Y2pnbDRlTGU3TzVGeVZlY2lYS014SmZJIn0.eyJleHAiOjE2NDkxMTE4NTUsImlhdCI6MTY0OTEwODI1NSwianRpIjoiMzI0YTM0YzktYWY1Yy00MzQwLWFhOTItNmM1MzZlMDdmZGMyIiwiaXNzIjoiaHR0cHM6Ly9rZXljbG9hay5pbmZyYS1uYW1lc3BhY2Uuc3ZjLmNsdXN0ZXIubG9jYWw6ODQ0My9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJzdWIiOiI1YzA0NDRiZC1kNmY3LTRmMTEtYmRhYy02ZDBjNGE1NThiMzMiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhZG1pbi1jbGkiLCJzZXNzaW9uX3N0YXRlIjoiOTM3YzIzZGMtYzAwYS00ODViLWIxM2ItNTNmNDYwZjY0OGI0IiwiYWNyIjoiMSIsInNjb3BlIjoicHJvZmlsZSBlbWFpbCIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4ifQ.QXY2ELECwpxsSQO46xg5y_sCW_wSFDjEzp8RaWc3mGZK_uXPE25qLr36qrGd8lLZT_wnADO44tx9Xsr06UeTkiC4NvZ3m8F7jOL2mrPv8qSdM46Ii1q1-cPUELxC8g3J6T-YTua7PaYDPtsEEAVvELSYOBuwS2GzoBaNX2nF15-tvWb8qifMPaFAXf4LmqmqF9xkltirAqV6Spquxm2SZuSVYxK07iQshJwnMAqofaMMAy32BwMRS3KaVxoLmdWLMaFx1vnjQWsZKP_07uoKgaIcL7Yyqnca3y0j-Wqr50nj6Ugn7IYej3h5J_GzIuHEcRVvVSsX5nBX20ogngAi1g
2022-04-04 21:37:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 21:37:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-sd9kq -- curl -v --insecure -X GET https://keycloak.infra-namespace.svc.cluster.local:8443/auth/admin/realms/kafka-authz/clients/13061dc2-2ce9-4251-84f0-56dd75306b64/authz/resource-server/policy -H Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJ4YUFnLWhoeFQtMjVvTUVvUjU0Y2pnbDRlTGU3TzVGeVZlY2lYS014SmZJIn0.eyJleHAiOjE2NDkxMTE4NTUsImlhdCI6MTY0OTEwODI1NSwianRpIjoiMzI0YTM0YzktYWY1Yy00MzQwLWFhOTItNmM1MzZlMDdmZGMyIiwiaXNzIjoiaHR0cHM6Ly9rZXljbG9hay5pbmZyYS1uYW1lc3BhY2Uuc3ZjLmNsdXN0ZXIubG9jYWw6ODQ0My9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJzdWIiOiI1YzA0NDRiZC1kNmY3LTRmMTEtYmRhYy02ZDBjNGE1NThiMzMiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhZG1pbi1jbGkiLCJzZXNzaW9uX3N0YXRlIjoiOTM3YzIzZGMtYzAwYS00ODViLWIxM2ItNTNmNDYwZjY0OGI0IiwiYWNyIjoiMSIsInNjb3BlIjoicHJvZmlsZSBlbWFpbCIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4ifQ.QXY2ELECwpxsSQO46xg5y_sCW_wSFDjEzp8RaWc3mGZK_uXPE25qLr36qrGd8lLZT_wnADO44tx9Xsr06UeTkiC4NvZ3m8F7jOL2mrPv8qSdM46Ii1q1-cPUELxC8g3J6T-YTua7PaYDPtsEEAVvELSYOBuwS2GzoBaNX2nF15-tvWb8qifMPaFAXf4LmqmqF9xkltirAqV6Spquxm2SZuSVYxK07iQshJwnMAqofaMMAy32BwMRS3KaVxoLmdWLMaFx1vnjQWsZKP_07uoKgaIcL7Yyqnca3y0j-Wqr50nj6Ugn7IYej3h5J_GzIuHEcRVvVSsX5nBX20ogngAi1g
2022-04-04 21:37:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 21:37:36 [main] [32mINFO [m [OauthAuthorizationIsolatedST:539] Changing the Dev Team A policy for topics starting with x- and checking that job will not be successful
2022-04-04 21:37:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-sd9kq -- curl -v --insecure -X PUT https://keycloak.infra-namespace.svc.cluster.local:8443/auth/admin/realms/kafka-authz/clients/13061dc2-2ce9-4251-84f0-56dd75306b64/authz/resource-server/policy/1d2eab0c-4d4b-47ae-951c-91b7dc12023c -H Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJ4YUFnLWhoeFQtMjVvTUVvUjU0Y2pnbDRlTGU3TzVGeVZlY2lYS014SmZJIn0.eyJleHAiOjE2NDkxMTE4NTUsImlhdCI6MTY0OTEwODI1NSwianRpIjoiMzI0YTM0YzktYWY1Yy00MzQwLWFhOTItNmM1MzZlMDdmZGMyIiwiaXNzIjoiaHR0cHM6Ly9rZXljbG9hay5pbmZyYS1uYW1lc3BhY2Uuc3ZjLmNsdXN0ZXIubG9jYWw6ODQ0My9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJzdWIiOiI1YzA0NDRiZC1kNmY3LTRmMTEtYmRhYy02ZDBjNGE1NThiMzMiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhZG1pbi1jbGkiLCJzZXNzaW9uX3N0YXRlIjoiOTM3YzIzZGMtYzAwYS00ODViLWIxM2ItNTNmNDYwZjY0OGI0IiwiYWNyIjoiMSIsInNjb3BlIjoicHJvZmlsZSBlbWFpbCIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4ifQ.QXY2ELECwpxsSQO46xg5y_sCW_wSFDjEzp8RaWc3mGZK_uXPE25qLr36qrGd8lLZT_wnADO44tx9Xsr06UeTkiC4NvZ3m8F7jOL2mrPv8qSdM46Ii1q1-cPUELxC8g3J6T-YTua7PaYDPtsEEAVvELSYOBuwS2GzoBaNX2nF15-tvWb8qifMPaFAXf4LmqmqF9xkltirAqV6Spquxm2SZuSVYxK07iQshJwnMAqofaMMAy32BwMRS3KaVxoLmdWLMaFx1vnjQWsZKP_07uoKgaIcL7Yyqnca3y0j-Wqr50nj6Ugn7IYej3h5J_GzIuHEcRVvVSsX5nBX20ogngAi1g -d {"id":"1d2eab0c-4d4b-47ae-951c-91b7dc12023c","name":"Dev Team A can write to topics that start with x- on any cluster","type":"scope","logic":"POSITIVE","decisionStrategy":"UNANIMOUS","config":{"resources":"[\"Topic:x-*\"]","scopes":"[\"Describe\"]","applyPolicies":"[\"Dev Team A\"]"}} -H Content-Type: application/json
2022-04-04 21:37:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 21:37:36 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-ef5722bc to finished
2022-04-04 21:41:16 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for job finished, null
io.strimzi.test.WaitException: Timeout after 220000 ms waiting for job finished
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientSuccess(ClientUtils.java:77)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientSuccess(ClientUtils.java:72)
	at io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.lambda$testSessionReAuthentication$2(OauthAuthorizationIsolatedST.java:541)
	at org.junit.jupiter.api.AssertThrows.assertThrows(AssertThrows.java:55)
	at org.junit.jupiter.api.AssertThrows.assertThrows(AssertThrows.java:37)
	at org.junit.jupiter.api.Assertions.assertThrows(Assertions.java:3082)
	at io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testSessionReAuthentication(OauthAuthorizationIsolatedST.java:541)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-04 21:41:16 [main] [32mINFO [m [OauthAuthorizationIsolatedST:545] Sending messages to topic starting with a- -> the messages should be successfully sent
2022-04-04 21:41:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-ef5722bc in namespace infra-namespace
2022-04-04 21:41:16 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-ef5722bc will be in active state
2022-04-04 21:41:17 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-ef5722bc to finished
2022-04-04 21:41:26 [main] [32mINFO [m [OauthAuthorizationIsolatedST:554] Changing back to the original settings and checking, if the producer will be successful
2022-04-04 21:41:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-sd9kq -- curl -v --insecure -X PUT https://keycloak.infra-namespace.svc.cluster.local:8443/auth/admin/realms/kafka-authz/clients/13061dc2-2ce9-4251-84f0-56dd75306b64/authz/resource-server/policy/1d2eab0c-4d4b-47ae-951c-91b7dc12023c -H Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJ4YUFnLWhoeFQtMjVvTUVvUjU0Y2pnbDRlTGU3TzVGeVZlY2lYS014SmZJIn0.eyJleHAiOjE2NDkxMTE4NTUsImlhdCI6MTY0OTEwODI1NSwianRpIjoiMzI0YTM0YzktYWY1Yy00MzQwLWFhOTItNmM1MzZlMDdmZGMyIiwiaXNzIjoiaHR0cHM6Ly9rZXljbG9hay5pbmZyYS1uYW1lc3BhY2Uuc3ZjLmNsdXN0ZXIubG9jYWw6ODQ0My9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJzdWIiOiI1YzA0NDRiZC1kNmY3LTRmMTEtYmRhYy02ZDBjNGE1NThiMzMiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhZG1pbi1jbGkiLCJzZXNzaW9uX3N0YXRlIjoiOTM3YzIzZGMtYzAwYS00ODViLWIxM2ItNTNmNDYwZjY0OGI0IiwiYWNyIjoiMSIsInNjb3BlIjoicHJvZmlsZSBlbWFpbCIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4ifQ.QXY2ELECwpxsSQO46xg5y_sCW_wSFDjEzp8RaWc3mGZK_uXPE25qLr36qrGd8lLZT_wnADO44tx9Xsr06UeTkiC4NvZ3m8F7jOL2mrPv8qSdM46Ii1q1-cPUELxC8g3J6T-YTua7PaYDPtsEEAVvELSYOBuwS2GzoBaNX2nF15-tvWb8qifMPaFAXf4LmqmqF9xkltirAqV6Spquxm2SZuSVYxK07iQshJwnMAqofaMMAy32BwMRS3KaVxoLmdWLMaFx1vnjQWsZKP_07uoKgaIcL7Yyqnca3y0j-Wqr50nj6Ugn7IYej3h5J_GzIuHEcRVvVSsX5nBX20ogngAi1g -d {"id":"1d2eab0c-4d4b-47ae-951c-91b7dc12023c","name":"Dev Team A can write to topics that start with x- on any cluster","type":"scope","logic":"POSITIVE","decisionStrategy":"UNANIMOUS","config":{"resources":"[\"Topic:x-*\"]","scopes":"[\"Describe\",\"Write\"]","applyPolicies":"[\"Dev Team A\"]"}} -H Content-Type: application/json
2022-04-04 21:41:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 21:41:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-ef5722bc in namespace infra-namespace
2022-04-04 21:41:27 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-ef5722bc will be in active state
2022-04-04 21:41:28 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-ef5722bc to finished
2022-04-04 21:43:16 [main] [32mINFO [m [OauthAuthorizationIsolatedST:568] Changing configuration of Kafka back to it's original form
2022-04-04 21:43:16 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-authz-name will have desired state: Ready
2022-04-04 21:43:16 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-authz-name is in desired state: Ready
2022-04-04 21:43:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:43:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSessionReAuthentication
2022-04-04 21:43:16 [main] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-ef5722bc in namespace infra-namespace
2022-04-04 21:43:16 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-ef5722bc in namespace infra-namespace
2022-04-04 21:43:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-ef5722bc in namespace infra-namespace
2022-04-04 21:43:16 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic x-topic-example-topic in namespace infra-namespace
2022-04-04 21:43:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic a-topic-example-topic in namespace infra-namespace
2022-04-04 21:43:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:43:26 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testSessionReAuthentication-FINISHED
2022-04-04 21:43:26 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:43:26 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:43:26 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testKeycloakAuthorizerToDelegateToSimpleAuthorizer-STARTED
2022-04-04 21:43:26 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:43:26 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-97 for test case:testKeycloakAuthorizerToDelegateToSimpleAuthorizer
2022-04-04 21:43:26 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-97
2022-04-04 21:43:26 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-97
2022-04-04 21:43:26 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-97
2022-04-04 21:43:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Secret sso-x509-https-secret in namespace infra-namespace
2022-04-04 21:43:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-04 21:43:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Secret team-a-client-secret in namespace infra-namespace
2022-04-04 21:43:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-04 21:43:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Secret team-b-client-secret in namespace infra-namespace
2022-04-04 21:43:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-04 21:43:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5a58f9bd in namespace namespace-97
2022-04-04 21:43:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-04 21:43:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5a58f9bd will have desired state: Ready
2022-04-04 21:44:39 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5a58f9bd is in desired state: Ready
2022-04-04 21:44:39 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser team-a-client in namespace namespace-97
2022-04-04 21:44:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-04 21:44:39 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: team-a-client will have desired state: Ready
2022-04-04 21:44:40 [main] [32mINFO [m [ResourceManager:444] KafkaUser: team-a-client is in desired state: Ready
2022-04-04 21:44:40 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser team-b-client in namespace namespace-97
2022-04-04 21:44:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-04 21:44:40 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: team-b-client will have desired state: Ready
2022-04-04 21:44:41 [main] [32mINFO [m [ResourceManager:444] KafkaUser: team-b-client is in desired state: Ready
2022-04-04 21:44:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic a-topic-my-topic-1449388578-1123655669 in namespace namespace-97
2022-04-04 21:44:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-04 21:44:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: a-topic-my-topic-1449388578-1123655669 will have desired state: Ready
2022-04-04 21:44:42 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: a-topic-my-topic-1449388578-1123655669 is in desired state: Ready
2022-04-04 21:44:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-5a58f9bd in namespace namespace-97
2022-04-04 21:44:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-04 21:44:42 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-5a58f9bd will be in active state
2022-04-04 21:44:43 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-5a58f9bd to finished
2022-04-04 21:44:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-consumer-my-cluster-5a58f9bd in namespace namespace-97
2022-04-04 21:44:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-04 21:44:51 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-consumer-my-cluster-5a58f9bd will be in active state
2022-04-04 21:44:52 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-consumer-my-cluster-5a58f9bd to finished
2022-04-04 21:44:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:44:59 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKeycloakAuthorizerToDelegateToSimpleAuthorizer
2022-04-04 21:44:59 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser team-b-client in namespace namespace-97
2022-04-04 21:44:59 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser team-a-client in namespace namespace-97
2022-04-04 21:44:59 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic a-topic-my-topic-1449388578-1123655669 in namespace namespace-97
2022-04-04 21:44:59 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-5a58f9bd in namespace namespace-97
2022-04-04 21:44:59 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-consumer-my-cluster-5a58f9bd in namespace namespace-97
2022-04-04 21:44:59 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Secret team-a-client-secret in namespace namespace-97
2022-04-04 21:44:59 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Secret team-b-client-secret in namespace namespace-97
2022-04-04 21:44:59 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5a58f9bd in namespace namespace-97
2022-04-04 21:44:59 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Secret sso-x509-https-secret in namespace namespace-97
2022-04-04 21:45:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:45:09 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-97 for test case:testKeycloakAuthorizerToDelegateToSimpleAuthorizer
2022-04-04 21:45:14 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testKeycloakAuthorizerToDelegateToSimpleAuthorizer-FINISHED
2022-04-04 21:45:14 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:45:14 [main] [32mINFO [m [KeycloakUtils:52] Teardown Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-04 21:45:18 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/teardown_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-04 21:45:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 21:45:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:45:18 [main] [32mINFO [m [ResourceManager:348] Delete all resources for OauthAuthorizationIsolatedST
2022-04-04 21:45:18 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser team-a-client in namespace infra-namespace
2022-04-04 21:45:18 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-authz-name in namespace infra-namespace
2022-04-04 21:45:18 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-04 21:45:18 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser team-b-client in namespace infra-namespace
2022-04-04 21:45:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:45:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:45:28 [main] [32mINFO [m [ResourceManager:346] In context OauthAuthorizationIsolatedST is everything deleted.
2022-04-04 21:45:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;33mWARNING[m] Tests run: 10, Failures: 0, Errors: 0, Skipped: 2, Time elapsed: 1,045.646 s - in io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST
2022-04-04 21:45:28 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 21:45:53 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 21:45:53 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 21:45:53 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 21:45:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:45:53 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 21:45:53 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 21:45:53 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 21:45:53 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 21:45:53 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:45:53 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 21:45:53 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 21:45:53 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 21:45:53 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 21:45:53 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 21:45:53 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 21:45:53 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 21:45:53 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 21:45:53 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 21:45:53 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 21:45:53 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:45:54 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 21:46:03 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 21:46:03 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 21:46:03 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:46:04 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 21:46:04 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 21:46:04 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 21:46:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 21:46:04 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:46:04 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 21:46:14 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:46:19 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 21:46:19 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 21:46:19 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 21:46:19 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 21:46:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:46:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 21:46:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 21:46:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 21:46:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 21:46:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 21:46:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 21:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 21:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 21:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 21:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 21:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 21:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 21:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 21:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 21:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 21:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:46:20 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 21:46:20 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 21:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 21:46:20 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 21:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 21:46:20 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 21:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 21:46:20 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 21:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:46:20 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 21:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 21:46:20 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 21:46:20 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 21:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 21:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 21:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:46:20 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 21:46:57 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 21:46:57 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 21:47:07 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 21:47:07 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-04 21:47:07 [main] [32mINFO [m [OauthAbstractST:125] Deploying keycloak...
2022-04-04 21:47:07 [main] [32mINFO [m [KeycloakUtils:35] Prepare Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-04 21:48:50 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/prepare_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-04 21:48:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 21:48:50 [main] [32mINFO [m [KeycloakUtils:48] Keycloak in namespace infra-namespace is ready
2022-04-04 21:48:50 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret credential-example-keycloak
2022-04-04 21:48:50 [main] [32mINFO [m [SecretUtils:50] Secret credential-example-keycloak created
2022-04-04 21:48:50 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-producer-secret
2022-04-04 21:48:50 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-consumer-secret
2022-04-04 21:48:50 [main] [32mINFO [m [SecretUtils:70] Creating secret team-a-client-secret
2022-04-04 21:48:50 [main] [32mINFO [m [SecretUtils:70] Creating secret team-b-client-secret
2022-04-04 21:48:50 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-broker-secret
2022-04-04 21:48:50 [main] [32mINFO [m [SecretUtils:70] Creating secret my-connect-oauth
2022-04-04 21:48:50 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-oauth
2022-04-04 21:48:50 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-2-oauth
2022-04-04 21:48:50 [main] [32mINFO [m [SecretUtils:70] Creating secret my-bridge-oauth
2022-04-04 21:48:50 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-audience-secret
2022-04-04 21:48:50 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-client-secret
2022-04-04 21:48:50 [main] [32mINFO [m [KeycloakInstance:50] Replacing validIssuerUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal to pointing to scope-test realm
2022-04-04 21:48:50 [main] [32mINFO [m [KeycloakInstance:51] Replacing jwksEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/certs to pointing to scope-test realm
2022-04-04 21:48:50 [main] [32mINFO [m [KeycloakInstance:52] Replacing oauthTokenEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token to pointing to scope-test realm
2022-04-04 21:48:50 [main] [32mINFO [m [KeycloakInstance:60] Using HTTP endpoints
2022-04-04 21:48:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-scope-name in namespace infra-namespace
2022-04-04 21:48:50 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-scope-name will have desired state: Ready
2022-04-04 21:49:56 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-scope-name is in desired state: Ready
2022-04-04 21:49:56 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:49:56 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testScopeKafkaConnectSetCorrectly-STARTED
2022-04-04 21:49:56 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:49:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-f6f90966-kafka-clients in namespace infra-namespace
2022-04-04 21:49:56 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f6f90966-kafka-clients will be ready
2022-04-04 21:49:58 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f6f90966-kafka-clients is ready
2022-04-04 21:49:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-f6f90966-scraper in namespace infra-namespace
2022-04-04 21:49:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f6f90966-scraper will be ready
2022-04-04 21:50:00 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f6f90966-scraper is ready
2022-04-04 21:50:00 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-f6f90966-scraper to be ready
2022-04-04 21:50:10 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-f6f90966-scraper is ready
2022-04-04 21:50:10 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-f6f90966-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 21:50:10 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-f6f90966-allow in namespace infra-namespace
2022-04-04 21:50:10 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 21:50:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-f6f90966 in namespace infra-namespace
2022-04-04 21:50:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-f6f90966 will have desired state: Ready
2022-04-04 21:51:14 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-f6f90966 is in desired state: Ready
2022-04-04 21:51:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:51:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScopeKafkaConnectSetCorrectly
2022-04-04 21:51:14 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-f6f90966-allow in namespace infra-namespace
2022-04-04 21:51:14 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-f6f90966 in namespace infra-namespace
2022-04-04 21:51:14 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-f6f90966-kafka-clients in namespace infra-namespace
2022-04-04 21:51:14 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-f6f90966-scraper in namespace infra-namespace
2022-04-04 21:51:54 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:51:54 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testScopeKafkaConnectSetCorrectly-FINISHED
2022-04-04 21:51:54 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:51:54 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:51:54 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testScopeKafkaConnectSetIncorrectly-STARTED
2022-04-04 21:51:54 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:51:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-75669502-kafka-clients in namespace infra-namespace
2022-04-04 21:51:54 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-75669502-kafka-clients will be ready
2022-04-04 21:51:55 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-75669502-kafka-clients is ready
2022-04-04 21:51:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-75669502-scraper in namespace infra-namespace
2022-04-04 21:51:55 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-75669502-scraper will be ready
2022-04-04 21:51:56 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-75669502-scraper is ready
2022-04-04 21:51:56 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-75669502-scraper to be ready
2022-04-04 21:52:06 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-75669502-scraper is ready
2022-04-04 21:52:06 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-75669502-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 21:52:06 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-75669502-allow in namespace infra-namespace
2022-04-04 21:52:06 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 21:52:06 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-75669502 in namespace infra-namespace
2022-04-04 21:52:20 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:52:20 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScopeKafkaConnectSetIncorrectly
2022-04-04 21:52:20 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-75669502-allow in namespace infra-namespace
2022-04-04 21:52:20 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-75669502 in namespace infra-namespace
2022-04-04 21:52:20 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-75669502-kafka-clients in namespace infra-namespace
2022-04-04 21:52:20 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-75669502-scraper in namespace infra-namespace
2022-04-04 21:53:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:53:10 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testScopeKafkaConnectSetIncorrectly-FINISHED
2022-04-04 21:53:10 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:53:10 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:53:10 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testClientScopeKafkaSetCorrectly-STARTED
2022-04-04 21:53:10 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:53:10 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 21:53:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-973179438-1216440319 in namespace infra-namespace
2022-04-04 21:53:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-973179438-1216440319 will have desired state: Ready
2022-04-04 21:53:11 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-973179438-1216440319 is in desired state: Ready
2022-04-04 21:53:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-d5311c2a in namespace infra-namespace
2022-04-04 21:53:11 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-d5311c2a will be in active state
2022-04-04 21:53:12 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-d5311c2a to finished
2022-04-04 21:53:20 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:53:20 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testClientScopeKafkaSetCorrectly
2022-04-04 21:53:20 [main] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-d5311c2a in namespace infra-namespace
2022-04-04 21:53:20 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-973179438-1216440319 in namespace infra-namespace
2022-04-04 21:53:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:53:30 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testClientScopeKafkaSetCorrectly-FINISHED
2022-04-04 21:53:30 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:53:30 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:53:30 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testClientScopeKafkaSetIncorrectly-STARTED
2022-04-04 21:53:30 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:53:30 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 21:53:30 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 1 Pod(s) of oauth-cluster-scope-name-kafka to be ready
2022-04-04 21:54:08 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-scope-name will have desired state: Ready
2022-04-04 21:54:08 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-scope-name is in desired state: Ready
2022-04-04 21:54:08 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: oauth-cluster-scope-name is ready
2022-04-04 21:54:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1313199862-93422375 in namespace infra-namespace
2022-04-04 21:54:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1313199862-93422375 will have desired state: Ready
2022-04-04 21:54:09 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1313199862-93422375 is in desired state: Ready
2022-04-04 21:54:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-611e6013 in namespace infra-namespace
2022-04-04 21:54:09 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-611e6013 will be in active state
2022-04-04 21:54:10 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:oauth-producer-my-cluster-611e6013 to finish with failure.
2022-04-04 21:57:50 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
io.strimzi.test.WaitException: Timeout after 220000 ms waiting for Job did not finish within time limit (as expected).
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientTimeout(ClientUtils.java:91)
	at io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testClientScopeKafkaSetIncorrectly(OauthScopeIsolatedST.java:224)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-04 21:57:50 [main] [32mINFO [m [ClientUtils:100] Client job 'oauth-producer-my-cluster-611e6013' finished with expected timeout.
2022-04-04 21:57:55 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 1 Pod(s) of oauth-cluster-scope-name-kafka to be ready
2022-04-04 21:58:43 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-scope-name will have desired state: Ready
2022-04-04 21:58:43 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-scope-name is in desired state: Ready
2022-04-04 21:58:43 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: oauth-cluster-scope-name is ready
2022-04-04 21:58:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:58:43 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testClientScopeKafkaSetIncorrectly
2022-04-04 21:58:43 [main] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-611e6013 in namespace infra-namespace
2022-04-04 21:58:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1313199862-93422375 in namespace infra-namespace
2022-04-04 21:58:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:58:53 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testClientScopeKafkaSetIncorrectly-FINISHED
2022-04-04 21:58:53 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:58:53 [main] [32mINFO [m [KeycloakUtils:52] Teardown Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-04 21:58:57 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/teardown_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-04 21:58:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 21:58:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:58:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for OauthScopeIsolatedST
2022-04-04 21:58:57 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-scope-name in namespace infra-namespace
2022-04-04 21:58:57 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-04 21:59:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:59:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:59:07 [main] [32mINFO [m [ResourceManager:346] In context OauthScopeIsolatedST is everything deleted.
2022-04-04 21:59:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 818.273 s - in io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST
2022-04-04 21:59:07 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 21:59:32 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 21:59:32 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 21:59:32 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 21:59:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:59:32 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 21:59:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 21:59:32 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 21:59:32 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 21:59:32 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 21:59:32 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 21:59:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:59:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 21:59:32 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 21:59:32 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 21:59:32 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:59:32 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 21:59:32 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 21:59:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 21:59:32 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 21:59:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:59:32 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 21:59:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 21:59:32 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 21:59:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 21:59:32 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 21:59:32 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:59:32 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 21:59:42 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 21:59:42 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 21:59:42 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 21:59:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:59:57 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 21:59:57 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 21:59:57 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 21:59:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 21:59:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:59:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 21:59:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 21:59:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 21:59:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 21:59:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 21:59:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 21:59:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 21:59:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 21:59:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 21:59:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 21:59:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 21:59:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 21:59:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 21:59:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 21:59:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 21:59:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:59:58 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 21:59:58 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 21:59:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 21:59:58 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 21:59:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 21:59:58 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 21:59:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 21:59:58 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 21:59:58 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:59:58 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 21:59:58 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 21:59:58 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 21:59:58 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 21:59:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 21:59:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 21:59:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:59:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 22:00:31 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 22:00:31 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 22:00:41 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 22:00:41 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-04 22:00:41 [main] [32mINFO [m [OauthAbstractST:125] Deploying keycloak...
2022-04-04 22:00:41 [main] [32mINFO [m [KeycloakUtils:35] Prepare Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-04 22:02:08 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/prepare_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-04 22:02:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 22:02:08 [main] [32mINFO [m [KeycloakUtils:48] Keycloak in namespace infra-namespace is ready
2022-04-04 22:02:08 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret credential-example-keycloak
2022-04-04 22:02:08 [main] [32mINFO [m [SecretUtils:50] Secret credential-example-keycloak created
2022-04-04 22:02:08 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-producer-secret
2022-04-04 22:02:08 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-consumer-secret
2022-04-04 22:02:08 [main] [32mINFO [m [SecretUtils:70] Creating secret team-a-client-secret
2022-04-04 22:02:09 [main] [32mINFO [m [SecretUtils:70] Creating secret team-b-client-secret
2022-04-04 22:02:09 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-broker-secret
2022-04-04 22:02:09 [main] [32mINFO [m [SecretUtils:70] Creating secret my-connect-oauth
2022-04-04 22:02:09 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-oauth
2022-04-04 22:02:09 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-2-oauth
2022-04-04 22:02:09 [main] [32mINFO [m [SecretUtils:70] Creating secret my-bridge-oauth
2022-04-04 22:02:09 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-audience-secret
2022-04-04 22:02:09 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-client-secret
2022-04-04 22:02:09 [main] [32mINFO [m [KeycloakInstance:50] Replacing validIssuerUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal to pointing to internal realm
2022-04-04 22:02:09 [main] [32mINFO [m [KeycloakInstance:51] Replacing jwksEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/certs to pointing to internal realm
2022-04-04 22:02:09 [main] [32mINFO [m [KeycloakInstance:52] Replacing oauthTokenEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token to pointing to internal realm
2022-04-04 22:02:09 [main] [32mINFO [m [KeycloakInstance:55] Using HTTPS endpoints
2022-04-04 22:02:09 [main] [32mINFO [m [OauthTlsIsolatedST:480] Keycloak settings KeycloakInstance{jwksExpireSeconds=500, jwksRefreshSeconds=400, username='admin', password='ZZOONi1t4JstmQ==', httpsUri='keycloak.infra-namespace.svc.cluster.local:8443', httpUri='keycloak-discovery.infra-namespace.svc.cluster.local:8080', validIssuerUri='https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal', jwksEndpointUri='https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/certs', oauthTokenEndpointUri='https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token', introspectionEndpointUri='https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token/introspect', userNameClaim='preferred_username', keystorePattern=<tls>\s*<key-stores>\s*<key-store name="kcKeyStore">\s*<credential-reference clear-text=".*"\/>, keystorePasswordPattern=\".*\"}
2022-04-04 22:02:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-tls-name in namespace infra-namespace
2022-04-04 22:02:09 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-tls-name will have desired state: Ready
2022-04-04 22:03:27 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-tls-name is in desired state: Ready
2022-04-04 22:03:27 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser hello-world-producer in namespace infra-namespace
2022-04-04 22:03:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: hello-world-producer will have desired state: Ready
2022-04-04 22:03:28 [main] [32mINFO [m [ResourceManager:444] KafkaUser: hello-world-producer is in desired state: Ready
2022-04-04 22:03:28 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 22:03:28 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testProducerConsumerBridge-STARTED
2022-04-04 22:03:28 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 22:03:28 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-546972930-1305438197 in namespace infra-namespace
2022-04-04 22:03:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-546972930-1305438197 will have desired state: Ready
2022-04-04 22:03:29 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-546972930-1305438197 is in desired state: Ready
2022-04-04 22:03:29 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 22:03:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-8ce85953 in namespace infra-namespace
2022-04-04 22:03:29 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-8ce85953 will be in active state
2022-04-04 22:03:30 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-8ce85953 to finished
2022-04-04 22:03:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-8ce85953 in namespace infra-namespace
2022-04-04 22:03:38 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-8ce85953 will be in active state
2022-04-04 22:03:39 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-8ce85953 to finished
2022-04-04 22:03:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-8ce85953-kafka-clients in namespace infra-namespace
2022-04-04 22:03:51 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-8ce85953-kafka-clients will be ready
2022-04-04 22:03:53 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-8ce85953-kafka-clients is ready
2022-04-04 22:03:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge oauth-cluster-tls-name in namespace infra-namespace
2022-04-04 22:03:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: oauth-cluster-tls-name will have desired state: Ready
2022-04-04 22:04:11 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: oauth-cluster-tls-name is in desired state: Ready
2022-04-04 22:04:11 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 22:04:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Job bridge-producer-my-cluster-8ce85953 in namespace infra-namespace
2022-04-04 22:04:11 [main] [32mINFO [m [JobUtils:81] Waiting for job: bridge-producer-my-cluster-8ce85953 will be in active state
2022-04-04 22:04:12 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:bridge-producer-my-cluster-8ce85953 to finished
2022-04-04 22:04:30 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:04:30 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerBridge
2022-04-04 22:04:30 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-8ce85953-kafka-clients in namespace infra-namespace
2022-04-04 22:04:30 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-546972930-1305438197 in namespace infra-namespace
2022-04-04 22:04:30 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job bridge-producer-my-cluster-8ce85953 in namespace infra-namespace
2022-04-04 22:04:30 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge oauth-cluster-tls-name in namespace infra-namespace
2022-04-04 22:04:30 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-8ce85953 in namespace infra-namespace
2022-04-04 22:04:30 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-8ce85953 in namespace infra-namespace
2022-04-04 22:05:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:05:10 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testProducerConsumerBridge-FINISHED
2022-04-04 22:05:10 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 22:05:10 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 22:05:10 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testProducerConsumer-STARTED
2022-04-04 22:05:10 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 22:05:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2116644535-766362517 in namespace infra-namespace
2022-04-04 22:05:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2116644535-766362517 will have desired state: Ready
2022-04-04 22:05:11 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2116644535-766362517 is in desired state: Ready
2022-04-04 22:05:11 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 22:05:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-d71c2a0a in namespace infra-namespace
2022-04-04 22:05:11 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-d71c2a0a will be in active state
2022-04-04 22:05:12 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-d71c2a0a to finished
2022-04-04 22:05:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-d71c2a0a in namespace infra-namespace
2022-04-04 22:05:21 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-d71c2a0a will be in active state
2022-04-04 22:05:22 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-d71c2a0a to finished
2022-04-04 22:05:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:05:33 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumer
2022-04-04 22:05:33 [main] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-d71c2a0a in namespace infra-namespace
2022-04-04 22:05:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-d71c2a0a in namespace infra-namespace
2022-04-04 22:05:33 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2116644535-766362517 in namespace infra-namespace
2022-04-04 22:05:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:05:43 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testProducerConsumer-FINISHED
2022-04-04 22:05:43 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 22:05:43 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 22:05:43 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testIntrospectionEndpoint-STARTED
2022-04-04 22:05:43 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 22:05:43 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-906715811-1246292896 in namespace infra-namespace
2022-04-04 22:05:43 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-906715811-1246292896 will have desired state: Ready
2022-04-04 22:05:44 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-906715811-1246292896 is in desired state: Ready
2022-04-04 22:05:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-tls-name-intro in namespace infra-namespace
2022-04-04 22:05:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-tls-name-intro will have desired state: Ready
2022-04-04 22:06:57 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-tls-name-intro is in desired state: Ready
2022-04-04 22:06:57 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 22:06:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-6bc7c758 in namespace infra-namespace
2022-04-04 22:06:57 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-6bc7c758 will be in active state
2022-04-04 22:06:58 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-6bc7c758 to finished
2022-04-04 22:07:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-6bc7c758 in namespace infra-namespace
2022-04-04 22:07:07 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-6bc7c758 will be in active state
2022-04-04 22:07:08 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-6bc7c758 to finished
2022-04-04 22:07:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:07:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testIntrospectionEndpoint
2022-04-04 22:07:19 [main] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-6bc7c758 in namespace infra-namespace
2022-04-04 22:07:19 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-6bc7c758 in namespace infra-namespace
2022-04-04 22:07:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-906715811-1246292896 in namespace infra-namespace
2022-04-04 22:07:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-tls-name-intro in namespace infra-namespace
2022-04-04 22:07:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:07:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testIntrospectionEndpoint-FINISHED
2022-04-04 22:07:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 22:07:29 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 22:07:29 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testProducerConsumerConnect-STARTED
2022-04-04 22:07:29 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 22:07:29 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1295769580-1529692603 in namespace infra-namespace
2022-04-04 22:07:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1295769580-1529692603 will have desired state: Ready
2022-04-04 22:07:30 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1295769580-1529692603 is in desired state: Ready
2022-04-04 22:07:30 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 22:07:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-795a9a21 in namespace infra-namespace
2022-04-04 22:07:30 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-795a9a21 will be in active state
2022-04-04 22:07:31 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-795a9a21 to finished
2022-04-04 22:07:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-795a9a21 in namespace infra-namespace
2022-04-04 22:07:40 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-795a9a21 will be in active state
2022-04-04 22:07:41 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-795a9a21 to finished
2022-04-04 22:07:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment oauth-cluster-tls-name-kafka-clients in namespace infra-namespace
2022-04-04 22:07:52 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: oauth-cluster-tls-name-kafka-clients will be ready
2022-04-04 22:07:54 [main] [32mINFO [m [DeploymentUtils:168] Deployment: oauth-cluster-tls-name-kafka-clients is ready
2022-04-04 22:07:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-795a9a21-scraper in namespace infra-namespace
2022-04-04 22:07:54 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-795a9a21-scraper will be ready
2022-04-04 22:07:56 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-795a9a21-scraper is ready
2022-04-04 22:07:56 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-795a9a21-scraper to be ready
2022-04-04 22:08:06 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-795a9a21-scraper is ready
2022-04-04 22:08:06 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-795a9a21-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 22:08:06 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-795a9a21-allow in namespace infra-namespace
2022-04-04 22:08:06 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 22:08:06 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-795a9a21 in namespace infra-namespace
2022-04-04 22:08:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-795a9a21 will have desired state: Ready
2022-04-04 22:09:11 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-795a9a21 is in desired state: Ready
2022-04-04 22:09:11 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-04 22:09:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-795a9a21-connect-57674ff7c4-llhhs -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-04 22:09:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 22:09:11 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-04 22:09:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec oauth-cluster-tls-name-kafka-clients-8cb45f87d-th8lh -- /bin/bash -c curl -X POST -H "Content-Type: application/json" --data '{ "name": "sink-test", "config": { "connector.class": "FileStreamSink", "tasks.max": "1", "topics": "my-topic-1295769580-1529692603", "file": "/tmp/test-file-sink.txt" } }' http://my-cluster-795a9a21-connect-api.infra-namespace.svc:8083/connectors
2022-04-04 22:09:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 22:09:12 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-795a9a21-connect-57674ff7c4-llhhs
2022-04-04 22:09:15 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-795a9a21-connect-57674ff7c4-llhhs
2022-04-04 22:09:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:09:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerConnect
2022-04-04 22:09:16 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-795a9a21-scraper in namespace infra-namespace
2022-04-04 22:09:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment oauth-cluster-tls-name-kafka-clients in namespace infra-namespace
2022-04-04 22:09:16 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-795a9a21 in namespace infra-namespace
2022-04-04 22:09:16 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-795a9a21 in namespace infra-namespace
2022-04-04 22:09:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1295769580-1529692603 in namespace infra-namespace
2022-04-04 22:09:16 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-795a9a21 in namespace infra-namespace
2022-04-04 22:09:16 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-795a9a21-allow in namespace infra-namespace
2022-04-04 22:09:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:09:56 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testProducerConsumerConnect-FINISHED
2022-04-04 22:09:56 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 22:09:56 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 22:09:56 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testMirrorMaker-STARTED
2022-04-04 22:09:56 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 22:09:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1499941235-1383096444 in namespace infra-namespace
2022-04-04 22:09:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1499941235-1383096444 will have desired state: Ready
2022-04-04 22:09:57 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1499941235-1383096444 is in desired state: Ready
2022-04-04 22:09:57 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 22:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-b016d555 in namespace infra-namespace
2022-04-04 22:09:57 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-b016d555 will be in active state
2022-04-04 22:09:58 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-b016d555 to finished
2022-04-04 22:10:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-b016d555 in namespace infra-namespace
2022-04-04 22:10:06 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-b016d555 will be in active state
2022-04-04 22:10:07 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-b016d555 to finished
2022-04-04 22:10:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-tls-name-target in namespace infra-namespace
2022-04-04 22:10:19 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-tls-name-target will have desired state: Ready
2022-04-04 22:11:24 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-tls-name-target is in desired state: Ready
2022-04-04 22:11:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker oauth-cluster-tls-name in namespace infra-namespace
2022-04-04 22:11:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: oauth-cluster-tls-name will have desired state: Ready
2022-04-04 22:12:34 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: oauth-cluster-tls-name is in desired state: Ready
2022-04-04 22:12:34 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1370630507-669433604 in namespace infra-namespace
2022-04-04 22:12:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1370630507-669433604 will have desired state: Ready
2022-04-04 22:12:35 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1370630507-669433604 is in desired state: Ready
2022-04-04 22:12:35 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret my-user-1370630507-669433604
2022-04-04 22:12:35 [main] [32mINFO [m [SecretUtils:50] Secret my-user-1370630507-669433604 created
2022-04-04 22:12:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1370630507-669433604 will have desired state: Ready
2022-04-04 22:12:35 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1370630507-669433604 is in desired state: Ready
2022-04-04 22:12:35 [main] [32mINFO [m [OauthTlsIsolatedST:390] Creating new client with new consumer-group and also to point on oauth-cluster-tls-name-target cluster
2022-04-04 22:12:35 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 22:12:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-b016d555 in namespace infra-namespace
2022-04-04 22:12:35 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-b016d555 will be in active state
2022-04-04 22:12:37 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-b016d555 to finished
2022-04-04 22:12:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:12:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker
2022-04-04 22:12:48 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker oauth-cluster-tls-name in namespace infra-namespace
2022-04-04 22:12:48 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-b016d555 in namespace infra-namespace
2022-04-04 22:12:48 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1499941235-1383096444 in namespace infra-namespace
2022-04-04 22:12:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1370630507-669433604 in namespace infra-namespace
2022-04-04 22:12:48 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-tls-name-target in namespace infra-namespace
2022-04-04 22:12:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-b016d555 in namespace infra-namespace
2022-04-04 22:12:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-b016d555 in namespace infra-namespace
2022-04-04 22:12:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:12:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testMirrorMaker-FINISHED
2022-04-04 22:12:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 22:12:58 [main] [32mINFO [m [KeycloakUtils:52] Teardown Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-04 22:13:02 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/teardown_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-04 22:13:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 22:13:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:13:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for OauthTlsIsolatedST
2022-04-04 22:13:02 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-tls-name in namespace infra-namespace
2022-04-04 22:13:02 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaUser hello-world-producer in namespace infra-namespace
2022-04-04 22:13:02 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-04 22:13:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:13:12 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:13:12 [main] [32mINFO [m [ResourceManager:346] In context OauthTlsIsolatedST is everything deleted.
2022-04-04 22:13:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 845.083 s - in io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST
2022-04-04 22:13:12 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 22:13:37 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 22:13:37 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 22:13:37 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 22:13:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:13:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 22:13:37 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 22:13:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 22:13:37 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 22:13:37 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 22:13:37 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 22:13:37 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 22:13:37 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 22:13:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:13:37 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 22:13:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:13:37 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 22:13:37 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 22:13:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 22:13:37 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:13:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 22:13:37 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 22:13:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 22:13:37 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 22:13:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 22:13:37 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:13:37 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 22:13:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 22:13:37 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 22:13:47 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 22:13:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 22:13:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:14:03 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=120000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 22:14:03 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 22:14:03 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 22:14:03 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 22:14:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:14:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 22:14:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 22:14:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 22:14:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 22:14:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 22:14:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 22:14:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 22:14:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 22:14:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 22:14:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 22:14:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 22:14:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 22:14:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 22:14:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 22:14:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 22:14:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:14:03 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 22:14:03 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 22:14:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 22:14:03 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 22:14:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 22:14:03 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 22:14:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 22:14:03 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 22:14:03 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:14:03 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 22:14:03 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 22:14:03 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 22:14:03 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 22:14:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 22:14:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 22:14:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:14:03 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 22:14:33 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 22:14:33 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 22:14:43 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 22:14:43 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 22:14:43 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaRollsWhenTopicIsUnderReplicated-STARTED
2022-04-04 22:14:43 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 22:14:43 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-98 for test case:testKafkaRollsWhenTopicIsUnderReplicated
2022-04-04 22:14:43 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-98
2022-04-04 22:14:43 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-98
2022-04-04 22:14:43 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-98
2022-04-04 22:14:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1896224c in namespace namespace-98
2022-04-04 22:14:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-98
2022-04-04 22:14:43 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1896224c will have desired state: Ready
2022-04-04 22:16:27 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1896224c is in desired state: Ready
2022-04-04 22:16:27 [main] [32mINFO [m [KafkaRollerIsolatedST:105] Running kafkaScaleUpScaleDown my-cluster-1896224c
2022-04-04 22:16:27 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-1896224c-kafka rolling update
2022-04-04 22:17:47 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-1896224c-kafka has been successfully rolled
2022-04-04 22:17:47 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 4 Pod(s) of my-cluster-1896224c-kafka to be ready
2022-04-04 22:18:41 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1896224c will have desired state: Ready
2022-04-04 22:18:41 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1896224c is in desired state: Ready
2022-04-04 22:18:41 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-1896224c is ready
2022-04-04 22:18:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-706103639-2072735128 in namespace namespace-98
2022-04-04 22:18:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-98
2022-04-04 22:18:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-706103639-2072735128 will have desired state: Ready
2022-04-04 22:18:43 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-706103639-2072735128 is in desired state: Ready
2022-04-04 22:18:43 [main] [32mINFO [m [KafkaRollerIsolatedST:124] Scaling down to 3
2022-04-04 22:18:43 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-1896224c-kafka rolling update
2022-04-04 22:20:03 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-1896224c-kafka has been successfully rolled
2022-04-04 22:20:03 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-1896224c-kafka to be ready
2022-04-04 22:20:29 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1896224c will have desired state: Ready
2022-04-04 22:20:29 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1896224c is in desired state: Ready
2022-04-04 22:20:29 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-1896224c is ready
2022-04-04 22:20:29 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-1896224c are stable
2022-04-04 22:20:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 22:20:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 22:20:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 22:20:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 22:20:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 22:20:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 22:20:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 22:20:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 22:20:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 22:20:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 22:20:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 22:20:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 22:20:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 22:20:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 22:20:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 22:20:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 22:20:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 22:20:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 22:20:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 22:20:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 22:20:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 22:20:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 22:20:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 22:20:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 22:20:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 22:20:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 22:20:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 22:20:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 22:20:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 22:20:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 22:20:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 22:20:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 22:20:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 22:20:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 22:20:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 22:20:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 22:20:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 22:20:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 22:20:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 22:20:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 22:20:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 22:20:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 22:20:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 22:20:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 22:20:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 22:20:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 22:20:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 22:20:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 22:20:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 22:20:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 22:20:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 22:20:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 22:20:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 22:20:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 22:20:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 22:20:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 22:20:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 22:20:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 22:20:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 22:20:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 22:20:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 22:20:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 22:20:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 22:20:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 22:20:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 22:20:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 22:20:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 22:20:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 22:20:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 22:20:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 22:20:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 22:20:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 22:20:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 22:20:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 22:20:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 22:20:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 22:20:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 22:20:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 22:20:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 22:20:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 22:20:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 22:20:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 22:20:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 22:20:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 22:20:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 22:20:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 22:20:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 22:20:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 22:20:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 22:20:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 22:20:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 22:20:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 22:20:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 22:20:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 22:20:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 22:20:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 22:20:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 22:20:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 22:20:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 22:20:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 22:20:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 22:20:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 22:20:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 22:20:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 22:20:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 22:20:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 22:20:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 22:20:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 22:20:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 22:20:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 22:20:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 22:20:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 22:20:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 22:20:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 22:20:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 22:20:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 22:20:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 22:20:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 22:20:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 22:20:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 22:20:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 22:20:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 22:20:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 22:20:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 22:20:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 22:20:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 22:20:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 22:20:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 22:20:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 22:20:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 22:20:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 22:20:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 22:20:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 22:20:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 22:20:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 22:20:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 22:20:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 22:20:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 22:20:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 22:20:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 22:20:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 22:20:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 22:20:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 22:20:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 22:20:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 22:20:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 22:20:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 22:20:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 22:20:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 22:20:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 22:20:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 22:20:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 22:20:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 22:20:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 22:20:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 22:20:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 22:20:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 22:20:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 22:20:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 22:20:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 22:20:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 22:20:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 22:20:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 22:20:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 22:20:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 22:20:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 22:20:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 22:20:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 22:20:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 22:20:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 22:20:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 22:20:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 22:20:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 22:20:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 22:20:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 22:20:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 22:20:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 22:20:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 22:20:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 22:20:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 22:20:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 22:20:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 22:20:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 22:20:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 22:20:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 22:20:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 22:20:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 22:20:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 22:20:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 22:20:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 22:20:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 22:20:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 22:20:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 22:20:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 22:20:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 22:20:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 22:20:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 22:20:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 22:20:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 22:20:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 22:20:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 22:20:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 22:20:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 22:20:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 22:20:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 22:20:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 22:20:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 22:20:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 22:20:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 22:20:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 22:21:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 22:21:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 22:21:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 22:21:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 22:21:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 22:21:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 22:21:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 22:21:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 22:21:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 22:21:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 22:21:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 22:21:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 22:21:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 22:21:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 22:21:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 22:21:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 22:21:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 22:21:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 22:21:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 22:21:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 22:21:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 22:21:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 22:21:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 22:21:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 22:21:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 22:21:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 22:21:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 22:21:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 22:21:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 22:21:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 22:21:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 22:21:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 22:21:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 22:21:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 22:21:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 22:21:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 22:21:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 22:21:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 22:21:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 22:21:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 22:21:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 22:21:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 22:21:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 22:21:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 22:21:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 22:21:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 22:21:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 22:21:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 22:21:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 22:21:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 22:21:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 22:21:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 22:21:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 22:21:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 22:21:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 22:21:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 22:21:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 22:21:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 22:21:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 22:21:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 22:21:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 22:21:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 22:21:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 22:21:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 22:21:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 22:21:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 22:21:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 22:21:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 22:21:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 22:21:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 22:21:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 22:21:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 22:21:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 22:21:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 22:21:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 22:21:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 22:21:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 22:21:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 22:21:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 22:21:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 22:21:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 22:21:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 22:21:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 22:21:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 22:21:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 22:21:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 22:21:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 22:21:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 22:21:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 22:21:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 22:21:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 22:21:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 22:21:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 22:21:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 22:21:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 22:21:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 22:21:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 22:21:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 22:21:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 22:21:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 22:21:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 22:21:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 22:21:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 22:21:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 22:21:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 22:21:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 22:21:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 22:21:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 22:21:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 22:21:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 22:21:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 22:21:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 22:21:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 22:21:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 22:21:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 22:21:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 22:21:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 22:21:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 22:21:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 22:21:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 22:21:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 22:21:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 22:21:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 22:21:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 22:21:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 22:21:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 22:21:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 22:21:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 22:21:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 22:21:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 22:21:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 22:21:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 22:21:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 22:21:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-entity-operator-577c5d956b-kj55g is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 22:21:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 22:21:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 22:21:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 22:21:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 22:21:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 22:21:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-1896224c-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 22:21:19 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-1896224c-entity-operator-577c5d956b-kj55g ,my-cluster-1896224c-kafka-0 ,my-cluster-1896224c-kafka-1 ,my-cluster-1896224c-kafka-2 ,my-cluster-1896224c-zookeeper-0 ,my-cluster-1896224c-zookeeper-1 ,my-cluster-1896224c-zookeeper-2
2022-04-04 22:21:19 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-1896224c-kafka rolling update
2022-04-04 22:22:54 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-1896224c-kafka has been successfully rolled
2022-04-04 22:22:54 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-1896224c-kafka to be ready
2022-04-04 22:23:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1896224c will have desired state: Ready
2022-04-04 22:23:25 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1896224c is in desired state: Ready
2022-04-04 22:23:25 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-1896224c is ready
2022-04-04 22:23:25 [main] [32mINFO [m [AbstractST:478] Search in strimzi-cluster-operator log for errors in last 521 seconds
2022-04-04 22:23:25 [main] [32mINFO [m [BaseCmdKubeClient:481] Exception not found
2022-04-04 22:23:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:23:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaRollsWhenTopicIsUnderReplicated
2022-04-04 22:23:25 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-706103639-2072735128 in namespace namespace-98
2022-04-04 22:23:25 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1896224c in namespace namespace-98
2022-04-04 22:23:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:23:35 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-98 for test case:testKafkaRollsWhenTopicIsUnderReplicated
2022-04-04 22:24:18 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaRollsWhenTopicIsUnderReplicated-FINISHED
2022-04-04 22:24:18 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 22:24:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 22:24:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodPendingDueToRack-STARTED
2022-04-04 22:24:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 22:24:18 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-99 for test case:testKafkaPodPendingDueToRack
2022-04-04 22:24:18 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-99
2022-04-04 22:24:18 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-99
2022-04-04 22:24:18 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-99
2022-04-04 22:24:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-bfec601c in namespace namespace-99
2022-04-04 22:24:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-99
2022-04-04 22:24:18 [main] [32mINFO [m [PodUtils:209] Wait until Pod my-cluster-bfec601c-kafka will have stable 3 replicas
2022-04-04 22:24:18 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:24:19 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:24:20 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:24:21 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:24:22 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:24:23 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:24:24 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:24:25 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:24:26 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:24:27 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:24:28 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:24:29 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:24:30 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:24:31 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:24:32 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:24:33 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:24:34 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:24:35 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:24:36 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:24:37 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:24:38 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:24:39 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:24:40 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:24:41 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:24:42 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:24:43 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 19 polls
2022-04-04 22:24:44 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 18 polls
2022-04-04 22:24:45 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 17 polls
2022-04-04 22:24:46 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 16 polls
2022-04-04 22:24:47 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 15 polls
2022-04-04 22:24:48 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 14 polls
2022-04-04 22:24:49 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 13 polls
2022-04-04 22:24:50 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 12 polls
2022-04-04 22:24:51 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 11 polls
2022-04-04 22:24:52 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 10 polls
2022-04-04 22:24:53 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 9 polls
2022-04-04 22:24:54 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 8 polls
2022-04-04 22:24:55 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 7 polls
2022-04-04 22:24:56 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 6 polls
2022-04-04 22:24:57 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 5 polls
2022-04-04 22:24:58 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 4 polls
2022-04-04 22:24:59 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 3 polls
2022-04-04 22:25:00 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 2 polls
2022-04-04 22:25:01 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 1 polls
2022-04-04 22:25:02 [main] [32mINFO [m [PodUtils:217] Pod replicas are stable for 20 polls intervals
2022-04-04 22:25:02 [main] [32mINFO [m [PodUtils:228] Pod my-cluster-bfec601c-kafka has 3 replicas
2022-04-04 22:25:02 [main] [32mINFO [m [KafkaRollerIsolatedST:309] Removing requirement for the affinity
2022-04-04 22:25:02 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-bfec601c will have desired state: Ready
2022-04-04 22:28:40 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-bfec601c is in desired state: Ready
2022-04-04 22:28:40 [main] [32mINFO [m [KafkaUtils:399] Waiting for deletion of Kafka:my-cluster-bfec601c
2022-04-04 22:28:42 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:28:42 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaPodPendingDueToRack
2022-04-04 22:28:42 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-bfec601c in namespace namespace-99
2022-04-04 22:28:42 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:28:42 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-99 for test case:testKafkaPodPendingDueToRack
2022-04-04 22:29:25 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodPendingDueToRack-FINISHED
2022-04-04 22:29:25 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 22:29:25 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 22:29:25 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodImagePullBackOff-STARTED
2022-04-04 22:29:25 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 22:29:25 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-100 for test case:testKafkaPodImagePullBackOff
2022-04-04 22:29:25 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-100
2022-04-04 22:29:25 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-100
2022-04-04 22:29:25 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-100
2022-04-04 22:29:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-6f689a08 in namespace namespace-100
2022-04-04 22:29:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-100
2022-04-04 22:29:25 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-6f689a08 will have desired state: Ready
2022-04-04 22:31:17 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-6f689a08 is in desired state: Ready
2022-04-04 22:31:17 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-6f689a08 will have desired state: NotReady
2022-04-04 22:33:34 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-6f689a08 is in desired state: NotReady
2022-04-04 22:33:34 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-6f689a08 will have desired state: Ready
2022-04-04 22:38:02 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-6f689a08 is in desired state: Ready
2022-04-04 22:38:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:38:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaPodImagePullBackOff
2022-04-04 22:38:02 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-6f689a08 in namespace namespace-100
2022-04-04 22:38:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:38:12 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-100 for test case:testKafkaPodImagePullBackOff
2022-04-04 22:38:55 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodImagePullBackOff-FINISHED
2022-04-04 22:38:55 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 22:38:55 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 22:38:55 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodPending-STARTED
2022-04-04 22:38:55 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 22:38:55 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-101 for test case:testKafkaPodPending
2022-04-04 22:38:55 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-101
2022-04-04 22:38:55 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-101
2022-04-04 22:38:55 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-101
2022-04-04 22:38:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-261c10f0 in namespace namespace-101
2022-04-04 22:38:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-101
2022-04-04 22:38:55 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-261c10f0 will have desired state: Ready
2022-04-04 22:40:13 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-261c10f0 is in desired state: Ready
2022-04-04 22:40:14 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-261c10f0 will have desired state: NotReady
2022-04-04 22:42:24 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-261c10f0 is in desired state: NotReady
2022-04-04 22:42:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-261c10f0 will have desired state: Ready
2022-04-04 22:44:13 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-261c10f0 is in desired state: Ready
2022-04-04 22:44:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:44:13 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaPodPending
2022-04-04 22:44:13 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-261c10f0 in namespace namespace-101
2022-04-04 22:44:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:44:23 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-101 for test case:testKafkaPodPending
2022-04-04 22:45:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodPending-FINISHED
2022-04-04 22:45:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 22:45:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 22:45:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaTopicRFLowerThanMinInSyncReplicas-STARTED
2022-04-04 22:45:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 22:45:07 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-102 for test case:testKafkaTopicRFLowerThanMinInSyncReplicas
2022-04-04 22:45:07 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-102
2022-04-04 22:45:07 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-102
2022-04-04 22:45:07 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-102
2022-04-04 22:45:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2c07ddb4 in namespace namespace-102
2022-04-04 22:45:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-102
2022-04-04 22:45:07 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2c07ddb4 will have desired state: Ready
2022-04-04 22:46:24 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2c07ddb4 is in desired state: Ready
2022-04-04 22:46:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-613039660-1976777169 in namespace namespace-102
2022-04-04 22:46:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-102
2022-04-04 22:46:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-613039660-1976777169 will have desired state: Ready
2022-04-04 22:46:25 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-613039660-1976777169 is in desired state: Ready
2022-04-04 22:46:25 [main] [32mINFO [m [KafkaRollerIsolatedST:155] Setting KafkaTopic's min.insync.replicas to be higher than replication factor
2022-04-04 22:46:25 [main] [32mINFO [m [KafkaRollerIsolatedST:159] Annotate Kafka StatefulSet my-cluster-2c07ddb4-kafka with manual rolling update annotation
2022-04-04 22:46:25 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-2c07ddb4-kafka rolling update
2022-04-04 22:47:35 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-2c07ddb4-kafka has been successfully rolled
2022-04-04 22:47:35 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-2c07ddb4-kafka to be ready
2022-04-04 22:48:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2c07ddb4 will have desired state: Ready
2022-04-04 22:48:00 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2c07ddb4 is in desired state: Ready
2022-04-04 22:48:00 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-2c07ddb4 is ready
2022-04-04 22:48:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:48:00 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaTopicRFLowerThanMinInSyncReplicas
2022-04-04 22:48:00 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-613039660-1976777169 in namespace namespace-102
2022-04-04 22:48:00 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2c07ddb4 in namespace namespace-102
2022-04-04 22:48:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:48:10 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-102 for test case:testKafkaTopicRFLowerThanMinInSyncReplicas
2022-04-04 22:48:53 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaTopicRFLowerThanMinInSyncReplicas-FINISHED
2022-04-04 22:48:53 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 22:48:53 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 22:48:53 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodCrashLooping-STARTED
2022-04-04 22:48:53 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 22:48:53 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-103 for test case:testKafkaPodCrashLooping
2022-04-04 22:48:53 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-103
2022-04-04 22:48:53 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-103
2022-04-04 22:48:53 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-103
2022-04-04 22:48:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-86eba9f1 in namespace namespace-103
2022-04-04 22:48:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-103
2022-04-04 22:48:53 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-86eba9f1 will have desired state: Ready
2022-04-04 22:51:17 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-86eba9f1 is in desired state: Ready
2022-04-04 22:51:17 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-86eba9f1 will have desired state: NotReady
2022-04-04 22:53:34 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-86eba9f1 is in desired state: NotReady
2022-04-04 22:53:34 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-86eba9f1 will have desired state: Ready
2022-04-04 22:58:46 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-86eba9f1 is in desired state: Ready
2022-04-04 22:58:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:58:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaPodCrashLooping
2022-04-04 22:58:46 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-86eba9f1 in namespace namespace-103
2022-04-04 22:58:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:58:56 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-103 for test case:testKafkaPodCrashLooping
2022-04-04 22:59:40 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodCrashLooping-FINISHED
2022-04-04 22:59:40 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 22:59:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:59:40 [main] [32mINFO [m [ResourceManager:346] In context KafkaRollerIsolatedST is everything deleted.
2022-04-04 22:59:40 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2,787.955 s - in io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.connect.ConnectIsolatedST
2022-04-04 22:59:40 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 23:00:05 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 23:00:05 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 23:00:05 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 23:00:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 23:00:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 23:00:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 23:00:05 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 23:00:05 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 23:00:05 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 23:00:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 23:00:05 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 23:00:05 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 23:00:05 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 23:00:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 23:00:05 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 23:00:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 23:00:05 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 23:00:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 23:00:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 23:00:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 23:00:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 23:00:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 23:00:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 23:00:15 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 23:00:15 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 23:00:15 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 23:00:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 23:00:15 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 23:00:15 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 23:00:15 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 23:00:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 23:00:30 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 23:00:30 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 23:00:30 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 23:00:30 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 23:00:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 23:00:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 23:00:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 23:00:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 23:00:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 23:00:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 23:00:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 23:00:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 23:00:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 23:00:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 23:00:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 23:00:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 23:00:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 23:00:31 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 23:00:31 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 23:00:31 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 23:00:31 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 23:00:31 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 23:00:31 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 23:00:31 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 23:00:31 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 23:00:31 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 23:00:31 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 23:00:31 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 23:00:31 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 23:00:31 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 23:00:31 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 23:00:31 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 23:00:31 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 23:00:31 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 23:00:31 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 23:00:31 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 23:00:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 23:00:31 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 23:00:54 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 23:00:54 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 23:01:04 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 23:01:04 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 23:01:04 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testMultiNodeKafkaConnectWithConnectorCreation-STARTED
2022-04-04 23:01:04 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 23:01:04 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-104 for test case:testMultiNodeKafkaConnectWithConnectorCreation
2022-04-04 23:01:04 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-104
2022-04-04 23:01:04 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-104
2022-04-04 23:01:04 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-104
2022-04-04 23:01:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2859fdc4 in namespace namespace-104
2022-04-04 23:01:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-04 23:01:04 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2859fdc4 will have desired state: Ready
2022-04-04 23:02:24 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2859fdc4 is in desired state: Ready
2022-04-04 23:02:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-2859fdc4-scraper in namespace namespace-104
2022-04-04 23:02:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-04 23:02:24 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-2859fdc4-scraper will be ready
2022-04-04 23:02:25 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-2859fdc4-scraper is ready
2022-04-04 23:02:25 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-2859fdc4-scraper to be ready
2022-04-04 23:02:35 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-2859fdc4-scraper is ready
2022-04-04 23:02:35 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-2859fdc4-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 23:02:35 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-2859fdc4-allow in namespace namespace-104
2022-04-04 23:02:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-04 23:02:35 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 23:02:35 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-2859fdc4 in namespace namespace-104
2022-04-04 23:02:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-04 23:02:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-2859fdc4 will have desired state: Ready
2022-04-04 23:03:44 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-2859fdc4 is in desired state: Ready
2022-04-04 23:03:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-2859fdc4 in namespace namespace-104
2022-04-04 23:03:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-04 23:03:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-2859fdc4 will have desired state: Ready
2022-04-04 23:03:45 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-2859fdc4 is in desired state: Ready
2022-04-04 23:03:45 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 23:03:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-104 exec my-cluster-2859fdc4-connect-79655994fd-lf64n -- curl -X GET http://localhost:8083/connectors/my-cluster-2859fdc4/status
2022-04-04 23:03:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:03:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-2859fdc4-hello-world-producer in namespace namespace-104
2022-04-04 23:03:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-04 23:03:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-2859fdc4-hello-world-consumer in namespace namespace-104
2022-04-04 23:03:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-04 23:03:46 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-2859fdc4-hello-world-producer will be in active state
2022-04-04 23:03:47 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-2859fdc4-hello-world-consumer will be in active state
2022-04-04 23:03:47 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-2859fdc4-hello-world-producer and consumer my-cluster-2859fdc4-hello-world-consumer finish
2022-04-04 23:04:03 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-2859fdc4-connect-79655994fd-lf64n
2022-04-04 23:04:03 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-2859fdc4-connect-79655994fd-lf64n
2022-04-04 23:04:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 23:04:03 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMultiNodeKafkaConnectWithConnectorCreation
2022-04-04 23:04:03 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-2859fdc4 in namespace namespace-104
2022-04-04 23:04:03 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2859fdc4 in namespace namespace-104
2022-04-04 23:04:03 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-2859fdc4-hello-world-producer in namespace namespace-104
2022-04-04 23:04:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-2859fdc4-hello-world-consumer in namespace namespace-104
2022-04-04 23:04:03 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-2859fdc4 in namespace namespace-104
2022-04-04 23:04:03 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-2859fdc4-allow in namespace namespace-104
2022-04-04 23:04:03 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-2859fdc4-scraper in namespace namespace-104
2022-04-04 23:04:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 23:04:53 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-104 for test case:testMultiNodeKafkaConnectWithConnectorCreation
2022-04-04 23:04:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testMultiNodeKafkaConnectWithConnectorCreation-FINISHED
2022-04-04 23:04:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 23:04:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 23:04:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectScaleUpScaleDown-STARTED
2022-04-04 23:04:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 23:04:58 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-105 for test case:testKafkaConnectScaleUpScaleDown
2022-04-04 23:04:58 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-105
2022-04-04 23:04:59 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-105
2022-04-04 23:04:59 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-105
2022-04-04 23:04:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-017b570c in namespace namespace-105
2022-04-04 23:04:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-105
2022-04-04 23:04:59 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-017b570c will have desired state: Ready
2022-04-04 23:06:10 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-017b570c is in desired state: Ready
2022-04-04 23:06:10 [main] [32mINFO [m [ConnectIsolatedST:395] Running kafkaConnectScaleUP namespace-105 in namespace
2022-04-04 23:06:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-017b570c in namespace namespace-105
2022-04-04 23:06:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-105
2022-04-04 23:06:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-017b570c will have desired state: Ready
2022-04-04 23:07:14 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-017b570c is in desired state: Ready
2022-04-04 23:07:14 [main] [32mINFO [m [ConnectIsolatedST:407] Scaling up to 4
2022-04-04 23:07:14 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-017b570c-connect will be ready
2022-04-04 23:07:14 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-017b570c-connect is ready
2022-04-04 23:07:14 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 4 Pod(s) of Deployment my-cluster-017b570c-connect to be ready
2022-04-04 23:08:34 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-017b570c-connect is ready
2022-04-04 23:08:34 [main] [32mINFO [m [ConnectIsolatedST:414] Scaling down to 1
2022-04-04 23:08:34 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-017b570c-connect will be ready
2022-04-04 23:08:34 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-017b570c-connect is ready
2022-04-04 23:08:34 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-017b570c-connect to be ready
2022-04-04 23:08:54 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-017b570c-connect is ready
2022-04-04 23:08:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 23:08:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectScaleUpScaleDown
2022-04-04 23:08:54 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-017b570c in namespace namespace-105
2022-04-04 23:08:54 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-017b570c in namespace namespace-105
2022-04-04 23:09:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 23:09:04 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-105 for test case:testKafkaConnectScaleUpScaleDown
2022-04-04 23:09:48 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectScaleUpScaleDown-FINISHED
2022-04-04 23:09:48 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 23:09:48 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 23:09:48 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testScaleConnectAndConnectorSubresource-STARTED
2022-04-04 23:09:48 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 23:09:48 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-106 for test case:testScaleConnectAndConnectorSubresource
2022-04-04 23:09:48 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-106
2022-04-04 23:09:48 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-106
2022-04-04 23:09:48 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-106
2022-04-04 23:09:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a116443f in namespace namespace-106
2022-04-04 23:09:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-106
2022-04-04 23:09:48 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a116443f will have desired state: Ready
2022-04-04 23:11:01 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a116443f is in desired state: Ready
2022-04-04 23:11:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-a116443f in namespace namespace-106
2022-04-04 23:11:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-106
2022-04-04 23:11:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-a116443f will have desired state: Ready
2022-04-04 23:12:10 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-a116443f is in desired state: Ready
2022-04-04 23:12:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-a116443f in namespace namespace-106
2022-04-04 23:12:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-106
2022-04-04 23:12:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-a116443f will have desired state: Ready
2022-04-04 23:12:11 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-a116443f is in desired state: Ready
2022-04-04 23:12:11 [main] [32mINFO [m [ConnectIsolatedST:979] -------> Scaling KafkaConnect subresource <-------
2022-04-04 23:12:11 [main] [32mINFO [m [ConnectIsolatedST:980] Scaling subresource replicas to 4
2022-04-04 23:12:11 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a116443f-connect will be ready
2022-04-04 23:12:11 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a116443f-connect is ready
2022-04-04 23:12:11 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 4 Pod(s) of Deployment my-cluster-a116443f-connect to be ready
2022-04-04 23:13:28 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-a116443f-connect is ready
2022-04-04 23:13:28 [main] [32mINFO [m [ConnectIsolatedST:984] Check if replicas is set to 4, observed generation is higher - for spec and status - naming prefix should be same
2022-04-04 23:13:28 [main] [32mINFO [m [ConnectIsolatedST:998] -------> Scaling KafkaConnector subresource <-------
2022-04-04 23:13:28 [main] [32mINFO [m [ConnectIsolatedST:999] Scaling subresource task max to 4
2022-04-04 23:13:29 [main] [32mINFO [m [ConnectIsolatedST:1003] Check if taskMax is set to 4
2022-04-04 23:13:29 [main] [32mINFO [m [ConnectIsolatedST:1007] Check taskMax on Connect pods API
2022-04-04 23:13:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-106 exec my-cluster-a116443f-connect-5c9565dc44-8rwcv -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-a116443f
2022-04-04 23:13:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:13:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-106 exec my-cluster-a116443f-connect-5c9565dc44-d6kn5 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-a116443f
2022-04-04 23:13:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:13:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-106 exec my-cluster-a116443f-connect-5c9565dc44-ncgqs -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-a116443f
2022-04-04 23:13:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:13:30 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-106 exec my-cluster-a116443f-connect-5c9565dc44-tmvmx -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-a116443f
2022-04-04 23:13:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:13:30 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 23:13:30 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleConnectAndConnectorSubresource
2022-04-04 23:13:30 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-a116443f in namespace namespace-106
2022-04-04 23:13:30 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-a116443f in namespace namespace-106
2022-04-04 23:13:30 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a116443f in namespace namespace-106
2022-04-04 23:13:40 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 23:13:40 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-106 for test case:testScaleConnectAndConnectorSubresource
2022-04-04 23:14:23 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testScaleConnectAndConnectorSubresource-FINISHED
2022-04-04 23:14:23 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 23:14:23 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 23:14:23 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectAndPausedConnectorWithFileSinkPlugin-STARTED
2022-04-04 23:14:23 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 23:14:23 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-107 for test case:testKafkaConnectAndPausedConnectorWithFileSinkPlugin
2022-04-04 23:14:23 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-107
2022-04-04 23:14:23 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-107
2022-04-04 23:14:23 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-107
2022-04-04 23:14:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7bea315e in namespace namespace-107
2022-04-04 23:14:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-04 23:14:23 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7bea315e will have desired state: Ready
2022-04-04 23:15:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7bea315e is in desired state: Ready
2022-04-04 23:15:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-285948304-1312284822 in namespace namespace-107
2022-04-04 23:15:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-04 23:15:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-285948304-1312284822 will have desired state: Ready
2022-04-04 23:15:46 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-285948304-1312284822 is in desired state: Ready
2022-04-04 23:15:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-7bea315e-scraper in namespace namespace-107
2022-04-04 23:15:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-04 23:15:46 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7bea315e-scraper will be ready
2022-04-04 23:15:47 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7bea315e-scraper is ready
2022-04-04 23:15:47 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-7bea315e-scraper to be ready
2022-04-04 23:15:57 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-7bea315e-scraper is ready
2022-04-04 23:15:57 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-7bea315e-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 23:15:57 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-7bea315e-allow in namespace namespace-107
2022-04-04 23:15:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-04 23:15:57 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 23:15:57 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-7bea315e in namespace namespace-107
2022-04-04 23:15:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-04 23:15:57 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-7bea315e will have desired state: Ready
2022-04-04 23:17:06 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-7bea315e is in desired state: Ready
2022-04-04 23:17:06 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-04 23:17:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-107 exec my-cluster-7bea315e-connect-7f9fc5f65f-dstwb -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-04 23:17:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:17:07 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-04 23:17:07 [main] [32mINFO [m [ConnectIsolatedST:181] Creating KafkaConnector with 'pause: true'
2022-04-04 23:17:07 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-7bea315e in namespace namespace-107
2022-04-04 23:17:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-04 23:17:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-7bea315e will have desired state: Ready
2022-04-04 23:17:08 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-7bea315e is in desired state: Ready
2022-04-04 23:17:08 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 23:17:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-7bea315e-hello-world-producer in namespace namespace-107
2022-04-04 23:17:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-04 23:17:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-7bea315e-hello-world-consumer in namespace namespace-107
2022-04-04 23:17:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-04 23:17:08 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-7bea315e-hello-world-producer will be in active state
2022-04-04 23:17:09 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-7bea315e-hello-world-consumer will be in active state
2022-04-04 23:17:09 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-7bea315e-hello-world-producer and consumer my-cluster-7bea315e-hello-world-consumer finish
2022-04-04 23:17:26 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-7bea315e-connect-7f9fc5f65f-dstwb
2022-04-04 23:17:26 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-7bea315e-connect-7f9fc5f65f-dstwb
2022-04-04 23:17:26 [main] [32mINFO [m [ConnectIsolatedST:207] Pausing KafkaConnector: my-cluster-7bea315e
2022-04-04 23:17:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-7bea315e will have desired state: Ready
2022-04-04 23:17:26 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-7bea315e is in desired state: Ready
2022-04-04 23:17:26 [main] [32mINFO [m [ConnectIsolatedST:213] Clearing FileSink file to check if KafkaConnector will be really paused
2022-04-04 23:17:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-107 exec my-cluster-7bea315e-connect-7f9fc5f65f-dstwb -- /bin/bash -c truncate -s 0 /tmp/test-file-sink.txt
2022-04-04 23:17:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:17:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-7bea315e-hello-world-producer in namespace namespace-107
2022-04-04 23:17:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-04 23:17:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-7bea315e-hello-world-consumer in namespace namespace-107
2022-04-04 23:17:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-04 23:17:26 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-7bea315e-hello-world-producer will be in active state
2022-04-04 23:17:26 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-7bea315e-hello-world-consumer will be in active state
2022-04-04 23:17:26 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-7bea315e-hello-world-producer and consumer my-cluster-7bea315e-hello-world-consumer finish
2022-04-04 23:18:10 [main] [32mINFO [m [ConnectIsolatedST:219] Because KafkaConnector is paused, no messages should appear to FileSink file
2022-04-04 23:18:10 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-7bea315e-connect-7f9fc5f65f-dstwb
io.strimzi.test.WaitException: Timeout after 60000 ms waiting for messages in file sink
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(KafkaConnectUtils.java:75)
	at io.strimzi.systemtest.connect.ConnectIsolatedST.lambda$testKafkaConnectAndPausedConnectorWithFileSinkPlugin$1(ConnectIsolatedST.java:220)
	at org.junit.jupiter.api.AssertThrows.assertThrows(AssertThrows.java:55)
	at org.junit.jupiter.api.AssertThrows.assertThrows(AssertThrows.java:37)
	at org.junit.jupiter.api.Assertions.assertThrows(Assertions.java:3082)
	at io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectAndPausedConnectorWithFileSinkPlugin(ConnectIsolatedST.java:220)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-04 23:19:11 [main] [32mINFO [m [ConnectIsolatedST:222] Unpausing KafkaConnector, messages should again appear to FileSink file
2022-04-04 23:19:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-7bea315e will have desired state: Ready
2022-04-04 23:19:11 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-7bea315e is in desired state: Ready
2022-04-04 23:19:11 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-7bea315e-connect-7f9fc5f65f-dstwb
2022-04-04 23:19:11 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-7bea315e-connect-7f9fc5f65f-dstwb
2022-04-04 23:19:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 23:19:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectAndPausedConnectorWithFileSinkPlugin
2022-04-04 23:19:11 [main] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-7bea315e-hello-world-producer in namespace namespace-107
2022-04-04 23:19:11 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-7bea315e-hello-world-consumer in namespace namespace-107
2022-04-04 23:19:11 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-7bea315e-hello-world-consumer in namespace namespace-107
2022-04-04 23:19:11 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-285948304-1312284822 in namespace namespace-107
2022-04-04 23:19:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-7bea315e-hello-world-producer in namespace namespace-107
2022-04-04 23:19:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-7bea315e in namespace namespace-107
2022-04-04 23:19:11 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-7bea315e-scraper in namespace namespace-107
2022-04-04 23:19:11 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-7bea315e in namespace namespace-107
2022-04-04 23:19:11 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-7bea315e-allow in namespace namespace-107
2022-04-04 23:19:11 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7bea315e in namespace namespace-107
2022-04-04 23:20:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 23:20:01 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-107 for test case:testKafkaConnectAndPausedConnectorWithFileSinkPlugin
2022-04-04 23:20:06 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectAndPausedConnectorWithFileSinkPlugin-FINISHED
2022-04-04 23:20:06 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 23:20:06 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 23:20:06 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectWithScramShaAuthenticationRolledAfterPasswordChanged-STARTED
2022-04-04 23:20:06 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 23:20:06 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-108 for test case:testKafkaConnectWithScramShaAuthenticationRolledAfterPasswordChanged
2022-04-04 23:20:06 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-108
2022-04-04 23:20:06 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-108
2022-04-04 23:20:06 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-108
2022-04-04 23:20:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5ad43a3a in namespace namespace-108
2022-04-04 23:20:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-108
2022-04-04 23:20:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5ad43a3a will have desired state: Ready
2022-04-04 23:21:22 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5ad43a3a is in desired state: Ready
2022-04-04 23:21:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-758160122-48587347 in namespace namespace-108
2022-04-04 23:21:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-108
2022-04-04 23:21:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-758160122-48587347 will have desired state: Ready
2022-04-04 23:21:23 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-758160122-48587347 is in desired state: Ready
2022-04-04 23:21:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-758160122-48587347 in namespace namespace-108
2022-04-04 23:21:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-108
2022-04-04 23:21:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-758160122-48587347 will have desired state: Ready
2022-04-04 23:21:23 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-758160122-48587347 is in desired state: Ready
2022-04-04 23:21:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-443722457-2117606029 in namespace namespace-108
2022-04-04 23:21:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-108
2022-04-04 23:21:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-443722457-2117606029 will have desired state: Ready
2022-04-04 23:21:25 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-443722457-2117606029 is in desired state: Ready
2022-04-04 23:21:25 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-5ad43a3a in namespace namespace-108
2022-04-04 23:21:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-108
2022-04-04 23:21:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-5ad43a3a will have desired state: Ready
2022-04-04 23:22:33 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-5ad43a3a is in desired state: Ready
2022-04-04 23:22:33 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-04 23:22:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-108 exec my-cluster-5ad43a3a-connect-64db58559-7dh99 -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-04 23:22:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:22:33 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-04 23:22:33 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-758160122-48587347 in namespace namespace-108
2022-04-04 23:22:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-108
2022-04-04 23:22:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-758160122-48587347 will have desired state: Ready
2022-04-04 23:22:33 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-758160122-48587347 is in desired state: Ready
2022-04-04 23:22:33 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-5ad43a3a-connect rolling update
2022-04-04 23:23:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-5ad43a3a-connect will be ready
2022-04-04 23:23:58 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-5ad43a3a-connect is ready
2022-04-04 23:24:08 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-5ad43a3a-connect rolling update finished
2022-04-04 23:24:08 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-04 23:24:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-108 exec my-cluster-5ad43a3a-connect-66b8c5bf66-nsdn2 -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-04 23:24:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:24:09 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-04 23:24:09 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 23:24:09 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectWithScramShaAuthenticationRolledAfterPasswordChanged
2022-04-04 23:24:09 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-443722457-2117606029 in namespace namespace-108
2022-04-04 23:24:09 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5ad43a3a in namespace namespace-108
2022-04-04 23:24:09 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-758160122-48587347 in namespace namespace-108
2022-04-04 23:24:09 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-758160122-48587347 in namespace namespace-108
2022-04-04 23:24:09 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-5ad43a3a in namespace namespace-108
2022-04-04 23:24:09 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-758160122-48587347 in namespace namespace-108
2022-04-04 23:24:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 23:24:19 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-108 for test case:testKafkaConnectWithScramShaAuthenticationRolledAfterPasswordChanged
2022-04-04 23:25:02 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectWithScramShaAuthenticationRolledAfterPasswordChanged-FINISHED
2022-04-04 23:25:02 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 23:25:02 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 23:25:02 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testSecretsWithKafkaConnectWithTlsAndScramShaAuthentication-STARTED
2022-04-04 23:25:02 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 23:25:02 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-109 for test case:testSecretsWithKafkaConnectWithTlsAndScramShaAuthentication
2022-04-04 23:25:02 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-109
2022-04-04 23:25:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-109
2022-04-04 23:25:02 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-109
2022-04-04 23:25:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ed0f18b6 in namespace namespace-109
2022-04-04 23:25:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-04 23:25:02 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ed0f18b6 will have desired state: Ready
2022-04-04 23:26:18 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ed0f18b6 is in desired state: Ready
2022-04-04 23:26:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-ed0f18b6-user in namespace namespace-109
2022-04-04 23:26:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-04 23:26:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-ed0f18b6-user will have desired state: Ready
2022-04-04 23:26:19 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-ed0f18b6-user is in desired state: Ready
2022-04-04 23:26:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1414755304-421978353 in namespace namespace-109
2022-04-04 23:26:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-04 23:26:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1414755304-421978353 will have desired state: Ready
2022-04-04 23:26:20 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1414755304-421978353 is in desired state: Ready
2022-04-04 23:26:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-ed0f18b6-scraper in namespace namespace-109
2022-04-04 23:26:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-04 23:26:20 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ed0f18b6-scraper will be ready
2022-04-04 23:26:22 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ed0f18b6-scraper is ready
2022-04-04 23:26:22 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-ed0f18b6-scraper to be ready
2022-04-04 23:26:32 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-ed0f18b6-scraper is ready
2022-04-04 23:26:32 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-ed0f18b6-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 23:26:32 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-ed0f18b6-allow in namespace namespace-109
2022-04-04 23:26:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-04 23:26:32 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 23:26:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-ed0f18b6 in namespace namespace-109
2022-04-04 23:26:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-04 23:26:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-ed0f18b6 will have desired state: Ready
2022-04-04 23:27:34 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-ed0f18b6 is in desired state: Ready
2022-04-04 23:27:35 [main] [32mINFO [m [ConnectIsolatedST:547] Verifying that KafkaConnect pod logs don't contain ERRORs
2022-04-04 23:27:35 [main] [32mINFO [m [ConnectIsolatedST:550] Creating FileStreamSink connector via pod my-cluster-ed0f18b6-scraper-7544d9987b-9kmzb with topic my-topic-1414755304-421978353
2022-04-04 23:27:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-109 exec my-cluster-ed0f18b6-scraper-7544d9987b-9kmzb -- /bin/bash -c curl -X POST -H "Content-Type: application/json" --data '{ "name": "sink-test", "config": { "connector.class": "FileStreamSink", "tasks.max": "1", "topics": "my-topic-1414755304-421978353", "file": "/tmp/test-file-sink.txt" } }' http://my-cluster-ed0f18b6-connect-api.namespace-109.svc:8083/connectors
2022-04-04 23:27:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:27:35 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 23:27:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-ed0f18b6-hello-world-producer in namespace namespace-109
2022-04-04 23:27:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-04 23:27:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-ed0f18b6-hello-world-consumer in namespace namespace-109
2022-04-04 23:27:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-04 23:27:35 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-ed0f18b6-hello-world-producer will be in active state
2022-04-04 23:27:36 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-ed0f18b6-hello-world-consumer will be in active state
2022-04-04 23:27:36 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-ed0f18b6-hello-world-producer and consumer my-cluster-ed0f18b6-hello-world-consumer finish
2022-04-04 23:27:52 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-ed0f18b6-connect-5645df77b4-wsgnt
2022-04-04 23:27:52 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-ed0f18b6-connect-5645df77b4-wsgnt
2022-04-04 23:27:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 23:27:52 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSecretsWithKafkaConnectWithTlsAndScramShaAuthentication
2022-04-04 23:27:52 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-ed0f18b6 in namespace namespace-109
2022-04-04 23:27:52 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-ed0f18b6-allow in namespace namespace-109
2022-04-04 23:27:52 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1414755304-421978353 in namespace namespace-109
2022-04-04 23:27:52 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-ed0f18b6-user in namespace namespace-109
2022-04-04 23:27:52 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-ed0f18b6-scraper in namespace namespace-109
2022-04-04 23:27:52 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-ed0f18b6-hello-world-producer in namespace namespace-109
2022-04-04 23:27:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-ed0f18b6-hello-world-consumer in namespace namespace-109
2022-04-04 23:27:52 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ed0f18b6 in namespace namespace-109
2022-04-04 23:28:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 23:28:52 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-109 for test case:testSecretsWithKafkaConnectWithTlsAndScramShaAuthentication
2022-04-04 23:28:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testSecretsWithKafkaConnectWithTlsAndScramShaAuthentication-FINISHED
2022-04-04 23:28:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 23:28:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 23:28:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testConfigureDeploymentStrategy-STARTED
2022-04-04 23:28:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 23:28:58 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-110 for test case:testConfigureDeploymentStrategy
2022-04-04 23:28:58 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-110
2022-04-04 23:28:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-110
2022-04-04 23:28:58 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-110
2022-04-04 23:28:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7707eabe in namespace namespace-110
2022-04-04 23:28:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-110
2022-04-04 23:28:58 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7707eabe will have desired state: Ready
2022-04-04 23:30:14 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7707eabe is in desired state: Ready
2022-04-04 23:30:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-7707eabe in namespace namespace-110
2022-04-04 23:30:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-110
2022-04-04 23:30:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-7707eabe will have desired state: Ready
2022-04-04 23:31:22 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-7707eabe is in desired state: Ready
2022-04-04 23:31:22 [main] [32mINFO [m [ConnectIsolatedST:1191] Adding label to Connect resource, the CR should be recreated
2022-04-04 23:31:22 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7707eabe-connect will be ready
2022-04-04 23:31:22 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7707eabe-connect is ready
2022-04-04 23:31:22 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-7707eabe-connect to be ready
2022-04-04 23:32:44 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-7707eabe-connect is ready
2022-04-04 23:32:44 [main] [32mINFO [m [ConnectIsolatedST:1198] Checking that observed gen. is still on 1 (recreation) and new label is present
2022-04-04 23:32:44 [main] [32mINFO [m [ConnectIsolatedST:1203] Changing deployment strategy to ROLLING_UPDATE
2022-04-04 23:32:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-7707eabe will have desired state: Ready
2022-04-04 23:32:44 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-7707eabe is in desired state: Ready
2022-04-04 23:32:44 [main] [32mINFO [m [ConnectIsolatedST:1208] Adding another label to Connect resource, pods should be rolled
2022-04-04 23:32:44 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7707eabe-connect will be ready
2022-04-04 23:32:44 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7707eabe-connect is ready
2022-04-04 23:32:44 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-7707eabe-connect to be ready
2022-04-04 23:33:58 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-7707eabe-connect is ready
2022-04-04 23:33:58 [main] [32mINFO [m [ConnectIsolatedST:1212] Checking that observed gen. higher (rolling update) and label is changed
2022-04-04 23:33:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 23:33:58 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigureDeploymentStrategy
2022-04-04 23:33:58 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-7707eabe in namespace namespace-110
2022-04-04 23:33:58 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7707eabe in namespace namespace-110
2022-04-04 23:34:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 23:34:08 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-110 for test case:testConfigureDeploymentStrategy
2022-04-04 23:34:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testConfigureDeploymentStrategy-FINISHED
2022-04-04 23:34:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 23:34:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 23:34:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectAndConnectorFileSinkPlugin-STARTED
2022-04-04 23:34:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 23:34:51 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-111 for test case:testKafkaConnectAndConnectorFileSinkPlugin
2022-04-04 23:34:51 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-111
2022-04-04 23:34:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-111
2022-04-04 23:34:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-111
2022-04-04 23:34:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-96ccdefc in namespace namespace-111
2022-04-04 23:34:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-111
2022-04-04 23:34:52 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-96ccdefc will have desired state: Ready
2022-04-04 23:36:04 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-96ccdefc is in desired state: Ready
2022-04-04 23:36:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-96ccdefc-scraper in namespace namespace-111
2022-04-04 23:36:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-111
2022-04-04 23:36:04 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-96ccdefc-scraper will be ready
2022-04-04 23:36:05 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-96ccdefc-scraper is ready
2022-04-04 23:36:05 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-96ccdefc-scraper to be ready
2022-04-04 23:36:15 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-96ccdefc-scraper is ready
2022-04-04 23:36:15 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-96ccdefc-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 23:36:15 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-96ccdefc-allow in namespace namespace-111
2022-04-04 23:36:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-111
2022-04-04 23:36:15 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 23:36:15 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-96ccdefc in namespace namespace-111
2022-04-04 23:36:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-111
2022-04-04 23:36:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-96ccdefc will have desired state: Ready
2022-04-04 23:37:20 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-96ccdefc is in desired state: Ready
2022-04-04 23:37:20 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector license-source in namespace namespace-111
2022-04-04 23:37:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-111
2022-04-04 23:37:20 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: license-source will have desired state: Ready
2022-04-04 23:37:21 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: license-source is in desired state: Ready
2022-04-04 23:37:21 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 23:37:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-96ccdefc-hello-world-consumer in namespace namespace-111
2022-04-04 23:37:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-111
2022-04-04 23:37:21 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-96ccdefc-hello-world-consumer will be in active state
2022-04-04 23:37:22 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:my-cluster-96ccdefc-hello-world-consumer to finished
2022-04-04 23:37:32 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-111 exec my-cluster-96ccdefc-scraper-58f49954bc-wsrlw -- /bin/bash -c curl http://my-cluster-96ccdefc-connect-api.namespace-111.svc:8083/connectors/license-source
2022-04-04 23:37:32 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:37:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 23:37:32 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectAndConnectorFileSinkPlugin
2022-04-04 23:37:32 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-96ccdefc in namespace namespace-111
2022-04-04 23:37:32 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector license-source in namespace namespace-111
2022-04-04 23:37:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-96ccdefc-hello-world-consumer in namespace namespace-111
2022-04-04 23:37:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-96ccdefc in namespace namespace-111
2022-04-04 23:37:32 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-96ccdefc-allow in namespace namespace-111
2022-04-04 23:37:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-96ccdefc-scraper in namespace namespace-111
2022-04-04 23:38:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 23:38:12 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-111 for test case:testKafkaConnectAndConnectorFileSinkPlugin
2022-04-04 23:38:18 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectAndConnectorFileSinkPlugin-FINISHED
2022-04-04 23:38:18 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 23:38:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 23:38:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testDeployUndeploy-STARTED
2022-04-04 23:38:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 23:38:18 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-112 for test case:testDeployUndeploy
2022-04-04 23:38:18 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-112
2022-04-04 23:38:18 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-112
2022-04-04 23:38:18 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-112
2022-04-04 23:38:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e76a042d in namespace namespace-112
2022-04-04 23:38:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-112
2022-04-04 23:38:18 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e76a042d will have desired state: Ready
2022-04-04 23:39:30 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e76a042d is in desired state: Ready
2022-04-04 23:39:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-e76a042d-scraper in namespace namespace-112
2022-04-04 23:39:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-112
2022-04-04 23:39:30 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-e76a042d-scraper will be ready
2022-04-04 23:39:32 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-e76a042d-scraper is ready
2022-04-04 23:39:32 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-e76a042d-scraper to be ready
2022-04-04 23:39:42 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-e76a042d-scraper is ready
2022-04-04 23:39:42 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-e76a042d-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 23:39:42 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-e76a042d-allow in namespace namespace-112
2022-04-04 23:39:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-112
2022-04-04 23:39:42 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 23:39:42 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-e76a042d in namespace namespace-112
2022-04-04 23:39:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-112
2022-04-04 23:39:42 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-e76a042d will have desired state: Ready
2022-04-04 23:40:52 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-e76a042d is in desired state: Ready
2022-04-04 23:40:52 [main] [32mINFO [m [ConnectIsolatedST:123] Looks like the connect cluster my-cluster deployed OK
2022-04-04 23:40:52 [main] [32mINFO [m [ConnectIsolatedST:140] Verifying docker image names
2022-04-04 23:40:52 [main] [32mINFO [m [AbstractST:172] strimzi-cluster-operator
2022-04-04 23:40:52 [main] [32mINFO [m [ConnectIsolatedST:152] Docker images verified
2022-04-04 23:40:52 [main] [32mINFO [m [AbstractST:311] Verifying labels on pod type connect
2022-04-04 23:40:52 [main] [32mINFO [m [AbstractST:315] Verifying labels for pod: my-cluster-e76a042d-connect-66f5c4b75-f24w8
2022-04-04 23:40:52 [main] [32mINFO [m [AbstractST:356] Verifying labels for Kafka Connect Services
2022-04-04 23:40:52 [main] [32mINFO [m [AbstractST:362] Verifying labels for service my-cluster-e76a042d-connect-api
2022-04-04 23:40:52 [main] [32mINFO [m [AbstractST:384] Verifying labels for Config maps
2022-04-04 23:40:52 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-e76a042d-connect-config
2022-04-04 23:40:52 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-e76a042d-entity-topic-operator-config
2022-04-04 23:40:52 [main] [32mINFO [m [AbstractST:407] CM my-cluster-e76a042d-entity-topic-operator-config is not related to current test
2022-04-04 23:40:52 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-e76a042d-entity-user-operator-config
2022-04-04 23:40:52 [main] [32mINFO [m [AbstractST:407] CM my-cluster-e76a042d-entity-user-operator-config is not related to current test
2022-04-04 23:40:52 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-e76a042d-kafka-config
2022-04-04 23:40:52 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-e76a042d-zookeeper-config
2022-04-04 23:40:52 [main] [32mINFO [m [AbstractST:407] CM my-cluster-e76a042d-zookeeper-config is not related to current test
2022-04-04 23:40:52 [main] [32mINFO [m [AbstractST:414] Verifying labels for Service Accounts
2022-04-04 23:40:52 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-e76a042d-connect
2022-04-04 23:40:52 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-e76a042d-entity-operator
2022-04-04 23:40:52 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-e76a042d-kafka
2022-04-04 23:40:52 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-e76a042d-zookeeper
2022-04-04 23:40:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 23:40:52 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeployUndeploy
2022-04-04 23:40:52 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-e76a042d-allow in namespace namespace-112
2022-04-04 23:40:52 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-e76a042d-scraper in namespace namespace-112
2022-04-04 23:40:52 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-e76a042d in namespace namespace-112
2022-04-04 23:40:52 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e76a042d in namespace namespace-112
2022-04-04 23:41:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 23:41:43 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-112 for test case:testDeployUndeploy
2022-04-04 23:41:48 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testDeployUndeploy-FINISHED
2022-04-04 23:41:48 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 23:41:48 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 23:41:48 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testMountingSecretAndConfigMapAsVolumesAndEnvVars-STARTED
2022-04-04 23:41:48 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 23:41:48 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-113 for test case:testMountingSecretAndConfigMapAsVolumesAndEnvVars
2022-04-04 23:41:48 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-113
2022-04-04 23:41:48 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-113
2022-04-04 23:41:48 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-113
2022-04-04 23:41:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b94f2773 in namespace namespace-113
2022-04-04 23:41:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-113
2022-04-04 23:41:48 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b94f2773 will have desired state: Ready
2022-04-04 23:43:02 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b94f2773 is in desired state: Ready
2022-04-04 23:43:02 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-b94f2773 in namespace namespace-113
2022-04-04 23:43:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-113
2022-04-04 23:43:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-b94f2773 will have desired state: Ready
2022-04-04 23:44:06 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-b94f2773 is in desired state: Ready
2022-04-04 23:44:06 [main] [32mINFO [m [ConnectIsolatedST:1148] Check if the ENVs contains desired values
2022-04-04 23:44:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-b94f2773-connect-54d74c5f88-w2rvl -- /bin/bash -c printenv MY_CONNECT_SECRET
2022-04-04 23:44:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:44:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-b94f2773-connect-54d74c5f88-w2rvl -- /bin/bash -c printenv MY_CONNECT_CONFIG_MAP
2022-04-04 23:44:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:44:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-b94f2773-connect-54d74c5f88-w2rvl -- /bin/bash -c printenv MY_DOTED_CONNECT_SECRET
2022-04-04 23:44:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:44:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-b94f2773-connect-54d74c5f88-w2rvl -- /bin/bash -c printenv MY_DOTED_CONNECT_CONFIG_MAP
2022-04-04 23:44:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:44:06 [main] [32mINFO [m [ConnectIsolatedST:1154] Check if volumes contains desired values
2022-04-04 23:44:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-b94f2773-connect-54d74c5f88-w2rvl -- /bin/bash -c cat external-configuration/connect-config-map/my-key
2022-04-04 23:44:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:44:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-b94f2773-connect-54d74c5f88-w2rvl -- /bin/bash -c cat external-configuration/connect-secret/my-secret-key
2022-04-04 23:44:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:44:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-b94f2773-connect-54d74c5f88-w2rvl -- /bin/bash -c cat external-configuration/connect.config.map/my-key
2022-04-04 23:44:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:44:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-b94f2773-connect-54d74c5f88-w2rvl -- /bin/bash -c cat external-configuration/connect.secret/my-secret-key
2022-04-04 23:44:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:44:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 23:44:07 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMountingSecretAndConfigMapAsVolumesAndEnvVars
2022-04-04 23:44:07 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-b94f2773 in namespace namespace-113
2022-04-04 23:44:07 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b94f2773 in namespace namespace-113
2022-04-04 23:44:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 23:44:17 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-113 for test case:testMountingSecretAndConfigMapAsVolumesAndEnvVars
2022-04-04 23:45:00 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testMountingSecretAndConfigMapAsVolumesAndEnvVars-FINISHED
2022-04-04 23:45:00 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 23:45:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 23:45:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testJvmAndResources-STARTED
2022-04-04 23:45:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 23:45:00 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-114 for test case:testJvmAndResources
2022-04-04 23:45:00 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-114
2022-04-04 23:45:00 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-114
2022-04-04 23:45:00 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-114
2022-04-04 23:45:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-6e268d6e in namespace namespace-114
2022-04-04 23:45:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-114
2022-04-04 23:45:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-6e268d6e will have desired state: Ready
2022-04-04 23:46:19 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-6e268d6e is in desired state: Ready
2022-04-04 23:46:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-6e268d6e-kafka-clients in namespace namespace-114
2022-04-04 23:46:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-114
2022-04-04 23:46:19 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-6e268d6e-kafka-clients will be ready
2022-04-04 23:46:21 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-6e268d6e-kafka-clients is ready
2022-04-04 23:46:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-6e268d6e-scraper in namespace namespace-114
2022-04-04 23:46:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-114
2022-04-04 23:46:21 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-6e268d6e-scraper will be ready
2022-04-04 23:46:23 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-6e268d6e-scraper is ready
2022-04-04 23:46:23 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-6e268d6e-scraper to be ready
2022-04-04 23:46:33 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-6e268d6e-scraper is ready
2022-04-04 23:46:33 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-6e268d6e-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 23:46:33 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-6e268d6e-allow in namespace namespace-114
2022-04-04 23:46:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-114
2022-04-04 23:46:33 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 23:46:33 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-6e268d6e in namespace namespace-114
2022-04-04 23:46:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-114
2022-04-04 23:46:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-6e268d6e will have desired state: Ready
2022-04-04 23:47:35 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-6e268d6e is in desired state: Ready
2022-04-04 23:47:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-114 exec my-cluster-6e268d6e-connect-5cb7c4dc7b-wz22w -c my-cluster-6e268d6e-connect -- /bin/bash -c for proc in $(ls -1 /proc/ | grep [0-9]); do if echo "$(ls -lh /proc/$proc/exe 2>/dev/null || true)" | grep -q java; then cat /proc/$proc/cmdline; fi; done
2022-04-04 23:47:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:47:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 23:47:35 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testJvmAndResources
2022-04-04 23:47:35 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-6e268d6e-scraper in namespace namespace-114
2022-04-04 23:47:35 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-6e268d6e in namespace namespace-114
2022-04-04 23:47:35 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-6e268d6e in namespace namespace-114
2022-04-04 23:47:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-6e268d6e-allow in namespace namespace-114
2022-04-04 23:47:35 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-6e268d6e-kafka-clients in namespace namespace-114
2022-04-04 23:48:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 23:48:25 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-114 for test case:testJvmAndResources
2022-04-04 23:48:31 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testJvmAndResources-FINISHED
2022-04-04 23:48:31 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 23:48:31 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 23:48:31 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testSecretsWithKafkaConnectWithTlsAndTlsClientAuthentication-STARTED
2022-04-04 23:48:31 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 23:48:31 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-115 for test case:testSecretsWithKafkaConnectWithTlsAndTlsClientAuthentication
2022-04-04 23:48:31 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-115
2022-04-04 23:48:31 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-115
2022-04-04 23:48:31 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-115
2022-04-04 23:48:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-663521af in namespace namespace-115
2022-04-04 23:48:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-04 23:48:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-663521af will have desired state: Ready
2022-04-04 23:49:44 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-663521af is in desired state: Ready
2022-04-04 23:49:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-663521af-user in namespace namespace-115
2022-04-04 23:49:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-04 23:49:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-663521af-user will have desired state: Ready
2022-04-04 23:49:45 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-663521af-user is in desired state: Ready
2022-04-04 23:49:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2006117859-1263838039 in namespace namespace-115
2022-04-04 23:49:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-04 23:49:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2006117859-1263838039 will have desired state: Ready
2022-04-04 23:49:46 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2006117859-1263838039 is in desired state: Ready
2022-04-04 23:49:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-663521af-scraper in namespace namespace-115
2022-04-04 23:49:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-04 23:49:46 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-663521af-scraper will be ready
2022-04-04 23:49:47 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-663521af-scraper is ready
2022-04-04 23:49:47 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-663521af-scraper to be ready
2022-04-04 23:49:57 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-663521af-scraper is ready
2022-04-04 23:49:57 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-663521af-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 23:49:57 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-663521af-allow in namespace namespace-115
2022-04-04 23:49:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-04 23:49:57 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 23:49:57 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-663521af in namespace namespace-115
2022-04-04 23:49:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-04 23:49:57 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-663521af will have desired state: Ready
2022-04-04 23:51:05 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-663521af is in desired state: Ready
2022-04-04 23:51:06 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-04 23:51:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-115 exec my-cluster-663521af-connect-9d8d65b59-84pxw -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-04 23:51:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:51:06 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-04 23:51:06 [main] [32mINFO [m [ConnectIsolatedST:474] Verifying that KafkaConnect pod logs don't contain ERRORs
2022-04-04 23:51:06 [main] [32mINFO [m [ConnectIsolatedST:477] Creating FileStreamSink connector via pod my-cluster-663521af-scraper-56d76b6bf8-vsxkn with topic my-topic-2006117859-1263838039
2022-04-04 23:51:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-115 exec my-cluster-663521af-scraper-56d76b6bf8-vsxkn -- /bin/bash -c curl -X POST -H "Content-Type: application/json" --data '{ "name": "sink-test", "config": { "connector.class": "FileStreamSink", "tasks.max": "1", "topics": "my-topic-2006117859-1263838039", "file": "/tmp/test-file-sink.txt" } }' http://my-cluster-663521af-connect-api.namespace-115.svc:8083/connectors
2022-04-04 23:51:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:51:06 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 23:51:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-663521af-hello-world-producer in namespace namespace-115
2022-04-04 23:51:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-04 23:51:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-663521af-hello-world-consumer in namespace namespace-115
2022-04-04 23:51:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-04 23:51:06 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-663521af-hello-world-producer will be in active state
2022-04-04 23:51:07 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-663521af-hello-world-consumer will be in active state
2022-04-04 23:51:07 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-663521af-hello-world-producer and consumer my-cluster-663521af-hello-world-consumer finish
2022-04-04 23:51:23 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-663521af-connect-9d8d65b59-84pxw
2022-04-04 23:51:24 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-663521af-connect-9d8d65b59-84pxw
2022-04-04 23:51:24 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 23:51:24 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSecretsWithKafkaConnectWithTlsAndTlsClientAuthentication
2022-04-04 23:51:24 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-663521af in namespace namespace-115
2022-04-04 23:51:24 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-663521af-allow in namespace namespace-115
2022-04-04 23:51:24 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-663521af-hello-world-consumer in namespace namespace-115
2022-04-04 23:51:24 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-663521af in namespace namespace-115
2022-04-04 23:51:24 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2006117859-1263838039 in namespace namespace-115
2022-04-04 23:51:24 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-663521af-scraper in namespace namespace-115
2022-04-04 23:51:24 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-663521af-user in namespace namespace-115
2022-04-04 23:51:24 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-663521af-hello-world-producer in namespace namespace-115
2022-04-04 23:52:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 23:52:04 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-115 for test case:testSecretsWithKafkaConnectWithTlsAndTlsClientAuthentication
2022-04-04 23:52:09 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testSecretsWithKafkaConnectWithTlsAndTlsClientAuthentication-FINISHED
2022-04-04 23:52:09 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 23:52:09 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 23:52:09 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testScaleConnectWithoutConnectorToZero-STARTED
2022-04-04 23:52:09 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 23:52:09 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-116 for test case:testScaleConnectWithoutConnectorToZero
2022-04-04 23:52:09 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-116
2022-04-04 23:52:09 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-116
2022-04-04 23:52:09 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-116
2022-04-04 23:52:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d7f5356b in namespace namespace-116
2022-04-04 23:52:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-116
2022-04-04 23:52:09 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d7f5356b will have desired state: Ready
2022-04-04 23:53:26 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d7f5356b is in desired state: Ready
2022-04-04 23:53:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-d7f5356b in namespace namespace-116
2022-04-04 23:53:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-116
2022-04-04 23:53:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-d7f5356b will have desired state: Ready
2022-04-04 23:54:38 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-d7f5356b is in desired state: Ready
2022-04-04 23:54:38 [main] [32mINFO [m [ConnectIsolatedST:891] Scaling KafkaConnect down to zero
2022-04-04 23:54:38 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-d7f5356b will have desired state: Ready
2022-04-04 23:54:38 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-d7f5356b is in desired state: Ready
2022-04-04 23:54:41 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 23:54:41 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleConnectWithoutConnectorToZero
2022-04-04 23:54:41 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-d7f5356b in namespace namespace-116
2022-04-04 23:54:41 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d7f5356b in namespace namespace-116
2022-04-04 23:54:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 23:54:51 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-116 for test case:testScaleConnectWithoutConnectorToZero
2022-04-04 23:55:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testScaleConnectWithoutConnectorToZero-FINISHED
2022-04-04 23:55:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 23:55:34 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 23:55:34 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testScaleConnectWithConnectorToZero-STARTED
2022-04-04 23:55:34 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 23:55:34 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-117 for test case:testScaleConnectWithConnectorToZero
2022-04-04 23:55:34 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-117
2022-04-04 23:55:34 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-117
2022-04-04 23:55:34 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-117
2022-04-04 23:55:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-84ba612d in namespace namespace-117
2022-04-04 23:55:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-117
2022-04-04 23:55:34 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-84ba612d will have desired state: Ready
2022-04-04 23:56:49 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-84ba612d is in desired state: Ready
2022-04-04 23:56:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-84ba612d in namespace namespace-117
2022-04-04 23:56:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-117
2022-04-04 23:56:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-84ba612d will have desired state: Ready
2022-04-04 23:58:01 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-84ba612d is in desired state: Ready
2022-04-04 23:58:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-84ba612d in namespace namespace-117
2022-04-04 23:58:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-117
2022-04-04 23:58:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-84ba612d will have desired state: Ready
2022-04-04 23:58:02 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-84ba612d is in desired state: Ready
2022-04-04 23:58:02 [main] [32mINFO [m [ConnectIsolatedST:934] Scaling KafkaConnect down to zero
2022-04-04 23:58:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-84ba612d will have desired state: Ready
2022-04-04 23:58:02 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-84ba612d is in desired state: Ready
2022-04-04 23:58:09 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 23:58:09 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleConnectWithConnectorToZero
2022-04-04 23:58:09 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-84ba612d in namespace namespace-117
2022-04-04 23:58:09 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-84ba612d in namespace namespace-117
2022-04-04 23:58:09 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-84ba612d in namespace namespace-117
2022-04-04 23:58:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 23:58:19 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-117 for test case:testScaleConnectWithConnectorToZero
2022-04-04 23:59:02 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testScaleConnectWithConnectorToZero-FINISHED
2022-04-04 23:59:02 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 23:59:02 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 23:59:02 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectWithPlainAndScramShaAuthentication-STARTED
2022-04-04 23:59:02 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 23:59:02 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-118 for test case:testKafkaConnectWithPlainAndScramShaAuthentication
2022-04-04 23:59:02 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-118
2022-04-04 23:59:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-118
2022-04-04 23:59:02 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-118
2022-04-04 23:59:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-86db49dc in namespace namespace-118
2022-04-04 23:59:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-04 23:59:02 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-86db49dc will have desired state: Ready
2022-04-05 00:00:20 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-86db49dc is in desired state: Ready
2022-04-05 00:00:20 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-86db49dc-user in namespace namespace-118
2022-04-05 00:00:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-05 00:00:20 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-86db49dc-user will have desired state: Ready
2022-04-05 00:00:21 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-86db49dc-user is in desired state: Ready
2022-04-05 00:00:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2123810815-2008910471 in namespace namespace-118
2022-04-05 00:00:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-05 00:00:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2123810815-2008910471 will have desired state: Ready
2022-04-05 00:00:22 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2123810815-2008910471 is in desired state: Ready
2022-04-05 00:00:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-86db49dc-scraper in namespace namespace-118
2022-04-05 00:00:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-05 00:00:22 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-86db49dc-scraper will be ready
2022-04-05 00:00:24 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-86db49dc-scraper is ready
2022-04-05 00:00:24 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-86db49dc-scraper to be ready
2022-04-05 00:00:34 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-86db49dc-scraper is ready
2022-04-05 00:00:34 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-86db49dc-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-05 00:00:34 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-86db49dc-allow in namespace namespace-118
2022-04-05 00:00:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-05 00:00:34 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-05 00:00:34 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-86db49dc in namespace namespace-118
2022-04-05 00:00:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-05 00:00:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-86db49dc will have desired state: Ready
2022-04-05 00:01:38 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-86db49dc is in desired state: Ready
2022-04-05 00:01:38 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-05 00:01:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-118 exec my-cluster-86db49dc-connect-984cfbd5f-48bfj -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-05 00:01:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 00:01:39 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-05 00:01:39 [main] [32mINFO [m [ConnectIsolatedST:280] Verifying that KafkaConnect pod logs don't contain ERRORs
2022-04-05 00:01:39 [main] [32mINFO [m [ConnectIsolatedST:283] Creating FileStreamSink connector via pod my-cluster-86db49dc-scraper-7bd8cc746d-gwqd2 with topic my-topic-2123810815-2008910471
2022-04-05 00:01:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-118 exec my-cluster-86db49dc-scraper-7bd8cc746d-gwqd2 -- /bin/bash -c curl -X POST -H "Content-Type: application/json" --data '{ "name": "sink-test", "config": { "connector.class": "FileStreamSink", "tasks.max": "1", "topics": "my-topic-2123810815-2008910471", "file": "/tmp/test-file-sink.txt" } }' http://my-cluster-86db49dc-connect-api.namespace-118.svc:8083/connectors
2022-04-05 00:01:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 00:01:39 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 00:01:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-86db49dc-hello-world-producer in namespace namespace-118
2022-04-05 00:01:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-05 00:01:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-86db49dc-hello-world-consumer in namespace namespace-118
2022-04-05 00:01:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-05 00:01:39 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-86db49dc-hello-world-producer will be in active state
2022-04-05 00:01:39 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-86db49dc-hello-world-consumer will be in active state
2022-04-05 00:01:39 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-86db49dc-hello-world-producer and consumer my-cluster-86db49dc-hello-world-consumer finish
2022-04-05 00:01:56 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-86db49dc-connect-984cfbd5f-48bfj
2022-04-05 00:01:56 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-86db49dc-connect-984cfbd5f-48bfj
2022-04-05 00:01:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:01:56 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectWithPlainAndScramShaAuthentication
2022-04-05 00:01:56 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-86db49dc-allow in namespace namespace-118
2022-04-05 00:01:56 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-86db49dc-user in namespace namespace-118
2022-04-05 00:01:56 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-86db49dc in namespace namespace-118
2022-04-05 00:01:56 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-86db49dc-hello-world-consumer in namespace namespace-118
2022-04-05 00:01:56 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-86db49dc in namespace namespace-118
2022-04-05 00:01:56 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-86db49dc-hello-world-producer in namespace namespace-118
2022-04-05 00:01:56 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2123810815-2008910471 in namespace namespace-118
2022-04-05 00:01:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-86db49dc-scraper in namespace namespace-118
2022-04-05 00:02:46 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 00:02:46 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-118 for test case:testKafkaConnectWithPlainAndScramShaAuthentication
2022-04-05 00:02:52 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectWithPlainAndScramShaAuthentication-FINISHED
2022-04-05 00:02:52 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 00:02:52 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 00:02:52 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testCustomAndUpdatedValues-STARTED
2022-04-05 00:02:52 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 00:02:52 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-119 for test case:testCustomAndUpdatedValues
2022-04-05 00:02:52 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-119
2022-04-05 00:02:52 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-119
2022-04-05 00:02:52 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-119
2022-04-05 00:02:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c5e20c37 in namespace namespace-119
2022-04-05 00:02:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-119
2022-04-05 00:02:52 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c5e20c37 will have desired state: Ready
2022-04-05 00:04:00 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c5e20c37 is in desired state: Ready
2022-04-05 00:04:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-c5e20c37 in namespace namespace-119
2022-04-05 00:04:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-119
2022-04-05 00:04:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-c5e20c37 will have desired state: Ready
2022-04-05 00:04:39 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-c5e20c37 is in desired state: Ready
2022-04-05 00:04:39 [main] [32mINFO [m [ConnectIsolatedST:629] Verify values before update
2022-04-05 00:04:39 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-c5e20c37-connect in pod name
2022-04-05 00:04:39 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container my-cluster-c5e20c37-connect
2022-04-05 00:04:39 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-c5e20c37-connect
2022-04-05 00:04:39 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container my-cluster-c5e20c37-connect
2022-04-05 00:04:39 [main] [32mINFO [m [ConnectIsolatedST:634] Check if actual env variable KAFKA_CONNECT_CONFIGURATION has different value than test.value
2022-04-05 00:04:39 [main] [32mINFO [m [ConnectIsolatedST:640] Updating values in MirrorMaker container
2022-04-05 00:04:39 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-c5e20c37-connect rolling update
2022-04-05 00:05:24 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c5e20c37-connect will be ready
2022-04-05 00:05:24 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c5e20c37-connect is ready
2022-04-05 00:05:34 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-c5e20c37-connect rolling update finished
2022-04-05 00:05:34 [main] [32mINFO [m [ConnectIsolatedST:657] Verify values after update
2022-04-05 00:05:34 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-c5e20c37-connect in pod name
2022-04-05 00:05:34 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container my-cluster-c5e20c37-connect
2022-04-05 00:05:34 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-c5e20c37-connect
2022-04-05 00:05:34 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container my-cluster-c5e20c37-connect
2022-04-05 00:05:34 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-c5e20c37-connect
2022-04-05 00:05:34 [main] [32mINFO [m [AbstractST:194] Testing configuration for container my-cluster-c5e20c37-connect
2022-04-05 00:05:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:05:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCustomAndUpdatedValues
2022-04-05 00:05:34 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-c5e20c37 in namespace namespace-119
2022-04-05 00:05:34 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c5e20c37 in namespace namespace-119
2022-04-05 00:05:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 00:05:44 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-119 for test case:testCustomAndUpdatedValues
2022-04-05 00:06:28 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testCustomAndUpdatedValues-FINISHED
2022-04-05 00:06:28 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 00:06:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:06:28 [main] [32mINFO [m [ResourceManager:346] In context ConnectIsolatedST is everything deleted.
2022-04-05 00:06:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4,008.016 s - in io.strimzi.systemtest.connect.ConnectIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.connect.ConnectBuilderIsolatedST
2022-04-05 00:06:28 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 00:06:53 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-05 00:06:53 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-05 00:06:53 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-05 00:06:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:06:53 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-05 00:06:53 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 00:06:53 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 00:06:53 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 00:06:53 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 00:06:53 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 00:06:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 00:06:53 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 00:06:53 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 00:06:53 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 00:06:53 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:06:53 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 00:06:53 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 00:06:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 00:06:53 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 00:06:53 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:06:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 00:06:53 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:06:53 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 00:06:53 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 00:06:53 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 00:07:03 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 00:07:03 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 00:07:03 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:07:03 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 00:07:03 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 00:07:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 00:07:18 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=30000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-05 00:07:18 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-05 00:07:18 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-05 00:07:18 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 00:07:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:07:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 00:07:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 00:07:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 00:07:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 00:07:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 00:07:18 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 00:07:18 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 00:07:18 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 00:07:18 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 00:07:18 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 00:07:18 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 00:07:18 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 00:07:18 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 00:07:18 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 00:07:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 00:07:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:07:19 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-05 00:07:19 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 00:07:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 00:07:19 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-05 00:07:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 00:07:19 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-05 00:07:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 00:07:19 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 00:07:19 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:07:19 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-05 00:07:19 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 00:07:19 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 00:07:19 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 00:07:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 00:07:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 00:07:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:07:19 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-05 00:07:51 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-05 00:07:51 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-05 00:08:01 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-05 00:08:01 [main] [33mWARN [m [ConnectBuilderIsolatedST:546] For running these tests on K8s you have to have internal registry deployed using `minikube start --insecure-registry '10.0.0.0/24'` and `minikube addons enable registry`
2022-04-05 00:08:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka infra-namespace in namespace infra-namespace
2022-04-05 00:08:01 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: infra-namespace will have desired state: Ready
2022-04-05 00:09:22 [main] [32mINFO [m [ResourceManager:444] Kafka: infra-namespace is in desired state: Ready
2022-04-05 00:09:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 00:09:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildWithJarTgzAndZip-STARTED
2022-04-05 00:09:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 00:09:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-515692599-1665805177 in namespace infra-namespace
2022-04-05 00:09:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-515692599-1665805177 will have desired state: Ready
2022-04-05 00:09:23 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-515692599-1665805177 is in desired state: Ready
2022-04-05 00:09:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-a575c520 in namespace infra-namespace
2022-04-05 00:09:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-a575c520 will have desired state: Ready
2022-04-05 00:11:07 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-a575c520 is in desired state: Ready
2022-04-05 00:11:07 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-a575c520 in namespace infra-namespace
2022-04-05 00:11:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-a575c520 will have desired state: Ready
2022-04-05 00:11:08 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-a575c520 is in desired state: Ready
2022-04-05 00:11:08 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 00:11:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-a575c520-hello-world-producer in namespace infra-namespace
2022-04-05 00:11:08 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-a575c520-hello-world-producer will be in active state
2022-04-05 00:11:09 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:my-cluster-a575c520-hello-world-producer to finished
2022-04-05 00:11:17 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-05 00:11:18 [main] [32mINFO [m [PodUtils:189] Message Received message with key 'null' and value '"Hello-world - 99"' found in my-cluster-a575c520-connect-7786d99cc5-8j9cd log
2022-04-05 00:11:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:11:18 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBuildWithJarTgzAndZip
2022-04-05 00:11:18 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-a575c520 in namespace infra-namespace
2022-04-05 00:11:18 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-a575c520-hello-world-producer in namespace infra-namespace
2022-04-05 00:11:18 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-515692599-1665805177 in namespace infra-namespace
2022-04-05 00:11:18 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-a575c520 in namespace infra-namespace
2022-04-05 00:11:38 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 00:11:38 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildWithJarTgzAndZip-FINISHED
2022-04-05 00:11:38 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 00:11:38 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 00:11:38 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildFailsWithWrongChecksumOfArtifact-STARTED
2022-04-05 00:11:38 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 00:11:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-11bb52d9-scraper in namespace infra-namespace
2022-04-05 00:11:38 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-11bb52d9-scraper will be ready
2022-04-05 00:11:39 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-11bb52d9-scraper is ready
2022-04-05 00:11:39 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-11bb52d9-scraper to be ready
2022-04-05 00:11:49 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-11bb52d9-scraper is ready
2022-04-05 00:11:49 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-11bb52d9-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-05 00:11:49 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-11bb52d9-allow in namespace infra-namespace
2022-04-05 00:11:49 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-05 00:11:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-11bb52d9 in namespace infra-namespace
2022-04-05 00:11:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-11bb52d9 will have desired state: NotReady
2022-04-05 00:11:50 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-11bb52d9 is in desired state: NotReady
2022-04-05 00:12:13 [main] [32mINFO [m [ConnectBuilderIsolatedST:186] Checking if KafkaConnect status condition contains message about build failure
2022-04-05 00:12:13 [main] [32mINFO [m [ConnectBuilderIsolatedST:189] Deploying network policies for KafkaConnect
2022-04-05 00:12:13 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-11bb52d9-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-05 00:12:13 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-11bb52d9-allow in namespace infra-namespace
2022-04-05 00:12:13 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-05 00:12:13 [main] [32mINFO [m [ConnectBuilderIsolatedST:197] Replacing plugin's checksum with right one
2022-04-05 00:12:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-11bb52d9 will have desired state: Ready
2022-04-05 00:14:33 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-11bb52d9 is in desired state: Ready
2022-04-05 00:14:33 [main] [32mINFO [m [ConnectBuilderIsolatedST:215] Checking if KafkaConnect API contains EchoSink connector
2022-04-05 00:14:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-11bb52d9-scraper-58c8f95bd9-pzgbg -- curl -X GET http://my-cluster-11bb52d9-connect-api:8083/connector-plugins
2022-04-05 00:14:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 00:14:33 [main] [32mINFO [m [ConnectBuilderIsolatedST:220] Checking if KafkaConnect resource contains EchoSink connector in status
2022-04-05 00:14:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:14:33 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBuildFailsWithWrongChecksumOfArtifact
2022-04-05 00:14:33 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-11bb52d9 in namespace infra-namespace
2022-04-05 00:14:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-11bb52d9-allow in namespace infra-namespace
2022-04-05 00:14:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-11bb52d9-scraper in namespace infra-namespace
2022-04-05 00:14:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-11bb52d9-allow in namespace infra-namespace
2022-04-05 00:15:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 00:15:13 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildFailsWithWrongChecksumOfArtifact-FINISHED
2022-04-05 00:15:13 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 00:15:13 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 00:15:13 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildOtherPluginTypeWithAndWithoutFileName-STARTED
2022-04-05 00:15:13 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 00:15:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-999969841-1912309979 in namespace infra-namespace
2022-04-05 00:15:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-999969841-1912309979 will have desired state: Ready
2022-04-05 00:15:15 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-999969841-1912309979 is in desired state: Ready
2022-04-05 00:15:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-f303f5c7-scraper in namespace infra-namespace
2022-04-05 00:15:15 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f303f5c7-scraper will be ready
2022-04-05 00:15:17 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f303f5c7-scraper is ready
2022-04-05 00:15:17 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-f303f5c7-scraper to be ready
2022-04-05 00:15:27 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-f303f5c7-scraper is ready
2022-04-05 00:15:27 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-f303f5c7-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-05 00:15:27 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-f303f5c7-allow in namespace infra-namespace
2022-04-05 00:15:27 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-05 00:15:27 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-f303f5c7 in namespace infra-namespace
2022-04-05 00:15:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-f303f5c7 will have desired state: Ready
2022-04-05 00:17:03 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-f303f5c7 is in desired state: Ready
2022-04-05 00:17:03 [main] [32mINFO [m [ConnectBuilderIsolatedST:448] Checking that plugin has correct file name: echo-sink-test.jar
2022-04-05 00:17:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-f303f5c7-connect-78c8c4556b-xpxsb -- /bin/bash -c ls plugins/plugin-with-other-type/*
2022-04-05 00:17:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 00:17:03 [main] [32mINFO [m [ConnectBuilderIsolatedST:461] Removing file name from the plugin, hash should be used
2022-04-05 00:17:03 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-f303f5c7-connect rolling update
2022-04-05 00:18:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f303f5c7-connect will be ready
2022-04-05 00:18:58 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f303f5c7-connect is ready
2022-04-05 00:19:08 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-f303f5c7-connect rolling update finished
2022-04-05 00:19:08 [main] [32mINFO [m [ConnectBuilderIsolatedST:468] Checking that plugin has different name than before
2022-04-05 00:19:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-f303f5c7-connect-564658cf66-52j5v -- /bin/bash -c ls plugins/plugin-with-other-type/*
2022-04-05 00:19:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 00:19:09 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:19:09 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBuildOtherPluginTypeWithAndWithoutFileName
2022-04-05 00:19:09 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-f303f5c7-allow in namespace infra-namespace
2022-04-05 00:19:09 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-f303f5c7 in namespace infra-namespace
2022-04-05 00:19:09 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-999969841-1912309979 in namespace infra-namespace
2022-04-05 00:19:09 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-f303f5c7-scraper in namespace infra-namespace
2022-04-05 00:19:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 00:19:49 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildOtherPluginTypeWithAndWithoutFileName-FINISHED
2022-04-05 00:19:49 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 00:19:49 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 00:19:49 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testUpdateConnectWithAnotherPlugin-STARTED
2022-04-05 00:19:49 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 00:19:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-253275963-639602005 in namespace infra-namespace
2022-04-05 00:19:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-253275963-639602005 will have desired state: Ready
2022-04-05 00:19:50 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-253275963-639602005 is in desired state: Ready
2022-04-05 00:19:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-44be319e-scraper in namespace infra-namespace
2022-04-05 00:19:50 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-44be319e-scraper will be ready
2022-04-05 00:19:52 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-44be319e-scraper is ready
2022-04-05 00:19:52 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-44be319e-scraper to be ready
2022-04-05 00:20:02 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-44be319e-scraper is ready
2022-04-05 00:20:02 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-44be319e-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-05 00:20:02 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-44be319e-allow in namespace infra-namespace
2022-04-05 00:20:02 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-05 00:20:02 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-44be319e in namespace infra-namespace
2022-04-05 00:20:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-44be319e will have desired state: Ready
2022-04-05 00:21:56 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-44be319e is in desired state: Ready
2022-04-05 00:21:56 [main] [32mINFO [m [ConnectBuilderIsolatedST:370] Creating EchoSink connector
2022-04-05 00:21:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector echo-sink-connector in namespace infra-namespace
2022-04-05 00:21:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: echo-sink-connector will have desired state: Ready
2022-04-05 00:21:57 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: echo-sink-connector is in desired state: Ready
2022-04-05 00:21:57 [main] [32mINFO [m [ConnectBuilderIsolatedST:382] Checking that KafkaConnect API contains EchoSink connector and not Camel-Telegram Connector class name
2022-04-05 00:21:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-44be319e-scraper-658dc488db-skkts -- curl -X GET http://my-cluster-44be319e-connect-api:8083/connector-plugins
2022-04-05 00:21:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 00:21:57 [main] [32mINFO [m [ConnectBuilderIsolatedST:388] Adding one more connector to the KafkaConnect
2022-04-05 00:21:57 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-44be319e-connect rolling update
2022-04-05 00:23:37 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-44be319e-connect will be ready
2022-04-05 00:23:37 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-44be319e-connect is ready
2022-04-05 00:23:48 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-44be319e-connect rolling update finished
2022-04-05 00:23:48 [main] [32mINFO [m [ConnectBuilderIsolatedST:399] Creating Camel-HTTP-Sink connector
2022-04-05 00:23:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector camel-http-connector in namespace infra-namespace
2022-04-05 00:23:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: camel-http-connector will have desired state: Ready
2022-04-05 00:23:49 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: camel-http-connector is in desired state: Ready
2022-04-05 00:23:49 [main] [32mINFO [m [ConnectBuilderIsolatedST:409] Checking if both Connectors were created and Connect contains both plugins
2022-04-05 00:23:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:23:49 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUpdateConnectWithAnotherPlugin
2022-04-05 00:23:49 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-44be319e in namespace infra-namespace
2022-04-05 00:23:49 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-253275963-639602005 in namespace infra-namespace
2022-04-05 00:23:49 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector camel-http-connector in namespace infra-namespace
2022-04-05 00:23:49 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector echo-sink-connector in namespace infra-namespace
2022-04-05 00:23:49 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-44be319e-allow in namespace infra-namespace
2022-04-05 00:23:49 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-44be319e-scraper in namespace infra-namespace
2022-04-05 00:24:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 00:24:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testUpdateConnectWithAnotherPlugin-FINISHED
2022-04-05 00:24:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 00:24:29 [main] [32mINFO [m [OpenShiftOnlyCondition:25] testPushIntoImageStream is @OpenShiftOnly, but the running cluster is not OpenShift: Ignoring testPushIntoImageStream
2022-04-05 00:24:29 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 00:24:29 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildPluginUsingMavenCoordinatesArtifacts-STARTED
2022-04-05 00:24:29 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 00:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1042600747-1736680388 in namespace infra-namespace
2022-04-05 00:24:29 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-4fc33a14 in namespace infra-namespace
2022-04-05 00:24:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1042600747-1736680388 will have desired state: Ready
2022-04-05 00:24:30 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1042600747-1736680388 is in desired state: Ready
2022-04-05 00:24:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-4fc33a14 will have desired state: Ready
2022-04-05 00:26:56 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-4fc33a14 is in desired state: Ready
2022-04-05 00:26:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-4fc33a14-camel-connector in namespace infra-namespace
2022-04-05 00:26:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-4fc33a14-camel-connector will have desired state: Ready
2022-04-05 00:26:57 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-4fc33a14-camel-connector is in desired state: Ready
2022-04-05 00:26:57 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 00:26:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-4fc33a14-hello-world-consumer in namespace infra-namespace
2022-04-05 00:26:57 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-4fc33a14-hello-world-consumer will be in active state
2022-04-05 00:26:58 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:my-cluster-4fc33a14-hello-world-consumer to finished
2022-04-05 00:27:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:27:53 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBuildPluginUsingMavenCoordinatesArtifacts
2022-04-05 00:27:53 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-4fc33a14-camel-connector in namespace infra-namespace
2022-04-05 00:27:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-4fc33a14-hello-world-consumer in namespace infra-namespace
2022-04-05 00:27:53 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1042600747-1736680388 in namespace infra-namespace
2022-04-05 00:27:53 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-4fc33a14 in namespace infra-namespace
2022-04-05 00:28:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 00:28:13 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildPluginUsingMavenCoordinatesArtifacts-FINISHED
2022-04-05 00:28:13 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 00:28:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:28:13 [main] [32mINFO [m [ResourceManager:348] Delete all resources for ConnectBuilderIsolatedST
2022-04-05 00:28:13 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka infra-namespace in namespace infra-namespace
2022-04-05 00:28:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;33mWARNING[m] Tests run: 6, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 1,315.664 s - in io.strimzi.systemtest.connect.ConnectBuilderIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST
2022-04-05 00:28:23 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 00:28:48 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-05 00:28:48 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-05 00:28:48 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-05 00:28:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:28:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-05 00:28:48 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 00:28:48 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 00:28:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 00:28:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 00:28:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 00:28:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 00:28:48 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 00:28:48 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:28:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 00:28:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 00:28:48 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 00:28:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:28:48 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 00:28:48 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:28:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 00:28:48 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 00:28:49 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 00:28:49 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 00:28:49 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 00:28:58 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 00:28:58 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 00:28:58 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 00:28:58 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:28:59 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 00:28:59 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 00:29:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 00:29:14 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-05 00:29:14 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-05 00:29:14 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-05 00:29:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 00:29:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:29:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 00:29:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 00:29:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 00:29:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 00:29:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 00:29:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 00:29:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 00:29:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 00:29:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 00:29:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 00:29:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 00:29:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 00:29:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 00:29:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 00:29:15 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 00:29:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:29:15 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-05 00:29:15 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 00:29:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 00:29:15 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-05 00:29:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 00:29:15 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-05 00:29:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 00:29:15 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 00:29:15 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:29:15 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-05 00:29:15 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 00:29:15 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 00:29:15 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 00:29:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 00:29:15 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 00:29:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:29:15 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-05 00:29:47 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-05 00:29:47 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-05 00:29:57 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-05 00:29:57 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 00:29:57 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST.backupAndRestore-STARTED
2022-04-05 00:29:57 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 00:29:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-99dd4801 in namespace infra-namespace
2022-04-05 00:29:57 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-99dd4801 will have desired state: Ready
2022-04-05 00:31:14 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-99dd4801 is in desired state: Ready
2022-04-05 00:31:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-99dd4801-producer in namespace infra-namespace
2022-04-05 00:31:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-99dd4801-consumer in namespace infra-namespace
2022-04-05 00:31:14 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-99dd4801-producer will be in active state
2022-04-05 00:31:14 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-99dd4801-consumer will be in active state
2022-04-05 00:31:14 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-99dd4801-producer and consumer my-cluster-99dd4801-consumer finish
2022-04-05 00:31:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-99dd4801-kafka-0 -- /opt/kafka/bin/kafka-consumer-groups.sh --describe --bootstrap-server localhost:9092 --group my-group
2022-04-05 00:31:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 00:31:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-99dd4801-producer in namespace infra-namespace
2022-04-05 00:31:33 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-99dd4801-producer will be in active state
2022-04-05 00:31:34 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:my-cluster-99dd4801-producer to finished
2022-04-05 00:31:42 [main] [32mINFO [m [ColdBackupScriptIsolatedST:95] Running backup procedure for infra-namespace/my-cluster-99dd4801
2022-04-05 00:33:53 [main] [32mINFO [m [Exec:417] Command: /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/cold-backup/run.sh backup -n infra-namespace -c my-cluster-99dd4801 -t /home/ec2-user/strimzi-kafka-operator/systemtest/target/my-cluster-99dd4801.tgz -y
2022-04-05 00:33:53 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 00:33:53 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-05 00:33:53 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-05 00:33:53 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-05 00:33:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:33:53 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-05 00:33:53 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 00:33:53 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 00:33:53 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 00:33:53 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 00:33:53 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 00:33:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 00:33:53 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 00:33:53 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 00:33:53 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 00:33:53 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:33:53 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:33:53 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:33:53 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 00:33:53 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 00:33:53 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 00:33:53 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 00:33:53 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 00:33:53 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 00:33:53 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 00:33:53 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 00:33:53 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 00:33:53 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:33:53 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 00:34:03 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 00:34:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 00:34:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 00:34:40 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-05 00:34:40 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-05 00:34:40 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-05 00:34:40 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 00:34:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:34:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 00:34:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 00:34:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 00:34:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 00:34:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 00:34:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 00:34:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 00:34:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 00:34:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 00:34:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 00:34:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 00:34:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 00:34:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 00:34:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 00:34:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 00:34:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:34:40 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-05 00:34:40 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 00:34:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 00:34:40 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-05 00:34:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 00:34:40 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-05 00:34:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 00:34:40 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 00:34:40 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:34:40 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-05 00:34:40 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 00:34:40 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 00:34:40 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 00:34:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 00:34:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 00:34:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:34:40 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-05 00:34:55 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-05 00:34:55 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-05 00:35:05 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-05 00:35:05 [main] [32mINFO [m [ColdBackupScriptIsolatedST:109] Running restore procedure for infra-namespace/my-cluster-99dd4801
2022-04-05 00:36:29 [main] [32mINFO [m [Exec:417] Command: /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/cold-backup/run.sh restore -n infra-namespace -c my-cluster-99dd4801 -s /home/ec2-user/strimzi-kafka-operator/systemtest/target/my-cluster-99dd4801.tgz -y
2022-04-05 00:36:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 00:36:29 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-99dd4801 will have desired state: Ready
2022-04-05 00:37:01 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-99dd4801 is in desired state: Ready
2022-04-05 00:37:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-99dd4801-kafka-0 -- /opt/kafka/bin/kafka-consumer-groups.sh --describe --bootstrap-server localhost:9092 --group my-group
2022-04-05 00:37:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 00:37:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-99dd4801-consumer in namespace infra-namespace
2022-04-05 00:37:03 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-99dd4801-consumer will be in active state
2022-04-05 00:37:04 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:my-cluster-99dd4801-consumer to finished
2022-04-05 00:37:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-99dd4801-consumer in namespace infra-namespace
2022-04-05 00:37:14 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-99dd4801-consumer will be in active state
2022-04-05 00:37:15 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:my-cluster-99dd4801-consumer to finished
2022-04-05 00:37:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:37:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for backupAndRestore
2022-04-05 00:37:25 [main] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-99dd4801-producer in namespace infra-namespace
2022-04-05 00:37:25 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-99dd4801-consumer in namespace infra-namespace
2022-04-05 00:37:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-99dd4801-consumer in namespace infra-namespace
2022-04-05 00:37:25 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-99dd4801-consumer in namespace infra-namespace
2022-04-05 00:37:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-99dd4801 in namespace infra-namespace
2022-04-05 00:37:25 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-99dd4801-producer in namespace infra-namespace
2022-04-05 00:37:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 00:37:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST.backupAndRestore-FINISHED
2022-04-05 00:37:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 00:37:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:37:35 [main] [32mINFO [m [ResourceManager:346] In context ColdBackupScriptIsolatedST is everything deleted.
2022-04-05 00:37:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 552.015 s - in io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST
2022-04-05 00:37:35 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 00:38:00 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-05 00:38:00 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-05 00:38:00 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-05 00:38:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:38:00 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-05 00:38:00 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 00:38:00 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 00:38:00 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 00:38:00 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 00:38:00 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:38:00 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 00:38:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 00:38:00 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 00:38:01 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 00:38:01 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 00:38:01 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 00:38:01 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 00:38:01 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:38:01 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:38:01 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 00:38:01 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 00:38:01 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 00:38:01 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 00:38:01 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 00:38:11 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 00:38:11 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:38:11 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 00:38:11 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 00:38:11 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 00:38:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 00:38:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 00:38:26 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=30000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-05 00:38:26 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-05 00:38:26 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-05 00:38:26 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 00:38:26 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:38:26 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 00:38:26 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 00:38:26 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 00:38:26 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 00:38:26 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 00:38:26 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 00:38:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 00:38:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 00:38:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 00:38:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 00:38:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 00:38:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 00:38:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 00:38:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 00:38:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 00:38:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:38:27 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-05 00:38:27 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 00:38:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 00:38:27 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-05 00:38:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 00:38:27 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-05 00:38:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 00:38:27 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 00:38:27 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:38:27 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-05 00:38:27 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 00:38:27 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 00:38:27 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 00:38:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 00:38:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 00:38:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:38:27 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-05 00:39:01 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-05 00:39:01 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-05 00:39:11 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-05 00:39:11 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 00:39:11 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testRestoreOffsetsInConsumerGroup-STARTED
2022-04-05 00:39:11 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 00:39:11 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-120 for test case:testRestoreOffsetsInConsumerGroup
2022-04-05 00:39:11 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-120
2022-04-05 00:39:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-120
2022-04-05 00:39:11 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-120
2022-04-05 00:39:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-9e54eecf-source in namespace namespace-120
2022-04-05 00:39:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-05 00:39:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-9e54eecf-target in namespace namespace-120
2022-04-05 00:39:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-05 00:39:11 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-9e54eecf-source will have desired state: Ready
2022-04-05 00:40:40 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-9e54eecf-source is in desired state: Ready
2022-04-05 00:40:40 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-9e54eecf-target will have desired state: Ready
2022-04-05 00:40:41 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-9e54eecf-target is in desired state: Ready
2022-04-05 00:40:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-9e54eecf-trg-src in namespace namespace-120
2022-04-05 00:40:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-05 00:40:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-9e54eecf-src-trg in namespace namespace-120
2022-04-05 00:40:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-05 00:40:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic test-sync-offset-1317640555 in namespace namespace-120
2022-04-05 00:40:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-05 00:40:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-9e54eecf-trg-src will have desired state: Ready
2022-04-05 00:41:50 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-9e54eecf-trg-src is in desired state: Ready
2022-04-05 00:41:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-9e54eecf-src-trg will have desired state: Ready
2022-04-05 00:41:51 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-9e54eecf-src-trg is in desired state: Ready
2022-04-05 00:41:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: test-sync-offset-1317640555 will have desired state: Ready
2022-04-05 00:41:51 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: test-sync-offset-1317640555 is in desired state: Ready
2022-04-05 00:41:51 [main] [32mINFO [m [MirrorMaker2IsolatedST:1090] Send & receive 100 messages to/from Source cluster.
2022-04-05 00:41:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-producer-source-my-consumer-group-1291687778 in namespace namespace-120
2022-04-05 00:41:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-05 00:41:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-consumer-source-my-consumer-group-1333712203 in namespace namespace-120
2022-04-05 00:41:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-05 00:41:51 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-producer-source-my-consumer-group-1291687778 will be in active state
2022-04-05 00:41:52 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-consumer-source-my-consumer-group-1333712203 will be in active state
2022-04-05 00:41:52 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-producer-source-my-consumer-group-1291687778 to finished
2022-04-05 00:42:00 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-consumer-source-my-consumer-group-1333712203 to finished
2022-04-05 00:42:05 [main] [32mINFO [m [MirrorMaker2IsolatedST:1098] Send 100 messages to Source cluster.
2022-04-05 00:42:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-producer-source-my-consumer-group-1291687778 in namespace namespace-120
2022-04-05 00:42:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-05 00:42:05 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-producer-source-my-consumer-group-1291687778 will be in active state
2022-04-05 00:42:06 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-producer-source-my-consumer-group-1291687778 to finished
2022-04-05 00:42:14 [main] [32mINFO [m [MirrorMaker2IsolatedST:1105] Wait 1 second as 'sync.group.offsets.interval.seconds=1'. As this is insignificant wait, we're skipping it
2022-04-05 00:42:14 [main] [32mINFO [m [MirrorMaker2IsolatedST:1107] Receive 100 messages from mirrored topic on Target cluster.
2022-04-05 00:42:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-consumer-target-my-consumer-group-1265139273 in namespace namespace-120
2022-04-05 00:42:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-05 00:42:14 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-consumer-target-my-consumer-group-1265139273 will be in active state
2022-04-05 00:42:15 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-consumer-target-my-consumer-group-1265139273 to finished
2022-04-05 00:42:26 [main] [32mINFO [m [MirrorMaker2IsolatedST:1112] Send 50 messages to Source cluster
2022-04-05 00:42:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-producer-source-my-consumer-group-1291687778 in namespace namespace-120
2022-04-05 00:42:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-05 00:42:26 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-producer-source-my-consumer-group-1291687778 will be in active state
2022-04-05 00:42:27 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-producer-source-my-consumer-group-1291687778 to finished
2022-04-05 00:42:35 [main] [32mINFO [m [MirrorMaker2IsolatedST:1118] Wait 1 second as 'sync.group.offsets.interval.seconds=1'. As this is insignificant wait, we're skipping it
2022-04-05 00:42:35 [main] [32mINFO [m [MirrorMaker2IsolatedST:1119] Receive 10 msgs from source cluster
2022-04-05 00:42:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-consumer-source-my-consumer-group-1333712203 in namespace namespace-120
2022-04-05 00:42:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-05 00:42:35 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-consumer-source-my-consumer-group-1333712203 will be in active state
2022-04-05 00:42:36 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-consumer-source-my-consumer-group-1333712203 to finished
2022-04-05 00:42:48 [main] [32mINFO [m [MirrorMaker2IsolatedST:1125] Wait 1 second as 'sync.group.offsets.interval.seconds=1'. As this is insignificant wait, we're skipping it
2022-04-05 00:42:48 [main] [32mINFO [m [MirrorMaker2IsolatedST:1127] Receive 40 msgs from mirrored topic on Target cluster
2022-04-05 00:42:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-consumer-target-my-consumer-group-1265139273 in namespace namespace-120
2022-04-05 00:42:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-05 00:42:48 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-consumer-target-my-consumer-group-1265139273 will be in active state
2022-04-05 00:42:49 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-consumer-target-my-consumer-group-1265139273 to finished
2022-04-05 00:43:10 [main] [32mINFO [m [MirrorMaker2IsolatedST:1133] There should be no more messages to read. Try to consume at least 1 message. This client job should fail on timeout.
2022-04-05 00:43:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-consumer-target-my-consumer-group-1265139273 in namespace namespace-120
2022-04-05 00:43:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-05 00:43:10 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-consumer-target-my-consumer-group-1265139273 will be in active state
2022-04-05 00:43:11 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:mm2-consumer-target-my-consumer-group-1265139273 to finish with failure.
2022-04-05 00:45:12 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
io.strimzi.test.WaitException: Timeout after 121000 ms waiting for Job did not finish within time limit (as expected).
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientTimeout(ClientUtils.java:91)
	at io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.lambda$testRestoreOffsetsInConsumerGroup$13(MirrorMaker2IsolatedST.java:1137)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:50)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:37)
	at org.junit.jupiter.api.Assertions.assertDoesNotThrow(Assertions.java:3135)
	at io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testRestoreOffsetsInConsumerGroup(MirrorMaker2IsolatedST.java:1137)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-05 00:45:12 [main] [32mINFO [m [ClientUtils:100] Client job 'mm2-consumer-target-my-consumer-group-1265139273' finished with expected timeout.
2022-04-05 00:45:12 [main] [32mINFO [m [MirrorMaker2IsolatedST:1139] As it's Active-Active MM2 mode, there should be no more messages to read from Source cluster topic. This client job should fail on timeout.
2022-04-05 00:45:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-consumer-source-my-consumer-group-1333712203 in namespace namespace-120
2022-04-05 00:45:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-05 00:45:12 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-consumer-source-my-consumer-group-1333712203 will be in active state
2022-04-05 00:45:13 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:mm2-consumer-source-my-consumer-group-1333712203 to finish with failure.
2022-04-05 00:47:14 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
io.strimzi.test.WaitException: Timeout after 121000 ms waiting for Job did not finish within time limit (as expected).
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientTimeout(ClientUtils.java:91)
	at io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.lambda$testRestoreOffsetsInConsumerGroup$14(MirrorMaker2IsolatedST.java:1143)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:50)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:37)
	at org.junit.jupiter.api.Assertions.assertDoesNotThrow(Assertions.java:3135)
	at io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testRestoreOffsetsInConsumerGroup(MirrorMaker2IsolatedST.java:1143)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-05 00:47:14 [main] [32mINFO [m [ClientUtils:100] Client job 'mm2-consumer-source-my-consumer-group-1333712203' finished with expected timeout.
2022-04-05 00:47:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:47:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRestoreOffsetsInConsumerGroup
2022-04-05 00:47:14 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job mm2-producer-source-my-consumer-group-1291687778 in namespace namespace-120
2022-04-05 00:47:14 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-9e54eecf-target in namespace namespace-120
2022-04-05 00:47:14 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job mm2-consumer-target-my-consumer-group-1265139273 in namespace namespace-120
2022-04-05 00:47:14 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job mm2-consumer-target-my-consumer-group-1265139273 in namespace namespace-120
2022-04-05 00:47:14 [main] [32mINFO [m [ResourceManager:241] Delete of Job mm2-consumer-target-my-consumer-group-1265139273 in namespace namespace-120
2022-04-05 00:47:14 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic test-sync-offset-1317640555 in namespace namespace-120
2022-04-05 00:47:14 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-9e54eecf-source in namespace namespace-120
2022-04-05 00:47:14 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job mm2-consumer-source-my-consumer-group-1333712203 in namespace namespace-120
2022-04-05 00:47:14 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Job mm2-producer-source-my-consumer-group-1291687778 in namespace namespace-120
2022-04-05 00:47:14 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job mm2-producer-source-my-consumer-group-1291687778 in namespace namespace-120
2022-04-05 00:47:14 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job mm2-consumer-source-my-consumer-group-1333712203 in namespace namespace-120
2022-04-05 00:47:14 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-9e54eecf-trg-src in namespace namespace-120
2022-04-05 00:47:14 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Job mm2-consumer-source-my-consumer-group-1333712203 in namespace namespace-120
2022-04-05 00:47:14 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-9e54eecf-src-trg in namespace namespace-120
2022-04-05 00:47:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 00:47:34 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-120 for test case:testRestoreOffsetsInConsumerGroup
2022-04-05 00:47:45 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testRestoreOffsetsInConsumerGroup-FINISHED
2022-04-05 00:47:45 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 00:47:45 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 00:47:45 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2-STARTED
2022-04-05 00:47:45 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 00:47:45 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-121 for test case:testMirrorMaker2
2022-04-05 00:47:45 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-121
2022-04-05 00:47:45 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-121
2022-04-05 00:47:45 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-121
2022-04-05 00:47:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-8007d8c2-source in namespace namespace-121
2022-04-05 00:47:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-121
2022-04-05 00:47:45 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8007d8c2-source will have desired state: Ready
2022-04-05 00:48:53 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8007d8c2-source is in desired state: Ready
2022-04-05 00:48:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-8007d8c2-target in namespace namespace-121
2022-04-05 00:48:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-121
2022-04-05 00:48:53 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8007d8c2-target will have desired state: Ready
2022-04-05 00:49:55 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8007d8c2-target is in desired state: Ready
2022-04-05 00:49:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-498126123 in namespace namespace-121
2022-04-05 00:49:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-121
2022-04-05 00:49:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-498126123 will have desired state: Ready
2022-04-05 00:49:56 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-498126123 is in desired state: Ready
2022-04-05 00:49:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-8007d8c2-kafka-clients in namespace namespace-121
2022-04-05 00:49:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-121
2022-04-05 00:50:06 [main] [32mINFO [m [MirrorMaker2IsolatedST:155] Sending messages to - topic availability-topic-source-my-topic-316288461-894314356, cluster my-cluster-8007d8c2-source and message count of 100
2022-04-05 00:50:06 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5197c3d7, messages=[], arguments=[--topic, availability-topic-source-my-topic-316288461-894314356, --max-messages, 100, --bootstrap-server, my-cluster-8007d8c2-source-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-8007d8c2-kafka-clients-d476c77b7-x5lnc', podNamespace='namespace-121', bootstrapServer='my-cluster-8007d8c2-source-kafka-bootstrap.namespace-121.svc:9092', topicName='availability-topic-source-my-topic-316288461-894314356', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4b96b644}
2022-04-05 00:50:06 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-8007d8c2-source-kafka-bootstrap.namespace-121.svc:9092:availability-topic-source-my-topic-316288461-894314356 from pod my-cluster-8007d8c2-kafka-clients-d476c77b7-x5lnc
2022-04-05 00:50:06 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-8007d8c2-kafka-clients-d476c77b7-x5lnc -n namespace-121 -- /opt/kafka/producer.sh --topic availability-topic-source-my-topic-316288461-894314356 --max-messages 100 --bootstrap-server my-cluster-8007d8c2-source-kafka-bootstrap.namespace-121.svc:9092
2022-04-05 00:50:08 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 00:50:08 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 00:50:08 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@32be866, messages=[], arguments=[--topic, availability-topic-source-my-topic-316288461-894314356, --max-messages, 100, --group-instance-id, instance511713681, --group-id, my-consumer-group-1569435135, --bootstrap-server, my-cluster-8007d8c2-source-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-8007d8c2-kafka-clients-d476c77b7-x5lnc', podNamespace='namespace-121', bootstrapServer='my-cluster-8007d8c2-source-kafka-bootstrap.namespace-121.svc:9092', topicName='availability-topic-source-my-topic-316288461-894314356', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1569435135', consumerInstanceId='instance511713681', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7df1450a}
2022-04-05 00:50:08 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-8007d8c2-source-kafka-bootstrap.namespace-121.svc:9092#availability-topic-source-my-topic-316288461-894314356 from pod my-cluster-8007d8c2-kafka-clients-d476c77b7-x5lnc
2022-04-05 00:50:08 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-8007d8c2-kafka-clients-d476c77b7-x5lnc -n namespace-121 -- /opt/kafka/consumer.sh --topic availability-topic-source-my-topic-316288461-894314356 --max-messages 100 --group-instance-id instance511713681 --group-id my-consumer-group-1569435135 --bootstrap-server my-cluster-8007d8c2-source-kafka-bootstrap.namespace-121.svc:9092
2022-04-05 00:50:14 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 00:50:14 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 00:50:14 [main] [32mINFO [m [MirrorMaker2IsolatedST:160] Setting topic to availability-topic-target-my-topic-316288461-894314356, cluster to my-cluster-8007d8c2-target and changing consumer group
2022-04-05 00:50:14 [main] [32mINFO [m [MirrorMaker2IsolatedST:168] Sending messages to - topic availability-topic-target-my-topic-316288461-894314356, cluster my-cluster-8007d8c2-target and message count of 100
2022-04-05 00:50:14 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@4610c328, messages=[], arguments=[--topic, availability-topic-target-my-topic-316288461-894314356, --max-messages, 100, --bootstrap-server, my-cluster-8007d8c2-target-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-8007d8c2-kafka-clients-d476c77b7-x5lnc', podNamespace='namespace-121', bootstrapServer='my-cluster-8007d8c2-target-kafka-bootstrap.namespace-121.svc:9092', topicName='availability-topic-target-my-topic-316288461-894314356', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6c4d1aaf}
2022-04-05 00:50:14 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-8007d8c2-target-kafka-bootstrap.namespace-121.svc:9092:availability-topic-target-my-topic-316288461-894314356 from pod my-cluster-8007d8c2-kafka-clients-d476c77b7-x5lnc
2022-04-05 00:50:14 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-8007d8c2-kafka-clients-d476c77b7-x5lnc -n namespace-121 -- /opt/kafka/producer.sh --topic availability-topic-target-my-topic-316288461-894314356 --max-messages 100 --bootstrap-server my-cluster-8007d8c2-target-kafka-bootstrap.namespace-121.svc:9092
2022-04-05 00:50:16 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 00:50:16 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 00:50:16 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6d8ab17c, messages=[], arguments=[--topic, availability-topic-target-my-topic-316288461-894314356, --max-messages, 100, --group-instance-id, instance692757915, --group-id, my-consumer-group-217105522, --bootstrap-server, my-cluster-8007d8c2-target-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-8007d8c2-kafka-clients-d476c77b7-x5lnc', podNamespace='namespace-121', bootstrapServer='my-cluster-8007d8c2-target-kafka-bootstrap.namespace-121.svc:9092', topicName='availability-topic-target-my-topic-316288461-894314356', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-217105522', consumerInstanceId='instance692757915', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@31be17f5}
2022-04-05 00:50:16 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-8007d8c2-target-kafka-bootstrap.namespace-121.svc:9092#availability-topic-target-my-topic-316288461-894314356 from pod my-cluster-8007d8c2-kafka-clients-d476c77b7-x5lnc
2022-04-05 00:50:16 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-8007d8c2-kafka-clients-d476c77b7-x5lnc -n namespace-121 -- /opt/kafka/consumer.sh --topic availability-topic-target-my-topic-316288461-894314356 --max-messages 100 --group-instance-id instance692757915 --group-id my-consumer-group-217105522 --bootstrap-server my-cluster-8007d8c2-target-kafka-bootstrap.namespace-121.svc:9092
2022-04-05 00:50:22 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 00:50:22 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 00:50:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-8007d8c2 in namespace namespace-121
2022-04-05 00:50:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-121
2022-04-05 00:50:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-8007d8c2 will have desired state: Ready
2022-04-05 00:51:35 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-8007d8c2 is in desired state: Ready
2022-04-05 00:51:35 [main] [32mINFO [m [MirrorMaker2IsolatedST:183] Looks like the mirrormaker2 cluster my-cluster deployed OK
2022-04-05 00:51:35 [main] [32mINFO [m [MirrorMaker2IsolatedST:640] Verifying docker image names
2022-04-05 00:51:35 [main] [32mINFO [m [AbstractST:172] strimzi-cluster-operator
2022-04-05 00:51:35 [main] [32mINFO [m [MirrorMaker2IsolatedST:653] Docker images verified
2022-04-05 00:51:35 [main] [32mINFO [m [AbstractST:311] Verifying labels on pod type mirrormaker2
2022-04-05 00:51:35 [main] [32mINFO [m [AbstractST:315] Verifying labels for pod: my-cluster-8007d8c2-mirrormaker2-6749b66776-5tlhd
2022-04-05 00:51:35 [main] [32mINFO [m [AbstractST:356] Verifying labels for Kafka Connect Services
2022-04-05 00:51:35 [main] [32mINFO [m [AbstractST:362] Verifying labels for service my-cluster-8007d8c2-mirrormaker2-api
2022-04-05 00:51:35 [main] [32mINFO [m [AbstractST:384] Verifying labels for Config maps
2022-04-05 00:51:35 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-8007d8c2-mirrormaker2-config
2022-04-05 00:51:35 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-8007d8c2-source-entity-topic-operator-config
2022-04-05 00:51:35 [main] [32mINFO [m [AbstractST:407] CM my-cluster-8007d8c2-source-entity-topic-operator-config is not related to current test
2022-04-05 00:51:35 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-8007d8c2-source-entity-user-operator-config
2022-04-05 00:51:35 [main] [32mINFO [m [AbstractST:407] CM my-cluster-8007d8c2-source-entity-user-operator-config is not related to current test
2022-04-05 00:51:35 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-8007d8c2-source-kafka-config
2022-04-05 00:51:35 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-8007d8c2-source-zookeeper-config
2022-04-05 00:51:35 [main] [32mINFO [m [AbstractST:407] CM my-cluster-8007d8c2-source-zookeeper-config is not related to current test
2022-04-05 00:51:35 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-8007d8c2-target-entity-topic-operator-config
2022-04-05 00:51:35 [main] [32mINFO [m [AbstractST:407] CM my-cluster-8007d8c2-target-entity-topic-operator-config is not related to current test
2022-04-05 00:51:35 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-8007d8c2-target-entity-user-operator-config
2022-04-05 00:51:35 [main] [32mINFO [m [AbstractST:407] CM my-cluster-8007d8c2-target-entity-user-operator-config is not related to current test
2022-04-05 00:51:35 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-8007d8c2-target-kafka-config
2022-04-05 00:51:35 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-8007d8c2-target-zookeeper-config
2022-04-05 00:51:35 [main] [32mINFO [m [AbstractST:407] CM my-cluster-8007d8c2-target-zookeeper-config is not related to current test
2022-04-05 00:51:35 [main] [32mINFO [m [AbstractST:414] Verifying labels for Service Accounts
2022-04-05 00:51:35 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-8007d8c2-source-entity-operator
2022-04-05 00:51:35 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-8007d8c2-source-kafka
2022-04-05 00:51:35 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-8007d8c2-source-zookeeper
2022-04-05 00:51:35 [main] [32mINFO [m [MirrorMaker2IsolatedST:198] Setting topic to mirrormaker2-topic-example-498126123, cluster to my-cluster-8007d8c2-source and changing consumer group
2022-04-05 00:51:35 [main] [32mINFO [m [MirrorMaker2IsolatedST:206] Sending messages to - topic mirrormaker2-topic-example-498126123, cluster my-cluster-8007d8c2-source and message count of 100
2022-04-05 00:51:35 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@58b59f3a, messages=[], arguments=[--topic, mirrormaker2-topic-example-498126123, --max-messages, 100, --bootstrap-server, my-cluster-8007d8c2-source-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-8007d8c2-kafka-clients-d476c77b7-x5lnc', podNamespace='namespace-121', bootstrapServer='my-cluster-8007d8c2-source-kafka-bootstrap.namespace-121.svc:9092', topicName='mirrormaker2-topic-example-498126123', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@138530d8}
2022-04-05 00:51:35 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-8007d8c2-source-kafka-bootstrap.namespace-121.svc:9092:mirrormaker2-topic-example-498126123 from pod my-cluster-8007d8c2-kafka-clients-d476c77b7-x5lnc
2022-04-05 00:51:35 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-8007d8c2-kafka-clients-d476c77b7-x5lnc -n namespace-121 -- /opt/kafka/producer.sh --topic mirrormaker2-topic-example-498126123 --max-messages 100 --bootstrap-server my-cluster-8007d8c2-source-kafka-bootstrap.namespace-121.svc:9092
2022-04-05 00:51:38 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 00:51:38 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 00:51:38 [main] [32mINFO [m [MirrorMaker2IsolatedST:210] Consumer in source cluster and topic should receive 100 messages
2022-04-05 00:51:38 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6d1d62b3, messages=[], arguments=[--topic, mirrormaker2-topic-example-498126123, --max-messages, 100, --group-instance-id, instance1974141710, --group-id, my-consumer-group-1185551956, --bootstrap-server, my-cluster-8007d8c2-source-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-8007d8c2-kafka-clients-d476c77b7-x5lnc', podNamespace='namespace-121', bootstrapServer='my-cluster-8007d8c2-source-kafka-bootstrap.namespace-121.svc:9092', topicName='mirrormaker2-topic-example-498126123', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1185551956', consumerInstanceId='instance1974141710', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@19a562f2}
2022-04-05 00:51:38 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-8007d8c2-source-kafka-bootstrap.namespace-121.svc:9092#mirrormaker2-topic-example-498126123 from pod my-cluster-8007d8c2-kafka-clients-d476c77b7-x5lnc
2022-04-05 00:51:38 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-8007d8c2-kafka-clients-d476c77b7-x5lnc -n namespace-121 -- /opt/kafka/consumer.sh --topic mirrormaker2-topic-example-498126123 --max-messages 100 --group-instance-id instance1974141710 --group-id my-consumer-group-1185551956 --bootstrap-server my-cluster-8007d8c2-source-kafka-bootstrap.namespace-121.svc:9092
2022-04-05 00:51:43 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 00:51:43 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 00:51:43 [main] [32mINFO [m [MirrorMaker2IsolatedST:214] Now setting topic to my-cluster-8007d8c2-source.mirrormaker2-topic-example-498126123 and cluster to my-cluster-8007d8c2-target - the messages should be mirrored
2022-04-05 00:51:43 [main] [32mINFO [m [MirrorMaker2IsolatedST:222] Consumer in target cluster and topic should receive 100 messages
2022-04-05 00:51:43 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6f39a437, messages=[], arguments=[--topic, my-cluster-8007d8c2-source.mirrormaker2-topic-example-498126123, --max-messages, 100, --group-instance-id, instance1135623376, --group-id, my-consumer-group-1807962865, --bootstrap-server, my-cluster-8007d8c2-target-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-8007d8c2-kafka-clients-d476c77b7-x5lnc', podNamespace='namespace-121', bootstrapServer='my-cluster-8007d8c2-target-kafka-bootstrap.namespace-121.svc:9092', topicName='my-cluster-8007d8c2-source.mirrormaker2-topic-example-498126123', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1807962865', consumerInstanceId='instance1135623376', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@284fcdca}
2022-04-05 00:51:43 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-8007d8c2-target-kafka-bootstrap.namespace-121.svc:9092#my-cluster-8007d8c2-source.mirrormaker2-topic-example-498126123 from pod my-cluster-8007d8c2-kafka-clients-d476c77b7-x5lnc
2022-04-05 00:51:43 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-8007d8c2-kafka-clients-d476c77b7-x5lnc -n namespace-121 -- /opt/kafka/consumer.sh --topic my-cluster-8007d8c2-source.mirrormaker2-topic-example-498126123 --max-messages 100 --group-instance-id instance1135623376 --group-id my-consumer-group-1807962865 --bootstrap-server my-cluster-8007d8c2-target-kafka-bootstrap.namespace-121.svc:9092
2022-04-05 00:51:49 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 00:51:49 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 00:51:49 [main] [32mINFO [m [MirrorMaker2IsolatedST:227] Changing topic to my-cluster-8007d8c2-source.availability-topic-source-my-topic-316288461-894314356
2022-04-05 00:51:49 [main] [32mINFO [m [MirrorMaker2IsolatedST:233] Check if mm2 mirror automatically created topic
2022-04-05 00:51:49 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5bb7102e, messages=[], arguments=[--topic, my-cluster-8007d8c2-source.availability-topic-source-my-topic-316288461-894314356, --max-messages, 100, --group-instance-id, instance1654582823, --group-id, my-consumer-group-573236261, --bootstrap-server, my-cluster-8007d8c2-target-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-8007d8c2-kafka-clients-d476c77b7-x5lnc', podNamespace='namespace-121', bootstrapServer='my-cluster-8007d8c2-target-kafka-bootstrap.namespace-121.svc:9092', topicName='my-cluster-8007d8c2-source.availability-topic-source-my-topic-316288461-894314356', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-573236261', consumerInstanceId='instance1654582823', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5db9f9d0}
2022-04-05 00:51:49 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-8007d8c2-target-kafka-bootstrap.namespace-121.svc:9092#my-cluster-8007d8c2-source.availability-topic-source-my-topic-316288461-894314356 from pod my-cluster-8007d8c2-kafka-clients-d476c77b7-x5lnc
2022-04-05 00:51:49 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-8007d8c2-kafka-clients-d476c77b7-x5lnc -n namespace-121 -- /opt/kafka/consumer.sh --topic my-cluster-8007d8c2-source.availability-topic-source-my-topic-316288461-894314356 --max-messages 100 --group-instance-id instance1654582823 --group-id my-consumer-group-573236261 --bootstrap-server my-cluster-8007d8c2-target-kafka-bootstrap.namespace-121.svc:9092
2022-04-05 00:51:55 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 00:51:55 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 00:51:55 [main] [32mINFO [m [MirrorMaker2IsolatedST:236] Mirrored successful
2022-04-05 00:51:55 [main] [32mINFO [m [KafkaTopicUtils:124] Waiting for KafkaTopic change my-cluster-8007d8c2-source.mirrormaker2-topic-example-498126123
2022-04-05 00:52:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:52:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker2
2022-04-05 00:52:36 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-498126123 in namespace namespace-121
2022-04-05 00:52:36 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-8007d8c2 in namespace namespace-121
2022-04-05 00:52:36 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-8007d8c2-kafka-clients in namespace namespace-121
2022-04-05 00:52:36 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-8007d8c2-source in namespace namespace-121
2022-04-05 00:52:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-8007d8c2-target in namespace namespace-121
2022-04-05 00:53:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 00:53:26 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-121 for test case:testMirrorMaker2
2022-04-05 00:53:31 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2-FINISHED
2022-04-05 00:53:31 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 00:53:31 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 00:53:31 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testKafkaMirrorMaker2ReflectsConnectorsState-STARTED
2022-04-05 00:53:31 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 00:53:31 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-122 for test case:testKafkaMirrorMaker2ReflectsConnectorsState
2022-04-05 00:53:31 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-122
2022-04-05 00:53:31 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-122
2022-04-05 00:53:31 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-122
2022-04-05 00:53:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3a4eda22-source in namespace namespace-122
2022-04-05 00:53:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-122
2022-04-05 00:53:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3a4eda22-target in namespace namespace-122
2022-04-05 00:53:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-122
2022-04-05 00:53:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3a4eda22-source will have desired state: Ready
2022-04-05 00:54:46 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3a4eda22-source is in desired state: Ready
2022-04-05 00:54:46 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3a4eda22-target will have desired state: Ready
2022-04-05 00:54:46 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3a4eda22-target is in desired state: Ready
2022-04-05 00:54:46 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-3a4eda22 in namespace namespace-122
2022-04-05 00:54:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-122
2022-04-05 00:54:46 [main] [32mINFO [m [ResourceManager:481] Wait for KafkaMirrorMaker2: my-cluster-3a4eda22 will contain desired status message: One or more connectors are in FAILED state
2022-04-05 00:56:05 [main] [32mINFO [m [ResourceManager:492] KafkaMirrorMaker2: my-cluster-3a4eda22 contains desired message in status: One or more connectors are in FAILED state
2022-04-05 00:56:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-3a4eda22 will have desired state: Ready
2022-04-05 00:56:06 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-3a4eda22 is in desired state: Ready
2022-04-05 00:56:06 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:56:06 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaMirrorMaker2ReflectsConnectorsState
2022-04-05 00:56:06 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3a4eda22-target in namespace namespace-122
2022-04-05 00:56:06 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3a4eda22-source in namespace namespace-122
2022-04-05 00:56:06 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-3a4eda22 in namespace namespace-122
2022-04-05 00:56:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 00:56:26 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-122 for test case:testKafkaMirrorMaker2ReflectsConnectorsState
2022-04-05 00:56:31 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testKafkaMirrorMaker2ReflectsConnectorsState-FINISHED
2022-04-05 00:56:31 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 00:56:31 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 00:56:31 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testKMM2RollAfterSecretsCertsUpdateTLS-STARTED
2022-04-05 00:56:31 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 00:56:31 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-123 for test case:testKMM2RollAfterSecretsCertsUpdateTLS
2022-04-05 00:56:31 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-123
2022-04-05 00:56:31 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-123
2022-04-05 00:56:31 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-123
2022-04-05 00:56:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-f076fe03-source in namespace namespace-123
2022-04-05 00:56:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-05 00:56:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f076fe03-source will have desired state: Ready
2022-04-05 00:57:42 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f076fe03-source is in desired state: Ready
2022-04-05 00:57:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-f076fe03-target in namespace namespace-123
2022-04-05 00:57:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-05 00:57:42 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f076fe03-target will have desired state: Ready
2022-04-05 00:59:08 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f076fe03-target is in desired state: Ready
2022-04-05 00:59:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-a-451339654 in namespace namespace-123
2022-04-05 00:59:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-05 00:59:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-a-451339654 will have desired state: Ready
2022-04-05 00:59:09 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-a-451339654 is in desired state: Ready
2022-04-05 00:59:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-b-21948576 in namespace namespace-123
2022-04-05 00:59:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-05 00:59:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-b-21948576 will have desired state: Ready
2022-04-05 00:59:10 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-b-21948576 is in desired state: Ready
2022-04-05 00:59:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-f076fe03-my-user-source in namespace namespace-123
2022-04-05 00:59:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-05 00:59:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-f076fe03-my-user-source will have desired state: Ready
2022-04-05 00:59:11 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-f076fe03-my-user-source is in desired state: Ready
2022-04-05 00:59:11 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-f076fe03-my-user-target in namespace namespace-123
2022-04-05 00:59:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-05 00:59:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-f076fe03-my-user-target will have desired state: Ready
2022-04-05 00:59:12 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-f076fe03-my-user-target is in desired state: Ready
2022-04-05 00:59:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-6c9173cb-kafka-clients in namespace namespace-123
2022-04-05 00:59:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-05 00:59:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-961900870-1999067505-test-1 in namespace namespace-123
2022-04-05 00:59:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-05 00:59:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-961900870-1999067505-test-1 will have desired state: Ready
2022-04-05 00:59:23 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-961900870-1999067505-test-1 is in desired state: Ready
2022-04-05 00:59:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-961900870-1999067505-test-2 in namespace namespace-123
2022-04-05 00:59:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-05 00:59:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-961900870-1999067505-test-2 will have desired state: Ready
2022-04-05 00:59:24 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-961900870-1999067505-test-2 is in desired state: Ready
2022-04-05 00:59:24 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 00:59:24 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1d3c4a91, messages=[], arguments=[--topic, my-topic-961900870-1999067505-test-2, --max-messages, 200, USER=my_cluster_f076fe03_my_user_target, --bootstrap-server, my-cluster-f076fe03-target-kafka-bootstrap.namespace-123.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-6c9173cb-kafka-clients-84db5b57bc-4lcpx', podNamespace='namespace-123', bootstrapServer='my-cluster-f076fe03-target-kafka-bootstrap.namespace-123.svc:9093', topicName='my-topic-961900870-1999067505-test-2', maxMessages=200, kafkaUsername='my-cluster-f076fe03-my-user-target', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5a54c934}
2022-04-05 00:59:24 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-f076fe03-target-kafka-bootstrap.namespace-123.svc:9093:my-topic-961900870-1999067505-test-2 from pod my-cluster-6c9173cb-kafka-clients-84db5b57bc-4lcpx
2022-04-05 00:59:24 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-6c9173cb-kafka-clients-84db5b57bc-4lcpx -n namespace-123 -- /opt/kafka/producer.sh --topic my-topic-961900870-1999067505-test-2 --max-messages 200 USER=my_cluster_f076fe03_my_user_target --bootstrap-server my-cluster-f076fe03-target-kafka-bootstrap.namespace-123.svc:9093
2022-04-05 00:59:28 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 00:59:28 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 00:59:28 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@93c089a, messages=[], arguments=[--topic, my-topic-961900870-1999067505-test-2, --max-messages, 200, --group-instance-id, instance108643039, USER=my_cluster_f076fe03_my_user_target, --group-id, my-consumer-group-1438398559, --bootstrap-server, my-cluster-f076fe03-target-kafka-bootstrap.namespace-123.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-6c9173cb-kafka-clients-84db5b57bc-4lcpx', podNamespace='namespace-123', bootstrapServer='my-cluster-f076fe03-target-kafka-bootstrap.namespace-123.svc:9093', topicName='my-topic-961900870-1999067505-test-2', maxMessages=200, kafkaUsername='my-cluster-f076fe03-my-user-target', consumerGroupName='my-consumer-group-1438398559', consumerInstanceId='instance108643039', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@755d626c}
2022-04-05 00:59:28 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-f076fe03-target-kafka-bootstrap.namespace-123.svc:9093:my-topic-961900870-1999067505-test-2 from pod my-cluster-6c9173cb-kafka-clients-84db5b57bc-4lcpx
2022-04-05 00:59:28 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-6c9173cb-kafka-clients-84db5b57bc-4lcpx -n namespace-123 -- /opt/kafka/consumer.sh --topic my-topic-961900870-1999067505-test-2 --max-messages 200 --group-instance-id instance108643039 USER=my_cluster_f076fe03_my_user_target --group-id my-consumer-group-1438398559 --bootstrap-server my-cluster-f076fe03-target-kafka-bootstrap.namespace-123.svc:9093
2022-04-05 00:59:35 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 00:59:35 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 00:59:35 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-f076fe03 in namespace namespace-123
2022-04-05 00:59:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-05 00:59:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-f076fe03 will have desired state: Ready
2022-04-05 01:00:40 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-f076fe03 is in desired state: Ready
2022-04-05 01:00:40 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5d582c34, messages=[], arguments=[--topic, mirrormaker2-topic-example-a-451339654, --max-messages, 200, USER=my_cluster_f076fe03_my_user_source, --bootstrap-server, my-cluster-f076fe03-source-kafka-bootstrap.namespace-123.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-6c9173cb-kafka-clients-84db5b57bc-4lcpx', podNamespace='namespace-123', bootstrapServer='my-cluster-f076fe03-source-kafka-bootstrap.namespace-123.svc:9093', topicName='mirrormaker2-topic-example-a-451339654', maxMessages=200, kafkaUsername='my-cluster-f076fe03-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@689c6ea0}
2022-04-05 01:00:40 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-f076fe03-source-kafka-bootstrap.namespace-123.svc:9093:mirrormaker2-topic-example-a-451339654 from pod my-cluster-6c9173cb-kafka-clients-84db5b57bc-4lcpx
2022-04-05 01:00:40 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-6c9173cb-kafka-clients-84db5b57bc-4lcpx -n namespace-123 -- /opt/kafka/producer.sh --topic mirrormaker2-topic-example-a-451339654 --max-messages 200 USER=my_cluster_f076fe03_my_user_source --bootstrap-server my-cluster-f076fe03-source-kafka-bootstrap.namespace-123.svc:9093
2022-04-05 01:00:43 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 01:00:43 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 01:00:43 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@71dcf2bf, messages=[], arguments=[--topic, mirrormaker2-topic-example-a-451339654, --max-messages, 200, --group-instance-id, instance14096070, USER=my_cluster_f076fe03_my_user_source, --group-id, my-consumer-group-1438398559, --bootstrap-server, my-cluster-f076fe03-source-kafka-bootstrap.namespace-123.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-6c9173cb-kafka-clients-84db5b57bc-4lcpx', podNamespace='namespace-123', bootstrapServer='my-cluster-f076fe03-source-kafka-bootstrap.namespace-123.svc:9093', topicName='mirrormaker2-topic-example-a-451339654', maxMessages=200, kafkaUsername='my-cluster-f076fe03-my-user-source', consumerGroupName='my-consumer-group-1438398559', consumerInstanceId='instance14096070', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7abe6a26}
2022-04-05 01:00:43 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-f076fe03-source-kafka-bootstrap.namespace-123.svc:9093:mirrormaker2-topic-example-a-451339654 from pod my-cluster-6c9173cb-kafka-clients-84db5b57bc-4lcpx
2022-04-05 01:00:43 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-6c9173cb-kafka-clients-84db5b57bc-4lcpx -n namespace-123 -- /opt/kafka/consumer.sh --topic mirrormaker2-topic-example-a-451339654 --max-messages 200 --group-instance-id instance14096070 USER=my_cluster_f076fe03_my_user_source --group-id my-consumer-group-1438398559 --bootstrap-server my-cluster-f076fe03-source-kafka-bootstrap.namespace-123.svc:9093
2022-04-05 01:00:50 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 01:00:50 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 01:00:50 [main] [32mINFO [m [MirrorMaker2IsolatedST:1551] Consumer in target cluster and topic should receive 200 messages
2022-04-05 01:00:50 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@57297a27, messages=[], arguments=[--topic, my-cluster-f076fe03-source.mirrormaker2-topic-example-a-451339654, --max-messages, 200, --group-instance-id, instance69584488, USER=my_cluster_f076fe03_my_user_target, --group-id, my-consumer-group-1438398559, --bootstrap-server, my-cluster-f076fe03-target-kafka-bootstrap.namespace-123.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-6c9173cb-kafka-clients-84db5b57bc-4lcpx', podNamespace='namespace-123', bootstrapServer='my-cluster-f076fe03-target-kafka-bootstrap.namespace-123.svc:9093', topicName='my-cluster-f076fe03-source.mirrormaker2-topic-example-a-451339654', maxMessages=200, kafkaUsername='my-cluster-f076fe03-my-user-target', consumerGroupName='my-consumer-group-1438398559', consumerInstanceId='instance69584488', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6df9493c}
2022-04-05 01:00:50 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-f076fe03-target-kafka-bootstrap.namespace-123.svc:9093:my-cluster-f076fe03-source.mirrormaker2-topic-example-a-451339654 from pod my-cluster-6c9173cb-kafka-clients-84db5b57bc-4lcpx
2022-04-05 01:00:50 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-6c9173cb-kafka-clients-84db5b57bc-4lcpx -n namespace-123 -- /opt/kafka/consumer.sh --topic my-cluster-f076fe03-source.mirrormaker2-topic-example-a-451339654 --max-messages 200 --group-instance-id instance69584488 USER=my_cluster_f076fe03_my_user_target --group-id my-consumer-group-1438398559 --bootstrap-server my-cluster-f076fe03-target-kafka-bootstrap.namespace-123.svc:9093
2022-04-05 01:00:57 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 01:00:57 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 01:00:57 [main] [32mINFO [m [MirrorMaker2IsolatedST:1553] Messages successfully mirrored
2022-04-05 01:00:57 [main] [32mINFO [m [MirrorMaker2IsolatedST:1567] Renew Clients CA secret for Source cluster via annotation
2022-04-05 01:00:57 [main] [32mINFO [m [SecretUtils:178] Annotating Secret:my-cluster-f076fe03-source-clients-ca-cert with annotation strimzi.io/force-renew=true
2022-04-05 01:00:57 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-f076fe03-source-kafka rolling update
2022-04-05 01:02:17 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-f076fe03-source-kafka has been successfully rolled
2022-04-05 01:02:17 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-f076fe03-source-kafka to be ready
2022-04-05 01:02:45 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-f076fe03-mirrormaker2 rolling update
2022-04-05 01:02:45 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f076fe03-mirrormaker2 will be ready
2022-04-05 01:02:45 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f076fe03-mirrormaker2 is ready
2022-04-05 01:02:55 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-f076fe03-mirrormaker2 rolling update finished
2022-04-05 01:02:55 [main] [32mINFO [m [MirrorMaker2IsolatedST:1573] Renew Clients CA secret for Target cluster via annotation
2022-04-05 01:02:55 [main] [32mINFO [m [SecretUtils:178] Annotating Secret:my-cluster-f076fe03-target-clients-ca-cert with annotation strimzi.io/force-renew=true
2022-04-05 01:02:55 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-f076fe03-target-kafka rolling update
2022-04-05 01:04:15 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-f076fe03-target-kafka has been successfully rolled
2022-04-05 01:04:15 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-f076fe03-target-kafka to be ready
2022-04-05 01:04:48 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-f076fe03-mirrormaker2 rolling update
2022-04-05 01:06:13 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f076fe03-mirrormaker2 will be ready
2022-04-05 01:06:13 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f076fe03-mirrormaker2 is ready
2022-04-05 01:06:23 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-f076fe03-mirrormaker2 rolling update finished
2022-04-05 01:06:23 [main] [32mINFO [m [MirrorMaker2IsolatedST:1579] Send and receive messages after clients certs were removed
2022-04-05 01:06:23 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3637d146, messages=[], arguments=[--topic, mirrormaker2-topic-example-a-451339654, --max-messages, 200, USER=my_cluster_f076fe03_my_user_source, --bootstrap-server, my-cluster-f076fe03-source-kafka-bootstrap.namespace-123.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-6c9173cb-kafka-clients-84db5b57bc-4lcpx', podNamespace='namespace-123', bootstrapServer='my-cluster-f076fe03-source-kafka-bootstrap.namespace-123.svc:9093', topicName='mirrormaker2-topic-example-a-451339654', maxMessages=200, kafkaUsername='my-cluster-f076fe03-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@54baa9be}
2022-04-05 01:06:23 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-f076fe03-source-kafka-bootstrap.namespace-123.svc:9093:mirrormaker2-topic-example-a-451339654 from pod my-cluster-6c9173cb-kafka-clients-84db5b57bc-4lcpx
2022-04-05 01:06:23 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-6c9173cb-kafka-clients-84db5b57bc-4lcpx -n namespace-123 -- /opt/kafka/producer.sh --topic mirrormaker2-topic-example-a-451339654 --max-messages 200 USER=my_cluster_f076fe03_my_user_source --bootstrap-server my-cluster-f076fe03-source-kafka-bootstrap.namespace-123.svc:9093
2022-04-05 01:06:27 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 01:06:27 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 01:06:27 [main] [32mINFO [m [MirrorMaker2IsolatedST:1595] Consumer in target cluster and topic should receive 200 messages
2022-04-05 01:06:27 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7841bbaa, messages=[], arguments=[--topic, my-cluster-f076fe03-source.mirrormaker2-topic-example-a-451339654, --max-messages, 200, --group-instance-id, instance1659107377, USER=my_cluster_f076fe03_my_user_target, --group-id, my-consumer-group-1038868174, --bootstrap-server, my-cluster-f076fe03-target-kafka-bootstrap.namespace-123.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-6c9173cb-kafka-clients-84db5b57bc-4lcpx', podNamespace='namespace-123', bootstrapServer='my-cluster-f076fe03-target-kafka-bootstrap.namespace-123.svc:9093', topicName='my-cluster-f076fe03-source.mirrormaker2-topic-example-a-451339654', maxMessages=200, kafkaUsername='my-cluster-f076fe03-my-user-target', consumerGroupName='my-consumer-group-1038868174', consumerInstanceId='instance1659107377', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@79371a6b}
2022-04-05 01:06:27 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-f076fe03-target-kafka-bootstrap.namespace-123.svc:9093:my-cluster-f076fe03-source.mirrormaker2-topic-example-a-451339654 from pod my-cluster-6c9173cb-kafka-clients-84db5b57bc-4lcpx
2022-04-05 01:06:27 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-6c9173cb-kafka-clients-84db5b57bc-4lcpx -n namespace-123 -- /opt/kafka/consumer.sh --topic my-cluster-f076fe03-source.mirrormaker2-topic-example-a-451339654 --max-messages 200 --group-instance-id instance1659107377 USER=my_cluster_f076fe03_my_user_target --group-id my-consumer-group-1038868174 --bootstrap-server my-cluster-f076fe03-target-kafka-bootstrap.namespace-123.svc:9093
2022-04-05 01:06:34 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 01:06:34 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 01:06:34 [main] [32mINFO [m [MirrorMaker2IsolatedST:1597] Messages successfully mirrored
2022-04-05 01:06:34 [main] [32mINFO [m [MirrorMaker2IsolatedST:1599] Renew Cluster CA secret for Source clusters via annotation
2022-04-05 01:06:34 [main] [32mINFO [m [SecretUtils:178] Annotating Secret:my-cluster-f076fe03-source-cluster-ca-cert with annotation strimzi.io/force-renew=true
2022-04-05 01:06:34 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-f076fe03-source-zookeeper rolling update
2022-04-05 01:08:14 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-f076fe03-source-zookeeper has been successfully rolled
2022-04-05 01:08:14 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-f076fe03-source-zookeeper to be ready
2022-04-05 01:08:45 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-f076fe03-source-kafka rolling update
2022-04-05 01:10:06 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-f076fe03-source-kafka has been successfully rolled
2022-04-05 01:10:06 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-f076fe03-source-kafka to be ready
2022-04-05 01:10:39 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-f076fe03-source-entity-operator rolling update
2022-04-05 01:10:39 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f076fe03-source-entity-operator will be ready
2022-04-05 01:11:23 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f076fe03-source-entity-operator is ready
2022-04-05 01:11:33 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-f076fe03-source-entity-operator rolling update finished
2022-04-05 01:11:33 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-f076fe03-mirrormaker2 rolling update
2022-04-05 01:11:33 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f076fe03-mirrormaker2 will be ready
2022-04-05 01:11:33 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f076fe03-mirrormaker2 is ready
2022-04-05 01:11:43 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-f076fe03-mirrormaker2 rolling update finished
2022-04-05 01:11:43 [main] [32mINFO [m [MirrorMaker2IsolatedST:1607] Renew Cluster CA secret for Target clusters via annotation
2022-04-05 01:11:43 [main] [32mINFO [m [SecretUtils:178] Annotating Secret:my-cluster-f076fe03-target-cluster-ca-cert with annotation strimzi.io/force-renew=true
2022-04-05 01:11:43 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-f076fe03-target-zookeeper rolling update
2022-04-05 01:13:28 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-f076fe03-target-zookeeper has been successfully rolled
2022-04-05 01:13:28 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-f076fe03-target-zookeeper to be ready
2022-04-05 01:13:54 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-f076fe03-target-kafka rolling update
2022-04-05 01:15:25 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-f076fe03-target-kafka has been successfully rolled
2022-04-05 01:15:25 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-f076fe03-target-kafka to be ready
2022-04-05 01:15:53 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-f076fe03-target-entity-operator rolling update
2022-04-05 01:16:18 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f076fe03-target-entity-operator will be ready
2022-04-05 01:16:47 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f076fe03-target-entity-operator is ready
2022-04-05 01:16:57 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-f076fe03-target-entity-operator rolling update finished
2022-04-05 01:16:57 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-f076fe03-mirrormaker2 rolling update
2022-04-05 01:16:57 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f076fe03-mirrormaker2 will be ready
2022-04-05 01:16:57 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f076fe03-mirrormaker2 is ready
2022-04-05 01:17:07 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-f076fe03-mirrormaker2 rolling update finished
2022-04-05 01:17:07 [main] [32mINFO [m [MirrorMaker2IsolatedST:1615] Send and receive messages after clients certs were removed
2022-04-05 01:17:07 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@35747e72, messages=[], arguments=[--topic, mirrormaker2-topic-example-b-21948576, --max-messages, 200, USER=my_cluster_f076fe03_my_user_source, --bootstrap-server, my-cluster-f076fe03-source-kafka-bootstrap.namespace-123.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-6c9173cb-kafka-clients-84db5b57bc-4lcpx', podNamespace='namespace-123', bootstrapServer='my-cluster-f076fe03-source-kafka-bootstrap.namespace-123.svc:9093', topicName='mirrormaker2-topic-example-b-21948576', maxMessages=200, kafkaUsername='my-cluster-f076fe03-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2a647e83}
2022-04-05 01:17:07 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-f076fe03-source-kafka-bootstrap.namespace-123.svc:9093:mirrormaker2-topic-example-b-21948576 from pod my-cluster-6c9173cb-kafka-clients-84db5b57bc-4lcpx
2022-04-05 01:17:07 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-6c9173cb-kafka-clients-84db5b57bc-4lcpx -n namespace-123 -- /opt/kafka/producer.sh --topic mirrormaker2-topic-example-b-21948576 --max-messages 200 USER=my_cluster_f076fe03_my_user_source --bootstrap-server my-cluster-f076fe03-source-kafka-bootstrap.namespace-123.svc:9093
2022-04-05 01:17:11 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 01:17:11 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 01:17:11 [main] [32mINFO [m [MirrorMaker2IsolatedST:1631] Consumer in target cluster and topic should receive 200 messages
2022-04-05 01:17:11 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1768de70, messages=[], arguments=[--topic, my-cluster-f076fe03-source.mirrormaker2-topic-example-b-21948576, --max-messages, 200, --group-instance-id, instance422988100, USER=my_cluster_f076fe03_my_user_target, --group-id, my-consumer-group-497580480, --bootstrap-server, my-cluster-f076fe03-target-kafka-bootstrap.namespace-123.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-6c9173cb-kafka-clients-84db5b57bc-4lcpx', podNamespace='namespace-123', bootstrapServer='my-cluster-f076fe03-target-kafka-bootstrap.namespace-123.svc:9093', topicName='my-cluster-f076fe03-source.mirrormaker2-topic-example-b-21948576', maxMessages=200, kafkaUsername='my-cluster-f076fe03-my-user-target', consumerGroupName='my-consumer-group-497580480', consumerInstanceId='instance422988100', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1e713b5b}
2022-04-05 01:17:11 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-f076fe03-target-kafka-bootstrap.namespace-123.svc:9093:my-cluster-f076fe03-source.mirrormaker2-topic-example-b-21948576 from pod my-cluster-6c9173cb-kafka-clients-84db5b57bc-4lcpx
2022-04-05 01:17:11 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-6c9173cb-kafka-clients-84db5b57bc-4lcpx -n namespace-123 -- /opt/kafka/consumer.sh --topic my-cluster-f076fe03-source.mirrormaker2-topic-example-b-21948576 --max-messages 200 --group-instance-id instance422988100 USER=my_cluster_f076fe03_my_user_target --group-id my-consumer-group-497580480 --bootstrap-server my-cluster-f076fe03-target-kafka-bootstrap.namespace-123.svc:9093
2022-04-05 01:17:17 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 01:17:17 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 01:17:17 [main] [32mINFO [m [MirrorMaker2IsolatedST:1633] Messages successfully mirrored
2022-04-05 01:17:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 01:17:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKMM2RollAfterSecretsCertsUpdateTLS
2022-04-05 01:17:17 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-f076fe03-my-user-target in namespace namespace-123
2022-04-05 01:17:17 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-6c9173cb-kafka-clients in namespace namespace-123
2022-04-05 01:17:17 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-f076fe03-target in namespace namespace-123
2022-04-05 01:17:17 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-961900870-1999067505-test-2 in namespace namespace-123
2022-04-05 01:17:17 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-961900870-1999067505-test-1 in namespace namespace-123
2022-04-05 01:17:17 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-a-451339654 in namespace namespace-123
2022-04-05 01:17:17 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-f076fe03-source in namespace namespace-123
2022-04-05 01:17:17 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-f076fe03-my-user-source in namespace namespace-123
2022-04-05 01:17:28 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-b-21948576 in namespace namespace-123
2022-04-05 01:17:28 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-f076fe03 in namespace namespace-123
2022-04-05 01:18:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 01:18:18 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-123 for test case:testKMM2RollAfterSecretsCertsUpdateTLS
2022-04-05 01:18:24 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testKMM2RollAfterSecretsCertsUpdateTLS-FINISHED
2022-04-05 01:18:24 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 01:18:24 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 01:18:24 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testStrimziIdentityReplicationPolicy-STARTED
2022-04-05 01:18:24 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 01:18:24 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-124 for test case:testStrimziIdentityReplicationPolicy
2022-04-05 01:18:24 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-124
2022-04-05 01:18:24 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-124
2022-04-05 01:18:24 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-124
2022-04-05 01:18:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1661ec6c-source in namespace namespace-124
2022-04-05 01:18:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-124
2022-04-05 01:18:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1661ec6c-source will have desired state: Ready
2022-04-05 01:19:26 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1661ec6c-source is in desired state: Ready
2022-04-05 01:19:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1661ec6c-target in namespace namespace-124
2022-04-05 01:19:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-124
2022-04-05 01:19:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1661ec6c-target will have desired state: Ready
2022-04-05 01:20:39 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1661ec6c-target is in desired state: Ready
2022-04-05 01:20:39 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-cluster-1661ec6c in namespace namespace-124
2022-04-05 01:20:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-124
2022-04-05 01:20:39 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-cluster-1661ec6c will have desired state: Ready
2022-04-05 01:20:40 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-cluster-1661ec6c is in desired state: Ready
2022-04-05 01:20:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-1661ec6c-kafka-clients in namespace namespace-124
2022-04-05 01:20:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-124
2022-04-05 01:20:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-1661ec6c in namespace namespace-124
2022-04-05 01:20:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-124
2022-04-05 01:20:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-1661ec6c will have desired state: Ready
2022-04-05 01:21:52 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-1661ec6c is in desired state: Ready
2022-04-05 01:21:52 [main] [32mINFO [m [MirrorMaker2IsolatedST:902] Sending and receiving messages via my-cluster-1661ec6c-source
2022-04-05 01:21:52 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 01:21:52 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@36afce56, messages=[], arguments=[--topic, my-cluster-1661ec6c, --max-messages, 100, --bootstrap-server, my-cluster-1661ec6c-source-kafka-bootstrap.namespace-124.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-1661ec6c-kafka-clients-d6cf6f58d-tcmtv', podNamespace='namespace-124', bootstrapServer='my-cluster-1661ec6c-source-kafka-bootstrap.namespace-124.svc:9092', topicName='my-cluster-1661ec6c', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@e4fddb3}
2022-04-05 01:21:52 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-1661ec6c-source-kafka-bootstrap.namespace-124.svc:9092:my-cluster-1661ec6c from pod my-cluster-1661ec6c-kafka-clients-d6cf6f58d-tcmtv
2022-04-05 01:21:52 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1661ec6c-kafka-clients-d6cf6f58d-tcmtv -n namespace-124 -- /opt/kafka/producer.sh --topic my-cluster-1661ec6c --max-messages 100 --bootstrap-server my-cluster-1661ec6c-source-kafka-bootstrap.namespace-124.svc:9092
2022-04-05 01:21:54 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 01:21:54 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 01:21:54 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@318896b2, messages=[], arguments=[--topic, my-cluster-1661ec6c, --max-messages, 100, --group-instance-id, instance456899350, --group-id, my-consumer-group-1169752087, --bootstrap-server, my-cluster-1661ec6c-source-kafka-bootstrap.namespace-124.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-1661ec6c-kafka-clients-d6cf6f58d-tcmtv', podNamespace='namespace-124', bootstrapServer='my-cluster-1661ec6c-source-kafka-bootstrap.namespace-124.svc:9092', topicName='my-cluster-1661ec6c', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1169752087', consumerInstanceId='instance456899350', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@41da697f}
2022-04-05 01:21:54 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-1661ec6c-source-kafka-bootstrap.namespace-124.svc:9092#my-cluster-1661ec6c from pod my-cluster-1661ec6c-kafka-clients-d6cf6f58d-tcmtv
2022-04-05 01:21:54 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1661ec6c-kafka-clients-d6cf6f58d-tcmtv -n namespace-124 -- /opt/kafka/consumer.sh --topic my-cluster-1661ec6c --max-messages 100 --group-instance-id instance456899350 --group-id my-consumer-group-1169752087 --bootstrap-server my-cluster-1661ec6c-source-kafka-bootstrap.namespace-124.svc:9092
2022-04-05 01:22:00 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 01:22:00 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 01:22:00 [main] [32mINFO [m [MirrorMaker2IsolatedST:917] Changing to my-cluster-1661ec6c-target and will try to receive messages
2022-04-05 01:22:00 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4fc2a6f2, messages=[], arguments=[--topic, my-cluster-1661ec6c, --max-messages, 100, --group-instance-id, instance1932947552, --group-id, my-consumer-group-1169752087, --bootstrap-server, my-cluster-1661ec6c-target-kafka-bootstrap.namespace-124.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-1661ec6c-kafka-clients-d6cf6f58d-tcmtv', podNamespace='namespace-124', bootstrapServer='my-cluster-1661ec6c-target-kafka-bootstrap.namespace-124.svc:9092', topicName='my-cluster-1661ec6c', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1169752087', consumerInstanceId='instance1932947552', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@799d33ab}
2022-04-05 01:22:00 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-1661ec6c-target-kafka-bootstrap.namespace-124.svc:9092#my-cluster-1661ec6c from pod my-cluster-1661ec6c-kafka-clients-d6cf6f58d-tcmtv
2022-04-05 01:22:00 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1661ec6c-kafka-clients-d6cf6f58d-tcmtv -n namespace-124 -- /opt/kafka/consumer.sh --topic my-cluster-1661ec6c --max-messages 100 --group-instance-id instance1932947552 --group-id my-consumer-group-1169752087 --bootstrap-server my-cluster-1661ec6c-target-kafka-bootstrap.namespace-124.svc:9092
2022-04-05 01:22:06 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 01:22:06 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 01:22:06 [main] [32mINFO [m [MirrorMaker2IsolatedST:925] Checking if the mirrored topic name is same as the original one
2022-04-05 01:22:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-124 exec my-cluster-1661ec6c-target-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-05 01:22:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 01:22:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-124 exec my-cluster-1661ec6c-target-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic my-cluster-1661ec6c
2022-04-05 01:22:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 01:22:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 01:22:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testStrimziIdentityReplicationPolicy
2022-04-05 01:22:11 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-cluster-1661ec6c in namespace namespace-124
2022-04-05 01:22:11 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-1661ec6c-kafka-clients in namespace namespace-124
2022-04-05 01:22:11 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1661ec6c-target in namespace namespace-124
2022-04-05 01:22:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-1661ec6c in namespace namespace-124
2022-04-05 01:22:11 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1661ec6c-source in namespace namespace-124
2022-04-05 01:23:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 01:23:01 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-124 for test case:testStrimziIdentityReplicationPolicy
2022-04-05 01:23:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testStrimziIdentityReplicationPolicy-FINISHED
2022-04-05 01:23:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 01:23:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 01:23:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testScaleMirrorMaker2Subresource-STARTED
2022-04-05 01:23:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 01:23:07 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-125 for test case:testScaleMirrorMaker2Subresource
2022-04-05 01:23:07 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-125
2022-04-05 01:23:07 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-125
2022-04-05 01:23:07 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-125
2022-04-05 01:23:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-835b3693-source in namespace namespace-125
2022-04-05 01:23:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-125
2022-04-05 01:23:07 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-835b3693-source will have desired state: Ready
2022-04-05 01:24:16 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-835b3693-source is in desired state: Ready
2022-04-05 01:24:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-835b3693-target in namespace namespace-125
2022-04-05 01:24:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-125
2022-04-05 01:24:16 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-835b3693-target will have desired state: Ready
2022-04-05 01:25:26 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-835b3693-target is in desired state: Ready
2022-04-05 01:25:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-835b3693 in namespace namespace-125
2022-04-05 01:25:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-125
2022-04-05 01:25:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-835b3693 will have desired state: Ready
2022-04-05 01:26:35 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-835b3693 is in desired state: Ready
2022-04-05 01:26:35 [main] [32mINFO [m [MirrorMaker2IsolatedST:675] -------> Scaling KafkaMirrorMaker2 subresource <-------
2022-04-05 01:26:35 [main] [32mINFO [m [MirrorMaker2IsolatedST:676] Scaling subresource replicas to 4
2022-04-05 01:26:35 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-835b3693-mirrormaker2 will be ready
2022-04-05 01:26:35 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-835b3693-mirrormaker2 is ready
2022-04-05 01:26:35 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 4 Pod(s) of Deployment my-cluster-835b3693-mirrormaker2 to be ready
2022-04-05 01:27:55 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-835b3693-mirrormaker2 is ready
2022-04-05 01:27:55 [main] [32mINFO [m [MirrorMaker2IsolatedST:680] Check if replicas is set to 4, naming prefix should be same and observed generation higher
2022-04-05 01:27:55 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 01:27:55 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleMirrorMaker2Subresource
2022-04-05 01:27:55 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-835b3693-target in namespace namespace-125
2022-04-05 01:27:55 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-835b3693 in namespace namespace-125
2022-04-05 01:27:55 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-835b3693-source in namespace namespace-125
2022-04-05 01:28:15 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 01:28:15 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-125 for test case:testScaleMirrorMaker2Subresource
2022-04-05 01:28:26 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testScaleMirrorMaker2Subresource-FINISHED
2022-04-05 01:28:26 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 01:28:26 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 01:28:26 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testIdentityReplicationPolicy-STARTED
2022-04-05 01:28:26 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 01:28:26 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-126 for test case:testIdentityReplicationPolicy
2022-04-05 01:28:26 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-126
2022-04-05 01:28:26 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-126
2022-04-05 01:28:26 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-126
2022-04-05 01:28:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e02edb5f-source in namespace namespace-126
2022-04-05 01:28:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-126
2022-04-05 01:28:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e02edb5f-source will have desired state: Ready
2022-04-05 01:29:38 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e02edb5f-source is in desired state: Ready
2022-04-05 01:29:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e02edb5f-target in namespace namespace-126
2022-04-05 01:29:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-126
2022-04-05 01:29:38 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e02edb5f-target will have desired state: Ready
2022-04-05 01:30:48 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e02edb5f-target is in desired state: Ready
2022-04-05 01:30:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-cluster-e02edb5f in namespace namespace-126
2022-04-05 01:30:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-126
2022-04-05 01:30:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-cluster-e02edb5f will have desired state: Ready
2022-04-05 01:30:49 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-cluster-e02edb5f is in desired state: Ready
2022-04-05 01:30:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-e02edb5f-kafka-clients in namespace namespace-126
2022-04-05 01:30:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-126
2022-04-05 01:30:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-e02edb5f in namespace namespace-126
2022-04-05 01:30:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-126
2022-04-05 01:30:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-e02edb5f will have desired state: Ready
2022-04-05 01:32:06 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-e02edb5f is in desired state: Ready
2022-04-05 01:32:06 [main] [32mINFO [m [MirrorMaker2IsolatedST:833] Sending and receiving messages via my-cluster-e02edb5f-source
2022-04-05 01:32:06 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 01:32:06 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@270e37af, messages=[], arguments=[--topic, my-cluster-e02edb5f, --max-messages, 100, --bootstrap-server, my-cluster-e02edb5f-source-kafka-bootstrap.namespace-126.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-e02edb5f-kafka-clients-7678ddbf94-k2n4l', podNamespace='namespace-126', bootstrapServer='my-cluster-e02edb5f-source-kafka-bootstrap.namespace-126.svc:9092', topicName='my-cluster-e02edb5f', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3538c5fc}
2022-04-05 01:32:06 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-e02edb5f-source-kafka-bootstrap.namespace-126.svc:9092:my-cluster-e02edb5f from pod my-cluster-e02edb5f-kafka-clients-7678ddbf94-k2n4l
2022-04-05 01:32:06 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-e02edb5f-kafka-clients-7678ddbf94-k2n4l -n namespace-126 -- /opt/kafka/producer.sh --topic my-cluster-e02edb5f --max-messages 100 --bootstrap-server my-cluster-e02edb5f-source-kafka-bootstrap.namespace-126.svc:9092
2022-04-05 01:32:08 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 01:32:08 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 01:32:08 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3578b49c, messages=[], arguments=[--topic, my-cluster-e02edb5f, --max-messages, 100, --group-instance-id, instance786856322, --group-id, my-consumer-group-1968239896, --bootstrap-server, my-cluster-e02edb5f-source-kafka-bootstrap.namespace-126.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-e02edb5f-kafka-clients-7678ddbf94-k2n4l', podNamespace='namespace-126', bootstrapServer='my-cluster-e02edb5f-source-kafka-bootstrap.namespace-126.svc:9092', topicName='my-cluster-e02edb5f', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1968239896', consumerInstanceId='instance786856322', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@461c9e86}
2022-04-05 01:32:08 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-e02edb5f-source-kafka-bootstrap.namespace-126.svc:9092#my-cluster-e02edb5f from pod my-cluster-e02edb5f-kafka-clients-7678ddbf94-k2n4l
2022-04-05 01:32:08 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-e02edb5f-kafka-clients-7678ddbf94-k2n4l -n namespace-126 -- /opt/kafka/consumer.sh --topic my-cluster-e02edb5f --max-messages 100 --group-instance-id instance786856322 --group-id my-consumer-group-1968239896 --bootstrap-server my-cluster-e02edb5f-source-kafka-bootstrap.namespace-126.svc:9092
2022-04-05 01:32:14 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 01:32:14 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 01:32:14 [main] [32mINFO [m [MirrorMaker2IsolatedST:848] Changing to my-cluster-e02edb5f-target and will try to receive messages
2022-04-05 01:32:14 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@9b109e9, messages=[], arguments=[--topic, my-cluster-e02edb5f, --max-messages, 100, --group-instance-id, instance585916279, --group-id, my-consumer-group-1968239896, --bootstrap-server, my-cluster-e02edb5f-target-kafka-bootstrap.namespace-126.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-e02edb5f-kafka-clients-7678ddbf94-k2n4l', podNamespace='namespace-126', bootstrapServer='my-cluster-e02edb5f-target-kafka-bootstrap.namespace-126.svc:9092', topicName='my-cluster-e02edb5f', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1968239896', consumerInstanceId='instance585916279', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@631d5ed3}
2022-04-05 01:32:14 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-e02edb5f-target-kafka-bootstrap.namespace-126.svc:9092#my-cluster-e02edb5f from pod my-cluster-e02edb5f-kafka-clients-7678ddbf94-k2n4l
2022-04-05 01:32:14 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-e02edb5f-kafka-clients-7678ddbf94-k2n4l -n namespace-126 -- /opt/kafka/consumer.sh --topic my-cluster-e02edb5f --max-messages 100 --group-instance-id instance585916279 --group-id my-consumer-group-1968239896 --bootstrap-server my-cluster-e02edb5f-target-kafka-bootstrap.namespace-126.svc:9092
2022-04-05 01:32:20 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 01:32:20 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 01:32:20 [main] [32mINFO [m [MirrorMaker2IsolatedST:856] Checking if the mirrored topic name is same as the original one
2022-04-05 01:32:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-126 exec my-cluster-e02edb5f-target-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-05 01:32:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 01:32:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-126 exec my-cluster-e02edb5f-target-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic my-cluster-e02edb5f
2022-04-05 01:32:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 01:32:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 01:32:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testIdentityReplicationPolicy
2022-04-05 01:32:25 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-cluster-e02edb5f in namespace namespace-126
2022-04-05 01:32:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-e02edb5f in namespace namespace-126
2022-04-05 01:32:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-e02edb5f-kafka-clients in namespace namespace-126
2022-04-05 01:32:25 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e02edb5f-target in namespace namespace-126
2022-04-05 01:32:25 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e02edb5f-source in namespace namespace-126
2022-04-05 01:33:15 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 01:33:15 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-126 for test case:testIdentityReplicationPolicy
2022-04-05 01:33:21 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testIdentityReplicationPolicy-FINISHED
2022-04-05 01:33:21 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 01:33:21 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 01:33:21 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testKMM2RollAfterSecretsCertsUpdateScramsha-STARTED
2022-04-05 01:33:21 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 01:33:21 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-127 for test case:testKMM2RollAfterSecretsCertsUpdateScramsha
2022-04-05 01:33:21 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-127
2022-04-05 01:33:21 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-127
2022-04-05 01:33:21 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-127
2022-04-05 01:33:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a7d7d80c-source in namespace namespace-127
2022-04-05 01:33:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-05 01:33:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a7d7d80c-source will have desired state: Ready
2022-04-05 01:34:27 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a7d7d80c-source is in desired state: Ready
2022-04-05 01:34:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a7d7d80c-target in namespace namespace-127
2022-04-05 01:34:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-05 01:34:27 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a7d7d80c-target will have desired state: Ready
2022-04-05 01:35:33 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a7d7d80c-target is in desired state: Ready
2022-04-05 01:35:33 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-a-1926939211 in namespace namespace-127
2022-04-05 01:35:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-05 01:35:33 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-b-1714743539 in namespace namespace-127
2022-04-05 01:35:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-05 01:35:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-a-1926939211 will have desired state: Ready
2022-04-05 01:35:34 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-a-1926939211 is in desired state: Ready
2022-04-05 01:35:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-b-1714743539 will have desired state: Ready
2022-04-05 01:35:34 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-b-1714743539 is in desired state: Ready
2022-04-05 01:35:34 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-a7d7d80c-my-user-source in namespace namespace-127
2022-04-05 01:35:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-05 01:35:34 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-a7d7d80c-my-user-target in namespace namespace-127
2022-04-05 01:35:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-05 01:35:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-a7d7d80c-my-user-source will have desired state: Ready
2022-04-05 01:35:35 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-a7d7d80c-my-user-source is in desired state: Ready
2022-04-05 01:35:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-a7d7d80c-my-user-target will have desired state: Ready
2022-04-05 01:35:35 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-a7d7d80c-my-user-target is in desired state: Ready
2022-04-05 01:35:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a7d7d80c-kafka-clients in namespace namespace-127
2022-04-05 01:35:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-05 01:35:35 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a7d7d80c-kafka-clients will be ready
2022-04-05 01:35:37 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a7d7d80c-kafka-clients is ready
2022-04-05 01:35:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-a7d7d80c in namespace namespace-127
2022-04-05 01:35:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-05 01:35:38 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-a7d7d80c will have desired state: Ready
2022-04-05 01:36:45 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-a7d7d80c is in desired state: Ready
2022-04-05 01:36:45 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 01:36:45 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@555f6388, messages=[], arguments=[--topic, mirrormaker2-topic-example-a-1926939211, --max-messages, 200, USER=my_cluster_a7d7d80c_my_user_source, --bootstrap-server, my-cluster-a7d7d80c-source-kafka-bootstrap.namespace-127.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-a7d7d80c-kafka-clients-5466b97c44-69v24', podNamespace='namespace-127', bootstrapServer='my-cluster-a7d7d80c-source-kafka-bootstrap.namespace-127.svc:9093', topicName='mirrormaker2-topic-example-a-1926939211', maxMessages=200, kafkaUsername='my-cluster-a7d7d80c-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7e605dc0}
2022-04-05 01:36:45 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-a7d7d80c-source-kafka-bootstrap.namespace-127.svc:9093:mirrormaker2-topic-example-a-1926939211 from pod my-cluster-a7d7d80c-kafka-clients-5466b97c44-69v24
2022-04-05 01:36:45 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a7d7d80c-kafka-clients-5466b97c44-69v24 -n namespace-127 -- /opt/kafka/producer.sh --topic mirrormaker2-topic-example-a-1926939211 --max-messages 200 USER=my_cluster_a7d7d80c_my_user_source --bootstrap-server my-cluster-a7d7d80c-source-kafka-bootstrap.namespace-127.svc:9093
2022-04-05 01:36:49 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 01:36:49 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 01:36:49 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5d846776, messages=[], arguments=[--topic, mirrormaker2-topic-example-a-1926939211, --max-messages, 200, --group-instance-id, instance603173121, USER=my_cluster_a7d7d80c_my_user_source, --group-id, my-consumer-group-45019714, --bootstrap-server, my-cluster-a7d7d80c-source-kafka-bootstrap.namespace-127.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a7d7d80c-kafka-clients-5466b97c44-69v24', podNamespace='namespace-127', bootstrapServer='my-cluster-a7d7d80c-source-kafka-bootstrap.namespace-127.svc:9093', topicName='mirrormaker2-topic-example-a-1926939211', maxMessages=200, kafkaUsername='my-cluster-a7d7d80c-my-user-source', consumerGroupName='my-consumer-group-45019714', consumerInstanceId='instance603173121', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@21f6b0d5}
2022-04-05 01:36:49 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-a7d7d80c-source-kafka-bootstrap.namespace-127.svc:9093:mirrormaker2-topic-example-a-1926939211 from pod my-cluster-a7d7d80c-kafka-clients-5466b97c44-69v24
2022-04-05 01:36:49 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a7d7d80c-kafka-clients-5466b97c44-69v24 -n namespace-127 -- /opt/kafka/consumer.sh --topic mirrormaker2-topic-example-a-1926939211 --max-messages 200 --group-instance-id instance603173121 USER=my_cluster_a7d7d80c_my_user_source --group-id my-consumer-group-45019714 --bootstrap-server my-cluster-a7d7d80c-source-kafka-bootstrap.namespace-127.svc:9093
2022-04-05 01:36:56 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 01:36:56 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 01:36:56 [main] [32mINFO [m [MirrorMaker2IsolatedST:1338] Now messages should be mirrored to target topic and cluster
2022-04-05 01:36:56 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2c738de4, messages=[], arguments=[--topic, my-cluster-a7d7d80c-source.mirrormaker2-topic-example-a-1926939211, --max-messages, 200, --group-instance-id, instance680494486, USER=my_cluster_a7d7d80c_my_user_target, --group-id, my-consumer-group-861364961, --bootstrap-server, my-cluster-a7d7d80c-target-kafka-bootstrap.namespace-127.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a7d7d80c-kafka-clients-5466b97c44-69v24', podNamespace='namespace-127', bootstrapServer='my-cluster-a7d7d80c-target-kafka-bootstrap.namespace-127.svc:9093', topicName='my-cluster-a7d7d80c-source.mirrormaker2-topic-example-a-1926939211', maxMessages=200, kafkaUsername='my-cluster-a7d7d80c-my-user-target', consumerGroupName='my-consumer-group-861364961', consumerInstanceId='instance680494486', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@73e91c6d}
2022-04-05 01:36:56 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-a7d7d80c-target-kafka-bootstrap.namespace-127.svc:9093:my-cluster-a7d7d80c-source.mirrormaker2-topic-example-a-1926939211 from pod my-cluster-a7d7d80c-kafka-clients-5466b97c44-69v24
2022-04-05 01:36:56 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a7d7d80c-kafka-clients-5466b97c44-69v24 -n namespace-127 -- /opt/kafka/consumer.sh --topic my-cluster-a7d7d80c-source.mirrormaker2-topic-example-a-1926939211 --max-messages 200 --group-instance-id instance680494486 USER=my_cluster_a7d7d80c_my_user_target --group-id my-consumer-group-861364961 --bootstrap-server my-cluster-a7d7d80c-target-kafka-bootstrap.namespace-127.svc:9093
2022-04-05 01:37:03 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 01:37:03 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 01:37:03 [main] [32mINFO [m [MirrorMaker2IsolatedST:1340] Messages successfully mirrored
2022-04-05 01:37:03 [main] [32mINFO [m [MirrorMaker2IsolatedST:1344] Changing KafkaUser sha-password on KMM2 Source and make sure it rolled
2022-04-05 01:37:03 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-a7d7d80c-mirrormaker2 rolling update
2022-04-05 01:38:28 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a7d7d80c-mirrormaker2 will be ready
2022-04-05 01:38:28 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a7d7d80c-mirrormaker2 is ready
2022-04-05 01:38:38 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-a7d7d80c-mirrormaker2 rolling update finished
2022-04-05 01:38:38 [main] [32mINFO [m [MirrorMaker2IsolatedST:1354] Changing KafkaUser sha-password on KMM2 Target
2022-04-05 01:38:38 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-a7d7d80c-mirrormaker2 rolling update
2022-04-05 01:40:38 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a7d7d80c-mirrormaker2 will be ready
2022-04-05 01:40:38 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a7d7d80c-mirrormaker2 is ready
2022-04-05 01:40:48 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-a7d7d80c-mirrormaker2 rolling update finished
2022-04-05 01:40:48 [main] [32mINFO [m [MirrorMaker2IsolatedST:1364] Recreate kafkaClients pod with new passwords.
2022-04-05 01:40:48 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a7d7d80c-kafka-clients in namespace namespace-127
2022-04-05 01:41:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a7d7d80c-kafka-clients in namespace namespace-127
2022-04-05 01:41:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-05 01:41:28 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a7d7d80c-kafka-clients will be ready
2022-04-05 01:41:29 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a7d7d80c-kafka-clients is ready
2022-04-05 01:41:29 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@384fe909, messages=[], arguments=[--topic, mirrormaker2-topic-example-b-1714743539, --max-messages, 200, USER=my_cluster_a7d7d80c_my_user_source, --bootstrap-server, my-cluster-a7d7d80c-source-kafka-bootstrap.namespace-127.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-a7d7d80c-kafka-clients-5689cccfdb-w8cht', podNamespace='namespace-127', bootstrapServer='my-cluster-a7d7d80c-source-kafka-bootstrap.namespace-127.svc:9093', topicName='mirrormaker2-topic-example-b-1714743539', maxMessages=200, kafkaUsername='my-cluster-a7d7d80c-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@aa30858}
2022-04-05 01:41:29 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-a7d7d80c-source-kafka-bootstrap.namespace-127.svc:9093:mirrormaker2-topic-example-b-1714743539 from pod my-cluster-a7d7d80c-kafka-clients-5689cccfdb-w8cht
2022-04-05 01:41:29 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a7d7d80c-kafka-clients-5689cccfdb-w8cht -n namespace-127 -- /opt/kafka/producer.sh --topic mirrormaker2-topic-example-b-1714743539 --max-messages 200 USER=my_cluster_a7d7d80c_my_user_source --bootstrap-server my-cluster-a7d7d80c-source-kafka-bootstrap.namespace-127.svc:9093
2022-04-05 01:41:33 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 01:41:33 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 01:41:33 [main] [32mINFO [m [MirrorMaker2IsolatedST:1385] Now messages should be mirrored to target topic and cluster
2022-04-05 01:41:33 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3b08196c, messages=[], arguments=[--topic, my-cluster-a7d7d80c-source.mirrormaker2-topic-example-b-1714743539, --max-messages, 200, --group-instance-id, instance1420916438, USER=my_cluster_a7d7d80c_my_user_target, --group-id, my-consumer-group-134767884, --bootstrap-server, my-cluster-a7d7d80c-target-kafka-bootstrap.namespace-127.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a7d7d80c-kafka-clients-5689cccfdb-w8cht', podNamespace='namespace-127', bootstrapServer='my-cluster-a7d7d80c-target-kafka-bootstrap.namespace-127.svc:9093', topicName='my-cluster-a7d7d80c-source.mirrormaker2-topic-example-b-1714743539', maxMessages=200, kafkaUsername='my-cluster-a7d7d80c-my-user-target', consumerGroupName='my-consumer-group-134767884', consumerInstanceId='instance1420916438', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@297b25d3}
2022-04-05 01:41:33 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-a7d7d80c-target-kafka-bootstrap.namespace-127.svc:9093:my-cluster-a7d7d80c-source.mirrormaker2-topic-example-b-1714743539 from pod my-cluster-a7d7d80c-kafka-clients-5689cccfdb-w8cht
2022-04-05 01:41:33 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a7d7d80c-kafka-clients-5689cccfdb-w8cht -n namespace-127 -- /opt/kafka/consumer.sh --topic my-cluster-a7d7d80c-source.mirrormaker2-topic-example-b-1714743539 --max-messages 200 --group-instance-id instance1420916438 USER=my_cluster_a7d7d80c_my_user_target --group-id my-consumer-group-134767884 --bootstrap-server my-cluster-a7d7d80c-target-kafka-bootstrap.namespace-127.svc:9093
2022-04-05 01:41:40 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 01:41:40 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 01:41:40 [main] [32mINFO [m [MirrorMaker2IsolatedST:1387] Messages successfully mirrored
2022-04-05 01:41:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 01:41:40 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKMM2RollAfterSecretsCertsUpdateScramsha
2022-04-05 01:41:40 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-a7d7d80c-my-user-source in namespace namespace-127
2022-04-05 01:41:40 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a7d7d80c-target in namespace namespace-127
2022-04-05 01:41:40 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-a7d7d80c-my-user-target in namespace namespace-127
2022-04-05 01:41:40 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a7d7d80c-source in namespace namespace-127
2022-04-05 01:41:40 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-a7d7d80c in namespace namespace-127
2022-04-05 01:41:40 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a7d7d80c-kafka-clients in namespace namespace-127
2022-04-05 01:41:40 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-a-1926939211 in namespace namespace-127
2022-04-05 01:41:40 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a7d7d80c-kafka-clients in namespace namespace-127
2022-04-05 01:41:50 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-b-1714743539 in namespace namespace-127
2022-04-05 01:42:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 01:42:30 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-127 for test case:testKMM2RollAfterSecretsCertsUpdateScramsha
2022-04-05 01:42:36 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testKMM2RollAfterSecretsCertsUpdateScramsha-FINISHED
2022-04-05 01:42:36 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 01:42:36 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 01:42:36 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2TlsAndTlsClientAuth-STARTED
2022-04-05 01:42:36 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 01:42:36 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-128 for test case:testMirrorMaker2TlsAndTlsClientAuth
2022-04-05 01:42:36 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-128
2022-04-05 01:42:36 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-128
2022-04-05 01:42:36 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-128
2022-04-05 01:42:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d80c9f2d-source in namespace namespace-128
2022-04-05 01:42:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-05 01:42:36 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d80c9f2d-source will have desired state: Ready
2022-04-05 01:43:38 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d80c9f2d-source is in desired state: Ready
2022-04-05 01:43:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d80c9f2d-target in namespace namespace-128
2022-04-05 01:43:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-05 01:43:38 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d80c9f2d-target will have desired state: Ready
2022-04-05 01:44:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d80c9f2d-target is in desired state: Ready
2022-04-05 01:44:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-1538251852 in namespace namespace-128
2022-04-05 01:44:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-05 01:44:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-1538251852 will have desired state: Ready
2022-04-05 01:44:46 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-1538251852 is in desired state: Ready
2022-04-05 01:44:46 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-d80c9f2d-my-user-source in namespace namespace-128
2022-04-05 01:44:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-05 01:44:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-d80c9f2d-my-user-source will have desired state: Ready
2022-04-05 01:44:47 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-d80c9f2d-my-user-source is in desired state: Ready
2022-04-05 01:44:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-d80c9f2d-my-user-target in namespace namespace-128
2022-04-05 01:44:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-05 01:44:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-d80c9f2d-my-user-target will have desired state: Ready
2022-04-05 01:44:48 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-d80c9f2d-my-user-target is in desired state: Ready
2022-04-05 01:44:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-d80c9f2d-kafka-clients in namespace namespace-128
2022-04-05 01:44:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-05 01:44:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-446913280-1084937416-test-1 in namespace namespace-128
2022-04-05 01:44:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-05 01:44:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-446913280-1084937416-test-1 will have desired state: Ready
2022-04-05 01:44:59 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-446913280-1084937416-test-1 is in desired state: Ready
2022-04-05 01:44:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-446913280-1084937416-test-2 in namespace namespace-128
2022-04-05 01:44:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-05 01:44:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-446913280-1084937416-test-2 will have desired state: Ready
2022-04-05 01:45:00 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-446913280-1084937416-test-2 is in desired state: Ready
2022-04-05 01:45:00 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 01:45:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-303217148-1738137783 in namespace namespace-128
2022-04-05 01:45:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-05 01:45:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-303217148-1738137783 will have desired state: Ready
2022-04-05 01:45:01 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-303217148-1738137783 is in desired state: Ready
2022-04-05 01:45:01 [main] [32mINFO [m [ClientUtils:127] Sending messages to - topic my-topic-446913280-1084937416-test-1, cluster my-cluster-d80c9f2d-source and message count of 200
2022-04-05 01:45:01 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@71f31ada, messages=[], arguments=[--topic, my-topic-303217148-1738137783, --max-messages, 200, USER=my_cluster_d80c9f2d_my_user_source, --bootstrap-server, my-cluster-d80c9f2d-source-kafka-bootstrap.namespace-128.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-d80c9f2d-kafka-clients-7f94d475f8-jzv7w', podNamespace='namespace-128', bootstrapServer='my-cluster-d80c9f2d-source-kafka-bootstrap.namespace-128.svc:9093', topicName='my-topic-303217148-1738137783', maxMessages=200, kafkaUsername='my-cluster-d80c9f2d-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@71ea3176}
2022-04-05 01:45:01 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-d80c9f2d-source-kafka-bootstrap.namespace-128.svc:9093:my-topic-303217148-1738137783 from pod my-cluster-d80c9f2d-kafka-clients-7f94d475f8-jzv7w
2022-04-05 01:45:01 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d80c9f2d-kafka-clients-7f94d475f8-jzv7w -n namespace-128 -- /opt/kafka/producer.sh --topic my-topic-303217148-1738137783 --max-messages 200 USER=my_cluster_d80c9f2d_my_user_source --bootstrap-server my-cluster-d80c9f2d-source-kafka-bootstrap.namespace-128.svc:9093
2022-04-05 01:45:05 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 01:45:05 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 01:45:05 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@12f620b7, messages=[], arguments=[--topic, my-topic-303217148-1738137783, --max-messages, 200, --group-instance-id, instance1323903617, USER=my_cluster_d80c9f2d_my_user_source, --group-id, my-consumer-group-2003290954, --bootstrap-server, my-cluster-d80c9f2d-source-kafka-bootstrap.namespace-128.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d80c9f2d-kafka-clients-7f94d475f8-jzv7w', podNamespace='namespace-128', bootstrapServer='my-cluster-d80c9f2d-source-kafka-bootstrap.namespace-128.svc:9093', topicName='my-topic-303217148-1738137783', maxMessages=200, kafkaUsername='my-cluster-d80c9f2d-my-user-source', consumerGroupName='my-consumer-group-2003290954', consumerInstanceId='instance1323903617', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3237d606}
2022-04-05 01:45:05 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-d80c9f2d-source-kafka-bootstrap.namespace-128.svc:9093:my-topic-303217148-1738137783 from pod my-cluster-d80c9f2d-kafka-clients-7f94d475f8-jzv7w
2022-04-05 01:45:05 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d80c9f2d-kafka-clients-7f94d475f8-jzv7w -n namespace-128 -- /opt/kafka/consumer.sh --topic my-topic-303217148-1738137783 --max-messages 200 --group-instance-id instance1323903617 USER=my_cluster_d80c9f2d_my_user_source --group-id my-consumer-group-2003290954 --bootstrap-server my-cluster-d80c9f2d-source-kafka-bootstrap.namespace-128.svc:9093
2022-04-05 01:45:13 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 01:45:13 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 01:45:13 [main] [32mINFO [m [ClientUtils:133] Sent 200 and received 200
2022-04-05 01:45:13 [main] [32mINFO [m [MirrorMaker2IsolatedST:328] Setting topic to my-topic-446913280-1084937416-test-2, cluster to my-cluster-d80c9f2d-target and changing user to my-cluster-d80c9f2d-my-user-target
2022-04-05 01:45:13 [main] [32mINFO [m [MirrorMaker2IsolatedST:337] Sending messages to - topic my-topic-446913280-1084937416-test-2, cluster my-cluster-d80c9f2d-target and message count of 200
2022-04-05 01:45:13 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@6333f59, messages=[], arguments=[--topic, my-topic-446913280-1084937416-test-2, --max-messages, 200, USER=my_cluster_d80c9f2d_my_user_target, --bootstrap-server, my-cluster-d80c9f2d-target-kafka-bootstrap.namespace-128.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-d80c9f2d-kafka-clients-7f94d475f8-jzv7w', podNamespace='namespace-128', bootstrapServer='my-cluster-d80c9f2d-target-kafka-bootstrap.namespace-128.svc:9093', topicName='my-topic-446913280-1084937416-test-2', maxMessages=200, kafkaUsername='my-cluster-d80c9f2d-my-user-target', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7b3acdf9}
2022-04-05 01:45:13 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-d80c9f2d-target-kafka-bootstrap.namespace-128.svc:9093:my-topic-446913280-1084937416-test-2 from pod my-cluster-d80c9f2d-kafka-clients-7f94d475f8-jzv7w
2022-04-05 01:45:13 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d80c9f2d-kafka-clients-7f94d475f8-jzv7w -n namespace-128 -- /opt/kafka/producer.sh --topic my-topic-446913280-1084937416-test-2 --max-messages 200 USER=my_cluster_d80c9f2d_my_user_target --bootstrap-server my-cluster-d80c9f2d-target-kafka-bootstrap.namespace-128.svc:9093
2022-04-05 01:45:17 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 01:45:17 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 01:45:17 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@29e83407, messages=[], arguments=[--topic, my-topic-446913280-1084937416-test-2, --max-messages, 200, --group-instance-id, instance1356922569, USER=my_cluster_d80c9f2d_my_user_target, --group-id, my-consumer-group-180905817, --bootstrap-server, my-cluster-d80c9f2d-target-kafka-bootstrap.namespace-128.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d80c9f2d-kafka-clients-7f94d475f8-jzv7w', podNamespace='namespace-128', bootstrapServer='my-cluster-d80c9f2d-target-kafka-bootstrap.namespace-128.svc:9093', topicName='my-topic-446913280-1084937416-test-2', maxMessages=200, kafkaUsername='my-cluster-d80c9f2d-my-user-target', consumerGroupName='my-consumer-group-180905817', consumerInstanceId='instance1356922569', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@ab85e7f}
2022-04-05 01:45:17 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-d80c9f2d-target-kafka-bootstrap.namespace-128.svc:9093:my-topic-446913280-1084937416-test-2 from pod my-cluster-d80c9f2d-kafka-clients-7f94d475f8-jzv7w
2022-04-05 01:45:17 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d80c9f2d-kafka-clients-7f94d475f8-jzv7w -n namespace-128 -- /opt/kafka/consumer.sh --topic my-topic-446913280-1084937416-test-2 --max-messages 200 --group-instance-id instance1356922569 USER=my_cluster_d80c9f2d_my_user_target --group-id my-consumer-group-180905817 --bootstrap-server my-cluster-d80c9f2d-target-kafka-bootstrap.namespace-128.svc:9093
2022-04-05 01:45:24 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 01:45:24 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 01:45:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-d80c9f2d in namespace namespace-128
2022-04-05 01:45:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-05 01:45:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-d80c9f2d will have desired state: Ready
2022-04-05 01:46:35 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-d80c9f2d is in desired state: Ready
2022-04-05 01:46:35 [main] [32mINFO [m [MirrorMaker2IsolatedST:397] Setting topic to mirrormaker2-topic-example-1538251852, cluster to my-cluster-d80c9f2d-source and changing user to my-cluster-d80c9f2d-my-user-source
2022-04-05 01:46:35 [main] [32mINFO [m [MirrorMaker2IsolatedST:407] Sending messages to - topic mirrormaker2-topic-example-1538251852, cluster my-cluster-d80c9f2d-source and message count of 200
2022-04-05 01:46:35 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1f3f4529, messages=[], arguments=[--topic, mirrormaker2-topic-example-1538251852, --max-messages, 200, USER=my_cluster_d80c9f2d_my_user_source, --bootstrap-server, my-cluster-d80c9f2d-source-kafka-bootstrap.namespace-128.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-d80c9f2d-kafka-clients-7f94d475f8-jzv7w', podNamespace='namespace-128', bootstrapServer='my-cluster-d80c9f2d-source-kafka-bootstrap.namespace-128.svc:9093', topicName='mirrormaker2-topic-example-1538251852', maxMessages=200, kafkaUsername='my-cluster-d80c9f2d-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@f799e19}
2022-04-05 01:46:35 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-d80c9f2d-source-kafka-bootstrap.namespace-128.svc:9093:mirrormaker2-topic-example-1538251852 from pod my-cluster-d80c9f2d-kafka-clients-7f94d475f8-jzv7w
2022-04-05 01:46:35 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d80c9f2d-kafka-clients-7f94d475f8-jzv7w -n namespace-128 -- /opt/kafka/producer.sh --topic mirrormaker2-topic-example-1538251852 --max-messages 200 USER=my_cluster_d80c9f2d_my_user_source --bootstrap-server my-cluster-d80c9f2d-source-kafka-bootstrap.namespace-128.svc:9093
2022-04-05 01:46:39 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 01:46:39 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 01:46:39 [main] [32mINFO [m [MirrorMaker2IsolatedST:411] Receiving messages from - topic mirrormaker2-topic-example-1538251852, cluster my-cluster-d80c9f2d-source and message count of 200
2022-04-05 01:46:39 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7aadb8b7, messages=[], arguments=[--topic, mirrormaker2-topic-example-1538251852, --max-messages, 200, --group-instance-id, instance960650541, USER=my_cluster_d80c9f2d_my_user_source, --group-id, my-consumer-group-180905817, --bootstrap-server, my-cluster-d80c9f2d-source-kafka-bootstrap.namespace-128.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d80c9f2d-kafka-clients-7f94d475f8-jzv7w', podNamespace='namespace-128', bootstrapServer='my-cluster-d80c9f2d-source-kafka-bootstrap.namespace-128.svc:9093', topicName='mirrormaker2-topic-example-1538251852', maxMessages=200, kafkaUsername='my-cluster-d80c9f2d-my-user-source', consumerGroupName='my-consumer-group-180905817', consumerInstanceId='instance960650541', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@39e770c4}
2022-04-05 01:46:39 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-d80c9f2d-source-kafka-bootstrap.namespace-128.svc:9093:mirrormaker2-topic-example-1538251852 from pod my-cluster-d80c9f2d-kafka-clients-7f94d475f8-jzv7w
2022-04-05 01:46:39 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d80c9f2d-kafka-clients-7f94d475f8-jzv7w -n namespace-128 -- /opt/kafka/consumer.sh --topic mirrormaker2-topic-example-1538251852 --max-messages 200 --group-instance-id instance960650541 USER=my_cluster_d80c9f2d_my_user_source --group-id my-consumer-group-180905817 --bootstrap-server my-cluster-d80c9f2d-source-kafka-bootstrap.namespace-128.svc:9093
2022-04-05 01:46:46 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 01:46:46 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 01:46:46 [main] [32mINFO [m [MirrorMaker2IsolatedST:418] Now setting topic to my-cluster-d80c9f2d-source.mirrormaker2-topic-example-1538251852, cluster to my-cluster-d80c9f2d-target and user to my-cluster-d80c9f2d-my-user-target - the messages should be mirrored
2022-04-05 01:46:46 [main] [32mINFO [m [MirrorMaker2IsolatedST:427] Consumer in target cluster and topic should receive 200 messages
2022-04-05 01:46:46 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4d3a92b, messages=[], arguments=[--topic, my-cluster-d80c9f2d-source.mirrormaker2-topic-example-1538251852, --max-messages, 200, --group-instance-id, instance729539242, USER=my_cluster_d80c9f2d_my_user_target, --group-id, my-consumer-group-180905817, --bootstrap-server, my-cluster-d80c9f2d-target-kafka-bootstrap.namespace-128.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d80c9f2d-kafka-clients-7f94d475f8-jzv7w', podNamespace='namespace-128', bootstrapServer='my-cluster-d80c9f2d-target-kafka-bootstrap.namespace-128.svc:9093', topicName='my-cluster-d80c9f2d-source.mirrormaker2-topic-example-1538251852', maxMessages=200, kafkaUsername='my-cluster-d80c9f2d-my-user-target', consumerGroupName='my-consumer-group-180905817', consumerInstanceId='instance729539242', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1fdeacc6}
2022-04-05 01:46:46 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-d80c9f2d-target-kafka-bootstrap.namespace-128.svc:9093:my-cluster-d80c9f2d-source.mirrormaker2-topic-example-1538251852 from pod my-cluster-d80c9f2d-kafka-clients-7f94d475f8-jzv7w
2022-04-05 01:46:46 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d80c9f2d-kafka-clients-7f94d475f8-jzv7w -n namespace-128 -- /opt/kafka/consumer.sh --topic my-cluster-d80c9f2d-source.mirrormaker2-topic-example-1538251852 --max-messages 200 --group-instance-id instance729539242 USER=my_cluster_d80c9f2d_my_user_target --group-id my-consumer-group-180905817 --bootstrap-server my-cluster-d80c9f2d-target-kafka-bootstrap.namespace-128.svc:9093
2022-04-05 01:46:52 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 01:46:52 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 01:46:52 [main] [32mINFO [m [MirrorMaker2IsolatedST:432] Messages successfully mirrored
2022-04-05 01:46:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 01:46:52 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker2TlsAndTlsClientAuth
2022-04-05 01:46:52 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-446913280-1084937416-test-1 in namespace namespace-128
2022-04-05 01:46:52 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d80c9f2d-target in namespace namespace-128
2022-04-05 01:46:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d80c9f2d-source in namespace namespace-128
2022-04-05 01:46:52 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-446913280-1084937416-test-2 in namespace namespace-128
2022-04-05 01:46:52 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-1538251852 in namespace namespace-128
2022-04-05 01:46:52 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-303217148-1738137783 in namespace namespace-128
2022-04-05 01:46:52 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-d80c9f2d-my-user-target in namespace namespace-128
2022-04-05 01:46:52 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-d80c9f2d-my-user-source in namespace namespace-128
2022-04-05 01:47:02 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-d80c9f2d in namespace namespace-128
2022-04-05 01:47:02 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-d80c9f2d-kafka-clients in namespace namespace-128
2022-04-05 01:47:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 01:47:43 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-128 for test case:testMirrorMaker2TlsAndTlsClientAuth
2022-04-05 01:47:48 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2TlsAndTlsClientAuth-FINISHED
2022-04-05 01:47:48 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 01:47:48 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 01:47:48 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testConfigureDeploymentStrategy-STARTED
2022-04-05 01:47:48 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 01:47:48 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-129 for test case:testConfigureDeploymentStrategy
2022-04-05 01:47:48 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-129
2022-04-05 01:47:48 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-129
2022-04-05 01:47:48 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-129
2022-04-05 01:47:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0490ff0c-source in namespace namespace-129
2022-04-05 01:47:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-129
2022-04-05 01:47:48 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0490ff0c-source will have desired state: Ready
2022-04-05 01:49:00 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0490ff0c-source is in desired state: Ready
2022-04-05 01:49:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0490ff0c-target in namespace namespace-129
2022-04-05 01:49:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-129
2022-04-05 01:49:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0490ff0c-target will have desired state: Ready
2022-04-05 01:50:04 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0490ff0c-target is in desired state: Ready
2022-04-05 01:50:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-0490ff0c in namespace namespace-129
2022-04-05 01:50:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-129
2022-04-05 01:50:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-0490ff0c will have desired state: Ready
2022-04-05 01:51:07 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-0490ff0c is in desired state: Ready
2022-04-05 01:51:07 [main] [32mINFO [m [MirrorMaker2IsolatedST:959] Adding label to MirrorMaker2 resource, the CR should be recreated
2022-04-05 01:51:07 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-0490ff0c-mirrormaker2 will be ready
2022-04-05 01:51:07 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-0490ff0c-mirrormaker2 is ready
2022-04-05 01:51:07 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-0490ff0c-mirrormaker2 to be ready
2022-04-05 01:52:35 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-0490ff0c-mirrormaker2 is ready
2022-04-05 01:52:35 [main] [32mINFO [m [MirrorMaker2IsolatedST:966] Checking that observed gen. is still on 1 (recreation) and new label is present
2022-04-05 01:52:35 [main] [32mINFO [m [MirrorMaker2IsolatedST:971] Changing deployment strategy to ROLLING_UPDATE
2022-04-05 01:52:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-0490ff0c will have desired state: Ready
2022-04-05 01:52:35 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-0490ff0c is in desired state: Ready
2022-04-05 01:52:35 [main] [32mINFO [m [MirrorMaker2IsolatedST:976] Adding another label to MirrorMaker2 resource, pods should be rolled
2022-04-05 01:52:35 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-0490ff0c-mirrormaker2 will be ready
2022-04-05 01:52:35 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-0490ff0c-mirrormaker2 is ready
2022-04-05 01:52:35 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-0490ff0c-mirrormaker2 to be ready
2022-04-05 01:54:04 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-0490ff0c-mirrormaker2 is ready
2022-04-05 01:54:04 [main] [32mINFO [m [MirrorMaker2IsolatedST:980] Checking that observed gen. higher (rolling update) and label is changed
2022-04-05 01:54:04 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 01:54:04 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigureDeploymentStrategy
2022-04-05 01:54:04 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0490ff0c-target in namespace namespace-129
2022-04-05 01:54:04 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0490ff0c-source in namespace namespace-129
2022-04-05 01:54:04 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-0490ff0c in namespace namespace-129
2022-04-05 01:54:24 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 01:54:24 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-129 for test case:testConfigureDeploymentStrategy
2022-04-05 01:54:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testConfigureDeploymentStrategy-FINISHED
2022-04-05 01:54:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 01:54:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 01:54:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2CorrectlyMirrorsHeaders-STARTED
2022-04-05 01:54:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 01:54:35 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-130 for test case:testMirrorMaker2CorrectlyMirrorsHeaders
2022-04-05 01:54:35 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-130
2022-04-05 01:54:35 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-130
2022-04-05 01:54:35 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-130
2022-04-05 01:54:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-433057ed-source in namespace namespace-130
2022-04-05 01:54:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-130
2022-04-05 01:54:35 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-433057ed-source will have desired state: Ready
2022-04-05 01:55:43 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-433057ed-source is in desired state: Ready
2022-04-05 01:55:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-433057ed-target in namespace namespace-130
2022-04-05 01:55:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-130
2022-04-05 01:55:43 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-433057ed-target will have desired state: Ready
2022-04-05 01:56:59 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-433057ed-target is in desired state: Ready
2022-04-05 01:56:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-cluster-433057ed-source-example-topic in namespace namespace-130
2022-04-05 01:56:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-130
2022-04-05 01:56:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-cluster-433057ed-source-example-topic will have desired state: Ready
2022-04-05 01:57:00 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-cluster-433057ed-source-example-topic is in desired state: Ready
2022-04-05 01:57:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-433057ed in namespace namespace-130
2022-04-05 01:57:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-130
2022-04-05 01:57:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-433057ed will have desired state: Ready
2022-04-05 01:58:11 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-433057ed is in desired state: Ready
2022-04-05 01:58:11 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 01:58:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-433057ed-target-consumer in namespace namespace-130
2022-04-05 01:58:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-130
2022-04-05 01:58:11 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-433057ed-target-consumer will be in active state
2022-04-05 01:58:12 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 01:58:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-433057ed-source-producer in namespace namespace-130
2022-04-05 01:58:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-130
2022-04-05 01:58:12 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-433057ed-source-producer will be in active state
2022-04-05 01:58:13 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-433057ed-source-producer and consumer my-cluster-433057ed-target-consumer finish
2022-04-05 01:59:55 [main] [32mINFO [m [MirrorMaker2IsolatedST:753] Checking log of my-cluster-433057ed-target-consumer job if the headers are correct
2022-04-05 01:59:55 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 01:59:55 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker2CorrectlyMirrorsHeaders
2022-04-05 01:59:55 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-433057ed in namespace namespace-130
2022-04-05 01:59:55 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-433057ed-source in namespace namespace-130
2022-04-05 01:59:55 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-433057ed-source-producer in namespace namespace-130
2022-04-05 01:59:55 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-433057ed-target-consumer in namespace namespace-130
2022-04-05 01:59:55 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-cluster-433057ed-source-example-topic in namespace namespace-130
2022-04-05 01:59:55 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-433057ed-target in namespace namespace-130
2022-04-05 02:00:15 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 02:00:15 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-130 for test case:testMirrorMaker2CorrectlyMirrorsHeaders
2022-04-05 02:00:42 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2CorrectlyMirrorsHeaders-FINISHED
2022-04-05 02:00:42 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 02:00:42 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 02:00:42 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2TlsAndScramSha512Auth-STARTED
2022-04-05 02:00:42 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 02:00:42 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-131 for test case:testMirrorMaker2TlsAndScramSha512Auth
2022-04-05 02:00:42 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-131
2022-04-05 02:00:42 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-131
2022-04-05 02:00:42 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-131
2022-04-05 02:00:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-068bc626-source in namespace namespace-131
2022-04-05 02:00:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-05 02:00:42 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-068bc626-source will have desired state: Ready
2022-04-05 02:01:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-068bc626-source is in desired state: Ready
2022-04-05 02:01:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-068bc626-target in namespace namespace-131
2022-04-05 02:01:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-05 02:01:45 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-068bc626-target will have desired state: Ready
2022-04-05 02:02:47 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-068bc626-target is in desired state: Ready
2022-04-05 02:02:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-1204224364 in namespace namespace-131
2022-04-05 02:02:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-05 02:02:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-1204224364 will have desired state: Ready
2022-04-05 02:02:48 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-1204224364 is in desired state: Ready
2022-04-05 02:02:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-068bc626-my-user-source in namespace namespace-131
2022-04-05 02:02:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-05 02:02:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-068bc626-my-user-source will have desired state: Ready
2022-04-05 02:02:49 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-068bc626-my-user-source is in desired state: Ready
2022-04-05 02:02:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-068bc626-my-user-target in namespace namespace-131
2022-04-05 02:02:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-05 02:02:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-068bc626-my-user-target will have desired state: Ready
2022-04-05 02:02:50 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-068bc626-my-user-target is in desired state: Ready
2022-04-05 02:02:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-068bc626-kafka-clients in namespace namespace-131
2022-04-05 02:02:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-05 02:02:50 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-068bc626-kafka-clients will be ready
2022-04-05 02:02:52 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-068bc626-kafka-clients is ready
2022-04-05 02:02:52 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 02:02:52 [main] [32mINFO [m [MirrorMaker2IsolatedST:536] Sending messages to - topic availability-topic-source-my-topic-495429288-970895480, cluster my-cluster-068bc626-source and message count of 200
2022-04-05 02:02:52 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@7a646eb3, messages=[], arguments=[--topic, availability-topic-source-my-topic-495429288-970895480, --max-messages, 200, USER=my_cluster_068bc626_my_user_source, --bootstrap-server, my-cluster-068bc626-source-kafka-bootstrap.namespace-131.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-068bc626-kafka-clients-5884747b8b-j4d6m', podNamespace='namespace-131', bootstrapServer='my-cluster-068bc626-source-kafka-bootstrap.namespace-131.svc:9093', topicName='availability-topic-source-my-topic-495429288-970895480', maxMessages=200, kafkaUsername='my-cluster-068bc626-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1036310d}
2022-04-05 02:02:52 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-068bc626-source-kafka-bootstrap.namespace-131.svc:9093:availability-topic-source-my-topic-495429288-970895480 from pod my-cluster-068bc626-kafka-clients-5884747b8b-j4d6m
2022-04-05 02:02:52 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-068bc626-kafka-clients-5884747b8b-j4d6m -n namespace-131 -- /opt/kafka/producer.sh --topic availability-topic-source-my-topic-495429288-970895480 --max-messages 200 USER=my_cluster_068bc626_my_user_source --bootstrap-server my-cluster-068bc626-source-kafka-bootstrap.namespace-131.svc:9093
2022-04-05 02:02:56 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 02:02:56 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 02:02:56 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@13c3d514, messages=[], arguments=[--topic, availability-topic-source-my-topic-495429288-970895480, --max-messages, 200, --group-instance-id, instance520716446, USER=my_cluster_068bc626_my_user_source, --group-id, my-consumer-group-1669018116, --bootstrap-server, my-cluster-068bc626-source-kafka-bootstrap.namespace-131.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-068bc626-kafka-clients-5884747b8b-j4d6m', podNamespace='namespace-131', bootstrapServer='my-cluster-068bc626-source-kafka-bootstrap.namespace-131.svc:9093', topicName='availability-topic-source-my-topic-495429288-970895480', maxMessages=200, kafkaUsername='my-cluster-068bc626-my-user-source', consumerGroupName='my-consumer-group-1669018116', consumerInstanceId='instance520716446', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@325c340b}
2022-04-05 02:02:56 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-068bc626-source-kafka-bootstrap.namespace-131.svc:9093:availability-topic-source-my-topic-495429288-970895480 from pod my-cluster-068bc626-kafka-clients-5884747b8b-j4d6m
2022-04-05 02:02:56 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-068bc626-kafka-clients-5884747b8b-j4d6m -n namespace-131 -- /opt/kafka/consumer.sh --topic availability-topic-source-my-topic-495429288-970895480 --max-messages 200 --group-instance-id instance520716446 USER=my_cluster_068bc626_my_user_source --group-id my-consumer-group-1669018116 --bootstrap-server my-cluster-068bc626-source-kafka-bootstrap.namespace-131.svc:9093
2022-04-05 02:03:03 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:03:03 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:03:03 [main] [32mINFO [m [MirrorMaker2IsolatedST:544] Setting topic to availability-topic-target-my-topic-495429288-970895480, cluster to my-cluster-068bc626-target and changing user to my-cluster-068bc626-my-user-target
2022-04-05 02:03:03 [main] [32mINFO [m [MirrorMaker2IsolatedST:553] Sending messages to - topic availability-topic-target-my-topic-495429288-970895480, cluster my-cluster-068bc626-target and message count of 200
2022-04-05 02:03:03 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@7326db23, messages=[], arguments=[--topic, availability-topic-target-my-topic-495429288-970895480, --max-messages, 200, USER=my_cluster_068bc626_my_user_target, --bootstrap-server, my-cluster-068bc626-target-kafka-bootstrap.namespace-131.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-068bc626-kafka-clients-5884747b8b-j4d6m', podNamespace='namespace-131', bootstrapServer='my-cluster-068bc626-target-kafka-bootstrap.namespace-131.svc:9093', topicName='availability-topic-target-my-topic-495429288-970895480', maxMessages=200, kafkaUsername='my-cluster-068bc626-my-user-target', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4a8b3029}
2022-04-05 02:03:03 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-068bc626-target-kafka-bootstrap.namespace-131.svc:9093:availability-topic-target-my-topic-495429288-970895480 from pod my-cluster-068bc626-kafka-clients-5884747b8b-j4d6m
2022-04-05 02:03:03 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-068bc626-kafka-clients-5884747b8b-j4d6m -n namespace-131 -- /opt/kafka/producer.sh --topic availability-topic-target-my-topic-495429288-970895480 --max-messages 200 USER=my_cluster_068bc626_my_user_target --bootstrap-server my-cluster-068bc626-target-kafka-bootstrap.namespace-131.svc:9093
2022-04-05 02:03:07 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 02:03:07 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 02:03:07 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2d6f4f40, messages=[], arguments=[--topic, availability-topic-target-my-topic-495429288-970895480, --max-messages, 200, --group-instance-id, instance1599061852, USER=my_cluster_068bc626_my_user_target, --group-id, my-consumer-group-1669018116, --bootstrap-server, my-cluster-068bc626-target-kafka-bootstrap.namespace-131.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-068bc626-kafka-clients-5884747b8b-j4d6m', podNamespace='namespace-131', bootstrapServer='my-cluster-068bc626-target-kafka-bootstrap.namespace-131.svc:9093', topicName='availability-topic-target-my-topic-495429288-970895480', maxMessages=200, kafkaUsername='my-cluster-068bc626-my-user-target', consumerGroupName='my-consumer-group-1669018116', consumerInstanceId='instance1599061852', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@20094520}
2022-04-05 02:03:07 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-068bc626-target-kafka-bootstrap.namespace-131.svc:9093:availability-topic-target-my-topic-495429288-970895480 from pod my-cluster-068bc626-kafka-clients-5884747b8b-j4d6m
2022-04-05 02:03:07 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-068bc626-kafka-clients-5884747b8b-j4d6m -n namespace-131 -- /opt/kafka/consumer.sh --topic availability-topic-target-my-topic-495429288-970895480 --max-messages 200 --group-instance-id instance1599061852 USER=my_cluster_068bc626_my_user_target --group-id my-consumer-group-1669018116 --bootstrap-server my-cluster-068bc626-target-kafka-bootstrap.namespace-131.svc:9093
2022-04-05 02:03:14 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:03:14 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:03:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-068bc626 in namespace namespace-131
2022-04-05 02:03:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-05 02:03:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-068bc626 will have desired state: Ready
2022-04-05 02:04:36 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-068bc626 is in desired state: Ready
2022-04-05 02:04:36 [main] [32mINFO [m [MirrorMaker2IsolatedST:597] Setting topic to mirrormaker2-topic-example-1204224364, cluster to my-cluster-068bc626-source and changing user to my-cluster-068bc626-my-user-source
2022-04-05 02:04:36 [main] [32mINFO [m [MirrorMaker2IsolatedST:606] Sending messages to - topic mirrormaker2-topic-example-1204224364, cluster my-cluster-068bc626-source and message count of 200
2022-04-05 02:04:36 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@6b7cea87, messages=[], arguments=[--topic, mirrormaker2-topic-example-1204224364, --max-messages, 200, USER=my_cluster_068bc626_my_user_source, --bootstrap-server, my-cluster-068bc626-source-kafka-bootstrap.namespace-131.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-068bc626-kafka-clients-5884747b8b-j4d6m', podNamespace='namespace-131', bootstrapServer='my-cluster-068bc626-source-kafka-bootstrap.namespace-131.svc:9093', topicName='mirrormaker2-topic-example-1204224364', maxMessages=200, kafkaUsername='my-cluster-068bc626-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@49006b68}
2022-04-05 02:04:36 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-068bc626-source-kafka-bootstrap.namespace-131.svc:9093:mirrormaker2-topic-example-1204224364 from pod my-cluster-068bc626-kafka-clients-5884747b8b-j4d6m
2022-04-05 02:04:36 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-068bc626-kafka-clients-5884747b8b-j4d6m -n namespace-131 -- /opt/kafka/producer.sh --topic mirrormaker2-topic-example-1204224364 --max-messages 200 USER=my_cluster_068bc626_my_user_source --bootstrap-server my-cluster-068bc626-source-kafka-bootstrap.namespace-131.svc:9093
2022-04-05 02:04:40 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 02:04:40 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 02:04:40 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3af0dbc6, messages=[], arguments=[--topic, mirrormaker2-topic-example-1204224364, --max-messages, 200, --group-instance-id, instance1428678316, USER=my_cluster_068bc626_my_user_source, --group-id, my-consumer-group-1669018116, --bootstrap-server, my-cluster-068bc626-source-kafka-bootstrap.namespace-131.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-068bc626-kafka-clients-5884747b8b-j4d6m', podNamespace='namespace-131', bootstrapServer='my-cluster-068bc626-source-kafka-bootstrap.namespace-131.svc:9093', topicName='mirrormaker2-topic-example-1204224364', maxMessages=200, kafkaUsername='my-cluster-068bc626-my-user-source', consumerGroupName='my-consumer-group-1669018116', consumerInstanceId='instance1428678316', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7061a589}
2022-04-05 02:04:40 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-068bc626-source-kafka-bootstrap.namespace-131.svc:9093:mirrormaker2-topic-example-1204224364 from pod my-cluster-068bc626-kafka-clients-5884747b8b-j4d6m
2022-04-05 02:04:40 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-068bc626-kafka-clients-5884747b8b-j4d6m -n namespace-131 -- /opt/kafka/consumer.sh --topic mirrormaker2-topic-example-1204224364 --max-messages 200 --group-instance-id instance1428678316 USER=my_cluster_068bc626_my_user_source --group-id my-consumer-group-1669018116 --bootstrap-server my-cluster-068bc626-source-kafka-bootstrap.namespace-131.svc:9093
2022-04-05 02:04:47 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:04:47 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:04:47 [main] [32mINFO [m [MirrorMaker2IsolatedST:615] Changing to target - topic my-cluster-068bc626-source.mirrormaker2-topic-example-1204224364, cluster my-cluster-068bc626-target, user my-cluster-068bc626-my-user-target
2022-04-05 02:04:47 [main] [32mINFO [m [MirrorMaker2IsolatedST:623] Now messages should be mirrored to target topic and cluster
2022-04-05 02:04:47 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7b6de1cc, messages=[], arguments=[--topic, my-cluster-068bc626-source.mirrormaker2-topic-example-1204224364, --max-messages, 200, --group-instance-id, instance1917440952, USER=my_cluster_068bc626_my_user_target, --group-id, my-consumer-group-1669018116, --bootstrap-server, my-cluster-068bc626-target-kafka-bootstrap.namespace-131.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-068bc626-kafka-clients-5884747b8b-j4d6m', podNamespace='namespace-131', bootstrapServer='my-cluster-068bc626-target-kafka-bootstrap.namespace-131.svc:9093', topicName='my-cluster-068bc626-source.mirrormaker2-topic-example-1204224364', maxMessages=200, kafkaUsername='my-cluster-068bc626-my-user-target', consumerGroupName='my-consumer-group-1669018116', consumerInstanceId='instance1917440952', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@36d436cd}
2022-04-05 02:04:47 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-068bc626-target-kafka-bootstrap.namespace-131.svc:9093:my-cluster-068bc626-source.mirrormaker2-topic-example-1204224364 from pod my-cluster-068bc626-kafka-clients-5884747b8b-j4d6m
2022-04-05 02:04:47 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-068bc626-kafka-clients-5884747b8b-j4d6m -n namespace-131 -- /opt/kafka/consumer.sh --topic my-cluster-068bc626-source.mirrormaker2-topic-example-1204224364 --max-messages 200 --group-instance-id instance1917440952 USER=my_cluster_068bc626_my_user_target --group-id my-consumer-group-1669018116 --bootstrap-server my-cluster-068bc626-target-kafka-bootstrap.namespace-131.svc:9093
2022-04-05 02:04:54 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:04:54 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:04:54 [main] [32mINFO [m [MirrorMaker2IsolatedST:628] Messages successfully mirrored
2022-04-05 02:04:54 [main] [32mINFO [m [KafkaTopicUtils:78] Waiting for KafkaTopic my-cluster-068bc626-source.mirrormaker2-topic-example-1204224364 creation 
2022-04-05 02:04:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 02:04:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker2TlsAndScramSha512Auth
2022-04-05 02:04:54 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-068bc626-my-user-target in namespace namespace-131
2022-04-05 02:04:54 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-068bc626-kafka-clients in namespace namespace-131
2022-04-05 02:04:54 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-068bc626 in namespace namespace-131
2022-04-05 02:04:54 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-068bc626-my-user-source in namespace namespace-131
2022-04-05 02:04:54 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-068bc626-source in namespace namespace-131
2022-04-05 02:04:54 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-1204224364 in namespace namespace-131
2022-04-05 02:04:54 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-068bc626-target in namespace namespace-131
2022-04-05 02:05:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 02:05:44 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-131 for test case:testMirrorMaker2TlsAndScramSha512Auth
2022-04-05 02:05:50 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2TlsAndScramSha512Auth-FINISHED
2022-04-05 02:05:50 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 02:05:50 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 02:05:50 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testScaleMirrorMaker2ToZero-STARTED
2022-04-05 02:05:50 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 02:05:50 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-132 for test case:testScaleMirrorMaker2ToZero
2022-04-05 02:05:50 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-132
2022-04-05 02:05:50 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-132
2022-04-05 02:05:50 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-132
2022-04-05 02:05:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7653c469-source in namespace namespace-132
2022-04-05 02:05:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-132
2022-04-05 02:05:50 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7653c469-source will have desired state: Ready
2022-04-05 02:06:57 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7653c469-source is in desired state: Ready
2022-04-05 02:06:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7653c469-target in namespace namespace-132
2022-04-05 02:06:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-132
2022-04-05 02:06:57 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7653c469-target will have desired state: Ready
2022-04-05 02:08:05 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7653c469-target is in desired state: Ready
2022-04-05 02:08:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-7653c469 in namespace namespace-132
2022-04-05 02:08:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-132
2022-04-05 02:08:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-7653c469 will have desired state: Ready
2022-04-05 02:09:12 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-7653c469 is in desired state: Ready
2022-04-05 02:09:12 [main] [32mINFO [m [MirrorMaker2IsolatedST:781] Scaling MirrorMaker2 to zero
2022-04-05 02:09:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 02:09:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleMirrorMaker2ToZero
2022-04-05 02:09:25 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7653c469-target in namespace namespace-132
2022-04-05 02:09:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-7653c469 in namespace namespace-132
2022-04-05 02:09:25 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7653c469-source in namespace namespace-132
2022-04-05 02:09:45 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 02:09:45 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-132 for test case:testScaleMirrorMaker2ToZero
2022-04-05 02:10:12 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testScaleMirrorMaker2ToZero-FINISHED
2022-04-05 02:10:12 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 02:10:12 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 02:10:12 [main] [32mINFO [m [ResourceManager:346] In context MirrorMaker2IsolatedST is everything deleted.
2022-04-05 02:10:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5,556.216 s - in io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST
2022-04-05 02:10:12 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 02:10:37 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-05 02:10:37 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-05 02:10:37 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-05 02:10:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 02:10:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-05 02:10:37 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 02:10:37 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 02:10:37 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 02:10:37 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 02:10:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 02:10:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 02:10:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 02:10:37 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 02:10:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 02:10:37 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 02:10:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 02:10:37 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 02:10:37 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 02:10:37 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 02:10:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 02:10:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 02:10:37 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 02:10:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 02:10:37 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 02:10:47 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 02:10:47 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 02:10:47 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 02:10:47 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 02:10:47 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 02:10:47 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 02:10:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 02:11:02 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=120000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-05 02:11:02 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-05 02:11:02 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-05 02:11:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 02:11:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 02:11:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 02:11:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 02:11:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 02:11:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 02:11:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 02:11:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 02:11:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 02:11:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 02:11:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 02:11:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 02:11:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 02:11:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 02:11:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 02:11:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 02:11:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 02:11:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 02:11:03 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-05 02:11:03 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 02:11:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 02:11:03 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-05 02:11:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 02:11:03 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-05 02:11:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 02:11:03 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 02:11:03 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 02:11:03 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-05 02:11:03 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 02:11:03 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 02:11:03 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 02:11:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 02:11:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 02:11:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 02:11:03 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-05 02:11:26 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-05 02:11:26 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-05 02:11:36 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-05 02:11:36 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 02:11:36 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMakerTlsAuthenticated-STARTED
2022-04-05 02:11:36 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 02:11:36 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-133 for test case:testMirrorMakerTlsAuthenticated
2022-04-05 02:11:36 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-133
2022-04-05 02:11:36 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-133
2022-04-05 02:11:36 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-133
2022-04-05 02:11:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-37487b4e-source in namespace namespace-133
2022-04-05 02:11:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-05 02:11:36 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-37487b4e-source will have desired state: Ready
2022-04-05 02:12:51 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-37487b4e-source is in desired state: Ready
2022-04-05 02:12:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-37487b4e-target in namespace namespace-133
2022-04-05 02:12:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-05 02:12:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-37487b4e-target will have desired state: Ready
2022-04-05 02:14:06 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-37487b4e-target is in desired state: Ready
2022-04-05 02:14:06 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-335653399-1112350690-source-996691668 in namespace namespace-133
2022-04-05 02:14:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-05 02:14:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-335653399-1112350690-source-996691668 will have desired state: Ready
2022-04-05 02:14:07 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-335653399-1112350690-source-996691668 is in desired state: Ready
2022-04-05 02:14:07 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-37487b4e-my-user-source in namespace namespace-133
2022-04-05 02:14:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-05 02:14:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-37487b4e-my-user-source will have desired state: Ready
2022-04-05 02:14:08 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-37487b4e-my-user-source is in desired state: Ready
2022-04-05 02:14:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-37487b4e-my-user-target in namespace namespace-133
2022-04-05 02:14:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-05 02:14:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-37487b4e-my-user-target will have desired state: Ready
2022-04-05 02:14:09 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-37487b4e-my-user-target is in desired state: Ready
2022-04-05 02:14:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-37487b4e-kafka-clients in namespace namespace-133
2022-04-05 02:14:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-05 02:14:09 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-37487b4e-kafka-clients will be ready
2022-04-05 02:14:11 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-37487b4e-kafka-clients is ready
2022-04-05 02:14:11 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2145179786-986801311-test-1 in namespace namespace-133
2022-04-05 02:14:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-05 02:14:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2145179786-986801311-test-1 will have desired state: Ready
2022-04-05 02:14:12 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2145179786-986801311-test-1 is in desired state: Ready
2022-04-05 02:14:12 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2145179786-986801311-test-2 in namespace namespace-133
2022-04-05 02:14:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-05 02:14:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2145179786-986801311-test-2 will have desired state: Ready
2022-04-05 02:14:13 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2145179786-986801311-test-2 is in desired state: Ready
2022-04-05 02:14:13 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 02:14:13 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@2828091c, messages=[], arguments=[--topic, my-topic-2145179786-986801311-test-1, --max-messages, 200, USER=my_cluster_37487b4e_my_user_source, --bootstrap-server, my-cluster-37487b4e-source-kafka-bootstrap.namespace-133.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-37487b4e-kafka-clients-67b796bf4-wdrbm', podNamespace='namespace-133', bootstrapServer='my-cluster-37487b4e-source-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-2145179786-986801311-test-1', maxMessages=200, kafkaUsername='my-cluster-37487b4e-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6b56e6d}
2022-04-05 02:14:13 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-37487b4e-source-kafka-bootstrap.namespace-133.svc:9093:my-topic-2145179786-986801311-test-1 from pod my-cluster-37487b4e-kafka-clients-67b796bf4-wdrbm
2022-04-05 02:14:13 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-37487b4e-kafka-clients-67b796bf4-wdrbm -n namespace-133 -- /opt/kafka/producer.sh --topic my-topic-2145179786-986801311-test-1 --max-messages 200 USER=my_cluster_37487b4e_my_user_source --bootstrap-server my-cluster-37487b4e-source-kafka-bootstrap.namespace-133.svc:9093
2022-04-05 02:14:16 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 02:14:16 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 02:14:16 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@d740942, messages=[], arguments=[--topic, my-topic-2145179786-986801311-test-1, --max-messages, 200, --group-instance-id, instance1372043052, USER=my_cluster_37487b4e_my_user_source, --group-id, my-consumer-group-1804505137, --bootstrap-server, my-cluster-37487b4e-source-kafka-bootstrap.namespace-133.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-37487b4e-kafka-clients-67b796bf4-wdrbm', podNamespace='namespace-133', bootstrapServer='my-cluster-37487b4e-source-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-2145179786-986801311-test-1', maxMessages=200, kafkaUsername='my-cluster-37487b4e-my-user-source', consumerGroupName='my-consumer-group-1804505137', consumerInstanceId='instance1372043052', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@201fdd2a}
2022-04-05 02:14:16 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-37487b4e-source-kafka-bootstrap.namespace-133.svc:9093:my-topic-2145179786-986801311-test-1 from pod my-cluster-37487b4e-kafka-clients-67b796bf4-wdrbm
2022-04-05 02:14:16 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-37487b4e-kafka-clients-67b796bf4-wdrbm -n namespace-133 -- /opt/kafka/consumer.sh --topic my-topic-2145179786-986801311-test-1 --max-messages 200 --group-instance-id instance1372043052 USER=my_cluster_37487b4e_my_user_source --group-id my-consumer-group-1804505137 --bootstrap-server my-cluster-37487b4e-source-kafka-bootstrap.namespace-133.svc:9093
2022-04-05 02:14:23 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:14:23 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:14:23 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@730da3d8, messages=[], arguments=[--topic, my-topic-2145179786-986801311-test-2, --max-messages, 200, USER=my_cluster_37487b4e_my_user_target, --bootstrap-server, my-cluster-37487b4e-target-kafka-bootstrap.namespace-133.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-37487b4e-kafka-clients-67b796bf4-wdrbm', podNamespace='namespace-133', bootstrapServer='my-cluster-37487b4e-target-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-2145179786-986801311-test-2', maxMessages=200, kafkaUsername='my-cluster-37487b4e-my-user-target', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@65fc8119}
2022-04-05 02:14:23 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-37487b4e-target-kafka-bootstrap.namespace-133.svc:9093:my-topic-2145179786-986801311-test-2 from pod my-cluster-37487b4e-kafka-clients-67b796bf4-wdrbm
2022-04-05 02:14:23 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-37487b4e-kafka-clients-67b796bf4-wdrbm -n namespace-133 -- /opt/kafka/producer.sh --topic my-topic-2145179786-986801311-test-2 --max-messages 200 USER=my_cluster_37487b4e_my_user_target --bootstrap-server my-cluster-37487b4e-target-kafka-bootstrap.namespace-133.svc:9093
2022-04-05 02:14:27 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 02:14:27 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 02:14:27 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@36f4f1, messages=[], arguments=[--topic, my-topic-2145179786-986801311-test-2, --max-messages, 200, --group-instance-id, instance636894814, USER=my_cluster_37487b4e_my_user_target, --group-id, my-consumer-group-1305770182, --bootstrap-server, my-cluster-37487b4e-target-kafka-bootstrap.namespace-133.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-37487b4e-kafka-clients-67b796bf4-wdrbm', podNamespace='namespace-133', bootstrapServer='my-cluster-37487b4e-target-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-2145179786-986801311-test-2', maxMessages=200, kafkaUsername='my-cluster-37487b4e-my-user-target', consumerGroupName='my-consumer-group-1305770182', consumerInstanceId='instance636894814', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2da5d61e}
2022-04-05 02:14:27 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-37487b4e-target-kafka-bootstrap.namespace-133.svc:9093:my-topic-2145179786-986801311-test-2 from pod my-cluster-37487b4e-kafka-clients-67b796bf4-wdrbm
2022-04-05 02:14:27 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-37487b4e-kafka-clients-67b796bf4-wdrbm -n namespace-133 -- /opt/kafka/consumer.sh --topic my-topic-2145179786-986801311-test-2 --max-messages 200 --group-instance-id instance636894814 USER=my_cluster_37487b4e_my_user_target --group-id my-consumer-group-1305770182 --bootstrap-server my-cluster-37487b4e-target-kafka-bootstrap.namespace-133.svc:9093
2022-04-05 02:14:34 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:14:34 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:14:34 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-37487b4e in namespace namespace-133
2022-04-05 02:14:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-05 02:14:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-37487b4e will have desired state: Ready
2022-04-05 02:15:43 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-37487b4e is in desired state: Ready
2022-04-05 02:15:43 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@4d04df35, messages=[], arguments=[--topic, my-topic-335653399-1112350690-source-996691668, --max-messages, 200, USER=my_cluster_37487b4e_my_user_source, --bootstrap-server, my-cluster-37487b4e-source-kafka-bootstrap.namespace-133.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-37487b4e-kafka-clients-67b796bf4-wdrbm', podNamespace='namespace-133', bootstrapServer='my-cluster-37487b4e-source-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-335653399-1112350690-source-996691668', maxMessages=200, kafkaUsername='my-cluster-37487b4e-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@379fe6a3}
2022-04-05 02:15:43 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-37487b4e-source-kafka-bootstrap.namespace-133.svc:9093:my-topic-335653399-1112350690-source-996691668 from pod my-cluster-37487b4e-kafka-clients-67b796bf4-wdrbm
2022-04-05 02:15:43 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-37487b4e-kafka-clients-67b796bf4-wdrbm -n namespace-133 -- /opt/kafka/producer.sh --topic my-topic-335653399-1112350690-source-996691668 --max-messages 200 USER=my_cluster_37487b4e_my_user_source --bootstrap-server my-cluster-37487b4e-source-kafka-bootstrap.namespace-133.svc:9093
2022-04-05 02:15:47 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 02:15:47 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 02:15:47 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@54871d2f, messages=[], arguments=[--topic, my-topic-335653399-1112350690-source-996691668, --max-messages, 200, --group-instance-id, instance257267270, USER=my_cluster_37487b4e_my_user_source, --group-id, my-consumer-group-421595874, --bootstrap-server, my-cluster-37487b4e-source-kafka-bootstrap.namespace-133.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-37487b4e-kafka-clients-67b796bf4-wdrbm', podNamespace='namespace-133', bootstrapServer='my-cluster-37487b4e-source-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-335653399-1112350690-source-996691668', maxMessages=200, kafkaUsername='my-cluster-37487b4e-my-user-source', consumerGroupName='my-consumer-group-421595874', consumerInstanceId='instance257267270', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1c654afe}
2022-04-05 02:15:47 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-37487b4e-source-kafka-bootstrap.namespace-133.svc:9093:my-topic-335653399-1112350690-source-996691668 from pod my-cluster-37487b4e-kafka-clients-67b796bf4-wdrbm
2022-04-05 02:15:47 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-37487b4e-kafka-clients-67b796bf4-wdrbm -n namespace-133 -- /opt/kafka/consumer.sh --topic my-topic-335653399-1112350690-source-996691668 --max-messages 200 --group-instance-id instance257267270 USER=my_cluster_37487b4e_my_user_source --group-id my-consumer-group-421595874 --bootstrap-server my-cluster-37487b4e-source-kafka-bootstrap.namespace-133.svc:9093
2022-04-05 02:15:54 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:15:54 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:15:54 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5a12f988, messages=[], arguments=[--topic, my-topic-335653399-1112350690-source-996691668, --max-messages, 200, --group-instance-id, instance1053845774, USER=my_cluster_37487b4e_my_user_target, --group-id, my-consumer-group-1838357836, --bootstrap-server, my-cluster-37487b4e-target-kafka-bootstrap.namespace-133.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-37487b4e-kafka-clients-67b796bf4-wdrbm', podNamespace='namespace-133', bootstrapServer='my-cluster-37487b4e-target-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-335653399-1112350690-source-996691668', maxMessages=200, kafkaUsername='my-cluster-37487b4e-my-user-target', consumerGroupName='my-consumer-group-1838357836', consumerInstanceId='instance1053845774', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3f919dfd}
2022-04-05 02:15:54 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-37487b4e-target-kafka-bootstrap.namespace-133.svc:9093:my-topic-335653399-1112350690-source-996691668 from pod my-cluster-37487b4e-kafka-clients-67b796bf4-wdrbm
2022-04-05 02:15:54 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-37487b4e-kafka-clients-67b796bf4-wdrbm -n namespace-133 -- /opt/kafka/consumer.sh --topic my-topic-335653399-1112350690-source-996691668 --max-messages 200 --group-instance-id instance1053845774 USER=my_cluster_37487b4e_my_user_target --group-id my-consumer-group-1838357836 --bootstrap-server my-cluster-37487b4e-target-kafka-bootstrap.namespace-133.svc:9093
2022-04-05 02:16:01 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:16:01 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:16:01 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 02:16:01 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMakerTlsAuthenticated
2022-04-05 02:16:01 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-37487b4e-kafka-clients in namespace namespace-133
2022-04-05 02:16:01 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-37487b4e-my-user-target in namespace namespace-133
2022-04-05 02:16:01 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2145179786-986801311-test-2 in namespace namespace-133
2022-04-05 02:16:01 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-37487b4e-source in namespace namespace-133
2022-04-05 02:16:01 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-37487b4e-target in namespace namespace-133
2022-04-05 02:16:01 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2145179786-986801311-test-1 in namespace namespace-133
2022-04-05 02:16:01 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-335653399-1112350690-source-996691668 in namespace namespace-133
2022-04-05 02:16:01 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-37487b4e-my-user-source in namespace namespace-133
2022-04-05 02:16:11 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-37487b4e in namespace namespace-133
2022-04-05 02:16:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 02:16:51 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-133 for test case:testMirrorMakerTlsAuthenticated
2022-04-05 02:16:56 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMakerTlsAuthenticated-FINISHED
2022-04-05 02:16:56 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 02:16:56 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 02:16:56 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMakerTlsScramSha-STARTED
2022-04-05 02:16:56 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 02:16:56 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-134 for test case:testMirrorMakerTlsScramSha
2022-04-05 02:16:56 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-134
2022-04-05 02:16:56 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-134
2022-04-05 02:16:56 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-134
2022-04-05 02:16:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2d6750d1-source in namespace namespace-134
2022-04-05 02:16:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-05 02:16:56 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2d6750d1-source will have desired state: Ready
2022-04-05 02:17:57 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2d6750d1-source is in desired state: Ready
2022-04-05 02:17:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2d6750d1-target in namespace namespace-134
2022-04-05 02:17:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-05 02:17:57 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2d6750d1-target will have desired state: Ready
2022-04-05 02:19:04 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2d6750d1-target is in desired state: Ready
2022-04-05 02:19:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1886493236-1451464049 in namespace namespace-134
2022-04-05 02:19:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-05 02:19:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1886493236-1451464049 will have desired state: Ready
2022-04-05 02:19:05 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1886493236-1451464049 is in desired state: Ready
2022-04-05 02:19:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-2d6750d1-my-user-source in namespace namespace-134
2022-04-05 02:19:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-05 02:19:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-2d6750d1-my-user-source will have desired state: Ready
2022-04-05 02:19:06 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-2d6750d1-my-user-source is in desired state: Ready
2022-04-05 02:19:06 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-2d6750d1-my-user-target in namespace namespace-134
2022-04-05 02:19:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-05 02:19:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-2d6750d1-my-user-target will have desired state: Ready
2022-04-05 02:19:07 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-2d6750d1-my-user-target is in desired state: Ready
2022-04-05 02:19:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-2d6750d1-kafka-clients in namespace namespace-134
2022-04-05 02:19:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-05 02:19:07 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-2d6750d1-kafka-clients will be ready
2022-04-05 02:19:09 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-2d6750d1-kafka-clients is ready
2022-04-05 02:19:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1886493236-1451464049-test-1 in namespace namespace-134
2022-04-05 02:19:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-05 02:19:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1886493236-1451464049-test-1 will have desired state: Ready
2022-04-05 02:19:10 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1886493236-1451464049-test-1 is in desired state: Ready
2022-04-05 02:19:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1886493236-1451464049-test-2 in namespace namespace-134
2022-04-05 02:19:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-05 02:19:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1886493236-1451464049-test-2 will have desired state: Ready
2022-04-05 02:19:11 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1886493236-1451464049-test-2 is in desired state: Ready
2022-04-05 02:19:11 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 02:19:11 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@40decfff, messages=[], arguments=[--topic, my-topic-1886493236-1451464049-test-1, --max-messages, 200, USER=my_cluster_2d6750d1_my_user_source, --bootstrap-server, my-cluster-2d6750d1-source-kafka-bootstrap.namespace-134.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-2d6750d1-kafka-clients-5d44f8d455-cvb9f', podNamespace='namespace-134', bootstrapServer='my-cluster-2d6750d1-source-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-1886493236-1451464049-test-1', maxMessages=200, kafkaUsername='my-cluster-2d6750d1-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@56cfd01b}
2022-04-05 02:19:11 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-2d6750d1-source-kafka-bootstrap.namespace-134.svc:9093:my-topic-1886493236-1451464049-test-1 from pod my-cluster-2d6750d1-kafka-clients-5d44f8d455-cvb9f
2022-04-05 02:19:11 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2d6750d1-kafka-clients-5d44f8d455-cvb9f -n namespace-134 -- /opt/kafka/producer.sh --topic my-topic-1886493236-1451464049-test-1 --max-messages 200 USER=my_cluster_2d6750d1_my_user_source --bootstrap-server my-cluster-2d6750d1-source-kafka-bootstrap.namespace-134.svc:9093
2022-04-05 02:19:15 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 02:19:15 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 02:19:15 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@a79e25c, messages=[], arguments=[--topic, my-topic-1886493236-1451464049-test-1, --max-messages, 200, --group-instance-id, instance741023167, USER=my_cluster_2d6750d1_my_user_source, --group-id, my-consumer-group-362264462, --bootstrap-server, my-cluster-2d6750d1-source-kafka-bootstrap.namespace-134.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-2d6750d1-kafka-clients-5d44f8d455-cvb9f', podNamespace='namespace-134', bootstrapServer='my-cluster-2d6750d1-source-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-1886493236-1451464049-test-1', maxMessages=200, kafkaUsername='my-cluster-2d6750d1-my-user-source', consumerGroupName='my-consumer-group-362264462', consumerInstanceId='instance741023167', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@221eb10c}
2022-04-05 02:19:15 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-2d6750d1-source-kafka-bootstrap.namespace-134.svc:9093:my-topic-1886493236-1451464049-test-1 from pod my-cluster-2d6750d1-kafka-clients-5d44f8d455-cvb9f
2022-04-05 02:19:15 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2d6750d1-kafka-clients-5d44f8d455-cvb9f -n namespace-134 -- /opt/kafka/consumer.sh --topic my-topic-1886493236-1451464049-test-1 --max-messages 200 --group-instance-id instance741023167 USER=my_cluster_2d6750d1_my_user_source --group-id my-consumer-group-362264462 --bootstrap-server my-cluster-2d6750d1-source-kafka-bootstrap.namespace-134.svc:9093
2022-04-05 02:19:22 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:19:22 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:19:22 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1d8bc4, messages=[], arguments=[--topic, my-topic-1886493236-1451464049-test-2, --max-messages, 200, USER=my_cluster_2d6750d1_my_user_target, --bootstrap-server, my-cluster-2d6750d1-target-kafka-bootstrap.namespace-134.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-2d6750d1-kafka-clients-5d44f8d455-cvb9f', podNamespace='namespace-134', bootstrapServer='my-cluster-2d6750d1-target-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-1886493236-1451464049-test-2', maxMessages=200, kafkaUsername='my-cluster-2d6750d1-my-user-target', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3c6e65db}
2022-04-05 02:19:22 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-2d6750d1-target-kafka-bootstrap.namespace-134.svc:9093:my-topic-1886493236-1451464049-test-2 from pod my-cluster-2d6750d1-kafka-clients-5d44f8d455-cvb9f
2022-04-05 02:19:22 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2d6750d1-kafka-clients-5d44f8d455-cvb9f -n namespace-134 -- /opt/kafka/producer.sh --topic my-topic-1886493236-1451464049-test-2 --max-messages 200 USER=my_cluster_2d6750d1_my_user_target --bootstrap-server my-cluster-2d6750d1-target-kafka-bootstrap.namespace-134.svc:9093
2022-04-05 02:19:25 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 02:19:25 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 02:19:25 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@12f2afbf, messages=[], arguments=[--topic, my-topic-1886493236-1451464049-test-2, --max-messages, 200, --group-instance-id, instance1226214095, USER=my_cluster_2d6750d1_my_user_target, --group-id, my-consumer-group-1255078975, --bootstrap-server, my-cluster-2d6750d1-target-kafka-bootstrap.namespace-134.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-2d6750d1-kafka-clients-5d44f8d455-cvb9f', podNamespace='namespace-134', bootstrapServer='my-cluster-2d6750d1-target-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-1886493236-1451464049-test-2', maxMessages=200, kafkaUsername='my-cluster-2d6750d1-my-user-target', consumerGroupName='my-consumer-group-1255078975', consumerInstanceId='instance1226214095', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@57dccc1a}
2022-04-05 02:19:25 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-2d6750d1-target-kafka-bootstrap.namespace-134.svc:9093:my-topic-1886493236-1451464049-test-2 from pod my-cluster-2d6750d1-kafka-clients-5d44f8d455-cvb9f
2022-04-05 02:19:25 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2d6750d1-kafka-clients-5d44f8d455-cvb9f -n namespace-134 -- /opt/kafka/consumer.sh --topic my-topic-1886493236-1451464049-test-2 --max-messages 200 --group-instance-id instance1226214095 USER=my_cluster_2d6750d1_my_user_target --group-id my-consumer-group-1255078975 --bootstrap-server my-cluster-2d6750d1-target-kafka-bootstrap.namespace-134.svc:9093
2022-04-05 02:19:32 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:19:32 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:19:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-2d6750d1 in namespace namespace-134
2022-04-05 02:19:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-05 02:19:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-2d6750d1 will have desired state: Ready
2022-04-05 02:20:42 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-2d6750d1 is in desired state: Ready
2022-04-05 02:20:42 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@147519d2, messages=[], arguments=[--topic, my-topic-1886493236-1451464049, --max-messages, 200, USER=my_cluster_2d6750d1_my_user_source, --bootstrap-server, my-cluster-2d6750d1-source-kafka-bootstrap.namespace-134.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-2d6750d1-kafka-clients-5d44f8d455-cvb9f', podNamespace='namespace-134', bootstrapServer='my-cluster-2d6750d1-source-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-1886493236-1451464049', maxMessages=200, kafkaUsername='my-cluster-2d6750d1-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3099dc9d}
2022-04-05 02:20:42 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-2d6750d1-source-kafka-bootstrap.namespace-134.svc:9093:my-topic-1886493236-1451464049 from pod my-cluster-2d6750d1-kafka-clients-5d44f8d455-cvb9f
2022-04-05 02:20:42 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2d6750d1-kafka-clients-5d44f8d455-cvb9f -n namespace-134 -- /opt/kafka/producer.sh --topic my-topic-1886493236-1451464049 --max-messages 200 USER=my_cluster_2d6750d1_my_user_source --bootstrap-server my-cluster-2d6750d1-source-kafka-bootstrap.namespace-134.svc:9093
2022-04-05 02:20:45 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 02:20:45 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 02:20:45 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2bf85ae6, messages=[], arguments=[--topic, my-topic-1886493236-1451464049, --max-messages, 200, --group-instance-id, instance1524994868, USER=my_cluster_2d6750d1_my_user_source, --group-id, my-consumer-group-1157431342, --bootstrap-server, my-cluster-2d6750d1-source-kafka-bootstrap.namespace-134.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-2d6750d1-kafka-clients-5d44f8d455-cvb9f', podNamespace='namespace-134', bootstrapServer='my-cluster-2d6750d1-source-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-1886493236-1451464049', maxMessages=200, kafkaUsername='my-cluster-2d6750d1-my-user-source', consumerGroupName='my-consumer-group-1157431342', consumerInstanceId='instance1524994868', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@557b09e0}
2022-04-05 02:20:45 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-2d6750d1-source-kafka-bootstrap.namespace-134.svc:9093:my-topic-1886493236-1451464049 from pod my-cluster-2d6750d1-kafka-clients-5d44f8d455-cvb9f
2022-04-05 02:20:45 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2d6750d1-kafka-clients-5d44f8d455-cvb9f -n namespace-134 -- /opt/kafka/consumer.sh --topic my-topic-1886493236-1451464049 --max-messages 200 --group-instance-id instance1524994868 USER=my_cluster_2d6750d1_my_user_source --group-id my-consumer-group-1157431342 --bootstrap-server my-cluster-2d6750d1-source-kafka-bootstrap.namespace-134.svc:9093
2022-04-05 02:20:52 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:20:52 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:20:52 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@36b073a5, messages=[], arguments=[--topic, my-topic-1886493236-1451464049, --max-messages, 200, --group-instance-id, instance917870026, USER=my_cluster_2d6750d1_my_user_target, --group-id, my-consumer-group-2013195241, --bootstrap-server, my-cluster-2d6750d1-target-kafka-bootstrap.namespace-134.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-2d6750d1-kafka-clients-5d44f8d455-cvb9f', podNamespace='namespace-134', bootstrapServer='my-cluster-2d6750d1-target-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-1886493236-1451464049', maxMessages=200, kafkaUsername='my-cluster-2d6750d1-my-user-target', consumerGroupName='my-consumer-group-2013195241', consumerInstanceId='instance917870026', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@17ff6dc2}
2022-04-05 02:20:52 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-2d6750d1-target-kafka-bootstrap.namespace-134.svc:9093:my-topic-1886493236-1451464049 from pod my-cluster-2d6750d1-kafka-clients-5d44f8d455-cvb9f
2022-04-05 02:20:52 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2d6750d1-kafka-clients-5d44f8d455-cvb9f -n namespace-134 -- /opt/kafka/consumer.sh --topic my-topic-1886493236-1451464049 --max-messages 200 --group-instance-id instance917870026 USER=my_cluster_2d6750d1_my_user_target --group-id my-consumer-group-2013195241 --bootstrap-server my-cluster-2d6750d1-target-kafka-bootstrap.namespace-134.svc:9093
2022-04-05 02:20:59 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:20:59 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:20:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 02:20:59 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMakerTlsScramSha
2022-04-05 02:20:59 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-2d6750d1-kafka-clients in namespace namespace-134
2022-04-05 02:20:59 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2d6750d1-source in namespace namespace-134
2022-04-05 02:20:59 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-2d6750d1-my-user-source in namespace namespace-134
2022-04-05 02:20:59 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1886493236-1451464049 in namespace namespace-134
2022-04-05 02:20:59 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2d6750d1-target in namespace namespace-134
2022-04-05 02:20:59 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1886493236-1451464049-test-2 in namespace namespace-134
2022-04-05 02:20:59 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-2d6750d1-my-user-target in namespace namespace-134
2022-04-05 02:20:59 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1886493236-1451464049-test-1 in namespace namespace-134
2022-04-05 02:21:09 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-2d6750d1 in namespace namespace-134
2022-04-05 02:21:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 02:21:49 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-134 for test case:testMirrorMakerTlsScramSha
2022-04-05 02:21:55 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMakerTlsScramSha-FINISHED
2022-04-05 02:21:55 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 02:21:55 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 02:21:55 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testIncludeList-STARTED
2022-04-05 02:21:55 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 02:21:55 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-135 for test case:testIncludeList
2022-04-05 02:21:55 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-135
2022-04-05 02:21:55 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-135
2022-04-05 02:21:55 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-135
2022-04-05 02:21:55 [main] [32mINFO [m [MirrorMakerIsolatedST:471] Creating kafka source cluster my-cluster-0cd39a24-source
2022-04-05 02:21:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0cd39a24-source in namespace namespace-135
2022-04-05 02:21:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-135
2022-04-05 02:21:55 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0cd39a24-source will have desired state: Ready
2022-04-05 02:23:06 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0cd39a24-source is in desired state: Ready
2022-04-05 02:23:06 [main] [32mINFO [m [MirrorMakerIsolatedST:473] Creating kafka target cluster my-cluster-0cd39a24-target
2022-04-05 02:23:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0cd39a24-target in namespace namespace-135
2022-04-05 02:23:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-135
2022-04-05 02:23:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0cd39a24-target will have desired state: Ready
2022-04-05 02:24:11 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0cd39a24-target is in desired state: Ready
2022-04-05 02:24:11 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic included-topic in namespace namespace-135
2022-04-05 02:24:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-135
2022-04-05 02:24:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: included-topic will have desired state: Ready
2022-04-05 02:24:12 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: included-topic is in desired state: Ready
2022-04-05 02:24:12 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic not-included-topic in namespace namespace-135
2022-04-05 02:24:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-135
2022-04-05 02:24:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: not-included-topic will have desired state: Ready
2022-04-05 02:24:13 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: not-included-topic is in desired state: Ready
2022-04-05 02:24:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-0cd39a24-kafka-clients in namespace namespace-135
2022-04-05 02:24:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-135
2022-04-05 02:24:13 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-0cd39a24-kafka-clients will be ready
2022-04-05 02:24:15 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-0cd39a24-kafka-clients is ready
2022-04-05 02:24:15 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@6b1493b7, messages=[], arguments=[--topic, topic-example-10, --max-messages, 200, --bootstrap-server, my-cluster-0cd39a24-source-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-0cd39a24-kafka-clients-7cb9b65f64-5tvm4', podNamespace='namespace-135', bootstrapServer='my-cluster-0cd39a24-source-kafka-bootstrap.namespace-135.svc:9092', topicName='topic-example-10', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2f65c9db}
2022-04-05 02:24:15 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-0cd39a24-source-kafka-bootstrap.namespace-135.svc:9092:topic-example-10 from pod my-cluster-0cd39a24-kafka-clients-7cb9b65f64-5tvm4
2022-04-05 02:24:15 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0cd39a24-kafka-clients-7cb9b65f64-5tvm4 -n namespace-135 -- /opt/kafka/producer.sh --topic topic-example-10 --max-messages 200 --bootstrap-server my-cluster-0cd39a24-source-kafka-bootstrap.namespace-135.svc:9092
2022-04-05 02:24:17 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 02:24:17 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-05 02:24:17 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4e02b1f4, messages=[], arguments=[--topic, topic-example-10, --max-messages, 200, --group-instance-id, instance1181931601, --group-id, my-consumer-group-1066971128, --bootstrap-server, my-cluster-0cd39a24-source-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-0cd39a24-kafka-clients-7cb9b65f64-5tvm4', podNamespace='namespace-135', bootstrapServer='my-cluster-0cd39a24-source-kafka-bootstrap.namespace-135.svc:9092', topicName='topic-example-10', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-1066971128', consumerInstanceId='instance1181931601', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4fa892cb}
2022-04-05 02:24:17 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-0cd39a24-source-kafka-bootstrap.namespace-135.svc:9092#topic-example-10 from pod my-cluster-0cd39a24-kafka-clients-7cb9b65f64-5tvm4
2022-04-05 02:24:17 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0cd39a24-kafka-clients-7cb9b65f64-5tvm4 -n namespace-135 -- /opt/kafka/consumer.sh --topic topic-example-10 --max-messages 200 --group-instance-id instance1181931601 --group-id my-consumer-group-1066971128 --bootstrap-server my-cluster-0cd39a24-source-kafka-bootstrap.namespace-135.svc:9092
2022-04-05 02:24:23 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 02:24:23 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-05 02:24:23 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@7ac0d5e1, messages=[], arguments=[--topic, topic-example-11, --max-messages, 200, --bootstrap-server, my-cluster-0cd39a24-target-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-0cd39a24-kafka-clients-7cb9b65f64-5tvm4', podNamespace='namespace-135', bootstrapServer='my-cluster-0cd39a24-target-kafka-bootstrap.namespace-135.svc:9092', topicName='topic-example-11', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1441aa8}
2022-04-05 02:24:23 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-0cd39a24-target-kafka-bootstrap.namespace-135.svc:9092:topic-example-11 from pod my-cluster-0cd39a24-kafka-clients-7cb9b65f64-5tvm4
2022-04-05 02:24:23 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0cd39a24-kafka-clients-7cb9b65f64-5tvm4 -n namespace-135 -- /opt/kafka/producer.sh --topic topic-example-11 --max-messages 200 --bootstrap-server my-cluster-0cd39a24-target-kafka-bootstrap.namespace-135.svc:9092
2022-04-05 02:24:25 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 02:24:25 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-05 02:24:25 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2aa3ac73, messages=[], arguments=[--topic, topic-example-11, --max-messages, 200, --group-instance-id, instance1633569369, --group-id, my-consumer-group-47683739, --bootstrap-server, my-cluster-0cd39a24-target-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-0cd39a24-kafka-clients-7cb9b65f64-5tvm4', podNamespace='namespace-135', bootstrapServer='my-cluster-0cd39a24-target-kafka-bootstrap.namespace-135.svc:9092', topicName='topic-example-11', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-47683739', consumerInstanceId='instance1633569369', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@71753eb8}
2022-04-05 02:24:25 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-0cd39a24-target-kafka-bootstrap.namespace-135.svc:9092#topic-example-11 from pod my-cluster-0cd39a24-kafka-clients-7cb9b65f64-5tvm4
2022-04-05 02:24:25 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0cd39a24-kafka-clients-7cb9b65f64-5tvm4 -n namespace-135 -- /opt/kafka/consumer.sh --topic topic-example-11 --max-messages 200 --group-instance-id instance1633569369 --group-id my-consumer-group-47683739 --bootstrap-server my-cluster-0cd39a24-target-kafka-bootstrap.namespace-135.svc:9092
2022-04-05 02:24:31 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 02:24:31 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-05 02:24:31 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-0cd39a24 in namespace namespace-135
2022-04-05 02:24:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-135
2022-04-05 02:24:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-0cd39a24 will have desired state: Ready
2022-04-05 02:25:34 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-0cd39a24 is in desired state: Ready
2022-04-05 02:25:34 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@7700c19b, messages=[], arguments=[--topic, included-topic, --max-messages, 200, --bootstrap-server, my-cluster-0cd39a24-source-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-0cd39a24-kafka-clients-7cb9b65f64-5tvm4', podNamespace='namespace-135', bootstrapServer='my-cluster-0cd39a24-source-kafka-bootstrap.namespace-135.svc:9092', topicName='included-topic', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@b9362d5}
2022-04-05 02:25:34 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-0cd39a24-source-kafka-bootstrap.namespace-135.svc:9092:included-topic from pod my-cluster-0cd39a24-kafka-clients-7cb9b65f64-5tvm4
2022-04-05 02:25:34 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0cd39a24-kafka-clients-7cb9b65f64-5tvm4 -n namespace-135 -- /opt/kafka/producer.sh --topic included-topic --max-messages 200 --bootstrap-server my-cluster-0cd39a24-source-kafka-bootstrap.namespace-135.svc:9092
2022-04-05 02:25:37 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 02:25:37 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-05 02:25:37 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@83a0c9b, messages=[], arguments=[--topic, included-topic, --max-messages, 200, --group-instance-id, instance609233470, --group-id, my-consumer-group-503880045, --bootstrap-server, my-cluster-0cd39a24-source-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-0cd39a24-kafka-clients-7cb9b65f64-5tvm4', podNamespace='namespace-135', bootstrapServer='my-cluster-0cd39a24-source-kafka-bootstrap.namespace-135.svc:9092', topicName='included-topic', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-503880045', consumerInstanceId='instance609233470', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@18af5091}
2022-04-05 02:25:37 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-0cd39a24-source-kafka-bootstrap.namespace-135.svc:9092#included-topic from pod my-cluster-0cd39a24-kafka-clients-7cb9b65f64-5tvm4
2022-04-05 02:25:37 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0cd39a24-kafka-clients-7cb9b65f64-5tvm4 -n namespace-135 -- /opt/kafka/consumer.sh --topic included-topic --max-messages 200 --group-instance-id instance609233470 --group-id my-consumer-group-503880045 --bootstrap-server my-cluster-0cd39a24-source-kafka-bootstrap.namespace-135.svc:9092
2022-04-05 02:25:42 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 02:25:42 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-05 02:25:42 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@13fc9f52, messages=[], arguments=[--topic, included-topic, --max-messages, 200, --group-instance-id, instance56536692, --group-id, my-consumer-group-121295696, --bootstrap-server, my-cluster-0cd39a24-target-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-0cd39a24-kafka-clients-7cb9b65f64-5tvm4', podNamespace='namespace-135', bootstrapServer='my-cluster-0cd39a24-target-kafka-bootstrap.namespace-135.svc:9092', topicName='included-topic', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-121295696', consumerInstanceId='instance56536692', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7947081e}
2022-04-05 02:25:42 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-0cd39a24-target-kafka-bootstrap.namespace-135.svc:9092#included-topic from pod my-cluster-0cd39a24-kafka-clients-7cb9b65f64-5tvm4
2022-04-05 02:25:42 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0cd39a24-kafka-clients-7cb9b65f64-5tvm4 -n namespace-135 -- /opt/kafka/consumer.sh --topic included-topic --max-messages 200 --group-instance-id instance56536692 --group-id my-consumer-group-121295696 --bootstrap-server my-cluster-0cd39a24-target-kafka-bootstrap.namespace-135.svc:9092
2022-04-05 02:25:48 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 02:25:48 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-05 02:25:48 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@2933fa0d, messages=[], arguments=[--topic, not-included-topic, --max-messages, 200, --bootstrap-server, my-cluster-0cd39a24-source-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-0cd39a24-kafka-clients-7cb9b65f64-5tvm4', podNamespace='namespace-135', bootstrapServer='my-cluster-0cd39a24-source-kafka-bootstrap.namespace-135.svc:9092', topicName='not-included-topic', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@71357e64}
2022-04-05 02:25:48 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-0cd39a24-source-kafka-bootstrap.namespace-135.svc:9092:not-included-topic from pod my-cluster-0cd39a24-kafka-clients-7cb9b65f64-5tvm4
2022-04-05 02:25:48 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0cd39a24-kafka-clients-7cb9b65f64-5tvm4 -n namespace-135 -- /opt/kafka/producer.sh --topic not-included-topic --max-messages 200 --bootstrap-server my-cluster-0cd39a24-source-kafka-bootstrap.namespace-135.svc:9092
2022-04-05 02:25:51 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 02:25:51 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-05 02:25:51 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1f84148e, messages=[], arguments=[--topic, not-included-topic, --max-messages, 200, --group-instance-id, instance1224665751, --group-id, my-consumer-group-1034228760, --bootstrap-server, my-cluster-0cd39a24-source-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-0cd39a24-kafka-clients-7cb9b65f64-5tvm4', podNamespace='namespace-135', bootstrapServer='my-cluster-0cd39a24-source-kafka-bootstrap.namespace-135.svc:9092', topicName='not-included-topic', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-1034228760', consumerInstanceId='instance1224665751', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@68f500cd}
2022-04-05 02:25:51 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-0cd39a24-source-kafka-bootstrap.namespace-135.svc:9092#not-included-topic from pod my-cluster-0cd39a24-kafka-clients-7cb9b65f64-5tvm4
2022-04-05 02:25:51 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0cd39a24-kafka-clients-7cb9b65f64-5tvm4 -n namespace-135 -- /opt/kafka/consumer.sh --topic not-included-topic --max-messages 200 --group-instance-id instance1224665751 --group-id my-consumer-group-1034228760 --bootstrap-server my-cluster-0cd39a24-source-kafka-bootstrap.namespace-135.svc:9092
2022-04-05 02:25:57 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 02:25:57 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-05 02:25:57 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@73cde668, messages=[], arguments=[--topic, not-included-topic, --max-messages, 200, --group-instance-id, instance1457796921, --group-id, my-consumer-group-1034228760, --bootstrap-server, my-cluster-0cd39a24-target-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-0cd39a24-kafka-clients-7cb9b65f64-5tvm4', podNamespace='namespace-135', bootstrapServer='my-cluster-0cd39a24-target-kafka-bootstrap.namespace-135.svc:9092', topicName='not-included-topic', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-1034228760', consumerInstanceId='instance1457796921', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@45989f44}
2022-04-05 02:25:57 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-0cd39a24-target-kafka-bootstrap.namespace-135.svc:9092#not-included-topic from pod my-cluster-0cd39a24-kafka-clients-7cb9b65f64-5tvm4
2022-04-05 02:25:57 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0cd39a24-kafka-clients-7cb9b65f64-5tvm4 -n namespace-135 -- /opt/kafka/consumer.sh --topic not-included-topic --max-messages 200 --group-instance-id instance1457796921 --group-id my-consumer-group-1034228760 --bootstrap-server my-cluster-0cd39a24-target-kafka-bootstrap.namespace-135.svc:9092
2022-04-05 02:27:57 [main] [32mINFO [m [VerifiableClient:199] CLI_KAFKA_VERIFIABLE_CONSUMER RETURN code: 1
2022-04-05 02:27:57 [main] [32mINFO [m [VerifiableClient:201] ======STDOUT START=======
2022-04-05 02:27:57 [main] [33mWARN [m [Exec:358] Executor log is too long. Going to strip it and print only first 20000 characters
2022-04-05 02:27:57 [main] [32mINFO [m [VerifiableClient:202] /tmp/.properties
Starting Consumer with configuration:

[2022-04-05 02:25:58,582] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [my-cluster-0cd39a24-target-kafka-bootstrap.namespace-135.svc:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-1034228760-instance1457796921
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group-1034228760
	group.instance.id = instance1457796921
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (ConsumerConfig:376)
[2022-04-05 02:25:58,587] DEBUG [Consumer instanceId=instance1457796921, clientId=consumer-my-consumer-group-1034228760-instance1457796921, groupId=my-consumer-group-1034228760] Initializing the Kafka consumer (KafkaConsumer:695)
[2022-04-05 02:25:58,709] INFO Kafka version: 3.1.0 (AppInfoParser:119)
[2022-04-05 02:25:58,710] INFO Kafka commitId: 37edeed0777bacb3 (AppInfoParser:120)
[2022-04-05 02:25:58,710] INFO Kafka startTimeMs: 1649125558706 (AppInfoParser:121)
[2022-04-05 02:25:58,713] DEBUG [Consumer instanceId=instance1457796921, clientId=consumer-my-consumer-group-1034228760-instance1457796921, groupId=my-consumer-group-1034228760] Kafka consumer initialized (KafkaConsumer:815)
{"timestamp":1649125558849,"name":"startup_complete"}
[2022-04-05 02:25:58,892] INFO [Consumer instanceId=instance1457796921, clientId=consumer-my-consumer-group-1034228760-instance1457796921, groupId=my-consumer-group-1034228760] Subscribed to topic(s): not-included-topic (KafkaConsumer:966)
[2022-04-05 02:25:58,893] DEBUG [Consumer instanceId=instance1457796921, clientId=consumer-my-consumer-group-1034228760-instance1457796921, groupId=my-consumer-group-1034228760] Sending FindCoordinator request to broker my-cluster-0cd39a24-target-kafka-bootstrap.namespace-135.svc:9092 (id: -1 rack: null) (ConsumerCoordinator:821)
[2022-04-05 02:25:59,135] DEBUG Resolved host my-cluster-0cd39a24-target-kafka-bootstrap.namespace-135.svc as 10.109.210.224 (ClientUtils:113)
[2022-04-05 02:25:59,135] DEBUG [Consumer instanceId=instance1457796921, clientId=consumer-my-consumer-group-1034228760-instance1457796921, groupId=my-consumer-group-1034228760] Initiating connection to node my-cluster-0cd39a24-target-kafka-bootstrap.namespace-135.svc:9092 (id: -1 rack: null) using address my-cluster-0cd39a24-target-kafka-bootstrap.namespace-135.svc/10.109.210.224 (NetworkClient:985)
[2022-04-05 02:25:59,149] DEBUG [Consumer instanceId=instance1457796921, clientId=consumer-my-consumer-group-1034228760-instance1457796921, groupId=my-consumer-group-1034228760] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1 (Selector:531)
[2022-04-05 02:25:59,150] DEBUG [Consumer instanceId=instance1457796921, clientId=consumer-my-consumer-group-1034228760-instance1457796921, groupId=my-consumer-group-1034228760] Completed connection to node -1. Fetching API versions. (NetworkClient:952)
[2022-04-05 02:25:59,150] DEBUG [Consumer instanceId=instance1457796921, clientId=consumer-my-consumer-group-1034228760-instance1457796921, groupId=my-consumer-group-1034228760] Initiating API versions fetch from node -1. (NetworkClient:966)
[2022-04-05 02:25:59,153] DEBUG [Consumer instanceId=instance1457796921, clientId=consumer-my-consumer-group-1034228760-instance1457796921, groupId=my-consumer-group-1034228760] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-my-consumer-group-1034228760-instance1457796921, correlationId=1) and timeout 30000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.1.0') (NetworkClient:521)
[2022-04-05 02:25:59,189] DEBUG [Consumer instanceId=instance1457796921, clientId=consumer-my-consumer-group-1034228760-instance1457796921, groupId=my-consumer-group-1034228760] Received API_VERSIONS response from node -1 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-my-consumer-group-1034228760-instance1457796921, correlationId=1): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=9), ApiVersion(apiKey=1, minVersion=0, maxVersion=13), ApiVersion(apiKey=2, minVersion=0, maxVersion=7), ApiVersion(apiKey=3, minVersion=0, maxVersion=12), ApiVersion(apiKey=4, minVersion=0, maxVersion=5), ApiVersion(apiKey=5, minVersion=0, maxVersion=3), ApiVersion(apiKey=6, minVersion=0, maxVersion=7), ApiVersion(apiKey=7, minVersion=0, maxVersion=3), ApiVersion(apiKey=8, minVersion=0, maxVersion=8), ApiVersion(apiKey=9, minVersion=0, maxVersion=8), ApiVersion(apiKey=10, minVersion=0, maxVersion=4), ApiVersion(apiKey=11, minVersion=0, maxVersion=7), ApiVersion(apiKey=12, minVersion=0, maxVersion=4), ApiVersion(apiKey=13, minVersion=0, maxVersion=4), ApiVersion(apiKey=14, minVersion=0, maxVersion=5), ApiVersion(apiKey=15, minVersion=0, maxVersion=5), ApiVersion(apiKey=16, minVersion=0, maxVersion=4), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=3), ApiVersion(apiKey=19, minVersion=0, maxVersion=7), ApiVersion(apiKey=20, minVersion=0, maxVersion=6), ApiVersion(apiKey=21, minVersion=0, maxVersion=2), ApiVersion(apiKey=22, minVersion=0, maxVersion=4), ApiVersion(apiKey=23, minVersion=0, maxVersion=4), ApiVersion(apiKey=24, minVersion=0, maxVersion=3), ApiVersion(apiKey=25, minVersion=0, maxVersion=3), ApiVersion(apiKey=26, minVersion=0, maxVersion=3), ApiVersion(apiKey=27, minVersion=0, maxVersion=1), ApiVersion(apiKey=28, minVersion=0, maxVersion=3), ApiVersion(apiKey=29, minVersion=0, maxVersion=2), ApiVersion(apiKey=30, minVersion=0, maxVersion=2), ApiVersion(apiKey=31, minVersion=0, maxVersion=2), ApiVersion(apiKey=32, minVersion=0, maxVersion=4), ApiVersion(apiKey=33, minVersion=0, maxVersion=2), ApiVersion(apiKey=34, minVersion=0, maxVersion=2), ApiVersion(apiKey=35, minVersion=0, maxVersion=2), ApiVersion(apiKey=36, minVersion=0, maxVersion=2), ApiVersion(apiKey=37, minVersion=0, maxVersion=3), ApiVersion(apiKey=38, minVersion=0, maxVersion=2), ApiVersion(apiKey=39, minVersion=0, maxVersion=2), ApiVersion(apiKey=40, minVersion=0, maxVersion=2), ApiVersion(apiKey=41, minVersion=0, maxVersion=2), ApiVersion(apiKey=42, minVersion=0, maxVersion=2), ApiVersion(apiKey=43, minVersion=0, maxVersion=2), ApiVersion(apiKey=44, minVersion=0, maxVersion=1), ApiVersion(apiKey=45, minVersion=0, maxVersion=0), ApiVersion(apiKey=46, minVersion=0, maxVersion=0), ApiVersion(apiKey=47, minVersion=0, maxVersion=0), ApiVersion(apiKey=48, minVersion=0, maxVersion=1), ApiVersion(apiKey=49, minVersion=0, maxVersion=1), ApiVersion(apiKey=50, minVersion=0, maxVersion=0), ApiVersion(apiKey=51, minVersion=0, maxVersion=0), ApiVersion(apiKey=56, minVersion=0, maxVersion=0), ApiVersion(apiKey=57, minVersion=0, maxVersion=0), ApiVersion(apiKey=60, minVersion=0, maxVersion=0), ApiVersion(apiKey=61, minVersion=0, maxVersion=0), ApiVersion(apiKey=65, minVersion=0, maxVersion=0), ApiVersion(apiKey=66, minVersion=0, maxVersion=0), ApiVersion(apiKey=67, minVersion=0, maxVersion=0)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=0, finalizedFeatures=[]) (NetworkClient:879)
[2022-04-05 02:25:59,253] DEBUG [Consumer instanceId=instance1457796921, clientId=consumer-my-consumer-group-1034228760-instance1457796921, groupId=my-consumer-group-1034228760] Node -1 has finalized features epoch: 0, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 9 [usable: 9], Fetch(1): 0 to 13 [usable: 13], ListOffsets(2): 0 to 7 [usable: 7], Metadata(3): 0 to 12 [usable: 12], LeaderAndIsr(4): 0 to 5 [usable: 5], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 7 [usable: 7], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 8 [usable: 8], FindCoordinator(10): 0 to 4 [usable: 4], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 7 [usable: 7], DeleteTopics(20): 0 to 6 [usable: 6], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 4 [usable: 4], AddPartitionsToTxn(24): 0 to 3 [usable: 3], AddOffsetsToTxn(25): 0 to 3 [usable: 3], EndTxn(26): 0 to 3 [usable: 3], WriteTxnMarkers(27): 0 to 1 [usable: 1], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 4 [usable: 4], AlterConfigs(33): 0 to 2 [usable: 2], AlterReplicaLogDirs(34): 0 to 2 [usable: 2], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 to 1 [usable: 1], AlterClientQuotas(49): 0 to 1 [usable: 1], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0], DescribeCluster(60): 0 [usable: 0], DescribeProducers(61): 0 [usable: 0], DescribeTransactions(65): 0 [usable: 0], ListTransactions(66): 0 [usable: 0], AllocateProducerIds(67): 0 [usable: 0]). (NetworkClient:921)
[2022-04-05 02:25:59,256] DEBUG [Consumer instanceId=instance1457796921, clientId=consumer-my-consumer-group-1034228760-instance1457796921, groupId=my-consumer-group-1034228760] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='not-included-topic')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node my-cluster-0cd39a24-target-kafka-bootstrap.namespace-135.svc:9092 (id: -1 rack: null) (NetworkClient:1139)
[2022-04-05 02:25:59,257] DEBUG [Consumer instanceId=instance1457796921, clientId=consumer-my-consumer-group-1034228760-instance1457796921, groupId=my-consumer-group-1034228760] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=12, clientId=consumer-my-consumer-group-1034228760-instance1457796921, correlationId=2) and timeout 30000 to node -1: MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='not-included-topic')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) (NetworkClient:521)
[2022-04-05 02:25:59,259] DEBUG [Consumer instanceId=instance1457796921, clientId=consumer-my-consumer-group-1034228760-instance1457796921, groupId=my-consumer-group-1034228760] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=4, clientId=consumer-my-consumer-group-1034228760-instance1457796921, correlationId=0) and timeout 30000 to node -1: FindCoordinatorRequestData(key='', keyType=0, coordinatorKeys=[my-consumer-group-1034228760]) (NetworkClient:521)
[2022-04-05 02:25:59,279] DEBUG [Consumer instanceId=instance1457796921, clientId=consumer-my-consumer-group-1034228760-instance1457796921, groupId=my-consumer-group-1034228760] Received METADATA response from node -1 for request with header RequestHeader(apiKey=METADATA, apiVersion=12, clientId=consumer-my-consumer-group-1034228760-instance1457796921, correlationId=2): MetadataResponseData(throttleTimeMs=0, brokers=[MetadataResponseBroker(nodeId=0, host='my-cluster-0cd39a24-target-kafka-0.my-cluster-0cd39a24-target-kafka-brokers.namespace-135.svc', port=9092, rack=null)], clusterId='xEiFfcpxSq-n-hw8VUIm2A', controllerId=0, topics=[MetadataResponseTopic(errorCode=5, name='not-included-topic', topicId=AAAAAAAAAAAAAAAAAAAAAA, isInternal=false, partitions=[], topicAuthorizedOperations=-2147483648)], clusterAuthorizedOperations=-2147483648) (NetworkClient:879)
[2022-04-05 02:25:59,283] WARN [Consumer instanceId=instance1457796921, clientId=consumer-my-consumer-group-1034228760-instance1457796921, groupId=my-consumer-group-1034228760] Error while fetching metadata with correlation id 2 : {not-included-topic=LEADER_NOT_AVAILABLE} (NetworkClient:1099)
[2022-04-05 02:25:59,284] DEBUG [Consumer instanceId=instance1457796921, clientId=consumer-my-consumer-group-1034228760-instance1457796921, groupId=my-consumer-group-1034228760] Requesting metadata update for topic not-included-topic due to error LEADER_NOT_AVAILABLE (Metadata:363)
[2022-04-05 02:25:59,285] INFO [Consumer instanceId=instance1457796921, clientId=consumer-my-consumer-group-1034228760-instance1457796921, groupId=my-consumer-group-1034228760] Cluster ID: xEiFfcpxSq-n-hw8VUIm2A (Metadata:287)
[2022-04-05 02:25:59,285] DEBUG [Consumer instanceId=instance1457796921, clientId=consumer-my-consumer-group-1034228760-instance1457796921, groupId=my-consumer-group-1034228760] Updated cluster metadata updateVersion 2 to MetadataCache{clusterId='xEiFfcpxSq-n-hw8VUIm2A', nodes={0=my-cluster-0cd39a24-target-kafka-0.my-cluster-0cd39a24-target-kafka-brokers.namespace-135.svc:9092 (id: 0 rack: null)}, partitions=[], controller=my-cluster-0cd39a24-target-kafka-0.my-cluster-0cd39a24-target-kafka-brokers.namespace-135.svc:9092 (id: 0 rack: null)} (Metadata:291)
[2022-04-05 02:25:59,286] DEBUG [Consumer instanceId=instance1457796921, clientId=consumer-my-consumer-group-1034228760-instance1457796921, groupId=my-consumer-group-1034228760] Received FIND_COORDINATOR response from node -1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=4, clientId=consumer-my-consumer-group-1034228760-instance1457796921, correlationId=0): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='', nodeId=0, host='', port=0, coordinators=[Coordinator(key='my-consumer-group-1034228760', nodeId=0, host='my-cluster-0cd39a24-target-kafka-0.my-cluster-0cd39a24-target-kafka-brokers.namespace-135.svc', port=9092, errorCode=0, errorMessage='')]) (NetworkClient:879)
[2022-04-05 02:25:59,287] DEBUG [Consumer instanceId=instance1457796921, clientId=consumer-my-consumer-group-1034228760-instance1457796921, groupId=my-consumer-group-1034228760] Received FindCoordinator response ClientResponse(receivedTimeMs=1649125559286, latencyMs=159, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=4, clientId=consumer-my-consumer-group-1034228760-instance1457796921, correlationId=0), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='', nodeId=0, host='', port=0, coordinators=[Coordinator(key='my-consumer-group-1034228760', nodeId=0, host='my-cluster-0cd39a24-target-kafka-0.my-cluster-0cd39a24-target-kafka-brokers.namespace-135.svc', port=9092, errorCode=0, errorMessage='')])) (ConsumerCoordinator:834)
[2022-04-05 02:25:59,287] INFO [Consumer instanceId=instance1457796921, clientId=consumer-my-consumer-group-1034228760-instance1457796921, groupId=my-consumer-group-1034228760] Discovered group coordinator my-cluster-0cd39a24-target-kafka-0.my-cluster-0cd39a24-target-kafka-brokers.namespace-135.svc:9092 (id: 2147483647 rack: null) (ConsumerCoordinator:853)
[2022-04-05 02:25:59,289] DEBUG Resolved host my-cluster-0cd39a24-target-kafka-0.my-cluster-0cd39a24-target-kafka-brokers.namespace-135.svc as 172.17.0.11 (ClientUtils:113)
[2022-04-05 02:25:59,289] DEBUG [Consumer instanceId=instance1457796921, clientId=consumer-my-consumer-group-1034228760-instance1457796921, groupId=my-consumer-group-1034228760] Initiating connection to node my-cluster-0cd39a24-target-kafka-0.my-cluster-0cd39a24-target-kafka-brokers.namespace-135.svc:9092 (id: 2147483647 rack: null) using address my-cluster-0cd39a24-target-kafka-0.my-cluster-0cd39a24-target-kafka-brokers.namespace-135.svc/172.17.0.11 (NetworkClient:985)
[2022-04-05 02:25:59,292] DEBUG [Consumer instanceId=instance1457796921, clientId=consumer-my-consumer-group-1034228760-instance1457796921, groupId=my-consumer-group-1034228760] Executing onJoinPrepare with generation -1 and memberId  (ConsumerCoordinator:700)
[2022-04-05 02:25:59,292] INFO [Consumer instanceId=instance1457796921, clientId=consumer-my-consumer-group-1034228760-instance1457796921, groupId=my-consumer-group-1034228760] (Re-)joining group (ConsumerCoordinator:535)
[2022-04-05 02:25:59,293] DEBUG [Consumer instanceId=instance1457796921, clientId=consumer-my-consumer-group-1034228760-instance1457796921, groupId=my-consumer-group-1034228760] Joining group with current subscription: [not-included-topic] (Cons
2022-04-05 02:27:57 [main] [32mINFO [m [VerifiableClient:203] ======STDOUT END======
2022-04-05 02:27:57 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: false
2022-04-05 02:27:57 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 0 messages
2022-04-05 02:27:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 02:27:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testIncludeList
2022-04-05 02:27:57 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic not-included-topic in namespace namespace-135
2022-04-05 02:27:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-0cd39a24-kafka-clients in namespace namespace-135
2022-04-05 02:27:57 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-0cd39a24 in namespace namespace-135
2022-04-05 02:27:57 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0cd39a24-source in namespace namespace-135
2022-04-05 02:27:57 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic included-topic in namespace namespace-135
2022-04-05 02:27:57 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0cd39a24-target in namespace namespace-135
2022-04-05 02:28:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 02:28:47 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-135 for test case:testIncludeList
2022-04-05 02:28:52 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testIncludeList-FINISHED
2022-04-05 02:28:52 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 02:28:52 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 02:28:52 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testConfigureDeploymentStrategy-STARTED
2022-04-05 02:28:52 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 02:28:52 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-136 for test case:testConfigureDeploymentStrategy
2022-04-05 02:28:52 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-136
2022-04-05 02:28:52 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-136
2022-04-05 02:28:52 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-136
2022-04-05 02:28:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b1784e0a-source in namespace namespace-136
2022-04-05 02:28:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-136
2022-04-05 02:28:52 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b1784e0a-source will have desired state: Ready
2022-04-05 02:29:58 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b1784e0a-source is in desired state: Ready
2022-04-05 02:29:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b1784e0a-target in namespace namespace-136
2022-04-05 02:29:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-136
2022-04-05 02:29:58 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b1784e0a-target will have desired state: Ready
2022-04-05 02:31:04 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b1784e0a-target is in desired state: Ready
2022-04-05 02:31:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-b1784e0a in namespace namespace-136
2022-04-05 02:31:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-136
2022-04-05 02:31:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-b1784e0a will have desired state: Ready
2022-04-05 02:32:10 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-b1784e0a is in desired state: Ready
2022-04-05 02:32:10 [main] [32mINFO [m [MirrorMakerIsolatedST:763] Adding label to MirrorMaker resource, the CR should be recreateAndWaitForReadinessd
2022-04-05 02:32:10 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b1784e0a-mirror-maker will be ready
2022-04-05 02:32:10 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b1784e0a-mirror-maker is ready
2022-04-05 02:32:10 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-b1784e0a-mirror-maker to be ready
2022-04-05 02:33:30 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-b1784e0a-mirror-maker is ready
2022-04-05 02:33:30 [main] [32mINFO [m [MirrorMakerIsolatedST:770] Checking that observed gen. is still on 1 (recreation) and new label is present
2022-04-05 02:33:30 [main] [32mINFO [m [MirrorMakerIsolatedST:775] Changing deployment strategy to ROLLING_UPDATE
2022-04-05 02:33:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-b1784e0a will have desired state: Ready
2022-04-05 02:33:30 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-b1784e0a is in desired state: Ready
2022-04-05 02:33:30 [main] [32mINFO [m [MirrorMakerIsolatedST:780] Adding another label to MirrorMaker resource, pods should be rolled
2022-04-05 02:33:30 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b1784e0a-mirror-maker will be ready
2022-04-05 02:33:30 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b1784e0a-mirror-maker is ready
2022-04-05 02:33:30 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-b1784e0a-mirror-maker to be ready
2022-04-05 02:34:44 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-b1784e0a-mirror-maker is ready
2022-04-05 02:34:44 [main] [32mINFO [m [MirrorMakerIsolatedST:784] Checking that observed gen. higher (rolling update) and label is changed
2022-04-05 02:34:44 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 02:34:44 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigureDeploymentStrategy
2022-04-05 02:34:44 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b1784e0a-target in namespace namespace-136
2022-04-05 02:34:44 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-b1784e0a in namespace namespace-136
2022-04-05 02:34:44 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b1784e0a-source in namespace namespace-136
2022-04-05 02:35:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 02:35:04 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-136 for test case:testConfigureDeploymentStrategy
2022-04-05 02:35:09 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testConfigureDeploymentStrategy-FINISHED
2022-04-05 02:35:09 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 02:35:09 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 02:35:09 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testScaleMirrorMakerToZero-STARTED
2022-04-05 02:35:09 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 02:35:09 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-137 for test case:testScaleMirrorMakerToZero
2022-04-05 02:35:09 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-137
2022-04-05 02:35:09 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-137
2022-04-05 02:35:09 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-137
2022-04-05 02:35:09 [main] [32mINFO [m [MirrorMakerIsolatedST:713] Creating kafka source cluster my-cluster-cb40dafa-source
2022-04-05 02:35:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-cb40dafa-source in namespace namespace-137
2022-04-05 02:35:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-137
2022-04-05 02:35:09 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-cb40dafa-source will have desired state: Ready
2022-04-05 02:36:16 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-cb40dafa-source is in desired state: Ready
2022-04-05 02:36:16 [main] [32mINFO [m [MirrorMakerIsolatedST:715] Creating kafka target cluster my-cluster-cb40dafa-target
2022-04-05 02:36:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-cb40dafa-target in namespace namespace-137
2022-04-05 02:36:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-137
2022-04-05 02:36:16 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-cb40dafa-target will have desired state: Ready
2022-04-05 02:37:26 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-cb40dafa-target is in desired state: Ready
2022-04-05 02:37:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-cb40dafa in namespace namespace-137
2022-04-05 02:37:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-137
2022-04-05 02:37:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-cb40dafa will have desired state: Ready
2022-04-05 02:38:36 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-cb40dafa is in desired state: Ready
2022-04-05 02:38:36 [main] [32mINFO [m [MirrorMakerIsolatedST:725] Scaling MirrorMaker to zero
2022-04-05 02:38:44 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 02:38:44 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleMirrorMakerToZero
2022-04-05 02:38:44 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-cb40dafa-target in namespace namespace-137
2022-04-05 02:38:44 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-cb40dafa in namespace namespace-137
2022-04-05 02:38:44 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-cb40dafa-source in namespace namespace-137
2022-04-05 02:39:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 02:39:04 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-137 for test case:testScaleMirrorMakerToZero
2022-04-05 02:39:15 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testScaleMirrorMakerToZero-FINISHED
2022-04-05 02:39:15 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 02:39:15 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 02:39:15 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testScaleMirrorMakerSubresource-STARTED
2022-04-05 02:39:15 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 02:39:15 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-138 for test case:testScaleMirrorMakerSubresource
2022-04-05 02:39:15 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-138
2022-04-05 02:39:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-138
2022-04-05 02:39:15 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-138
2022-04-05 02:39:15 [main] [32mINFO [m [MirrorMakerIsolatedST:674] Creating kafka source cluster my-cluster-8feb579b-source
2022-04-05 02:39:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-8feb579b-source in namespace namespace-138
2022-04-05 02:39:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-138
2022-04-05 02:39:15 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8feb579b-source will have desired state: Ready
2022-04-05 02:40:20 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8feb579b-source is in desired state: Ready
2022-04-05 02:40:20 [main] [32mINFO [m [MirrorMakerIsolatedST:676] Creating kafka target cluster my-cluster-8feb579b-target
2022-04-05 02:40:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-8feb579b-target in namespace namespace-138
2022-04-05 02:40:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-138
2022-04-05 02:40:20 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8feb579b-target will have desired state: Ready
2022-04-05 02:41:28 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8feb579b-target is in desired state: Ready
2022-04-05 02:41:28 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-8feb579b in namespace namespace-138
2022-04-05 02:41:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-138
2022-04-05 02:41:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-8feb579b will have desired state: Ready
2022-04-05 02:42:32 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-8feb579b is in desired state: Ready
2022-04-05 02:42:32 [main] [32mINFO [m [MirrorMakerIsolatedST:685] -------> Scaling KafkaMirrorMaker subresource <-------
2022-04-05 02:42:32 [main] [32mINFO [m [MirrorMakerIsolatedST:686] Scaling subresource replicas to 4
2022-04-05 02:42:32 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-8feb579b-mirror-maker will be ready
2022-04-05 02:42:32 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-8feb579b-mirror-maker is ready
2022-04-05 02:42:32 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 4 Pod(s) of Deployment my-cluster-8feb579b-mirror-maker to be ready
2022-04-05 02:43:51 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-8feb579b-mirror-maker is ready
2022-04-05 02:43:51 [main] [32mINFO [m [MirrorMakerIsolatedST:690] Check if replicas is set to 4, naming prefix should be same and observed generation higher
2022-04-05 02:43:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 02:43:51 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleMirrorMakerSubresource
2022-04-05 02:43:51 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-8feb579b-target in namespace namespace-138
2022-04-05 02:43:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-8feb579b in namespace namespace-138
2022-04-05 02:43:51 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-8feb579b-source in namespace namespace-138
2022-04-05 02:44:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 02:44:11 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-138 for test case:testScaleMirrorMakerSubresource
2022-04-05 02:44:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testScaleMirrorMakerSubresource-FINISHED
2022-04-05 02:44:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 02:44:17 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 02:44:17 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testCustomAndUpdatedValues-STARTED
2022-04-05 02:44:17 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 02:44:17 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-139 for test case:testCustomAndUpdatedValues
2022-04-05 02:44:17 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-139
2022-04-05 02:44:17 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-139
2022-04-05 02:44:17 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-139
2022-04-05 02:44:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c2576700 in namespace namespace-139
2022-04-05 02:44:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-139
2022-04-05 02:44:17 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c2576700 will have desired state: Ready
2022-04-05 02:45:02 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c2576700 is in desired state: Ready
2022-04-05 02:45:02 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-c2576700 in namespace namespace-139
2022-04-05 02:45:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-139
2022-04-05 02:45:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-c2576700 will have desired state: Ready
2022-04-05 02:45:43 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-c2576700 is in desired state: Ready
2022-04-05 02:45:43 [main] [32mINFO [m [MirrorMakerIsolatedST:622] Verify values before update
2022-04-05 02:45:43 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-c2576700-mirror-maker in pod name
2022-04-05 02:45:43 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container my-cluster-c2576700-mirror-maker
2022-04-05 02:45:43 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-c2576700-mirror-maker
2022-04-05 02:45:43 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container my-cluster-c2576700-mirror-maker
2022-04-05 02:45:43 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-c2576700-mirror-maker
2022-04-05 02:45:43 [main] [32mINFO [m [AbstractST:194] Testing configuration for container my-cluster-c2576700-mirror-maker
2022-04-05 02:45:43 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-c2576700-mirror-maker
2022-04-05 02:45:43 [main] [32mINFO [m [AbstractST:194] Testing configuration for container my-cluster-c2576700-mirror-maker
2022-04-05 02:45:43 [main] [32mINFO [m [MirrorMakerIsolatedST:633] Check if actual env variable KAFKA_MIRRORMAKER_CONFIGURATION_PRODUCER has different value than test.value
2022-04-05 02:45:43 [main] [32mINFO [m [MirrorMakerIsolatedST:637] Updating values in MirrorMaker container
2022-04-05 02:45:43 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-c2576700-mirror-maker rolling update
2022-04-05 02:46:28 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c2576700-mirror-maker will be ready
2022-04-05 02:46:28 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c2576700-mirror-maker is ready
2022-04-05 02:46:38 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-c2576700-mirror-maker rolling update finished
2022-04-05 02:46:38 [main] [32mINFO [m [MirrorMakerIsolatedST:654] Verify values after update
2022-04-05 02:46:38 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-c2576700-mirror-maker in pod name
2022-04-05 02:46:38 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container my-cluster-c2576700-mirror-maker
2022-04-05 02:46:38 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-c2576700-mirror-maker
2022-04-05 02:46:38 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container my-cluster-c2576700-mirror-maker
2022-04-05 02:46:38 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-c2576700-mirror-maker
2022-04-05 02:46:38 [main] [32mINFO [m [AbstractST:194] Testing configuration for container my-cluster-c2576700-mirror-maker
2022-04-05 02:46:38 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-c2576700-mirror-maker
2022-04-05 02:46:38 [main] [32mINFO [m [AbstractST:194] Testing configuration for container my-cluster-c2576700-mirror-maker
2022-04-05 02:46:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 02:46:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCustomAndUpdatedValues
2022-04-05 02:46:38 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-c2576700 in namespace namespace-139
2022-04-05 02:46:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c2576700 in namespace namespace-139
2022-04-05 02:46:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 02:46:48 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-139 for test case:testCustomAndUpdatedValues
2022-04-05 02:47:15 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testCustomAndUpdatedValues-FINISHED
2022-04-05 02:47:15 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 02:47:15 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 02:47:15 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMaker-STARTED
2022-04-05 02:47:15 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 02:47:15 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-140 for test case:testMirrorMaker
2022-04-05 02:47:15 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-140
2022-04-05 02:47:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-140
2022-04-05 02:47:15 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-140
2022-04-05 02:47:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-89fe8b45-source in namespace namespace-140
2022-04-05 02:47:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-140
2022-04-05 02:47:15 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-89fe8b45-source will have desired state: Ready
2022-04-05 02:48:18 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-89fe8b45-source is in desired state: Ready
2022-04-05 02:48:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-89fe8b45-target in namespace namespace-140
2022-04-05 02:48:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-140
2022-04-05 02:48:19 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-89fe8b45-target will have desired state: Ready
2022-04-05 02:49:30 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-89fe8b45-target is in desired state: Ready
2022-04-05 02:49:30 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-335653399-1112350690-source-2056025853 in namespace namespace-140
2022-04-05 02:49:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-140
2022-04-05 02:49:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-335653399-1112350690-source-2056025853 will have desired state: Ready
2022-04-05 02:49:31 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-335653399-1112350690-source-2056025853 is in desired state: Ready
2022-04-05 02:49:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-89fe8b45-kafka-clients in namespace namespace-140
2022-04-05 02:49:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-140
2022-04-05 02:49:31 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-89fe8b45-kafka-clients will be ready
2022-04-05 02:49:33 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-89fe8b45-kafka-clients is ready
2022-04-05 02:49:33 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 02:49:33 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3904657b, messages=[], arguments=[--topic, topic-for-test-broker-1, --max-messages, 200, --bootstrap-server, my-cluster-89fe8b45-source-kafka-bootstrap.namespace-140.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-89fe8b45-kafka-clients-fbf7d9995-9vqcv', podNamespace='namespace-140', bootstrapServer='my-cluster-89fe8b45-source-kafka-bootstrap.namespace-140.svc:9092', topicName='topic-for-test-broker-1', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@326086fd}
2022-04-05 02:49:33 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-89fe8b45-source-kafka-bootstrap.namespace-140.svc:9092:topic-for-test-broker-1 from pod my-cluster-89fe8b45-kafka-clients-fbf7d9995-9vqcv
2022-04-05 02:49:33 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-89fe8b45-kafka-clients-fbf7d9995-9vqcv -n namespace-140 -- /opt/kafka/producer.sh --topic topic-for-test-broker-1 --max-messages 200 --bootstrap-server my-cluster-89fe8b45-source-kafka-bootstrap.namespace-140.svc:9092
2022-04-05 02:49:35 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 02:49:35 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-05 02:49:35 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2e7b0b4d, messages=[], arguments=[--topic, topic-for-test-broker-1, --max-messages, 200, --group-instance-id, instance1311942234, --group-id, my-consumer-group-1207629406, --bootstrap-server, my-cluster-89fe8b45-source-kafka-bootstrap.namespace-140.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-89fe8b45-kafka-clients-fbf7d9995-9vqcv', podNamespace='namespace-140', bootstrapServer='my-cluster-89fe8b45-source-kafka-bootstrap.namespace-140.svc:9092', topicName='topic-for-test-broker-1', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-1207629406', consumerInstanceId='instance1311942234', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@189a31cd}
2022-04-05 02:49:35 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-89fe8b45-source-kafka-bootstrap.namespace-140.svc:9092#topic-for-test-broker-1 from pod my-cluster-89fe8b45-kafka-clients-fbf7d9995-9vqcv
2022-04-05 02:49:35 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-89fe8b45-kafka-clients-fbf7d9995-9vqcv -n namespace-140 -- /opt/kafka/consumer.sh --topic topic-for-test-broker-1 --max-messages 200 --group-instance-id instance1311942234 --group-id my-consumer-group-1207629406 --bootstrap-server my-cluster-89fe8b45-source-kafka-bootstrap.namespace-140.svc:9092
2022-04-05 02:49:41 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 02:49:41 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-05 02:49:41 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1c4038d, messages=[], arguments=[--topic, topic-for-test-broker-2, --max-messages, 200, --bootstrap-server, my-cluster-89fe8b45-target-kafka-bootstrap.namespace-140.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-89fe8b45-kafka-clients-fbf7d9995-9vqcv', podNamespace='namespace-140', bootstrapServer='my-cluster-89fe8b45-target-kafka-bootstrap.namespace-140.svc:9092', topicName='topic-for-test-broker-2', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@344e8c44}
2022-04-05 02:49:41 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-89fe8b45-target-kafka-bootstrap.namespace-140.svc:9092:topic-for-test-broker-2 from pod my-cluster-89fe8b45-kafka-clients-fbf7d9995-9vqcv
2022-04-05 02:49:41 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-89fe8b45-kafka-clients-fbf7d9995-9vqcv -n namespace-140 -- /opt/kafka/producer.sh --topic topic-for-test-broker-2 --max-messages 200 --bootstrap-server my-cluster-89fe8b45-target-kafka-bootstrap.namespace-140.svc:9092
2022-04-05 02:49:44 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 02:49:44 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-05 02:49:44 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3e4e150c, messages=[], arguments=[--topic, topic-for-test-broker-2, --max-messages, 200, --group-instance-id, instance1251226104, --group-id, my-consumer-group-600604415, --bootstrap-server, my-cluster-89fe8b45-target-kafka-bootstrap.namespace-140.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-89fe8b45-kafka-clients-fbf7d9995-9vqcv', podNamespace='namespace-140', bootstrapServer='my-cluster-89fe8b45-target-kafka-bootstrap.namespace-140.svc:9092', topicName='topic-for-test-broker-2', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-600604415', consumerInstanceId='instance1251226104', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@48195e21}
2022-04-05 02:49:44 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-89fe8b45-target-kafka-bootstrap.namespace-140.svc:9092#topic-for-test-broker-2 from pod my-cluster-89fe8b45-kafka-clients-fbf7d9995-9vqcv
2022-04-05 02:49:44 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-89fe8b45-kafka-clients-fbf7d9995-9vqcv -n namespace-140 -- /opt/kafka/consumer.sh --topic topic-for-test-broker-2 --max-messages 200 --group-instance-id instance1251226104 --group-id my-consumer-group-600604415 --bootstrap-server my-cluster-89fe8b45-target-kafka-bootstrap.namespace-140.svc:9092
2022-04-05 02:49:49 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 02:49:49 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-05 02:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-89fe8b45 in namespace namespace-140
2022-04-05 02:49:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-140
2022-04-05 02:49:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-89fe8b45 will have desired state: Ready
2022-04-05 02:50:59 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-89fe8b45 is in desired state: Ready
2022-04-05 02:50:59 [main] [32mINFO [m [AbstractST:311] Verifying labels on pod type mirror-maker
2022-04-05 02:50:59 [main] [32mINFO [m [AbstractST:315] Verifying labels for pod: my-cluster-89fe8b45-mirror-maker-7f6fbc458d-2jr47
2022-04-05 02:50:59 [main] [32mINFO [m [AbstractST:356] Verifying labels for Kafka Connect Services
2022-04-05 02:50:59 [main] [32mINFO [m [AbstractST:384] Verifying labels for Config maps
2022-04-05 02:50:59 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-89fe8b45-mirror-maker-config
2022-04-05 02:50:59 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-89fe8b45-source-entity-topic-operator-config
2022-04-05 02:50:59 [main] [32mINFO [m [AbstractST:407] CM my-cluster-89fe8b45-source-entity-topic-operator-config is not related to current test
2022-04-05 02:50:59 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-89fe8b45-source-entity-user-operator-config
2022-04-05 02:50:59 [main] [32mINFO [m [AbstractST:407] CM my-cluster-89fe8b45-source-entity-user-operator-config is not related to current test
2022-04-05 02:50:59 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-89fe8b45-source-kafka-config
2022-04-05 02:50:59 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-89fe8b45-source-zookeeper-config
2022-04-05 02:50:59 [main] [32mINFO [m [AbstractST:407] CM my-cluster-89fe8b45-source-zookeeper-config is not related to current test
2022-04-05 02:50:59 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-89fe8b45-target-entity-topic-operator-config
2022-04-05 02:50:59 [main] [32mINFO [m [AbstractST:407] CM my-cluster-89fe8b45-target-entity-topic-operator-config is not related to current test
2022-04-05 02:50:59 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-89fe8b45-target-entity-user-operator-config
2022-04-05 02:50:59 [main] [32mINFO [m [AbstractST:407] CM my-cluster-89fe8b45-target-entity-user-operator-config is not related to current test
2022-04-05 02:50:59 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-89fe8b45-target-kafka-config
2022-04-05 02:50:59 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-89fe8b45-target-zookeeper-config
2022-04-05 02:50:59 [main] [32mINFO [m [AbstractST:407] CM my-cluster-89fe8b45-target-zookeeper-config is not related to current test
2022-04-05 02:50:59 [main] [32mINFO [m [AbstractST:414] Verifying labels for Service Accounts
2022-04-05 02:50:59 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-89fe8b45-source-entity-operator
2022-04-05 02:50:59 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-89fe8b45-source-kafka
2022-04-05 02:50:59 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-89fe8b45-source-zookeeper
2022-04-05 02:50:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-140 exec my-cluster-89fe8b45-mirror-maker-7f6fbc458d-2jr47 -c my-cluster-89fe8b45-mirror-maker -- /bin/bash -c for proc in $(ls -1 /proc/ | grep [0-9]); do if echo "$(ls -lh /proc/$proc/exe 2>/dev/null || true)" | grep -q java; then cat /proc/$proc/cmdline; fi; done
2022-04-05 02:50:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 02:50:59 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@79c0d8e8, messages=[], arguments=[--topic, my-topic-335653399-1112350690-source-2056025853, --max-messages, 200, --bootstrap-server, my-cluster-89fe8b45-source-kafka-bootstrap.namespace-140.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-89fe8b45-kafka-clients-fbf7d9995-9vqcv', podNamespace='namespace-140', bootstrapServer='my-cluster-89fe8b45-source-kafka-bootstrap.namespace-140.svc:9092', topicName='my-topic-335653399-1112350690-source-2056025853', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1319035c}
2022-04-05 02:50:59 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-89fe8b45-source-kafka-bootstrap.namespace-140.svc:9092:my-topic-335653399-1112350690-source-2056025853 from pod my-cluster-89fe8b45-kafka-clients-fbf7d9995-9vqcv
2022-04-05 02:50:59 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-89fe8b45-kafka-clients-fbf7d9995-9vqcv -n namespace-140 -- /opt/kafka/producer.sh --topic my-topic-335653399-1112350690-source-2056025853 --max-messages 200 --bootstrap-server my-cluster-89fe8b45-source-kafka-bootstrap.namespace-140.svc:9092
2022-04-05 02:51:01 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 02:51:01 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-05 02:51:01 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2ed1db64, messages=[], arguments=[--topic, my-topic-335653399-1112350690-source-2056025853, --max-messages, 200, --group-instance-id, instance51734126, --group-id, my-consumer-group-626322890, --bootstrap-server, my-cluster-89fe8b45-source-kafka-bootstrap.namespace-140.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-89fe8b45-kafka-clients-fbf7d9995-9vqcv', podNamespace='namespace-140', bootstrapServer='my-cluster-89fe8b45-source-kafka-bootstrap.namespace-140.svc:9092', topicName='my-topic-335653399-1112350690-source-2056025853', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-626322890', consumerInstanceId='instance51734126', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7f6d3a09}
2022-04-05 02:51:01 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-89fe8b45-source-kafka-bootstrap.namespace-140.svc:9092#my-topic-335653399-1112350690-source-2056025853 from pod my-cluster-89fe8b45-kafka-clients-fbf7d9995-9vqcv
2022-04-05 02:51:01 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-89fe8b45-kafka-clients-fbf7d9995-9vqcv -n namespace-140 -- /opt/kafka/consumer.sh --topic my-topic-335653399-1112350690-source-2056025853 --max-messages 200 --group-instance-id instance51734126 --group-id my-consumer-group-626322890 --bootstrap-server my-cluster-89fe8b45-source-kafka-bootstrap.namespace-140.svc:9092
2022-04-05 02:51:07 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 02:51:07 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-05 02:51:07 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@af1afc0, messages=[], arguments=[--topic, my-topic-335653399-1112350690-source-2056025853, --max-messages, 200, --group-instance-id, instance1743737543, --group-id, my-consumer-group-1197863590, --bootstrap-server, my-cluster-89fe8b45-target-kafka-bootstrap.namespace-140.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-89fe8b45-kafka-clients-fbf7d9995-9vqcv', podNamespace='namespace-140', bootstrapServer='my-cluster-89fe8b45-target-kafka-bootstrap.namespace-140.svc:9092', topicName='my-topic-335653399-1112350690-source-2056025853', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-1197863590', consumerInstanceId='instance1743737543', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@75892e01}
2022-04-05 02:51:07 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-89fe8b45-target-kafka-bootstrap.namespace-140.svc:9092#my-topic-335653399-1112350690-source-2056025853 from pod my-cluster-89fe8b45-kafka-clients-fbf7d9995-9vqcv
2022-04-05 02:51:07 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-89fe8b45-kafka-clients-fbf7d9995-9vqcv -n namespace-140 -- /opt/kafka/consumer.sh --topic my-topic-335653399-1112350690-source-2056025853 --max-messages 200 --group-instance-id instance1743737543 --group-id my-consumer-group-1197863590 --bootstrap-server my-cluster-89fe8b45-target-kafka-bootstrap.namespace-140.svc:9092
2022-04-05 02:51:13 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 02:51:13 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-05 02:51:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 02:51:13 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker
2022-04-05 02:51:13 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-335653399-1112350690-source-2056025853 in namespace namespace-140
2022-04-05 02:51:13 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-89fe8b45-source in namespace namespace-140
2022-04-05 02:51:13 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-89fe8b45 in namespace namespace-140
2022-04-05 02:51:13 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-89fe8b45-kafka-clients in namespace namespace-140
2022-04-05 02:51:13 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-89fe8b45-target in namespace namespace-140
2022-04-05 02:52:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 02:52:13 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-140 for test case:testMirrorMaker
2022-04-05 02:52:18 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMaker-FINISHED
2022-04-05 02:52:18 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 02:52:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 02:52:18 [main] [32mINFO [m [ResourceManager:346] In context MirrorMakerIsolatedST is everything deleted.
2022-04-05 02:52:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2,526.458 s - in io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.metrics.MetricsIsolatedST
2022-04-05 02:52:18 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 02:52:43 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-05 02:52:43 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-05 02:52:43 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-05 02:52:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 02:52:43 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-05 02:52:43 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 02:52:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 02:52:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 02:52:43 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 02:52:43 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 02:52:43 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 02:52:43 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 02:52:43 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 02:52:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 02:52:43 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 02:52:43 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 02:52:43 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 02:52:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 02:52:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 02:52:43 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 02:52:43 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 02:52:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 02:52:43 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 02:52:43 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 02:52:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 02:52:43 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 02:52:43 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 02:52:53 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 02:52:53 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 02:52:53 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 02:53:03 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 02:53:08 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace,second-metrics-cluster-test
bindingsNamespaces=[infra-namespace, second-metrics-cluster-test]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-05 02:53:08 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-05 02:53:08 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-05 02:53:09 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: second-metrics-cluster-test
2022-04-05 02:53:09 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 02:53:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 02:53:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 02:53:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 02:53:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 02:53:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 02:53:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 02:53:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 02:53:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 02:53:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 02:53:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 02:53:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 02:53:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 02:53:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 02:53:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 02:53:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 02:53:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 02:53:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 02:53:09 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-05 02:53:09 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: second-metrics-cluster-test
2022-04-05 02:53:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 02:53:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 02:53:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-05 02:53:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 02:53:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-05 02:53:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 02:53:09 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 02:53:09 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 02:53:09 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-05 02:53:09 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 02:53:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 02:53:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 02:53:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-05 02:53:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 02:53:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-05 02:53:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 02:53:09 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 02:53:09 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace second-metrics-cluster-test
2022-04-05 02:53:09 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-05 02:53:09 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-metrics-cluster-test
2022-04-05 02:53:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 02:53:09 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-05 02:53:23 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-05 02:53:23 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-05 02:53:33 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-05 02:53:33 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 02:53:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka metrics-cluster-name in namespace infra-namespace
2022-04-05 02:53:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka second-kafka-cluster in namespace second-metrics-cluster-test
2022-04-05 02:53:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment infra-namespace-kafka-clients in namespace infra-namespace
2022-04-05 02:53:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment second-metrics-cluster-test-kafka-clients in namespace second-metrics-cluster-test
2022-04-05 02:53:33 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: metrics-cluster-name will have desired state: Ready
2022-04-05 02:56:46 [main] [32mINFO [m [ResourceManager:444] Kafka: metrics-cluster-name is in desired state: Ready
2022-04-05 02:56:46 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: second-kafka-cluster will have desired state: Ready
2022-04-05 02:56:46 [main] [32mINFO [m [ResourceManager:444] Kafka: second-kafka-cluster is in desired state: Ready
2022-04-05 02:56:46 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: infra-namespace-kafka-clients will be ready
2022-04-05 02:56:46 [main] [32mINFO [m [DeploymentUtils:168] Deployment: infra-namespace-kafka-clients is ready
2022-04-05 02:56:46 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: second-metrics-cluster-test-kafka-clients will be ready
2022-04-05 02:56:46 [main] [32mINFO [m [DeploymentUtils:168] Deployment: second-metrics-cluster-test-kafka-clients is ready
2022-04-05 02:56:46 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge my-bridge in namespace infra-namespace
2022-04-05 02:56:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: my-bridge will have desired state: Ready
2022-04-05 02:57:08 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: my-bridge is in desired state: Ready
2022-04-05 02:57:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 mm2-cluster in namespace infra-namespace
2022-04-05 02:57:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: mm2-cluster will have desired state: Ready
2022-04-05 02:58:12 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: mm2-cluster is in desired state: Ready
2022-04-05 02:58:12 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1358415632-1212417626 in namespace infra-namespace
2022-04-05 02:58:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1358415632-1212417626 will have desired state: Ready
2022-04-05 02:58:13 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1358415632-1212417626 is in desired state: Ready
2022-04-05 02:58:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-101332078-1719163062 in namespace infra-namespace
2022-04-05 02:58:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-101332078-1719163062 will have desired state: Ready
2022-04-05 02:58:14 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-101332078-1719163062 is in desired state: Ready
2022-04-05 02:58:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1638441894-1683475880 in namespace infra-namespace
2022-04-05 02:58:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1638441894-1683475880 will have desired state: Ready
2022-04-05 02:58:15 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1638441894-1683475880 is in desired state: Ready
2022-04-05 02:58:15 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-351241077-21057745 in namespace infra-namespace
2022-04-05 02:58:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-351241077-21057745 will have desired state: Ready
2022-04-05 02:58:16 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-351241077-21057745 is in desired state: Ready
2022-04-05 02:58:16 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-336537388-719992738 in namespace infra-namespace
2022-04-05 02:58:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-336537388-719992738 will have desired state: Ready
2022-04-05 02:58:17 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-336537388-719992738 is in desired state: Ready
2022-04-05 02:58:17 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect metrics-cluster-name in namespace infra-namespace
2022-04-05 02:58:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: metrics-cluster-name will have desired state: Ready
2022-04-05 02:59:29 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: metrics-cluster-name is in desired state: Ready
2022-04-05 02:59:29 [main] [32mINFO [m [NetworkPolicyResource:72] Apply NetworkPolicy access to cluster-operator from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-04-05 02:59:29 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy cluster-operator-allow in namespace infra-namespace
2022-04-05 02:59:29 [main] [32mINFO [m [NetworkPolicyResource:90] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-04-05 02:59:29 [main] [32mINFO [m [NetworkPolicyResource:104] Apply NetworkPolicy access to metrics-cluster-name-entity-operator from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-04-05 02:59:29 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy metrics-cluster-name-entity-operator-allow in namespace infra-namespace
2022-04-05 02:59:29 [main] [32mINFO [m [NetworkPolicyResource:128] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-04-05 02:59:29 [main] [32mINFO [m [NetworkPolicyResource:104] Apply NetworkPolicy access to second-kafka-cluster-entity-operator from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-04-05 02:59:29 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy second-kafka-cluster-entity-operator-allow in namespace second-metrics-cluster-test
2022-04-05 02:59:29 [main] [32mINFO [m [NetworkPolicyResource:128] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-04-05 02:59:29 [main] [32mINFO [m [NetworkPolicyResource:141] Apply NetworkPolicy access to metrics-cluster-name-kafka-exporter from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-04-05 02:59:29 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy metrics-cluster-name-kafka-exporter-allow in namespace infra-namespace
2022-04-05 02:59:29 [main] [32mINFO [m [NetworkPolicyResource:161] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-04-05 02:59:29 [main] [32mINFO [m [NetworkPolicyResource:141] Apply NetworkPolicy access to second-kafka-cluster-kafka-exporter from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-04-05 02:59:29 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy second-kafka-cluster-kafka-exporter-allow in namespace second-metrics-cluster-test
2022-04-05 02:59:29 [main] [32mINFO [m [NetworkPolicyResource:161] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-04-05 03:00:51 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.13 from Pod infra-namespace-kafka-clients-748578f786-d7pgl finished with return code: 0
2022-04-05 03:00:53 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.14 from Pod infra-namespace-kafka-clients-748578f786-d7pgl finished with return code: 0
2022-04-05 03:00:55 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.15 from Pod infra-namespace-kafka-clients-748578f786-d7pgl finished with return code: 0
2022-04-05 03:00:55 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.10 from Pod infra-namespace-kafka-clients-748578f786-d7pgl finished with return code: 0
2022-04-05 03:00:56 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.11 from Pod infra-namespace-kafka-clients-748578f786-d7pgl finished with return code: 0
2022-04-05 03:00:56 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.12 from Pod infra-namespace-kafka-clients-748578f786-d7pgl finished with return code: 0
2022-04-05 03:00:57 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.24 from Pod infra-namespace-kafka-clients-748578f786-d7pgl finished with return code: 0
2022-04-05 03:00:57 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.21 from Pod infra-namespace-kafka-clients-748578f786-d7pgl finished with return code: 0
2022-04-05 03:00:57 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:00:57 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testUserOperatorMetrics-STARTED
2022-04-05 03:00:57 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:00:58 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.18 from Pod infra-namespace-kafka-clients-748578f786-d7pgl finished with return code: 0
2022-04-05 03:00:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [ResourceManager:346] In context testUserOperatorMetrics is everything deleted.
2022-04-05 03:00:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testUserOperatorMetrics-FINISHED
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperWatchersCount-STARTED
2022-04-05 03:00:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:00:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [ResourceManager:346] In context testZookeeperWatchersCount is everything deleted.
2022-04-05 03:00:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperWatchersCount-FINISHED
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectIoNetwork-STARTED
2022-04-05 03:00:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:00:58 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.24 from Pod infra-namespace-kafka-clients-748578f786-d7pgl finished with return code: 0
2022-04-05 03:00:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [ResourceManager:346] In context testKafkaConnectIoNetwork is everything deleted.
2022-04-05 03:00:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectIoNetwork-FINISHED
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaBrokersCount-STARTED
2022-04-05 03:00:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:00:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [ResourceManager:346] In context testKafkaBrokersCount is everything deleted.
2022-04-05 03:00:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaBrokersCount-FINISHED
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaActiveControllers-STARTED
2022-04-05 03:00:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:00:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [ResourceManager:346] In context testKafkaActiveControllers is everything deleted.
2022-04-05 03:00:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaActiveControllers-FINISHED
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaTopicUnderReplicatedPartitions-STARTED
2022-04-05 03:00:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:00:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [ResourceManager:346] In context testKafkaTopicUnderReplicatedPartitions is everything deleted.
2022-04-05 03:00:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaTopicUnderReplicatedPartitions-FINISHED
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperQuorumSize-STARTED
2022-04-05 03:00:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:00:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [ResourceManager:346] In context testZookeeperQuorumSize is everything deleted.
2022-04-05 03:00:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperQuorumSize-FINISHED
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperAliveConnections-STARTED
2022-04-05 03:00:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:00:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [ResourceManager:346] In context testZookeeperAliveConnections is everything deleted.
2022-04-05 03:00:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperAliveConnections-FINISHED
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaTopicPartitions-STARTED
2022-04-05 03:00:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:00:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [ResourceManager:346] In context testKafkaTopicPartitions is everything deleted.
2022-04-05 03:00:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaTopicPartitions-FINISHED
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:00:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testReconcileStateMetricInTopicOperator-STARTED
2022-04-05 03:00:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:00:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-metrics-cluster-test
2022-04-05 03:00:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1826898759-341715697 in namespace second-metrics-cluster-test
2022-04-05 03:00:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1826898759-341715697 will have desired state: Ready
2022-04-05 03:00:59 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1826898759-341715697 is in desired state: Ready
2022-04-05 03:01:00 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.17 from Pod second-metrics-cluster-test-kafka-clients-6c57d6898-sq7ql finished with return code: 0
2022-04-05 03:01:00 [main] [32mINFO [m [MetricsIsolatedST:555] Checking if resource state metric reason message is "none" and KafkaTopic is ready
2022-04-05 03:01:00 [main] [32mINFO [m [MetricsIsolatedST:558] Changing topic name in spec.topicName
2022-04-05 03:01:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1826898759-341715697 will have desired state: NotReady
2022-04-05 03:01:01 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1826898759-341715697 is in desired state: NotReady
2022-04-05 03:01:01 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.17 from Pod second-metrics-cluster-test-kafka-clients-6c57d6898-sq7ql finished with return code: 0
2022-04-05 03:01:01 [main] [32mINFO [m [MetricsIsolatedST:566] Changing back to it's original name and scaling replicas to be higher number
2022-04-05 03:01:01 [main] [32mINFO [m [KafkaTopicUtils:132] Waiting for KafkaTopic change my-topic-1826898759-341715697
2022-04-05 03:01:01 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.17 from Pod second-metrics-cluster-test-kafka-clients-6c57d6898-sq7ql finished with return code: 0
2022-04-05 03:01:01 [main] [32mINFO [m [MetricsIsolatedST:578] Scaling replicas to be higher than before
2022-04-05 03:01:01 [main] [32mINFO [m [KafkaTopicUtils:132] Waiting for KafkaTopic change my-topic-1826898759-341715697
2022-04-05 03:01:01 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.17 from Pod second-metrics-cluster-test-kafka-clients-6c57d6898-sq7ql finished with return code: 0
2022-04-05 03:01:01 [main] [32mINFO [m [MetricsIsolatedST:586] Changing KafkaTopic's spec to correct state
2022-04-05 03:01:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1826898759-341715697 will have desired state: Ready
2022-04-05 03:01:02 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1826898759-341715697 is in desired state: Ready
2022-04-05 03:01:02 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.17 from Pod second-metrics-cluster-test-kafka-clients-6c57d6898-sq7ql finished with return code: 0
2022-04-05 03:01:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 03:01:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:01:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testReconcileStateMetricInTopicOperator
2022-04-05 03:01:02 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1826898759-341715697 in namespace second-metrics-cluster-test
2022-04-05 03:01:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:01:12 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testReconcileStateMetricInTopicOperator-FINISHED
2022-04-05 03:01:12 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:01:12 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:01:12 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testMirrorMaker2Metrics-STARTED
2022-04-05 03:01:12 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:01:13 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.23 from Pod infra-namespace-kafka-clients-748578f786-d7pgl finished with return code: 0
2022-04-05 03:01:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:01:13 [main] [32mINFO [m [ResourceManager:346] In context testMirrorMaker2Metrics is everything deleted.
2022-04-05 03:01:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:01:13 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testMirrorMaker2Metrics-FINISHED
2022-04-05 03:01:13 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:01:13 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:01:13 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaBridgeMetrics-STARTED
2022-04-05 03:01:13 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:01:13 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 03:01:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Job bridge-producer in namespace infra-namespace
2022-04-05 03:01:13 [main] [32mINFO [m [JobUtils:81] Waiting for job: bridge-producer will be in active state
2022-04-05 03:01:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Job bridge-consumer in namespace infra-namespace
2022-04-05 03:01:14 [main] [32mINFO [m [JobUtils:81] Waiting for job: bridge-consumer will be in active state
2022-04-05 03:01:15 [main] [32mINFO [m [MetricsIsolatedST:422] Looking for 'strimzi_bridge_kafka_producer_count' in bridge metrics
2022-04-05 03:01:16 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.22 from Pod infra-namespace-kafka-clients-748578f786-d7pgl finished with return code: 0
2022-04-05 03:01:17 [main] [32mINFO [m [MetricsIsolatedST:422] Looking for 'strimzi_bridge_kafka_producer_count' in bridge metrics
2022-04-05 03:01:17 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.22 from Pod infra-namespace-kafka-clients-748578f786-d7pgl finished with return code: 0
2022-04-05 03:01:17 [main] [32mINFO [m [MetricsIsolatedST:430] Looking for 'strimzi_bridge_kafka_consumer_connection_count' in bridge metrics
2022-04-05 03:01:17 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.22 from Pod infra-namespace-kafka-clients-748578f786-d7pgl finished with return code: 0
2022-04-05 03:01:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:01:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaBridgeMetrics
2022-04-05 03:01:17 [main] [32mINFO [m [ResourceManager:241] Delete of Job bridge-consumer in namespace infra-namespace
2022-04-05 03:01:17 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job bridge-producer in namespace infra-namespace
2022-04-05 03:01:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:01:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaBridgeMetrics-FINISHED
2022-04-05 03:01:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:01:17 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:01:17 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaMetricsSettings-STARTED
2022-04-05 03:01:17 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:01:17 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: second-kafka-cluster are stable
2022-04-05 03:01:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 03:01:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 03:01:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 03:01:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 03:01:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 03:01:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 03:01:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 03:01:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 03:01:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 03:01:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 03:01:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 03:01:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 03:01:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 03:01:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 03:01:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 03:01:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 03:01:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 03:01:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 03:01:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 03:01:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 03:01:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 03:01:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 03:01:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 03:01:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 03:01:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 03:01:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 03:01:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 03:01:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 03:01:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 03:01:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 03:01:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 03:01:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 03:01:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 03:01:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 03:01:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 03:01:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 03:01:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 03:01:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 03:01:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 03:01:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 03:01:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 03:01:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 03:01:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 03:01:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 03:01:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 03:01:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 03:01:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 03:01:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 03:01:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 03:01:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 03:01:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 03:01:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 03:01:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 03:01:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 03:01:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 03:01:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 03:01:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 03:01:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 03:01:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 03:01:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 03:01:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 03:01:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 03:01:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 03:01:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 03:01:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 03:01:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 03:01:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 03:01:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 03:01:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 03:01:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 03:01:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 03:01:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 03:01:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 03:01:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 03:01:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 03:01:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 03:01:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 03:01:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 03:01:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 03:01:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 03:01:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 03:01:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 03:01:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 03:01:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 03:01:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 03:01:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 03:01:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 03:01:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 03:01:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 03:01:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 03:01:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 03:01:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 03:01:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 03:01:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 03:01:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 03:01:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 03:01:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 03:01:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 03:01:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 03:01:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 03:01:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 03:01:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 03:01:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 03:01:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 03:01:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 03:01:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 03:01:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 03:01:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 03:01:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 03:01:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 03:01:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 03:01:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 03:01:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 03:01:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 03:01:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 03:01:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 03:01:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 03:01:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 03:01:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 03:01:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 03:01:48 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 03:01:48 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 03:01:48 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 03:01:48 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 03:01:49 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 03:01:49 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 03:01:49 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 03:01:49 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 03:01:50 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 03:01:50 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 03:01:50 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 03:01:50 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 03:01:51 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 03:01:51 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 03:01:51 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 03:01:51 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 03:01:52 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 03:01:52 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 03:01:52 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 03:01:52 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 03:01:53 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 03:01:53 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 03:01:53 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 03:01:53 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 03:01:54 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 03:01:54 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 03:01:54 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 03:01:54 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 03:01:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 03:01:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 03:01:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 03:01:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 03:01:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 03:01:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 03:01:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 03:01:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 03:01:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 03:01:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 03:01:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 03:01:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 03:01:58 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 03:01:58 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 03:01:58 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 03:01:58 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 03:01:59 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 03:01:59 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 03:01:59 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 03:01:59 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 03:02:00 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 03:02:00 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 03:02:00 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 03:02:00 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 03:02:01 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 03:02:01 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 03:02:01 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 03:02:01 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 03:02:02 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 03:02:02 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 03:02:02 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 03:02:02 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 03:02:03 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 03:02:03 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 03:02:03 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 03:02:03 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 03:02:04 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 03:02:04 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 03:02:04 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 03:02:04 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 03:02:05 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 03:02:05 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 03:02:05 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 03:02:05 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 03:02:06 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 03:02:06 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 03:02:06 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 03:02:06 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 03:02:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 03:02:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 03:02:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 03:02:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 03:02:07 [main] [32mINFO [m [PodUtils:335] All pods are stable second-kafka-cluster-entity-operator-5f8949dc9c-kr95c ,second-kafka-cluster-kafka-0 ,second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m ,second-kafka-cluster-zookeeper-0
2022-04-05 03:02:07 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: second-kafka-cluster are stable
2022-04-05 03:02:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 03:02:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 03:02:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 03:02:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 03:02:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 03:02:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 03:02:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 03:02:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 03:02:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 03:02:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 03:02:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 03:02:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 03:02:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 03:02:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 03:02:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 03:02:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 03:02:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 03:02:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 03:02:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 03:02:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 03:02:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 03:02:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 03:02:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 03:02:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 03:02:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 03:02:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 03:02:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 03:02:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 03:02:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 03:02:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 03:02:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 03:02:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 03:02:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 03:02:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 03:02:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 03:02:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 03:02:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 03:02:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 03:02:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 03:02:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 03:02:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 03:02:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 03:02:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 03:02:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 03:02:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 03:02:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 03:02:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 03:02:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 03:02:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 03:02:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 03:02:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 03:02:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 03:02:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 03:02:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 03:02:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 03:02:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 03:02:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 03:02:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 03:02:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 03:02:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 03:02:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 03:02:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 03:02:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 03:02:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 03:02:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 03:02:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 03:02:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 03:02:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 03:02:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 03:02:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 03:02:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 03:02:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 03:02:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 03:02:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 03:02:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 03:02:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 03:02:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 03:02:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 03:02:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 03:02:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 03:02:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 03:02:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 03:02:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 03:02:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 03:02:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 03:02:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 03:02:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 03:02:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 03:02:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 03:02:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 03:02:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 03:02:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 03:02:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 03:02:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 03:02:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 03:02:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 03:02:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 03:02:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 03:02:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 03:02:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 03:02:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 03:02:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 03:02:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 03:02:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 03:02:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 03:02:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 03:02:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 03:02:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 03:02:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 03:02:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 03:02:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 03:02:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 03:02:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 03:02:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 03:02:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 03:02:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 03:02:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 03:02:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 03:02:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 03:02:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 03:02:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 03:02:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 03:02:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 03:02:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 03:02:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 03:02:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 03:02:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 03:02:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 03:02:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 03:02:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 03:02:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 03:02:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 03:02:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 03:02:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 03:02:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 03:02:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 03:02:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 03:02:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 03:02:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 03:02:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 03:02:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 03:02:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 03:02:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 03:02:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 03:02:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 03:02:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 03:02:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 03:02:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 03:02:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 03:02:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 03:02:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 03:02:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 03:02:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 03:02:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 03:02:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 03:02:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 03:02:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 03:02:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 03:02:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 03:02:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 03:02:48 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 03:02:48 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 03:02:48 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 03:02:48 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 03:02:49 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 03:02:49 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 03:02:49 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 03:02:49 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 03:02:50 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 03:02:50 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 03:02:50 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 03:02:50 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 03:02:51 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 03:02:51 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 03:02:51 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 03:02:51 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 03:02:52 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 03:02:52 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 03:02:52 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 03:02:52 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 03:02:53 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 03:02:53 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 03:02:53 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 03:02:53 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 03:02:54 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 03:02:54 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 03:02:54 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 03:02:54 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 03:02:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 03:02:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 03:02:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 03:02:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 03:02:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 03:02:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 03:02:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 03:02:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 03:02:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-kr95c is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 03:02:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 03:02:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 03:02:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 03:02:57 [main] [32mINFO [m [PodUtils:335] All pods are stable second-kafka-cluster-entity-operator-5f8949dc9c-kr95c ,second-kafka-cluster-kafka-0 ,second-kafka-cluster-kafka-exporter-6dfb7ccc69-fnj5m ,second-kafka-cluster-zookeeper-0
2022-04-05 03:02:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:02:57 [main] [32mINFO [m [ResourceManager:346] In context testKafkaMetricsSettings is everything deleted.
2022-04-05 03:02:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:02:57 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaMetricsSettings-FINISHED
2022-04-05 03:02:57 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:02:57 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:02:57 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testClusterOperatorMetrics-STARTED
2022-04-05 03:02:57 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:02:57 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.6 from Pod infra-namespace-kafka-clients-748578f786-d7pgl finished with return code: 0
2022-04-05 03:02:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:02:57 [main] [32mINFO [m [ResourceManager:346] In context testClusterOperatorMetrics is everything deleted.
2022-04-05 03:02:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:02:57 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testClusterOperatorMetrics-FINISHED
2022-04-05 03:02:57 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:02:57 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:02:57 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testCruiseControlMetrics-STARTED
2022-04-05 03:02:57 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:02:58 [main] [32mINFO [m [MetricsIsolatedST:452] Verifying that we have more than 0 groups
2022-04-05 03:02:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:02:58 [main] [32mINFO [m [ResourceManager:346] In context testCruiseControlMetrics is everything deleted.
2022-04-05 03:02:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:02:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testCruiseControlMetrics-FINISHED
2022-04-05 03:02:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:02:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:02:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaExporterDataAfterExchange-STARTED
2022-04-05 03:02:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:02:58 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 03:02:58 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@20656abf, messages=[], arguments=[--topic, my-topic-101332078-1719163062, --max-messages, 5000, --bootstrap-server, metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='infra-namespace-kafka-clients-748578f786-d7pgl', podNamespace='infra-namespace', bootstrapServer='metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092', topicName='my-topic-101332078-1719163062', maxMessages=5000, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3f46a0c9}
2022-04-05 03:02:58 [main] [32mINFO [m [InternalKafkaClient:94] Producing 5000 messages to metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092:my-topic-101332078-1719163062 from pod infra-namespace-kafka-clients-748578f786-d7pgl
2022-04-05 03:02:58 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec infra-namespace-kafka-clients-748578f786-d7pgl -n infra-namespace -- /opt/kafka/producer.sh --topic my-topic-101332078-1719163062 --max-messages 5000 --bootstrap-server metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092
2022-04-05 03:03:00 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 03:03:00 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 5000 messages
2022-04-05 03:03:00 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2027ca12, messages=[], arguments=[--topic, my-topic-101332078-1719163062, --max-messages, 5000, --group-instance-id, instance1321193835, --group-id, my-consumer-group-1611555233, --bootstrap-server, metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='infra-namespace-kafka-clients-748578f786-d7pgl', podNamespace='infra-namespace', bootstrapServer='metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092', topicName='my-topic-101332078-1719163062', maxMessages=5000, kafkaUsername='null', consumerGroupName='my-consumer-group-1611555233', consumerInstanceId='instance1321193835', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@72ece16d}
2022-04-05 03:03:00 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 5000 messages from metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092#my-topic-101332078-1719163062 from pod infra-namespace-kafka-clients-748578f786-d7pgl
2022-04-05 03:03:00 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec infra-namespace-kafka-clients-748578f786-d7pgl -n infra-namespace -- /opt/kafka/consumer.sh --topic my-topic-101332078-1719163062 --max-messages 5000 --group-instance-id instance1321193835 --group-id my-consumer-group-1611555233 --bootstrap-server metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092
2022-04-05 03:03:06 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 03:03:06 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 5000 messages
2022-04-05 03:03:06 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.21 from Pod infra-namespace-kafka-clients-748578f786-d7pgl finished with return code: 0
2022-04-05 03:03:06 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:03:06 [main] [32mINFO [m [ResourceManager:346] In context testKafkaExporterDataAfterExchange is everything deleted.
2022-04-05 03:03:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:03:06 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaExporterDataAfterExchange-FINISHED
2022-04-05 03:03:06 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:03:06 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:03:06 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testTopicOperatorMetrics-STARTED
2022-04-05 03:03:06 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:03:06 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.18 from Pod infra-namespace-kafka-clients-748578f786-d7pgl finished with return code: 0
2022-04-05 03:03:06 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: consumer-offsets---84e7a678d08f4bd226872e5cdd4eb527fadc1c6a
2022-04-05 03:03:06 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: heartbeats
2022-04-05 03:03:06 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: metrics-cluster-name-connect-config
2022-04-05 03:03:06 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: metrics-cluster-name-connect-offsets
2022-04-05 03:03:06 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: metrics-cluster-name-connect-status
2022-04-05 03:03:06 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: mirrormaker2-cluster-configs
2022-04-05 03:03:06 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: mirrormaker2-cluster-offsets
2022-04-05 03:03:06 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: mirrormaker2-cluster-status
2022-04-05 03:03:06 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: my-topic-101332078-1719163062
2022-04-05 03:03:06 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: my-topic-1358415632-1212417626
2022-04-05 03:03:06 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: my-topic-1638441894-1683475880
2022-04-05 03:03:06 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: second-kafka-cluster.checkpoints.internal
2022-04-05 03:03:06 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: strimzi-store-topic---effb8e3e057afce1ecf67c3f5d8e4e3ff177fc55
2022-04-05 03:03:06 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: strimzi-topic-operator-kstreams-topic-store-changelog---b75e702040b99be8a9263134de3507fc0cc4017b
2022-04-05 03:03:06 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: strimzi.cruisecontrol.metrics
2022-04-05 03:03:06 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: strimzi.cruisecontrol.modeltrainingsamples
2022-04-05 03:03:06 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: strimzi.cruisecontrol.partitionmetricsamples
2022-04-05 03:03:06 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:03:06 [main] [32mINFO [m [ResourceManager:346] In context testTopicOperatorMetrics is everything deleted.
2022-04-05 03:03:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:03:06 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testTopicOperatorMetrics-FINISHED
2022-04-05 03:03:06 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:03:06 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:03:06 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectRequests-STARTED
2022-04-05 03:03:06 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:03:07 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.24 from Pod infra-namespace-kafka-clients-748578f786-d7pgl finished with return code: 0
2022-04-05 03:03:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:03:07 [main] [32mINFO [m [ResourceManager:346] In context testKafkaConnectRequests is everything deleted.
2022-04-05 03:03:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:03:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectRequests-FINISHED
2022-04-05 03:03:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:03:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:03:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectResponse-STARTED
2022-04-05 03:03:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:03:08 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.24 from Pod infra-namespace-kafka-clients-748578f786-d7pgl finished with return code: 0
2022-04-05 03:03:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:03:08 [main] [32mINFO [m [ResourceManager:346] In context testKafkaConnectResponse is everything deleted.
2022-04-05 03:03:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:03:08 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectResponse-FINISHED
2022-04-05 03:03:08 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:03:08 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:03:08 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaExporterDifferentSetting-STARTED
2022-04-05 03:03:08 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:03:08 [main] [32mINFO [m [MetricsIsolatedST:610] Metrics collection for pod metrics-cluster-name-kafka-exporter-8454677f49-tmtfl return code - 0
2022-04-05 03:03:08 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment metrics-cluster-name-kafka-exporter rolling update
2022-04-05 03:03:43 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: metrics-cluster-name-kafka-exporter will be ready
2022-04-05 03:03:43 [main] [32mINFO [m [DeploymentUtils:168] Deployment: metrics-cluster-name-kafka-exporter is ready
2022-04-05 03:03:53 [main] [32mINFO [m [DeploymentUtils:141] Deployment metrics-cluster-name-kafka-exporter rolling update finished
2022-04-05 03:03:53 [main] [32mINFO [m [MetricsIsolatedST:610] Metrics collection for pod metrics-cluster-name-kafka-exporter-54654bcffc-7hkvv return code - 0
2022-04-05 03:03:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:03:53 [main] [32mINFO [m [ResourceManager:346] In context testKafkaExporterDifferentSetting is everything deleted.
2022-04-05 03:03:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:03:53 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaExporterDifferentSetting-FINISHED
2022-04-05 03:03:53 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:03:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:03:53 [main] [32mINFO [m [ResourceManager:348] Delete all resources for MetricsIsolatedST
2022-04-05 03:03:53 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy second-kafka-cluster-entity-operator-allow in namespace second-metrics-cluster-test
2022-04-05 03:03:53 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy metrics-cluster-name-entity-operator-allow in namespace infra-namespace
2022-04-05 03:03:53 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-336537388-719992738 in namespace infra-namespace
2022-04-05 03:03:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka second-kafka-cluster in namespace second-metrics-cluster-test
2022-04-05 03:03:53 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment infra-namespace-kafka-clients in namespace infra-namespace
2022-04-05 03:03:53 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy second-kafka-cluster-kafka-exporter-allow in namespace second-metrics-cluster-test
2022-04-05 03:03:53 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 mm2-cluster in namespace infra-namespace
2022-04-05 03:03:53 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment second-metrics-cluster-test-kafka-clients in namespace second-metrics-cluster-test
2022-04-05 03:03:53 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy metrics-cluster-name-kafka-exporter-allow in namespace infra-namespace
2022-04-05 03:03:53 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy cluster-operator-allow in namespace infra-namespace
2022-04-05 03:03:53 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-351241077-21057745 in namespace infra-namespace
2022-04-05 03:03:53 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1638441894-1683475880 in namespace infra-namespace
2022-04-05 03:03:53 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka metrics-cluster-name in namespace infra-namespace
2022-04-05 03:03:53 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace infra-namespace, for cruise control Kafka cluster metrics-cluster-name
2022-04-05 03:04:03 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-101332078-1719163062 in namespace infra-namespace
2022-04-05 03:04:03 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1358415632-1212417626 in namespace infra-namespace
2022-04-05 03:04:03 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect metrics-cluster-name in namespace infra-namespace
2022-04-05 03:04:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge my-bridge in namespace infra-namespace
2022-04-05 03:05:03 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 20, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 765.06 s - in io.strimzi.systemtest.metrics.MetricsIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.metrics.JmxIsolatedST
2022-04-05 03:05:03 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 03:05:28 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-05 03:05:28 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-05 03:05:28 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-05 03:05:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:05:28 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-05 03:05:28 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 03:05:28 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 03:05:28 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-metrics-cluster-test
2022-04-05 03:05:28 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 03:05:28 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:05:28 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 03:05:28 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace second-metrics-cluster-test
2022-04-05 03:05:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 03:05:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 03:05:28 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 03:05:28 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 03:05:28 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:05:28 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 03:05:28 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 03:05:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 03:05:28 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 03:05:28 [main] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:05:28 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 03:05:28 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:05:28 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:05:28 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 03:05:28 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 03:05:28 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 03:05:28 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:05:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 03:05:38 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 03:05:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 03:05:38 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:05:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:06:09 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=30000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-05 03:06:09 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-05 03:06:09 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-05 03:06:09 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 03:06:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:06:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:06:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 03:06:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 03:06:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 03:06:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 03:06:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 03:06:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 03:06:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 03:06:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 03:06:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:06:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:06:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 03:06:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 03:06:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 03:06:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 03:06:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:06:10 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-05 03:06:10 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 03:06:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 03:06:10 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-05 03:06:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 03:06:10 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-05 03:06:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 03:06:10 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 03:06:10 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:06:10 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-05 03:06:10 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 03:06:10 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 03:06:10 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 03:06:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:06:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 03:06:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:06:10 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-05 03:06:39 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-05 03:06:39 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-05 03:06:49 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-05 03:06:49 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:06:49 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.JmxIsolatedST.testKafkaZookeeperAndKafkaConnectWithJMX-STARTED
2022-04-05 03:06:49 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:06:49 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-141 for test case:testKafkaZookeeperAndKafkaConnectWithJMX
2022-04-05 03:06:49 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-141
2022-04-05 03:06:49 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-141
2022-04-05 03:06:49 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-141
2022-04-05 03:06:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1b611c2a in namespace namespace-141
2022-04-05 03:06:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-141
2022-04-05 03:06:49 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1b611c2a will have desired state: Ready
2022-04-05 03:08:10 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1b611c2a is in desired state: Ready
2022-04-05 03:08:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-1b611c2a-kafka-clients in namespace namespace-141
2022-04-05 03:08:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-141
2022-04-05 03:08:10 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1b611c2a-kafka-clients will be ready
2022-04-05 03:08:12 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1b611c2a-kafka-clients is ready
2022-04-05 03:08:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-1b611c2a-scraper in namespace namespace-141
2022-04-05 03:08:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-141
2022-04-05 03:08:12 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1b611c2a-scraper will be ready
2022-04-05 03:08:14 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1b611c2a-scraper is ready
2022-04-05 03:08:14 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-1b611c2a-scraper to be ready
2022-04-05 03:08:24 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-1b611c2a-scraper is ready
2022-04-05 03:08:24 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-1b611c2a-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-05 03:08:24 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-1b611c2a-allow in namespace namespace-141
2022-04-05 03:08:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-141
2022-04-05 03:08:24 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-05 03:08:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-1b611c2a in namespace namespace-141
2022-04-05 03:08:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-141
2022-04-05 03:08:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-1b611c2a will have desired state: Ready
2022-04-05 03:09:27 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-1b611c2a is in desired state: Ready
2022-04-05 03:09:27 [main] [32mINFO [m [JmxUtils:54] Getting username and password for service: my-cluster-1b611c2a-kafka-brokers and secret: my-cluster-1b611c2a-kafka-jmx
2022-04-05 03:09:27 [main] [32mINFO [m [JmxUtils:58] Creating script file for service: my-cluster-1b611c2a-kafka-brokers
2022-04-05 03:09:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-1b611c2a-kafka-clients-7bd784d5cd-799k2 -- /bin/bash -c echo 'open service:jmx:rmi:///jndi/rmi://my-cluster-1b611c2a-kafka-brokers:9999/jmxrmi -u A1oiZnngEdZI4g1C -p ikjQ5h70lATwaCYr
bean kafka.server:type=app-info
get -i *' > /tmp/my-cluster-1b611c2a-kafka-brokers.sh
2022-04-05 03:09:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:09:27 [main] [32mINFO [m [JmxUtils:63] Waiting for JMX metrics for service: my-cluster-1b611c2a-kafka-brokers will be present
2022-04-05 03:09:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-1b611c2a-kafka-clients-7bd784d5cd-799k2 -- java -jar jmxterm/jmxterm.jar -i /tmp/my-cluster-1b611c2a-kafka-brokers.sh
2022-04-05 03:09:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:09:28 [main] [32mINFO [m [JmxUtils:54] Getting username and password for service: my-cluster-1b611c2a-connect-api and secret: my-cluster-1b611c2a-kafka-connect-jmx
2022-04-05 03:09:28 [main] [32mINFO [m [JmxUtils:58] Creating script file for service: my-cluster-1b611c2a-connect-api
2022-04-05 03:09:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-1b611c2a-kafka-clients-7bd784d5cd-799k2 -- /bin/bash -c echo 'open service:jmx:rmi:///jndi/rmi://my-cluster-1b611c2a-connect-api:9999/jmxrmi -u DrEc98aRw5qTQN4s -p Mqbq56xHYlYlHghX
bean kafka.connect:type=app-info
get -i *' > /tmp/my-cluster-1b611c2a-connect-api.sh
2022-04-05 03:09:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:09:28 [main] [32mINFO [m [JmxUtils:63] Waiting for JMX metrics for service: my-cluster-1b611c2a-connect-api will be present
2022-04-05 03:09:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-1b611c2a-kafka-clients-7bd784d5cd-799k2 -- java -jar jmxterm/jmxterm.jar -i /tmp/my-cluster-1b611c2a-connect-api.sh
2022-04-05 03:09:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:09:29 [main] [32mINFO [m [JmxUtils:54] Getting username and password for service: my-cluster-1b611c2a-zookeeper-nodes and secret: my-cluster-1b611c2a-zookeeper-jmx
2022-04-05 03:09:29 [main] [32mINFO [m [JmxUtils:58] Creating script file for service: my-cluster-1b611c2a-zookeeper-nodes
2022-04-05 03:09:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-1b611c2a-kafka-clients-7bd784d5cd-799k2 -- /bin/bash -c echo 'open service:jmx:rmi:///jndi/rmi://my-cluster-1b611c2a-zookeeper-nodes:9999/jmxrmi -u D2Df1ufyu6zerSzL -p ogvh3uAaAOQHEBD1
domain org.apache.ZooKeeperService
beans' > /tmp/my-cluster-1b611c2a-zookeeper-nodes.sh
2022-04-05 03:09:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:09:29 [main] [32mINFO [m [JmxUtils:63] Waiting for JMX metrics for service: my-cluster-1b611c2a-zookeeper-nodes will be present
2022-04-05 03:09:30 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-1b611c2a-kafka-clients-7bd784d5cd-799k2 -- java -jar jmxterm/jmxterm.jar -i /tmp/my-cluster-1b611c2a-zookeeper-nodes.sh
2022-04-05 03:09:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:09:30 [main] [32mINFO [m [JmxUtils:54] Getting username and password for service: my-cluster-1b611c2a-zookeeper-nodes and secret: my-cluster-1b611c2a-zookeeper-jmx
2022-04-05 03:09:30 [main] [32mINFO [m [JmxUtils:58] Creating script file for service: my-cluster-1b611c2a-zookeeper-nodes
2022-04-05 03:09:30 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-1b611c2a-kafka-clients-7bd784d5cd-799k2 -- /bin/bash -c echo 'open service:jmx:rmi:///jndi/rmi://my-cluster-1b611c2a-zookeeper-nodes:9999/jmxrmi -u D2Df1ufyu6zerSzL -p ogvh3uAaAOQHEBD1
bean org.apache.ZooKeeperService:name0=ReplicatedServer_id3
get -i *' > /tmp/my-cluster-1b611c2a-zookeeper-nodes.sh
2022-04-05 03:09:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:09:30 [main] [32mINFO [m [JmxUtils:63] Waiting for JMX metrics for service: my-cluster-1b611c2a-zookeeper-nodes will be present
2022-04-05 03:09:31 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-1b611c2a-kafka-clients-7bd784d5cd-799k2 -- java -jar jmxterm/jmxterm.jar -i /tmp/my-cluster-1b611c2a-zookeeper-nodes.sh
2022-04-05 03:09:31 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:09:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-1b611c2a-kafka-clients-7bd784d5cd-799k2 -- java -jar jmxterm/jmxterm.jar -i /tmp/my-cluster-1b611c2a-zookeeper-nodes.sh
2022-04-05 03:09:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:09:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-1b611c2a-kafka-clients-7bd784d5cd-799k2 -- java -jar jmxterm/jmxterm.jar -i /tmp/my-cluster-1b611c2a-zookeeper-nodes.sh
2022-04-05 03:09:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:09:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-1b611c2a-kafka-clients-7bd784d5cd-799k2 -- java -jar jmxterm/jmxterm.jar -i /tmp/my-cluster-1b611c2a-zookeeper-nodes.sh
2022-04-05 03:09:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:09:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-1b611c2a-kafka-clients-7bd784d5cd-799k2 -- java -jar jmxterm/jmxterm.jar -i /tmp/my-cluster-1b611c2a-zookeeper-nodes.sh
2022-04-05 03:09:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:09:40 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-1b611c2a-kafka-clients-7bd784d5cd-799k2 -- java -jar jmxterm/jmxterm.jar -i /tmp/my-cluster-1b611c2a-zookeeper-nodes.sh
2022-04-05 03:09:40 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:09:42 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-1b611c2a-kafka-clients-7bd784d5cd-799k2 -- java -jar jmxterm/jmxterm.jar -i /tmp/my-cluster-1b611c2a-zookeeper-nodes.sh
2022-04-05 03:09:42 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:09:43 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-1b611c2a-kafka-clients-7bd784d5cd-799k2 -- java -jar jmxterm/jmxterm.jar -i /tmp/my-cluster-1b611c2a-zookeeper-nodes.sh
2022-04-05 03:09:43 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:09:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-1b611c2a-kafka-clients-7bd784d5cd-799k2 -- java -jar jmxterm/jmxterm.jar -i /tmp/my-cluster-1b611c2a-zookeeper-nodes.sh
2022-04-05 03:09:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:09:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-1b611c2a-kafka-clients-7bd784d5cd-799k2 -- java -jar jmxterm/jmxterm.jar -i /tmp/my-cluster-1b611c2a-zookeeper-nodes.sh
2022-04-05 03:09:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:09:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-1b611c2a-kafka-clients-7bd784d5cd-799k2 -- java -jar jmxterm/jmxterm.jar -i /tmp/my-cluster-1b611c2a-zookeeper-nodes.sh
2022-04-05 03:09:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:09:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-1b611c2a-kafka-clients-7bd784d5cd-799k2 -- java -jar jmxterm/jmxterm.jar -i /tmp/my-cluster-1b611c2a-zookeeper-nodes.sh
2022-04-05 03:09:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:09:52 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-1b611c2a-kafka-clients-7bd784d5cd-799k2 -- java -jar jmxterm/jmxterm.jar -i /tmp/my-cluster-1b611c2a-zookeeper-nodes.sh
2022-04-05 03:09:52 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:09:54 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-1b611c2a-kafka-clients-7bd784d5cd-799k2 -- java -jar jmxterm/jmxterm.jar -i /tmp/my-cluster-1b611c2a-zookeeper-nodes.sh
2022-04-05 03:09:54 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:09:54 [main] [32mINFO [m [JmxIsolatedST:110] Checking that Zookeeper JMX secret is created with custom labels and annotations
2022-04-05 03:09:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:09:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaZookeeperAndKafkaConnectWithJMX
2022-04-05 03:09:54 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-1b611c2a-scraper in namespace namespace-141
2022-04-05 03:09:54 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-1b611c2a in namespace namespace-141
2022-04-05 03:09:54 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1b611c2a in namespace namespace-141
2022-04-05 03:09:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-1b611c2a-allow in namespace namespace-141
2022-04-05 03:09:54 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-1b611c2a-kafka-clients in namespace namespace-141
2022-04-05 03:10:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:10:44 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-141 for test case:testKafkaZookeeperAndKafkaConnectWithJMX
2022-04-05 03:10:50 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.JmxIsolatedST.testKafkaZookeeperAndKafkaConnectWithJMX-FINISHED
2022-04-05 03:10:50 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:10:50 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:10:50 [main] [32mINFO [m [ResourceManager:346] In context JmxIsolatedST is everything deleted.
2022-04-05 03:10:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 346.737 s - in io.strimzi.systemtest.metrics.JmxIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.dump.LogDumpScriptIsolatedST
2022-04-05 03:10:50 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 03:11:15 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-05 03:11:15 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-05 03:11:15 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-05 03:11:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:11:15 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-05 03:11:15 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 03:11:15 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 03:11:15 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 03:11:15 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:11:15 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 03:11:15 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:11:15 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:11:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 03:11:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 03:11:15 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:11:15 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 03:11:15 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:11:15 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 03:11:15 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 03:11:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 03:11:15 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:11:15 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 03:11:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:11:15 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 03:11:25 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 03:11:25 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 03:11:25 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:11:25 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 03:11:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 03:11:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 03:11:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:11:40 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@575dcac6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-05 03:11:40 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-05 03:11:40 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-05 03:11:41 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 03:11:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:11:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:11:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 03:11:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 03:11:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 03:11:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 03:11:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 03:11:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 03:11:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 03:11:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 03:11:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:11:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:11:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 03:11:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 03:11:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 03:11:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 03:11:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:11:41 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-05 03:11:41 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 03:11:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 03:11:41 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-05 03:11:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 03:11:41 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-05 03:11:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 03:11:41 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 03:11:41 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:11:41 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-05 03:11:41 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 03:11:41 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 03:11:41 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 03:11:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:11:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 03:11:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:11:41 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-05 03:12:12 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-05 03:12:12 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-05 03:12:22 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-05 03:12:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:12:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.dump.LogDumpScriptIsolatedST.dumpPartitions-STARTED
2022-04-05 03:12:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:12:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-60921dcb in namespace infra-namespace
2022-04-05 03:12:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-60921dcb will have desired state: Ready
2022-04-05 03:13:44 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-60921dcb is in desired state: Ready
2022-04-05 03:13:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-60921dcb-hello-world-producer in namespace infra-namespace
2022-04-05 03:13:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-60921dcb-hello-world-consumer in namespace infra-namespace
2022-04-05 03:13:44 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-60921dcb-hello-world-producer will be in active state
2022-04-05 03:13:45 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-60921dcb-hello-world-consumer will be in active state
2022-04-05 03:13:45 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-60921dcb-hello-world-producer and consumer my-cluster-60921dcb-hello-world-consumer finish
2022-04-05 03:14:02 [main] [32mINFO [m [LogDumpScriptIsolatedST:78] Print partition segments from cluster infra-namespace/my-cluster-60921dcb
2022-04-05 03:14:02 [main] [32mINFO [m [Exec:417] Command: /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/log-dump/run.sh partition --namespace infra-namespace --cluster my-cluster-60921dcb --topic my-topic-1209262512-1995908342 --partition 0 --dry-run
2022-04-05 03:14:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:14:02 [main] [32mINFO [m [LogDumpScriptIsolatedST:87] Dump topic partition from cluster infra-namespace/my-cluster-60921dcb
2022-04-05 03:14:04 [main] [32mINFO [m [Exec:417] Command: /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/log-dump/run.sh partition --namespace infra-namespace --cluster my-cluster-60921dcb --topic my-topic-1209262512-1995908342 --partition 0 --out-path /home/ec2-user/strimzi-kafka-operator/systemtest/target/my-cluster-60921dcb
2022-04-05 03:14:04 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:14:04 [main] [32mINFO [m [LogDumpScriptIsolatedST:99] Dump consumer offsets partition from cluster infra-namespace/my-cluster-60921dcb
2022-04-05 03:14:09 [main] [32mINFO [m [Exec:417] Command: /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/log-dump/run.sh cg_offsets --namespace infra-namespace --cluster my-cluster-60921dcb --group-id my-group --out-path /home/ec2-user/strimzi-kafka-operator/systemtest/target/my-cluster-60921dcb
2022-04-05 03:14:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:14:09 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:14:09 [main] [32mINFO [m [ResourceManager:348] Delete all resources for dumpPartitions
2022-04-05 03:14:09 [main] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-60921dcb-hello-world-producer in namespace infra-namespace
2022-04-05 03:14:09 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-60921dcb in namespace infra-namespace
2022-04-05 03:14:09 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-60921dcb-hello-world-consumer in namespace infra-namespace
2022-04-05 03:14:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:14:19 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.dump.LogDumpScriptIsolatedST.dumpPartitions-FINISHED
2022-04-05 03:14:19 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:14:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:14:19 [main] [32mINFO [m [ResourceManager:346] In context LogDumpScriptIsolatedST is everything deleted.
2022-04-05 03:14:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 209.099 s - in io.strimzi.systemtest.dump.LogDumpScriptIsolatedST
2022-04-05 03:14:19 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-05 03:14:19 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-05 03:14:19 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-05 03:14:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:14:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-05 03:14:19 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 03:14:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 03:14:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:14:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:14:19 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 03:14:19 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 03:14:19 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 03:14:19 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 03:14:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 03:14:19 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:14:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 03:14:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 03:14:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:14:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 03:14:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 03:14:19 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:14:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 03:14:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:14:19 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 03:14:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 03:14:19 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:14:19 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:14:19 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 03:14:29 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 03:14:29 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 03:14:39 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:14:44 [main] [32mINFO [m [TestExecutionListener:40] =======================================================================
2022-04-05 03:14:44 [main] [32mINFO [m [TestExecutionListener:41] =======================================================================
2022-04-05 03:14:44 [main] [32mINFO [m [TestExecutionListener:42]                         Test run finished
2022-04-05 03:14:44 [main] [32mINFO [m [TestExecutionListener:43] =======================================================================
2022-04-05 03:14:44 [main] [32mINFO [m [TestExecutionListener:44] =======================================================================
2022-04-05 03:14:44 [main] [32mINFO [m [TestExecutionListener:29] =======================================================================
2022-04-05 03:14:44 [main] [32mINFO [m [TestExecutionListener:30] =======================================================================
2022-04-05 03:14:44 [main] [32mINFO [m [TestExecutionListener:31]                         Test run started
2022-04-05 03:14:44 [main] [32mINFO [m [TestExecutionListener:32] =======================================================================
2022-04-05 03:14:44 [main] [32mINFO [m [TestExecutionListener:33] =======================================================================
2022-04-05 03:14:44 [main] [32mINFO [m [TestExecutionListener:48] Following testclasses are selected for run:
2022-04-05 03:14:44 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.rollingupdate.RollingUpdateST
2022-04-05 03:14:44 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST
2022-04-05 03:14:44 [main] [32mINFO [m [TestExecutionListener:52] =======================================================================
2022-04-05 03:14:44 [main] [32mINFO [m [TestExecutionListener:53] =======================================================================
[[1;34mINFO[m] Running io.strimzi.systemtest.rollingupdate.RollingUpdateST
2022-04-05 03:14:44 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@49b5b064
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-05 03:14:44 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-05 03:14:44 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-05 03:14:45 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 03:14:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:14:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:14:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 03:14:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 03:14:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 03:14:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 03:14:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 03:14:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 03:14:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 03:14:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 03:14:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:14:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:14:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 03:14:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 03:14:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 03:14:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 03:14:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:14:45 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-05 03:14:45 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 03:14:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 03:14:45 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-05 03:14:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 03:14:45 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-05 03:14:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 03:14:45 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 03:14:45 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:14:45 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-05 03:14:45 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 03:14:45 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 03:14:45 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 03:14:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:14:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 03:14:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:14:45 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-05 03:15:21 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-05 03:15:21 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-05 03:15:31 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-05 03:15:31 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: rolling-update-st
2022-04-05 03:15:31 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: rolling-update-st
2022-04-05 03:15:31 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: rolling-update-st
2022-04-05 03:15:31 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:15:31 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testClusterOperatorFinishAllRollingUpdates-STARTED
2022-04-05 03:15:31 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:15:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-494962b3 in namespace rolling-update-st
2022-04-05 03:15:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-494962b3 will have desired state: Ready
2022-04-05 03:17:23 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-494962b3 is in desired state: Ready
2022-04-05 03:17:28 [main] [32mINFO [m [RollingUpdateST:630] Deleting Cluster Operator pod with labels LabelSelector(matchExpressions=[], matchLabels={name=strimzi-cluster-operator}, additionalProperties={})
2022-04-05 03:17:28 [main] [32mINFO [m [RollingUpdateST:632] Cluster Operator pod deleted
2022-04-05 03:17:28 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-494962b3-zookeeper rolling update
2022-04-05 03:18:03 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-494962b3-zookeeper has been successfully rolled
2022-04-05 03:18:03 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-494962b3-zookeeper to be ready
2022-04-05 03:18:27 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-494962b3 will have desired state: Ready
2022-04-05 03:18:27 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-494962b3 is in desired state: Ready
2022-04-05 03:18:27 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-494962b3 is ready
2022-04-05 03:18:29 [main] [32mINFO [m [RollingUpdateST:639] Deleting Cluster Operator pod with labels LabelSelector(matchExpressions=[], matchLabels={name=strimzi-cluster-operator}, additionalProperties={})
2022-04-05 03:18:29 [main] [32mINFO [m [RollingUpdateST:641] Cluster Operator pod deleted
2022-04-05 03:18:29 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-494962b3-kafka rolling update
2022-04-05 03:19:54 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-494962b3-kafka has been successfully rolled
2022-04-05 03:19:54 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-494962b3-kafka to be ready
2022-04-05 03:20:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-494962b3 will have desired state: Ready
2022-04-05 03:20:26 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-494962b3 is in desired state: Ready
2022-04-05 03:20:26 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-494962b3 is ready
2022-04-05 03:20:26 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:20:26 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testClusterOperatorFinishAllRollingUpdates
2022-04-05 03:20:26 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-494962b3 in namespace rolling-update-st
2022-04-05 03:20:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:20:36 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testClusterOperatorFinishAllRollingUpdates-FINISHED
2022-04-05 03:20:36 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:20:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:20:36 [main] [32mINFO [m [ResourceManager:346] In context RollingUpdateST is everything deleted.
2022-04-05 03:20:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 395.261 s - in io.strimzi.systemtest.rollingupdate.RollingUpdateST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST
2022-04-05 03:21:20 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 03:21:45 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-05 03:21:45 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-05 03:21:45 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-05 03:21:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:21:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-05 03:21:45 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 03:21:45 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 03:21:45 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 03:21:45 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:21:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 03:21:45 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 03:21:45 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:21:45 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 03:21:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 03:21:45 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 03:21:45 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 03:21:45 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:21:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 03:21:45 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:21:45 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 03:21:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:21:45 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:21:45 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 03:21:55 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 03:21:55 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 03:21:55 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:21:55 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 03:21:55 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:21:55 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 03:21:55 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 03:22:05 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:22:10 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@49b5b064
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-05 03:22:10 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-05 03:22:10 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-05 03:22:10 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 03:22:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:22:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:22:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 03:22:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 03:22:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 03:22:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 03:22:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 03:22:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 03:22:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 03:22:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 03:22:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:22:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:22:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 03:22:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 03:22:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 03:22:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 03:22:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:22:11 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-05 03:22:11 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 03:22:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 03:22:11 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-05 03:22:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 03:22:11 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-05 03:22:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 03:22:11 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 03:22:11 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:22:11 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-05 03:22:11 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 03:22:11 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 03:22:11 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 03:22:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:22:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 03:22:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:22:11 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-05 03:22:35 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-05 03:22:35 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-05 03:22:45 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-05 03:22:45 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-05 03:22:45 [main] [32mINFO [m [OauthAbstractST:125] Deploying keycloak...
2022-04-05 03:22:45 [main] [32mINFO [m [KeycloakUtils:35] Prepare Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-05 03:24:14 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/prepare_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-05 03:24:14 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:24:14 [main] [32mINFO [m [KeycloakUtils:48] Keycloak in namespace infra-namespace is ready
2022-04-05 03:24:14 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret credential-example-keycloak
2022-04-05 03:24:14 [main] [32mINFO [m [SecretUtils:50] Secret credential-example-keycloak created
2022-04-05 03:24:14 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-producer-secret
2022-04-05 03:24:14 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-consumer-secret
2022-04-05 03:24:14 [main] [32mINFO [m [SecretUtils:70] Creating secret team-a-client-secret
2022-04-05 03:24:14 [main] [32mINFO [m [SecretUtils:70] Creating secret team-b-client-secret
2022-04-05 03:24:14 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-broker-secret
2022-04-05 03:24:14 [main] [32mINFO [m [SecretUtils:70] Creating secret my-connect-oauth
2022-04-05 03:24:14 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-oauth
2022-04-05 03:24:14 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-2-oauth
2022-04-05 03:24:14 [main] [32mINFO [m [SecretUtils:70] Creating secret my-bridge-oauth
2022-04-05 03:24:14 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-audience-secret
2022-04-05 03:24:14 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-client-secret
2022-04-05 03:24:14 [main] [32mINFO [m [KeycloakInstance:50] Replacing validIssuerUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal to pointing to internal realm
2022-04-05 03:24:14 [main] [32mINFO [m [KeycloakInstance:51] Replacing jwksEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/certs to pointing to internal realm
2022-04-05 03:24:14 [main] [32mINFO [m [KeycloakInstance:52] Replacing oauthTokenEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token to pointing to internal realm
2022-04-05 03:24:14 [main] [32mINFO [m [KeycloakInstance:60] Using HTTP endpoints
2022-04-05 03:24:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-plain-name in namespace infra-namespace
2022-04-05 03:24:14 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-plain-name will have desired state: Ready
2022-04-05 03:25:31 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-plain-name is in desired state: Ready
2022-04-05 03:25:31 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:25:31 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect-STARTED
2022-04-05 03:25:31 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:25:31 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 03:25:31 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-932096122-827118657 in namespace infra-namespace
2022-04-05 03:25:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-932096122-827118657 will have desired state: Ready
2022-04-05 03:25:32 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-932096122-827118657 is in desired state: Ready
2022-04-05 03:25:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-cdfbe254 in namespace infra-namespace
2022-04-05 03:25:32 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-cdfbe254 will be in active state
2022-04-05 03:25:33 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-cdfbe254 to finished
2022-04-05 03:25:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-cdfbe254 in namespace infra-namespace
2022-04-05 03:25:41 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-cdfbe254 will be in active state
2022-04-05 03:25:42 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-cdfbe254 to finished
2022-04-05 03:25:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-cdfbe254-kafka-clients in namespace infra-namespace
2022-04-05 03:25:53 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-cdfbe254-kafka-clients will be ready
2022-04-05 03:25:54 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-cdfbe254-kafka-clients is ready
2022-04-05 03:25:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-cdfbe254-scraper in namespace infra-namespace
2022-04-05 03:25:54 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-cdfbe254-scraper will be ready
2022-04-05 03:25:55 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-cdfbe254-scraper is ready
2022-04-05 03:25:55 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-cdfbe254-scraper to be ready
2022-04-05 03:26:05 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-cdfbe254-scraper is ready
2022-04-05 03:26:05 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-cdfbe254-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-05 03:26:05 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-cdfbe254-allow in namespace infra-namespace
2022-04-05 03:26:05 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-05 03:26:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-cdfbe254 in namespace infra-namespace
2022-04-05 03:26:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-cdfbe254 will have desired state: Ready
2022-04-05 03:27:09 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-cdfbe254 is in desired state: Ready
2022-04-05 03:27:09 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-05 03:27:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-cdfbe254-connect-8545b58576-h8m9z -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-05 03:27:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:27:10 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-05 03:27:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-cdfbe254-connect-8545b58576-h8m9z -- /bin/bash -c curl -X POST -H "Content-Type: application/json" --data '{ "name": "sink-test", "config": { "connector.class": "FileStreamSink", "tasks.max": "1", "topics": "my-topic-932096122-827118657", "file": "/tmp/test-file-sink.txt" } }' http://localhost:8083/connectors
2022-04-05 03:27:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:27:10 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-cdfbe254-connect-8545b58576-h8m9z
2022-04-05 03:27:14 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-cdfbe254-connect-8545b58576-h8m9z
2022-04-05 03:27:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:27:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerConnect
2022-04-05 03:27:14 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-cdfbe254-scraper in namespace infra-namespace
2022-04-05 03:27:14 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-cdfbe254-kafka-clients in namespace infra-namespace
2022-04-05 03:27:14 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-cdfbe254 in namespace infra-namespace
2022-04-05 03:27:14 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-cdfbe254-allow in namespace infra-namespace
2022-04-05 03:27:14 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-932096122-827118657 in namespace infra-namespace
2022-04-05 03:27:14 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-cdfbe254 in namespace infra-namespace
2022-04-05 03:27:14 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-cdfbe254 in namespace infra-namespace
2022-04-05 03:27:54 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:27:54 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect-FINISHED
2022-04-05 03:27:54 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:27:54 [main] [32mINFO [m [KeycloakUtils:52] Teardown Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-05 03:27:58 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/teardown_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-05 03:27:58 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:27:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:27:58 [main] [32mINFO [m [ResourceManager:348] Delete all resources for OauthPlainIsolatedST
2022-04-05 03:27:58 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-plain-name in namespace infra-namespace
2022-04-05 03:27:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-05 03:28:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:28:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:28:08 [main] [32mINFO [m [ResourceManager:346] In context OauthPlainIsolatedST is everything deleted.
2022-04-05 03:28:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 408.785 s - in io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST
2022-04-05 03:28:08 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-05 03:28:08 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-05 03:28:08 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-05 03:28:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:28:08 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-05 03:28:08 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 03:28:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 03:28:08 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 03:28:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 03:28:08 [ForkJoinPool.commonPool-worker-15] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 03:28:08 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 03:28:08 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:28:08 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 03:28:09 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:28:09 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:28:09 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 03:28:09 [ForkJoinPool.commonPool-worker-11] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:28:09 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 03:28:09 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 03:28:09 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:28:09 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 03:28:09 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 03:28:09 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 03:28:09 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:28:09 [ForkJoinPool.commonPool-worker-13] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:28:09 [ForkJoinPool.commonPool-worker-9] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 03:28:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:28:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 03:28:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 03:28:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 03:28:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:28:34 [main] [32mINFO [m [TestExecutionListener:40] =======================================================================
2022-04-05 03:28:34 [main] [32mINFO [m [TestExecutionListener:41] =======================================================================
2022-04-05 03:28:34 [main] [32mINFO [m [TestExecutionListener:42]                         Test run finished
2022-04-05 03:28:34 [main] [32mINFO [m [TestExecutionListener:43] =======================================================================
2022-04-05 03:28:34 [main] [32mINFO [m [TestExecutionListener:44] =======================================================================
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;33mWARNING[m] Flakes: 
[[1;33mWARNING[m] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testClusterOperatorFinishAllRollingUpdates(ExtensionContext)
[[1;31mERROR[m]   Run 1: RollingUpdateST.testClusterOperatorFinishAllRollingUpdates:625 ? Wait Timeout ...
[[1;34mINFO[m]   Run 2: PASS
[[1;34mINFO[m] 
[[1;33mWARNING[m] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect(ExtensionContext)
[[1;31mERROR[m]   Run 1: OauthPlainIsolatedST.testProducerConsumerConnect:287 ? Wait Timeout after 6000...
[[1;34mINFO[m]   Run 2: PASS
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;33mWARNING[m] Tests run: 304, Failures: 0, Errors: 0, Skipped: 10, Flakes: 2
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] [1mReactor Summary for Strimzi - Apache Kafka on Kubernetes and OpenShift 0.29.0-SNAPSHOT:[m
[[1;34mINFO[m] 
[[1;34mINFO[m] Strimzi - Apache Kafka on Kubernetes and OpenShift . [1;32mSUCCESS[m [  2.330 s]
[[1;34mINFO[m] test ............................................... [1;32mSUCCESS[m [  0.936 s]
[[1;34mINFO[m] crd-annotations .................................... [1;32mSUCCESS[m [  0.906 s]
[[1;34mINFO[m] crd-generator ...................................... [1;32mSUCCESS[m [  2.384 s]
[[1;34mINFO[m] api ................................................ [1;32mSUCCESS[m [  6.232 s]
[[1;34mINFO[m] mockkube ........................................... [1;32mSUCCESS[m [  0.811 s]
[[1;34mINFO[m] config-model ....................................... [1;32mSUCCESS[m [  0.655 s]
[[1;34mINFO[m] certificate-manager ................................ [1;32mSUCCESS[m [  0.686 s]
[[1;34mINFO[m] operator-common .................................... [1;32mSUCCESS[m [  1.596 s]
[[1;34mINFO[m] systemtest ......................................... [1;32mSUCCESS[m [  20:32 h]
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] [1;32mBUILD SUCCESS[m
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] Total time:  20:33 h
[[1;34mINFO[m] Finished at: 2022-04-05T03:28:34Z
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
